Files already downloaded and verified
Files already downloaded and verified
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
INFO - Created `MobileNetv2` model
          Use pre-trained model = True
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
  warnings.warn(
INFO - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.0005
               maximize: False
               weight_decay: 0.0005
           )
INFO - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.0005
********************pre-trained*****************
*************soft_pruning_mode*******************
INFO - >>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
0.00000000
tensor(1.4291, device='cuda:0', grad_fn=<AddBackward0>)
0.00000000
tensor(1.2005, device='cuda:0', grad_fn=<AddBackward0>)
0.00000000
tensor(1.2236, device='cuda:0', grad_fn=<AddBackward0>)
0.00000000
tensor(1.1557, device='cuda:0', grad_fn=<AddBackward0>)
0.00000000
tensor(1.2394, device='cuda:0', grad_fn=<AddBackward0>)
0.00000000
tensor(1.1689, device='cuda:0', grad_fn=<AddBackward0>)
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
0.00000000
tensor(1.1595, device='cuda:0', grad_fn=<AddBackward0>)
0.00000000
tensor(1.2096, device='cuda:0', grad_fn=<AddBackward0>)
0.00000000
tensor(1.1609, device='cuda:0', grad_fn=<AddBackward0>)
0.00000000
tensor(1.2479, device='cuda:0', grad_fn=<AddBackward0>)
0.00000000
tensor(1.1494, device='cuda:0', grad_fn=<AddBackward0>)
0.96281165
tensor(1.6588, device='cuda:0', grad_fn=<AddBackward0>)
0.96227443
tensor(1.5967, device='cuda:0', grad_fn=<AddBackward0>)
0.96022302
tensor(1.4347, device='cuda:0', grad_fn=<AddBackward0>)
0.94548786
tensor(1.4477, device='cuda:0', grad_fn=<AddBackward0>)
0.91790569
tensor(1.4388, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [0][   20/  196]   Loss 1.369970   Top1 54.140625   Top5 90.898438   BatchTime 0.313381   LR 0.000500
0.90646327
tensor(1.4340, device='cuda:0', grad_fn=<AddBackward0>)
0.90034580
tensor(2.3335, device='cuda:0', grad_fn=<AddBackward0>)
0.89361161
tensor(1.3849, device='cuda:0', grad_fn=<AddBackward0>)
0.89121962
tensor(1.3257, device='cuda:0', grad_fn=<AddBackward0>)
0.89164639
tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>)
0.89033842
tensor(1.2946, device='cuda:0', grad_fn=<AddBackward0>)
0.88936305
tensor(1.2898, device='cuda:0', grad_fn=<AddBackward0>)
0.88851607
tensor(1.3023, device='cuda:0', grad_fn=<AddBackward0>)
0.88719726
tensor(1.1364, device='cuda:0', grad_fn=<AddBackward0>)
0.88621819
tensor(1.1976, device='cuda:0', grad_fn=<AddBackward0>)
0.88583970
tensor(1.2212, device='cuda:0', grad_fn=<AddBackward0>)
0.88519895
tensor(1.2420, device='cuda:0', grad_fn=<AddBackward0>)
0.88453102
tensor(1.1686, device='cuda:0', grad_fn=<AddBackward0>)
0.88456953
tensor(1.1293, device='cuda:0', grad_fn=<AddBackward0>)
0.88396949
tensor(1.1257, device='cuda:0', grad_fn=<AddBackward0>)
0.88441807
tensor(1.0934, device='cuda:0', grad_fn=<AddBackward0>)
0.88419873
tensor(1.0814, device='cuda:0', grad_fn=<AddBackward0>)
0.88408959
tensor(1.1557, device='cuda:0', grad_fn=<AddBackward0>)
0.88403797
tensor(1.1851, device='cuda:0', grad_fn=<AddBackward0>)
0.88422990
tensor(1.1733, device='cuda:0', grad_fn=<AddBackward0>)
0.88346738
tensor(1.2067, device='cuda:0', grad_fn=<AddBackward0>)
0.88315505
tensor(1.2065, device='cuda:0', grad_fn=<AddBackward0>)
0.88292015
tensor(1.1696, device='cuda:0', grad_fn=<AddBackward0>)
0.88232106
tensor(1.0807, device='cuda:0', grad_fn=<AddBackward0>)
0.88235283
tensor(1.0419, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [0][   40/  196]   Loss 1.278735   Top1 56.835938   Top5 92.871094   BatchTime 0.275803   LR 0.000500
0.88218057
tensor(1.0357, device='cuda:0', grad_fn=<AddBackward0>)
0.88207728
tensor(1.1743, device='cuda:0', grad_fn=<AddBackward0>)
0.88242656
tensor(0.9323, device='cuda:0', grad_fn=<AddBackward0>)
0.88239717
tensor(1.0417, device='cuda:0', grad_fn=<AddBackward0>)
0.88286179
tensor(1.0285, device='cuda:0', grad_fn=<AddBackward0>)
0.88229954
tensor(1.1061, device='cuda:0', grad_fn=<AddBackward0>)
0.88029838
tensor(1.0526, device='cuda:0', grad_fn=<AddBackward0>)
0.87934709
tensor(0.9803, device='cuda:0', grad_fn=<AddBackward0>)
0.87887752
tensor(1.0266, device='cuda:0', grad_fn=<AddBackward0>)
0.87884331
tensor(1.1293, device='cuda:0', grad_fn=<AddBackward0>)
0.87883812
tensor(1.0313, device='cuda:0', grad_fn=<AddBackward0>)
0.87905157
tensor(1.0022, device='cuda:0', grad_fn=<AddBackward0>)
0.87935543
tensor(1.1716, device='cuda:0', grad_fn=<AddBackward0>)
0.88020456
tensor(1.0006, device='cuda:0', grad_fn=<AddBackward0>)
0.88346893
tensor(0.9014, device='cuda:0', grad_fn=<AddBackward0>)
0.88376945
tensor(1.0528, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [0][   60/  196]   Loss 1.197163   Top1 59.778646   Top5 94.036458   BatchTime 0.266315   LR 0.000499
0.88364863
tensor(1.0046, device='cuda:0', grad_fn=<AddBackward0>)
0.88390434
tensor(0.9728, device='cuda:0', grad_fn=<AddBackward0>)
0.88404018
tensor(0.9938, device='cuda:0', grad_fn=<AddBackward0>)
0.88440907
tensor(1.0345, device='cuda:0', grad_fn=<AddBackward0>)
0.88424003
tensor(0.9820, device='cuda:0', grad_fn=<AddBackward0>)
0.88424391
tensor(0.9392, device='cuda:0', grad_fn=<AddBackward0>)
0.88437086
tensor(0.8704, device='cuda:0', grad_fn=<AddBackward0>)
0.88400728
tensor(1.0144, device='cuda:0', grad_fn=<AddBackward0>)
0.88423443
tensor(1.0302, device='cuda:0', grad_fn=<AddBackward0>)
0.88416165
tensor(0.9642, device='cuda:0', grad_fn=<AddBackward0>)
0.88384247
tensor(1.0265, device='cuda:0', grad_fn=<AddBackward0>)
0.88412261
tensor(0.9171, device='cuda:0', grad_fn=<AddBackward0>)
0.88406694
tensor(1.1026, device='cuda:0', grad_fn=<AddBackward0>)
0.88404423
tensor(0.9231, device='cuda:0', grad_fn=<AddBackward0>)
0.88382179
tensor(1.0241, device='cuda:0', grad_fn=<AddBackward0>)
0.88372868
tensor(1.0382, device='cuda:0', grad_fn=<AddBackward0>)
0.88366675
tensor(1.0123, device='cuda:0', grad_fn=<AddBackward0>)
0.88355583
tensor(0.9842, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [0][   80/  196]   Loss 1.144238   Top1 61.738281   Top5 94.501953   BatchTime 0.257023   LR 0.000498
0.88311923
tensor(1.0804, device='cuda:0', grad_fn=<AddBackward0>)
0.88307440
tensor(0.9947, device='cuda:0', grad_fn=<AddBackward0>)
0.88302106
tensor(0.8750, device='cuda:0', grad_fn=<AddBackward0>)
0.88276964
tensor(0.8914, device='cuda:0', grad_fn=<AddBackward0>)
0.88297629
tensor(1.0047, device='cuda:0', grad_fn=<AddBackward0>)
0.88279635
tensor(0.8900, device='cuda:0', grad_fn=<AddBackward0>)
0.88259369
tensor(1.0471, device='cuda:0', grad_fn=<AddBackward0>)
0.88258916
tensor(0.9897, device='cuda:0', grad_fn=<AddBackward0>)
0.88268346
tensor(0.9708, device='cuda:0', grad_fn=<AddBackward0>)
0.88246828
tensor(1.0215, device='cuda:0', grad_fn=<AddBackward0>)
0.88253736
tensor(0.9583, device='cuda:0', grad_fn=<AddBackward0>)
0.88202488
tensor(0.9033, device='cuda:0', grad_fn=<AddBackward0>)
0.88167560
tensor(0.9983, device='cuda:0', grad_fn=<AddBackward0>)
0.88094896
tensor(0.8729, device='cuda:0', grad_fn=<AddBackward0>)
0.88046509
tensor(0.8835, device='cuda:0', grad_fn=<AddBackward0>)
0.88073027
tensor(0.9592, device='cuda:0', grad_fn=<AddBackward0>)
0.88092297
tensor(0.7702, device='cuda:0', grad_fn=<AddBackward0>)
0.88074630
tensor(0.9491, device='cuda:0', grad_fn=<AddBackward0>)
0.88075846
tensor(0.9267, device='cuda:0', grad_fn=<AddBackward0>)
0.88044697
tensor(0.9693, device='cuda:0', grad_fn=<AddBackward0>)
0.88019806
tensor(0.8995, device='cuda:0', grad_fn=<AddBackward0>)
0.87998831
tensor(0.9642, device='cuda:0', grad_fn=<AddBackward0>)
0.87956387
tensor(0.9660, device='cuda:0', grad_fn=<AddBackward0>)
0.87937057
tensor(0.8962, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [0][  100/  196]   Loss 1.102598   Top1 63.015625   Top5 95.003906   BatchTime 0.256604   LR 0.000497
0.87902576
tensor(0.8850, device='cuda:0', grad_fn=<AddBackward0>)
0.87869948
tensor(0.9396, device='cuda:0', grad_fn=<AddBackward0>)
0.87820369
tensor(0.7598, device='cuda:0', grad_fn=<AddBackward0>)
0.87810290
tensor(0.9854, device='cuda:0', grad_fn=<AddBackward0>)
0.87798524
tensor(0.8874, device='cuda:0', grad_fn=<AddBackward0>)
0.87801921
tensor(0.8908, device='cuda:0', grad_fn=<AddBackward0>)
0.87754339
tensor(0.9555, device='cuda:0', grad_fn=<AddBackward0>)
0.87689960
tensor(1.0310, device='cuda:0', grad_fn=<AddBackward0>)
0.87613487
tensor(0.8129, device='cuda:0', grad_fn=<AddBackward0>)
0.87568820
tensor(0.9515, device='cuda:0', grad_fn=<AddBackward0>)
0.87489474
tensor(0.9617, device='cuda:0', grad_fn=<AddBackward0>)
0.87435025
tensor(0.8206, device='cuda:0', grad_fn=<AddBackward0>)
0.87398946
tensor(0.8428, device='cuda:0', grad_fn=<AddBackward0>)
0.87348211
tensor(0.8405, device='cuda:0', grad_fn=<AddBackward0>)
0.87298048
tensor(0.8179, device='cuda:0', grad_fn=<AddBackward0>)
0.87254071
tensor(0.9109, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [0][  120/  196]   Loss 1.067632   Top1 64.163411   Top5 95.335286   BatchTime 0.256838   LR 0.000495
0.87171710
tensor(0.7662, device='cuda:0', grad_fn=<AddBackward0>)
0.87108636
tensor(0.9831, device='cuda:0', grad_fn=<AddBackward0>)
0.87037736
tensor(1.0011, device='cuda:0', grad_fn=<AddBackward0>)
0.86975336
tensor(0.8219, device='cuda:0', grad_fn=<AddBackward0>)
0.86923689
tensor(0.8756, device='cuda:0', grad_fn=<AddBackward0>)
0.86870456
tensor(0.8172, device='cuda:0', grad_fn=<AddBackward0>)
0.86852735
tensor(0.7722, device='cuda:0', grad_fn=<AddBackward0>)
0.86811292
tensor(0.8217, device='cuda:0', grad_fn=<AddBackward0>)
0.86782551
tensor(0.8525, device='cuda:0', grad_fn=<AddBackward0>)
0.86739320
tensor(0.9021, device='cuda:0', grad_fn=<AddBackward0>)
0.86726516
tensor(0.7451, device='cuda:0', grad_fn=<AddBackward0>)
0.86692566
tensor(0.9960, device='cuda:0', grad_fn=<AddBackward0>)
0.86638826
tensor(0.9052, device='cuda:0', grad_fn=<AddBackward0>)
0.86634904
tensor(0.8122, device='cuda:0', grad_fn=<AddBackward0>)
0.86598718
tensor(0.8974, device='cuda:0', grad_fn=<AddBackward0>)
0.86525649
tensor(0.8296, device='cuda:0', grad_fn=<AddBackward0>)
0.86499047
tensor(0.8921, device='cuda:0', grad_fn=<AddBackward0>)
0.86483574
tensor(0.7901, device='cuda:0', grad_fn=<AddBackward0>)
0.86438787
tensor(0.9009, device='cuda:0', grad_fn=<AddBackward0>)
0.86404014
tensor(0.8570, device='cuda:0', grad_fn=<AddBackward0>)
0.86359525
tensor(0.9235, device='cuda:0', grad_fn=<AddBackward0>)
0.86331141
tensor(0.9355, device='cuda:0', grad_fn=<AddBackward0>)
0.86318111
tensor(0.8792, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [0][  140/  196]   Loss 1.037125   Top1 65.262277   Top5 95.650112   BatchTime 0.256568   LR 0.000494
0.86306494
tensor(0.8601, device='cuda:0', grad_fn=<AddBackward0>)
0.86270565
tensor(0.6920, device='cuda:0', grad_fn=<AddBackward0>)
0.86275858
tensor(0.8316, device='cuda:0', grad_fn=<AddBackward0>)
0.86301327
tensor(0.7242, device='cuda:0', grad_fn=<AddBackward0>)
0.86304134
tensor(0.8205, device='cuda:0', grad_fn=<AddBackward0>)
0.86281270
tensor(0.8107, device='cuda:0', grad_fn=<AddBackward0>)
0.86233151
tensor(3.5061, device='cuda:0', grad_fn=<AddBackward0>)
0.86192757
tensor(0.8993, device='cuda:0', grad_fn=<AddBackward0>)
0.86170101
tensor(0.8001, device='cuda:0', grad_fn=<AddBackward0>)
0.86168045
tensor(0.8730, device='cuda:0', grad_fn=<AddBackward0>)
0.86112815
tensor(0.7739, device='cuda:0', grad_fn=<AddBackward0>)
0.86054456
tensor(0.8625, device='cuda:0', grad_fn=<AddBackward0>)
0.86046207
tensor(0.8208, device='cuda:0', grad_fn=<AddBackward0>)
0.86059952
tensor(0.7696, device='cuda:0', grad_fn=<AddBackward0>)
0.86043251
tensor(0.8442, device='cuda:0', grad_fn=<AddBackward0>)
0.86044616
tensor(0.8129, device='cuda:0', grad_fn=<AddBackward0>)
0.86027771
tensor(0.8821, device='cuda:0', grad_fn=<AddBackward0>)
0.86046958
tensor(0.8704, device='cuda:0', grad_fn=<AddBackward0>)
0.86019766
tensor(0.9698, device='cuda:0', grad_fn=<AddBackward0>)
0.86009824
tensor(0.8055, device='cuda:0', grad_fn=<AddBackward0>)
0.85999227
tensor(0.8124, device='cuda:0', grad_fn=<AddBackward0>)
0.86009187
tensor(0.8589, device='cuda:0', grad_fn=<AddBackward0>)
0.85988170
tensor(0.8705, device='cuda:0', grad_fn=<AddBackward0>)
0.85964394
tensor(0.7925, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [0][  160/  196]   Loss 1.028412   Top1 65.747070   Top5 95.546875   BatchTime 0.255799   LR 0.000492
0.85927176
tensor(0.7573, device='cuda:0', grad_fn=<AddBackward0>)
0.85933310
tensor(0.8122, device='cuda:0', grad_fn=<AddBackward0>)
0.85922045
tensor(0.8881, device='cuda:0', grad_fn=<AddBackward0>)
0.85925913
tensor(0.8120, device='cuda:0', grad_fn=<AddBackward0>)
0.85929829
tensor(0.9377, device='cuda:0', grad_fn=<AddBackward0>)
0.85921860
tensor(0.9210, device='cuda:0', grad_fn=<AddBackward0>)
0.85933584
tensor(0.8467, device='cuda:0', grad_fn=<AddBackward0>)
0.85881191
tensor(0.8054, device='cuda:0', grad_fn=<AddBackward0>)
0.85903984
tensor(0.8416, device='cuda:0', grad_fn=<AddBackward0>)
0.85894549
tensor(0.8885, device='cuda:0', grad_fn=<AddBackward0>)
0.85907227
tensor(0.8930, device='cuda:0', grad_fn=<AddBackward0>)
0.85880727
tensor(0.7910, device='cuda:0', grad_fn=<AddBackward0>)
0.85892147
tensor(0.7842, device='cuda:0', grad_fn=<AddBackward0>)
0.85934263
tensor(0.9385, device='cuda:0', grad_fn=<AddBackward0>)
0.85912031
tensor(0.8149, device='cuda:0', grad_fn=<AddBackward0>)
0.85915500
tensor(0.7879, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [0][  180/  196]   Loss 1.008667   Top1 66.375868   Top5 95.785590   BatchTime 0.254982   LR 0.000490
0.85909426
tensor(0.8637, device='cuda:0', grad_fn=<AddBackward0>)
0.85902369
tensor(0.9673, device='cuda:0', grad_fn=<AddBackward0>)
0.85922521
tensor(0.7396, device='cuda:0', grad_fn=<AddBackward0>)
0.85916817
tensor(0.6535, device='cuda:0', grad_fn=<AddBackward0>)
0.85889345
tensor(0.6880, device='cuda:0', grad_fn=<AddBackward0>)
0.85877430
tensor(0.9919, device='cuda:0', grad_fn=<AddBackward0>)
0.85852057
tensor(0.8325, device='cuda:0', grad_fn=<AddBackward0>)
0.85846919
tensor(0.8853, device='cuda:0', grad_fn=<AddBackward0>)
0.85843253
tensor(0.7740, device='cuda:0', grad_fn=<AddBackward0>)
0.85841191
tensor(0.7765, device='cuda:0', grad_fn=<AddBackward0>)
0.85868478
tensor(0.8482, device='cuda:0', grad_fn=<AddBackward0>)
0.85888034
tensor(0.8199, device='cuda:0', grad_fn=<AddBackward0>)
0.85886514
tensor(0.8046, device='cuda:0', grad_fn=<AddBackward0>)
0.85894114
tensor(0.8668, device='cuda:0', grad_fn=<AddBackward0>)
0.85894382
tensor(0.8281, device='cuda:0', grad_fn=<AddBackward0>)
0.85920841
tensor(0.6622, device='cuda:0', grad_fn=<AddBackward0>)
0.85875815
tensor(0.9047, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 66.900    Top5: 95.920    Loss: 0.993
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.85861087
tensor(0.9651, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.811502   Top1 72.597656   Top5 97.285156   BatchTime 0.113611
INFO - Validation [0][   40/   40]   Loss 0.810250   Top1 72.380000   Top5 97.640000   BatchTime 0.084239
INFO - ==> Top1: 72.380    Top5: 97.640    Loss: 0.810
INFO - ==> Sparsity : 0.282
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 72.380   Top5: 97.640]
features.0.conv.0 tensor(0.2986)
features.0.conv.3 tensor(0.1270)
features.1.conv.0 tensor(0.0625)
features.1.conv.3 tensor(0.0822)
features.1.conv.6 tensor(0.0725)
features.2.conv.0 tensor(0.1317)
features.2.conv.3 tensor(0.3534)
features.2.conv.6 tensor(0.1782)
features.3.conv.0 tensor(0.0642)
features.3.conv.3 tensor(0.0841)
features.3.conv.6 tensor(0.1074)
features.4.conv.0 tensor(0.0866)
features.4.conv.3 tensor(0.3061)
features.4.conv.6 tensor(0.1761)
features.5.conv.0 tensor(0.3885)
features.5.conv.3 tensor(0.4317)
features.5.conv.6 tensor(0.1139)
features.6.conv.0 tensor(0.0584)
features.6.conv.3 tensor(0.0544)
features.6.conv.6 tensor(0.0816)
features.7.conv.0 tensor(0.2528)
features.7.conv.3 tensor(0.4592)
features.7.conv.6 tensor(0.1760)
features.8.conv.0 tensor(0.4787)
features.8.conv.3 tensor(0.5396)
features.8.conv.6 tensor(0.1544)
features.9.conv.0 tensor(0.4886)
features.9.conv.3 tensor(0.5703)
features.9.conv.6 tensor(0.1477)
features.10.conv.0 tensor(0.0768)
features.10.conv.3 tensor(0.1076)
features.10.conv.6 tensor(0.1061)
features.11.conv.0 tensor(0.5738)
features.11.conv.3 tensor(0.6524)
features.11.conv.6 tensor(0.7150)
features.12.conv.0 tensor(0.5560)
features.12.conv.3 tensor(0.6709)
features.12.conv.6 tensor(0.1583)
features.13.conv.0 tensor(0.3722)
features.13.conv.3 tensor(0.4932)
features.13.conv.6 tensor(0.0929)
features.14.conv.0 tensor(0.7534)
features.14.conv.3 tensor(0.8191)
features.14.conv.6 tensor(0.1143)
features.15.conv.0 tensor(0.7353)
features.15.conv.3 tensor(0.8265)
features.15.conv.6 tensor(0.1496)
features.16.conv.0 tensor(0.4971)
features.16.conv.3 tensor(0.8066)
features.16.conv.6 tensor(0.0492)
conv.0 tensor(0.0567)
tensor(617991.) 2188896.0
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)
  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
0.85857677
tensor(0.7776, device='cuda:0', grad_fn=<AddBackward0>)
0.85851163
tensor(0.7924, device='cuda:0', grad_fn=<AddBackward0>)
0.85844690
tensor(0.6935, device='cuda:0', grad_fn=<AddBackward0>)
0.85862911
tensor(0.7678, device='cuda:0', grad_fn=<AddBackward0>)
0.85853863
tensor(0.8116, device='cuda:0', grad_fn=<AddBackward0>)
0.85858703
tensor(0.7123, device='cuda:0', grad_fn=<AddBackward0>)
0.85859114
tensor(0.7394, device='cuda:0', grad_fn=<AddBackward0>)
0.85841006
tensor(0.7888, device='cuda:0', grad_fn=<AddBackward0>)
0.85838544
tensor(0.7517, device='cuda:0', grad_fn=<AddBackward0>)
0.85826349
tensor(0.7228, device='cuda:0', grad_fn=<AddBackward0>)
0.85828936
tensor(0.7786, device='cuda:0', grad_fn=<AddBackward0>)
0.85815978
tensor(0.6768, device='cuda:0', grad_fn=<AddBackward0>)
0.85801685
tensor(0.8051, device='cuda:0', grad_fn=<AddBackward0>)
0.85848325
tensor(0.8185, device='cuda:0', grad_fn=<AddBackward0>)
0.85815388
tensor(0.5993, device='cuda:0', grad_fn=<AddBackward0>)
0.85783261
tensor(0.8142, device='cuda:0', grad_fn=<AddBackward0>)
0.85789829
tensor(0.7577, device='cuda:0', grad_fn=<AddBackward0>)
0.85777324
tensor(0.7596, device='cuda:0', grad_fn=<AddBackward0>)
0.85768098
tensor(0.7903, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [1][   20/  196]   Loss 0.752070   Top1 75.175781   Top5 97.851562   BatchTime 0.337569   LR 0.000485
0.85756731
tensor(0.6832, device='cuda:0', grad_fn=<AddBackward0>)
0.85775894
tensor(0.6688, device='cuda:0', grad_fn=<AddBackward0>)
0.85769039
tensor(0.8619, device='cuda:0', grad_fn=<AddBackward0>)
0.85785472
tensor(0.8197, device='cuda:0', grad_fn=<AddBackward0>)
0.85753459
tensor(0.8604, device='cuda:0', grad_fn=<AddBackward0>)
0.85759556
tensor(0.7462, device='cuda:0', grad_fn=<AddBackward0>)
0.85750514
tensor(0.8078, device='cuda:0', grad_fn=<AddBackward0>)
0.85737431
tensor(0.6829, device='cuda:0', grad_fn=<AddBackward0>)
0.85724789
tensor(0.7521, device='cuda:0', grad_fn=<AddBackward0>)
0.85731012
tensor(0.8227, device='cuda:0', grad_fn=<AddBackward0>)
0.85719800
tensor(0.8753, device='cuda:0', grad_fn=<AddBackward0>)
0.85710466
tensor(0.7176, device='cuda:0', grad_fn=<AddBackward0>)
0.85686189
tensor(0.8032, device='cuda:0', grad_fn=<AddBackward0>)
0.85559362
tensor(0.7639, device='cuda:0', grad_fn=<AddBackward0>)
0.84857541
tensor(0.7914, device='cuda:0', grad_fn=<AddBackward0>)
0.84163755
tensor(0.7001, device='cuda:0', grad_fn=<AddBackward0>)
0.84070230
tensor(0.7503, device='cuda:0', grad_fn=<AddBackward0>)
0.83729511
tensor(0.8072, device='cuda:0', grad_fn=<AddBackward0>)
0.83465397
tensor(0.7087, device='cuda:0', grad_fn=<AddBackward0>)
0.83547992
tensor(0.6633, device='cuda:0', grad_fn=<AddBackward0>)
0.83518249
tensor(0.7838, device='cuda:0', grad_fn=<AddBackward0>)
0.83478951
tensor(0.7615, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [1][   40/  196]   Loss 0.760720   Top1 74.755859   Top5 97.880859   BatchTime 0.305400   LR 0.000482
0.83441430
tensor(0.5552, device='cuda:0', grad_fn=<AddBackward0>)
0.83388531
tensor(0.8028, device='cuda:0', grad_fn=<AddBackward0>)
0.83379084
tensor(0.7275, device='cuda:0', grad_fn=<AddBackward0>)
0.83325136
tensor(0.8297, device='cuda:0', grad_fn=<AddBackward0>)
0.83270806
tensor(0.7523, device='cuda:0', grad_fn=<AddBackward0>)
0.83260113
tensor(0.5937, device='cuda:0', grad_fn=<AddBackward0>)
0.83261359
tensor(0.7579, device='cuda:0', grad_fn=<AddBackward0>)
0.83263576
tensor(0.7076, device='cuda:0', grad_fn=<AddBackward0>)
0.83260643
tensor(0.6802, device='cuda:0', grad_fn=<AddBackward0>)
0.83305067
tensor(0.6779, device='cuda:0', grad_fn=<AddBackward0>)
0.83336240
tensor(0.8694, device='cuda:0', grad_fn=<AddBackward0>)
0.83379036
tensor(0.7890, device='cuda:0', grad_fn=<AddBackward0>)
0.83426440
tensor(0.8099, device='cuda:0', grad_fn=<AddBackward0>)
0.83504397
tensor(0.7017, device='cuda:0', grad_fn=<AddBackward0>)
0.83530742
tensor(0.6114, device='cuda:0', grad_fn=<AddBackward0>)
0.83551842
tensor(0.7326, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [1][   60/  196]   Loss 0.750465   Top1 74.928385   Top5 97.968750   BatchTime 0.286974   LR 0.000479
0.83627683
tensor(0.7725, device='cuda:0', grad_fn=<AddBackward0>)
0.83772188
tensor(0.8293, device='cuda:0', grad_fn=<AddBackward0>)
0.83896405
tensor(0.6371, device='cuda:0', grad_fn=<AddBackward0>)
0.84047794
tensor(0.6138, device='cuda:0', grad_fn=<AddBackward0>)
0.84534776
tensor(0.6955, device='cuda:0', grad_fn=<AddBackward0>)
0.85526389
tensor(0.6512, device='cuda:0', grad_fn=<AddBackward0>)
0.85784537
tensor(0.7848, device='cuda:0', grad_fn=<AddBackward0>)
0.85751903
tensor(0.6354, device='cuda:0', grad_fn=<AddBackward0>)
0.85791630
tensor(0.7016, device='cuda:0', grad_fn=<AddBackward0>)
0.85751659
tensor(0.7728, device='cuda:0', grad_fn=<AddBackward0>)
0.85759258
tensor(0.8393, device='cuda:0', grad_fn=<AddBackward0>)
0.85784543
tensor(0.7866, device='cuda:0', grad_fn=<AddBackward0>)
0.85787213
tensor(0.8169, device='cuda:0', grad_fn=<AddBackward0>)
0.85782886
tensor(0.6944, device='cuda:0', grad_fn=<AddBackward0>)
0.85779518
tensor(0.7367, device='cuda:0', grad_fn=<AddBackward0>)
0.85751641
tensor(0.6659, device='cuda:0', grad_fn=<AddBackward0>)
0.85775733
tensor(0.6689, device='cuda:0', grad_fn=<AddBackward0>)
0.85791516
tensor(0.6948, device='cuda:0', grad_fn=<AddBackward0>)
0.85805756
tensor(0.7407, device='cuda:0', grad_fn=<AddBackward0>)
0.85781133
tensor(0.7265, device='cuda:0', grad_fn=<AddBackward0>)
0.85761797
tensor(0.6998, device='cuda:0', grad_fn=<AddBackward0>)
0.85784870
tensor(0.7403, device='cuda:0', grad_fn=<AddBackward0>)
0.85745239
tensor(0.6431, device='cuda:0', grad_fn=<AddBackward0>)
0.85743421
tensor(0.7813, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [1][   80/  196]   Loss 0.741711   Top1 74.936523   Top5 98.046875   BatchTime 0.278193   LR 0.000476
0.85745454
tensor(0.7224, device='cuda:0', grad_fn=<AddBackward0>)
0.85742432
tensor(0.7630, device='cuda:0', grad_fn=<AddBackward0>)
0.85753280
tensor(0.7479, device='cuda:0', grad_fn=<AddBackward0>)
0.85728145
tensor(0.7290, device='cuda:0', grad_fn=<AddBackward0>)
0.85734892
tensor(0.7885, device='cuda:0', grad_fn=<AddBackward0>)
0.85696244
tensor(0.5558, device='cuda:0', grad_fn=<AddBackward0>)
0.85704648
tensor(0.8612, device='cuda:0', grad_fn=<AddBackward0>)
0.85677683
tensor(0.7180, device='cuda:0', grad_fn=<AddBackward0>)
0.85689241
tensor(0.7566, device='cuda:0', grad_fn=<AddBackward0>)
0.85703743
tensor(0.6075, device='cuda:0', grad_fn=<AddBackward0>)
0.85687089
tensor(0.7807, device='cuda:0', grad_fn=<AddBackward0>)
0.85714287
tensor(0.7925, device='cuda:0', grad_fn=<AddBackward0>)
0.85710210
tensor(0.7449, device='cuda:0', grad_fn=<AddBackward0>)
0.85710210
tensor(0.7600, device='cuda:0', grad_fn=<AddBackward0>)
0.85748756
tensor(0.6989, device='cuda:0', grad_fn=<AddBackward0>)
0.85748380
tensor(0.6871, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [1][  100/  196]   Loss 0.740600   Top1 75.121094   Top5 98.066406   BatchTime 0.272291   LR 0.000473
0.85759425
tensor(0.7500, device='cuda:0', grad_fn=<AddBackward0>)
0.85753876
tensor(0.7718, device='cuda:0', grad_fn=<AddBackward0>)
0.85751635
tensor(0.7060, device='cuda:0', grad_fn=<AddBackward0>)
0.85741895
tensor(0.6799, device='cuda:0', grad_fn=<AddBackward0>)
0.85716784
tensor(0.7807, device='cuda:0', grad_fn=<AddBackward0>)
0.85681647
tensor(0.6566, device='cuda:0', grad_fn=<AddBackward0>)
0.85655749
tensor(0.7074, device='cuda:0', grad_fn=<AddBackward0>)
0.85692090
tensor(0.7013, device='cuda:0', grad_fn=<AddBackward0>)
0.85720664
tensor(0.7639, device='cuda:0', grad_fn=<AddBackward0>)
0.85707533
tensor(0.7334, device='cuda:0', grad_fn=<AddBackward0>)
0.85696304
tensor(0.8100, device='cuda:0', grad_fn=<AddBackward0>)
0.85699135
tensor(0.7468, device='cuda:0', grad_fn=<AddBackward0>)
0.85695130
tensor(0.6228, device='cuda:0', grad_fn=<AddBackward0>)
0.85726273
tensor(0.7378, device='cuda:0', grad_fn=<AddBackward0>)
0.85712308
tensor(0.6393, device='cuda:0', grad_fn=<AddBackward0>)
0.85717350
tensor(0.6387, device='cuda:0', grad_fn=<AddBackward0>)
0.85701954
tensor(0.6792, device='cuda:0', grad_fn=<AddBackward0>)
0.85704458
tensor(0.7297, device='cuda:0', grad_fn=<AddBackward0>)
0.85696203
tensor(0.7846, device='cuda:0', grad_fn=<AddBackward0>)
0.85700279
tensor(0.6951, device='cuda:0', grad_fn=<AddBackward0>)
0.85711873
tensor(0.7431, device='cuda:0', grad_fn=<AddBackward0>)
0.85703236
tensor(0.5806, device='cuda:0', grad_fn=<AddBackward0>)
0.85699749
tensor(0.6666, device='cuda:0', grad_fn=<AddBackward0>)
0.85703933
tensor(0.7647, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [1][  120/  196]   Loss 0.734647   Top1 75.214844   Top5 98.105469   BatchTime 0.268454   LR 0.000469
0.85745156
tensor(0.6651, device='cuda:0', grad_fn=<AddBackward0>)
0.85735500
tensor(0.7082, device='cuda:0', grad_fn=<AddBackward0>)
0.85709816
tensor(0.7227, device='cuda:0', grad_fn=<AddBackward0>)
0.85706764
tensor(0.6265, device='cuda:0', grad_fn=<AddBackward0>)
0.85690814
tensor(0.5898, device='cuda:0', grad_fn=<AddBackward0>)
0.85683554
tensor(0.6877, device='cuda:0', grad_fn=<AddBackward0>)
0.85695684
tensor(0.6622, device='cuda:0', grad_fn=<AddBackward0>)
0.85685551
tensor(0.7333, device='cuda:0', grad_fn=<AddBackward0>)
0.85657132
tensor(0.7276, device='cuda:0', grad_fn=<AddBackward0>)
0.85637939
tensor(0.6773, device='cuda:0', grad_fn=<AddBackward0>)
0.85627747
tensor(0.7946, device='cuda:0', grad_fn=<AddBackward0>)
0.85628760
tensor(0.6528, device='cuda:0', grad_fn=<AddBackward0>)
0.85608017
tensor(0.7571, device='cuda:0', grad_fn=<AddBackward0>)
0.85609061
tensor(0.7365, device='cuda:0', grad_fn=<AddBackward0>)
0.85646403
tensor(0.8172, device='cuda:0', grad_fn=<AddBackward0>)
0.85675204
tensor(0.6851, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [1][  140/  196]   Loss 0.731616   Top1 75.326451   Top5 98.158482   BatchTime 0.265417   LR 0.000465
0.85655230
tensor(0.7739, device='cuda:0', grad_fn=<AddBackward0>)
0.85617286
tensor(0.7167, device='cuda:0', grad_fn=<AddBackward0>)
0.85616803
tensor(0.7697, device='cuda:0', grad_fn=<AddBackward0>)
0.85605991
tensor(0.7430, device='cuda:0', grad_fn=<AddBackward0>)
0.85606086
tensor(0.8282, device='cuda:0', grad_fn=<AddBackward0>)
0.85608774
tensor(0.6989, device='cuda:0', grad_fn=<AddBackward0>)
0.85608661
tensor(0.7034, device='cuda:0', grad_fn=<AddBackward0>)
0.85603136
tensor(0.7757, device='cuda:0', grad_fn=<AddBackward0>)
0.85641360
tensor(0.7672, device='cuda:0', grad_fn=<AddBackward0>)
0.85631466
tensor(0.7081, device='cuda:0', grad_fn=<AddBackward0>)
0.85659850
tensor(0.7148, device='cuda:0', grad_fn=<AddBackward0>)
0.85674053
tensor(0.6642, device='cuda:0', grad_fn=<AddBackward0>)
0.85641336
tensor(0.5496, device='cuda:0', grad_fn=<AddBackward0>)
0.85636061
tensor(0.6637, device='cuda:0', grad_fn=<AddBackward0>)
0.85662448
tensor(0.6614, device='cuda:0', grad_fn=<AddBackward0>)
0.85647923
tensor(0.7048, device='cuda:0', grad_fn=<AddBackward0>)
0.85677427
tensor(0.6951, device='cuda:0', grad_fn=<AddBackward0>)
0.85668409
tensor(0.6868, device='cuda:0', grad_fn=<AddBackward0>)
0.85683864
tensor(0.8678, device='cuda:0', grad_fn=<AddBackward0>)
0.85673428
tensor(0.7682, device='cuda:0', grad_fn=<AddBackward0>)
0.85678941
tensor(0.6882, device='cuda:0', grad_fn=<AddBackward0>)
0.85445744
tensor(0.6051, device='cuda:0', grad_fn=<AddBackward0>)
0.85423911
tensor(0.5487, device='cuda:0', grad_fn=<AddBackward0>)
0.85470986
tensor(0.7150, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [1][  160/  196]   Loss 0.727931   Top1 75.483398   Top5 98.186035   BatchTime 0.264353   LR 0.000460
0.85691881
tensor(0.7516, device='cuda:0', grad_fn=<AddBackward0>)
0.85666311
tensor(0.6094, device='cuda:0', grad_fn=<AddBackward0>)
0.85670835
tensor(0.6674, device='cuda:0', grad_fn=<AddBackward0>)
0.85668528
tensor(0.5944, device='cuda:0', grad_fn=<AddBackward0>)
0.85684919
tensor(0.5577, device='cuda:0', grad_fn=<AddBackward0>)
0.85695052
tensor(0.6357, device='cuda:0', grad_fn=<AddBackward0>)
0.85701239
tensor(0.7325, device='cuda:0', grad_fn=<AddBackward0>)
0.85689020
tensor(0.6187, device='cuda:0', grad_fn=<AddBackward0>)
0.85665822
tensor(0.6836, device='cuda:0', grad_fn=<AddBackward0>)
0.85632265
tensor(0.7670, device='cuda:0', grad_fn=<AddBackward0>)
0.85549325
tensor(0.6655, device='cuda:0', grad_fn=<AddBackward0>)
0.85505497
tensor(0.7163, device='cuda:0', grad_fn=<AddBackward0>)
0.85398912
tensor(0.7137, device='cuda:0', grad_fn=<AddBackward0>)
0.85237783
tensor(0.7121, device='cuda:0', grad_fn=<AddBackward0>)
0.85062110
tensor(0.5633, device='cuda:0', grad_fn=<AddBackward0>)
0.84871918
tensor(0.6437, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [1][  180/  196]   Loss 0.721473   Top1 75.755208   Top5 98.203125   BatchTime 0.262192   LR 0.000456
0.84742165
tensor(0.7677, device='cuda:0', grad_fn=<AddBackward0>)
0.84747863
tensor(0.6380, device='cuda:0', grad_fn=<AddBackward0>)
0.84755385
tensor(0.6427, device='cuda:0', grad_fn=<AddBackward0>)
0.84775698
tensor(0.7511, device='cuda:0', grad_fn=<AddBackward0>)
0.84820902
tensor(0.8006, device='cuda:0', grad_fn=<AddBackward0>)
0.84810233
tensor(0.6027, device='cuda:0', grad_fn=<AddBackward0>)
0.84798115
tensor(0.6129, device='cuda:0', grad_fn=<AddBackward0>)
0.84785724
tensor(0.5562, device='cuda:0', grad_fn=<AddBackward0>)
0.84798253
tensor(0.7049, device='cuda:0', grad_fn=<AddBackward0>)
0.84800202
tensor(0.5980, device='cuda:0', grad_fn=<AddBackward0>)
0.84793031
tensor(0.6574, device='cuda:0', grad_fn=<AddBackward0>)
0.84746200
tensor(0.6786, device='cuda:0', grad_fn=<AddBackward0>)
0.84709030
tensor(0.6628, device='cuda:0', grad_fn=<AddBackward0>)
0.84690177
tensor(0.6782, device='cuda:0', grad_fn=<AddBackward0>)
0.84686714
tensor(0.6185, device='cuda:0', grad_fn=<AddBackward0>)
0.84706765
tensor(0.5948, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 75.920    Top5: 98.258    Loss: 0.716
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.84750408
tensor(0.6396, device='cuda:0', grad_fn=<AddBackward0>)
0.84691656
tensor(0.6697, device='cuda:0', grad_fn=<AddBackward0>)
0.84674394
tensor(0.7178, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [1][   20/   40]   Loss 0.728329   Top1 76.621094   Top5 97.792969   BatchTime 0.126461
features.0.conv.0 tensor(0.2847)
features.0.conv.3 tensor(0.1113)
features.1.conv.0 tensor(0.0566)
features.1.conv.3 tensor(0.0660)
features.1.conv.6 tensor(0.0768)
features.2.conv.0 tensor(0.1215)
features.2.conv.3 tensor(0.3511)
features.2.conv.6 tensor(0.1780)
features.3.conv.0 tensor(0.0613)
features.3.conv.3 tensor(0.0926)
features.3.conv.6 tensor(0.1063)
features.4.conv.0 tensor(0.0811)
features.4.conv.3 tensor(0.3073)
features.4.conv.6 tensor(0.1802)
features.5.conv.0 tensor(0.3548)
features.5.conv.3 tensor(0.4282)
features.5.conv.6 tensor(0.1120)
features.6.conv.0 tensor(0.0563)
features.6.conv.3 tensor(0.0625)
features.6.conv.6 tensor(0.0854)
features.7.conv.0 tensor(0.2245)
features.7.conv.3 tensor(0.4580)
features.7.conv.6 tensor(0.1840)
features.8.conv.0 tensor(0.5281)
features.8.conv.3 tensor(0.5379)
features.8.conv.6 tensor(0.1776)
features.9.conv.0 tensor(0.4816)
features.9.conv.3 tensor(0.5729)
features.9.conv.6 tensor(0.1481)
features.10.conv.0 tensor(0.0787)
features.10.conv.3 tensor(0.1085)
features.10.conv.6 tensor(0.1035)
features.11.conv.0 tensor(0.6004)
features.11.conv.3 tensor(0.6487)
features.11.conv.6 tensor(0.7612)
features.12.conv.0 tensor(0.5712)
features.12.conv.3 tensor(0.6734)
features.12.conv.6 tensor(0.1720)
features.13.conv.0 tensor(0.3748)
features.13.conv.3 tensor(0.4958)
features.13.conv.6 tensor(0.0965)
features.14.conv.0 tensor(0.7720)
features.14.conv.3 tensor(0.8171)
features.14.conv.6 tensor(0.1113)
features.15.conv.0 tensor(0.7504)
features.15.conv.3 tensor(0.8253)
features.15.conv.6 tensor(0.1600)
features.16.conv.0 tensor(0.2589)
features.16.conv.3 tensor(0.7876)
features.16.conv.6 tensor(0.0564)
conv.0 tensor(0.0753)
tensor(604286.) 2188896.0
INFO - Validation [1][   40/   40]   Loss 0.731360   Top1 76.430000   Top5 97.990000   BatchTime 0.092381
INFO - ==> Top1: 76.430    Top5: 97.990    Loss: 0.731
INFO - ==> Sparsity : 0.276
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.430   Top5: 97.990]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 72.380   Top5: 97.640]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
0.84687769
tensor(0.7033, device='cuda:0', grad_fn=<AddBackward0>)
0.84641594
tensor(0.6843, device='cuda:0', grad_fn=<AddBackward0>)
0.84602004
tensor(0.6165, device='cuda:0', grad_fn=<AddBackward0>)
0.84608144
tensor(0.7927, device='cuda:0', grad_fn=<AddBackward0>)
0.84621030
tensor(0.6955, device='cuda:0', grad_fn=<AddBackward0>)
0.84592468
tensor(0.7954, device='cuda:0', grad_fn=<AddBackward0>)
0.84616864
tensor(0.6512, device='cuda:0', grad_fn=<AddBackward0>)
0.84622461
tensor(0.7767, device='cuda:0', grad_fn=<AddBackward0>)
0.84636235
tensor(0.6117, device='cuda:0', grad_fn=<AddBackward0>)
0.84641457
tensor(0.6583, device='cuda:0', grad_fn=<AddBackward0>)
0.84661275
tensor(0.5741, device='cuda:0', grad_fn=<AddBackward0>)
0.84643859
tensor(0.6213, device='cuda:0', grad_fn=<AddBackward0>)
0.84644568
tensor(0.6202, device='cuda:0', grad_fn=<AddBackward0>)
0.84626031
tensor(0.6184, device='cuda:0', grad_fn=<AddBackward0>)
0.84617209
tensor(0.7138, device='cuda:0', grad_fn=<AddBackward0>)
0.84610200
tensor(0.5703, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [2][   20/  196]   Loss 0.671000   Top1 77.558594   Top5 98.417969   BatchTime 0.330820   LR 0.000448
0.84592479
tensor(0.5573, device='cuda:0', grad_fn=<AddBackward0>)
0.84560633
tensor(0.7201, device='cuda:0', grad_fn=<AddBackward0>)
0.84546298
tensor(0.7650, device='cuda:0', grad_fn=<AddBackward0>)
0.84540069
tensor(0.6740, device='cuda:0', grad_fn=<AddBackward0>)
0.84520352
tensor(0.6535, device='cuda:0', grad_fn=<AddBackward0>)
0.84510678
tensor(0.6062, device='cuda:0', grad_fn=<AddBackward0>)
0.84514815
tensor(0.6114, device='cuda:0', grad_fn=<AddBackward0>)
0.84522933
tensor(0.6822, device='cuda:0', grad_fn=<AddBackward0>)
0.84532166
tensor(0.5929, device='cuda:0', grad_fn=<AddBackward0>)
0.84565556
tensor(0.6908, device='cuda:0', grad_fn=<AddBackward0>)
0.84587294
tensor(0.6176, device='cuda:0', grad_fn=<AddBackward0>)
0.84599268
tensor(0.6453, device='cuda:0', grad_fn=<AddBackward0>)
0.84609842
tensor(0.7485, device='cuda:0', grad_fn=<AddBackward0>)
0.84619027
tensor(0.4835, device='cuda:0', grad_fn=<AddBackward0>)
0.84623748
tensor(0.6232, device='cuda:0', grad_fn=<AddBackward0>)
0.84639966
tensor(0.6810, device='cuda:0', grad_fn=<AddBackward0>)
0.84647399
tensor(0.6563, device='cuda:0', grad_fn=<AddBackward0>)
0.84631890
tensor(0.6441, device='cuda:0', grad_fn=<AddBackward0>)
0.84633827
tensor(0.5599, device='cuda:0', grad_fn=<AddBackward0>)
0.84631771
tensor(0.6112, device='cuda:0', grad_fn=<AddBackward0>)
0.84639102
tensor(0.5768, device='cuda:0', grad_fn=<AddBackward0>)
0.84621274
tensor(0.7314, device='cuda:0', grad_fn=<AddBackward0>)
0.84640497
tensor(0.6236, device='cuda:0', grad_fn=<AddBackward0>)
0.84654909
tensor(0.6144, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [2][   40/  196]   Loss 0.651842   Top1 78.408203   Top5 98.476562   BatchTime 0.290235   LR 0.000443
0.84679294
tensor(0.6518, device='cuda:0', grad_fn=<AddBackward0>)
0.84681749
tensor(0.6526, device='cuda:0', grad_fn=<AddBackward0>)
0.84736836
tensor(0.6033, device='cuda:0', grad_fn=<AddBackward0>)
0.84758466
tensor(0.6459, device='cuda:0', grad_fn=<AddBackward0>)
0.84747583
tensor(0.7813, device='cuda:0', grad_fn=<AddBackward0>)
0.84754527
tensor(0.5337, device='cuda:0', grad_fn=<AddBackward0>)
0.84790522
tensor(0.6918, device='cuda:0', grad_fn=<AddBackward0>)
0.84809852
tensor(0.7139, device='cuda:0', grad_fn=<AddBackward0>)
0.84834278
tensor(0.5299, device='cuda:0', grad_fn=<AddBackward0>)
0.84833550
tensor(0.6295, device='cuda:0', grad_fn=<AddBackward0>)
0.84857714
tensor(0.6257, device='cuda:0', grad_fn=<AddBackward0>)
0.84898472
tensor(0.5751, device='cuda:0', grad_fn=<AddBackward0>)
0.84893948
tensor(0.5296, device='cuda:0', grad_fn=<AddBackward0>)
0.84910601
tensor(0.6668, device='cuda:0', grad_fn=<AddBackward0>)
0.84946495
tensor(0.6340, device='cuda:0', grad_fn=<AddBackward0>)
0.84927833
tensor(0.5745, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [2][   60/  196]   Loss 0.643692   Top1 78.430990   Top5 98.671875   BatchTime 0.276381   LR 0.000437
0.84921974
tensor(0.6953, device='cuda:0', grad_fn=<AddBackward0>)
0.84946066
tensor(0.5568, device='cuda:0', grad_fn=<AddBackward0>)
0.84967858
tensor(0.5977, device='cuda:0', grad_fn=<AddBackward0>)
0.84931731
tensor(0.6588, device='cuda:0', grad_fn=<AddBackward0>)
0.84936613
tensor(0.5088, device='cuda:0', grad_fn=<AddBackward0>)
0.84937239
tensor(0.6265, device='cuda:0', grad_fn=<AddBackward0>)
0.84951246
tensor(0.5625, device='cuda:0', grad_fn=<AddBackward0>)
0.84962344
tensor(0.5782, device='cuda:0', grad_fn=<AddBackward0>)
0.84974033
tensor(0.6890, device='cuda:0', grad_fn=<AddBackward0>)
0.84996653
tensor(0.7013, device='cuda:0', grad_fn=<AddBackward0>)
0.84924227
tensor(0.6266, device='cuda:0', grad_fn=<AddBackward0>)
0.84868926
tensor(0.6305, device='cuda:0', grad_fn=<AddBackward0>)
0.84878188
tensor(0.6319, device='cuda:0', grad_fn=<AddBackward0>)
0.84852654
tensor(0.5021, device='cuda:0', grad_fn=<AddBackward0>)
0.84843129
tensor(0.7106, device='cuda:0', grad_fn=<AddBackward0>)
0.84775007
tensor(0.6154, device='cuda:0', grad_fn=<AddBackward0>)
0.84718257
tensor(0.6611, device='cuda:0', grad_fn=<AddBackward0>)
0.84695101
tensor(0.5847, device='cuda:0', grad_fn=<AddBackward0>)
0.84623533
tensor(0.6744, device='cuda:0', grad_fn=<AddBackward0>)
0.84569728
tensor(0.5814, device='cuda:0', grad_fn=<AddBackward0>)
0.84525758
tensor(0.5718, device='cuda:0', grad_fn=<AddBackward0>)
0.84469968
tensor(0.6531, device='cuda:0', grad_fn=<AddBackward0>)
0.84429282
tensor(0.7889, device='cuda:0', grad_fn=<AddBackward0>)
0.84359205
tensor(0.6387, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [2][   80/  196]   Loss 0.639486   Top1 78.549805   Top5 98.666992   BatchTime 0.271260   LR 0.000432
0.84326780
tensor(0.5730, device='cuda:0', grad_fn=<AddBackward0>)
0.84253579
tensor(0.6180, device='cuda:0', grad_fn=<AddBackward0>)
0.84273183
tensor(0.6471, device='cuda:0', grad_fn=<AddBackward0>)
0.84219843
tensor(0.5671, device='cuda:0', grad_fn=<AddBackward0>)
0.84161288
tensor(0.5873, device='cuda:0', grad_fn=<AddBackward0>)
0.84138030
tensor(0.6103, device='cuda:0', grad_fn=<AddBackward0>)
0.84120518
tensor(0.6798, device='cuda:0', grad_fn=<AddBackward0>)
0.84147602
tensor(0.6620, device='cuda:0', grad_fn=<AddBackward0>)
0.84176809
tensor(0.5388, device='cuda:0', grad_fn=<AddBackward0>)
0.84228724
tensor(0.5413, device='cuda:0', grad_fn=<AddBackward0>)
0.84248418
tensor(0.6329, device='cuda:0', grad_fn=<AddBackward0>)
0.84275341
tensor(0.4923, device='cuda:0', grad_fn=<AddBackward0>)
0.84338439
tensor(0.5971, device='cuda:0', grad_fn=<AddBackward0>)
0.84500390
tensor(0.5411, device='cuda:0', grad_fn=<AddBackward0>)
0.84720278
tensor(0.6231, device='cuda:0', grad_fn=<AddBackward0>)
0.84706163
tensor(0.5423, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [2][  100/  196]   Loss 0.628805   Top1 78.921875   Top5 98.695312   BatchTime 0.266384   LR 0.000426
0.84699786
tensor(0.6124, device='cuda:0', grad_fn=<AddBackward0>)
0.84703952
tensor(0.5442, device='cuda:0', grad_fn=<AddBackward0>)
0.84693784
tensor(0.6060, device='cuda:0', grad_fn=<AddBackward0>)
0.84714818
tensor(0.5055, device='cuda:0', grad_fn=<AddBackward0>)
0.84669471
tensor(0.6313, device='cuda:0', grad_fn=<AddBackward0>)
0.84660596
tensor(0.6030, device='cuda:0', grad_fn=<AddBackward0>)
0.84669548
tensor(0.4945, device='cuda:0', grad_fn=<AddBackward0>)
0.84670806
tensor(0.7323, device='cuda:0', grad_fn=<AddBackward0>)
0.84667003
tensor(0.5701, device='cuda:0', grad_fn=<AddBackward0>)
0.84637046
tensor(0.5270, device='cuda:0', grad_fn=<AddBackward0>)
0.84639412
tensor(0.6597, device='cuda:0', grad_fn=<AddBackward0>)
0.84617388
tensor(0.5217, device='cuda:0', grad_fn=<AddBackward0>)
0.84596968
tensor(0.5288, device='cuda:0', grad_fn=<AddBackward0>)
0.84591538
tensor(0.6136, device='cuda:0', grad_fn=<AddBackward0>)
0.84584123
tensor(0.6448, device='cuda:0', grad_fn=<AddBackward0>)
0.84569323
tensor(0.6113, device='cuda:0', grad_fn=<AddBackward0>)
0.84551948
tensor(0.6509, device='cuda:0', grad_fn=<AddBackward0>)
0.84583712
tensor(0.6384, device='cuda:0', grad_fn=<AddBackward0>)
0.84576380
tensor(0.5559, device='cuda:0', grad_fn=<AddBackward0>)
0.84583956
tensor(0.6052, device='cuda:0', grad_fn=<AddBackward0>)
0.84561628
tensor(0.5276, device='cuda:0', grad_fn=<AddBackward0>)
0.84574968
tensor(0.5403, device='cuda:0', grad_fn=<AddBackward0>)
0.84593207
tensor(0.5880, device='cuda:0', grad_fn=<AddBackward0>)
0.84576225
tensor(0.4041, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [2][  120/  196]   Loss 0.621074   Top1 79.182943   Top5 98.746745   BatchTime 0.264229   LR 0.000421
0.84566480
tensor(0.6107, device='cuda:0', grad_fn=<AddBackward0>)
0.84584552
tensor(0.5072, device='cuda:0', grad_fn=<AddBackward0>)
0.84561205
tensor(0.5172, device='cuda:0', grad_fn=<AddBackward0>)
0.84577727
tensor(0.6413, device='cuda:0', grad_fn=<AddBackward0>)
0.84548044
tensor(0.6171, device='cuda:0', grad_fn=<AddBackward0>)
0.84538615
tensor(0.5796, device='cuda:0', grad_fn=<AddBackward0>)
0.84561473
tensor(0.5245, device='cuda:0', grad_fn=<AddBackward0>)
0.84556794
tensor(0.7313, device='cuda:0', grad_fn=<AddBackward0>)
0.84584606
tensor(0.5920, device='cuda:0', grad_fn=<AddBackward0>)
0.84576148
tensor(0.6538, device='cuda:0', grad_fn=<AddBackward0>)
0.84567916
tensor(0.5891, device='cuda:0', grad_fn=<AddBackward0>)
0.84603488
tensor(0.5704, device='cuda:0', grad_fn=<AddBackward0>)
0.84583640
tensor(0.4822, device='cuda:0', grad_fn=<AddBackward0>)
0.84590340
tensor(0.5326, device='cuda:0', grad_fn=<AddBackward0>)
0.84585011
tensor(0.5444, device='cuda:0', grad_fn=<AddBackward0>)
0.84580106
tensor(0.6041, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [2][  140/  196]   Loss 0.617792   Top1 79.316406   Top5 98.741629   BatchTime 0.262870   LR 0.000415
0.84572667
tensor(0.7365, device='cuda:0', grad_fn=<AddBackward0>)
0.84599674
tensor(0.6042, device='cuda:0', grad_fn=<AddBackward0>)
0.84573060
tensor(0.5801, device='cuda:0', grad_fn=<AddBackward0>)
0.84577906
tensor(0.7437, device='cuda:0', grad_fn=<AddBackward0>)
0.84564990
tensor(0.6380, device='cuda:0', grad_fn=<AddBackward0>)
0.84560418
tensor(0.5842, device='cuda:0', grad_fn=<AddBackward0>)
0.84585786
tensor(0.5592, device='cuda:0', grad_fn=<AddBackward0>)
0.84601146
tensor(0.5603, device='cuda:0', grad_fn=<AddBackward0>)
0.84609085
tensor(0.7043, device='cuda:0', grad_fn=<AddBackward0>)
0.84596771
tensor(0.5804, device='cuda:0', grad_fn=<AddBackward0>)
0.84580445
tensor(0.5094, device='cuda:0', grad_fn=<AddBackward0>)
0.84538883
tensor(0.5326, device='cuda:0', grad_fn=<AddBackward0>)
0.84569001
tensor(0.6055, device='cuda:0', grad_fn=<AddBackward0>)
0.84551656
tensor(0.5758, device='cuda:0', grad_fn=<AddBackward0>)
0.84567541
tensor(0.5264, device='cuda:0', grad_fn=<AddBackward0>)
0.84535879
tensor(0.5750, device='cuda:0', grad_fn=<AddBackward0>)
0.84523535
tensor(0.6827, device='cuda:0', grad_fn=<AddBackward0>)
0.84531128
tensor(0.5264, device='cuda:0', grad_fn=<AddBackward0>)
0.84534812
tensor(0.4376, device='cuda:0', grad_fn=<AddBackward0>)
0.84538901
tensor(0.5359, device='cuda:0', grad_fn=<AddBackward0>)
0.84519559
tensor(0.4874, device='cuda:0', grad_fn=<AddBackward0>)
0.84579432
tensor(0.5210, device='cuda:0', grad_fn=<AddBackward0>)
0.84611338
tensor(0.4752, device='cuda:0', grad_fn=<AddBackward0>)
0.84617853
tensor(0.5601, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [2][  160/  196]   Loss 0.610426   Top1 79.545898   Top5 98.784180   BatchTime 0.261226   LR 0.000409
0.84604377
tensor(0.5252, device='cuda:0', grad_fn=<AddBackward0>)
0.84588027
tensor(0.5623, device='cuda:0', grad_fn=<AddBackward0>)
0.84571993
tensor(0.5413, device='cuda:0', grad_fn=<AddBackward0>)
0.84557205
tensor(0.6591, device='cuda:0', grad_fn=<AddBackward0>)
0.84574258
tensor(0.4486, device='cuda:0', grad_fn=<AddBackward0>)
0.84559238
tensor(0.4776, device='cuda:0', grad_fn=<AddBackward0>)
0.84521699
tensor(0.5126, device='cuda:0', grad_fn=<AddBackward0>)
0.84538990
tensor(0.6378, device='cuda:0', grad_fn=<AddBackward0>)
0.84563935
tensor(0.5746, device='cuda:0', grad_fn=<AddBackward0>)
0.84545666
tensor(0.5042, device='cuda:0', grad_fn=<AddBackward0>)
0.84500301
tensor(0.5356, device='cuda:0', grad_fn=<AddBackward0>)
0.84404081
tensor(0.7478, device='cuda:0', grad_fn=<AddBackward0>)
0.84476775
tensor(0.5751, device='cuda:0', grad_fn=<AddBackward0>)
0.84481251
tensor(0.6213, device='cuda:0', grad_fn=<AddBackward0>)
0.84492654
tensor(0.6155, device='cuda:0', grad_fn=<AddBackward0>)
0.84492391
tensor(0.4395, device='cuda:0', grad_fn=<AddBackward0>)
0.84470034
tensor(0.6605, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [2][  180/  196]   Loss 0.605217   Top1 79.663628   Top5 98.791233   BatchTime 0.258442   LR 0.000402
0.84459364
tensor(0.6022, device='cuda:0', grad_fn=<AddBackward0>)
0.84436804
tensor(0.5398, device='cuda:0', grad_fn=<AddBackward0>)
0.84435326
tensor(0.4904, device='cuda:0', grad_fn=<AddBackward0>)
0.84439462
tensor(0.5624, device='cuda:0', grad_fn=<AddBackward0>)
0.84418994
tensor(0.5673, device='cuda:0', grad_fn=<AddBackward0>)
0.84401071
tensor(0.5647, device='cuda:0', grad_fn=<AddBackward0>)
0.84376460
tensor(0.6169, device='cuda:0', grad_fn=<AddBackward0>)
0.84337026
tensor(0.6426, device='cuda:0', grad_fn=<AddBackward0>)
0.84316391
tensor(0.6425, device='cuda:0', grad_fn=<AddBackward0>)
0.84327388
tensor(0.6042, device='cuda:0', grad_fn=<AddBackward0>)
0.84339231
tensor(0.6457, device='cuda:0', grad_fn=<AddBackward0>)
0.84271801
tensor(0.6117, device='cuda:0', grad_fn=<AddBackward0>)
0.84271801
tensor(0.5627, device='cuda:0', grad_fn=<AddBackward0>)
0.84283179
tensor(0.5762, device='cuda:0', grad_fn=<AddBackward0>)
0.84281045
tensor(0.5897, device='cuda:0', grad_fn=<AddBackward0>)
0.84257734
tensor(0.6076, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 79.660    Top5: 98.792    Loss: 0.605
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.84241921
tensor(0.5985, device='cuda:0', grad_fn=<AddBackward0>)
0.84254164
tensor(0.6299, device='cuda:0', grad_fn=<AddBackward0>)
0.84256953
tensor(0.6649, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 0.791563   Top1 73.867188   Top5 97.773438   BatchTime 0.122295
INFO - Validation [2][   40/   40]   Loss 0.774521   Top1 74.400000   Top5 98.150000   BatchTime 0.090667
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1465)
features.1.conv.0 tensor(0.0482)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0794)
features.2.conv.0 tensor(0.0744)
features.2.conv.3 tensor(0.3526)
features.2.conv.6 tensor(0.1814)
features.3.conv.0 tensor(0.0631)
features.3.conv.3 tensor(0.0965)
features.3.conv.6 tensor(0.1150)
features.4.conv.0 tensor(0.0767)
features.4.conv.3 tensor(0.3119)
features.4.conv.6 tensor(0.1834)
features.5.conv.0 tensor(0.3477)
features.5.conv.3 tensor(0.4213)
features.5.conv.6 tensor(0.1139)
features.6.conv.0 tensor(0.0560)
features.6.conv.3 tensor(0.0625)
features.6.conv.6 tensor(0.0863)
features.7.conv.0 tensor(0.2216)
features.7.conv.3 tensor(0.4531)
features.7.conv.6 tensor(0.1911)
features.8.conv.0 tensor(0.3216)
features.8.conv.3 tensor(0.5321)
features.8.conv.6 tensor(0.1647)
features.9.conv.0 tensor(0.2953)
features.9.conv.3 tensor(0.5680)
features.9.conv.6 tensor(0.1650)
features.10.conv.0 tensor(0.0724)
features.10.conv.3 tensor(0.1062)
features.10.conv.6 tensor(0.1050)
features.11.conv.0 tensor(0.6288)
features.11.conv.3 tensor(0.6483)
features.11.conv.6 tensor(0.7962)
features.12.conv.0 tensor(0.6129)
features.12.conv.3 tensor(0.6699)
features.12.conv.6 tensor(0.1712)
features.13.conv.0 tensor(0.3757)
features.13.conv.3 tensor(0.4950)
features.13.conv.6 tensor(0.0981)
features.14.conv.0 tensor(0.8044)
features.14.conv.3 tensor(0.8193)
features.14.conv.6 tensor(0.1226)
features.15.conv.0 tensor(0.7671)
features.15.conv.3 tensor(0.8257)
features.15.conv.6 tensor(0.1820)
features.16.conv.0 tensor(0.2500)
features.16.conv.3 tensor(0.7887)
features.16.conv.6 tensor(0.0598)
conv.0 tensor(0.0856)
tensor(617104.) 2188896.0
INFO - ==> Top1: 74.400    Top5: 98.150    Loss: 0.775
INFO - ==> Sparsity : 0.282
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.430   Top5: 97.990]
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 74.400   Top5: 98.150]
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 72.380   Top5: 97.640]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
0.84273368
tensor(0.6618, device='cuda:0', grad_fn=<AddBackward0>)
0.84290427
tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)
0.84295338
tensor(0.5513, device='cuda:0', grad_fn=<AddBackward0>)
0.84299582
tensor(0.5811, device='cuda:0', grad_fn=<AddBackward0>)
0.84298581
tensor(0.6124, device='cuda:0', grad_fn=<AddBackward0>)
0.84311968
tensor(0.6212, device='cuda:0', grad_fn=<AddBackward0>)
0.84302980
tensor(0.4963, device='cuda:0', grad_fn=<AddBackward0>)
0.84341735
tensor(0.5452, device='cuda:0', grad_fn=<AddBackward0>)
0.84361583
tensor(0.5083, device='cuda:0', grad_fn=<AddBackward0>)
0.84356266
tensor(0.4874, device='cuda:0', grad_fn=<AddBackward0>)
0.84364772
tensor(0.5824, device='cuda:0', grad_fn=<AddBackward0>)
0.84398186
tensor(0.5478, device='cuda:0', grad_fn=<AddBackward0>)
0.84375519
tensor(0.5097, device='cuda:0', grad_fn=<AddBackward0>)
0.84221405
tensor(0.5598, device='cuda:0', grad_fn=<AddBackward0>)
0.84087974
tensor(0.4837, device='cuda:0', grad_fn=<AddBackward0>)
0.83972597
tensor(0.6590, device='cuda:0', grad_fn=<AddBackward0>)
0.83940959
tensor(0.5896, device='cuda:0', grad_fn=<AddBackward0>)
0.83987588
tensor(0.5907, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [3][   20/  196]   Loss 0.555689   Top1 80.976562   Top5 99.082031   BatchTime 0.332940   LR 0.000391
0.84093881
tensor(0.5099, device='cuda:0', grad_fn=<AddBackward0>)
0.84171331
tensor(0.5327, device='cuda:0', grad_fn=<AddBackward0>)
0.84260422
tensor(0.5952, device='cuda:0', grad_fn=<AddBackward0>)
0.84346074
tensor(0.5406, device='cuda:0', grad_fn=<AddBackward0>)
0.84443945
tensor(0.5441, device='cuda:0', grad_fn=<AddBackward0>)
0.84472644
tensor(0.5161, device='cuda:0', grad_fn=<AddBackward0>)
0.84482241
tensor(0.4605, device='cuda:0', grad_fn=<AddBackward0>)
0.84466618
tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
0.84481376
tensor(0.6251, device='cuda:0', grad_fn=<AddBackward0>)
0.84483522
tensor(0.6328, device='cuda:0', grad_fn=<AddBackward0>)
0.84480464
tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
0.84469545
tensor(0.4919, device='cuda:0', grad_fn=<AddBackward0>)
0.84479254
tensor(0.4617, device='cuda:0', grad_fn=<AddBackward0>)
0.84503019
tensor(0.4988, device='cuda:0', grad_fn=<AddBackward0>)
0.84499645
tensor(0.7003, device='cuda:0', grad_fn=<AddBackward0>)
0.84481812
tensor(0.4960, device='cuda:0', grad_fn=<AddBackward0>)
0.84474653
tensor(0.5352, device='cuda:0', grad_fn=<AddBackward0>)
0.84491456
tensor(0.5692, device='cuda:0', grad_fn=<AddBackward0>)
0.84492391
tensor(0.5250, device='cuda:0', grad_fn=<AddBackward0>)
0.84486008
tensor(0.4916, device='cuda:0', grad_fn=<AddBackward0>)
0.84478772
tensor(0.5399, device='cuda:0', grad_fn=<AddBackward0>)
0.84496272
tensor(0.5918, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [3][   40/  196]   Loss 0.547597   Top1 81.679688   Top5 99.082031   BatchTime 0.303752   LR 0.000384
0.84475112
tensor(0.5820, device='cuda:0', grad_fn=<AddBackward0>)
0.84471458
tensor(0.4724, device='cuda:0', grad_fn=<AddBackward0>)
0.84476244
tensor(0.5545, device='cuda:0', grad_fn=<AddBackward0>)
0.84369236
tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)
0.84322912
tensor(0.6056, device='cuda:0', grad_fn=<AddBackward0>)
0.84253341
tensor(0.6520, device='cuda:0', grad_fn=<AddBackward0>)
0.84123737
tensor(0.5354, device='cuda:0', grad_fn=<AddBackward0>)
0.84033841
tensor(0.5403, device='cuda:0', grad_fn=<AddBackward0>)
0.83942884
tensor(0.5411, device='cuda:0', grad_fn=<AddBackward0>)
0.83837938
tensor(0.6037, device='cuda:0', grad_fn=<AddBackward0>)
0.83892769
tensor(0.5178, device='cuda:0', grad_fn=<AddBackward0>)
0.83871615
tensor(0.5679, device='cuda:0', grad_fn=<AddBackward0>)
0.83906293
tensor(0.4962, device='cuda:0', grad_fn=<AddBackward0>)
0.83875120
tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)
0.83877224
tensor(0.5548, device='cuda:0', grad_fn=<AddBackward0>)
0.83855855
tensor(0.5118, device='cuda:0', grad_fn=<AddBackward0>)
0.83810765
tensor(0.5176, device='cuda:0', grad_fn=<AddBackward0>)
0.83782965
tensor(0.5058, device='cuda:0', grad_fn=<AddBackward0>)
0.83791399
tensor(0.4969, device='cuda:0', grad_fn=<AddBackward0>)
0.83785135
tensor(0.6036, device='cuda:0', grad_fn=<AddBackward0>)
0.83788896
tensor(0.5141, device='cuda:0', grad_fn=<AddBackward0>)
0.83824241
tensor(0.6161, device='cuda:0', grad_fn=<AddBackward0>)
0.83877409
tensor(0.5416, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [3][   60/  196]   Loss 0.545905   Top1 81.575521   Top5 99.114583   BatchTime 0.289320   LR 0.000377
0.83922505
tensor(0.5581, device='cuda:0', grad_fn=<AddBackward0>)
0.84012800
tensor(0.5080, device='cuda:0', grad_fn=<AddBackward0>)
0.83971471
tensor(0.6044, device='cuda:0', grad_fn=<AddBackward0>)
0.83998513
tensor(0.4590, device='cuda:0', grad_fn=<AddBackward0>)
0.84031826
tensor(0.5736, device='cuda:0', grad_fn=<AddBackward0>)
0.84069508
tensor(0.5334, device='cuda:0', grad_fn=<AddBackward0>)
0.84093970
tensor(0.5801, device='cuda:0', grad_fn=<AddBackward0>)
0.84097838
tensor(0.4322, device='cuda:0', grad_fn=<AddBackward0>)
0.84110409
tensor(0.5592, device='cuda:0', grad_fn=<AddBackward0>)
0.84134561
tensor(0.5898, device='cuda:0', grad_fn=<AddBackward0>)
0.84182048
tensor(0.6313, device='cuda:0', grad_fn=<AddBackward0>)
0.84272093
tensor(0.5708, device='cuda:0', grad_fn=<AddBackward0>)
0.84327924
tensor(0.5215, device='cuda:0', grad_fn=<AddBackward0>)
0.84311765
tensor(0.4676, device='cuda:0', grad_fn=<AddBackward0>)
0.84289455
tensor(0.5180, device='cuda:0', grad_fn=<AddBackward0>)
0.84286726
tensor(0.5849, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [3][   80/  196]   Loss 0.545663   Top1 81.542969   Top5 99.121094   BatchTime 0.279011   LR 0.000370
0.84272087
tensor(0.5352, device='cuda:0', grad_fn=<AddBackward0>)
0.84224659
tensor(0.5719, device='cuda:0', grad_fn=<AddBackward0>)
0.84229958
tensor(0.5623, device='cuda:0', grad_fn=<AddBackward0>)
0.84224069
tensor(0.6169, device='cuda:0', grad_fn=<AddBackward0>)
0.84209597
tensor(0.5070, device='cuda:0', grad_fn=<AddBackward0>)
0.84207350
tensor(0.5659, device='cuda:0', grad_fn=<AddBackward0>)
0.84211981
tensor(0.4334, device='cuda:0', grad_fn=<AddBackward0>)
0.84182078
tensor(0.4785, device='cuda:0', grad_fn=<AddBackward0>)
0.84176373
tensor(0.5807, device='cuda:0', grad_fn=<AddBackward0>)
0.84155172
tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)
0.84137201
tensor(0.5434, device='cuda:0', grad_fn=<AddBackward0>)
0.84145063
tensor(0.5923, device='cuda:0', grad_fn=<AddBackward0>)
0.84132069
tensor(0.5683, device='cuda:0', grad_fn=<AddBackward0>)
0.84115952
tensor(0.4866, device='cuda:0', grad_fn=<AddBackward0>)
0.84113795
tensor(0.5413, device='cuda:0', grad_fn=<AddBackward0>)
0.84112418
tensor(0.5533, device='cuda:0', grad_fn=<AddBackward0>)
0.84101439
tensor(0.4561, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [3][  100/  196]   Loss 0.541600   Top1 81.843750   Top5 99.105469   BatchTime 0.272769   LR 0.000363
0.84100395
tensor(0.4599, device='cuda:0', grad_fn=<AddBackward0>)
0.84096009
tensor(0.4884, device='cuda:0', grad_fn=<AddBackward0>)
0.84111679
tensor(0.5462, device='cuda:0', grad_fn=<AddBackward0>)
0.84100789
tensor(0.4967, device='cuda:0', grad_fn=<AddBackward0>)
0.84104842
tensor(0.5720, device='cuda:0', grad_fn=<AddBackward0>)
0.84123528
tensor(0.6269, device='cuda:0', grad_fn=<AddBackward0>)
0.84136349
tensor(0.5561, device='cuda:0', grad_fn=<AddBackward0>)
0.84137154
tensor(0.6789, device='cuda:0', grad_fn=<AddBackward0>)
0.84131908
tensor(0.6201, device='cuda:0', grad_fn=<AddBackward0>)
0.84155375
tensor(0.6068, device='cuda:0', grad_fn=<AddBackward0>)
0.84166557
tensor(0.6101, device='cuda:0', grad_fn=<AddBackward0>)
0.84178448
tensor(0.5241, device='cuda:0', grad_fn=<AddBackward0>)
0.84183729
tensor(0.5586, device='cuda:0', grad_fn=<AddBackward0>)
0.84213006
tensor(0.5944, device='cuda:0', grad_fn=<AddBackward0>)
0.84192520
tensor(0.4527, device='cuda:0', grad_fn=<AddBackward0>)
0.84195137
tensor(0.5469, device='cuda:0', grad_fn=<AddBackward0>)
0.84212482
tensor(0.5506, device='cuda:0', grad_fn=<AddBackward0>)
0.84215111
tensor(0.6789, device='cuda:0', grad_fn=<AddBackward0>)
0.84217411
tensor(0.4902, device='cuda:0', grad_fn=<AddBackward0>)
0.84256226
tensor(0.4657, device='cuda:0', grad_fn=<AddBackward0>)
0.84243166
tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
0.84276867
tensor(0.5290, device='cuda:0', grad_fn=<AddBackward0>)
0.84246111
tensor(0.5962, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [3][  120/  196]   Loss 0.544904   Top1 81.708984   Top5 99.104818   BatchTime 0.269168   LR 0.000356
0.84232104
tensor(0.5770, device='cuda:0', grad_fn=<AddBackward0>)
0.84269655
tensor(0.5256, device='cuda:0', grad_fn=<AddBackward0>)
0.84282869
tensor(0.5111, device='cuda:0', grad_fn=<AddBackward0>)
0.84278595
tensor(0.5409, device='cuda:0', grad_fn=<AddBackward0>)
0.84290391
tensor(0.5401, device='cuda:0', grad_fn=<AddBackward0>)
0.84313279
tensor(0.4785, device='cuda:0', grad_fn=<AddBackward0>)
0.84339052
tensor(0.5475, device='cuda:0', grad_fn=<AddBackward0>)
0.84588748
tensor(0.5803, device='cuda:0', grad_fn=<AddBackward0>)
0.84960735
tensor(0.4548, device='cuda:0', grad_fn=<AddBackward0>)
0.84984052
tensor(0.5560, device='cuda:0', grad_fn=<AddBackward0>)
0.85036635
tensor(0.4739, device='cuda:0', grad_fn=<AddBackward0>)
0.85004109
tensor(0.6405, device='cuda:0', grad_fn=<AddBackward0>)
0.85025644
tensor(0.5410, device='cuda:0', grad_fn=<AddBackward0>)
0.85051590
tensor(0.4664, device='cuda:0', grad_fn=<AddBackward0>)
0.85031420
tensor(0.4641, device='cuda:0', grad_fn=<AddBackward0>)
0.85023814
tensor(0.5442, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [3][  140/  196]   Loss 0.541003   Top1 81.805246   Top5 99.098772   BatchTime 0.266742   LR 0.000348
0.85024339
tensor(0.4732, device='cuda:0', grad_fn=<AddBackward0>)
0.85011280
tensor(0.5987, device='cuda:0', grad_fn=<AddBackward0>)
0.85014623
tensor(0.5097, device='cuda:0', grad_fn=<AddBackward0>)
0.85017139
tensor(0.4423, device='cuda:0', grad_fn=<AddBackward0>)
0.84983855
tensor(0.4630, device='cuda:0', grad_fn=<AddBackward0>)
0.84994161
tensor(0.5591, device='cuda:0', grad_fn=<AddBackward0>)
0.84986311
tensor(0.6079, device='cuda:0', grad_fn=<AddBackward0>)
0.84986168
tensor(0.5564, device='cuda:0', grad_fn=<AddBackward0>)
0.84987074
tensor(0.4674, device='cuda:0', grad_fn=<AddBackward0>)
0.84960830
tensor(0.5106, device='cuda:0', grad_fn=<AddBackward0>)
0.84955055
tensor(0.5837, device='cuda:0', grad_fn=<AddBackward0>)
0.84967428
tensor(0.4648, device='cuda:0', grad_fn=<AddBackward0>)
0.84944516
tensor(0.5278, device='cuda:0', grad_fn=<AddBackward0>)
0.84935927
tensor(0.4843, device='cuda:0', grad_fn=<AddBackward0>)
0.84929097
tensor(0.5740, device='cuda:0', grad_fn=<AddBackward0>)
0.84936625
tensor(0.6296, device='cuda:0', grad_fn=<AddBackward0>)
0.84944302
tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
0.84935558
tensor(0.4994, device='cuda:0', grad_fn=<AddBackward0>)
0.84920478
tensor(0.4622, device='cuda:0', grad_fn=<AddBackward0>)
0.84926158
tensor(0.7085, device='cuda:0', grad_fn=<AddBackward0>)
0.84927166
tensor(0.5847, device='cuda:0', grad_fn=<AddBackward0>)
0.84898663
tensor(0.5760, device='cuda:0', grad_fn=<AddBackward0>)
0.84922987
tensor(0.5282, device='cuda:0', grad_fn=<AddBackward0>)
0.84941310
tensor(0.4607, device='cuda:0', grad_fn=<AddBackward0>)
0.84932047
tensor(0.5039, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [3][  160/  196]   Loss 0.540329   Top1 81.782227   Top5 99.089355   BatchTime 0.264182   LR 0.000341
0.84894484
tensor(0.5150, device='cuda:0', grad_fn=<AddBackward0>)
0.84913522
tensor(0.5681, device='cuda:0', grad_fn=<AddBackward0>)
0.84935129
tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
0.84948260
tensor(0.6515, device='cuda:0', grad_fn=<AddBackward0>)
0.84903872
tensor(0.4395, device='cuda:0', grad_fn=<AddBackward0>)
0.84894520
tensor(0.5023, device='cuda:0', grad_fn=<AddBackward0>)
0.84897512
tensor(0.4223, device='cuda:0', grad_fn=<AddBackward0>)
0.84916168
tensor(0.6536, device='cuda:0', grad_fn=<AddBackward0>)
0.84913838
tensor(0.4750, device='cuda:0', grad_fn=<AddBackward0>)
0.84914267
tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)
0.84917986
tensor(0.5528, device='cuda:0', grad_fn=<AddBackward0>)
0.84923816
tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)
0.84951514
tensor(0.4987, device='cuda:0', grad_fn=<AddBackward0>)
0.84953117
tensor(0.7036, device='cuda:0', grad_fn=<AddBackward0>)
0.84959090
tensor(0.6217, device='cuda:0', grad_fn=<AddBackward0>)
0.84976530
tensor(0.4695, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [3][  180/  196]   Loss 0.538152   Top1 81.864149   Top5 99.084201   BatchTime 0.262727   LR 0.000333
0.84957266
tensor(0.6017, device='cuda:0', grad_fn=<AddBackward0>)
0.84903073
tensor(0.4916, device='cuda:0', grad_fn=<AddBackward0>)
0.84891981
tensor(0.4928, device='cuda:0', grad_fn=<AddBackward0>)
0.84884834
tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
0.84886175
tensor(0.4770, device='cuda:0', grad_fn=<AddBackward0>)
0.84880859
tensor(0.4431, device='cuda:0', grad_fn=<AddBackward0>)
0.84888500
tensor(0.5066, device='cuda:0', grad_fn=<AddBackward0>)
0.84892488
tensor(0.4711, device='cuda:0', grad_fn=<AddBackward0>)
0.84905177
tensor(0.5978, device='cuda:0', grad_fn=<AddBackward0>)
0.84894091
tensor(0.5517, device='cuda:0', grad_fn=<AddBackward0>)
0.84907931
tensor(0.5419, device='cuda:0', grad_fn=<AddBackward0>)
0.84884083
tensor(0.5597, device='cuda:0', grad_fn=<AddBackward0>)
0.84885174
tensor(0.5153, device='cuda:0', grad_fn=<AddBackward0>)
0.84890628
tensor(0.5141, device='cuda:0', grad_fn=<AddBackward0>)
0.84897584
tensor(0.5453, device='cuda:0', grad_fn=<AddBackward0>)
0.84901148
tensor(0.4606, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 81.922    Top5: 99.080    Loss: 0.536
0.84903097
tensor(0.4484, device='cuda:0', grad_fn=<AddBackward0>)
0.84910107
tensor(0.6028, device='cuda:0', grad_fn=<AddBackward0>)
0.84892035
tensor(0.5270, device='cuda:0', grad_fn=<AddBackward0>)
0.84886348
tensor(0.4105, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [3][   20/   40]   Loss 0.574250   Top1 80.976562   Top5 98.964844   BatchTime 0.125986
INFO - Validation [3][   40/   40]   Loss 0.565715   Top1 81.130000   Top5 99.040000   BatchTime 0.091150
INFO - ==> Top1: 81.130    Top5: 99.040    Loss: 0.566
INFO - ==> Sparsity : 0.283
INFO - Scoreboard best 1 ==> Epoch [3][Top1: 81.130   Top5: 99.040]
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 76.430   Top5: 97.990]
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 74.400   Top5: 98.150]
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1406)
features.1.conv.0 tensor(0.0612)
features.1.conv.3 tensor(0.0729)
features.1.conv.6 tensor(0.0812)
features.2.conv.0 tensor(0.0735)
features.2.conv.3 tensor(0.3457)
features.2.conv.6 tensor(0.1846)
features.3.conv.0 tensor(0.0668)
features.3.conv.3 tensor(0.0957)
features.3.conv.6 tensor(0.1191)
features.4.conv.0 tensor(0.0895)
features.4.conv.3 tensor(0.3003)
features.4.conv.6 tensor(0.1880)
features.5.conv.0 tensor(0.3460)
features.5.conv.3 tensor(0.4167)
features.5.conv.6 tensor(0.1068)
features.6.conv.0 tensor(0.0529)
features.6.conv.3 tensor(0.0596)
features.6.conv.6 tensor(0.0819)
features.7.conv.0 tensor(0.2175)
features.7.conv.3 tensor(0.4488)
features.7.conv.6 tensor(0.1929)
features.8.conv.0 tensor(0.2107)
features.8.conv.3 tensor(0.5341)
features.8.conv.6 tensor(0.1697)
features.9.conv.0 tensor(0.2926)
features.9.conv.3 tensor(0.5700)
features.9.conv.6 tensor(0.1608)
features.10.conv.0 tensor(0.0736)
features.10.conv.3 tensor(0.1088)
features.10.conv.6 tensor(0.1066)
features.11.conv.0 tensor(0.6571)
features.11.conv.3 tensor(0.6460)
features.11.conv.6 tensor(0.8197)
features.12.conv.0 tensor(0.6241)
features.12.conv.3 tensor(0.6726)
features.12.conv.6 tensor(0.1668)
features.13.conv.0 tensor(0.2403)
features.13.conv.3 tensor(0.4884)
features.13.conv.6 tensor(0.0955)
features.14.conv.0 tensor(0.8074)
features.14.conv.3 tensor(0.8188)
features.14.conv.6 tensor(0.1385)
features.15.conv.0 tensor(0.7837)
features.15.conv.3 tensor(0.8255)
features.15.conv.6 tensor(0.1813)
features.16.conv.0 tensor(0.2475)
features.16.conv.3 tensor(0.7869)
features.16.conv.6 tensor(0.0699)
conv.0 tensor(0.0891)
tensor(619269.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
0.84880036
tensor(0.4972, device='cuda:0', grad_fn=<AddBackward0>)
0.84885561
tensor(0.5697, device='cuda:0', grad_fn=<AddBackward0>)
0.84891582
tensor(0.4693, device='cuda:0', grad_fn=<AddBackward0>)
0.84878176
tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)
0.84850210
tensor(0.4228, device='cuda:0', grad_fn=<AddBackward0>)
0.84842885
tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>)
0.84823793
tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)
0.84816223
tensor(0.5020, device='cuda:0', grad_fn=<AddBackward0>)
0.84808779
tensor(0.5726, device='cuda:0', grad_fn=<AddBackward0>)
0.84821242
tensor(0.4537, device='cuda:0', grad_fn=<AddBackward0>)
0.84824425
tensor(0.5653, device='cuda:0', grad_fn=<AddBackward0>)
0.84821659
tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)
0.84779936
tensor(0.4992, device='cuda:0', grad_fn=<AddBackward0>)
0.84801179
tensor(0.4273, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [4][   20/  196]   Loss 0.473855   Top1 83.945312   Top5 99.375000   BatchTime 0.326998   LR 0.000320
0.84804362
tensor(0.4358, device='cuda:0', grad_fn=<AddBackward0>)
0.84799373
tensor(0.4702, device='cuda:0', grad_fn=<AddBackward0>)
0.84799218
tensor(0.4739, device='cuda:0', grad_fn=<AddBackward0>)
0.84806210
tensor(0.4989, device='cuda:0', grad_fn=<AddBackward0>)
0.84817666
tensor(0.4262, device='cuda:0', grad_fn=<AddBackward0>)
0.84809411
tensor(0.4514, device='cuda:0', grad_fn=<AddBackward0>)
0.84808308
tensor(0.5318, device='cuda:0', grad_fn=<AddBackward0>)
0.84760642
tensor(0.4681, device='cuda:0', grad_fn=<AddBackward0>)
0.84777778
tensor(0.4936, device='cuda:0', grad_fn=<AddBackward0>)
0.84786886
tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)
0.84770328
tensor(0.5685, device='cuda:0', grad_fn=<AddBackward0>)
0.84786439
tensor(0.4564, device='cuda:0', grad_fn=<AddBackward0>)
0.84803706
tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
0.84814739
tensor(0.5341, device='cuda:0', grad_fn=<AddBackward0>)
0.84819782
tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
0.84809726
tensor(0.4945, device='cuda:0', grad_fn=<AddBackward0>)
0.84805042
tensor(0.5556, device='cuda:0', grad_fn=<AddBackward0>)
0.84780610
tensor(0.5614, device='cuda:0', grad_fn=<AddBackward0>)
0.84744698
tensor(0.4044, device='cuda:0', grad_fn=<AddBackward0>)
0.84755713
tensor(0.4744, device='cuda:0', grad_fn=<AddBackward0>)
0.84711218
tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)
0.84699577
tensor(0.4384, device='cuda:0', grad_fn=<AddBackward0>)
0.84708208
tensor(0.5039, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [4][   40/  196]   Loss 0.480538   Top1 83.964844   Top5 99.306641   BatchTime 0.294044   LR 0.000312
0.84703630
tensor(0.4613, device='cuda:0', grad_fn=<AddBackward0>)
0.84689367
tensor(0.4300, device='cuda:0', grad_fn=<AddBackward0>)
0.84692287
tensor(0.6573, device='cuda:0', grad_fn=<AddBackward0>)
0.84698182
tensor(0.5788, device='cuda:0', grad_fn=<AddBackward0>)
0.84708488
tensor(0.4520, device='cuda:0', grad_fn=<AddBackward0>)
0.84716618
tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>)
0.84743702
tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)
0.84749079
tensor(0.4949, device='cuda:0', grad_fn=<AddBackward0>)
0.84760398
tensor(0.5358, device='cuda:0', grad_fn=<AddBackward0>)
0.84775543
tensor(0.4755, device='cuda:0', grad_fn=<AddBackward0>)
0.84769362
tensor(0.4509, device='cuda:0', grad_fn=<AddBackward0>)
0.84751391
tensor(0.5145, device='cuda:0', grad_fn=<AddBackward0>)
0.84724873
tensor(0.5182, device='cuda:0', grad_fn=<AddBackward0>)
0.84726524
tensor(0.4539, device='cuda:0', grad_fn=<AddBackward0>)
0.84709942
tensor(0.6032, device='cuda:0', grad_fn=<AddBackward0>)
0.84707397
tensor(0.5422, device='cuda:0', grad_fn=<AddBackward0>)
0.84724331
tensor(0.5854, device='cuda:0', grad_fn=<AddBackward0>)
0.84659493
tensor(0.6188, device='cuda:0', grad_fn=<AddBackward0>)
0.84669185
tensor(0.4418, device='cuda:0', grad_fn=<AddBackward0>)
0.84693807
tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)
0.84689093
tensor(0.4725, device='cuda:0', grad_fn=<AddBackward0>)
0.84705251
tensor(0.4832, device='cuda:0', grad_fn=<AddBackward0>)
0.84710950
tensor(0.4936, device='cuda:0', grad_fn=<AddBackward0>)
0.84714329
tensor(0.4759, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [4][   60/  196]   Loss 0.487594   Top1 83.671875   Top5 99.244792   BatchTime 0.279704   LR 0.000304
0.84724003
tensor(0.5035, device='cuda:0', grad_fn=<AddBackward0>)
0.84693170
tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>)
0.84632289
tensor(0.4907, device='cuda:0', grad_fn=<AddBackward0>)
0.84621960
tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)
0.84616321
tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)
0.84614104
tensor(0.5118, device='cuda:0', grad_fn=<AddBackward0>)
0.84638083
tensor(0.4750, device='cuda:0', grad_fn=<AddBackward0>)
0.84621418
tensor(0.4612, device='cuda:0', grad_fn=<AddBackward0>)
0.84632009
tensor(0.4934, device='cuda:0', grad_fn=<AddBackward0>)
0.84605330
tensor(0.5224, device='cuda:0', grad_fn=<AddBackward0>)
0.84618658
tensor(0.4788, device='cuda:0', grad_fn=<AddBackward0>)
0.84645218
tensor(0.4399, device='cuda:0', grad_fn=<AddBackward0>)
0.84789044
tensor(0.5118, device='cuda:0', grad_fn=<AddBackward0>)
0.84820670
tensor(0.4414, device='cuda:0', grad_fn=<AddBackward0>)
0.84823453
tensor(0.4278, device='cuda:0', grad_fn=<AddBackward0>)
0.84852558
tensor(0.5157, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [4][   80/  196]   Loss 0.483935   Top1 83.833008   Top5 99.199219   BatchTime 0.272132   LR 0.000296
0.84843051
tensor(0.4983, device='cuda:0', grad_fn=<AddBackward0>)
0.84860796
tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
0.84821534
tensor(0.4952, device='cuda:0', grad_fn=<AddBackward0>)
0.84784418
tensor(0.5389, device='cuda:0', grad_fn=<AddBackward0>)
0.84795707
tensor(0.4805, device='cuda:0', grad_fn=<AddBackward0>)
0.84776497
tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
0.84767002
tensor(0.5030, device='cuda:0', grad_fn=<AddBackward0>)
0.84756368
tensor(0.4405, device='cuda:0', grad_fn=<AddBackward0>)
0.84763443
tensor(0.5592, device='cuda:0', grad_fn=<AddBackward0>)
0.84791708
tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)
0.84761757
tensor(0.4950, device='cuda:0', grad_fn=<AddBackward0>)
0.84766543
tensor(0.4143, device='cuda:0', grad_fn=<AddBackward0>)
0.84765410
tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
0.84763259
tensor(0.4290, device='cuda:0', grad_fn=<AddBackward0>)
0.84766096
tensor(0.5577, device='cuda:0', grad_fn=<AddBackward0>)
0.84770584
tensor(0.4906, device='cuda:0', grad_fn=<AddBackward0>)
0.84769648
tensor(0.4373, device='cuda:0', grad_fn=<AddBackward0>)
0.84786779
tensor(0.5387, device='cuda:0', grad_fn=<AddBackward0>)
0.84761393
tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
0.84763300
tensor(0.4428, device='cuda:0', grad_fn=<AddBackward0>)
0.84785908
tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
0.84800971
tensor(0.5268, device='cuda:0', grad_fn=<AddBackward0>)
0.84790796
tensor(0.5055, device='cuda:0', grad_fn=<AddBackward0>)
0.84779316
tensor(0.4556, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [4][  100/  196]   Loss 0.481683   Top1 83.882812   Top5 99.238281   BatchTime 0.267162   LR 0.000289
0.84809405
tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
0.84789044
tensor(0.5427, device='cuda:0', grad_fn=<AddBackward0>)
0.84798193
tensor(0.5000, device='cuda:0', grad_fn=<AddBackward0>)
0.84781981
tensor(0.4679, device='cuda:0', grad_fn=<AddBackward0>)
0.84766537
tensor(0.4570, device='cuda:0', grad_fn=<AddBackward0>)
0.84752578
tensor(0.4530, device='cuda:0', grad_fn=<AddBackward0>)
0.84740233
tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
0.84697545
tensor(0.5666, device='cuda:0', grad_fn=<AddBackward0>)
0.84664214
tensor(0.5016, device='cuda:0', grad_fn=<AddBackward0>)
0.84643620
tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>)
0.84640402
tensor(0.4896, device='cuda:0', grad_fn=<AddBackward0>)
0.84680992
tensor(0.5852, device='cuda:0', grad_fn=<AddBackward0>)
0.84668237
tensor(0.6780, device='cuda:0', grad_fn=<AddBackward0>)
0.84653509
tensor(0.4174, device='cuda:0', grad_fn=<AddBackward0>)
0.84653413
tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
0.84640050
tensor(0.5576, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [4][  120/  196]   Loss 0.480249   Top1 83.873698   Top5 99.257812   BatchTime 0.264006   LR 0.000281
0.84592664
tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
0.84607875
tensor(0.4216, device='cuda:0', grad_fn=<AddBackward0>)
0.84606630
tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
0.84598804
tensor(0.4558, device='cuda:0', grad_fn=<AddBackward0>)
0.84594047
tensor(0.4321, device='cuda:0', grad_fn=<AddBackward0>)
0.84578717
tensor(0.5442, device='cuda:0', grad_fn=<AddBackward0>)
0.84545869
tensor(0.5282, device='cuda:0', grad_fn=<AddBackward0>)
0.84523535
tensor(0.4690, device='cuda:0', grad_fn=<AddBackward0>)
0.84495336
tensor(0.5389, device='cuda:0', grad_fn=<AddBackward0>)
0.84472394
tensor(0.5051, device='cuda:0', grad_fn=<AddBackward0>)
0.84441960
tensor(0.4448, device='cuda:0', grad_fn=<AddBackward0>)
0.84419912
tensor(0.4811, device='cuda:0', grad_fn=<AddBackward0>)
0.84377819
tensor(0.4164, device='cuda:0', grad_fn=<AddBackward0>)
0.84378552
tensor(0.5230, device='cuda:0', grad_fn=<AddBackward0>)
0.84370977
tensor(0.4949, device='cuda:0', grad_fn=<AddBackward0>)
0.84399706
tensor(0.4320, device='cuda:0', grad_fn=<AddBackward0>)
0.84401530
tensor(0.5205, device='cuda:0', grad_fn=<AddBackward0>)
0.84376115
tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)
0.84355932
tensor(0.5398, device='cuda:0', grad_fn=<AddBackward0>)
0.84342039
tensor(0.5976, device='cuda:0', grad_fn=<AddBackward0>)
0.84327459
tensor(0.4552, device='cuda:0', grad_fn=<AddBackward0>)
0.84320658
tensor(0.5805, device='cuda:0', grad_fn=<AddBackward0>)
0.84338826
tensor(0.4647, device='cuda:0', grad_fn=<AddBackward0>)
0.84325397
tensor(0.5042, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [4][  140/  196]   Loss 0.482056   Top1 83.691406   Top5 99.249442   BatchTime 0.261969   LR 0.000273
0.84336466
tensor(0.4708, device='cuda:0', grad_fn=<AddBackward0>)
0.84314942
tensor(0.5003, device='cuda:0', grad_fn=<AddBackward0>)
0.84300804
tensor(0.5257, device='cuda:0', grad_fn=<AddBackward0>)
0.84332556
tensor(0.4855, device='cuda:0', grad_fn=<AddBackward0>)
0.84333384
tensor(0.4408, device='cuda:0', grad_fn=<AddBackward0>)
0.84309816
tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>)
0.84314233
tensor(0.4660, device='cuda:0', grad_fn=<AddBackward0>)
0.84313804
tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
0.84282535
tensor(0.4498, device='cuda:0', grad_fn=<AddBackward0>)
0.84258741
tensor(0.6454, device='cuda:0', grad_fn=<AddBackward0>)
0.84227616
tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
0.84219563
tensor(0.4976, device='cuda:0', grad_fn=<AddBackward0>)
0.84174377
tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
0.84159422
tensor(0.4956, device='cuda:0', grad_fn=<AddBackward0>)
0.84103400
tensor(0.6115, device='cuda:0', grad_fn=<AddBackward0>)
0.84074497
tensor(0.4421, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [4][  160/  196]   Loss 0.480492   Top1 83.806152   Top5 99.228516   BatchTime 0.261143   LR 0.000265
0.84074998
tensor(0.4608, device='cuda:0', grad_fn=<AddBackward0>)
0.84042507
tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
0.83989882
tensor(0.5065, device='cuda:0', grad_fn=<AddBackward0>)
0.83942050
tensor(0.5203, device='cuda:0', grad_fn=<AddBackward0>)
0.83917892
tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>)
0.83893138
tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)
0.83891451
tensor(0.4179, device='cuda:0', grad_fn=<AddBackward0>)
0.83888298
tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
0.83939332
tensor(0.4619, device='cuda:0', grad_fn=<AddBackward0>)
0.83914542
tensor(0.5357, device='cuda:0', grad_fn=<AddBackward0>)
0.83933806
tensor(0.5249, device='cuda:0', grad_fn=<AddBackward0>)
0.83966923
tensor(0.4981, device='cuda:0', grad_fn=<AddBackward0>)
0.84044737
tensor(0.4954, device='cuda:0', grad_fn=<AddBackward0>)
0.84064221
tensor(0.4486, device='cuda:0', grad_fn=<AddBackward0>)
0.84087139
tensor(0.4470, device='cuda:0', grad_fn=<AddBackward0>)
0.84092194
tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
0.84076089
tensor(0.4845, device='cuda:0', grad_fn=<AddBackward0>)
0.84080696
tensor(0.4746, device='cuda:0', grad_fn=<AddBackward0>)
0.84067506
tensor(0.4206, device='cuda:0', grad_fn=<AddBackward0>)
0.84044379
tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)
0.84058201
tensor(0.3879, device='cuda:0', grad_fn=<AddBackward0>)
0.84051824
tensor(0.5124, device='cuda:0', grad_fn=<AddBackward0>)
0.84095097
tensor(0.4701, device='cuda:0', grad_fn=<AddBackward0>)
0.84115160
tensor(0.4833, device='cuda:0', grad_fn=<AddBackward0>)
0.84138608
tensor(0.4730, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [4][  180/  196]   Loss 0.478214   Top1 83.869358   Top5 99.236111   BatchTime 0.259030   LR 0.000257
0.84152061
tensor(0.5121, device='cuda:0', grad_fn=<AddBackward0>)
0.84200233
tensor(0.4515, device='cuda:0', grad_fn=<AddBackward0>)
0.84227264
tensor(0.5144, device='cuda:0', grad_fn=<AddBackward0>)
0.84220219
tensor(0.5662, device='cuda:0', grad_fn=<AddBackward0>)
0.84194916
tensor(0.5150, device='cuda:0', grad_fn=<AddBackward0>)
0.84172225
tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
0.84163904
tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
0.84156567
tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
0.84168261
tensor(0.4974, device='cuda:0', grad_fn=<AddBackward0>)
0.84145916
tensor(0.4704, device='cuda:0', grad_fn=<AddBackward0>)
0.84149539
tensor(0.4671, device='cuda:0', grad_fn=<AddBackward0>)
0.84136844
tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
0.84164149
tensor(0.5230, device='cuda:0', grad_fn=<AddBackward0>)
0.84117150
tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 83.886    Top5: 99.250    Loss: 0.478
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [4][   20/   40]   Loss 0.538666   Top1 80.664062   Top5 99.179688   BatchTime 0.114835
INFO - Validation [4][   40/   40]   Loss 0.531644   Top1 81.110000   Top5 99.300000   BatchTime 0.086068
INFO - ==> Top1: 81.110    Top5: 99.300    Loss: 0.532
INFO - ==> Sparsity : 0.288
INFO - Scoreboard best 1 ==> Epoch [3][Top1: 81.130   Top5: 99.040]
INFO - Scoreboard best 2 ==> Epoch [4][Top1: 81.110   Top5: 99.300]
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 76.430   Top5: 97.990]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2674)
features.0.conv.3 tensor(0.1406)
features.1.conv.0 tensor(0.0599)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0825)
features.2.conv.0 tensor(0.0712)
features.2.conv.3 tensor(0.3426)
features.2.conv.6 tensor(0.1803)
features.3.conv.0 tensor(0.0666)
features.3.conv.3 tensor(0.0864)
features.3.conv.6 tensor(0.1161)
features.4.conv.0 tensor(0.0798)
features.4.conv.3 tensor(0.3084)
features.4.conv.6 tensor(0.1922)
features.5.conv.0 tensor(0.3451)
features.5.conv.3 tensor(0.4213)
features.5.conv.6 tensor(0.1064)
features.6.conv.0 tensor(0.0605)
features.6.conv.3 tensor(0.0567)
features.6.conv.6 tensor(0.0861)
features.7.conv.0 tensor(0.2213)
features.7.conv.3 tensor(0.4540)
features.7.conv.6 tensor(0.1992)
features.8.conv.0 tensor(0.1975)
features.8.conv.3 tensor(0.5344)
features.8.conv.6 tensor(0.1613)
features.9.conv.0 tensor(0.2679)
features.9.conv.3 tensor(0.5651)
features.9.conv.6 tensor(0.1480)
features.10.conv.0 tensor(0.0763)
features.10.conv.3 tensor(0.1062)
features.10.conv.6 tensor(0.1038)
features.11.conv.0 tensor(0.6638)
features.11.conv.3 tensor(0.6472)
features.11.conv.6 tensor(0.8230)
features.12.conv.0 tensor(0.6296)
features.12.conv.3 tensor(0.6707)
features.12.conv.6 tensor(0.1598)
features.13.conv.0 tensor(0.2425)
features.13.conv.3 tensor(0.4911)
features.13.conv.6 tensor(0.0946)
features.14.conv.0 tensor(0.8236)
features.14.conv.3 tensor(0.8168)
features.14.conv.6 tensor(0.1668)
features.15.conv.0 tensor(0.7896)
features.15.conv.3 tensor(0.8257)
features.15.conv.6 tensor(0.2043)
features.16.conv.0 tensor(0.2534)
features.16.conv.3 tensor(0.7881)
features.16.conv.6 tensor(0.0658)
conv.0 tensor(0.0906)
tensor(630147.) 2188896.0
0.84109908
tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)
0.84123921
tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
0.84102511
tensor(0.4989, device='cuda:0', grad_fn=<AddBackward0>)
0.84097660
tensor(0.4720, device='cuda:0', grad_fn=<AddBackward0>)
0.84082645
tensor(0.4260, device='cuda:0', grad_fn=<AddBackward0>)
0.84024215
tensor(0.4527, device='cuda:0', grad_fn=<AddBackward0>)
0.84012794
tensor(0.4099, device='cuda:0', grad_fn=<AddBackward0>)
0.84032947
tensor(0.5092, device='cuda:0', grad_fn=<AddBackward0>)
0.84043068
tensor(0.4892, device='cuda:0', grad_fn=<AddBackward0>)
0.84024298
tensor(0.3926, device='cuda:0', grad_fn=<AddBackward0>)
0.84008431
tensor(0.5019, device='cuda:0', grad_fn=<AddBackward0>)
0.84013397
tensor(0.4433, device='cuda:0', grad_fn=<AddBackward0>)
0.84009612
tensor(0.4030, device='cuda:0', grad_fn=<AddBackward0>)
0.83986562
tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>)
0.83963662
tensor(0.5057, device='cuda:0', grad_fn=<AddBackward0>)
0.83963090
tensor(0.4708, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [5][   20/  196]   Loss 0.452992   Top1 84.042969   Top5 99.472656   BatchTime 0.313778   LR 0.000242
0.83977675
tensor(0.5188, device='cuda:0', grad_fn=<AddBackward0>)
0.83976781
tensor(0.4518, device='cuda:0', grad_fn=<AddBackward0>)
0.83982009
tensor(0.4525, device='cuda:0', grad_fn=<AddBackward0>)
0.83982944
tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
0.83985996
tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
0.84015083
tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
0.83997440
tensor(0.4743, device='cuda:0', grad_fn=<AddBackward0>)
0.83968604
tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
0.83985251
tensor(0.4687, device='cuda:0', grad_fn=<AddBackward0>)
0.83998019
tensor(0.3761, device='cuda:0', grad_fn=<AddBackward0>)
0.84011078
tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)
0.83996880
tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>)
0.83989638
tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>)
0.83991069
tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)
0.84003109
tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
0.83993226
tensor(0.4412, device='cuda:0', grad_fn=<AddBackward0>)
0.83974886
tensor(0.4965, device='cuda:0', grad_fn=<AddBackward0>)
0.83946496
tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
0.83976787
tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)
0.83988535
tensor(0.4961, device='cuda:0', grad_fn=<AddBackward0>)
0.83952582
tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)
0.83944190
tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
0.83925247
tensor(0.4852, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [5][   40/  196]   Loss 0.436174   Top1 84.873047   Top5 99.462891   BatchTime 0.288157   LR 0.000234
0.83922869
tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>)
0.83893555
tensor(0.4728, device='cuda:0', grad_fn=<AddBackward0>)
0.83886439
tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
0.83899844
tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
0.83850807
tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
0.83806771
tensor(0.5213, device='cuda:0', grad_fn=<AddBackward0>)
0.83754385
tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
0.83739841
tensor(0.4334, device='cuda:0', grad_fn=<AddBackward0>)
0.83749253
tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
0.83692443
tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)
0.83677524
tensor(0.4914, device='cuda:0', grad_fn=<AddBackward0>)
0.83673173
tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
0.83646888
tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
0.83622068
tensor(0.4987, device='cuda:0', grad_fn=<AddBackward0>)
0.83606672
tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)
0.83539253
tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
0.83447891
tensor(0.5026, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [5][   60/  196]   Loss 0.427667   Top1 85.305990   Top5 99.485677   BatchTime 0.275405   LR 0.000226
0.83424443
tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
0.83425748
tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>)
0.83411330
tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
0.83345068
tensor(0.3822, device='cuda:0', grad_fn=<AddBackward0>)
0.83332920
tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
0.83273464
tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)
0.83199286
tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
0.83145422
tensor(0.5014, device='cuda:0', grad_fn=<AddBackward0>)
0.83111763
tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
0.83022928
tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
0.82959074
tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
0.82914096
tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>)
0.82870620
tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)
0.82799524
tensor(0.4637, device='cuda:0', grad_fn=<AddBackward0>)
0.82753861
tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>)
0.82717854
tensor(0.4447, device='cuda:0', grad_fn=<AddBackward0>)
0.82695884
tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
0.82609814
tensor(0.4816, device='cuda:0', grad_fn=<AddBackward0>)
0.82572430
tensor(0.4480, device='cuda:0', grad_fn=<AddBackward0>)
0.82540852
tensor(0.4418, device='cuda:0', grad_fn=<AddBackward0>)
0.82467479
tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
0.82458287
tensor(0.5294, device='cuda:0', grad_fn=<AddBackward0>)
0.82415384
tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
0.82338512
tensor(0.4370, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [5][   80/  196]   Loss 0.424612   Top1 85.405273   Top5 99.487305   BatchTime 0.268145   LR 0.000218
0.82278073
tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
0.82181346
tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)
0.82116395
tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>)
0.82060134
tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
0.81984407
tensor(0.5043, device='cuda:0', grad_fn=<AddBackward0>)
0.81881028
tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
0.81764656
tensor(0.4508, device='cuda:0', grad_fn=<AddBackward0>)
0.81642234
tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>)
0.81527746
tensor(0.4317, device='cuda:0', grad_fn=<AddBackward0>)
0.81387055
tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
0.81248212
tensor(0.4658, device='cuda:0', grad_fn=<AddBackward0>)
0.81110799
tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
0.80945653
tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)
0.80858397
tensor(0.4698, device='cuda:0', grad_fn=<AddBackward0>)
0.80755007
tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
0.80645204
tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [5][  100/  196]   Loss 0.425020   Top1 85.539062   Top5 99.449219   BatchTime 0.264786   LR 0.000210
0.80600899
tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
0.80584329
tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)
0.80541301
tensor(0.4480, device='cuda:0', grad_fn=<AddBackward0>)
0.80489123
tensor(0.4882, device='cuda:0', grad_fn=<AddBackward0>)
0.80456895
tensor(0.4209, device='cuda:0', grad_fn=<AddBackward0>)
0.80445313
tensor(0.4516, device='cuda:0', grad_fn=<AddBackward0>)
0.80417180
tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
0.80408221
tensor(0.4792, device='cuda:0', grad_fn=<AddBackward0>)
0.80391806
tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
0.80337244
tensor(0.5406, device='cuda:0', grad_fn=<AddBackward0>)
0.80316675
tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
0.80307621
tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)
0.80262756
tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)
0.80243975
tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>)
0.80242217
tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)
0.80213875
tensor(0.4376, device='cuda:0', grad_fn=<AddBackward0>)
0.80189443
tensor(0.4214, device='cuda:0', grad_fn=<AddBackward0>)
0.80163902
tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)
0.80122852
tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>)
0.80084318
tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
0.80057412
tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)
0.80012631
tensor(0.4011, device='cuda:0', grad_fn=<AddBackward0>)
0.79985577
tensor(0.4591, device='cuda:0', grad_fn=<AddBackward0>)
0.79969227
tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [5][  120/  196]   Loss 0.424078   Top1 85.579427   Top5 99.462891   BatchTime 0.261857   LR 0.000202
0.79935944
tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
0.79878104
tensor(0.4384, device='cuda:0', grad_fn=<AddBackward0>)
0.79865223
tensor(0.4733, device='cuda:0', grad_fn=<AddBackward0>)
0.79839528
tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
0.79851598
tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>)
0.79807317
tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
0.79791945
tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)
0.79803300
tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>)
0.79827112
tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
0.79797316
tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
0.79798001
tensor(0.4978, device='cuda:0', grad_fn=<AddBackward0>)
0.79808158
tensor(0.4856, device='cuda:0', grad_fn=<AddBackward0>)
0.79815060
tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)
0.79824221
tensor(0.5057, device='cuda:0', grad_fn=<AddBackward0>)
0.79801404
tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>)
0.79799843
tensor(0.4600, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [5][  140/  196]   Loss 0.423676   Top1 85.546875   Top5 99.464286   BatchTime 0.260036   LR 0.000195
0.79839373
tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)
0.79873383
tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
0.79902512
tensor(0.4317, device='cuda:0', grad_fn=<AddBackward0>)
0.79912287
tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>)
0.79879177
tensor(0.4880, device='cuda:0', grad_fn=<AddBackward0>)
0.79879433
tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
0.79849041
tensor(0.4543, device='cuda:0', grad_fn=<AddBackward0>)
0.79877174
tensor(0.4709, device='cuda:0', grad_fn=<AddBackward0>)
0.79893488
tensor(0.4096, device='cuda:0', grad_fn=<AddBackward0>)
0.79934227
tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
0.79909849
tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
0.79902619
tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
0.79891700
tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
0.79890764
tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
0.79921323
tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
0.79911232
tensor(0.4694, device='cuda:0', grad_fn=<AddBackward0>)
0.79938704
tensor(0.4464, device='cuda:0', grad_fn=<AddBackward0>)
0.79946095
tensor(0.4329, device='cuda:0', grad_fn=<AddBackward0>)
0.79926771
tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)
0.79925001
tensor(0.4632, device='cuda:0', grad_fn=<AddBackward0>)
0.79937494
tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
0.79933959
tensor(0.4321, device='cuda:0', grad_fn=<AddBackward0>)
0.79931486
tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
0.79944384
tensor(0.4998, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [5][  160/  196]   Loss 0.422238   Top1 85.549316   Top5 99.492188   BatchTime 0.259026   LR 0.000187
0.79933250
tensor(0.4756, device='cuda:0', grad_fn=<AddBackward0>)
0.79932362
tensor(0.4960, device='cuda:0', grad_fn=<AddBackward0>)
0.79912430
tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)
0.79900414
tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
0.79899079
tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
0.79868007
tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
0.79874492
tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>)
0.79865944
tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
0.79881626
tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>)
0.79888624
tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)
0.79901183
tensor(0.4753, device='cuda:0', grad_fn=<AddBackward0>)
0.79899555
tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
0.79925549
tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
0.79937053
tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
0.79901505
tensor(0.5303, device='cuda:0', grad_fn=<AddBackward0>)
0.79888445
tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [5][  180/  196]   Loss 0.420306   Top1 85.646701   Top5 99.483507   BatchTime 0.258070   LR 0.000179
0.79860544
tensor(0.4143, device='cuda:0', grad_fn=<AddBackward0>)
0.79833901
tensor(0.4099, device='cuda:0', grad_fn=<AddBackward0>)
0.79833424
tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
0.79829174
tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)
0.79843253
tensor(0.4151, device='cuda:0', grad_fn=<AddBackward0>)
0.79837453
tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>)
0.79835725
tensor(0.5347, device='cuda:0', grad_fn=<AddBackward0>)
0.79849809
tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
0.79822987
tensor(0.4949, device='cuda:0', grad_fn=<AddBackward0>)
0.79769975
tensor(0.4238, device='cuda:0', grad_fn=<AddBackward0>)
0.79761964
tensor(0.5045, device='cuda:0', grad_fn=<AddBackward0>)
0.79777992
tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)
0.79732049
tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>)
0.79708111
tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)
0.79704523
tensor(0.4845, device='cuda:0', grad_fn=<AddBackward0>)
0.79724330
tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
0.79740685
tensor(0.4535, device='cuda:0', grad_fn=<AddBackward0>)
0.79710412
tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>)
0.79695702
tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
0.79697907
tensor(0.5136, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 85.660    Top5: 99.476    Loss: 0.421
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [5][   20/   40]   Loss 0.466610   Top1 84.375000   Top5 99.140625   BatchTime 0.120396
features.0.conv.0 tensor(0.2743)
features.0.conv.3 tensor(0.1504)
features.1.conv.0 tensor(0.0547)
features.1.conv.3 tensor(0.0775)
features.1.conv.6 tensor(0.0820)
features.2.conv.0 tensor(0.0854)
features.2.conv.3 tensor(0.3457)
features.2.conv.6 tensor(0.1811)
features.3.conv.0 tensor(0.0573)
features.3.conv.3 tensor(0.0926)
features.3.conv.6 tensor(0.1133)
features.4.conv.0 tensor(0.0700)
features.4.conv.3 tensor(0.3027)
features.4.conv.6 tensor(0.1916)
features.5.conv.0 tensor(0.3436)
features.5.conv.3 tensor(0.4184)
features.5.conv.6 tensor(0.1086)
features.6.conv.0 tensor(0.0625)
features.6.conv.3 tensor(0.0561)
features.6.conv.6 tensor(0.0844)
features.7.conv.0 tensor(0.2268)
features.7.conv.3 tensor(0.4537)
features.7.conv.6 tensor(0.1995)
features.8.conv.0 tensor(0.1940)
features.8.conv.3 tensor(0.5356)
features.8.conv.6 tensor(0.1596)
features.9.conv.0 tensor(0.2920)
features.9.conv.3 tensor(0.5660)
features.9.conv.6 tensor(0.1470)
features.10.conv.0 tensor(0.0661)
features.10.conv.3 tensor(0.1050)
features.10.conv.6 tensor(0.1029)
features.11.conv.0 tensor(0.6904)
features.11.conv.3 tensor(0.6458)
features.11.conv.6 tensor(0.8342)
features.12.conv.0 tensor(0.6399)
features.12.conv.3 tensor(0.6717)
features.12.conv.6 tensor(0.1681)
features.13.conv.0 tensor(0.2413)
features.13.conv.3 tensor(0.4904)
features.13.conv.6 tensor(0.0949)
features.14.conv.0 tensor(0.8374)
features.14.conv.3 tensor(0.8176)
features.14.conv.6 tensor(0.1716)
features.15.conv.0 tensor(0.7995)
features.15.conv.3 tensor(0.8257)
features.15.conv.6 tensor(0.7497)
features.16.conv.0 tensor(0.6441)
features.16.conv.3 tensor(0.7880)
features.16.conv.6 tensor(0.0664)
INFO - Validation [5][   40/   40]   Loss 0.451236   Top1 84.690000   Top5 99.380000   BatchTime 0.089153
INFO - ==> Top1: 84.690    Top5: 99.380    Loss: 0.451
INFO - ==> Sparsity : 0.357
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 84.690   Top5: 99.380]
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 81.130   Top5: 99.040]
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 81.110   Top5: 99.300]
conv.0 tensor(0.0912)
tensor(782037.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
0.79664403
tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
0.79648966
tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
0.79663235
tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
0.79666418
tensor(0.4584, device='cuda:0', grad_fn=<AddBackward0>)
0.79669368
tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
0.79649681
tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
0.79651356
tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
0.79631358
tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
0.79614389
tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)
0.79594153
tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
0.79613602
tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)
0.79574430
tensor(0.4674, device='cuda:0', grad_fn=<AddBackward0>)
0.79551023
tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
0.79549563
tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
0.79575908
tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>)
0.79591256
tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
0.79587686
tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)
0.79581982
tensor(0.4482, device='cuda:0', grad_fn=<AddBackward0>)
0.79598534
tensor(0.4101, device='cuda:0', grad_fn=<AddBackward0>)
0.79566151
tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
0.79571491
tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>)
0.79563689
tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>)
0.79557222
tensor(0.4621, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [6][   20/  196]   Loss 0.382094   Top1 87.324219   Top5 99.433594   BatchTime 0.318703   LR 0.000166
0.79549205
tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
0.79558551
tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)
0.79552710
tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
0.79562616
tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>)
0.79576927
tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)
0.79559886
tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
0.79543304
tensor(0.4075, device='cuda:0', grad_fn=<AddBackward0>)
0.79398656
tensor(0.4248, device='cuda:0', grad_fn=<AddBackward0>)
0.79364115
tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
0.79343450
tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
0.79331386
tensor(0.4402, device='cuda:0', grad_fn=<AddBackward0>)
0.79334193
tensor(0.4501, device='cuda:0', grad_fn=<AddBackward0>)
0.79343468
tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
0.79333651
tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
0.79305768
tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
0.79306024
tensor(0.4592, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [6][   40/  196]   Loss 0.392833   Top1 86.582031   Top5 99.521484   BatchTime 0.284848   LR 0.000158
0.79308343
tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
0.79449570
tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
0.79529709
tensor(0.4384, device='cuda:0', grad_fn=<AddBackward0>)
0.79537082
tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>)
0.79529738
tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>)
0.79504836
tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)
0.79497111
tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
0.79499584
tensor(0.5026, device='cuda:0', grad_fn=<AddBackward0>)
0.79508448
tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
0.79533726
tensor(0.4364, device='cuda:0', grad_fn=<AddBackward0>)
0.79504538
tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>)
0.79486400
tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
0.79471993
tensor(0.4080, device='cuda:0', grad_fn=<AddBackward0>)
0.79467189
tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)
0.79462773
tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
0.79465556
tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
0.79459393
tensor(0.4046, device='cuda:0', grad_fn=<AddBackward0>)
0.79492795
tensor(0.3843, device='cuda:0', grad_fn=<AddBackward0>)
0.79500461
tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)
0.79478645
tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
0.79479247
tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
0.79451460
tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
0.79421645
tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
0.79431480
tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)
0.79412848
tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [6][   60/  196]   Loss 0.393510   Top1 86.705729   Top5 99.563802   BatchTime 0.272992   LR 0.000151
0.79413831
tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
0.79416043
tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>)
0.79421836
tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
0.79409689
tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>)
0.79374868
tensor(0.4729, device='cuda:0', grad_fn=<AddBackward0>)
0.79368240
tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
0.79342359
tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
0.79291320
tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
0.79177105
tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)
0.79135859
tensor(0.4602, device='cuda:0', grad_fn=<AddBackward0>)
0.79109573
tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
0.79058564
tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
0.78963524
tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
0.78850633
tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>)
0.78691864
tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)
0.78503764
tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [6][   80/  196]   Loss 0.390621   Top1 86.889648   Top5 99.541016   BatchTime 0.267408   LR 0.000143
0.78360134
tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
0.78177333
tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
0.78037602
tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
0.77930534
tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
0.77772939
tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
0.77701330
tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
0.77699584
tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)
0.77669579
tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)
0.77627486
tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
0.77574652
tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
0.77553248
tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
0.77543980
tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>)
0.77502173
tensor(0.4491, device='cuda:0', grad_fn=<AddBackward0>)
0.77482831
tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
0.77473909
tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
0.77439135
tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
0.77401650
tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
0.77405304
tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
0.77391952
tensor(0.4910, device='cuda:0', grad_fn=<AddBackward0>)
0.77389145
tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>)
0.77363497
tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
0.77357876
tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
0.77343953
tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [6][  100/  196]   Loss 0.386981   Top1 86.964844   Top5 99.566406   BatchTime 0.265025   LR 0.000136
0.77336019
tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
0.77325577
tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
0.77271891
tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
0.77201921
tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
0.77179730
tensor(0.4888, device='cuda:0', grad_fn=<AddBackward0>)
0.77170020
tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
0.77150232
tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
0.77136064
tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
0.77147144
tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)
0.77123606
tensor(0.4909, device='cuda:0', grad_fn=<AddBackward0>)
0.77127373
tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
0.77109039
tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
0.77112222
tensor(0.4216, device='cuda:0', grad_fn=<AddBackward0>)
0.77114171
tensor(0.4251, device='cuda:0', grad_fn=<AddBackward0>)
0.77083915
tensor(0.4488, device='cuda:0', grad_fn=<AddBackward0>)
0.77073723
tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
0.77074063
tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [6][  120/  196]   Loss 0.384838   Top1 87.060547   Top5 99.563802   BatchTime 0.261519   LR 0.000129
0.77059752
tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)
0.77056324
tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)
0.77073252
tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)
0.77071661
tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)
0.77036870
tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
0.77022928
tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
0.77032071
tensor(0.4242, device='cuda:0', grad_fn=<AddBackward0>)
0.77053869
tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
0.77093190
tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
0.77066207
tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
0.77029300
tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
0.76990151
tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
0.76980299
tensor(0.4525, device='cuda:0', grad_fn=<AddBackward0>)
0.76977867
tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)
0.76970154
tensor(0.4249, device='cuda:0', grad_fn=<AddBackward0>)
0.76930225
tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
0.76936316
tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
0.76907361
tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>)
0.76885635
tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
0.76880974
tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>)
0.76889229
tensor(0.4474, device='cuda:0', grad_fn=<AddBackward0>)
0.76834649
tensor(0.4037, device='cuda:0', grad_fn=<AddBackward0>)
0.76814026
tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [6][  140/  196]   Loss 0.383115   Top1 87.117746   Top5 99.559152   BatchTime 0.260522   LR 0.000122
0.76782519
tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
0.76771927
tensor(0.4163, device='cuda:0', grad_fn=<AddBackward0>)
0.76757491
tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
0.76739824
tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>)
0.76745808
tensor(0.4443, device='cuda:0', grad_fn=<AddBackward0>)
0.76737130
tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>)
0.76716989
tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
0.76716381
tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
0.76718152
tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
0.76720554
tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
0.76702064
tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
0.76737088
tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
0.76744395
tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
0.76742250
tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
0.76707703
tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
0.76705921
tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
0.76699400
tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [6][  160/  196]   Loss 0.381759   Top1 87.153320   Top5 99.555664   BatchTime 0.259019   LR 0.000115
0.76684177
tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>)
0.76686478
tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
0.76684445
tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
0.76667553
tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
0.76695174
tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
0.76707590
tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
0.76711631
tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
0.76751053
tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
0.76704788
tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
0.76669580
tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
0.76637626
tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
0.76626706
tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
0.76588845
tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
0.76568490
tensor(0.3378, device='cuda:0', grad_fn=<AddBackward0>)
0.76549250
tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
0.76546711
tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
0.76517200
tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)
0.76515961
tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
0.76516151
tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
0.76514930
tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
0.76507533
tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
0.76458335
tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
0.76415211
tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
0.76373428
tensor(0.3249, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [6][  180/  196]   Loss 0.378380   Top1 87.269965   Top5 99.578993   BatchTime 0.257800   LR 0.000108
0.76343393
tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
0.76334965
tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
0.76315969
tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
0.76297951
tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
0.76292789
tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
0.76272899
tensor(0.4509, device='cuda:0', grad_fn=<AddBackward0>)
0.76276129
tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>)
0.76289976
tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
0.76267868
tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
0.76238990
tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
0.76204097
tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
0.76187742
tensor(0.5473, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 87.302    Top5: 99.572    Loss: 0.377
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [6][   20/   40]   Loss 0.428717   Top1 85.390625   Top5 99.257812   BatchTime 0.116045
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1484)
features.1.conv.0 tensor(0.0612)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0768)
features.2.conv.0 tensor(0.0689)
features.2.conv.3 tensor(0.3472)
features.2.conv.6 tensor(0.1843)
features.3.conv.0 tensor(0.0608)
features.3.conv.3 tensor(0.0957)
features.3.conv.6 tensor(0.1213)
features.4.conv.0 tensor(0.0692)
features.4.conv.3 tensor(0.3015)
features.4.conv.6 tensor(0.1880)
features.5.conv.0 tensor(0.3416)
features.5.conv.3 tensor(0.4236)
features.5.conv.6 tensor(0.1069)
features.6.conv.0 tensor(0.0615)
features.6.conv.3 tensor(0.0550)
features.6.conv.6 tensor(0.0853)
features.7.conv.0 tensor(0.2281)
features.7.conv.3 tensor(0.4560)
features.7.conv.6 tensor(0.2030)
features.8.conv.0 tensor(0.2313)
features.8.conv.3 tensor(0.5359)
features.8.conv.6 tensor(0.1554)
features.9.conv.0 tensor(0.2903)
features.9.conv.3 tensor(0.5680)
features.9.conv.6 tensor(0.1491)
features.10.conv.0 tensor(0.0708)
features.10.conv.3 tensor(0.1013)
features.10.conv.6 tensor(0.1031)
features.11.conv.0 tensor(0.7217)
features.11.conv.3 tensor(0.6447)
features.11.conv.6 tensor(0.8407)
features.12.conv.0 tensor(0.6728)
features.12.conv.3 tensor(0.6705)
features.12.conv.6 tensor(0.1740)
features.13.conv.0 tensor(0.2534)
features.13.conv.3 tensor(0.4890)
features.13.conv.6 tensor(0.0941)
features.14.conv.0 tensor(0.8381)
features.14.conv.3 tensor(0.8170)
features.14.conv.6 tensor(0.7009)
features.15.conv.0 tensor(0.8102)
features.15.conv.3 tensor(0.8257)
features.15.conv.6 tensor(0.8658)
features.16.conv.0 tensor(0.6592)
features.16.conv.3 tensor(0.7880)
features.16.conv.6 tensor(0.0721)
INFO - Validation [6][   40/   40]   Loss 0.423263   Top1 86.060000   Top5 99.360000   BatchTime 0.086465
INFO - ==> Top1: 86.060    Top5: 99.360    Loss: 0.423
INFO - ==> Sparsity : 0.408
INFO - Scoreboard best 1 ==> Epoch [6][Top1: 86.060   Top5: 99.360]
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 84.690   Top5: 99.380]
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 81.130   Top5: 99.040]
conv.0 tensor(0.0910)
tensor(892774.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
0.76193935
tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
0.76198566
tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
0.76194382
tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)
0.76171452
tensor(0.4428, device='cuda:0', grad_fn=<AddBackward0>)
0.76161587
tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
0.76159751
tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)
0.76112992
tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>)
0.76083612
tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
0.76078594
tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
0.76078415
tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
0.76050556
tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
0.76019508
tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
0.76018423
tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
0.76029587
tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
0.76032621
tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>)
0.75992948
tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
0.75966156
tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>)
0.75932986
tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)
0.75933558
tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
0.75914013
tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>)
0.75886267
tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
0.75860417
tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [7][   20/  196]   Loss 0.337821   Top1 88.457031   Top5 99.589844   BatchTime 0.329215   LR 0.000097
0.75836128
tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
0.75844145
tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>)
0.75805509
tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
0.75792569
tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
0.75810671
tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
0.75802422
tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>)
0.75836432
tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
0.75852674
tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
0.75841302
tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>)
0.75819135
tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
0.75829965
tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
0.75785846
tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
0.75749606
tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
0.75727105
tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
0.75725472
tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
0.75707746
tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [7][   40/  196]   Loss 0.335983   Top1 88.642578   Top5 99.599609   BatchTime 0.291740   LR 0.000091
0.75672990
tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
0.75686467
tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
0.75716639
tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
0.75713128
tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
0.75727135
tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
0.75764048
tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
0.75750303
tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
0.75714403
tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
0.75700086
tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
0.75680697
tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
0.75668418
tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
0.75658494
tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
0.75658864
tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)
0.75656921
tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
0.75628269
tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
0.75617015
tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)
0.75622761
tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)
0.75628281
tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
0.75602657
tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
0.75602013
tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>)
0.75601131
tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
0.75625181
tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)
0.75649297
tensor(0.4644, device='cuda:0', grad_fn=<AddBackward0>)
0.75658494
tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [7][   60/  196]   Loss 0.338439   Top1 88.723958   Top5 99.557292   BatchTime 0.278275   LR 0.000085
0.75669819
tensor(0.4575, device='cuda:0', grad_fn=<AddBackward0>)
0.75657904
tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
0.75647074
tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
0.75618839
tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
0.75604707
tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)
0.75589252
tensor(0.2902, device='cuda:0', grad_fn=<AddBackward0>)
0.75593746
tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
0.75603640
tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
0.75587946
tensor(0.4234, device='cuda:0', grad_fn=<AddBackward0>)
0.75565010
tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
0.75518757
tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)
0.75447643
tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
0.75444269
tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
0.75432259
tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
0.75430667
tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
0.75383598
tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [7][   80/  196]   Loss 0.342796   Top1 88.696289   Top5 99.560547   BatchTime 0.272583   LR 0.000079
0.75376785
tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
0.75371015
tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)
0.75365061
tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
0.75360590
tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
0.75355595
tensor(0.4131, device='cuda:0', grad_fn=<AddBackward0>)
0.75339496
tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>)
0.75340867
tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)
0.75356549
tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
0.75360364
tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
0.75361562
tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
0.75351614
tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
0.75335461
tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
0.75338620
tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
0.75343490
tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
0.75370586
tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
0.75376749
tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
0.75348043
tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
0.75308019
tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
0.75282174
tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>)
0.75264549
tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
0.75251746
tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
0.75224179
tensor(0.4611, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [7][  100/  196]   Loss 0.344532   Top1 88.511719   Top5 99.558594   BatchTime 0.272163   LR 0.000073
0.75205052
tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
0.75183600
tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
0.75153923
tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
0.75134456
tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
0.75125813
tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
0.75110942
tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
0.75078326
tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
0.75067377
tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
0.75057513
tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
0.75016910
tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
0.74969035
tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
0.74936116
tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
0.74916798
tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
0.74890578
tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
0.74864048
tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
0.74854463
tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>)
0.74825138
tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)
0.74802023
tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
0.74758923
tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
0.74729550
tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>)
0.74712068
tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)
0.74688935
tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [7][  120/  196]   Loss 0.340954   Top1 88.548177   Top5 99.596354   BatchTime 0.271439   LR 0.000067
0.74656111
tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
0.74647480
tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
0.74657911
tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)
0.74643075
tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
0.74628401
tensor(0.2870, device='cuda:0', grad_fn=<AddBackward0>)
0.74591482
tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
0.74557263
tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
0.74551958
tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
0.74552727
tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)
0.74522257
tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>)
0.74493533
tensor(0.4421, device='cuda:0', grad_fn=<AddBackward0>)
0.74465197
tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>)
0.74447429
tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
0.74435729
tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
0.74409795
tensor(0.4581, device='cuda:0', grad_fn=<AddBackward0>)
0.74373990
tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)
0.74341279
INFO - Training [7][  140/  196]   Loss 0.341997   Top1 88.546317   Top5 99.575893   BatchTime 0.268528   LR 0.000062
tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>)
0.74299675
tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
0.74269587
tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
0.74258876
tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>)
0.74237341
tensor(0.4362, device='cuda:0', grad_fn=<AddBackward0>)
0.74222082
tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
0.74202937
tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
0.74166983
tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
0.74163818
tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>)
0.74139917
tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
0.74123722
tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
0.74104446
tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
0.74087650
tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
0.74073970
tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
0.74040759
tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
0.74016178
tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
0.74043173
tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
0.74011761
tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
0.73965526
tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
0.73982149
tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
0.73988205
tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
0.74002773
tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>)
0.73944682
tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)
0.73920363
tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
0.73889607
tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [7][  160/  196]   Loss 0.340813   Top1 88.547363   Top5 99.589844   BatchTime 0.266278   LR 0.000057
0.73863322
tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
0.73857737
tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
0.73857319
tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
0.73847210
tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
0.73829752
tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
0.73809159
tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
0.73810893
tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
0.73822272
tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>)
0.73802453
tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>)
0.73768449
tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)
0.73759043
tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
0.73745006
tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
0.73736179
tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
0.73739576
tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>)
0.73725754
tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
0.73720938
tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [7][  180/  196]   Loss 0.339689   Top1 88.565538   Top5 99.602865   BatchTime 0.264506   LR 0.000052
0.73741174
tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
0.73719680
tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
0.73689568
tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
0.73665673
tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
0.73644817
tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>)
0.73614788
tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>)
0.73568672
tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>)
0.73485780
tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
0.73448074
tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
0.73432744
tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
0.73439831
tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
0.73450446
tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
0.73470265
tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
0.73418528
tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
0.73414373
tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
0.73415905
tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 88.634    Top5: 99.624    Loss: 0.337
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.73435009
tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 0.418761   Top1 86.093750   Top5 99.316406   BatchTime 0.113815
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1445)
features.1.conv.0 tensor(0.0560)
features.1.conv.3 tensor(0.0741)
features.1.conv.6 tensor(0.0799)
features.2.conv.0 tensor(0.0796)
features.2.conv.3 tensor(0.3457)
features.2.conv.6 tensor(0.1811)
features.3.conv.0 tensor(0.0648)
features.3.conv.3 tensor(0.0895)
features.3.conv.6 tensor(0.1159)
features.4.conv.0 tensor(0.0654)
features.4.conv.3 tensor(0.2998)
features.4.conv.6 tensor(0.1886)
features.5.conv.0 tensor(0.3594)
features.5.conv.3 tensor(0.4230)
features.5.conv.6 tensor(0.1060)
features.6.conv.0 tensor(0.0651)
features.6.conv.3 tensor(0.0567)
features.6.conv.6 tensor(0.0852)
features.7.conv.0 tensor(0.2350)
features.7.conv.3 tensor(0.4552)
features.7.conv.6 tensor(0.2004)
features.8.conv.0 tensor(0.2768)
features.8.conv.3 tensor(0.5353)
features.8.conv.6 tensor(0.1578)
features.9.conv.0 tensor(0.3216)
features.9.conv.3 tensor(0.5671)
features.9.conv.6 tensor(0.1509)
features.10.conv.0 tensor(0.0688)
features.10.conv.3 tensor(0.1045)
features.10.conv.6 tensor(0.1035)
features.11.conv.0 tensor(0.7273)
features.11.conv.3 tensor(0.6451)
features.11.conv.6 tensor(0.8417)
features.12.conv.0 tensor(0.6939)
features.12.conv.3 tensor(0.6709)
features.12.conv.6 tensor(0.1661)
features.13.conv.0 tensor(0.2684)
features.13.conv.3 tensor(0.4871)
features.13.conv.6 tensor(0.0939)
features.14.conv.0 tensor(0.8429)
features.14.conv.3 tensor(0.8167)
features.14.conv.6 tensor(0.8367)
features.15.conv.0 tensor(0.8198)
features.15.conv.3 tensor(0.8258)
features.15.conv.6 tensor(0.8905)
features.16.conv.0 tensor(0.6760)
features.16.conv.3 tensor(0.7877)
features.16.conv.6 tensor(0.4856)
conv.0 tensor(0.0903)
tensor(1052988.) 2188896.0
INFO - Validation [7][   40/   40]   Loss 0.408278   Top1 86.240000   Top5 99.480000   BatchTime 0.085779
INFO - ==> Top1: 86.240    Top5: 99.480    Loss: 0.408
INFO - ==> Sparsity : 0.481
INFO - Scoreboard best 1 ==> Epoch [7][Top1: 86.240   Top5: 99.480]
INFO - Scoreboard best 2 ==> Epoch [6][Top1: 86.060   Top5: 99.360]
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 84.690   Top5: 99.380]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
0.73419839
tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)
0.73426998
tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
0.73422062
tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
0.73395807
tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
0.73389167
tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
0.73360461
tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
0.73334175
tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
0.73331589
tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
0.73330367
tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
0.73302841
tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
0.73301989
tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
0.73299801
tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
0.73297721
tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
0.73316330
tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
0.73282439
tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
0.73268813
tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [8][   20/  196]   Loss 0.301120   Top1 90.078125   Top5 99.765625   BatchTime 0.319239   LR 0.000043
0.73271197
tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>)
0.73267645
tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
0.73251861
tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
0.73233700
tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
0.73228121
tensor(0.4169, device='cuda:0', grad_fn=<AddBackward0>)
0.73225743
tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)
0.73232049
tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
0.73214340
tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
0.73183787
tensor(0.4030, device='cuda:0', grad_fn=<AddBackward0>)
0.73183036
tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)
0.73179013
tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
0.73152959
tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
0.73151016
tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
0.73137969
tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
0.73125172
tensor(0.4589, device='cuda:0', grad_fn=<AddBackward0>)
0.73110312
tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
0.73111802
tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)
0.73129630
tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
0.73136407
tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
0.73143744
tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
0.73144549
tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
0.73143834
tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
0.73136634
tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [8][   40/  196]   Loss 0.321421   Top1 89.414062   Top5 99.726562   BatchTime 0.293950   LR 0.000039
0.73125076
tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
0.73095566
tensor(0.4330, device='cuda:0', grad_fn=<AddBackward0>)
0.73090011
tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
0.73088986
tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
0.73065466
tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
0.73060286
tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
0.73044777
tensor(0.4359, device='cuda:0', grad_fn=<AddBackward0>)
0.73060369
tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
0.73062140
tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
0.73027551
tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
0.73020023
tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
0.73028356
tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)
0.73032624
tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
0.73026299
tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
0.73041111
tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)
0.73059249
tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)
0.73036534
tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
0.73029834
tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
0.73033571
tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
0.73051453
tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [8][   60/  196]   Loss 0.323679   Top1 89.342448   Top5 99.700521   BatchTime 0.294639   LR 0.000035
0.73025376
tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
0.72977424
tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
0.72972673
tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
0.72987688
tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
0.72968912
tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
0.72985917
tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
0.72997820
tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
0.72976661
tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
0.72986901
tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
0.72965074
tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
0.72964489
tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)
0.72955674
tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)
0.72979212
tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
0.72957188
tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
0.72942352
tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)
0.72951239
tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>)
0.72955513
tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
0.72964251
tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
0.72944373
tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>)
0.72916013
tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
0.72928137
tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
0.72928542
tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [8][   80/  196]   Loss 0.320966   Top1 89.350586   Top5 99.682617   BatchTime 0.290336   LR 0.000031
0.72939086
tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
0.72934234
tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
0.72927165
tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
0.72926283
tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
0.72921377
tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
0.72909755
tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
0.72836429
tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
0.72772920
tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
0.72764003
tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)
0.72778183
tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
0.72804290
tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
0.72771317
tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
0.72730231
tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
0.72700775
tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
0.72682387
tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
0.72676402
tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [8][  100/  196]   Loss 0.318618   Top1 89.359375   Top5 99.703125   BatchTime 0.282981   LR 0.000027
0.72678721
tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
0.72654688
tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
0.72659272
tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
0.72662163
tensor(0.3068, device='cuda:0', grad_fn=<AddBackward0>)
0.72672641
tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
0.72658408
tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
0.72647882
tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
0.72657979
tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
0.72667366
tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
0.72662216
tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
0.72659349
tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
0.72657061
tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
0.72644639
tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
0.72641224
tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
0.72630692
tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
0.72580135
tensor(0.4022, device='cuda:0', grad_fn=<AddBackward0>)
0.72523332
tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
0.72493619
tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
0.72493178
tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
0.72486418
tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
0.72506928
tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
0.72529590
tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
0.72537881
tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
0.72548735
tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [8][  120/  196]   Loss 0.315260   Top1 89.436849   Top5 99.707031   BatchTime 0.277813   LR 0.000023
0.72558838
tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
0.72529781
tensor(0.4251, device='cuda:0', grad_fn=<AddBackward0>)
0.72491211
tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)
0.72495836
tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
0.72486246
tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
0.72464877
tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
0.72461748
tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
0.72474849
tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
0.72479218
tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
0.72460055
tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
0.72450572
tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)
0.72479755
tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
0.72484291
tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)
0.72478354
tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)
0.72463632
tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
0.72454041
tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [8][  140/  196]   Loss 0.316574   Top1 89.433594   Top5 99.701451   BatchTime 0.273687   LR 0.000020
0.72456908
tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)
0.72443628
tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
0.72451603
tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
0.72472394
tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
0.72478575
tensor(0.3771, device='cuda:0', grad_fn=<AddBackward0>)
0.72459078
tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
0.72412038
tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
0.72380590
tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
0.72361332
tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
0.72369128
tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
0.72369307
tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
0.72363812
tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
0.72348744
tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>)
0.72379857
tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
0.72395605
tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>)
0.72359747
tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
0.72335726
tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
0.72250617
tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
0.72202069
tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
0.72186458
tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)
0.72178179
tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
0.72189593
tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)
0.72203130
tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
0.72182912
tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [8][  160/  196]   Loss 0.314457   Top1 89.477539   Top5 99.704590   BatchTime 0.270608   LR 0.000017
0.72163123
tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
0.72193158
tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>)
0.72200704
tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
0.72190481
tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
0.72185808
tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>)
0.72198951
tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
0.72207391
tensor(0.4206, device='cuda:0', grad_fn=<AddBackward0>)
0.72149903
tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)
0.72155255
tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
0.72138178
tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
0.72142559
tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
0.72120529
tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
0.72113997
tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>)
0.72116649
tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
0.72103626
tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
0.72092110
tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)
0.72080183
tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [8][  180/  196]   Loss 0.314434   Top1 89.485677   Top5 99.696181   BatchTime 0.267204   LR 0.000014
0.72075677
tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
0.72081250
tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>)
0.72073174
tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>)
0.72080946
tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
0.72064078
tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
0.72085381
tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
0.72105169
tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
0.72103590
tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
0.72077727
tensor(0.2896, device='cuda:0', grad_fn=<AddBackward0>)
0.72065932
tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
0.72053707
tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
0.72046447
tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
0.72030258
tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
0.72037613
tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
0.71998072
tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
0.71980578
tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 89.544    Top5: 99.704    Loss: 0.313
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.71980375
tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
0.71961606
tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 0.397254   Top1 86.367188   Top5 99.316406   BatchTime 0.122469
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1582)
features.1.conv.0 tensor(0.0534)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0786)
features.2.conv.0 tensor(0.0900)
features.2.conv.3 tensor(0.3465)
features.2.conv.6 tensor(0.1918)
features.3.conv.0 tensor(0.0677)
features.3.conv.3 tensor(0.0856)
features.3.conv.6 tensor(0.1172)
features.4.conv.0 tensor(0.0674)
features.4.conv.3 tensor(0.3003)
features.4.conv.6 tensor(0.1896)
features.5.conv.0 tensor(0.3913)
features.5.conv.3 tensor(0.4259)
features.5.conv.6 tensor(0.1063)
features.6.conv.0 tensor(0.0612)
features.6.conv.3 tensor(0.0590)
features.6.conv.6 tensor(0.0854)
features.7.conv.0 tensor(0.2355)
features.7.conv.3 tensor(0.4557)
features.7.conv.6 tensor(0.2010)
features.8.conv.0 tensor(0.2904)
features.8.conv.3 tensor(0.5336)
features.8.conv.6 tensor(0.1801)
features.9.conv.0 tensor(0.3397)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.1494)
features.10.conv.0 tensor(0.0680)
features.10.conv.3 tensor(0.1047)
features.10.conv.6 tensor(0.1032)
features.11.conv.0 tensor(0.7390)
features.11.conv.3 tensor(0.6439)
features.11.conv.6 tensor(0.8443)
features.12.conv.0 tensor(0.7092)
features.12.conv.3 tensor(0.6698)
features.12.conv.6 tensor(0.2548)
features.13.conv.0 tensor(0.2668)
features.13.conv.3 tensor(0.4878)
features.13.conv.6 tensor(0.0937)
features.14.conv.0 tensor(0.8464)
features.14.conv.3 tensor(0.8172)
features.14.conv.6 tensor(0.8671)
features.15.conv.0 tensor(0.8229)
features.15.conv.3 tensor(0.8256)
features.15.conv.6 tensor(0.9004)
features.16.conv.0 tensor(0.6849)
features.16.conv.3 tensor(0.7878)
features.16.conv.6 tensor(0.6172)
conv.0 tensor(0.0898)
tensor(1109806.) 2188896.0
INFO - Validation [8][   40/   40]   Loss 0.386081   Top1 86.780000   Top5 99.490000   BatchTime 0.090870
INFO - ==> Top1: 86.780    Top5: 99.490    Loss: 0.386
INFO - ==> Sparsity : 0.507
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 86.240   Top5: 99.480]
INFO - Scoreboard best 3 ==> Epoch [6][Top1: 86.060   Top5: 99.360]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
0.71964413
tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
0.71965790
tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
0.71974385
tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
0.71969187
tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
0.71963167
tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
0.71970326
tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
0.71958971
tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>)
0.71966350
tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
0.71974021
tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>)
0.71961236
tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
0.71960884
tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
0.71948290
tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
0.71951038
tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
0.71956998
tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
0.71940094
tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
0.71927530
tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
0.71906865
tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
0.71895802
tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
0.71848285
tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
0.71805024
tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
0.71761662
tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)
0.71738136
tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
0.71650302
tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [9][   20/  196]   Loss 0.291597   Top1 90.351562   Top5 99.726562   BatchTime 0.341868   LR 0.000010
0.71655631
tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
0.71614563
tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
0.71592796
tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
0.71568739
tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>)
0.71543515
tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>)
0.71523237
tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
0.71520013
tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)
0.71531183
tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
0.71506125
tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
0.71496713
tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)
0.71490985
tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
0.71500456
tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>)
0.71494043
tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
0.71503550
tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
0.71505129
tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [9][   40/  196]   Loss 0.295753   Top1 89.951172   Top5 99.775391   BatchTime 0.306193   LR 0.000008
0.71512508
tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
0.71495903
tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
0.71495551
tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
0.71476024
tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
0.71464682
tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>)
0.71458268
tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
0.71458626
tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
0.71446949
tensor(0.3000, device='cuda:0', grad_fn=<AddBackward0>)
0.71457261
tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)
0.71453935
tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
0.71437746
tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
0.71405590
tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
0.71348774
tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)
0.71310490
tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
0.71308219
tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
0.71326309
tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
0.71315366
tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
0.71308351
tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
0.71295023
tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
0.71270996
tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>)
0.71274179
tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)
0.71284533
tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [9][   60/  196]   Loss 0.300268   Top1 89.759115   Top5 99.694010   BatchTime 0.294071   LR 0.000006
0.71291339
tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
0.71291125
tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
0.71276450
tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
0.71267444
tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
0.71289814
tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)
0.71297568
tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
0.71281523
tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
0.71284676
tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
0.71271771
tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
0.71250802
tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
0.71238047
tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)
0.71214300
tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
0.71134782
tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
0.71119934
tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
0.71112341
tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
0.71115315
tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [9][   80/  196]   Loss 0.298813   Top1 89.877930   Top5 99.692383   BatchTime 0.283640   LR 0.000004
0.71128792
tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
0.71125948
tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>)
0.71105665
tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)
0.71090072
tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)
0.71088469
tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>)
0.71099114
tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
0.71107811
tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
0.71102995
tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)
0.71115154
tensor(0.2947, device='cuda:0', grad_fn=<AddBackward0>)
0.71115822
tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
0.71115506
tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
0.71098608
tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
0.71089590
tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
0.71078855
tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
0.71070892
tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
0.71063137
tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
0.71055615
tensor(0.3903, device='cuda:0', grad_fn=<AddBackward0>)
0.71061349
tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
0.71064830
tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)
0.71083325
tensor(0.4628, device='cuda:0', grad_fn=<AddBackward0>)
0.71097922
tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
0.71109235
tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
0.71097642
tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
0.71068233
tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
0.71061283
tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [9][  100/  196]   Loss 0.304124   Top1 89.710938   Top5 99.671875   BatchTime 0.275977   LR 0.000003
0.71052587
tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
0.71051353
tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
0.71061379
tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
0.71071732
tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
0.71078014
tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
0.71068436
tensor(0.2945, device='cuda:0', grad_fn=<AddBackward0>)
0.71075922
tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
0.71066272
tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
0.71054226
tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
0.71051115
tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
0.71034014
tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
0.71036154
tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
0.71045524
tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
0.71047360
tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
0.71058160
tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [9][  120/  196]   Loss 0.301528   Top1 89.833984   Top5 99.694010   BatchTime 0.273865   LR 0.000002
0.71058035
tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
0.71049255
tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
0.71054739
tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
0.71045911
tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
0.71035856
tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
0.71050888
tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>)
0.71052092
tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
0.71052969
tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
0.71071368
tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
0.71062404
tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)
0.71054691
tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
0.71054840
tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
0.71062875
tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
0.71047223
tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)
0.71045607
tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
0.71055579
tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
0.71041006
tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
0.71028614
tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
0.71020263
tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
0.70999897
tensor(0.4323, device='cuda:0', grad_fn=<AddBackward0>)
0.70993447
tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [9][  140/  196]   Loss 0.300870   Top1 89.863281   Top5 99.701451   BatchTime 0.276411   LR 0.000001
0.70966125
tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
0.70925510
tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
0.70899087
tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
0.70900589
tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
0.70917553
tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
0.70912522
tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
0.70907414
tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>)
0.70891839
tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
0.70884186
tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)
0.70886356
tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)
0.70882237
tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
0.70874196
tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
0.70879006
tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
0.70865607
tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
0.70864195
tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
0.70859671
tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
0.70842135
tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
0.70818216
tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>)
0.70786464
tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
0.70793390
tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
0.70791447
tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
0.70772177
tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
0.70758778
tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [9][  160/  196]   Loss 0.303031   Top1 89.819336   Top5 99.704590   BatchTime 0.274103   LR 0.000000
0.70729691
tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
0.70711380
tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
0.70693231
tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
0.70668435
tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)
0.70635009
tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
0.70606387
tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
0.70599794
tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
0.70595688
tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
0.70590198
tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
0.70582289
tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
0.70581079
tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
0.70579463
tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)
0.70579016
tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
0.70581180
tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)
0.70588404
tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
0.70613062
tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
0.70628840
tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [9][  180/  196]   Loss 0.304022   Top1 89.774306   Top5 99.711372   BatchTime 0.269964   LR 0.000000
0.70613998
tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)
0.70594597
tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
0.70588046
tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
0.70577395
tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>)
0.70570385
tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
0.70564938
tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
0.70560294
tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
0.70557493
tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)
0.70555627
tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
0.70554489
tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
0.70553917
tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
0.70552927
tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
0.70552421
tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
0.70552182
tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
0.70551723
tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
0.70544648
tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 89.764    Top5: 99.708    Loss: 0.304
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.70538676
tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
0.70535225
tensor(0.4063, device='cuda:0', grad_fn=<AddBackward0>)
0.70532936
tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [9][   20/   40]   Loss 0.406135   Top1 86.679688   Top5 99.414062   BatchTime 0.128187
INFO - Validation [9][   40/   40]   Loss 0.396543   Top1 86.710000   Top5 99.510000   BatchTime 0.094016
INFO - ==> Top1: 86.710    Top5: 99.510    Loss: 0.397
INFO - ==> Sparsity : 0.514
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.240   Top5: 99.480]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1621)
features.1.conv.0 tensor(0.0527)
features.1.conv.3 tensor(0.0752)
features.1.conv.6 tensor(0.0794)
features.2.conv.0 tensor(0.0903)
features.2.conv.3 tensor(0.3472)
features.2.conv.6 tensor(0.1968)
features.3.conv.0 tensor(0.0671)
features.3.conv.3 tensor(0.0841)
features.3.conv.6 tensor(0.1200)
features.4.conv.0 tensor(0.0671)
features.4.conv.3 tensor(0.2998)
features.4.conv.6 tensor(0.1896)
features.5.conv.0 tensor(0.3939)
features.5.conv.3 tensor(0.4259)
features.5.conv.6 tensor(0.1064)
features.6.conv.0 tensor(0.0622)
features.6.conv.3 tensor(0.0608)
features.6.conv.6 tensor(0.0857)
features.7.conv.0 tensor(0.2357)
features.7.conv.3 tensor(0.4546)
features.7.conv.6 tensor(0.2016)
features.8.conv.0 tensor(0.2930)
features.8.conv.3 tensor(0.5336)
features.8.conv.6 tensor(0.1812)
features.9.conv.0 tensor(0.3426)
features.9.conv.3 tensor(0.5651)
features.9.conv.6 tensor(0.1494)
features.10.conv.0 tensor(0.0681)
features.10.conv.3 tensor(0.1047)
features.10.conv.6 tensor(0.1029)
features.11.conv.0 tensor(0.7396)
features.11.conv.3 tensor(0.6441)
features.11.conv.6 tensor(0.8443)
features.12.conv.0 tensor(0.7115)
features.12.conv.3 tensor(0.6699)
features.12.conv.6 tensor(0.2839)
features.13.conv.0 tensor(0.2686)
features.13.conv.3 tensor(0.4877)
features.13.conv.6 tensor(0.1055)
features.14.conv.0 tensor(0.8467)
features.14.conv.3 tensor(0.8170)
features.14.conv.6 tensor(0.8704)
features.15.conv.0 tensor(0.8226)
features.15.conv.3 tensor(0.8256)
features.15.conv.6 tensor(0.9017)
features.16.conv.0 tensor(0.6882)
features.16.conv.3 tensor(0.7880)
features.16.conv.6 tensor(0.6333)
conv.0 tensor(0.1032)
tensor(1124625.) 2188896.0
0.70532280
tensor(0.2725, device='cuda:0', grad_fn=<AddBackward0>)
0.70993698
tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
0.71016043
tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>)
0.70869738
tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
0.70780832
tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
0.70637244
tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
0.70472068
tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)
0.70245767
tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
0.70009917
tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
0.69729906
tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
0.69516093
tensor(0.4566, device='cuda:0', grad_fn=<AddBackward0>)
0.69356972
tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
0.69217318
tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
0.69075710
tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)
0.69076091
tensor(0.4248, device='cuda:0', grad_fn=<AddBackward0>)
0.69207323
tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
0.69368458
tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)
0.69332248
tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
0.69174743
tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>)
0.69047993
tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
0.68927777
tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)
0.68881899
tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [10][   20/  196]   Loss 0.345394   Top1 88.261719   Top5 99.648438   BatchTime 0.351149   LR 0.000250
0.68981880
tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
0.68934351
tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
0.68866205
tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
0.68882722
tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
0.69061154
tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
0.69073194
tensor(0.3068, device='cuda:0', grad_fn=<AddBackward0>)
0.69060421
tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>)
0.69035578
tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
0.69019336
tensor(0.3007, device='cuda:0', grad_fn=<AddBackward0>)
0.68980461
tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
0.68951213
tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)
0.68976057
tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
0.69005531
tensor(0.5188, device='cuda:0', grad_fn=<AddBackward0>)
0.69106156
tensor(0.4236, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [10][   40/  196]   Loss 0.360811   Top1 87.626953   Top5 99.570312   BatchTime 0.313891   LR 0.000250
0.69086397
tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
0.69054770
tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
0.69081104
tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
0.69121796
tensor(0.4816, device='cuda:0', grad_fn=<AddBackward0>)
0.69137144
tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
0.69194144
tensor(0.4242, device='cuda:0', grad_fn=<AddBackward0>)
0.69249547
tensor(0.4566, device='cuda:0', grad_fn=<AddBackward0>)
0.69300729
tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)
0.69418973
tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
0.69444096
tensor(0.4848, device='cuda:0', grad_fn=<AddBackward0>)
0.69462544
tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
0.69475704
tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
0.69438732
tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
0.69401073
tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
0.69427973
tensor(0.4280, device='cuda:0', grad_fn=<AddBackward0>)
0.69392067
tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
0.69434363
tensor(0.4697, device='cuda:0', grad_fn=<AddBackward0>)
0.69510257
tensor(0.4822, device='cuda:0', grad_fn=<AddBackward0>)
0.69708347
tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
0.70122486
tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
0.71380454
tensor(0.4659, device='cuda:0', grad_fn=<AddBackward0>)
0.71374202
tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
0.71343523
tensor(0.4171, device='cuda:0', grad_fn=<AddBackward0>)
0.71313691
tensor(0.4620, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [10][   60/  196]   Loss 0.376434   Top1 87.018229   Top5 99.557292   BatchTime 0.293022   LR 0.000250
0.71321499
tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
0.71317506
tensor(0.5114, device='cuda:0', grad_fn=<AddBackward0>)
0.71330363
tensor(0.4912, device='cuda:0', grad_fn=<AddBackward0>)
0.71311718
tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
0.71295023
tensor(0.4468, device='cuda:0', grad_fn=<AddBackward0>)
0.71275598
tensor(0.4626, device='cuda:0', grad_fn=<AddBackward0>)
0.71280414
tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)
0.71267509
tensor(0.4362, device='cuda:0', grad_fn=<AddBackward0>)
0.71300071
tensor(0.4208, device='cuda:0', grad_fn=<AddBackward0>)
0.71317255
tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
0.71347910
tensor(0.4460, device='cuda:0', grad_fn=<AddBackward0>)
0.71347010
tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
0.71379089
tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
0.71405786
tensor(0.4242, device='cuda:0', grad_fn=<AddBackward0>)
0.71471173
tensor(0.4519, device='cuda:0', grad_fn=<AddBackward0>)
0.71565783
tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [10][   80/  196]   Loss 0.382600   Top1 86.806641   Top5 99.555664   BatchTime 0.282073   LR 0.000250
0.71651202
tensor(0.4823, device='cuda:0', grad_fn=<AddBackward0>)
0.71765631
tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
0.71907663
tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>)
0.72034097
tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)
0.72122461
tensor(0.4287, device='cuda:0', grad_fn=<AddBackward0>)
0.72172594
tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
0.72181255
tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
0.72173804
tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)
0.72174376
tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>)
0.72165924
tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
0.72146946
tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)
0.72165602
tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)
0.72124749
tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
0.72069627
tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
0.72034502
tensor(0.5071, device='cuda:0', grad_fn=<AddBackward0>)
0.71975571
tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)
0.71882993
tensor(0.5194, device='cuda:0', grad_fn=<AddBackward0>)
0.71821171
tensor(0.3349, device='cuda:0', grad_fn=<AddBackward0>)
0.71767670
tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
0.71693534
tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
0.71649116
tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)
0.71567738
tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
0.71530700
tensor(0.4235, device='cuda:0', grad_fn=<AddBackward0>)
0.71499658
tensor(0.4861, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [10][  100/  196]   Loss 0.386907   Top1 86.679688   Top5 99.527344   BatchTime 0.275647   LR 0.000250
0.71480036
tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>)
0.71427506
tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)
0.71398890
tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>)
0.71387881
tensor(0.4583, device='cuda:0', grad_fn=<AddBackward0>)
0.71354389
tensor(0.4463, device='cuda:0', grad_fn=<AddBackward0>)
0.71354520
tensor(0.4498, device='cuda:0', grad_fn=<AddBackward0>)
0.71370685
tensor(0.4145, device='cuda:0', grad_fn=<AddBackward0>)
0.71610254
tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)
0.71656495
tensor(0.4353, device='cuda:0', grad_fn=<AddBackward0>)
0.71699959
tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
0.71706021
tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
0.71718472
tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)
0.71633071
tensor(0.5771, device='cuda:0', grad_fn=<AddBackward0>)
0.71560597
tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
0.71507418
tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
0.71423960
tensor(0.4960, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [10][  120/  196]   Loss 0.390917   Top1 86.565755   Top5 99.492188   BatchTime 0.271570   LR 0.000249
0.71294212
tensor(0.4712, device='cuda:0', grad_fn=<AddBackward0>)
0.71196860
tensor(0.3631, device='cuda:0', grad_fn=<AddBackward0>)
0.71069002
tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
0.70942473
tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
0.70878142
tensor(0.4563, device='cuda:0', grad_fn=<AddBackward0>)
0.70821720
tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)
0.70774448
tensor(0.4570, device='cuda:0', grad_fn=<AddBackward0>)
0.70729947
tensor(0.4657, device='cuda:0', grad_fn=<AddBackward0>)
0.70672870
tensor(0.4645, device='cuda:0', grad_fn=<AddBackward0>)
0.70636952
tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>)
0.70626628
tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
0.70578724
tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
0.70565856
tensor(0.4719, device='cuda:0', grad_fn=<AddBackward0>)
0.70537591
tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
0.70548689
tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
0.70515501
tensor(0.3972, device='cuda:0', grad_fn=<AddBackward0>)
0.70511657
tensor(0.4347, device='cuda:0', grad_fn=<AddBackward0>)
0.70503771
tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
0.70491189
tensor(0.4269, device='cuda:0', grad_fn=<AddBackward0>)
0.70476007
tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
0.70455170
tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
0.70478046
tensor(0.4859, device='cuda:0', grad_fn=<AddBackward0>)
0.70440817
tensor(0.3972, device='cuda:0', grad_fn=<AddBackward0>)
0.70439786
tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [10][  140/  196]   Loss 0.392946   Top1 86.548549   Top5 99.486607   BatchTime 0.269093   LR 0.000249
0.70414639
tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
0.70399666
tensor(0.4426, device='cuda:0', grad_fn=<AddBackward0>)
0.70403934
tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
0.70390433
tensor(0.4546, device='cuda:0', grad_fn=<AddBackward0>)
0.70377123
tensor(0.4558, device='cuda:0', grad_fn=<AddBackward0>)
0.70383990
tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
0.70378661
tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)
0.70404339
tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
0.70426321
tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
0.70382673
tensor(0.4573, device='cuda:0', grad_fn=<AddBackward0>)
0.70388216
tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
0.70410883
tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
0.70422542
tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
0.70410705
tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>)
0.70419669
tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
0.70422411
tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)
0.70395523
tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
0.70393276
tensor(0.4239, device='cuda:0', grad_fn=<AddBackward0>)
0.70409787
tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
0.70390821
tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
0.70376533
tensor(0.4660, device='cuda:0', grad_fn=<AddBackward0>)
0.70378447
tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
0.70365667
tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [10][  160/  196]   Loss 0.391871   Top1 86.618652   Top5 99.475098   BatchTime 0.267698   LR 0.000249
0.70373875
tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
0.70340312
tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)
0.70330262
tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)
0.70346540
tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)
0.70319825
tensor(0.4562, device='cuda:0', grad_fn=<AddBackward0>)
0.70284802
tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)
0.70236057
tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>)
0.70175856
tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)
0.70122415
tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
0.70080423
tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
0.70029795
tensor(0.4187, device='cuda:0', grad_fn=<AddBackward0>)
0.69933403
tensor(0.4261, device='cuda:0', grad_fn=<AddBackward0>)
0.69851810
tensor(0.4457, device='cuda:0', grad_fn=<AddBackward0>)
0.69820541
tensor(0.4744, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [10][  180/  196]   Loss 0.393506   Top1 86.623264   Top5 99.468316   BatchTime 0.269295   LR 0.000249
0.69745612
tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>)
0.69692916
tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
0.69640505
tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
0.69567907
tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>)
0.69491714
tensor(0.4301, device='cuda:0', grad_fn=<AddBackward0>)
0.69486731
tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
0.69419217
tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
0.69348985
tensor(0.4273, device='cuda:0', grad_fn=<AddBackward0>)
0.69292957
tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
0.69256479
tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)
0.69253200
tensor(0.4681, device='cuda:0', grad_fn=<AddBackward0>)
0.69246727
tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)
0.69264477
tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)
0.69257271
tensor(0.4910, device='cuda:0', grad_fn=<AddBackward0>)
0.69241691
tensor(0.4908, device='cuda:0', grad_fn=<AddBackward0>)
0.69240326
tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 86.514    Top5: 99.458    Loss: 0.396
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.69250661
tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
0.69227010
tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
0.69211733
tensor(0.4995, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [10][   20/   40]   Loss 0.516309   Top1 83.105469   Top5 99.023438   BatchTime 0.131366
INFO - Validation [10][   40/   40]   Loss 0.507953   Top1 83.400000   Top5 99.260000   BatchTime 0.095135
INFO - ==> Top1: 83.400    Top5: 99.260    Loss: 0.508
INFO - ==> Sparsity : 0.498
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.240   Top5: 99.480]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2847)
features.0.conv.3 tensor(0.1562)
features.1.conv.0 tensor(0.0658)
features.1.conv.3 tensor(0.0926)
features.1.conv.6 tensor(0.0868)
features.2.conv.0 tensor(0.0868)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.2214)
features.3.conv.0 tensor(0.0518)
features.3.conv.3 tensor(0.0810)
features.3.conv.6 tensor(0.1111)
features.4.conv.0 tensor(0.0557)
features.4.conv.3 tensor(0.3084)
features.4.conv.6 tensor(0.1991)
features.5.conv.0 tensor(0.2507)
features.5.conv.3 tensor(0.4178)
features.5.conv.6 tensor(0.1089)
features.6.conv.0 tensor(0.0633)
features.6.conv.3 tensor(0.0596)
features.6.conv.6 tensor(0.0837)
features.7.conv.0 tensor(0.2116)
features.7.conv.3 tensor(0.4586)
features.7.conv.6 tensor(0.2304)
features.8.conv.0 tensor(0.3247)
features.8.conv.3 tensor(0.5362)
features.8.conv.6 tensor(0.5867)
features.9.conv.0 tensor(0.3400)
features.9.conv.3 tensor(0.5648)
features.9.conv.6 tensor(0.5122)
features.10.conv.0 tensor(0.0645)
features.10.conv.3 tensor(0.0992)
features.10.conv.6 tensor(0.0612)
features.11.conv.0 tensor(0.7075)
features.11.conv.3 tensor(0.6478)
features.11.conv.6 tensor(0.8584)
features.12.conv.0 tensor(0.6436)
features.12.conv.3 tensor(0.6721)
features.12.conv.6 tensor(0.6646)
features.13.conv.0 tensor(0.2406)
features.13.conv.3 tensor(0.4913)
features.13.conv.6 tensor(0.0897)
features.14.conv.0 tensor(0.8453)
features.14.conv.3 tensor(0.8174)
features.14.conv.6 tensor(0.8936)
features.15.conv.0 tensor(0.8112)
features.15.conv.3 tensor(0.8249)
features.15.conv.6 tensor(0.9255)
features.16.conv.0 tensor(0.2766)
features.16.conv.3 tensor(0.7865)
features.16.conv.6 tensor(0.6318)
conv.0 tensor(0.0892)
tensor(1091013.) 2188896.0
0.69231808
tensor(0.4482, device='cuda:0', grad_fn=<AddBackward0>)
0.69242507
tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)
0.69255269
tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)
0.69271177
tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
0.69278204
tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)
0.69281262
tensor(0.4429, device='cuda:0', grad_fn=<AddBackward0>)
0.69272727
tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
0.69268173
tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
0.69258362
tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
0.69250643
tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
0.69247657
tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
0.69257933
tensor(0.4555, device='cuda:0', grad_fn=<AddBackward0>)
0.69232625
tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)
0.69227117
tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
0.69253325
tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>)
0.69240606
tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
0.69249278
tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [11][   20/  196]   Loss 0.380491   Top1 87.031250   Top5 99.687500   BatchTime 0.317686   LR 0.000248
0.69229478
tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)
0.69200784
tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
0.69192833
tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
0.69189388
tensor(0.4145, device='cuda:0', grad_fn=<AddBackward0>)
0.69183356
tensor(0.4177, device='cuda:0', grad_fn=<AddBackward0>)
0.69184339
tensor(0.4239, device='cuda:0', grad_fn=<AddBackward0>)
0.69229448
tensor(0.5027, device='cuda:0', grad_fn=<AddBackward0>)
0.69331467
tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)
0.69443071
tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)
0.69526762
tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
0.69650507
tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
0.69783515
tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
0.69932938
tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
0.70072389
tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)
0.70324117
tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
0.70567471
tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>)
0.70762485
tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
0.70801359
tensor(0.3279, device='cuda:0', grad_fn=<AddBackward0>)
0.70796126
tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
0.70823932
tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
0.70826185
tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
0.70846456
tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)
0.70860678
tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>)
0.70940727
tensor(0.4397, device='cuda:0', grad_fn=<AddBackward0>)
0.70986778
tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [11][   40/  196]   Loss 0.385676   Top1 86.992188   Top5 99.638672   BatchTime 0.278711   LR 0.000248
0.70993400
tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
0.71010822
tensor(0.4414, device='cuda:0', grad_fn=<AddBackward0>)
0.71003902
tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
0.70996928
tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>)
0.71018255
tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
0.70979458
tensor(0.4332, device='cuda:0', grad_fn=<AddBackward0>)
0.70964295
tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
0.71016109
tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
0.70958292
tensor(0.4432, device='cuda:0', grad_fn=<AddBackward0>)
0.70959342
tensor(0.4654, device='cuda:0', grad_fn=<AddBackward0>)
0.70946032
tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
0.70936561
tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
0.70929754
tensor(0.4197, device='cuda:0', grad_fn=<AddBackward0>)
0.70941675
tensor(0.4494, device='cuda:0', grad_fn=<AddBackward0>)
0.70949680
tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
0.70952529
tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [11][   60/  196]   Loss 0.390379   Top1 86.927083   Top5 99.570312   BatchTime 0.268462   LR 0.000247
0.70939255
tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
0.70935768
tensor(0.4460, device='cuda:0', grad_fn=<AddBackward0>)
0.70938563
tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
0.70934576
tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)
0.70931280
tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
0.70916808
tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>)
0.70933062
tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
0.70882165
tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
0.70878559
tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
0.70865768
tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
0.70865768
tensor(0.3774, device='cuda:0', grad_fn=<AddBackward0>)
0.70869112
tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>)
0.70865250
tensor(0.4236, device='cuda:0', grad_fn=<AddBackward0>)
0.70888424
tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
0.70906335
tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>)
0.70882452
tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
0.70878357
tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
0.70842797
tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>)
0.70822924
tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)
0.70798516
tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)
0.70789236
tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>)
0.70778513
tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
0.70772743
tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>)
0.70772767
tensor(0.4608, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [11][   80/  196]   Loss 0.382310   Top1 87.084961   Top5 99.604492   BatchTime 0.264816   LR 0.000247
0.70766526
tensor(0.4426, device='cuda:0', grad_fn=<AddBackward0>)
0.70744425
tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)
0.70742595
tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>)
0.70715624
tensor(0.4810, device='cuda:0', grad_fn=<AddBackward0>)
0.70709729
tensor(0.5305, device='cuda:0', grad_fn=<AddBackward0>)
0.70738459
tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)
0.70758754
tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
0.70774490
tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>)
0.70738298
tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
0.70732361
tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)
0.70755279
tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
0.70737875
tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
0.70714623
tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
0.70707077
tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
0.70709550
tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
0.70733285
tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [11][  100/  196]   Loss 0.385106   Top1 86.984375   Top5 99.589844   BatchTime 0.261378   LR 0.000247
0.70734471
tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>)
0.70742285
tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
0.70747405
tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
0.70769447
tensor(0.4259, device='cuda:0', grad_fn=<AddBackward0>)
0.70779568
tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
0.70783234
tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
0.70761198
tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)
0.70766789
tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
0.70749342
tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
0.70750111
tensor(0.4633, device='cuda:0', grad_fn=<AddBackward0>)
0.70762247
tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
0.70743901
tensor(0.4137, device='cuda:0', grad_fn=<AddBackward0>)
0.70746565
tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)
0.70718729
tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
0.70680487
tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
0.70676094
tensor(0.4411, device='cuda:0', grad_fn=<AddBackward0>)
0.70663124
tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
0.70656163
tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)
0.70663911
tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)
0.70667255
tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
0.70646286
tensor(0.4987, device='cuda:0', grad_fn=<AddBackward0>)
0.70612335
tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
0.70604205
tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
0.70603472
tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [11][  120/  196]   Loss 0.386559   Top1 86.995443   Top5 99.576823   BatchTime 0.259650   LR 0.000246
0.70587349
tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
0.70574975
tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>)
0.70556825
tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
0.70556796
tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)
0.70560032
tensor(0.4635, device='cuda:0', grad_fn=<AddBackward0>)
0.70554376
tensor(0.3888, device='cuda:0', grad_fn=<AddBackward0>)
0.70546693
tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)
0.70559895
tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
0.70569539
tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
0.70560873
tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)
0.70545578
tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)
0.70535034
tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
0.70542818
tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)
0.70532960
tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
0.70554006
tensor(0.4291, device='cuda:0', grad_fn=<AddBackward0>)
0.70550907
tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)
0.70555520
tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
0.70546103
tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
0.70559615
tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
0.70564818
tensor(0.4632, device='cuda:0', grad_fn=<AddBackward0>)
0.70578843
tensor(0.5078, device='cuda:0', grad_fn=<AddBackward0>)
0.70597064
tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
0.70566642
tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
0.70540112
tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [11][  140/  196]   Loss 0.385192   Top1 87.006138   Top5 99.578683   BatchTime 0.258262   LR 0.000246
0.70529705
tensor(0.4273, device='cuda:0', grad_fn=<AddBackward0>)
0.70531082
tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
0.70540923
tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
0.70537949
tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
0.70577681
tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)
0.70547849
tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)
0.70555311
tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
0.70546895
tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)
0.70535088
tensor(0.4387, device='cuda:0', grad_fn=<AddBackward0>)
0.70537889
tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>)
0.70529360
tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
0.70530981
tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
0.70516491
tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)
0.70524621
tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)
0.70576829
tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>)
0.70558524
tensor(0.4326, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [11][  160/  196]   Loss 0.385957   Top1 87.001953   Top5 99.580078   BatchTime 0.256598   LR 0.000245
0.70550460
tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
0.70563471
tensor(0.5321, device='cuda:0', grad_fn=<AddBackward0>)
0.70555454
tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
0.70573550
tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)
0.70568812
tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
0.70562017
tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
0.70542550
tensor(0.4143, device='cuda:0', grad_fn=<AddBackward0>)
0.70560032
tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
0.70586509
tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
0.70607364
tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
0.70662642
tensor(0.4588, device='cuda:0', grad_fn=<AddBackward0>)
0.70729840
tensor(0.4939, device='cuda:0', grad_fn=<AddBackward0>)
0.70785737
tensor(0.4633, device='cuda:0', grad_fn=<AddBackward0>)
0.70821285
tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
0.70869321
tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
0.70879596
tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [11][  180/  196]   Loss 0.385919   Top1 86.981337   Top5 99.576823   BatchTime 0.255883   LR 0.000244
0.70951056
tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)
0.71019095
tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
0.71046656
tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)
0.71115428
tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
0.71142542
tensor(0.4898, device='cuda:0', grad_fn=<AddBackward0>)
0.71199054
tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)
0.71258020
tensor(0.4770, device='cuda:0', grad_fn=<AddBackward0>)
0.71300423
tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)
0.71330267
tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)
0.71364725
tensor(0.4599, device='cuda:0', grad_fn=<AddBackward0>)
0.71394604
tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
0.71424770
tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
0.71431911
tensor(0.4650, device='cuda:0', grad_fn=<AddBackward0>)
0.71434921
tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
0.71450192
tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
0.71417195
tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)
0.71434343
tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)
0.71455050
tensor(0.5161, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 86.938    Top5: 99.572    Loss: 0.388
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [11][   20/   40]   Loss 0.486664   Top1 83.671875   Top5 99.199219   BatchTime 0.124564
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1602)
features.1.conv.0 tensor(0.0592)
features.1.conv.3 tensor(0.0752)
features.1.conv.6 tensor(0.0872)
features.2.conv.0 tensor(0.0770)
features.2.conv.3 tensor(0.3519)
features.2.conv.6 tensor(0.2170)
features.3.conv.0 tensor(0.0599)
features.3.conv.3 tensor(0.0856)
features.3.conv.6 tensor(0.1096)
features.4.conv.0 tensor(0.0649)
features.4.conv.3 tensor(0.3061)
features.4.conv.6 tensor(0.1981)
features.5.conv.0 tensor(0.2479)
features.5.conv.3 tensor(0.4259)
features.5.conv.6 tensor(0.1107)
features.6.conv.0 tensor(0.0524)
features.6.conv.3 tensor(0.0602)
features.6.conv.6 tensor(0.0828)
features.7.conv.0 tensor(0.2158)
features.7.conv.3 tensor(0.4549)
features.7.conv.6 tensor(0.3089)
features.8.conv.0 tensor(0.3465)
features.8.conv.3 tensor(0.5370)
features.8.conv.6 tensor(0.1591)
features.9.conv.0 tensor(0.3175)
features.9.conv.3 tensor(0.5680)
features.9.conv.6 tensor(0.3464)
features.10.conv.0 tensor(0.0653)
features.10.conv.3 tensor(0.1019)
features.10.conv.6 tensor(0.0634)
features.11.conv.0 tensor(0.7024)
features.11.conv.3 tensor(0.6474)
features.11.conv.6 tensor(0.8553)
features.12.conv.0 tensor(0.6548)
features.12.conv.3 tensor(0.6690)
features.12.conv.6 tensor(0.7129)
features.13.conv.0 tensor(0.2421)
features.13.conv.3 tensor(0.4925)
features.13.conv.6 tensor(0.0906)
features.14.conv.0 tensor(0.8532)
features.14.conv.3 tensor(0.8168)
features.14.conv.6 tensor(0.9223)
features.15.conv.0 tensor(0.8228)
features.15.conv.3 tensor(0.8249)
features.15.conv.6 tensor(0.9368)
features.16.conv.0 tensor(0.2703)
features.16.conv.3 tensor(0.7867)
features.16.conv.6 tensor(0.6340)
conv.0 tensor(0.0901)
tensor(1090702.) 2188896.0
INFO - Validation [11][   40/   40]   Loss 0.473387   Top1 83.960000   Top5 99.340000   BatchTime 0.090938
INFO - ==> Top1: 83.960    Top5: 99.340    Loss: 0.473
INFO - ==> Sparsity : 0.498
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.240   Top5: 99.480]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
0.71468300
tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
0.71444410
tensor(0.4532, device='cuda:0', grad_fn=<AddBackward0>)
0.71442324
tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
0.71470809
tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>)
0.71457762
tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>)
0.71460932
tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
0.71472567
tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
0.71479756
tensor(0.4880, device='cuda:0', grad_fn=<AddBackward0>)
0.71496385
tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>)
0.71482295
tensor(0.4163, device='cuda:0', grad_fn=<AddBackward0>)
0.71479744
tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
0.71467358
tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
0.71462506
tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)
0.71434987
tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
0.71427971
tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
0.71453333
tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
0.71452624
tensor(0.4509, device='cuda:0', grad_fn=<AddBackward0>)
0.71447921
tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>)
0.71434110
tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)
0.71431881
tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [12][   20/  196]   Loss 0.378392   Top1 86.933594   Top5 99.550781   BatchTime 0.316374   LR 0.000243
0.71413487
tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
0.71412444
tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)
0.71413952
tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
0.71418297
tensor(0.4318, device='cuda:0', grad_fn=<AddBackward0>)
0.71410233
tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
0.71401268
tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>)
0.71417987
tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
0.71423918
tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
0.71416968
tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>)
0.71377647
tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
0.71369642
tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
0.71377140
tensor(0.2925, device='cuda:0', grad_fn=<AddBackward0>)
0.71373707
tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)
0.71372163
tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>)
0.71370071
tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
0.71356809
tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)
0.71357924
tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)
0.71359593
tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
0.71340686
tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>)
0.71336353
tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
0.71341681
tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
0.71325940
tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
0.71315700
tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [12][   40/  196]   Loss 0.374464   Top1 87.187500   Top5 99.628906   BatchTime 0.289653   LR 0.000243
0.71313488
tensor(0.4584, device='cuda:0', grad_fn=<AddBackward0>)
0.71295387
tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)
0.71287572
tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>)
0.71289557
tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
0.71288848
tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)
0.71292263
tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
0.71301824
tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)
0.71306455
tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
0.71313351
tensor(0.3244, device='cuda:0', grad_fn=<AddBackward0>)
0.71313256
tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
0.71324944
tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
0.71318781
tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
0.71320570
tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)
0.71345180
tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
0.71343946
tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>)
0.71328914
tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [12][   60/  196]   Loss 0.371753   Top1 87.337240   Top5 99.609375   BatchTime 0.276370   LR 0.000242
0.71321738
tensor(0.4289, device='cuda:0', grad_fn=<AddBackward0>)
0.71328360
tensor(0.4559, device='cuda:0', grad_fn=<AddBackward0>)
0.71329653
tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
0.71363389
tensor(0.5214, device='cuda:0', grad_fn=<AddBackward0>)
0.71396118
tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
0.71423930
tensor(0.4538, device='cuda:0', grad_fn=<AddBackward0>)
0.71468955
tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)
0.71490061
tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
0.71514302
tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)
0.71522164
tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
0.71585107
tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>)
0.71605736
tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
0.71577185
tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
0.71594429
tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
0.71585923
tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
0.71556091
tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)
0.71565390
tensor(0.4308, device='cuda:0', grad_fn=<AddBackward0>)
0.71574670
tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)
0.71573997
tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>)
0.71587253
tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
0.71588224
tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)
0.71597934
tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>)
0.71605492
tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
0.71574223
tensor(0.4364, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [12][   80/  196]   Loss 0.373048   Top1 87.324219   Top5 99.580078   BatchTime 0.269919   LR 0.000241
0.71590704
tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
0.71563870
tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>)
0.71548241
tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)
0.71555740
tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>)
0.71550483
tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
0.71512985
tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)
0.71490592
tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)
0.71491671
tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>)
0.71484667
tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
0.71473032
tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
0.71467668
tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>)
0.71468216
tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
0.71454072
tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
0.71476364
tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>)
0.71451432
tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
0.71428072
tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
0.71413416
tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)
0.71402222
tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
0.71362954
tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
0.71287549
tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
0.71291178
tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>)
0.71297365
tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
0.71314758
tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [12][  100/  196]   Loss 0.370776   Top1 87.472656   Top5 99.570312   BatchTime 0.268339   LR 0.000240
0.71297920
tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
0.71270907
tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)
0.71251607
tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
0.71222395
tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
0.71209401
tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)
0.71210283
tensor(0.4010, device='cuda:0', grad_fn=<AddBackward0>)
0.71199763
tensor(0.4103, device='cuda:0', grad_fn=<AddBackward0>)
0.71182263
tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)
0.71119422
tensor(0.4789, device='cuda:0', grad_fn=<AddBackward0>)
0.71120393
tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)
0.71101296
tensor(0.4471, device='cuda:0', grad_fn=<AddBackward0>)
0.71088964
tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>)
0.71089178
tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
0.71099019
tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>)
0.71101713
tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>)
0.71111232
tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [12][  120/  196]   Loss 0.370691   Top1 87.418620   Top5 99.576823   BatchTime 0.266189   LR 0.000240
0.71086234
tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>)
0.71072227
tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>)
0.71039146
tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
0.71021360
tensor(0.5081, device='cuda:0', grad_fn=<AddBackward0>)
0.70987272
tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)
0.70995408
tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
0.71018714
tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
0.70990306
tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)
0.70993966
tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
0.70969921
tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
0.70924616
tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
0.70914447
tensor(0.4568, device='cuda:0', grad_fn=<AddBackward0>)
0.70911270
tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)
0.70922583
tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
0.70913380
tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)
0.70896029
tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)
0.70900881
tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
0.70940870
tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)
0.70955276
tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)
0.70930928
tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)
0.70908630
tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>)
0.70904565
tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
0.70906955
tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
0.70898843
tensor(0.4616, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [12][  140/  196]   Loss 0.371134   Top1 87.371652   Top5 99.589844   BatchTime 0.263682   LR 0.000239
0.70894933
tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)
0.70891643
tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
0.70881915
tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
0.70861745
tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>)
0.70866889
tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
0.70890075
tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)
0.70916462
tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
0.70933735
tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)
0.70967251
tensor(0.4109, device='cuda:0', grad_fn=<AddBackward0>)
0.70934850
tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>)
0.70974642
tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
0.70951945
tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)
0.71079648
tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)
0.71085584
tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
0.71064126
tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [12][  160/  196]   Loss 0.370588   Top1 87.414551   Top5 99.606934   BatchTime 0.263612   LR 0.000238
0.71059072
tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)
0.71037722
tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
0.71014458
tensor(0.4539, device='cuda:0', grad_fn=<AddBackward0>)
0.71009874
tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
0.71024746
tensor(0.2976, device='cuda:0', grad_fn=<AddBackward0>)
0.71053940
tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
0.71036631
tensor(0.3778, device='cuda:0', grad_fn=<AddBackward0>)
0.71029270
tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)
0.71003395
tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
0.71019566
tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
0.70992118
tensor(0.4804, device='cuda:0', grad_fn=<AddBackward0>)
0.70957208
tensor(0.4086, device='cuda:0', grad_fn=<AddBackward0>)
0.70930821
tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)
0.70946795
tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>)
0.70948356
tensor(0.4613, device='cuda:0', grad_fn=<AddBackward0>)
0.70928091
tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
0.70934951
tensor(0.4360, device='cuda:0', grad_fn=<AddBackward0>)
0.70927060
tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
0.70922256
tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
0.70923460
tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
0.70906323
tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
0.70906311
tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
0.70931399
tensor(0.5170, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [12][  180/  196]   Loss 0.371061   Top1 87.400174   Top5 99.587674   BatchTime 0.263204   LR 0.000237
0.70911491
tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
0.70905703
tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
0.70926005
tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)
0.70891720
tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
0.70881784
tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)
0.70888263
tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>)
0.70899498
tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
0.70902741
tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
0.70873952
tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
0.70899636
tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)
0.70902765
tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>)
0.70867562
tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 87.484    Top5: 99.594    Loss: 0.370
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 0.472695   Top1 84.550781   Top5 99.101562   BatchTime 0.131644
INFO - Validation [12][   40/   40]   Loss 0.457448   Top1 84.740000   Top5 99.300000   BatchTime 0.095355
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1602)
features.1.conv.0 tensor(0.0527)
features.1.conv.3 tensor(0.0706)
features.1.conv.6 tensor(0.0781)
features.2.conv.0 tensor(0.0749)
features.2.conv.3 tensor(0.3472)
features.2.conv.6 tensor(0.2378)
features.3.conv.0 tensor(0.0608)
features.3.conv.3 tensor(0.0810)
features.3.conv.6 tensor(0.1170)
features.4.conv.0 tensor(0.0778)
features.4.conv.3 tensor(0.3050)
features.4.conv.6 tensor(0.1960)
features.5.conv.0 tensor(0.2490)
features.5.conv.3 tensor(0.4201)
features.5.conv.6 tensor(0.1121)
features.6.conv.0 tensor(0.0578)
features.6.conv.3 tensor(0.0567)
features.6.conv.6 tensor(0.0841)
features.7.conv.0 tensor(0.2189)
features.7.conv.3 tensor(0.4552)
features.7.conv.6 tensor(0.2885)
features.8.conv.0 tensor(0.3632)
features.8.conv.3 tensor(0.5382)
features.8.conv.6 tensor(0.1544)
features.9.conv.0 tensor(0.3384)
features.9.conv.3 tensor(0.5654)
features.9.conv.6 tensor(0.4322)
features.10.conv.0 tensor(0.0651)
features.10.conv.3 tensor(0.1021)
features.10.conv.6 tensor(0.0684)
features.11.conv.0 tensor(0.7231)
features.11.conv.3 tensor(0.6483)
features.11.conv.6 tensor(0.8614)
features.12.conv.0 tensor(0.6732)
features.12.conv.3 tensor(0.6698)
features.12.conv.6 tensor(0.7470)
features.13.conv.0 tensor(0.2441)
features.13.conv.3 tensor(0.4896)
features.13.conv.6 tensor(0.0909)
features.14.conv.0 tensor(0.8642)
features.14.conv.3 tensor(0.8169)
features.14.conv.6 tensor(0.9367)
features.15.conv.0 tensor(0.8207)
features.15.conv.3 tensor(0.8260)
features.15.conv.6 tensor(0.9415)
features.16.conv.0 tensor(0.2705)
features.16.conv.3 tensor(0.7876)
features.16.conv.6 tensor(0.6423)
conv.0 tensor(0.0896)
tensor(1104763.) 2188896.0
INFO - ==> Top1: 84.740    Top5: 99.300    Loss: 0.457
INFO - ==> Sparsity : 0.505
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.240   Top5: 99.480]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
0.70846230
tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>)
0.70831066
tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
0.70854944
tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
0.70834237
tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)
0.70807314
tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)
0.70807880
tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
0.70803988
tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
0.70794523
tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)
0.70805067
tensor(0.4138, device='cuda:0', grad_fn=<AddBackward0>)
0.70804328
tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)
0.70789951
tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
0.70785743
tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
0.70780504
tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
0.70784938
tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
0.70795768
tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
0.70805407
tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
0.70799917
tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
0.70782053
tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)
0.70779216
tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
0.70774865
tensor(0.4562, device='cuda:0', grad_fn=<AddBackward0>)
0.70776403
tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
0.70797807
tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)
0.70812720
tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
0.70811486
tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [13][   20/  196]   Loss 0.342942   Top1 88.320312   Top5 99.570312   BatchTime 0.316271   LR 0.000235
0.70805484
tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)
0.70794499
tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>)
0.70783669
tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
0.70780480
tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
0.70774025
tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
0.70763445
tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
0.70779264
tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>)
0.70771825
tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
0.70755756
tensor(0.3015, device='cuda:0', grad_fn=<AddBackward0>)
0.70740837
tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
0.70733708
tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)
0.70734459
tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
0.70730233
tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
0.70721287
tensor(0.4624, device='cuda:0', grad_fn=<AddBackward0>)
0.70732766
tensor(0.3879, device='cuda:0', grad_fn=<AddBackward0>)
0.70707560
tensor(0.4226, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [13][   40/  196]   Loss 0.345452   Top1 88.398438   Top5 99.560547   BatchTime 0.283188   LR 0.000235
0.70680338
tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>)
0.70668715
tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)
0.70666462
tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
0.70683134
tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>)
0.70691937
tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
0.70693010
tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
0.70698953
tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)
0.70686710
tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)
0.70712525
tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
0.70702374
tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
0.70687723
tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
0.70695359
tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
0.70661664
tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
0.70666552
tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
0.70666176
tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>)
0.70679420
tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
0.70684612
tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>)
0.70689183
tensor(0.4289, device='cuda:0', grad_fn=<AddBackward0>)
0.70680285
tensor(0.4948, device='cuda:0', grad_fn=<AddBackward0>)
0.70684165
tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
0.70686710
tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
0.70698941
tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
0.70711553
tensor(0.4613, device='cuda:0', grad_fn=<AddBackward0>)
0.70693034
tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [13][   60/  196]   Loss 0.349950   Top1 88.248698   Top5 99.544271   BatchTime 0.272198   LR 0.000234
0.70686013
tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
0.70675987
tensor(0.5532, device='cuda:0', grad_fn=<AddBackward0>)
0.70683134
tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)
0.70680624
tensor(0.3617, device='cuda:0', grad_fn=<AddBackward0>)
0.70697719
tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)
0.70705020
tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>)
0.70697212
tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
0.70705491
tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
0.70706546
tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
0.70710009
tensor(0.4489, device='cuda:0', grad_fn=<AddBackward0>)
0.70697135
tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
0.70697796
tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
0.70726395
tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>)
0.70736384
tensor(0.4939, device='cuda:0', grad_fn=<AddBackward0>)
0.70762175
tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
0.70788914
tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [13][   80/  196]   Loss 0.359312   Top1 87.919922   Top5 99.565430   BatchTime 0.266560   LR 0.000233
0.70779365
tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)
0.70768422
tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
0.70775491
tensor(0.3834, device='cuda:0', grad_fn=<AddBackward0>)
0.70765662
tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)
0.70748502
tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
0.70733339
tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
0.70728338
tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
0.70737761
tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
0.70706540
tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
0.70718294
tensor(0.2971, device='cuda:0', grad_fn=<AddBackward0>)
0.70748913
tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)
0.70727992
tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)
0.70712566
tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
0.70733881
tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
0.70740223
tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
0.70695919
tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)
0.70708179
tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)
0.70706367
tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>)
0.70691514
tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
0.70679116
tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
0.70676982
tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)
0.70677942
tensor(0.4721, device='cuda:0', grad_fn=<AddBackward0>)
0.70682961
tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
0.70664024
tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
0.70667511
tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [13][  100/  196]   Loss 0.356089   Top1 87.968750   Top5 99.582031   BatchTime 0.262229   LR 0.000232
0.70664704
tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
0.70671099
tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
0.70688927
tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)
0.70680249
tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>)
0.70663363
tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
0.70645422
tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
0.70594013
tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
0.70552593
tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)
0.70566696
tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)
0.70564193
tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
0.70579374
tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
0.70569587
tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
0.70551389
tensor(0.4174, device='cuda:0', grad_fn=<AddBackward0>)
0.70552391
tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>)
0.70565361
tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
0.70558286
tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)
0.70570618
tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [13][  120/  196]   Loss 0.353396   Top1 88.092448   Top5 99.589844   BatchTime 0.259076   LR 0.000230
0.70566648
tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
0.70542836
tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)
0.70547384
tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
0.70562607
tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)
0.70553225
tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
0.70557421
tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
0.70551676
tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)
0.70549446
tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
0.70566696
tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
0.70585489
tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>)
0.70595878
tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
0.70603800
tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>)
0.70600283
tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
0.70603192
tensor(0.4533, device='cuda:0', grad_fn=<AddBackward0>)
0.70582050
tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
0.70584106
tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>)
0.70585114
tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
0.70561957
tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)
0.70561999
tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
0.70600200
tensor(0.4208, device='cuda:0', grad_fn=<AddBackward0>)
0.70611352
tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
0.70596945
tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)
0.70553786
tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
0.70529836
tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [13][  140/  196]   Loss 0.353171   Top1 88.085938   Top5 99.592634   BatchTime 0.258061   LR 0.000229
0.70502812
tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
0.70473427
tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
0.70454454
tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)
0.70427972
tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>)
0.70412844
tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
0.70361036
tensor(0.4287, device='cuda:0', grad_fn=<AddBackward0>)
0.70315063
tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
0.70287663
tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>)
0.70263404
tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
0.70234764
tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
0.70198303
tensor(0.4131, device='cuda:0', grad_fn=<AddBackward0>)
0.70182890
tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)
0.70152575
tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
0.70130283
tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
0.70074779
tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
0.70023227
INFO - Training [13][  160/  196]   Loss 0.355447   Top1 87.990723   Top5 99.584961   BatchTime 0.257332   LR 0.000228
tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
0.69973779
tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
0.69952732
tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>)
0.69921255
tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>)
0.69873506
tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
0.69811046
tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
0.69763088
tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>)
0.69710642
tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
0.69662416
tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
0.69634426
tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
0.69593382
tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)
0.69547731
tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
0.69532001
tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
0.69515866
tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>)
0.69488865
tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
0.69473499
tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
0.69436568
tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
0.69409043
tensor(0.3864, device='cuda:0', grad_fn=<AddBackward0>)
0.69378716
tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
0.69358295
tensor(0.3342, device='cuda:0', grad_fn=<AddBackward0>)
0.69325966
tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
0.69313675
tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)
0.69283360
tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)
0.69208151
tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
0.69152904
tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [13][  180/  196]   Loss 0.354725   Top1 87.990451   Top5 99.587674   BatchTime 0.256282   LR 0.000227
0.69111580
tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)
0.69069844
tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
0.69041407
tensor(0.4437, device='cuda:0', grad_fn=<AddBackward0>)
0.69038838
tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
0.69013494
tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>)
0.68986404
tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
0.68965071
tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
0.68944418
tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)
0.68921900
tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
0.68903017
tensor(0.4465, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 87.994    Top5: 99.588    Loss: 0.355
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1523)
features.1.conv.0 tensor(0.0579)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0786)
features.2.conv.0 tensor(0.0747)
features.2.conv.3 tensor(0.3511)
features.2.conv.6 tensor(0.2457)
features.3.conv.0 tensor(0.0639)
features.3.conv.3 tensor(0.0764)
features.3.conv.6 tensor(0.1150)
features.4.conv.0 tensor(0.0715)
features.4.conv.3 tensor(0.3015)
features.4.conv.6 tensor(0.1987)
features.5.conv.0 tensor(0.2520)
features.5.conv.3 tensor(0.4178)
features.5.conv.6 tensor(0.1138)
features.6.conv.0 tensor(0.0535)
features.6.conv.3 tensor(0.0475)
features.6.conv.6 tensor(0.0841)
features.7.conv.0 tensor(0.2239)
features.7.conv.3 tensor(0.4546)
features.7.conv.6 tensor(0.2945)
features.8.conv.0 tensor(0.3704)
features.8.conv.3 tensor(0.5399)
features.8.conv.6 tensor(0.1549)
INFO - Validation [13][   20/   40]   Loss 0.448115   Top1 84.882812   Top5 99.238281   BatchTime 0.128890
INFO - Validation [13][   40/   40]   Loss 0.443044   Top1 85.020000   Top5 99.390000   BatchTime 0.092290
INFO - ==> Top1: 85.020    Top5: 99.390    Loss: 0.443
INFO - ==> Sparsity : 0.525
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.240   Top5: 99.480]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
features.9.conv.0 tensor(0.3591)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.4693)
features.10.conv.0 tensor(0.0655)
features.10.conv.3 tensor(0.1013)
features.10.conv.6 tensor(0.0697)
features.11.conv.0 tensor(0.7194)
features.11.conv.3 tensor(0.6483)
features.11.conv.6 tensor(0.8607)
features.12.conv.0 tensor(0.6765)
features.12.conv.3 tensor(0.6696)
features.12.conv.6 tensor(0.7556)
features.13.conv.0 tensor(0.2437)
features.13.conv.3 tensor(0.4886)
features.13.conv.6 tensor(0.0898)
features.14.conv.0 tensor(0.8606)
features.14.conv.3 tensor(0.8183)
features.14.conv.6 tensor(0.9381)
features.15.conv.0 tensor(0.8243)
features.15.conv.3 tensor(0.8263)
features.15.conv.6 tensor(0.9453)
features.16.conv.0 tensor(0.5277)
features.16.conv.3 tensor(0.7876)
features.16.conv.6 tensor(0.6480)
conv.0 tensor(0.0901)
tensor(1149234.) 2188896.0
0.68844479
tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>)
0.68811649
tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)
0.68782401
tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)
0.68764943
tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>)
0.68721336
tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>)
0.68697816
tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
0.68671298
tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
0.68656194
tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)
0.68645692
tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)
0.68631893
tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>)
0.68608594
tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)
0.68571198
tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
0.68565792
tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)
0.68569797
tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>)
0.68558609
tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)
0.68570042
tensor(0.3957, device='cuda:0', grad_fn=<AddBackward0>)
0.68579775
tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
0.68583393
tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>)
0.68594456
tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)
0.68618351
tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
0.68619561
tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)
0.68605745
tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
0.68635869
tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
0.68670577
tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)
0.68629509
tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)
0.68637639
tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [14][   20/  196]   Loss 0.339519   Top1 88.574219   Top5 99.785156   BatchTime 0.314019   LR 0.000225
0.68641436
tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)
0.68648088
tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
0.68639427
tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
0.68627560
tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)
0.68622112
tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>)
0.68601364
tensor(0.4900, device='cuda:0', grad_fn=<AddBackward0>)
0.68585229
tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>)
0.68587124
tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
0.68582577
tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
0.68565995
tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)
0.68580025
tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
0.68604523
tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)
0.68602949
tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
0.68604302
tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
0.68598378
tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
0.68604255
tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [14][   40/  196]   Loss 0.337227   Top1 88.613281   Top5 99.736328   BatchTime 0.285501   LR 0.000224
0.68601835
tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
0.68614674
tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)
0.68622178
tensor(0.4649, device='cuda:0', grad_fn=<AddBackward0>)
0.68619090
tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
0.68608743
tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
0.68598670
tensor(0.4281, device='cuda:0', grad_fn=<AddBackward0>)
0.68572569
tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
0.68566185
tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>)
0.68553382
tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
0.68556184
tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)
0.68544453
tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
0.68537909
tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>)
0.68544745
tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>)
0.68551815
tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>)
0.68556577
tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
0.68571740
tensor(0.4277, device='cuda:0', grad_fn=<AddBackward0>)
0.68553734
tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
0.68544376
tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
0.68539506
tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)
0.68548810
tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
0.68531471
tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
0.68507630
tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
0.68506366
tensor(0.4767, device='cuda:0', grad_fn=<AddBackward0>)
0.68484873
tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [14][   60/  196]   Loss 0.348188   Top1 88.359375   Top5 99.622396   BatchTime 0.273705   LR 0.000223
0.68463862
tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)
0.68471003
tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)
0.68469650
tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>)
0.68458700
tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
0.68471664
tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
0.68485439
tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>)
0.68493778
tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
0.68496221
tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)
0.68496180
tensor(0.3321, device='cuda:0', grad_fn=<AddBackward0>)
0.68480831
tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
0.68446302
tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)
0.68433660
tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
0.68425930
tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
0.68426585
tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
0.68441933
tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
0.68428469
tensor(0.3879, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [14][   80/  196]   Loss 0.345935   Top1 88.320312   Top5 99.658203   BatchTime 0.267525   LR 0.000221
0.68423963
tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)
0.68445653
tensor(0.4298, device='cuda:0', grad_fn=<AddBackward0>)
0.68430519
tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
0.68441767
tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
0.68415028
tensor(0.3277, device='cuda:0', grad_fn=<AddBackward0>)
0.68417215
tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)
0.68408781
tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)
0.68406731
tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
0.68395728
tensor(0.4692, device='cuda:0', grad_fn=<AddBackward0>)
0.68412703
tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)
0.68428159
tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
0.68425190
tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
0.68419009
tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
0.68408442
tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
0.68446988
tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
0.68463099
tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
0.68449455
tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
0.68458676
tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
0.68434614
tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
0.68401337
tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>)
0.68388605
tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
0.68380535
tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
0.68355709
tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
0.68344349
tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [14][  100/  196]   Loss 0.345418   Top1 88.335938   Top5 99.664062   BatchTime 0.263760   LR 0.000220
0.68334299
tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)
0.68334836
tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
0.68341941
tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
0.68345016
tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>)
0.68352735
tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
0.68354970
tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
0.68346226
tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)
0.68330818
tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
0.68334544
tensor(0.4446, device='cuda:0', grad_fn=<AddBackward0>)
0.68331647
tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
0.68332809
tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
0.68332630
tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)
0.68334824
tensor(0.4641, device='cuda:0', grad_fn=<AddBackward0>)
0.68326986
tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
0.68350387
tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [14][  120/  196]   Loss 0.348610   Top1 88.157552   Top5 99.645182   BatchTime 0.262991   LR 0.000219
0.68334097
tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
0.68320519
tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
0.68326962
tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)
0.68311828
tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)
0.68300360
tensor(0.4365, device='cuda:0', grad_fn=<AddBackward0>)
0.68293011
tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)
0.68294084
tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
0.68295997
tensor(0.4255, device='cuda:0', grad_fn=<AddBackward0>)
0.68314630
tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
0.68335027
tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
0.68344367
tensor(0.4317, device='cuda:0', grad_fn=<AddBackward0>)
0.68325001
tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
0.68318421
tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
0.68312925
tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>)
0.68307883
tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>)
0.68317133
tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
0.68304229
tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
0.68276364
tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
0.68254805
tensor(0.4775, device='cuda:0', grad_fn=<AddBackward0>)
0.68252695
tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
0.68263012
tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>)
0.68231922
tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>)
0.68233478
tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>)
0.68258148
tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [14][  140/  196]   Loss 0.349611   Top1 88.088728   Top5 99.637277   BatchTime 0.261620   LR 0.000217
0.68277919
tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)
0.68311191
tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
0.68324739
tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
0.68319279
tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
0.68333346
tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
0.68317258
tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
0.68315166
tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
0.68327487
tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
0.68330342
tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>)
0.68332213
tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
0.68361491
tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>)
0.68520683
tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
0.68521702
tensor(0.3485, device='cuda:0', grad_fn=<AddBackward0>)
0.68557829
tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)
0.68584067
tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
0.68561029
tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [14][  160/  196]   Loss 0.346645   Top1 88.178711   Top5 99.643555   BatchTime 0.260391   LR 0.000216
0.68555290
tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
0.68557966
tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)
0.68571049
tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
0.68572122
tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
0.68564945
tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
0.68550789
tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>)
0.68517083
tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>)
0.68511629
tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
0.68504107
tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
0.68494761
tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
0.68515670
tensor(0.4253, device='cuda:0', grad_fn=<AddBackward0>)
0.68521035
tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
0.68525124
tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
0.68534738
tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
0.68516976
tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
0.68480706
tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
0.68478572
tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)
0.68483901
tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
0.68490374
tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)
0.68512279
tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
0.68498355
tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
0.68493128
tensor(0.4237, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [14][  180/  196]   Loss 0.346500   Top1 88.213976   Top5 99.652778   BatchTime 0.262010   LR 0.000215
0.68483782
tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
0.68461645
tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)
0.68449378
tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)
0.68460083
tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)
0.68451655
tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
0.68432146
tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)
0.68432194
tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
0.68422866
tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
0.68410003
tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)
0.68427974
tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)
0.68428534
tensor(0.4216, device='cuda:0', grad_fn=<AddBackward0>)
0.68424124
tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>)
0.68442076
tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 88.190    Top5: 99.658    Loss: 0.346
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 0.468055   Top1 84.687500   Top5 99.199219   BatchTime 0.123421
features.0.conv.0 tensor(0.2847)
features.0.conv.3 tensor(0.1641)
features.1.conv.0 tensor(0.0423)
features.1.conv.3 tensor(0.0741)
features.1.conv.6 tensor(0.0846)
features.2.conv.0 tensor(0.0909)
features.2.conv.3 tensor(0.3472)
features.2.conv.6 tensor(0.2219)
features.3.conv.0 tensor(0.0613)
features.3.conv.3 tensor(0.0849)
features.3.conv.6 tensor(0.1076)
features.4.conv.0 tensor(0.0788)
features.4.conv.3 tensor(0.3056)
features.4.conv.6 tensor(0.1981)
features.5.conv.0 tensor(0.2598)
features.5.conv.3 tensor(0.4213)
features.5.conv.6 tensor(0.1172)
features.6.conv.0 tensor(0.0558)
features.6.conv.3 tensor(0.0492)
features.6.conv.6 tensor(0.0879)
features.7.conv.0 tensor(0.2255)
features.7.conv.3 tensor(0.4502)
features.7.conv.6 tensor(0.3140)
features.8.conv.0 tensor(0.3676)
features.8.conv.3 tensor(0.5405)
features.8.conv.6 tensor(0.1563)
features.9.conv.0 tensor(0.3429)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.4812)
features.10.conv.0 tensor(0.0688)
features.10.conv.3 tensor(0.1001)
features.10.conv.6 tensor(0.0702)
features.11.conv.0 tensor(0.7276)
features.11.conv.3 tensor(0.6454)
features.11.conv.6 tensor(0.8563)
features.12.conv.0 tensor(0.6829)
features.12.conv.3 tensor(0.6692)
features.12.conv.6 tensor(0.7644)
features.13.conv.0 tensor(0.2443)
features.13.conv.3 tensor(0.4892)
features.13.conv.6 tensor(0.0912)
features.14.conv.0 tensor(0.8633)
features.14.conv.3 tensor(0.8189)
features.14.conv.6 tensor(0.9379)
features.15.conv.0 tensor(0.8297)
features.15.conv.3 tensor(0.8259)
features.15.conv.6 tensor(0.9489)
features.16.conv.0 tensor(0.6155)
features.16.conv.3 tensor(0.7873)
features.16.conv.6 tensor(0.6563)
conv.0 tensor(0.0892)
tensor(1168442.) 2188896.0
INFO - Validation [14][   40/   40]   Loss 0.450964   Top1 85.120000   Top5 99.340000   BatchTime 0.090927
INFO - ==> Top1: 85.120    Top5: 99.340    Loss: 0.451
INFO - ==> Sparsity : 0.534
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.240   Top5: 99.480]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
0.68465525
tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
0.68453282
tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
0.68451738
tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
0.68441427
tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>)
0.68438089
tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
0.68439597
tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
0.68468672
tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
0.68494087
tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
0.68496585
tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
0.68522745
tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
0.68495077
tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
0.68527055
tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
0.68518049
tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)
0.68508148
tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
0.68480241
tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)
0.68479282
tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)
0.68496680
tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
0.68518740
tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
0.68492687
tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
0.68507165
tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)
0.68519402
tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)
0.68519872
tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
0.68535572
tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
0.68535024
tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [15][   20/  196]   Loss 0.279670   Top1 90.683594   Top5 99.804688   BatchTime 0.324135   LR 0.000212
0.68491530
tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
0.68531132
tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
0.68553555
tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
0.68547589
tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
0.68528682
tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>)
0.68540674
tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>)
0.68563604
tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)
0.68534696
tensor(0.4827, device='cuda:0', grad_fn=<AddBackward0>)
0.68510205
tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>)
0.68491632
tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
0.68455356
tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
0.68456459
tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
0.68465358
tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
0.68444985
tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
0.68450236
tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
0.68432689
tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [15][   40/  196]   Loss 0.292790   Top1 90.292969   Top5 99.746094   BatchTime 0.285168   LR 0.000211
0.68410927
tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
0.68404156
tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>)
0.68397671
tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
0.68358511
tensor(0.3513, device='cuda:0', grad_fn=<AddBackward0>)
0.68371367
tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
0.68348265
tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)
0.68332112
tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
0.68338627
tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>)
0.68328589
tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>)
0.68358415
tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
0.68297404
tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
0.68273121
tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)
0.68284982
tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>)
0.68290842
tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
0.68312567
tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)
0.68302459
tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
0.68316787
tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)
0.68327397
tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
0.68327588
tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
0.68267047
tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>)
0.68274903
tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
0.68259543
tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>)
0.68245906
tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
0.68238056
tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [15][   60/  196]   Loss 0.306478   Top1 89.817708   Top5 99.680990   BatchTime 0.274254   LR 0.000209
0.68236113
tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)
0.68256617
tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)
0.68256336
tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
0.68233579
tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)
0.68243057
tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>)
0.68235010
tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
0.68245894
tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
0.68362117
tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
0.68355751
tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
0.68336755
tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>)
0.68355292
tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)
0.68349290
tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)
0.68342072
tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
0.68339396
tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
0.68323755
tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [15][   80/  196]   Loss 0.312253   Top1 89.643555   Top5 99.702148   BatchTime 0.270671   LR 0.000208
0.68334097
tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
0.68335944
tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
0.68326783
tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)
0.68292826
tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)
0.68292534
tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)
0.68282181
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.68287832
tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)
0.68307626
tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
0.68280870
tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)
0.68275309
tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>)
0.68284851
tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)
0.68283790
tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
0.68281239
tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
0.68269056
tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
0.68257666
tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
0.68281525
tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
0.68279916
tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
0.68274212
tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
0.68241668
tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
0.68245113
tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>)
0.68260944
tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
0.68233162
tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
0.68235141
tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>)
0.68243271
tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [15][  100/  196]   Loss 0.312316   Top1 89.574219   Top5 99.710938   BatchTime 0.267767   LR 0.000206
0.68226928
tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
0.68195277
tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)
0.68193144
tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
0.68203098
tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
0.68217593
tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
0.68210548
tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>)
0.68218780
tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
0.68240905
tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
0.68230075
tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>)
0.68217647
tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
0.68242717
tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
0.68229091
tensor(0.3480, device='cuda:0', grad_fn=<AddBackward0>)
0.68222934
tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>)
0.68225151
tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>)
0.68211877
tensor(0.3183, device='cuda:0', grad_fn=<AddBackward0>)
0.68161446
tensor(0.4210, device='cuda:0', grad_fn=<AddBackward0>)
0.68152100
tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
0.68153256
tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
0.68146616
tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
0.68120599
tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
0.68129563
tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>)
0.68129224
tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
0.68127245
tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
0.68115819
tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [15][  120/  196]   Loss 0.315818   Top1 89.407552   Top5 99.703776   BatchTime 0.264669   LR 0.000205
0.68093258
tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
0.68104553
tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)
0.68114334
tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
0.68121171
tensor(0.3454, device='cuda:0', grad_fn=<AddBackward0>)
0.68122876
tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)
0.68117559
tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>)
0.68121290
tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
0.68114269
tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
0.68118316
tensor(0.4480, device='cuda:0', grad_fn=<AddBackward0>)
0.68120980
tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)
0.68121600
tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)
0.68108636
tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
0.68087971
tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)
0.68089366
tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>)
0.68085849
INFO - Training [15][  140/  196]   Loss 0.315639   Top1 89.338728   Top5 99.720982   BatchTime 0.264641   LR 0.000203
tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
0.68079895
tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)
0.68072939
tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
0.68078953
tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
0.68078506
tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)
0.68091470
tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
0.68103391
tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)
0.68099135
tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)
0.68101412
tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>)
0.68075228
tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)
0.68083459
tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>)
0.68092626
tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
0.68099898
tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
0.68103105
tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>)
0.68104225
tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)
0.68132657
tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)
0.68096900
tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
0.68119723
tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
0.68118030
tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
0.68103302
tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)
0.68097585
tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
0.68104678
tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
0.68104488
tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
0.68104857
tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [15][  160/  196]   Loss 0.317124   Top1 89.282227   Top5 99.714355   BatchTime 0.264019   LR 0.000201
0.68097121
tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
0.68087792
tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
0.68135351
tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>)
0.68145502
tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
0.68103999
tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
0.68087077
tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
0.68080968
tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
0.68056846
tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
0.68053186
tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)
0.68069768
tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
0.68065757
tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
0.68073446
tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
0.68036836
tensor(0.4603, device='cuda:0', grad_fn=<AddBackward0>)
0.68000036
tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
0.68018198
tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)
0.68039024
tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [15][  180/  196]   Loss 0.316977   Top1 89.229601   Top5 99.709201   BatchTime 0.262604   LR 0.000200
0.68051666
tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
0.68042809
tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
0.68033892
tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>)
0.68026763
tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
0.68027163
tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>)
0.68028998
tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)
0.68017054
tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)
0.68001133
tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
0.68015373
tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
0.68016773
tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>)
0.68027341
tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
0.68022251
tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
0.67990506
tensor(0.4450, device='cuda:0', grad_fn=<AddBackward0>)
0.67985541
tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
0.68004853
tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 89.162    Top5: 99.706    Loss: 0.319
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [15][   20/   40]   Loss 0.440681   Top1 85.332031   Top5 99.335938   BatchTime 0.122869
features.0.conv.0 tensor(0.2743)
features.0.conv.3 tensor(0.1641)
features.1.conv.0 tensor(0.0430)
features.1.conv.3 tensor(0.0718)
features.1.conv.6 tensor(0.0855)
features.2.conv.0 tensor(0.0998)
features.2.conv.3 tensor(0.3534)
features.2.conv.6 tensor(0.2572)
features.3.conv.0 tensor(0.0582)
features.3.conv.3 tensor(0.0856)
features.3.conv.6 tensor(0.1133)
features.4.conv.0 tensor(0.0675)
features.4.conv.3 tensor(0.3073)
features.4.conv.6 tensor(0.1963)
features.5.conv.0 tensor(0.2591)
features.5.conv.3 tensor(0.4161)
features.5.conv.6 tensor(0.1175)
features.6.conv.0 tensor(0.0560)
features.6.conv.3 tensor(0.0532)
features.6.conv.6 tensor(0.0882)
features.7.conv.0 tensor(0.2186)
features.7.conv.3 tensor(0.4531)
features.7.conv.6 tensor(0.3246)
features.8.conv.0 tensor(0.3993)
features.8.conv.3 tensor(0.5399)
features.8.conv.6 tensor(0.1542)
features.9.conv.0 tensor(0.3761)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.4922)
features.10.conv.0 tensor(0.0681)
features.10.conv.3 tensor(0.0969)
features.10.conv.6 tensor(0.0696)
features.11.conv.0 tensor(0.7205)
features.11.conv.3 tensor(0.6470)
features.11.conv.6 tensor(0.8649)
features.12.conv.0 tensor(0.6966)
features.12.conv.3 tensor(0.6676)
features.12.conv.6 tensor(0.7781)
features.13.conv.0 tensor(0.2448)
features.13.conv.3 tensor(0.4904)
features.13.conv.6 tensor(0.0912)
features.14.conv.0 tensor(0.8705)
features.14.conv.3 tensor(0.8196)
features.14.conv.6 tensor(0.9436)
features.15.conv.0 tensor(0.8387)
features.15.conv.3 tensor(0.8258)
features.15.conv.6 tensor(0.9499)
features.16.conv.0 tensor(0.6286)
features.16.conv.3 tensor(0.7877)
features.16.conv.6 tensor(0.6648)
conv.0 tensor(0.0889)
tensor(1180072.) 2188896.0
INFO - Validation [15][   40/   40]   Loss 0.420431   Top1 85.750000   Top5 99.510000   BatchTime 0.090642
INFO - ==> Top1: 85.750    Top5: 99.510    Loss: 0.420
INFO - ==> Sparsity : 0.539
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.240   Top5: 99.480]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
0.68001074
tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)
0.67984480
tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)
0.68007463
tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
0.67994446
tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
0.67995679
tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)
0.67974871
tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
0.67949551
tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)
0.67954403
tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>)
0.67939079
tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>)
0.67954147
tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
0.67983949
tensor(0.4520, device='cuda:0', grad_fn=<AddBackward0>)
0.67989594
tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)
0.67985958
tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)
0.67986435
tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
0.68013245
tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
0.67992699
tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
0.68007463
tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
0.67981911
tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)
0.68010402
tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)
0.68062884
tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
0.68058115
tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [16][   20/  196]   Loss 0.302630   Top1 90.019531   Top5 99.667969   BatchTime 0.330088   LR 0.000197
0.68036878
tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>)
0.68034375
tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>)
0.68031096
tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
0.68015426
tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)
0.68031275
tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)
0.68008804
tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)
0.67995870
tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
0.68005627
tensor(0.3187, device='cuda:0', grad_fn=<AddBackward0>)
0.68023467
tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
0.68013269
tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)
0.67991620
tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
0.68001455
tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
0.67996967
tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>)
0.68005502
tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)
0.67994851
tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
0.67990178
tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>)
0.67982346
tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>)
0.67986804
tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
0.67989677
tensor(0.4468, device='cuda:0', grad_fn=<AddBackward0>)
0.68002254
tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>)
0.67979437
tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
0.67989910
tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
0.67979670
tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
0.67989475
tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [16][   40/  196]   Loss 0.304850   Top1 89.697266   Top5 99.707031   BatchTime 0.290360   LR 0.000195
0.67985684
tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>)
0.67983538
tensor(0.3376, device='cuda:0', grad_fn=<AddBackward0>)
0.67979836
tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
0.67965573
tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>)
0.67970556
tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)
0.67978424
tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
0.67965823
tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
0.67952180
tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>)
0.67941576
tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)
0.67943662
tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
0.67943269
tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
0.67925912
tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)
0.67927486
tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
0.67928970
tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
0.67945725
tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [16][   60/  196]   Loss 0.302761   Top1 89.746094   Top5 99.726562   BatchTime 0.281926   LR 0.000194
0.67979193
tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)
0.67975837
tensor(0.3055, device='cuda:0', grad_fn=<AddBackward0>)
0.67950600
tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
0.67907029
tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
0.67905247
tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
0.67910028
tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
0.67897123
tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
0.67892337
tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
0.67876941
tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)
0.67874712
tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)
0.67886722
tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
0.67907292
tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
0.67903870
tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
0.67894810
tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
0.67873800
tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
0.67859924
tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
0.67860347
tensor(0.3433, device='cuda:0', grad_fn=<AddBackward0>)
0.67864317
tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
0.67861414
tensor(0.3296, device='cuda:0', grad_fn=<AddBackward0>)
0.67881572
tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
0.67872542
tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
0.67876750
tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
0.67887229
tensor(0.4498, device='cuda:0', grad_fn=<AddBackward0>)
0.67878127
tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)
0.67899191
tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [16][   80/  196]   Loss 0.301839   Top1 89.804688   Top5 99.711914   BatchTime 0.290768   LR 0.000192
0.67887980
tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
0.67874235
tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)
0.67874801
tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
0.67875367
tensor(0.3624, device='cuda:0', grad_fn=<AddBackward0>)
0.67878592
tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>)
0.67862105
tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)
0.67844999
tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>)
0.67881101
tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
0.67902231
tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
0.67919856
tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
0.67932075
tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
0.67896330
tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
0.67880034
tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
0.67868829
tensor(0.3879, device='cuda:0', grad_fn=<AddBackward0>)
0.67861784
tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
0.67867899
tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
0.67877001
tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
0.67857701
tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
0.67819613
tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [16][  100/  196]   Loss 0.302957   Top1 89.777344   Top5 99.714844   BatchTime 0.297025   LR 0.000190
0.67823660
tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>)
0.67802787
tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)
0.67795658
tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)
0.67784488
tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)
0.67785859
tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)
0.67765087
tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
0.67734665
tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
0.67741448
tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
0.67742807
tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
0.67724878
tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>)
0.67693514
tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>)
0.67677504
tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
0.67679179
tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
0.67705631
tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
0.67696816
tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>)
0.67668992
tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
0.67672724
tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
0.67694455
tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)
0.67701596
tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
0.67679256
tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
0.67668539
tensor(0.4694, device='cuda:0', grad_fn=<AddBackward0>)
0.67662507
tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
0.67673206
tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
0.67687947
tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [16][  120/  196]   Loss 0.304361   Top1 89.768880   Top5 99.713542   BatchTime 0.292007   LR 0.000188
0.67670417
tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>)
0.67663026
tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
0.67674178
tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)
0.67699379
tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
0.67719865
tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
0.67715120
tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
0.67691362
tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
0.67679238
tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
0.67665154
tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)
0.67659634
tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
0.67665410
tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
0.67659688
tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
0.67674971
tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)
0.67668629
tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
0.67651898
tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
0.67643571
tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [16][  140/  196]   Loss 0.307191   Top1 89.631696   Top5 99.701451   BatchTime 0.286370   LR 0.000187
0.67671525
tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
0.67671359
tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
0.67668253
tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)
0.67667300
tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)
0.67617035
tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>)
0.67595267
tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)
0.67593855
tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
0.67581707
tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
0.67549878
tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)
0.67529124
tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
0.67518842
tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>)
0.67515111
tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)
0.67520714
tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
0.67550212
tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)
0.67555034
tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
0.67540842
tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)
0.67537338
tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
0.67550302
tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
0.67550319
tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
0.67532277
tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
0.67549133
tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)
0.67600256
tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
0.67564172
tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [16][  160/  196]   Loss 0.306697   Top1 89.614258   Top5 99.716797   BatchTime 0.281971   LR 0.000185
0.67533201
tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
0.67507130
tensor(0.3609, device='cuda:0', grad_fn=<AddBackward0>)
0.67498118
tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
0.67498755
tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
0.67506242
tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)
0.67488796
tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)
0.67493528
tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)
0.67493886
tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
0.67479223
tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
0.67472482
tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
0.67462838
tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
0.67434299
tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
0.67413723
tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
0.67390305
tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)
0.67388111
tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [16][  180/  196]   Loss 0.305633   Top1 89.709201   Top5 99.713542   BatchTime 0.280209   LR 0.000183
0.67383409
tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
0.67384541
tensor(0.4052, device='cuda:0', grad_fn=<AddBackward0>)
0.67394978
tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)
0.67378545
tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
0.67384636
tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
0.67370170
tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)
0.67354810
tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
0.67374057
tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
0.67396110
tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>)
0.67381179
tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>)
0.67373621
tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
0.67384684
tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
0.67369527
tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
0.67345178
tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 89.676    Top5: 99.710    Loss: 0.307
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [16][   20/   40]   Loss 0.438616   Top1 85.839844   Top5 99.160156   BatchTime 0.130892
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1562)
features.1.conv.0 tensor(0.0475)
features.1.conv.3 tensor(0.0694)
features.1.conv.6 tensor(0.0859)
features.2.conv.0 tensor(0.0807)
features.2.conv.3 tensor(0.3519)
features.2.conv.6 tensor(0.3330)
features.3.conv.0 tensor(0.0677)
features.3.conv.3 tensor(0.0810)
features.3.conv.6 tensor(0.1109)
features.4.conv.0 tensor(0.0669)
features.4.conv.3 tensor(0.3079)
features.4.conv.6 tensor(0.2002)
features.5.conv.0 tensor(0.2586)
features.5.conv.3 tensor(0.4172)
features.5.conv.6 tensor(0.1182)
features.6.conv.0 tensor(0.0534)
features.6.conv.3 tensor(0.0503)
features.6.conv.6 tensor(0.0840)
features.7.conv.0 tensor(0.2173)
features.7.conv.3 tensor(0.4473)
features.7.conv.6 tensor(0.3154)
features.8.conv.0 tensor(0.4150)
features.8.conv.3 tensor(0.5425)
features.8.conv.6 tensor(0.1652)
features.9.conv.0 tensor(0.3902)
features.9.conv.3 tensor(0.5668)
features.9.conv.6 tensor(0.5075)
features.10.conv.0 tensor(0.0671)
features.10.conv.3 tensor(0.0920)
features.10.conv.6 tensor(0.0728)
features.11.conv.0 tensor(0.7222)
features.11.conv.3 tensor(0.6453)
features.11.conv.6 tensor(0.8742)
features.12.conv.0 tensor(0.6813)
features.12.conv.3 tensor(0.6686)
features.12.conv.6 tensor(0.8081)
features.13.conv.0 tensor(0.2444)
features.13.conv.3 tensor(0.4932)
features.13.conv.6 tensor(0.0907)
features.14.conv.0 tensor(0.8735)
features.14.conv.3 tensor(0.8188)
features.14.conv.6 tensor(0.9461)
features.15.conv.0 tensor(0.8418)
features.15.conv.3 tensor(0.8266)
features.15.conv.6 tensor(0.9512)
features.16.conv.0 tensor(0.6345)
features.16.conv.3 tensor(0.7877)
features.16.conv.6 tensor(0.6700)
conv.0 tensor(0.0882)
tensor(1186507.) 2188896.0
INFO - Validation [16][   40/   40]   Loss 0.437058   Top1 85.600000   Top5 99.370000   BatchTime 0.092992
INFO - ==> Top1: 85.600    Top5: 99.370    Loss: 0.437
INFO - ==> Sparsity : 0.542
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.240   Top5: 99.480]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
0.67341322
tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
0.67336845
tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
0.67341584
tensor(0.3556, device='cuda:0', grad_fn=<AddBackward0>)
0.67351997
tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
0.67351872
tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
0.67329824
tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>)
0.67343509
tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
0.67318887
tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
0.67312199
tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)
0.67279083
tensor(0.3008, device='cuda:0', grad_fn=<AddBackward0>)
0.67239088
tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)
0.67209679
tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
0.67211878
tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
0.67202425
tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
0.67164898
tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
0.67135549
tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>)
0.67133385
tensor(0.2824, device='cuda:0', grad_fn=<AddBackward0>)
0.67134732
tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)
0.67135507
tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>)
0.67135483
tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)
0.67139602
tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
0.67187345
tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
0.67199981
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.67154211
tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
0.67149836
tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>)
0.67143744
tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [17][   20/  196]   Loss 0.294424   Top1 89.863281   Top5 99.921875   BatchTime 0.347767   LR 0.000180
0.67137963
tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)
0.67115706
tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)
0.67097718
tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
0.67107344
tensor(0.3082, device='cuda:0', grad_fn=<AddBackward0>)
0.67138249
tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>)
0.67149001
tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)
0.67148155
tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
0.67129636
tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
0.67121965
tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
0.67119813
tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
0.67108625
tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>)
0.67107540
tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
0.67096955
tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
0.67075044
tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)
0.67070556
tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
0.67056721
INFO - Training [17][   40/  196]   Loss 0.290680   Top1 90.000000   Top5 99.853516   BatchTime 0.300552   LR 0.000178
tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
0.67071223
tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>)
0.67096317
tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
0.67127222
tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
0.67125130
tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
0.67095423
tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)
0.67099917
tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
0.67104739
tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
0.67070931
tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
0.67050612
tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
0.67038614
tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)
0.67037779
tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
0.67036182
tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
0.67044055
tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
0.67040128
tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>)
0.67034376
tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
0.67043430
tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)
0.67052525
tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
0.67038041
tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
0.67033195
tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
0.67022574
tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
0.67012048
tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
0.67001152
tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)
0.66999775
tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>)
0.66997880
tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [17][   60/  196]   Loss 0.287159   Top1 90.260417   Top5 99.811198   BatchTime 0.282508   LR 0.000176
0.66987193
tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
0.66971052
tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
0.66987026
tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
0.66994703
tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
0.66991884
tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
0.66992044
tensor(0.2949, device='cuda:0', grad_fn=<AddBackward0>)
0.66954398
tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
0.66931278
tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
0.66933745
tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
0.66891056
tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)
0.66859323
tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
0.66850162
tensor(0.1661, device='cuda:0', grad_fn=<AddBackward0>)
0.66829896
tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)
0.66814333
tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
0.66832221
tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [17][   80/  196]   Loss 0.290499   Top1 90.161133   Top5 99.785156   BatchTime 0.276734   LR 0.000175
0.66821218
tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>)
0.66824555
tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
0.66797888
tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)
0.66793489
tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)
0.66815048
tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
0.66822225
tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
0.66827011
tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>)
0.66818529
tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
0.66822475
tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>)
0.66826010
tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
0.66827005
tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)
0.66849303
tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>)
0.66868156
tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
0.66846222
tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>)
0.66847664
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.66867214
tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
0.66901386
tensor(0.4171, device='cuda:0', grad_fn=<AddBackward0>)
0.66908520
tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
0.66904926
tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
0.66913438
tensor(0.3697, device='cuda:0', grad_fn=<AddBackward0>)
0.66916955
tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
0.66951424
tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)
0.66931963
tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)
0.66924328
tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [17][  100/  196]   Loss 0.291686   Top1 90.085938   Top5 99.750000   BatchTime 0.272080   LR 0.000173
0.66923660
tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>)
0.66942722
tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)
0.66935664
tensor(0.3516, device='cuda:0', grad_fn=<AddBackward0>)
0.66946691
tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)
0.66980833
tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
0.66989988
tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)
0.66974622
tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
0.66960126
tensor(0.3730, device='cuda:0', grad_fn=<AddBackward0>)
0.66961247
tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)
0.66982788
tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
0.66973168
tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>)
0.66957372
tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
0.66925567
tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
0.66873240
tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
0.66826624
tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>)
0.66806895
tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)
0.66794002
INFO - Training [17][  120/  196]   Loss 0.293046   Top1 90.055339   Top5 99.733073   BatchTime 0.267298   LR 0.000171
tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>)
0.66773057
tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
0.66780555
tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
0.66762680
tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
0.66751444
tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
0.66745150
tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
0.66759229
tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
0.66768432
tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
0.66762555
tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)
0.66777647
tensor(0.3068, device='cuda:0', grad_fn=<AddBackward0>)
0.66788977
tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)
0.66785580
tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
0.66767657
tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
0.66755402
tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
0.66779232
tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
0.66803843
tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
0.66789156
tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
0.66770935
tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
0.66753781
tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
0.66754365
tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
0.66760212
tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>)
0.66744286
tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
0.66749752
tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [17][  140/  196]   Loss 0.290219   Top1 90.172991   Top5 99.734933   BatchTime 0.266400   LR 0.000169
0.66746163
tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)
0.66757226
tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)
0.66760051
tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
0.66759175
tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
0.66754144
tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
0.66777360
tensor(0.3392, device='cuda:0', grad_fn=<AddBackward0>)
0.66908079
tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)
0.66912889
tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)
0.66900498
tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)
0.66900969
tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)
0.66902119
tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
0.66897237
tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
0.66881770
tensor(0.3498, device='cuda:0', grad_fn=<AddBackward0>)
0.66881156
tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
0.66864496
tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)
0.66862410
tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
0.66868007
tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)
0.66869545
tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)
0.66868407
tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
0.66848046
tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
0.66845661
tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>)
0.66856700
tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [17][  160/  196]   Loss 0.292856   Top1 90.087891   Top5 99.726562   BatchTime 0.266910   LR 0.000167
0.66870624
tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
0.66868442
tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)
0.66897547
tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>)
0.66885197
tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
0.66885859
tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
0.66901129
tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
0.66892761
tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
0.66887701
tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>)
0.66889256
tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)
0.66847807
tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
0.66832483
tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>)
0.66833299
tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
0.66835332
tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
0.66846937
tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
0.66880143
tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
0.66862756
tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [17][  180/  196]   Loss 0.290377   Top1 90.177951   Top5 99.741753   BatchTime 0.266893   LR 0.000165
0.66848367
tensor(0.3510, device='cuda:0', grad_fn=<AddBackward0>)
0.66839653
tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
0.66851461
tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
0.66838205
tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
0.66819966
tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>)
0.66797453
tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
0.66803896
tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>)
0.66796517
tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
0.66800135
tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)
0.66813296
tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
0.66814142
tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
0.66831166
tensor(0.2997, device='cuda:0', grad_fn=<AddBackward0>)
0.66830498
tensor(0.2896, device='cuda:0', grad_fn=<AddBackward0>)
0.66796339
tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 90.154    Top5: 99.736    Loss: 0.291
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [17][   20/   40]   Loss 0.412791   Top1 86.308594   Top5 99.570312   BatchTime 0.120433
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1719)
features.1.conv.0 tensor(0.0449)
features.1.conv.3 tensor(0.0671)
features.1.conv.6 tensor(0.0903)
features.2.conv.0 tensor(0.0938)
features.2.conv.3 tensor(0.3511)
features.2.conv.6 tensor(0.3406)
features.3.conv.0 tensor(0.0720)
features.3.conv.3 tensor(0.0795)
features.3.conv.6 tensor(0.1126)
features.4.conv.0 tensor(0.0641)
features.4.conv.3 tensor(0.3056)
features.4.conv.6 tensor(0.1963)
features.5.conv.0 tensor(0.2319)
features.5.conv.3 tensor(0.4184)
features.5.conv.6 tensor(0.1198)
features.6.conv.0 tensor(0.0521)
features.6.conv.3 tensor(0.0521)
features.6.conv.6 tensor(0.0869)
features.7.conv.0 tensor(0.2122)
features.7.conv.3 tensor(0.4470)
features.7.conv.6 tensor(0.3224)
features.8.conv.0 tensor(0.4455)
features.8.conv.3 tensor(0.5417)
features.8.conv.6 tensor(0.1602)
features.9.conv.0 tensor(0.4017)
features.9.conv.3 tensor(0.5663)
features.9.conv.6 tensor(0.5377)
features.10.conv.0 tensor(0.0651)
features.10.conv.3 tensor(0.0972)
features.10.conv.6 tensor(0.0699)
features.11.conv.0 tensor(0.7348)
features.11.conv.3 tensor(0.6458)
features.11.conv.6 tensor(0.8771)
features.12.conv.0 tensor(0.6800)
features.12.conv.3 tensor(0.6686)
features.12.conv.6 tensor(0.8078)
features.13.conv.0 tensor(0.2449)
features.13.conv.3 tensor(0.4904)
features.13.conv.6 tensor(0.0917)
features.14.conv.0 tensor(0.8714)
features.14.conv.3 tensor(0.8196)
features.14.conv.6 tensor(0.9444)
features.15.conv.0 tensor(0.8438)
features.15.conv.3 tensor(0.8269)
features.15.conv.6 tensor(0.9526)
features.16.conv.0 tensor(0.6400)
features.16.conv.3 tensor(0.7877)
features.16.conv.6 tensor(0.6781)
conv.0 tensor(0.0883)
tensor(1192234.) 2188896.0
INFO - Validation [17][   40/   40]   Loss 0.409213   Top1 86.400000   Top5 99.660000   BatchTime 0.088701
INFO - ==> Top1: 86.400    Top5: 99.660    Loss: 0.409
INFO - ==> Sparsity : 0.545
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 86.400   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
0.66787785
tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>)
0.66791761
tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
0.66802961
tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
0.66823453
tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
0.66831964
tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)
0.66833156
tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>)
0.66852176
tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
0.66818774
tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)
0.66828221
tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
0.66816777
tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
0.66830879
tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)
0.66836661
tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
0.66828489
tensor(0.3104, device='cuda:0', grad_fn=<AddBackward0>)
0.66822714
tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)
0.66849893
tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
0.66837794
tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>)
0.66809511
tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
0.66811270
tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)
0.66808093
tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
0.66811544
tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [18][   20/  196]   Loss 0.276194   Top1 90.761719   Top5 99.843750   BatchTime 0.327243   LR 0.000162
0.66823399
tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
0.66814953
tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
0.66803062
tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
0.66793329
tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
0.66776317
tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
0.66780186
tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
0.66767681
tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
0.66737086
tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
0.66738331
tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>)
0.66739953
tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
0.66747326
tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>)
0.66756546
tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)
0.66761738
tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
0.66753691
tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
0.66755903
tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
0.66761631
tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
0.66775864
tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)
0.66767812
tensor(0.3297, device='cuda:0', grad_fn=<AddBackward0>)
0.66733629
tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
0.66722846
tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
0.66733921
tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
0.66714025
tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
0.66699332
tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
0.66692549
tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [18][   40/  196]   Loss 0.269222   Top1 91.103516   Top5 99.853516   BatchTime 0.288936   LR 0.000160
0.66683626
tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
0.66674089
tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
0.66684645
tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
0.66720587
tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
0.66704571
tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
0.66701669
tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>)
0.66696221
tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
0.66695231
tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
0.66704369
tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
0.66698468
tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
0.66688544
tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
0.66692376
tensor(0.4345, device='cuda:0', grad_fn=<AddBackward0>)
0.66686749
tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
0.66707218
tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
0.66707855
tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)
0.66683006
tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [18][   60/  196]   Loss 0.269505   Top1 91.165365   Top5 99.817708   BatchTime 0.275869   LR 0.000158
0.66688538
tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
0.66684657
tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
0.66661382
tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
0.66656250
tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
0.66653216
tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
0.66632599
tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
0.66640145
tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>)
0.66642183
tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
0.66661566
tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
0.66661054
tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
0.66664189
tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>)
0.66663611
tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>)
0.66666460
tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
0.66661769
tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
0.66680056
tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
0.66669285
tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
0.66670740
tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
0.66657764
tensor(0.3173, device='cuda:0', grad_fn=<AddBackward0>)
0.66644055
tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
0.66647011
tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>)
0.66643804
tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
0.66630834
tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
0.66644657
tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
0.66624451
tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [18][   80/  196]   Loss 0.268300   Top1 91.093750   Top5 99.799805   BatchTime 0.269969   LR 0.000156
0.66620231
tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>)
0.66629940
tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>)
0.66643703
tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)
0.66631091
tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)
0.66617858
tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)
0.66603595
tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
0.66574383
tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
0.66558522
tensor(0.2949, device='cuda:0', grad_fn=<AddBackward0>)
0.66551167
tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
0.66606164
tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)
0.66610485
tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
0.66557503
tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
0.66571099
tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>)
0.66561419
tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)
0.66525346
tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>)
0.66516429
tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [18][  100/  196]   Loss 0.271766   Top1 90.925781   Top5 99.796875   BatchTime 0.264680   LR 0.000154
0.66510922
tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
0.66500884
tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
0.66505331
tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>)
0.66505265
tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
0.66538012
tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
0.66509616
tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
0.66483963
tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
0.66461742
tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
0.66453308
tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
0.66461241
tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
0.66457582
tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
0.66450649
tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
0.66419816
tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)
0.66416132
tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
0.66420341
tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
0.66399962
tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
0.66391683
tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
0.66395456
tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
0.66383934
tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)
0.66367108
tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
0.66348302
tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
0.66339588
tensor(0.4263, device='cuda:0', grad_fn=<AddBackward0>)
0.66327929
tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)
0.66305745
tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [18][  120/  196]   Loss 0.271627   Top1 90.882161   Top5 99.794922   BatchTime 0.262960   LR 0.000152
0.66297442
tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
0.66292048
tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
0.66288555
tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
0.66277158
tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
0.66256434
tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)
0.66248673
tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
0.66256624
tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
0.66248369
tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
0.66233850
tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
0.66228551
tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
0.66226792
tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
0.66241676
tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
0.66210139
tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
0.66225523
tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>)
0.66256630
tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [18][  140/  196]   Loss 0.272430   Top1 90.811942   Top5 99.796317   BatchTime 0.263081   LR 0.000150
0.66244370
tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
0.66209835
tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>)
0.66202813
tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)
0.66206574
tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>)
0.66195148
tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
0.66191739
tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
0.66180331
tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
0.66175902
tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
0.66172665
tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
0.66164738
tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>)
0.66154301
tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
0.66133952
tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
0.66133040
tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)
0.66113317
tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
0.66085953
tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
0.66049880
tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
0.66033316
tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>)
0.66036922
tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>)
0.66050535
tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>)
0.66038287
tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
0.66031265
tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)
0.65974194
tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
0.65955883
tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
0.65947950
tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [18][  160/  196]   Loss 0.272384   Top1 90.839844   Top5 99.794922   BatchTime 0.261436   LR 0.000148
0.65945029
tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
0.65937883
tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)
0.65915155
tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
0.65891266
tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
0.65872413
tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>)
0.65857798
tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
0.65842295
tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
0.65844530
tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
0.65856797
tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
0.65863818
tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
0.65833151
tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
0.65824741
tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>)
0.65825850
tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
0.65776455
tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)
0.65728110
tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
0.65702856
tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [18][  180/  196]   Loss 0.271270   Top1 90.868056   Top5 99.804688   BatchTime 0.259801   LR 0.000146
0.65686113
tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>)
0.65701276
tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)
0.65663600
tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
0.65666270
tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>)
0.65661711
tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
0.65667355
tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
0.65653753
tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
0.65635389
tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)
0.65643227
tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
0.65643334
tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
0.65617424
tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
0.65606219
tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
0.65592170
tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
0.65570706
tensor(0.3575, device='cuda:0', grad_fn=<AddBackward0>)
0.65558296
tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
0.65549463
tensor(0.3068, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 90.792    Top5: 99.806    Loss: 0.273
0.65550190
tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [18][   20/   40]   Loss 0.410865   Top1 86.406250   Top5 99.316406   BatchTime 0.122845
INFO - Validation [18][   40/   40]   Loss 0.400215   Top1 86.660000   Top5 99.480000   BatchTime 0.089925
INFO - ==> Top1: 86.660    Top5: 99.480    Loss: 0.400
INFO - ==> Sparsity : 0.552
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 86.660   Top5: 99.480]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1738)
features.1.conv.0 tensor(0.0378)
features.1.conv.3 tensor(0.0741)
features.1.conv.6 tensor(0.0898)
features.2.conv.0 tensor(0.0992)
features.2.conv.3 tensor(0.3519)
features.2.conv.6 tensor(0.3545)
features.3.conv.0 tensor(0.0718)
features.3.conv.3 tensor(0.0748)
features.3.conv.6 tensor(0.1181)
features.4.conv.0 tensor(0.0545)
features.4.conv.3 tensor(0.3096)
features.4.conv.6 tensor(0.2020)
features.5.conv.0 tensor(0.2487)
features.5.conv.3 tensor(0.4201)
features.5.conv.6 tensor(0.1226)
features.6.conv.0 tensor(0.0583)
features.6.conv.3 tensor(0.0515)
features.6.conv.6 tensor(0.0851)
features.7.conv.0 tensor(0.2153)
features.7.conv.3 tensor(0.4494)
features.7.conv.6 tensor(0.4802)
features.8.conv.0 tensor(0.4496)
features.8.conv.3 tensor(0.5431)
features.8.conv.6 tensor(0.1710)
features.9.conv.0 tensor(0.4074)
features.9.conv.3 tensor(0.5694)
features.9.conv.6 tensor(0.6084)
features.10.conv.0 tensor(0.0701)
features.10.conv.3 tensor(0.1013)
features.10.conv.6 tensor(0.0707)
features.11.conv.0 tensor(0.7397)
features.11.conv.3 tensor(0.6453)
features.11.conv.6 tensor(0.8748)
features.12.conv.0 tensor(0.6794)
features.12.conv.3 tensor(0.6671)
features.12.conv.6 tensor(0.8131)
features.13.conv.0 tensor(0.2446)
features.13.conv.3 tensor(0.4880)
features.13.conv.6 tensor(0.0912)
features.14.conv.0 tensor(0.8735)
features.14.conv.3 tensor(0.8215)
features.14.conv.6 tensor(0.9495)
features.15.conv.0 tensor(0.8487)
features.15.conv.3 tensor(0.8264)
features.15.conv.6 tensor(0.9541)
features.16.conv.0 tensor(0.6428)
features.16.conv.3 tensor(0.7872)
features.16.conv.6 tensor(0.6998)
conv.0 tensor(0.0877)
tensor(1208036.) 2188896.0
0.65559143
tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
0.65519726
tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
0.65497512
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.65494561
tensor(0.1516, device='cuda:0', grad_fn=<AddBackward0>)
0.65480828
tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
0.65445662
tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
0.65430564
tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
0.65430957
tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
0.65424323
tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
0.65410906
tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
0.65430468
tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
0.65418142
tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)
0.65406382
tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)
0.65369916
tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)
0.65352082
tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)
0.65341669
tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
0.65323067
tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
0.65348732
tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)
0.65369850
tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)
0.65358800
tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [19][   20/  196]   Loss 0.243580   Top1 91.738281   Top5 99.882812   BatchTime 0.388799   LR 0.000143
0.65356004
tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
0.65333110
tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
0.65313077
tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
0.65311104
tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)
0.65306479
tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)
0.65296048
tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)
0.65289587
tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
0.65287036
tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
0.65278208
tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
0.65264595
tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
0.65274608
tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
0.65275431
tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
0.65270633
tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
0.65266150
tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
0.65269428
tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>)
0.65264744
tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
0.65246481
tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>)
0.65242690
tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
0.65231520
tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
0.65217990
tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
0.65209645
tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [19][   40/  196]   Loss 0.256538   Top1 91.230469   Top5 99.873047   BatchTime 0.341353   LR 0.000141
0.65210044
tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
0.65209556
tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
0.65221107
tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)
0.65207720
tensor(0.1474, device='cuda:0', grad_fn=<AddBackward0>)
0.65177876
tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)
0.65151393
tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>)
0.65122545
tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
0.65101939
tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>)
0.65094638
tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)
0.65084040
tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
0.65071452
tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
0.65056175
tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
0.65025890
tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)
0.65004987
tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
0.64992416
tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
0.64977175
tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>)
0.64966881
tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)
0.64957243
tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
0.64935690
tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
0.64935303
tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [19][   60/  196]   Loss 0.256562   Top1 91.263021   Top5 99.843750   BatchTime 0.325899   LR 0.000139
0.64936006
tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
0.64907795
tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>)
0.64895797
tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
0.64895636
tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)
0.64906275
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.64902180
tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
0.64873368
tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
0.64857334
tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)
0.64861375
tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
0.64854038
tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>)
0.64846534
tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>)
0.64833540
tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>)
0.64819396
tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
0.64806950
tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
0.64812243
tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
0.64809901
tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
0.64814907
tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
0.64789248
tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
0.64781088
tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)
0.64778495
tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>)
0.64781773
tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
0.64778811
tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [19][   80/  196]   Loss 0.255859   Top1 91.250000   Top5 99.833984   BatchTime 0.314996   LR 0.000137
0.64770764
tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)
0.64741713
tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
0.64733118
tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
0.64731419
tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)
0.64726311
tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
0.64718181
tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
0.64698905
tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
0.64673829
tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
0.64662623
tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
0.64652926
tensor(0.1654, device='cuda:0', grad_fn=<AddBackward0>)
0.64650840
tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
0.64645070
tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
0.64647740
tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
0.64660442
tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>)
0.64678490
tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)
0.64669281
tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
0.64675033
tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
0.64679754
tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)
0.64663142
tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
0.64661789
tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
0.64667469
tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
0.64665616
tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
0.64687777
tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [19][  100/  196]   Loss 0.258631   Top1 91.167969   Top5 99.820312   BatchTime 0.301964   LR 0.000135
0.64728469
tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
0.64698762
tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
0.64701372
tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)
0.64691532
tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)
0.64677739
tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
0.64687335
tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
0.64695472
tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
0.64684129
tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
0.64690697
tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
0.64682508
tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
0.64686549
tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
0.64687419
tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>)
0.64687002
tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)
0.64681876
tensor(0.2857, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [19][  120/  196]   Loss 0.260518   Top1 91.175130   Top5 99.817708   BatchTime 0.300310   LR 0.000133
0.64683342
tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)
0.64684576
tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
0.64674813
tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
0.64671832
tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
0.64669138
tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)
0.64660269
tensor(0.1696, device='cuda:0', grad_fn=<AddBackward0>)
0.64653981
tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
0.64642167
tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
0.64642984
tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
0.64650524
tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)
0.64633328
tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>)
0.64626008
tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
0.64617062
tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
0.64624864
tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
0.64614588
tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>)
0.64602709
tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
0.64599866
tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
0.64607137
tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [19][  140/  196]   Loss 0.260651   Top1 91.236049   Top5 99.810268   BatchTime 0.303161   LR 0.000131
0.64617652
tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>)
0.64604568
tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>)
0.64606136
tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)
0.64611167
tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
0.64590645
tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
0.64581734
tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
0.64589781
tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>)
0.64592469
tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
0.64594215
tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
0.64599824
tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>)
0.64597857
tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)
0.64580047
tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
0.64560515
tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
0.64566857
tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
0.64602625
tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
0.64618790
tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
0.64639449
tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
0.64641464
tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
0.64643425
tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
0.64620882
tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [19][  160/  196]   Loss 0.261340   Top1 91.210938   Top5 99.804688   BatchTime 0.303567   LR 0.000129
0.64621925
tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>)
0.64580292
tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
0.64569026
tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>)
0.64570153
tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
0.64560241
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.64578003
tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
0.64517933
tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
0.64523864
tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)
0.64537698
tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
0.64530563
tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
0.64515740
tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)
0.64519387
tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
0.64534891
tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>)
0.64548999
tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
0.64538360
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.64551669
tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
0.64573628
tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
0.64552993
tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>)
0.64542806
tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
0.64514595
tensor(0.3239, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [19][  180/  196]   Loss 0.261152   Top1 91.226128   Top5 99.800347   BatchTime 0.302918   LR 0.000127
0.64527398
tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)
0.64508796
tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
0.64502084
tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
0.64505607
tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
0.64499289
tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>)
0.64516073
tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
0.64489138
tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
0.64482838
tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
0.64496118
tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
0.64502490
tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
0.64513731
tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
0.64506996
tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)
0.64489937
tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
0.64489180
tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
0.64475757
tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
0.64479887
tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
0.64475232
tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
0.64479923
tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 91.214    Top5: 99.798    Loss: 0.262
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [19][   20/   40]   Loss 0.411077   Top1 86.835938   Top5 99.335938   BatchTime 0.122060
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1816)
features.1.conv.0 tensor(0.0508)
features.1.conv.3 tensor(0.0810)
features.1.conv.6 tensor(0.0920)
features.2.conv.0 tensor(0.0885)
features.2.conv.3 tensor(0.3503)
features.2.conv.6 tensor(0.3976)
features.3.conv.0 tensor(0.0712)
features.3.conv.3 tensor(0.0756)
features.3.conv.6 tensor(0.1168)
features.4.conv.0 tensor(0.0658)
features.4.conv.3 tensor(0.3056)
features.4.conv.6 tensor(0.2342)
features.5.conv.0 tensor(0.2570)
features.5.conv.3 tensor(0.4167)
features.5.conv.6 tensor(0.1211)
features.6.conv.0 tensor(0.0553)
features.6.conv.3 tensor(0.0498)
features.6.conv.6 tensor(0.0849)
features.7.conv.0 tensor(0.2160)
features.7.conv.3 tensor(0.4470)
features.7.conv.6 tensor(0.5642)
features.8.conv.0 tensor(0.4273)
features.8.conv.3 tensor(0.5428)
features.8.conv.6 tensor(0.1632)
features.9.conv.0 tensor(0.4294)
features.9.conv.3 tensor(0.5668)
features.9.conv.6 tensor(0.6368)
features.10.conv.0 tensor(0.0698)
features.10.conv.3 tensor(0.0958)
features.10.conv.6 tensor(0.0711)
features.11.conv.0 tensor(0.7315)
features.11.conv.3 tensor(0.6456)
features.11.conv.6 tensor(0.8756)
features.12.conv.0 tensor(0.6943)
features.12.conv.3 tensor(0.6651)
features.12.conv.6 tensor(0.8177)
features.13.conv.0 tensor(0.2450)
features.13.conv.3 tensor(0.4888)
features.13.conv.6 tensor(0.0899)
features.14.conv.0 tensor(0.8752)
features.14.conv.3 tensor(0.8208)
features.14.conv.6 tensor(0.9462)
features.15.conv.0 tensor(0.8509)
features.15.conv.3 tensor(0.8266)
features.15.conv.6 tensor(0.9528)
features.16.conv.0 tensor(0.6476)
features.16.conv.3 tensor(0.7876)
features.16.conv.6 tensor(0.7457)
conv.0 tensor(0.0874)
tensor(1226203.) 2188896.0
INFO - Validation [19][   40/   40]   Loss 0.400452   Top1 87.070000   Top5 99.510000   BatchTime 0.086792
INFO - ==> Top1: 87.070    Top5: 99.510    Loss: 0.400
INFO - ==> Sparsity : 0.560
INFO - Scoreboard best 1 ==> Epoch [19][Top1: 87.070   Top5: 99.510]
INFO - Scoreboard best 2 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 86.710   Top5: 99.510]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
0.64482808
tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
0.64465350
tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
0.64451373
tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
0.64452869
tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
0.64441872
tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>)
0.64436001
tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
0.64442050
tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
0.64437139
tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
0.64436764
tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
0.64430946
tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
0.64424753
tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
0.64439368
tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
0.64445025
tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
0.64409423
tensor(0.1887, device='cuda:0', grad_fn=<AddBackward0>)
0.64392829
tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
0.64374673
tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>)
0.64355731
tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
0.64344734
tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
0.64333838
tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
0.64286298
tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [20][   20/  196]   Loss 0.223094   Top1 92.558594   Top5 99.765625   BatchTime 0.331000   LR 0.000123
0.64276236
tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
0.64298809
tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
0.64283389
tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)
0.64277691
tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)
0.64264613
tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
0.64252222
tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
0.64239538
tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
0.64230764
tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
0.64234066
tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
0.64239222
tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
0.64263833
tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
0.64277917
tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
0.64268547
tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
0.64257818
tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
0.64258355
tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
0.64256597
tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
0.64265072
tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
0.64301378
tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
0.64255494
tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)
0.64235932
tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
0.64231259
tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
0.64225042
tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
0.64224082
tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
0.64229256
tensor(0.3777, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [20][   40/  196]   Loss 0.240721   Top1 91.972656   Top5 99.785156   BatchTime 0.290797   LR 0.000121
0.64223164
tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
0.64196575
tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
0.64191681
tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
0.64185959
tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
0.64181507
tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)
0.64171731
tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
0.64161098
tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
0.64155263
tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
0.64161772
tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
0.64170903
tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
0.64159381
tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)
0.64143074
tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
0.64147252
tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
0.64146841
tensor(0.1709, device='cuda:0', grad_fn=<AddBackward0>)
0.64135242
tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
0.64134967
tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [20][   60/  196]   Loss 0.238894   Top1 92.050781   Top5 99.791667   BatchTime 0.277212   LR 0.000119
0.64133614
tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)
0.64135969
tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
0.64137334
tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
0.64132613
tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
0.64130002
tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
0.64126664
tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
0.64129764
tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
0.64131916
tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
0.64130706
tensor(0.1636, device='cuda:0', grad_fn=<AddBackward0>)
0.64143825
tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
0.64156389
tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
0.64169365
tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
0.64185536
tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
0.64195919
tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
0.64184201
tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
0.64174420
tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
0.64171767
tensor(0.1616, device='cuda:0', grad_fn=<AddBackward0>)
0.64179450
tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
0.64200628
tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
0.64182162
tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
0.64164019
tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
0.64151436
tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
0.64146739
tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
0.64166981
tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [20][   80/  196]   Loss 0.238633   Top1 92.031250   Top5 99.785156   BatchTime 0.270275   LR 0.000117
0.64182115
tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
0.64188409
tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
0.64148182
tensor(0.2775, device='cuda:0', grad_fn=<AddBackward0>)
0.64140296
tensor(0.2463, device='cuda:0', grad_fn=<AddBackward0>)
0.64145839
tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
0.64136595
tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)
0.64132774
tensor(0.1476, device='cuda:0', grad_fn=<AddBackward0>)
0.64121562
tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
0.64111251
tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
0.64112920
tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
0.64123130
tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
0.64170009
tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
0.64146560
tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
0.64150506
tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
0.64148825
tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
0.64165640
tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [20][  100/  196]   Loss 0.237355   Top1 91.988281   Top5 99.796875   BatchTime 0.266252   LR 0.000115
0.64170784
tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
0.64164096
tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
0.64159513
tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
0.64150047
tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
0.64106363
tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
0.64102989
tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)
0.64116883
tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)
0.64120793
tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
0.64124805
tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
0.64130169
tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
0.64129829
tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
0.64138842
tensor(0.2410, device='cuda:0', grad_fn=<AddBackward0>)
0.64131087
tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
0.64134198
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.64107996
tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)
0.64082032
tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
0.64082062
tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
0.64070189
tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
0.64071327
tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
0.64074510
tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)
0.64087915
tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
0.64098674
tensor(0.1729, device='cuda:0', grad_fn=<AddBackward0>)
0.64114887
tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
0.64114714
tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [20][  120/  196]   Loss 0.239348   Top1 91.868490   Top5 99.811198   BatchTime 0.263403   LR 0.000113
0.64094639
tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
0.64100838
tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)
0.64091688
tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
0.64096779
tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
0.64078480
tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)
0.64054322
tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
0.64052635
tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
0.64072406
tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
0.64085561
tensor(0.1547, device='cuda:0', grad_fn=<AddBackward0>)
0.64109433
tensor(0.3015, device='cuda:0', grad_fn=<AddBackward0>)
0.64110428
tensor(0.1665, device='cuda:0', grad_fn=<AddBackward0>)
0.64096528
tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>)
0.64082199
tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
0.64091134
tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)
0.64078665
tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
0.64077640
tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [20][  140/  196]   Loss 0.239991   Top1 91.872210   Top5 99.821429   BatchTime 0.261506   LR 0.000111
0.64074987
tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
0.64077491
tensor(0.1745, device='cuda:0', grad_fn=<AddBackward0>)
0.64068568
tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
0.64055806
tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)
0.64061993
tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
0.64079499
tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
0.64063579
tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
0.64065796
tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
0.64084935
tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)
0.64062637
tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)
0.64069402
tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>)
0.64069051
tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
0.64046913
tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
0.64058840
tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)
0.64057106
tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>)
0.64058453
tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
0.64055645
tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
0.64052093
tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
0.64080924
tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
0.64031422
tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>)
0.64032227
tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
0.64043200
tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
0.64035845
tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
0.64022720
tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [20][  160/  196]   Loss 0.241254   Top1 91.835938   Top5 99.824219   BatchTime 0.260354   LR 0.000109
0.64015651
tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
0.64009768
tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
0.64001197
tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
0.64009362
tensor(0.1748, device='cuda:0', grad_fn=<AddBackward0>)
0.64060962
tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
0.64044869
tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
0.64043671
tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>)
0.64054894
tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
0.64017063
tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)
0.64015353
tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>)
0.64013147
tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
0.64020449
tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
0.64022857
tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
0.64027309
tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)
0.64014930
tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
0.64020848
tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
0.64026225
tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
0.64002764
tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
0.64024532
tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
0.64023006
tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [20][  180/  196]   Loss 0.241373   Top1 91.788194   Top5 99.832899   BatchTime 0.264008   LR 0.000107
0.64025581
tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
0.64021546
tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
0.64017892
tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>)
0.64015794
tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
0.64008242
tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
0.64010632
tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
0.64031619
tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
0.64016050
tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
0.64015120
tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
0.64030379
tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
0.64035332
tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
0.64029604
tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 91.784    Top5: 99.826    Loss: 0.242
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [20][   20/   40]   Loss 0.384729   Top1 87.343750   Top5 99.589844   BatchTime 0.117446
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1699)
features.1.conv.0 tensor(0.0488)
features.1.conv.3 tensor(0.0741)
features.1.conv.6 tensor(0.0942)
features.2.conv.0 tensor(0.1024)
features.2.conv.3 tensor(0.3480)
features.2.conv.6 tensor(0.4039)
features.3.conv.0 tensor(0.0677)
features.3.conv.3 tensor(0.0841)
features.3.conv.6 tensor(0.1146)
features.4.conv.0 tensor(0.0682)
features.4.conv.3 tensor(0.3032)
features.4.conv.6 tensor(0.2342)
features.5.conv.0 tensor(0.2695)
features.5.conv.3 tensor(0.4172)
features.5.conv.6 tensor(0.1219)
features.6.conv.0 tensor(0.0562)
features.6.conv.3 tensor(0.0515)
features.6.conv.6 tensor(0.0856)
features.7.conv.0 tensor(0.2184)
features.7.conv.3 tensor(0.4517)
features.7.conv.6 tensor(0.5657)
features.8.conv.0 tensor(0.4532)
features.8.conv.3 tensor(0.5396)
features.8.conv.6 tensor(0.1619)
features.9.conv.0 tensor(0.4211)
features.9.conv.3 tensor(0.5683)
features.9.conv.6 tensor(0.6528)
features.10.conv.0 tensor(0.0723)
features.10.conv.3 tensor(0.0935)
features.10.conv.6 tensor(0.0690)
features.11.conv.0 tensor(0.7314)
features.11.conv.3 tensor(0.6470)
features.11.conv.6 tensor(0.8772)
features.12.conv.0 tensor(0.7065)
features.12.conv.3 tensor(0.6649)
features.12.conv.6 tensor(0.8202)
features.13.conv.0 tensor(0.2709)
features.13.conv.3 tensor(0.4890)
features.13.conv.6 tensor(0.0897)
features.14.conv.0 tensor(0.8777)
features.14.conv.3 tensor(0.8204)
features.14.conv.6 tensor(0.9476)
features.15.conv.0 tensor(0.8550)
features.15.conv.3 tensor(0.8264)
features.15.conv.6 tensor(0.9556)
features.16.conv.0 tensor(0.6518)
features.16.conv.3 tensor(0.7875)
features.16.conv.6 tensor(0.7755)
conv.0 tensor(0.0869)
tensor(1240819.) 2188896.0
INFO - Validation [20][   40/   40]   Loss 0.372278   Top1 87.460000   Top5 99.690000   BatchTime 0.085609
INFO - ==> Top1: 87.460    Top5: 99.690    Loss: 0.372
INFO - ==> Sparsity : 0.567
INFO - Scoreboard best 1 ==> Epoch [20][Top1: 87.460   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [19][Top1: 87.070   Top5: 99.510]
INFO - Scoreboard best 3 ==> Epoch [8][Top1: 86.780   Top5: 99.490]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
0.64016771
tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
0.64043677
tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>)
0.64026600
tensor(0.1756, device='cuda:0', grad_fn=<AddBackward0>)
0.64025915
tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
0.64016598
tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
0.63990837
tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)
0.63960505
tensor(0.1686, device='cuda:0', grad_fn=<AddBackward0>)
0.63953346
tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)
0.63963652
tensor(0.1560, device='cuda:0', grad_fn=<AddBackward0>)
0.63978958
tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)
0.64001018
tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
0.63973713
tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
0.63982975
tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
0.63994348
tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>)
0.64018971
tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
0.64022517
tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
0.64026350
tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
0.64001369
tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
0.63983309
tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
0.63982773
tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
0.63963491
tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
0.63962305
tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)
0.63971823
tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [21][   20/  196]   Loss 0.232823   Top1 91.914062   Top5 99.863281   BatchTime 0.347704   LR 0.000104
0.63985062
tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)
0.63983983
tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)
0.63987911
tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
0.63980150
tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
0.63969749
tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
0.63950497
tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
0.63958168
tensor(0.1439, device='cuda:0', grad_fn=<AddBackward0>)
0.63953537
tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
0.63950199
tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
0.63962519
tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
0.63947248
tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
0.63931501
tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
0.63939148
tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)
0.63937974
tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
0.63929147
tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
0.63924193
tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
0.63926780
tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
0.63921225
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.63926202
tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [21][   40/  196]   Loss 0.231178   Top1 92.050781   Top5 99.853516   BatchTime 0.330226   LR 0.000102
0.63918626
tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
0.63921750
tensor(0.1832, device='cuda:0', grad_fn=<AddBackward0>)
0.63919407
tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
0.63916409
tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
0.63914967
tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
0.63924915
tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
0.63904577
tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>)
0.63887775
tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>)
0.63866854
tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
0.63866192
tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)
0.63885963
tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
0.63895655
tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
0.63884139
tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
0.63893926
tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
0.63889170
tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
0.63880956
tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
0.63857865
tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
0.63849938
tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
0.63844419
tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
0.63840181
tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [21][   60/  196]   Loss 0.228328   Top1 92.239583   Top5 99.830729   BatchTime 0.321187   LR 0.000100
0.63836479
tensor(0.1767, device='cuda:0', grad_fn=<AddBackward0>)
0.63832629
tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)
0.63809305
tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
0.63798213
tensor(0.1757, device='cuda:0', grad_fn=<AddBackward0>)
0.63794762
tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
0.63769215
tensor(0.1748, device='cuda:0', grad_fn=<AddBackward0>)
0.63741750
tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
0.63747388
tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
0.63724285
tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
0.63719660
tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
0.63709974
tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)
0.63695598
tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
0.63698936
tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
0.63693798
tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
0.63689804
tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>)
0.63688129
tensor(0.1649, device='cuda:0', grad_fn=<AddBackward0>)
0.63675499
tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
0.63661557
tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>)
0.63657260
tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
0.63652891
tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
0.63666701
tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
0.63672298
tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
0.63660598
tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [21][   80/  196]   Loss 0.226462   Top1 92.373047   Top5 99.853516   BatchTime 0.306866   LR 0.000098
0.63640130
tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
0.63630545
tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
0.63621575
tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
0.63626719
tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
0.63613164
tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
0.63605797
tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
0.63612062
tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
0.63640112
tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
0.63637197
tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)
0.63641965
tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
0.63643903
tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
0.63632214
tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>)
0.63623661
tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
0.63626862
tensor(0.1724, device='cuda:0', grad_fn=<AddBackward0>)
0.63623029
tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>)
0.63619334
tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [21][  100/  196]   Loss 0.230531   Top1 92.222656   Top5 99.855469   BatchTime 0.295742   LR 0.000096
0.63623899
tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
0.63608307
tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>)
0.63608891
tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>)
0.63610232
tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>)
0.63616830
tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)
0.63625425
tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
0.63608849
tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
0.63644874
tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
0.63821983
tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
0.63798022
tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
0.63791543
tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
0.63829672
tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
0.63882202
tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
0.64041567
tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
0.64045155
tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
0.64029759
tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
0.64014238
tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
0.64024460
tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)
0.64036787
tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>)
0.64035296
tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
0.63992155
tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
0.63991332
tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>)
0.64010036
tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
0.64010990
tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [21][  120/  196]   Loss 0.230563   Top1 92.294922   Top5 99.843750   BatchTime 0.288133   LR 0.000094
0.64015138
tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
0.64020646
tensor(0.1506, device='cuda:0', grad_fn=<AddBackward0>)
0.64024782
tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
0.64032245
tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
0.64034224
tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
0.64055139
tensor(0.1758, device='cuda:0', grad_fn=<AddBackward0>)
0.64018810
tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
0.64015186
tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)
0.64017099
tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
0.64024216
tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
0.64034283
tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
0.64041001
tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
0.64042467
tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
0.64047486
tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>)
0.64037812
tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
0.64029169
tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [21][  140/  196]   Loss 0.231797   Top1 92.226562   Top5 99.849330   BatchTime 0.282401   LR 0.000092
0.64028990
tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
0.64031845
tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
0.64004487
tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
0.63993478
tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
0.63995284
tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
0.63997471
tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
0.64002943
tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
0.64001185
tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
0.63980901
tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
0.63958490
tensor(0.2410, device='cuda:0', grad_fn=<AddBackward0>)
0.63967186
tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
0.63958645
tensor(0.1822, device='cuda:0', grad_fn=<AddBackward0>)
0.63953900
tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>)
0.63957852
tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
0.63965762
tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
0.63965255
tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
0.63959807
tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)
0.63940334
tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
0.63958871
tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
0.63942045
tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
0.63934225
tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
0.63904881
tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
0.63920718
tensor(0.1502, device='cuda:0', grad_fn=<AddBackward0>)
0.63931799
tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [21][  160/  196]   Loss 0.230642   Top1 92.253418   Top5 99.841309   BatchTime 0.278696   LR 0.000090
0.63913548
tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
0.63909590
tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
0.63893455
tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
0.63881314
tensor(0.1770, device='cuda:0', grad_fn=<AddBackward0>)
0.63883263
tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
0.63891089
tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>)
0.63874525
tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
0.63871360
tensor(0.1696, device='cuda:0', grad_fn=<AddBackward0>)
0.63874966
tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>)
0.63892323
tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
0.63901556
tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
0.63886070
tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
0.63869256
tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)
0.63864911
tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)
0.63866043
tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)
0.63875812
tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [21][  180/  196]   Loss 0.230826   Top1 92.265625   Top5 99.850260   BatchTime 0.275250   LR 0.000088
0.63889563
tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
0.63869041
tensor(0.1803, device='cuda:0', grad_fn=<AddBackward0>)
0.63873631
tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
0.63863468
tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
0.63872874
tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
0.63858426
tensor(0.2902, device='cuda:0', grad_fn=<AddBackward0>)
0.63845980
tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
0.63850677
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.63853329
tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)
0.63865829
tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
0.63858634
tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
0.63845438
tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>)
0.63847655
tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)
0.63839871
tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
0.63839871
tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 92.168    Top5: 99.852    Loss: 0.231
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 0.382273   Top1 87.929688   Top5 99.335938   BatchTime 0.123988
features.0.conv.0 tensor(0.2917)
features.0.conv.3 tensor(0.1641)
features.1.conv.0 tensor(0.0397)
features.1.conv.3 tensor(0.0729)
features.1.conv.6 tensor(0.0907)
features.2.conv.0 tensor(0.1036)
features.2.conv.3 tensor(0.3503)
features.2.conv.6 tensor(0.4077)
features.3.conv.0 tensor(0.0686)
features.3.conv.3 tensor(0.0802)
features.3.conv.6 tensor(0.1152)
features.4.conv.0 tensor(0.0662)
features.4.conv.3 tensor(0.3021)
features.4.conv.6 tensor(0.2386)
features.5.conv.0 tensor(0.2806)
features.5.conv.3 tensor(0.4184)
features.5.conv.6 tensor(0.1229)
features.6.conv.0 tensor(0.0562)
features.6.conv.3 tensor(0.0521)
features.6.conv.6 tensor(0.0888)
features.7.conv.0 tensor(0.2173)
features.7.conv.3 tensor(0.4494)
features.7.conv.6 tensor(0.5838)
features.8.conv.0 tensor(0.4612)
features.8.conv.3 tensor(0.5382)
features.8.conv.6 tensor(0.1694)
features.9.conv.0 tensor(0.4574)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.6606)
features.10.conv.0 tensor(0.0698)
features.10.conv.3 tensor(0.0969)
features.10.conv.6 tensor(0.0695)
features.11.conv.0 tensor(0.7332)
features.11.conv.3 tensor(0.6458)
features.11.conv.6 tensor(0.8800)
features.12.conv.0 tensor(0.7145)
features.12.conv.3 tensor(0.6651)
features.12.conv.6 tensor(0.8254)
features.13.conv.0 tensor(0.2519)
features.13.conv.3 tensor(0.4867)
features.13.conv.6 tensor(0.0889)
features.14.conv.0 tensor(0.8801)
features.14.conv.3 tensor(0.8205)
features.14.conv.6 tensor(0.9482)
features.15.conv.0 tensor(0.8601)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9560)
features.16.conv.0 tensor(0.6587)
features.16.conv.3 tensor(0.7873)
features.16.conv.6 tensor(0.8053)
conv.0 tensor(0.0879)
tensor(1254506.) 2188896.0
INFO - Validation [21][   40/   40]   Loss 0.372362   Top1 88.000000   Top5 99.540000   BatchTime 0.091443
INFO - ==> Top1: 88.000    Top5: 99.540    Loss: 0.372
INFO - ==> Sparsity : 0.573
INFO - Scoreboard best 1 ==> Epoch [21][Top1: 88.000   Top5: 99.540]
INFO - Scoreboard best 2 ==> Epoch [20][Top1: 87.460   Top5: 99.690]
INFO - Scoreboard best 3 ==> Epoch [19][Top1: 87.070   Top5: 99.510]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
0.63854498
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.63838822
tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
0.63850492
tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
0.63840985
tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
0.63826388
tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
0.63828617
tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
0.63836402
tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)
0.63848901
tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
0.63847923
tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
0.63850725
tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
0.63853914
tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
0.63821948
tensor(0.1677, device='cuda:0', grad_fn=<AddBackward0>)
0.63799888
tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
0.63788658
tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>)
0.63792759
tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
0.63805300
tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
0.63791603
tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
0.63773078
tensor(0.1713, device='cuda:0', grad_fn=<AddBackward0>)
0.63756227
tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
0.63749975
tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
0.63752401
tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
0.63764572
tensor(0.1490, device='cuda:0', grad_fn=<AddBackward0>)
0.63766402
tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
0.63767892
tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>)
0.63760543
tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [22][   20/  196]   Loss 0.213006   Top1 92.851562   Top5 99.902344   BatchTime 0.309337   LR 0.000085
0.63753837
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.63757461
tensor(0.1591, device='cuda:0', grad_fn=<AddBackward0>)
0.63747978
tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
0.63735741
tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
0.63733822
tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
0.63733673
tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>)
0.63743085
tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
0.63764417
tensor(0.1299, device='cuda:0', grad_fn=<AddBackward0>)
0.63736588
tensor(0.1633, device='cuda:0', grad_fn=<AddBackward0>)
0.63733065
tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
0.63718718
tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
0.63709313
tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
0.63699818
tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
0.63703299
tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
0.63692528
tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)
0.63682580
tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
0.63678449
tensor(0.1869, device='cuda:0', grad_fn=<AddBackward0>)
0.63684720
tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
0.63689142
tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)
0.63729477
tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
0.63749957
tensor(0.1657, device='cuda:0', grad_fn=<AddBackward0>)
0.63734871
tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [22][   40/  196]   Loss 0.205955   Top1 93.183594   Top5 99.873047   BatchTime 0.285775   LR 0.000083
0.63707155
tensor(0.1608, device='cuda:0', grad_fn=<AddBackward0>)
0.63697410
tensor(0.1678, device='cuda:0', grad_fn=<AddBackward0>)
0.63673693
tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
0.63667506
tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)
0.63666916
tensor(0.1832, device='cuda:0', grad_fn=<AddBackward0>)
0.63666588
tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
0.63664335
tensor(0.1732, device='cuda:0', grad_fn=<AddBackward0>)
0.63664877
tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
0.63676888
tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
0.63708895
tensor(0.1755, device='cuda:0', grad_fn=<AddBackward0>)
0.63680124
tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)
0.63683218
tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
0.63704485
tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)
0.63693535
tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
0.63683319
tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [22][   60/  196]   Loss 0.208656   Top1 93.001302   Top5 99.889323   BatchTime 0.283627   LR 0.000081
0.63689721
tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
0.63722575
tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
0.63747889
tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
0.63738722
tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
0.63734192
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
0.63709843
tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>)
0.63698947
tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>)
0.63703549
tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
0.63720030
tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>)
0.63716882
tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
0.63687688
tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
0.63675344
tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>)
0.63666636
tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
0.63686424
tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
0.63713568
tensor(0.1748, device='cuda:0', grad_fn=<AddBackward0>)
0.63699424
tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
0.63691282
tensor(0.1783, device='cuda:0', grad_fn=<AddBackward0>)
0.63677293
tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>)
0.63685173
tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
0.63703030
tensor(0.1439, device='cuda:0', grad_fn=<AddBackward0>)
0.63665020
tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [22][   80/  196]   Loss 0.206929   Top1 93.032227   Top5 99.877930   BatchTime 0.279611   LR 0.000079
0.63650864
tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
0.63648552
tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
0.63665837
tensor(0.1826, device='cuda:0', grad_fn=<AddBackward0>)
0.63672668
tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
0.63667172
tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
0.63666689
tensor(0.1569, device='cuda:0', grad_fn=<AddBackward0>)
0.63657516
tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
0.63674742
tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>)
0.63687944
tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
0.63666958
tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>)
0.63658017
tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
0.63661581
tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
0.63685668
tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
0.63676798
tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
0.63694817
tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
0.63668555
tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
0.63659531
tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
0.63655591
tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
0.63657403
tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
0.63651210
tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [22][  100/  196]   Loss 0.208839   Top1 93.050781   Top5 99.855469   BatchTime 0.286252   LR 0.000077
0.63649136
tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
0.63648987
tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
0.63637084
tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
0.63658863
tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
0.63676798
tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
0.63671666
tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>)
0.63657749
tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
0.63654649
tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
0.63654566
tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
0.63670063
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.63659865
tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>)
0.63654619
tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
0.63659698
tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
0.63676697
tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
0.63654232
tensor(0.1437, device='cuda:0', grad_fn=<AddBackward0>)
0.63652170
tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
0.63663125
tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
0.63642681
tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>)
0.63620871
tensor(0.1818, device='cuda:0', grad_fn=<AddBackward0>)
0.63610613
tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)
0.63610125
tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
0.63600427
tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
0.63590944
tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [22][  120/  196]   Loss 0.210200   Top1 93.020833   Top5 99.853516   BatchTime 0.280988   LR 0.000075
0.63586175
tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
0.63569617
tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
0.63534510
tensor(0.1764, device='cuda:0', grad_fn=<AddBackward0>)
0.63520086
tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
0.63533729
tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>)
0.63535577
tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
0.63560122
tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>)
0.63554090
tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
0.63527107
tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
0.63513482
tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
0.63506180
tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
0.63492066
tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
0.63495636
tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
0.63485283
tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>)
0.63481158
tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
0.63489175
tensor(0.1780, device='cuda:0', grad_fn=<AddBackward0>)
0.63487548
tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>)
0.63481802
tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
0.63495737
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.63498074
tensor(0.1488, device='cuda:0', grad_fn=<AddBackward0>)
0.63489878
tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [22][  140/  196]   Loss 0.208215   Top1 93.099888   Top5 99.860491   BatchTime 0.283131   LR 0.000073
0.63460696
tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
0.63460624
tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
0.63477641
tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
0.63460535
tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
0.63424176
tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
0.63415182
tensor(0.1861, device='cuda:0', grad_fn=<AddBackward0>)
0.63373184
tensor(0.1702, device='cuda:0', grad_fn=<AddBackward0>)
0.63338977
tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)
0.63316745
tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
0.63301265
tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
0.63257456
tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)
0.63227004
tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
0.63196468
tensor(0.1793, device='cuda:0', grad_fn=<AddBackward0>)
0.63168573
tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
0.63129753
tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [22][  160/  196]   Loss 0.209296   Top1 93.022461   Top5 99.860840   BatchTime 0.281166   LR 0.000072
0.63107657
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.63081890
tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
0.63082004
tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
0.63058931
tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
0.63045025
tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
0.63010734
tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
0.62964499
tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
0.62950730
tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
0.62940520
tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
0.62922305
tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>)
0.62913471
tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
0.62895405
tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
0.62895536
tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
0.62903607
tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>)
0.62913895
tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>)
0.62903833
tensor(0.1716, device='cuda:0', grad_fn=<AddBackward0>)
0.62877560
tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
0.62874466
tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>)
0.62864470
tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>)
0.62846398
tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
0.62838107
tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
0.62812859
tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
0.62807328
tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>)
0.62798989
tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [22][  180/  196]   Loss 0.210559   Top1 92.966580   Top5 99.850260   BatchTime 0.277677   LR 0.000070
0.62804323
tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
0.62804496
tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
0.62786490
tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
0.62775475
tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
0.62772459
tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>)
0.62760216
tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
0.62755924
tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
0.62767714
tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>)
0.62717891
tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
0.62713200
tensor(0.3572, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 92.920    Top5: 99.850    Loss: 0.212
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1660)
features.1.conv.0 tensor(0.0417)
features.1.conv.3 tensor(0.0694)
features.1.conv.6 tensor(0.0933)
features.2.conv.0 tensor(0.0955)
features.2.conv.3 tensor(0.3534)
features.2.conv.6 tensor(0.4213)
features.3.conv.0 tensor(0.0741)
features.3.conv.3 tensor(0.0810)
features.3.conv.6 tensor(0.1131)
features.4.conv.0 tensor(0.0633)
features.4.conv.3 tensor(0.3044)
features.4.conv.6 tensor(0.2380)
features.5.conv.0 tensor(0.2850)
features.5.conv.3 tensor(0.4132)
features.5.conv.6 tensor(0.1250)
features.6.conv.0 tensor(0.0542)
features.6.conv.3 tensor(0.0538)
features.6.conv.6 tensor(0.0877)
features.7.conv.0 tensor(0.2178)
features.7.conv.3 tensor(0.4482)
features.7.conv.6 tensor(0.5871)
features.8.conv.0 tensor(0.4825)
features.8.conv.3 tensor(0.5385)
features.8.conv.6 tensor(0.1759)
features.9.conv.0 tensor(0.4679)
features.9.conv.3 tensor(0.5645)
features.9.conv.6 tensor(0.6689)
features.10.conv.0 tensor(0.0721)
features.10.conv.3 tensor(0.0966)
features.10.conv.6 tensor(0.0685)
features.11.conv.0 tensor(0.7453)
features.11.conv.3 tensor(0.6451)
features.11.conv.6 tensor(0.8810)
features.12.conv.0 tensor(0.7112)
features.12.conv.3 tensor(0.6669)
features.12.conv.6 tensor(0.8296)
features.13.conv.0 tensor(0.2499)
features.13.conv.3 tensor(0.4863)
features.13.conv.6 tensor(0.2713)
features.14.conv.0 tensor(0.8821)
features.14.conv.3 tensor(0.8208)
features.14.conv.6 tensor(0.9492)
features.15.conv.0 tensor(0.8603)
features.15.conv.3 tensor(0.8271)
features.15.conv.6 tensor(0.9567)
features.16.conv.0 tensor(0.6562)
features.16.conv.3 tensor(0.7876)
features.16.conv.6 tensor(0.8429)
conv.0 tensor(0.0869)
tensor(1284684.) 2188896.0
INFO - Validation [22][   20/   40]   Loss 0.372904   Top1 88.183594   Top5 99.433594   BatchTime 0.118129
INFO - Validation [22][   40/   40]   Loss 0.361574   Top1 88.490000   Top5 99.580000   BatchTime 0.084029
INFO - ==> Top1: 88.490    Top5: 99.580    Loss: 0.362
INFO - ==> Sparsity : 0.587
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 88.490   Top5: 99.580]
INFO - Scoreboard best 2 ==> Epoch [21][Top1: 88.000   Top5: 99.540]
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 87.460   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
0.62685061
tensor(0.1661, device='cuda:0', grad_fn=<AddBackward0>)
0.62659031
tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
0.62623572
tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)
0.62600857
tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
0.62564915
tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
0.62541705
tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
0.62504214
tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
0.62478399
tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
0.62463450
tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
0.62442046
tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
0.62418443
tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
0.62409890
tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
0.62404913
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.62426293
tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
0.62448132
tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
0.62416649
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.62374443
tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
0.62342918
tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
0.62303936
tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
0.62283188
tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
0.62266892
tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
0.62257695
tensor(0.1770, device='cuda:0', grad_fn=<AddBackward0>)
0.62245852
tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [23][   20/  196]   Loss 0.211446   Top1 92.988281   Top5 99.824219   BatchTime 0.306896   LR 0.000067
0.62234336
tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
0.62222618
tensor(0.1743, device='cuda:0', grad_fn=<AddBackward0>)
0.62228328
tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
0.62206787
tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
0.62203825
tensor(0.1842, device='cuda:0', grad_fn=<AddBackward0>)
0.62191057
tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
0.62184829
tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
0.62163275
tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
0.62169105
tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
0.62171429
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
0.62175798
tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
0.62210155
tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
0.62197757
tensor(0.1420, device='cuda:0', grad_fn=<AddBackward0>)
0.62179029
tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
0.62172967
tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
0.62165827
tensor(0.1384, device='cuda:0', grad_fn=<AddBackward0>)
0.62174118
tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
0.62164426
tensor(0.1814, device='cuda:0', grad_fn=<AddBackward0>)
0.62144434
tensor(0.1763, device='cuda:0', grad_fn=<AddBackward0>)
0.62136197
tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
0.62131619
tensor(0.2824, device='cuda:0', grad_fn=<AddBackward0>)
0.62132013
tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
0.62140441
tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
0.62150675
tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [23][   40/  196]   Loss 0.206791   Top1 93.066406   Top5 99.853516   BatchTime 0.284014   LR 0.000065
0.62148356
tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
0.62151051
tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
0.62143743
tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>)
0.62123454
tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
0.62119621
tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
0.62132430
tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
0.62142998
tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
0.62138593
tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
0.62145209
tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
0.62149060
tensor(0.1523, device='cuda:0', grad_fn=<AddBackward0>)
0.62152022
tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
0.62137359
tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
0.62119359
tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
0.62117630
tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>)
0.62112534
tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)
0.62112480
tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [23][   60/  196]   Loss 0.205389   Top1 93.059896   Top5 99.856771   BatchTime 0.272945   LR 0.000063
0.62103128
tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
0.62100524
tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
0.62092686
tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
0.62086666
tensor(0.1827, device='cuda:0', grad_fn=<AddBackward0>)
0.62083548
tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)
0.62082165
tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)
0.62075651
tensor(0.1691, device='cuda:0', grad_fn=<AddBackward0>)
0.62072521
tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)
0.62080902
tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
0.62107295
tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
0.62122560
tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>)
0.62112641
tensor(0.1782, device='cuda:0', grad_fn=<AddBackward0>)
0.62099266
tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
0.62095147
tensor(0.1673, device='cuda:0', grad_fn=<AddBackward0>)
0.62083238
tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
0.62066734
tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
0.62064832
tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
0.62067121
tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>)
0.62083894
tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)
0.62119204
tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)
0.62101811
tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>)
0.62090993
tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
0.62096936
tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
0.62082392
tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [23][   80/  196]   Loss 0.205508   Top1 93.046875   Top5 99.829102   BatchTime 0.267024   LR 0.000061
0.62070960
tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
0.62067574
tensor(0.1283, device='cuda:0', grad_fn=<AddBackward0>)
0.62056726
tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
0.62045693
tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
0.62044591
tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
0.62052101
tensor(0.1278, device='cuda:0', grad_fn=<AddBackward0>)
0.62062275
tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
0.62073743
tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>)
0.62095022
tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>)
0.62119740
tensor(0.1348, device='cuda:0', grad_fn=<AddBackward0>)
0.62131441
tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>)
0.62145704
tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>)
0.62158424
tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>)
0.62141734
tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
0.62141460
tensor(0.1614, device='cuda:0', grad_fn=<AddBackward0>)
0.62137741
tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [23][  100/  196]   Loss 0.205043   Top1 93.082031   Top5 99.832031   BatchTime 0.263569   LR 0.000060
0.62134999
tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
0.62134796
tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
0.62116677
tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
0.62130463
tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>)
0.62116867
tensor(0.1672, device='cuda:0', grad_fn=<AddBackward0>)
0.62114131
tensor(0.1670, device='cuda:0', grad_fn=<AddBackward0>)
0.62102115
tensor(0.1435, device='cuda:0', grad_fn=<AddBackward0>)
0.62085444
tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
0.62089503
tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>)
0.62067997
tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
0.62034333
tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
0.61999959
tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
0.61994272
tensor(0.1617, device='cuda:0', grad_fn=<AddBackward0>)
0.61990124
tensor(0.1473, device='cuda:0', grad_fn=<AddBackward0>)
0.61990404
tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)
0.61978024
tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
0.61954534
tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
0.61934775
tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
0.61950016
tensor(0.1695, device='cuda:0', grad_fn=<AddBackward0>)
0.61955553
tensor(0.1691, device='cuda:0', grad_fn=<AddBackward0>)
0.61943614
tensor(0.1887, device='cuda:0', grad_fn=<AddBackward0>)
0.61941463
tensor(0.1563, device='cuda:0', grad_fn=<AddBackward0>)
0.61929786
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.61918139
tensor(0.1633, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [23][  120/  196]   Loss 0.202654   Top1 93.167318   Top5 99.840495   BatchTime 0.261244   LR 0.000058
0.61907142
tensor(0.1671, device='cuda:0', grad_fn=<AddBackward0>)
0.61900836
tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
0.61898381
tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
0.61884725
tensor(0.1631, device='cuda:0', grad_fn=<AddBackward0>)
0.61895186
tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
0.61877012
tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>)
0.61844069
tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)
0.61853367
tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
0.61860603
tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
0.61846519
tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)
0.61856294
tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
0.61812890
tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
0.61791325
tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
0.61774743
tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
0.61760479
tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
0.61750227
tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [23][  140/  196]   Loss 0.200841   Top1 93.236607   Top5 99.849330   BatchTime 0.259830   LR 0.000056
0.61746830
tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
0.61742985
tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
0.61743754
tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
0.61751133
tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
0.61748844
tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>)
0.61747444
tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
0.61756212
tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
0.61778194
tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
0.61764199
tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
0.61783475
tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
0.61820930
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.61858332
tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>)
0.61848074
tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
0.61854726
tensor(0.1681, device='cuda:0', grad_fn=<AddBackward0>)
0.61858612
tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)
0.61815399
tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
0.61804938
tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
0.61811852
tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>)
0.61794841
tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)
0.61784434
tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
0.61784530
tensor(0.1565, device='cuda:0', grad_fn=<AddBackward0>)
0.61780727
tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
0.61759770
tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
0.61760765
tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
0.61768574
tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [23][  160/  196]   Loss 0.202836   Top1 93.149414   Top5 99.855957   BatchTime 0.258393   LR 0.000055
0.61750132
tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)
0.61755699
tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
0.61729413
tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
0.61697412
tensor(0.1489, device='cuda:0', grad_fn=<AddBackward0>)
0.61713934
tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)
0.61702794
tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
0.61689121
tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
0.61691302
tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
0.61682713
tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>)
0.61692452
tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
0.61706638
tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
0.61729771
tensor(0.1832, device='cuda:0', grad_fn=<AddBackward0>)
0.61738789
tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
0.61746234
tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
0.61740834
tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [23][  180/  196]   Loss 0.202675   Top1 93.174913   Top5 99.861111   BatchTime 0.257572   LR 0.000053
0.61764610
tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>)
0.61751461
tensor(0.1493, device='cuda:0', grad_fn=<AddBackward0>)
0.61751860
tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
0.61741811
tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
0.61731869
tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>)
0.61728334
tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>)
0.61729962
tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
0.61758226
tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
0.61736637
tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
0.61724955
tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
0.61713713
tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
0.61708516
tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
0.61694151
tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 93.184    Top5: 99.864    Loss: 0.202
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [23][   20/   40]   Loss 0.379825   Top1 88.066406   Top5 99.472656   BatchTime 0.126248
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1680)
features.1.conv.0 tensor(0.0391)
features.1.conv.3 tensor(0.0660)
features.1.conv.6 tensor(0.0959)
features.2.conv.0 tensor(0.0851)
features.2.conv.3 tensor(0.3549)
features.2.conv.6 tensor(0.4274)
features.3.conv.0 tensor(0.0715)
features.3.conv.3 tensor(0.0802)
features.3.conv.6 tensor(0.1120)
features.4.conv.0 tensor(0.0718)
features.4.conv.3 tensor(0.3032)
features.4.conv.6 tensor(0.2453)
features.5.conv.0 tensor(0.2829)
features.5.conv.3 tensor(0.4144)
features.5.conv.6 tensor(0.1253)
features.6.conv.0 tensor(0.0532)
features.6.conv.3 tensor(0.0573)
features.6.conv.6 tensor(0.0868)
features.7.conv.0 tensor(0.2210)
features.7.conv.3 tensor(0.4473)
features.7.conv.6 tensor(0.5908)
features.8.conv.0 tensor(0.4811)
features.8.conv.3 tensor(0.5385)
features.8.conv.6 tensor(0.1886)
features.9.conv.0 tensor(0.4702)
features.9.conv.3 tensor(0.5677)
features.9.conv.6 tensor(0.6768)
features.10.conv.0 tensor(0.0714)
features.10.conv.3 tensor(0.0972)
features.10.conv.6 tensor(0.0680)
features.11.conv.0 tensor(0.7526)
features.11.conv.3 tensor(0.6449)
features.11.conv.6 tensor(0.8820)
features.12.conv.0 tensor(0.7197)
features.12.conv.3 tensor(0.6657)
features.12.conv.6 tensor(0.8313)
features.13.conv.0 tensor(0.2880)
features.13.conv.3 tensor(0.4857)
features.13.conv.6 tensor(0.3673)
features.14.conv.0 tensor(0.8851)
features.14.conv.3 tensor(0.8211)
features.14.conv.6 tensor(0.9500)
features.15.conv.0 tensor(0.8642)
features.15.conv.3 tensor(0.8267)
features.15.conv.6 tensor(0.9581)
features.16.conv.0 tensor(0.6621)
features.16.conv.3 tensor(0.7875)
features.16.conv.6 tensor(0.8644)
conv.0 tensor(0.0864)
tensor(1306041.) 2188896.0
0.61690569
tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Validation [23][   40/   40]   Loss 0.366750   Top1 88.120000   Top5 99.630000   BatchTime 0.090035
INFO - ==> Top1: 88.120    Top5: 99.630    Loss: 0.367
INFO - ==> Sparsity : 0.597
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 88.490   Top5: 99.580]
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 88.120   Top5: 99.630]
INFO - Scoreboard best 3 ==> Epoch [21][Top1: 88.000   Top5: 99.540]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
0.61697757
tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>)
0.61725843
tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>)
0.61711937
tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>)
0.61716461
tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
0.61705649
tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>)
0.61699134
tensor(0.1663, device='cuda:0', grad_fn=<AddBackward0>)
0.61696076
tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
0.61688131
tensor(0.1496, device='cuda:0', grad_fn=<AddBackward0>)
0.61673188
tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
0.61663562
tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
0.61661667
tensor(0.1723, device='cuda:0', grad_fn=<AddBackward0>)
0.61686462
tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
0.61691344
tensor(0.1480, device='cuda:0', grad_fn=<AddBackward0>)
0.61688131
tensor(0.1383, device='cuda:0', grad_fn=<AddBackward0>)
0.61698037
tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
0.61685139
tensor(0.1428, device='cuda:0', grad_fn=<AddBackward0>)
0.61666542
tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
0.61654526
tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
0.61635816
tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
0.61627722
tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
0.61620140
tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [24][   20/  196]   Loss 0.186270   Top1 93.750000   Top5 99.941406   BatchTime 0.351352   LR 0.000050
0.61609924
tensor(0.1612, device='cuda:0', grad_fn=<AddBackward0>)
0.61613083
tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>)
0.61620450
tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>)
0.61606264
tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
0.61610085
tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
0.61616468
tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
0.61631024
tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
0.61640161
tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
0.61654878
tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
0.61614162
tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
0.61570513
tensor(0.1715, device='cuda:0', grad_fn=<AddBackward0>)
0.61557817
tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)
0.61555672
tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>)
0.61555344
tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
0.61554867
tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>)
0.61546487
tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
0.61536485
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.61549187
tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
0.61542648
tensor(0.1738, device='cuda:0', grad_fn=<AddBackward0>)
0.61534256
tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
0.61520678
tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
0.61517519
tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [24][   40/  196]   Loss 0.195505   Top1 93.544922   Top5 99.892578   BatchTime 0.311615   LR 0.000048
0.61516547
tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
0.61517161
tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
0.61522347
tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
0.61534244
tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>)
0.61530471
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
0.61517775
tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
0.61514384
tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
0.61515617
tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
0.61511648
tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
0.61508244
tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
0.61515367
tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
0.61519003
tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
0.61522508
tensor(0.1439, device='cuda:0', grad_fn=<AddBackward0>)
0.61524975
tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
0.61540449
tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>)
0.61570287
tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
0.61556107
tensor(0.1383, device='cuda:0', grad_fn=<AddBackward0>)
0.61575311
tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
0.61575812
tensor(0.1724, device='cuda:0', grad_fn=<AddBackward0>)
0.61568487
tensor(0.1270, device='cuda:0', grad_fn=<AddBackward0>)
0.61579478
tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
0.61563438
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [24][   60/  196]   Loss 0.195139   Top1 93.541667   Top5 99.895833   BatchTime 0.299801   LR 0.000047
0.61555737
tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
0.61546326
tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
0.61538786
tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
0.61523879
tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
0.61514986
tensor(0.1774, device='cuda:0', grad_fn=<AddBackward0>)
0.61512059
tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
0.61515903
tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>)
0.61522067
tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>)
0.61539513
tensor(0.1351, device='cuda:0', grad_fn=<AddBackward0>)
0.61538941
tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
0.61519760
tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
0.61517954
tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
0.61493409
tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
0.61489564
tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
0.61488968
tensor(0.1242, device='cuda:0', grad_fn=<AddBackward0>)
0.61494404
tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
0.61476666
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [24][   80/  196]   Loss 0.193454   Top1 93.574219   Top5 99.912109   BatchTime 0.287300   LR 0.000045
0.61474282
tensor(0.1570, device='cuda:0', grad_fn=<AddBackward0>)
0.61478651
tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
0.61480463
tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
0.61481386
tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
0.61481625
tensor(0.1628, device='cuda:0', grad_fn=<AddBackward0>)
0.61491722
tensor(0.1589, device='cuda:0', grad_fn=<AddBackward0>)
0.61500001
tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
0.61506945
tensor(0.1555, device='cuda:0', grad_fn=<AddBackward0>)
0.61498946
tensor(0.1668, device='cuda:0', grad_fn=<AddBackward0>)
0.61479318
tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)
0.61471432
tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>)
0.61457175
tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
0.61440903
tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>)
0.61437058
tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
0.61433476
tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>)
0.61422235
tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
0.61427081
tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>)
0.61414337
tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
0.61396843
tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
0.61371738
tensor(0.1898, device='cuda:0', grad_fn=<AddBackward0>)
0.61325848
tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
0.61311656
tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
0.61320621
tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
0.61330962
tensor(0.1709, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [24][  100/  196]   Loss 0.193565   Top1 93.550781   Top5 99.894531   BatchTime 0.280004   LR 0.000044
0.61306351
tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
0.61293107
tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
0.61281639
tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
0.61281908
tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
0.61279225
tensor(0.1500, device='cuda:0', grad_fn=<AddBackward0>)
0.61263323
tensor(0.1130, device='cuda:0', grad_fn=<AddBackward0>)
0.61292434
tensor(0.1743, device='cuda:0', grad_fn=<AddBackward0>)
0.61265409
tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
0.61258459
tensor(0.1330, device='cuda:0', grad_fn=<AddBackward0>)
0.61257321
tensor(0.1671, device='cuda:0', grad_fn=<AddBackward0>)
0.61249304
tensor(0.1614, device='cuda:0', grad_fn=<AddBackward0>)
0.61236024
tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
0.61223370
tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)
0.61213005
tensor(0.1183, device='cuda:0', grad_fn=<AddBackward0>)
0.61208099
tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
0.61197615
tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [24][  120/  196]   Loss 0.192220   Top1 93.577474   Top5 99.899089   BatchTime 0.275025   LR 0.000042
0.61196178
tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
0.61202735
tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
0.61207324
tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
0.61202061
tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
0.61226672
tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
0.61220104
tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
0.61216909
tensor(0.1726, device='cuda:0', grad_fn=<AddBackward0>)
0.61206102
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.61167759
tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
0.61154151
tensor(0.1574, device='cuda:0', grad_fn=<AddBackward0>)
0.61148411
tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
0.61161631
tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
0.61156321
tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
0.61158687
tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
0.61166102
tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
0.61163104
tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [24][  140/  196]   Loss 0.192734   Top1 93.551897   Top5 99.902344   BatchTime 0.271134   LR 0.000041
0.61128622
tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
0.61154366
tensor(0.1740, device='cuda:0', grad_fn=<AddBackward0>)
0.61131388
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.61124545
tensor(0.1773, device='cuda:0', grad_fn=<AddBackward0>)
0.61125696
tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>)
0.61114186
tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
0.61107558
tensor(0.1672, device='cuda:0', grad_fn=<AddBackward0>)
0.61101794
tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
0.61090827
tensor(0.1773, device='cuda:0', grad_fn=<AddBackward0>)
0.61086041
tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
0.61085594
tensor(0.1810, device='cuda:0', grad_fn=<AddBackward0>)
0.61084270
tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
0.61072946
tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
0.61067575
tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>)
0.61081290
tensor(0.1675, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [24][  160/  196]   Loss 0.192601   Top1 93.520508   Top5 99.902344   BatchTime 0.270676   LR 0.000039
0.61105001
tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
0.61095947
tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
0.61081046
tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
0.61074120
tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
0.61087334
tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
0.61062217
tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
0.61065441
tensor(0.1637, device='cuda:0', grad_fn=<AddBackward0>)
0.61061627
tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
0.61066639
tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
0.61056954
tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>)
0.61048663
tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
0.61049718
tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
0.61054975
tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
0.61052424
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
0.61062205
tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
0.61069757
tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
0.61081415
tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>)
0.61084092
tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
0.61087924
tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
0.61052394
tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
0.61024767
tensor(0.1399, device='cuda:0', grad_fn=<AddBackward0>)
0.61018449
tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [24][  180/  196]   Loss 0.190755   Top1 93.585069   Top5 99.906684   BatchTime 0.271995   LR 0.000038
0.61023623
tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
0.61023396
tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
0.61032897
tensor(0.1645, device='cuda:0', grad_fn=<AddBackward0>)
0.61033899
tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>)
0.61039925
tensor(0.1810, device='cuda:0', grad_fn=<AddBackward0>)
0.61029828
tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)
0.61024857
tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
0.61019588
tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
0.61012554
tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
0.61007172
tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
0.61001998
tensor(0.1738, device='cuda:0', grad_fn=<AddBackward0>)
0.60983849
tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)
0.60976505
tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
0.60975891
tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)
0.60991985
tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
0.61006927
tensor(0.1598, device='cuda:0', grad_fn=<AddBackward0>)
0.61017776
tensor(0.1365, device='cuda:0', grad_fn=<AddBackward0>)
0.61043829
tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
0.61028963
tensor(0.1682, device='cuda:0', grad_fn=<AddBackward0>)
0.61031187
tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 93.576    Top5: 99.902    Loss: 0.191
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [24][   20/   40]   Loss 0.355047   Top1 89.101562   Top5 99.609375   BatchTime 0.124213
INFO - Validation [24][   40/   40]   Loss 0.344451   Top1 89.210000   Top5 99.690000   BatchTime 0.089529
INFO - ==> Top1: 89.210    Top5: 99.690    Loss: 0.344
INFO - ==> Sparsity : 0.603
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [22][Top1: 88.490   Top5: 99.580]
INFO - Scoreboard best 3 ==> Epoch [23][Top1: 88.120   Top5: 99.630]
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1719)
features.1.conv.0 tensor(0.0404)
features.1.conv.3 tensor(0.0660)
features.1.conv.6 tensor(0.0942)
features.2.conv.0 tensor(0.0961)
features.2.conv.3 tensor(0.3549)
features.2.conv.6 tensor(0.4638)
features.3.conv.0 tensor(0.0720)
features.3.conv.3 tensor(0.0795)
features.3.conv.6 tensor(0.1131)
features.4.conv.0 tensor(0.0765)
features.4.conv.3 tensor(0.3015)
features.4.conv.6 tensor(0.2541)
features.5.conv.0 tensor(0.2863)
features.5.conv.3 tensor(0.4120)
features.5.conv.6 tensor(0.1230)
features.6.conv.0 tensor(0.0535)
features.6.conv.3 tensor(0.0561)
features.6.conv.6 tensor(0.0868)
features.7.conv.0 tensor(0.2229)
features.7.conv.3 tensor(0.4462)
features.7.conv.6 tensor(0.5953)
features.8.conv.0 tensor(0.4978)
features.8.conv.3 tensor(0.5394)
features.8.conv.6 tensor(0.1924)
features.9.conv.0 tensor(0.5033)
features.9.conv.3 tensor(0.5671)
features.9.conv.6 tensor(0.6801)
features.10.conv.0 tensor(0.0697)
features.10.conv.3 tensor(0.0943)
features.10.conv.6 tensor(0.0678)
features.11.conv.0 tensor(0.7584)
features.11.conv.3 tensor(0.6456)
features.11.conv.6 tensor(0.8830)
features.12.conv.0 tensor(0.7290)
features.12.conv.3 tensor(0.6645)
features.12.conv.6 tensor(0.8385)
features.13.conv.0 tensor(0.2751)
features.13.conv.3 tensor(0.4850)
features.13.conv.6 tensor(0.3705)
features.14.conv.0 tensor(0.8878)
features.14.conv.3 tensor(0.8207)
features.14.conv.6 tensor(0.9523)
features.15.conv.0 tensor(0.8665)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9582)
features.16.conv.0 tensor(0.6684)
features.16.conv.3 tensor(0.7876)
features.16.conv.6 tensor(0.8734)
conv.0 tensor(0.1025)
tensor(1320119.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
0.61031771
tensor(0.1491, device='cuda:0', grad_fn=<AddBackward0>)
0.61018902
tensor(0.1878, device='cuda:0', grad_fn=<AddBackward0>)
0.61019963
tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
0.61002564
tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
0.60996729
tensor(0.1435, device='cuda:0', grad_fn=<AddBackward0>)
0.60990822
tensor(0.1356, device='cuda:0', grad_fn=<AddBackward0>)
0.60987908
tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
0.60979080
tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>)
0.60973603
tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
0.60978585
tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
0.60991561
tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
0.60998112
tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
0.60991722
tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>)
0.60991794
tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [25][   20/  196]   Loss 0.181538   Top1 93.691406   Top5 99.843750   BatchTime 0.319974   LR 0.000035
0.60981834
tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)
0.60975200
tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
0.60970014
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.60967863
tensor(0.1783, device='cuda:0', grad_fn=<AddBackward0>)
0.60972822
tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
0.60969692
tensor(0.1411, device='cuda:0', grad_fn=<AddBackward0>)
0.60971618
tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
0.60963386
tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>)
0.60975301
tensor(0.1463, device='cuda:0', grad_fn=<AddBackward0>)
0.61022836
tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
0.61015713
tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
0.60987866
tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)
0.60998738
tensor(0.1488, device='cuda:0', grad_fn=<AddBackward0>)
0.61007506
tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
0.60988474
tensor(0.1357, device='cuda:0', grad_fn=<AddBackward0>)
0.60969454
tensor(0.1517, device='cuda:0', grad_fn=<AddBackward0>)
0.60957909
tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>)
0.60946399
tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
0.60947812
tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
0.60956877
tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
0.60975432
tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [25][   40/  196]   Loss 0.186297   Top1 93.652344   Top5 99.882812   BatchTime 0.305290   LR 0.000034
0.60988396
tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
0.60994643
tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>)
0.60984612
tensor(0.1613, device='cuda:0', grad_fn=<AddBackward0>)
0.60968620
tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>)
0.60970855
tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
0.60976946
tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
0.60952085
tensor(0.1130, device='cuda:0', grad_fn=<AddBackward0>)
0.60920745
tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
0.60884058
tensor(0.1869, device='cuda:0', grad_fn=<AddBackward0>)
0.60827631
tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
0.60781211
tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
0.60789895
tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
0.60799247
tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)
0.60776895
tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
0.60785574
tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>)
0.60768032
tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
0.60764539
tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
0.60741246
tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
0.60733271
tensor(0.1686, device='cuda:0', grad_fn=<AddBackward0>)
0.60727638
tensor(0.1662, device='cuda:0', grad_fn=<AddBackward0>)
0.60710186
tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
0.60704190
tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>)
0.60698956
tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [25][   60/  196]   Loss 0.183174   Top1 93.847656   Top5 99.902344   BatchTime 0.289975   LR 0.000033
0.60696095
tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>)
0.60697073
tensor(0.1464, device='cuda:0', grad_fn=<AddBackward0>)
0.60687268
tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
0.60688084
tensor(0.1493, device='cuda:0', grad_fn=<AddBackward0>)
0.60690463
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.60706443
tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
0.60697377
tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
0.60687828
tensor(0.1619, device='cuda:0', grad_fn=<AddBackward0>)
0.60680592
tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
0.60659444
tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
0.60649008
tensor(0.1677, device='cuda:0', grad_fn=<AddBackward0>)
0.60637295
tensor(0.1587, device='cuda:0', grad_fn=<AddBackward0>)
0.60626817
tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
0.60617089
tensor(0.1685, device='cuda:0', grad_fn=<AddBackward0>)
0.60617310
tensor(0.1305, device='cuda:0', grad_fn=<AddBackward0>)
0.60622323
tensor(0.1619, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [25][   80/  196]   Loss 0.184296   Top1 93.823242   Top5 99.907227   BatchTime 0.279682   LR 0.000031
0.60633290
tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
0.60641587
tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
0.60636872
tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
0.60632515
tensor(0.1827, device='cuda:0', grad_fn=<AddBackward0>)
0.60631990
tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
0.60660136
tensor(0.1437, device='cuda:0', grad_fn=<AddBackward0>)
0.60651648
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
0.60634702
tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)
0.60620564
tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
0.60612839
tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
0.60613543
tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>)
0.60617739
tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>)
0.60628194
tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
0.60617435
tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
0.60625863
tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
0.60601604
tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
0.60599416
tensor(0.1617, device='cuda:0', grad_fn=<AddBackward0>)
0.60604036
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.60601574
tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>)
0.60605508
tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
0.60592514
tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>)
0.60593200
tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
0.60603762
tensor(0.1770, device='cuda:0', grad_fn=<AddBackward0>)
0.60600144
tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [25][  100/  196]   Loss 0.186351   Top1 93.730469   Top5 99.898438   BatchTime 0.273583   LR 0.000030
0.60603470
tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
0.60603237
tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
0.60607314
tensor(0.1602, device='cuda:0', grad_fn=<AddBackward0>)
0.60589921
tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
0.60584819
tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
0.60581738
tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
0.60583544
tensor(0.1572, device='cuda:0', grad_fn=<AddBackward0>)
0.60586256
tensor(0.1434, device='cuda:0', grad_fn=<AddBackward0>)
0.60560596
tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
0.60562873
tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
0.60570109
tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
0.60570955
tensor(0.1076, device='cuda:0', grad_fn=<AddBackward0>)
0.60549980
tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
0.60559541
tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>)
0.60566735
tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
0.60554069
tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
0.60551155
tensor(0.1688, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [25][  120/  196]   Loss 0.184803   Top1 93.841146   Top5 99.892578   BatchTime 0.269236   LR 0.000029
0.60536093
tensor(0.1727, device='cuda:0', grad_fn=<AddBackward0>)
0.60537475
tensor(0.1715, device='cuda:0', grad_fn=<AddBackward0>)
0.60543251
tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
0.60562187
tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
0.60540307
tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
0.60527176
tensor(0.1770, device='cuda:0', grad_fn=<AddBackward0>)
0.60538739
tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
0.60542530
tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
0.60530418
tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
0.60527164
tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
0.60518408
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.60513520
tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
0.60516334
tensor(0.1474, device='cuda:0', grad_fn=<AddBackward0>)
0.60540658
tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
0.60527802
tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
0.60514569
tensor(0.1348, device='cuda:0', grad_fn=<AddBackward0>)
0.60518301
tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>)
0.60508603
tensor(0.1442, device='cuda:0', grad_fn=<AddBackward0>)
0.60503346
tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
0.60499340
tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)
0.60478157
tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
0.60461193
INFO - Training [25][  140/  196]   Loss 0.183505   Top1 93.895089   Top5 99.893973   BatchTime 0.272559   LR 0.000027
tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)
0.60467291
tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>)
0.60443890
tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
0.60432392
tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
0.60416657
tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
0.60400212
tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
0.60377550
tensor(0.0867, device='cuda:0', grad_fn=<AddBackward0>)
0.60356098
tensor(0.1733, device='cuda:0', grad_fn=<AddBackward0>)
0.60355884
tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>)
0.60349298
tensor(0.1588, device='cuda:0', grad_fn=<AddBackward0>)
0.60331875
tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
0.60298115
tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
0.60286897
tensor(0.1621, device='cuda:0', grad_fn=<AddBackward0>)
0.60290807
tensor(0.1441, device='cuda:0', grad_fn=<AddBackward0>)
0.60294771
tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
0.60291886
tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
0.60287309
tensor(0.1343, device='cuda:0', grad_fn=<AddBackward0>)
0.60278624
tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
0.60273588
tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
0.60266089
tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
0.60260653
tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [25][  160/  196]   Loss 0.182998   Top1 93.901367   Top5 99.897461   BatchTime 0.273808   LR 0.000026
0.60259110
tensor(0.1495, device='cuda:0', grad_fn=<AddBackward0>)
0.60258889
tensor(0.1346, device='cuda:0', grad_fn=<AddBackward0>)
0.60257083
tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
0.60253197
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.60249668
tensor(0.1361, device='cuda:0', grad_fn=<AddBackward0>)
0.60246122
tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
0.60242671
tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>)
0.60247153
tensor(0.1490, device='cuda:0', grad_fn=<AddBackward0>)
0.60248411
tensor(0.1879, device='cuda:0', grad_fn=<AddBackward0>)
0.60250586
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.60258955
tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
0.60289675
tensor(0.1842, device='cuda:0', grad_fn=<AddBackward0>)
0.60278374
tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>)
0.60276312
tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>)
0.60274035
tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
0.60265225
tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
0.60265231
tensor(0.1861, device='cuda:0', grad_fn=<AddBackward0>)
0.60265303
tensor(0.1828, device='cuda:0', grad_fn=<AddBackward0>)
0.60266966
tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)
0.60260504
tensor(0.1696, device='cuda:0', grad_fn=<AddBackward0>)
0.60242033
tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>)
0.60232550
tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [25][  180/  196]   Loss 0.183547   Top1 93.873698   Top5 99.900174   BatchTime 0.274180   LR 0.000025
0.60237640
tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
0.60239112
tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>)
0.60238951
tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
0.60234916
tensor(0.1366, device='cuda:0', grad_fn=<AddBackward0>)
0.60231119
tensor(0.1481, device='cuda:0', grad_fn=<AddBackward0>)
0.60218024
tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
0.60235602
tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>)
0.60256797
tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
0.60245258
tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
0.60254449
tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
0.60250366
tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
0.60254741
tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)
0.60262984
tensor(0.1832, device='cuda:0', grad_fn=<AddBackward0>)
0.60241187
tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>)
0.60246140
tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
0.60247195
tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 93.894    Top5: 99.902    Loss: 0.183
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.60242414
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [25][   20/   40]   Loss 0.360897   Top1 88.769531   Top5 99.570312   BatchTime 0.125826
INFO - Validation [25][   40/   40]   Loss 0.350693   Top1 88.960000   Top5 99.650000   BatchTime 0.087786
INFO - ==> Top1: 88.960    Top5: 99.650    Loss: 0.351
INFO - ==> Sparsity : 0.606
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [25][Top1: 88.960   Top5: 99.650]
INFO - Scoreboard best 3 ==> Epoch [22][Top1: 88.490   Top5: 99.580]
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1719)
features.1.conv.0 tensor(0.0449)
features.1.conv.3 tensor(0.0660)
features.1.conv.6 tensor(0.0933)
features.2.conv.0 tensor(0.1024)
features.2.conv.3 tensor(0.3542)
features.2.conv.6 tensor(0.4760)
features.3.conv.0 tensor(0.0729)
features.3.conv.3 tensor(0.0826)
features.3.conv.6 tensor(0.1181)
features.4.conv.0 tensor(0.0814)
features.4.conv.3 tensor(0.3021)
features.4.conv.6 tensor(0.2790)
features.5.conv.0 tensor(0.2894)
features.5.conv.3 tensor(0.4103)
features.5.conv.6 tensor(0.1419)
features.6.conv.0 tensor(0.0534)
features.6.conv.3 tensor(0.0556)
features.6.conv.6 tensor(0.0872)
features.7.conv.0 tensor(0.2233)
features.7.conv.3 tensor(0.4459)
features.7.conv.6 tensor(0.5966)
features.8.conv.0 tensor(0.5237)
features.8.conv.3 tensor(0.5385)
features.8.conv.6 tensor(0.1893)
features.9.conv.0 tensor(0.5012)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.6830)
features.10.conv.0 tensor(0.0700)
features.10.conv.3 tensor(0.0955)
features.10.conv.6 tensor(0.0679)
features.11.conv.0 tensor(0.7591)
features.11.conv.3 tensor(0.6453)
features.11.conv.6 tensor(0.8838)
features.12.conv.0 tensor(0.7330)
features.12.conv.3 tensor(0.6651)
features.12.conv.6 tensor(0.8389)
features.13.conv.0 tensor(0.2848)
features.13.conv.3 tensor(0.4850)
features.13.conv.6 tensor(0.3847)
features.14.conv.0 tensor(0.8890)
features.14.conv.3 tensor(0.8208)
features.14.conv.6 tensor(0.9525)
features.15.conv.0 tensor(0.8681)
features.15.conv.3 tensor(0.8272)
features.15.conv.6 tensor(0.9580)
features.16.conv.0 tensor(0.6735)
features.16.conv.3 tensor(0.7878)
features.16.conv.6 tensor(0.8778)
conv.0 tensor(0.1064)
tensor(1327521.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
0.60239619
tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
0.60236931
tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
0.60228711
tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>)
0.60230041
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.60256606
tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
0.60247028
tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
0.60259855
tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
0.60269123
tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
0.60256058
tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
0.60235912
tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
0.60240477
tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
0.60252327
tensor(0.1658, device='cuda:0', grad_fn=<AddBackward0>)
0.60240066
tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
0.60230225
tensor(0.1402, device='cuda:0', grad_fn=<AddBackward0>)
0.60221106
tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>)
0.60218340
tensor(0.1358, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [26][   20/  196]   Loss 0.180397   Top1 94.394531   Top5 99.960938   BatchTime 0.350549   LR 0.000023
0.60224569
tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
0.60260242
tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
0.60236388
tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
0.60213053
tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>)
0.60209668
tensor(0.1550, device='cuda:0', grad_fn=<AddBackward0>)
0.60205716
tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
0.60200059
tensor(0.1582, device='cuda:0', grad_fn=<AddBackward0>)
0.60189527
tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
0.60187954
tensor(0.1778, device='cuda:0', grad_fn=<AddBackward0>)
0.60195726
tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>)
0.60209340
tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
0.60210615
tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
0.60227340
tensor(0.1381, device='cuda:0', grad_fn=<AddBackward0>)
0.60249490
tensor(0.1258, device='cuda:0', grad_fn=<AddBackward0>)
0.60230088
tensor(0.1396, device='cuda:0', grad_fn=<AddBackward0>)
0.60224378
tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
0.60217923
tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
0.60215747
tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)
0.60209930
tensor(0.1248, device='cuda:0', grad_fn=<AddBackward0>)
0.60203439
tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
0.60204369
tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [26][   40/  196]   Loss 0.176038   Top1 94.335938   Top5 99.902344   BatchTime 0.318002   LR 0.000022
0.60211885
tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
0.60227150
tensor(0.1383, device='cuda:0', grad_fn=<AddBackward0>)
0.60214615
tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
0.60218626
tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>)
0.60230941
tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
0.60240263
tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
0.60224593
tensor(0.1531, device='cuda:0', grad_fn=<AddBackward0>)
0.60209769
tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
0.60205978
tensor(0.1355, device='cuda:0', grad_fn=<AddBackward0>)
0.60202879
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
0.60206616
tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
0.60216898
tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
0.60213190
tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
0.60200548
tensor(0.1473, device='cuda:0', grad_fn=<AddBackward0>)
0.60202509
tensor(0.1774, device='cuda:0', grad_fn=<AddBackward0>)
0.60215789
tensor(0.1537, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [26][   60/  196]   Loss 0.175551   Top1 94.407552   Top5 99.908854   BatchTime 0.295297   LR 0.000021
0.60201722
tensor(0.1477, device='cuda:0', grad_fn=<AddBackward0>)
0.60193521
tensor(0.1363, device='cuda:0', grad_fn=<AddBackward0>)
0.60202342
tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
0.60221344
tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
0.60206932
tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
0.60184264
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.60179985
tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>)
0.60176861
tensor(0.1399, device='cuda:0', grad_fn=<AddBackward0>)
0.60175043
tensor(0.1693, device='cuda:0', grad_fn=<AddBackward0>)
0.60172015
tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
0.60166484
tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
0.60162371
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.60161752
tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
0.60161662
tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
0.60162711
tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
0.60162926
tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>)
0.60160279
tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
0.60184479
tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>)
0.60182440
tensor(0.1364, device='cuda:0', grad_fn=<AddBackward0>)
0.60187584
tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
0.60158527
tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
0.60153598
tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>)
0.60149741
tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)
0.60147911
tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [26][   80/  196]   Loss 0.177738   Top1 94.145508   Top5 99.921875   BatchTime 0.282539   LR 0.000019
0.60144281
tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)
0.60139441
tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
0.60136729
tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
0.60134101
tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
0.60134369
tensor(0.1515, device='cuda:0', grad_fn=<AddBackward0>)
0.60140878
tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
0.60138357
tensor(0.1386, device='cuda:0', grad_fn=<AddBackward0>)
0.60134614
tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
0.60133350
tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
0.60133749
tensor(0.1807, device='cuda:0', grad_fn=<AddBackward0>)
0.60148585
tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
0.60188556
tensor(0.1727, device='cuda:0', grad_fn=<AddBackward0>)
0.60160816
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.60134363
tensor(0.1615, device='cuda:0', grad_fn=<AddBackward0>)
0.60125887
tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)
0.60125148
tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [26][  100/  196]   Loss 0.178161   Top1 94.101562   Top5 99.906250   BatchTime 0.275836   LR 0.000018
0.60123688
tensor(0.1092, device='cuda:0', grad_fn=<AddBackward0>)
0.60120201
tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
0.60114086
tensor(0.1780, device='cuda:0', grad_fn=<AddBackward0>)
0.60109735
tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
0.60108578
tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
0.60106748
tensor(0.1713, device='cuda:0', grad_fn=<AddBackward0>)
0.60104799
tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
0.60105312
tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
0.60104889
tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
0.60104823
tensor(0.1511, device='cuda:0', grad_fn=<AddBackward0>)
0.60103834
tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
0.60103774
tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>)
0.60105664
tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>)
0.60110068
tensor(0.1573, device='cuda:0', grad_fn=<AddBackward0>)
0.60112381
tensor(0.1312, device='cuda:0', grad_fn=<AddBackward0>)
0.60113019
tensor(0.1364, device='cuda:0', grad_fn=<AddBackward0>)
0.60118937
tensor(0.1628, device='cuda:0', grad_fn=<AddBackward0>)
0.60151792
tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>)
0.60156858
tensor(0.1639, device='cuda:0', grad_fn=<AddBackward0>)
0.60144150
tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
0.60137212
tensor(0.1305, device='cuda:0', grad_fn=<AddBackward0>)
0.60138947
tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)
0.60148299
tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [26][  120/  196]   Loss 0.177886   Top1 94.117839   Top5 99.912109   BatchTime 0.273874   LR 0.000017
0.60162586
tensor(0.1353, device='cuda:0', grad_fn=<AddBackward0>)
0.60149539
tensor(0.1676, device='cuda:0', grad_fn=<AddBackward0>)
0.60141170
tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>)
0.60143214
tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)
0.60153556
tensor(0.1676, device='cuda:0', grad_fn=<AddBackward0>)
0.60137278
tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
0.60148770
tensor(0.1163, device='cuda:0', grad_fn=<AddBackward0>)
0.60125715
tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
0.60114187
tensor(0.1348, device='cuda:0', grad_fn=<AddBackward0>)
0.60105580
tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
0.60101956
tensor(0.1178, device='cuda:0', grad_fn=<AddBackward0>)
0.60102093
tensor(0.1569, device='cuda:0', grad_fn=<AddBackward0>)
0.60100812
tensor(0.1506, device='cuda:0', grad_fn=<AddBackward0>)
0.60104162
tensor(0.1443, device='cuda:0', grad_fn=<AddBackward0>)
0.60101455
tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
0.60097533
tensor(0.1606, device='cuda:0', grad_fn=<AddBackward0>)
0.60110480
tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>)
0.60135996
tensor(0.1462, device='cuda:0', grad_fn=<AddBackward0>)
0.60127634
tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>)
0.60139036
tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
0.60125518
tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>)
0.60120636
tensor(0.1627, device='cuda:0', grad_fn=<AddBackward0>)
0.60116160
tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [26][  140/  196]   Loss 0.175649   Top1 94.182478   Top5 99.907924   BatchTime 0.274649   LR 0.000016
0.60111350
tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
0.60103148
tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
0.60092109
tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)
0.60085261
tensor(0.1760, device='cuda:0', grad_fn=<AddBackward0>)
0.60086417
tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
0.60089177
tensor(0.1676, device='cuda:0', grad_fn=<AddBackward0>)
0.60087788
tensor(0.1463, device='cuda:0', grad_fn=<AddBackward0>)
0.60081267
tensor(0.1821, device='cuda:0', grad_fn=<AddBackward0>)
0.60083032
tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
0.60080540
tensor(0.1278, device='cuda:0', grad_fn=<AddBackward0>)
0.60078466
tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
0.60074729
tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
0.60084307
tensor(0.1667, device='cuda:0', grad_fn=<AddBackward0>)
0.60098612
tensor(0.1502, device='cuda:0', grad_fn=<AddBackward0>)
0.60122639
tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [26][  160/  196]   Loss 0.175698   Top1 94.179688   Top5 99.904785   BatchTime 0.271692   LR 0.000015
0.60120291
tensor(0.1365, device='cuda:0', grad_fn=<AddBackward0>)
0.60090059
tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
0.60085386
tensor(0.1826, device='cuda:0', grad_fn=<AddBackward0>)
0.60082155
tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
0.60083097
tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)
0.60082191
tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
0.60079569
tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
0.60082090
tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
0.60100478
tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)
0.60098481
tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
0.60123932
tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
0.60115796
tensor(0.1506, device='cuda:0', grad_fn=<AddBackward0>)
0.60099876
tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)
0.60098380
tensor(0.1504, device='cuda:0', grad_fn=<AddBackward0>)
0.60097694
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
0.60084742
tensor(0.1570, device='cuda:0', grad_fn=<AddBackward0>)
0.60080165
tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
0.60092074
tensor(0.1434, device='cuda:0', grad_fn=<AddBackward0>)
0.60107678
tensor(0.1711, device='cuda:0', grad_fn=<AddBackward0>)
0.60083443
tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>)
0.60084116
tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
0.60076147
tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>)
0.60072201
tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
0.60063869
tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [26][  180/  196]   Loss 0.175139   Top1 94.186198   Top5 99.915365   BatchTime 0.269249   LR 0.000014
0.60055417
tensor(0.1460, device='cuda:0', grad_fn=<AddBackward0>)
0.60050660
tensor(0.1325, device='cuda:0', grad_fn=<AddBackward0>)
0.60052186
tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
0.60050046
tensor(0.1555, device='cuda:0', grad_fn=<AddBackward0>)
0.60044342
tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
0.60042417
tensor(0.1462, device='cuda:0', grad_fn=<AddBackward0>)
0.60048193
tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
0.60058814
tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)
0.60061562
tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
0.60051399
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.60070348
tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)
0.60082114
tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)
0.60068607
tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
0.60057873
tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
0.60059345
tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>)
0.60056710
tensor(0.1711, device='cuda:0', grad_fn=<AddBackward0>)
0.60049373
tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 94.166    Top5: 99.916    Loss: 0.176
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
0.60044771
tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [26][   20/   40]   Loss 0.363125   Top1 88.574219   Top5 99.589844   BatchTime 0.124257
INFO - Validation [26][   40/   40]   Loss 0.349279   Top1 88.810000   Top5 99.680000   BatchTime 0.086891
INFO - ==> Top1: 88.810    Top5: 99.680    Loss: 0.349
INFO - ==> Sparsity : 0.611
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [25][Top1: 88.960   Top5: 99.650]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 88.810   Top5: 99.680]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1680)
features.1.conv.0 tensor(0.0482)
features.1.conv.3 tensor(0.0660)
features.1.conv.6 tensor(0.0924)
features.2.conv.0 tensor(0.1082)
features.2.conv.3 tensor(0.3534)
features.2.conv.6 tensor(0.4763)
features.3.conv.0 tensor(0.0718)
features.3.conv.3 tensor(0.0826)
features.3.conv.6 tensor(0.1241)
features.4.conv.0 tensor(0.0806)
features.4.conv.3 tensor(0.3021)
features.4.conv.6 tensor(0.2801)
features.5.conv.0 tensor(0.2959)
features.5.conv.3 tensor(0.4103)
features.5.conv.6 tensor(0.1423)
features.6.conv.0 tensor(0.0527)
features.6.conv.3 tensor(0.0556)
features.6.conv.6 tensor(0.0882)
features.7.conv.0 tensor(0.2234)
features.7.conv.3 tensor(0.4453)
features.7.conv.6 tensor(0.5971)
features.8.conv.0 tensor(0.5230)
features.8.conv.3 tensor(0.5394)
features.8.conv.6 tensor(0.1898)
features.9.conv.0 tensor(0.5123)
features.9.conv.3 tensor(0.5648)
features.9.conv.6 tensor(0.6846)
features.10.conv.0 tensor(0.0690)
features.10.conv.3 tensor(0.0940)
features.10.conv.6 tensor(0.0681)
features.11.conv.0 tensor(0.7615)
features.11.conv.3 tensor(0.6451)
features.11.conv.6 tensor(0.8851)
features.12.conv.0 tensor(0.7386)
features.12.conv.3 tensor(0.6651)
features.12.conv.6 tensor(0.8396)
features.13.conv.0 tensor(0.2856)
features.13.conv.3 tensor(0.4840)
features.13.conv.6 tensor(0.4035)
features.14.conv.0 tensor(0.8895)
features.14.conv.3 tensor(0.8207)
features.14.conv.6 tensor(0.9531)
features.15.conv.0 tensor(0.8693)
features.15.conv.3 tensor(0.8271)
features.15.conv.6 tensor(0.9582)
features.16.conv.0 tensor(0.6785)
features.16.conv.3 tensor(0.7878)
features.16.conv.6 tensor(0.8821)
conv.0 tensor(0.1160)
tensor(1336641.) 2188896.0
0.60040379
tensor(0.1491, device='cuda:0', grad_fn=<AddBackward0>)
0.60038674
tensor(0.1548, device='cuda:0', grad_fn=<AddBackward0>)
0.60035861
tensor(0.1464, device='cuda:0', grad_fn=<AddBackward0>)
0.60032260
tensor(0.1651, device='cuda:0', grad_fn=<AddBackward0>)
0.60034204
tensor(0.1571, device='cuda:0', grad_fn=<AddBackward0>)
0.60038096
tensor(0.1731, device='cuda:0', grad_fn=<AddBackward0>)
0.60042346
tensor(0.1430, device='cuda:0', grad_fn=<AddBackward0>)
0.60049778
tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
0.60048473
tensor(0.1198, device='cuda:0', grad_fn=<AddBackward0>)
0.60063237
tensor(0.1633, device='cuda:0', grad_fn=<AddBackward0>)
0.60082018
tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>)
0.60065264
tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>)
0.60064375
tensor(0.1223, device='cuda:0', grad_fn=<AddBackward0>)
0.60056365
tensor(0.1325, device='cuda:0', grad_fn=<AddBackward0>)
0.60058153
tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
0.60057861
tensor(0.1494, device='cuda:0', grad_fn=<AddBackward0>)
0.60045111
tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
0.60031062
tensor(0.1759, device='cuda:0', grad_fn=<AddBackward0>)
0.60037005
tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [27][   20/  196]   Loss 0.155572   Top1 94.843750   Top5 99.902344   BatchTime 0.331230   LR 0.000013
0.60055846
tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
0.60063517
tensor(0.1353, device='cuda:0', grad_fn=<AddBackward0>)
0.60057676
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
0.60067677
tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
0.60071141
tensor(0.1544, device='cuda:0', grad_fn=<AddBackward0>)
0.60042149
tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)
0.60036337
tensor(0.1703, device='cuda:0', grad_fn=<AddBackward0>)
0.60031456
tensor(0.1538, device='cuda:0', grad_fn=<AddBackward0>)
0.60031807
tensor(0.1662, device='cuda:0', grad_fn=<AddBackward0>)
0.60040689
tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
0.60041451
tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
0.60037333
tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
0.60035187
tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
0.60033756
tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>)
0.60033721
tensor(0.1601, device='cuda:0', grad_fn=<AddBackward0>)
0.60035300
tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [27][   40/  196]   Loss 0.158769   Top1 94.707031   Top5 99.912109   BatchTime 0.290209   LR 0.000012
0.60055363
tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>)
0.60049486
tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)
0.60050285
tensor(0.1780, device='cuda:0', grad_fn=<AddBackward0>)
0.60030502
tensor(0.1100, device='cuda:0', grad_fn=<AddBackward0>)
0.60025316
tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>)
0.60022944
tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
0.60023940
tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)
0.60022557
tensor(0.1493, device='cuda:0', grad_fn=<AddBackward0>)
0.60019648
tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
0.60012865
tensor(0.1383, device='cuda:0', grad_fn=<AddBackward0>)
0.60007310
tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
0.60005039
tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
0.60003990
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
0.60002571
tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
0.60003608
tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
0.60001796
tensor(0.1088, device='cuda:0', grad_fn=<AddBackward0>)
0.60003358
tensor(0.1675, device='cuda:0', grad_fn=<AddBackward0>)
0.60002482
tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>)
0.60003650
tensor(0.1763, device='cuda:0', grad_fn=<AddBackward0>)
0.60001928
tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)
0.60003239
tensor(0.1500, device='cuda:0', grad_fn=<AddBackward0>)
0.60004699
tensor(0.1585, device='cuda:0', grad_fn=<AddBackward0>)
0.60013461
tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
0.60050434
tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [27][   60/  196]   Loss 0.159709   Top1 94.680990   Top5 99.915365   BatchTime 0.276566   LR 0.000011
0.60013849
tensor(0.1594, device='cuda:0', grad_fn=<AddBackward0>)
0.60005468
tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
0.60002023
tensor(0.1554, device='cuda:0', grad_fn=<AddBackward0>)
0.59999084
tensor(0.1499, device='cuda:0', grad_fn=<AddBackward0>)
0.59996700
tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>)
0.59993225
tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
0.59991157
tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
0.59988195
tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
0.59985912
tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
0.59983712
tensor(0.1326, device='cuda:0', grad_fn=<AddBackward0>)
0.59981292
tensor(0.1353, device='cuda:0', grad_fn=<AddBackward0>)
0.59980059
tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
0.59978318
tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
0.59976578
tensor(0.1618, device='cuda:0', grad_fn=<AddBackward0>)
0.59974837
tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
0.59971875
tensor(0.1558, device='cuda:0', grad_fn=<AddBackward0>)
0.59969479
tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
0.59966958
tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>)
0.59964836
tensor(0.1370, device='cuda:0', grad_fn=<AddBackward0>)
0.59962535
tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
0.59960592
tensor(0.1638, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [27][   80/  196]   Loss 0.163153   Top1 94.526367   Top5 99.902344   BatchTime 0.278204   LR 0.000010
0.59959894
tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
0.59958988
tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
0.59958613
tensor(0.1756, device='cuda:0', grad_fn=<AddBackward0>)
0.59957284
tensor(0.1588, device='cuda:0', grad_fn=<AddBackward0>)
0.59956312
tensor(0.1446, device='cuda:0', grad_fn=<AddBackward0>)
0.59954584
tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
0.59953266
tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
0.59952247
tensor(0.1201, device='cuda:0', grad_fn=<AddBackward0>)
0.59951085
tensor(0.1765, device='cuda:0', grad_fn=<AddBackward0>)
0.59951186
tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
0.59949595
tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>)
0.59950000
tensor(0.1610, device='cuda:0', grad_fn=<AddBackward0>)
0.59949732
tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>)
0.59949458
tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>)
0.59948909
tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
0.59948170
tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>)
0.59946477
tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>)
0.59945410
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.59945065
tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
0.59944141
tensor(0.1299, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [27][  100/  196]   Loss 0.164096   Top1 94.515625   Top5 99.902344   BatchTime 0.283388   LR 0.000009
0.59943151
tensor(0.1617, device='cuda:0', grad_fn=<AddBackward0>)
0.59941149
tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>)
0.59940386
tensor(0.1566, device='cuda:0', grad_fn=<AddBackward0>)
0.59939700
tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
0.59937340
tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
0.59935617
tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>)
0.59934831
tensor(0.1149, device='cuda:0', grad_fn=<AddBackward0>)
0.59933710
tensor(0.1299, device='cuda:0', grad_fn=<AddBackward0>)
0.59931719
tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
0.59930354
tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
0.59930253
tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
0.59927744
tensor(0.1580, device='cuda:0', grad_fn=<AddBackward0>)
0.59926742
tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
0.59927040
tensor(0.1618, device='cuda:0', grad_fn=<AddBackward0>)
0.59925115
tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
0.59924400
tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
0.59922618
tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
0.59920961
tensor(0.1601, device='cuda:0', grad_fn=<AddBackward0>)
0.59922570
tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
0.59923166
tensor(0.1297, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [27][  120/  196]   Loss 0.165896   Top1 94.417318   Top5 99.905599   BatchTime 0.286032   LR 0.000009
0.59919500
tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>)
0.59915572
tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
0.59912211
tensor(0.1756, device='cuda:0', grad_fn=<AddBackward0>)
0.59903580
tensor(0.1748, device='cuda:0', grad_fn=<AddBackward0>)
0.59867346
tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>)
0.59937114
tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>)
0.59944582
tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>)
0.59942019
tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)
0.59939480
tensor(0.1495, device='cuda:0', grad_fn=<AddBackward0>)
0.59936148
tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
0.59934574
tensor(0.1292, device='cuda:0', grad_fn=<AddBackward0>)
0.59932721
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.59930867
tensor(0.1228, device='cuda:0', grad_fn=<AddBackward0>)
0.59929287
tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)
0.59926993
tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
0.59925604
tensor(0.1433, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [27][  140/  196]   Loss 0.164239   Top1 94.517299   Top5 99.910714   BatchTime 0.281249   LR 0.000008
0.59923959
tensor(0.1515, device='cuda:0', grad_fn=<AddBackward0>)
0.59922254
tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>)
0.59921902
tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
0.59921229
tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
0.59920096
tensor(0.1763, device='cuda:0', grad_fn=<AddBackward0>)
0.59919876
tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
0.59918314
tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>)
0.59917617
tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
0.59916967
tensor(0.1728, device='cuda:0', grad_fn=<AddBackward0>)
0.59917217
tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
0.59916365
tensor(0.1270, device='cuda:0', grad_fn=<AddBackward0>)
0.59916061
tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
0.59914958
tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)
0.59914207
tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
0.59913307
tensor(0.1734, device='cuda:0', grad_fn=<AddBackward0>)
0.59911323
tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>)
0.59909970
tensor(0.1609, device='cuda:0', grad_fn=<AddBackward0>)
0.59908539
tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>)
0.59906554
tensor(0.1751, device='cuda:0', grad_fn=<AddBackward0>)
0.59904552
tensor(0.1667, device='cuda:0', grad_fn=<AddBackward0>)
0.59903371
tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
0.59902686
tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>)
0.59900838
tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>)
0.59899384
tensor(0.1278, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [27][  160/  196]   Loss 0.165419   Top1 94.487305   Top5 99.909668   BatchTime 0.276762   LR 0.000007
0.59897459
tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
0.59895039
tensor(0.1672, device='cuda:0', grad_fn=<AddBackward0>)
0.59891796
tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
0.59890610
tensor(0.1763, device='cuda:0', grad_fn=<AddBackward0>)
0.59889060
tensor(0.1550, device='cuda:0', grad_fn=<AddBackward0>)
0.59887511
tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>)
0.59886873
tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
0.59886092
tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)
0.59885377
tensor(0.1409, device='cuda:0', grad_fn=<AddBackward0>)
0.59884042
tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>)
0.59882736
tensor(0.1623, device='cuda:0', grad_fn=<AddBackward0>)
0.59881318
tensor(0.1227, device='cuda:0', grad_fn=<AddBackward0>)
0.59880114
tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
0.59878564
tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
0.59877610
tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
0.59875512
tensor(0.1575, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [27][  180/  196]   Loss 0.164840   Top1 94.511719   Top5 99.913194   BatchTime 0.274230   LR 0.000007
0.59874266
tensor(0.1381, device='cuda:0', grad_fn=<AddBackward0>)
0.59873307
tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>)
0.59871632
tensor(0.1537, device='cuda:0', grad_fn=<AddBackward0>)
0.59869295
tensor(0.1746, device='cuda:0', grad_fn=<AddBackward0>)
0.59867162
tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
0.59864771
tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
0.59861779
tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
0.59858716
tensor(0.1430, device='cuda:0', grad_fn=<AddBackward0>)
0.59855145
tensor(0.1104, device='cuda:0', grad_fn=<AddBackward0>)
0.59852779
tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
0.59848905
tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
0.59846711
tensor(0.1776, device='cuda:0', grad_fn=<AddBackward0>)
0.59843618
tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
0.59838319
tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
0.59832388
tensor(0.1421, device='cuda:0', grad_fn=<AddBackward0>)
0.59827793
tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 94.496    Top5: 99.906    Loss: 0.165
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.59822881
tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>)
0.59818733
tensor(0.1358, device='cuda:0', grad_fn=<AddBackward0>)
0.59812886
tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
0.59806544
tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [27][   20/   40]   Loss 0.363484   Top1 88.906250   Top5 99.511719   BatchTime 0.122539
INFO - Validation [27][   40/   40]   Loss 0.349051   Top1 88.840000   Top5 99.650000   BatchTime 0.087432
INFO - ==> Top1: 88.840    Top5: 99.650    Loss: 0.349
INFO - ==> Sparsity : 0.613
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [25][Top1: 88.960   Top5: 99.650]
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 88.840   Top5: 99.650]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1719)
features.1.conv.0 tensor(0.0482)
features.1.conv.3 tensor(0.0683)
features.1.conv.6 tensor(0.0929)
features.2.conv.0 tensor(0.1100)
features.2.conv.3 tensor(0.3526)
features.2.conv.6 tensor(0.4780)
features.3.conv.0 tensor(0.0718)
features.3.conv.3 tensor(0.0818)
features.3.conv.6 tensor(0.1211)
features.4.conv.0 tensor(0.0814)
features.4.conv.3 tensor(0.3015)
features.4.conv.6 tensor(0.2808)
features.5.conv.0 tensor(0.2954)
features.5.conv.3 tensor(0.4109)
features.5.conv.6 tensor(0.1414)
features.6.conv.0 tensor(0.0526)
features.6.conv.3 tensor(0.0550)
features.6.conv.6 tensor(0.0864)
features.7.conv.0 tensor(0.2236)
features.7.conv.3 tensor(0.4453)
features.7.conv.6 tensor(0.5982)
features.8.conv.0 tensor(0.5278)
features.8.conv.3 tensor(0.5396)
features.8.conv.6 tensor(0.1921)
features.9.conv.0 tensor(0.5244)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.6856)
features.10.conv.0 tensor(0.0685)
features.10.conv.3 tensor(0.0946)
features.10.conv.6 tensor(0.0683)
features.11.conv.0 tensor(0.7623)
features.11.conv.3 tensor(0.6447)
features.11.conv.6 tensor(0.8855)
features.12.conv.0 tensor(0.7425)
features.12.conv.3 tensor(0.6647)
features.12.conv.6 tensor(0.8411)
features.13.conv.0 tensor(0.2869)
features.13.conv.3 tensor(0.4846)
features.13.conv.6 tensor(0.4187)
features.14.conv.0 tensor(0.8897)
features.14.conv.3 tensor(0.8204)
features.14.conv.6 tensor(0.9533)
features.15.conv.0 tensor(0.8699)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9584)
features.16.conv.0 tensor(0.6814)
features.16.conv.3 tensor(0.7880)
features.16.conv.6 tensor(0.8835)
conv.0 tensor(0.1229)
tensor(1342862.) 2188896.0
0.59799993
tensor(0.1346, device='cuda:0', grad_fn=<AddBackward0>)
0.59793133
tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
0.59785956
tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>)
0.59777349
tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
0.59775674
tensor(0.1401, device='cuda:0', grad_fn=<AddBackward0>)
0.59771985
tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
0.59770489
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
0.59767365
tensor(0.1621, device='cuda:0', grad_fn=<AddBackward0>)
0.59764481
tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
0.59760624
tensor(0.1825, device='cuda:0', grad_fn=<AddBackward0>)
0.59757203
tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
0.59753376
tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
0.59750670
tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
0.59747273
tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
0.59744877
tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>)
0.59743512
tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
0.59743190
tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [28][   20/  196]   Loss 0.174676   Top1 94.062500   Top5 99.843750   BatchTime 0.319698   LR 0.000006
0.59741527
tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>)
0.59739083
tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>)
0.59737629
tensor(0.0881, device='cuda:0', grad_fn=<AddBackward0>)
0.59735602
tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>)
0.59734488
tensor(0.1203, device='cuda:0', grad_fn=<AddBackward0>)
0.59732753
tensor(0.1492, device='cuda:0', grad_fn=<AddBackward0>)
0.59733272
tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
0.59732515
tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
0.59732479
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.59732437
tensor(0.1639, device='cuda:0', grad_fn=<AddBackward0>)
0.59732473
tensor(0.1637, device='cuda:0', grad_fn=<AddBackward0>)
0.59731984
tensor(0.1158, device='cuda:0', grad_fn=<AddBackward0>)
0.59732115
tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
0.59731865
tensor(0.1439, device='cuda:0', grad_fn=<AddBackward0>)
0.59731764
tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
0.59730679
tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [28][   40/  196]   Loss 0.162108   Top1 94.638672   Top5 99.902344   BatchTime 0.280151   LR 0.000005
0.59730315
tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
0.59730899
tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>)
0.59730679
tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>)
0.59728926
tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
0.59729058
tensor(0.1621, device='cuda:0', grad_fn=<AddBackward0>)
0.59729671
tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
0.59728914
tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)
0.59728020
tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
0.59726971
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.59726042
tensor(0.1062, device='cuda:0', grad_fn=<AddBackward0>)
0.59724844
tensor(0.1313, device='cuda:0', grad_fn=<AddBackward0>)
0.59723979
tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>)
0.59723878
tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
0.59723788
tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
0.59723812
tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
0.59722584
tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>)
0.59722519
tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
0.59721619
tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
0.59720916
tensor(0.1566, device='cuda:0', grad_fn=<AddBackward0>)
0.59719980
tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
0.59719652
tensor(0.1357, device='cuda:0', grad_fn=<AddBackward0>)
0.59719366
tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)
0.59718186
tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
0.59717703
tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>)
0.59716517
tensor(0.1561, device='cuda:0', grad_fn=<AddBackward0>)
0.59714735
tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
0.59714210
tensor(0.1293, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [28][   60/  196]   Loss 0.165156   Top1 94.459635   Top5 99.915365   BatchTime 0.262812   LR 0.000004
0.59714657
tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>)
0.59714359
tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)
0.59713060
tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
0.59711748
tensor(0.1786, device='cuda:0', grad_fn=<AddBackward0>)
0.59711504
tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
0.59710747
tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
0.59709597
tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
0.59707451
tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)
0.59707236
tensor(0.1393, device='cuda:0', grad_fn=<AddBackward0>)
0.59707028
tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>)
0.59706074
tensor(0.1230, device='cuda:0', grad_fn=<AddBackward0>)
0.59705567
tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
0.59705168
tensor(0.1422, device='cuda:0', grad_fn=<AddBackward0>)
0.59704953
tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)
0.59704804
tensor(0.1671, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [28][   80/  196]   Loss 0.165799   Top1 94.462891   Top5 99.907227   BatchTime 0.263637   LR 0.000004
0.59704989
tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
0.59704149
tensor(0.1420, device='cuda:0', grad_fn=<AddBackward0>)
0.59704918
tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
0.59704310
tensor(0.1499, device='cuda:0', grad_fn=<AddBackward0>)
0.59703541
tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
0.59702760
tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
0.59702349
tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
0.59701079
tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
0.59701645
tensor(0.1887, device='cuda:0', grad_fn=<AddBackward0>)
0.59701496
tensor(0.1486, device='cuda:0', grad_fn=<AddBackward0>)
0.59700829
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
0.59700412
tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
0.59700048
tensor(0.1394, device='cuda:0', grad_fn=<AddBackward0>)
0.59699237
tensor(0.1864, device='cuda:0', grad_fn=<AddBackward0>)
0.59698844
tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>)
0.59697634
tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>)
0.59697002
tensor(0.1751, device='cuda:0', grad_fn=<AddBackward0>)
0.59697223
tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
0.59697187
tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
0.59696108
tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>)
0.59695232
tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
0.59693897
tensor(0.1494, device='cuda:0', grad_fn=<AddBackward0>)
0.59694761
tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
0.59694457
tensor(0.1299, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [28][  100/  196]   Loss 0.165969   Top1 94.406250   Top5 99.910156   BatchTime 0.260987   LR 0.000003
0.59694815
tensor(0.1067, device='cuda:0', grad_fn=<AddBackward0>)
0.59694463
tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
0.59693784
tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)
0.59693027
tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>)
0.59692907
tensor(0.1517, device='cuda:0', grad_fn=<AddBackward0>)
0.59691650
tensor(0.1374, device='cuda:0', grad_fn=<AddBackward0>)
0.59691924
tensor(0.1584, device='cuda:0', grad_fn=<AddBackward0>)
0.59691530
tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
0.59691119
tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
0.59690267
tensor(0.1595, device='cuda:0', grad_fn=<AddBackward0>)
0.59690231
tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
0.59689522
tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
0.59689295
tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
0.59689009
tensor(0.1677, device='cuda:0', grad_fn=<AddBackward0>)
0.59688532
tensor(0.1561, device='cuda:0', grad_fn=<AddBackward0>)
0.59688205
tensor(0.1292, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [28][  120/  196]   Loss 0.166665   Top1 94.397786   Top5 99.915365   BatchTime 0.259127   LR 0.000003
0.59688759
tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
0.59688389
tensor(0.1534, device='cuda:0', grad_fn=<AddBackward0>)
0.59688431
tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
0.59687525
tensor(0.1685, device='cuda:0', grad_fn=<AddBackward0>)
0.59687114
tensor(0.1292, device='cuda:0', grad_fn=<AddBackward0>)
0.59687412
tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
0.59687406
tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>)
0.59687334
tensor(0.1161, device='cuda:0', grad_fn=<AddBackward0>)
0.59687543
tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>)
0.59687501
tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)
0.59687394
tensor(0.1609, device='cuda:0', grad_fn=<AddBackward0>)
0.59687662
tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>)
0.59687048
tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>)
0.59686571
tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)
0.59686810
tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
0.59686750
tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
0.59686315
tensor(0.1515, device='cuda:0', grad_fn=<AddBackward0>)
0.59685379
tensor(0.1608, device='cuda:0', grad_fn=<AddBackward0>)
0.59684438
tensor(0.1501, device='cuda:0', grad_fn=<AddBackward0>)
0.59684271
tensor(0.1780, device='cuda:0', grad_fn=<AddBackward0>)
0.59683985
tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
0.59684026
tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
0.59683824
tensor(0.1598, device='cuda:0', grad_fn=<AddBackward0>)
0.59683514
tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [28][  140/  196]   Loss 0.164881   Top1 94.414062   Top5 99.924665   BatchTime 0.257880   LR 0.000003
0.59683156
tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
0.59682328
tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>)
0.59682065
tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
0.59681672
tensor(0.1703, device='cuda:0', grad_fn=<AddBackward0>)
0.59681612
tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)
0.59680992
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
0.59681648
tensor(0.1443, device='cuda:0', grad_fn=<AddBackward0>)
0.59680706
tensor(0.1316, device='cuda:0', grad_fn=<AddBackward0>)
0.59680504
tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
0.59680581
tensor(0.1514, device='cuda:0', grad_fn=<AddBackward0>)
0.59681255
tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
0.59681565
tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
0.59681106
tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
0.59681016
tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
0.59680825
tensor(0.1554, device='cuda:0', grad_fn=<AddBackward0>)
0.59680492
tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
0.59679759
tensor(0.1582, device='cuda:0', grad_fn=<AddBackward0>)
0.59679371
tensor(0.1608, device='cuda:0', grad_fn=<AddBackward0>)
0.59679919
tensor(0.1357, device='cuda:0', grad_fn=<AddBackward0>)
0.59678864
tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
0.59679371
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [28][  160/  196]   Loss 0.165469   Top1 94.450684   Top5 99.916992   BatchTime 0.260234   LR 0.000002
0.59678686
tensor(0.1204, device='cuda:0', grad_fn=<AddBackward0>)
0.59677762
tensor(0.1527, device='cuda:0', grad_fn=<AddBackward0>)
0.59677541
tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
0.59677130
tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
0.59678334
tensor(0.1734, device='cuda:0', grad_fn=<AddBackward0>)
0.59678662
tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
0.59678078
tensor(0.1660, device='cuda:0', grad_fn=<AddBackward0>)
0.59677541
tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)
0.59677774
tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
0.59677714
tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>)
0.59677684
tensor(0.1822, device='cuda:0', grad_fn=<AddBackward0>)
0.59677213
tensor(0.1657, device='cuda:0', grad_fn=<AddBackward0>)
0.59676987
tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
0.59677124
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.59677988
tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>)
0.59677953
tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
0.59678167
tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [28][  180/  196]   Loss 0.165107   Top1 94.446615   Top5 99.915365   BatchTime 0.258381   LR 0.000002
0.59677559
tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
0.59678149
tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
0.59677291
tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>)
0.59676772
tensor(0.1614, device='cuda:0', grad_fn=<AddBackward0>)
0.59676433
tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)
0.59676307
tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
0.59675014
tensor(0.1657, device='cuda:0', grad_fn=<AddBackward0>)
0.59674454
tensor(0.1432, device='cuda:0', grad_fn=<AddBackward0>)
0.59674317
tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>)
0.59675139
tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
0.59674591
tensor(0.1401, device='cuda:0', grad_fn=<AddBackward0>)
0.59674037
tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)
0.59673858
tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>)
0.59673131
tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 94.432    Top5: 99.912    Loss: 0.165
0.59672785
tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
0.59671158
tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
0.59670162
tensor(0.1457, device='cuda:0', grad_fn=<AddBackward0>)
0.59668666
tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>)
0.59665620
tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [28][   20/   40]   Loss 0.361600   Top1 88.847656   Top5 99.531250   BatchTime 0.126733
INFO - Validation [28][   40/   40]   Loss 0.350124   Top1 88.960000   Top5 99.660000   BatchTime 0.091234
INFO - ==> Top1: 88.960    Top5: 99.660    Loss: 0.350
INFO - ==> Sparsity : 0.614
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [25][Top1: 88.960   Top5: 99.650]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2847)
features.0.conv.3 tensor(0.1719)
features.1.conv.0 tensor(0.0475)
features.1.conv.3 tensor(0.0683)
features.1.conv.6 tensor(0.0933)
features.2.conv.0 tensor(0.1100)
features.2.conv.3 tensor(0.3526)
features.2.conv.6 tensor(0.4789)
features.3.conv.0 tensor(0.0726)
features.3.conv.3 tensor(0.0833)
features.3.conv.6 tensor(0.1213)
features.4.conv.0 tensor(0.0820)
features.4.conv.3 tensor(0.3015)
features.4.conv.6 tensor(0.2819)
features.5.conv.0 tensor(0.2957)
features.5.conv.3 tensor(0.4115)
features.5.conv.6 tensor(0.1414)
features.6.conv.0 tensor(0.0526)
features.6.conv.3 tensor(0.0544)
features.6.conv.6 tensor(0.0868)
features.7.conv.0 tensor(0.2243)
features.7.conv.3 tensor(0.4456)
features.7.conv.6 tensor(0.5983)
features.8.conv.0 tensor(0.5299)
features.8.conv.3 tensor(0.5402)
features.8.conv.6 tensor(0.1924)
features.9.conv.0 tensor(0.5286)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.6863)
features.10.conv.0 tensor(0.0681)
features.10.conv.3 tensor(0.0938)
features.10.conv.6 tensor(0.0685)
features.11.conv.0 tensor(0.7629)
features.11.conv.3 tensor(0.6447)
features.11.conv.6 tensor(0.8858)
features.12.conv.0 tensor(0.7439)
features.12.conv.3 tensor(0.6649)
features.12.conv.6 tensor(0.8413)
features.13.conv.0 tensor(0.2876)
features.13.conv.3 tensor(0.4842)
features.13.conv.6 tensor(0.4255)
features.14.conv.0 tensor(0.8899)
features.14.conv.3 tensor(0.8204)
features.14.conv.6 tensor(0.9534)
features.15.conv.0 tensor(0.8700)
features.15.conv.3 tensor(0.8269)
features.15.conv.6 tensor(0.9583)
features.16.conv.0 tensor(0.6826)
features.16.conv.3 tensor(0.7880)
features.16.conv.6 tensor(0.8843)
conv.0 tensor(0.1238)
tensor(1344745.) 2188896.0
0.59662014
tensor(0.1527, device='cuda:0', grad_fn=<AddBackward0>)
0.59656268
tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
0.59652954
tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
0.59647971
tensor(0.1636, device='cuda:0', grad_fn=<AddBackward0>)
0.59641796
tensor(0.1694, device='cuda:0', grad_fn=<AddBackward0>)
0.59635466
tensor(0.1477, device='cuda:0', grad_fn=<AddBackward0>)
0.59626836
tensor(0.1446, device='cuda:0', grad_fn=<AddBackward0>)
0.59619737
tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
0.59611511
tensor(0.1396, device='cuda:0', grad_fn=<AddBackward0>)
0.59601671
tensor(0.1645, device='cuda:0', grad_fn=<AddBackward0>)
0.59590608
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
0.59578675
tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>)
0.59567434
tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>)
0.59566891
tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [29][   20/  196]   Loss 0.173172   Top1 94.218750   Top5 99.902344   BatchTime 0.331148   LR 0.000001
0.59567237
tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
0.59566051
tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
0.59566438
tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
0.59566242
tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
0.59565783
tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
0.59565318
tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
0.59565747
tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)
0.59565115
tensor(0.1686, device='cuda:0', grad_fn=<AddBackward0>)
0.59564948
tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
0.59564686
tensor(0.1678, device='cuda:0', grad_fn=<AddBackward0>)
0.59564477
tensor(0.1457, device='cuda:0', grad_fn=<AddBackward0>)
0.59563732
tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
0.59563798
tensor(0.1610, device='cuda:0', grad_fn=<AddBackward0>)
0.59563673
tensor(0.1517, device='cuda:0', grad_fn=<AddBackward0>)
0.59562516
tensor(0.1591, device='cuda:0', grad_fn=<AddBackward0>)
0.59563041
tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)
0.59562147
tensor(0.1548, device='cuda:0', grad_fn=<AddBackward0>)
0.59561986
tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)
0.59562171
tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
0.59562761
tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>)
0.59562594
tensor(0.1463, device='cuda:0', grad_fn=<AddBackward0>)
0.59562874
tensor(0.1369, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [29][   40/  196]   Loss 0.165114   Top1 94.453125   Top5 99.921875   BatchTime 0.310021   LR 0.000001
0.59561819
tensor(0.1725, device='cuda:0', grad_fn=<AddBackward0>)
0.59561229
tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
0.59560782
tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)
0.59560138
tensor(0.1609, device='cuda:0', grad_fn=<AddBackward0>)
0.59560740
tensor(0.2201, device='cuda:0', grad_fn=<AddBackward0>)
0.59560543
tensor(0.1688, device='cuda:0', grad_fn=<AddBackward0>)
0.59560794
tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)
0.59560639
tensor(0.1745, device='cuda:0', grad_fn=<AddBackward0>)
0.59560364
tensor(0.1543, device='cuda:0', grad_fn=<AddBackward0>)
0.59560442
tensor(0.1126, device='cuda:0', grad_fn=<AddBackward0>)
0.59560174
tensor(0.1411, device='cuda:0', grad_fn=<AddBackward0>)
0.59559315
tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)
0.59559190
tensor(0.1050, device='cuda:0', grad_fn=<AddBackward0>)
0.59560013
tensor(0.1402, device='cuda:0', grad_fn=<AddBackward0>)
0.59559441
tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)
0.59559315
tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
0.59559119
tensor(0.1585, device='cuda:0', grad_fn=<AddBackward0>)
0.59559566
tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>)
0.59559315
tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [29][   60/  196]   Loss 0.165440   Top1 94.466146   Top5 99.941406   BatchTime 0.309504   LR 0.000001
0.59559608
tensor(0.1063, device='cuda:0', grad_fn=<AddBackward0>)
0.59559208
tensor(0.1451, device='cuda:0', grad_fn=<AddBackward0>)
0.59559435
tensor(0.1685, device='cuda:0', grad_fn=<AddBackward0>)
0.59559458
tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
0.59559590
tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
0.59559637
tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>)
0.59559768
tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>)
0.59560001
tensor(0.1309, device='cuda:0', grad_fn=<AddBackward0>)
0.59560490
tensor(0.1748, device='cuda:0', grad_fn=<AddBackward0>)
0.59559947
tensor(0.1402, device='cuda:0', grad_fn=<AddBackward0>)
0.59559363
tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
0.59559119
tensor(0.1532, device='cuda:0', grad_fn=<AddBackward0>)
0.59559214
tensor(0.1429, device='cuda:0', grad_fn=<AddBackward0>)
0.59558553
tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
0.59558243
tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
0.59558803
tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
0.59558809
tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
0.59560138
tensor(0.1755, device='cuda:0', grad_fn=<AddBackward0>)
0.59559256
tensor(0.1655, device='cuda:0', grad_fn=<AddBackward0>)
0.59559417
tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>)
0.59559816
tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [29][   80/  196]   Loss 0.168333   Top1 94.394531   Top5 99.951172   BatchTime 0.298895   LR 0.000001
0.59560329
tensor(0.1443, device='cuda:0', grad_fn=<AddBackward0>)
0.59559822
tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
0.59559053
tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>)
0.59558481
tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
0.59557968
tensor(0.1651, device='cuda:0', grad_fn=<AddBackward0>)
0.59557801
tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>)
0.59557968
tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
0.59558201
tensor(0.1346, device='cuda:0', grad_fn=<AddBackward0>)
0.59558469
tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)
0.59558493
tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)
0.59558183
tensor(0.1353, device='cuda:0', grad_fn=<AddBackward0>)
0.59558922
tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
0.59559494
tensor(0.1826, device='cuda:0', grad_fn=<AddBackward0>)
0.59558982
tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>)
0.59559304
tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
0.59559369
tensor(0.1426, device='cuda:0', grad_fn=<AddBackward0>)
0.59560013
tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>)
0.59560317
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.59559667
tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>)
0.59559309
tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>)
0.59559661
tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
0.59559387
tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
0.59559655
tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)
0.59559602
tensor(0.1429, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [29][  100/  196]   Loss 0.167145   Top1 94.390625   Top5 99.945312   BatchTime 0.289465   LR 0.000000
0.59559673
tensor(0.1822, device='cuda:0', grad_fn=<AddBackward0>)
0.59560162
tensor(0.1487, device='cuda:0', grad_fn=<AddBackward0>)
0.59559655
tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
0.59560406
tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
0.59560162
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.59560007
tensor(0.1599, device='cuda:0', grad_fn=<AddBackward0>)
0.59559542
tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
0.59559113
tensor(0.1522, device='cuda:0', grad_fn=<AddBackward0>)
0.59558690
tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
0.59558666
tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
0.59558177
tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
0.59558779
tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>)
0.59558600
tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)
0.59558541
tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>)
0.59558177
tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
0.59557790
tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [29][  120/  196]   Loss 0.170016   Top1 94.222005   Top5 99.934896   BatchTime 0.282710   LR 0.000000
0.59558457
tensor(0.1780, device='cuda:0', grad_fn=<AddBackward0>)
0.59558195
tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
0.59558439
tensor(0.1656, device='cuda:0', grad_fn=<AddBackward0>)
0.59559005
tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
0.59558141
tensor(0.1094, device='cuda:0', grad_fn=<AddBackward0>)
0.59558171
tensor(0.1677, device='cuda:0', grad_fn=<AddBackward0>)
0.59558731
tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>)
0.59558934
tensor(0.1736, device='cuda:0', grad_fn=<AddBackward0>)
0.59558553
tensor(0.1631, device='cuda:0', grad_fn=<AddBackward0>)
0.59558004
tensor(0.1240, device='cuda:0', grad_fn=<AddBackward0>)
0.59558004
tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
0.59557837
tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
0.59558201
tensor(0.1659, device='cuda:0', grad_fn=<AddBackward0>)
0.59558350
tensor(0.1334, device='cuda:0', grad_fn=<AddBackward0>)
0.59557337
tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
0.59558344
tensor(0.1670, device='cuda:0', grad_fn=<AddBackward0>)
0.59557885
tensor(0.1475, device='cuda:0', grad_fn=<AddBackward0>)
0.59558642
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
0.59558219
tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>)
0.59557736
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.59558052
tensor(0.1667, device='cuda:0', grad_fn=<AddBackward0>)
0.59558344
tensor(0.1552, device='cuda:0', grad_fn=<AddBackward0>)
0.59558249
tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
0.59557647
tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [29][  140/  196]   Loss 0.168391   Top1 94.291295   Top5 99.930246   BatchTime 0.278300   LR 0.000000
0.59557909
tensor(0.1386, device='cuda:0', grad_fn=<AddBackward0>)
0.59557760
tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>)
0.59557199
tensor(0.1295, device='cuda:0', grad_fn=<AddBackward0>)
0.59556651
tensor(0.1645, device='cuda:0', grad_fn=<AddBackward0>)
0.59557599
tensor(0.1401, device='cuda:0', grad_fn=<AddBackward0>)
0.59557050
tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
0.59557408
tensor(0.1561, device='cuda:0', grad_fn=<AddBackward0>)
0.59557474
tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>)
0.59557503
tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>)
0.59557921
tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
0.59557867
tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
0.59558016
tensor(0.1182, device='cuda:0', grad_fn=<AddBackward0>)
0.59558803
tensor(0.1675, device='cuda:0', grad_fn=<AddBackward0>)
0.59558409
tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>)
0.59558606
tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>)
0.59559065
tensor(0.1653, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [29][  160/  196]   Loss 0.166572   Top1 94.345703   Top5 99.936523   BatchTime 0.275895   LR 0.000000
0.59558839
tensor(0.1543, device='cuda:0', grad_fn=<AddBackward0>)
0.59558511
tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
0.59558284
tensor(0.1521, device='cuda:0', grad_fn=<AddBackward0>)
0.59558475
tensor(0.1533, device='cuda:0', grad_fn=<AddBackward0>)
0.59558445
tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
0.59557909
tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
0.59556872
tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
0.59557319
tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
0.59557432
tensor(0.1566, device='cuda:0', grad_fn=<AddBackward0>)
0.59557670
tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
0.59557354
tensor(0.1036, device='cuda:0', grad_fn=<AddBackward0>)
0.59557503
tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>)
0.59557682
tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
0.59557736
tensor(0.1762, device='cuda:0', grad_fn=<AddBackward0>)
0.59557557
tensor(0.1627, device='cuda:0', grad_fn=<AddBackward0>)
0.59557581
tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
0.59557492
tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
0.59557682
tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
0.59557647
tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>)
0.59558266
tensor(0.1736, device='cuda:0', grad_fn=<AddBackward0>)
0.59558356
tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [29][  180/  196]   Loss 0.168009   Top1 94.333767   Top5 99.924045   BatchTime 0.278178   LR 0.000000
0.59558624
tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
0.59558386
tensor(0.1698, device='cuda:0', grad_fn=<AddBackward0>)
0.59558636
tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
0.59557760
tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>)
0.59558105
tensor(0.1496, device='cuda:0', grad_fn=<AddBackward0>)
0.59558809
tensor(0.1486, device='cuda:0', grad_fn=<AddBackward0>)
0.59557748
tensor(0.1495, device='cuda:0', grad_fn=<AddBackward0>)
0.59557545
tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
0.59556603
tensor(0.1271, device='cuda:0', grad_fn=<AddBackward0>)
0.59556502
tensor(0.1421, device='cuda:0', grad_fn=<AddBackward0>)
0.59556752
tensor(0.1878, device='cuda:0', grad_fn=<AddBackward0>)
0.59556770
tensor(0.1561, device='cuda:0', grad_fn=<AddBackward0>)
0.59556717
tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)
0.59556043
tensor(0.1760, device='cuda:0', grad_fn=<AddBackward0>)
0.59556109
tensor(0.1135, device='cuda:0', grad_fn=<AddBackward0>)
0.59555835
tensor(0.1489, device='cuda:0', grad_fn=<AddBackward0>)
0.59556663
tensor(0.1511, device='cuda:0', grad_fn=<AddBackward0>)
0.59556586
tensor(0.1776, device='cuda:0', grad_fn=<AddBackward0>)
0.59557068
tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 94.386    Top5: 99.924    Loss: 0.167
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [29][   20/   40]   Loss 0.364486   Top1 88.984375   Top5 99.667969   BatchTime 0.124364
INFO - Validation [29][   40/   40]   Loss 0.352443   Top1 88.960000   Top5 99.720000   BatchTime 0.088244
INFO - ==> Top1: 88.960    Top5: 99.720    Loss: 0.352
INFO - ==> Sparsity : 0.615
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2847)
features.0.conv.3 tensor(0.1719)
features.1.conv.0 tensor(0.0482)
features.1.conv.3 tensor(0.0683)
features.1.conv.6 tensor(0.0933)
features.2.conv.0 tensor(0.1102)
features.2.conv.3 tensor(0.3534)
features.2.conv.6 tensor(0.4795)
features.3.conv.0 tensor(0.0723)
features.3.conv.3 tensor(0.0833)
features.3.conv.6 tensor(0.1213)
features.4.conv.0 tensor(0.0825)
features.4.conv.3 tensor(0.3015)
features.4.conv.6 tensor(0.2821)
features.5.conv.0 tensor(0.2956)
features.5.conv.3 tensor(0.4115)
features.5.conv.6 tensor(0.1414)
features.6.conv.0 tensor(0.0526)
features.6.conv.3 tensor(0.0550)
features.6.conv.6 tensor(0.0866)
features.7.conv.0 tensor(0.2309)
features.7.conv.3 tensor(0.4456)
features.7.conv.6 tensor(0.5983)
features.8.conv.0 tensor(0.5301)
features.8.conv.3 tensor(0.5396)
features.8.conv.6 tensor(0.1923)
features.9.conv.0 tensor(0.5289)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.6864)
features.10.conv.0 tensor(0.0682)
features.10.conv.3 tensor(0.0938)
features.10.conv.6 tensor(0.0684)
features.11.conv.0 tensor(0.7631)
features.11.conv.3 tensor(0.6447)
features.11.conv.6 tensor(0.8858)
features.12.conv.0 tensor(0.7441)
features.12.conv.3 tensor(0.6647)
features.12.conv.6 tensor(0.8415)
features.13.conv.0 tensor(0.2877)
features.13.conv.3 tensor(0.4842)
features.13.conv.6 tensor(0.4265)
features.14.conv.0 tensor(0.8899)
features.14.conv.3 tensor(0.8205)
features.14.conv.6 tensor(0.9534)
features.15.conv.0 tensor(0.8700)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9583)
features.16.conv.0 tensor(0.6829)
features.16.conv.3 tensor(0.7880)
features.16.conv.6 tensor(0.8844)
conv.0 tensor(0.1239)
tensor(1345156.) 2188896.0
0.59558952
tensor(0.1312, device='cuda:0', grad_fn=<AddBackward0>)
0.59520286
tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
0.59483415
tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
0.59447438
tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
0.59415579
tensor(0.1565, device='cuda:0', grad_fn=<AddBackward0>)
0.59398931
tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
0.59394026
tensor(0.1458, device='cuda:0', grad_fn=<AddBackward0>)
0.59399378
tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
0.59395844
tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
0.59394914
tensor(0.1623, device='cuda:0', grad_fn=<AddBackward0>)
0.59385997
tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
0.59369236
tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
0.59354752
tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>)
0.59348798
tensor(0.1715, device='cuda:0', grad_fn=<AddBackward0>)
0.59340107
tensor(0.1726, device='cuda:0', grad_fn=<AddBackward0>)
0.59346336
tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
0.59349221
tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [30][   20/  196]   Loss 0.179863   Top1 94.042969   Top5 99.902344   BatchTime 0.372239   LR 0.000125
0.59358966
tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>)
0.59360749
tensor(0.1343, device='cuda:0', grad_fn=<AddBackward0>)
0.59359014
tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)
0.59353596
tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
0.59353459
tensor(0.1451, device='cuda:0', grad_fn=<AddBackward0>)
0.59347165
tensor(0.1688, device='cuda:0', grad_fn=<AddBackward0>)
0.59437943
tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
0.59453976
tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
0.59457272
tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
0.59466439
tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)
0.59465927
tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
0.59463459
tensor(0.1216, device='cuda:0', grad_fn=<AddBackward0>)
0.59462422
tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)
0.59467751
tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
0.59464920
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
0.59463525
tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
0.59467125
tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>)
0.59477007
tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>)
0.59484941
tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
0.59487027
tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
0.59490830
tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
0.59503084
tensor(0.1756, device='cuda:0', grad_fn=<AddBackward0>)
0.59527308
tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [30][   40/  196]   Loss 0.189643   Top1 93.623047   Top5 99.912109   BatchTime 0.312405   LR 0.000125
0.59662598
tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>)
0.59665269
tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
0.59660763
tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)
0.59661269
tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)
0.59664851
tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
0.59666657
tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
0.59674007
tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
0.59677178
tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
0.59674138
tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
0.59672630
tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
0.59667617
tensor(0.1600, device='cuda:0', grad_fn=<AddBackward0>)
0.59663337
tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
0.59660029
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
0.59658772
tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)
0.59654021
tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
0.59670830
tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [30][   60/  196]   Loss 0.198809   Top1 93.320312   Top5 99.882812   BatchTime 0.293049   LR 0.000125
0.59645319
tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
0.59635353
tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
0.59641570
tensor(0.1766, device='cuda:0', grad_fn=<AddBackward0>)
0.59647709
tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
0.59660149
tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>)
0.59675974
tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
0.59654582
tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
0.59656030
tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
0.59671640
tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
0.59666198
tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
0.59671259
tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
0.59664828
tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
0.59666789
tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
0.59670657
tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
0.59673500
tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>)
0.59674060
tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
0.59674489
tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
0.59680629
tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)
0.59682769
tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)
0.59688318
tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>)
0.59691781
tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
0.59693545
tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>)
0.59702057
tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
0.59716237
tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [30][   80/  196]   Loss 0.204075   Top1 93.154297   Top5 99.882812   BatchTime 0.282231   LR 0.000125
0.59699821
tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
0.59700090
tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>)
0.59705979
tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
0.59715456
tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
0.59722072
tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
0.59732282
tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
0.59750515
tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
0.59790486
tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>)
0.59811366
tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
0.59820640
tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
0.59819943
tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
0.59813237
tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
0.59815729
tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
0.59818554
tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
0.59832609
tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
0.59838229
tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
0.59842128
tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)
0.59863377
tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
0.59888023
tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
0.59931260
tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>)
0.60052413
tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [30][  100/  196]   Loss 0.210445   Top1 92.941406   Top5 99.882812   BatchTime 0.283158   LR 0.000125
0.60051394
tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
0.60047472
tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)
0.60047913
tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
0.60051012
tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
0.60061747
tensor(0.1696, device='cuda:0', grad_fn=<AddBackward0>)
0.60044694
tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)
0.60037392
tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
0.60029763
tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
0.60017699
tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
0.60004687
tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
0.59994543
tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
0.59986329
tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>)
0.59988266
tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
0.59985423
tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [30][  120/  196]   Loss 0.213312   Top1 92.838542   Top5 99.879557   BatchTime 0.281141   LR 0.000125
0.59979790
tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
0.59980166
tensor(0.1571, device='cuda:0', grad_fn=<AddBackward0>)
0.59988493
tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
0.59985346
tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
0.59963655
tensor(0.1518, device='cuda:0', grad_fn=<AddBackward0>)
0.59954888
tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
0.59945905
tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
0.59944153
tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
0.59939140
tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
0.59943759
tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
0.59948117
tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
0.59945637
tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>)
0.59957939
tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
0.59937423
tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
0.59937733
tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
0.59932798
tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
0.59928948
tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
0.59936106
tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)
0.59939206
tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)
0.59935153
tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>)
0.59933496
tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
0.59924197
tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
0.59926826
tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [30][  140/  196]   Loss 0.217074   Top1 92.737165   Top5 99.866071   BatchTime 0.279070   LR 0.000125
0.59933609
tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)
0.59926784
tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>)
0.59919006
tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
0.59918612
tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)
0.59923059
tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
0.59925365
tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
0.59928697
tensor(0.1755, device='cuda:0', grad_fn=<AddBackward0>)
0.59935898
tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
0.59923941
tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
0.59924686
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.59935433
tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
0.59920341
tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
0.59934092
tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
0.59933650
tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
0.59941792
tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
0.59935158
tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [30][  160/  196]   Loss 0.217356   Top1 92.705078   Top5 99.868164   BatchTime 0.275499   LR 0.000125
0.59944731
tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
0.59943974
tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
0.59937209
tensor(0.1655, device='cuda:0', grad_fn=<AddBackward0>)
0.59927380
tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
0.59933627
tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
0.59932590
tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
0.59949625
tensor(0.1672, device='cuda:0', grad_fn=<AddBackward0>)
0.59956318
tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
0.59954309
tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
0.59954226
tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
0.59941775
tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>)
0.59935415
tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
0.59929651
tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>)
0.59923059
tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>)
0.59911484
tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
0.59906542
tensor(0.1769, device='cuda:0', grad_fn=<AddBackward0>)
0.59911078
tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)
0.59904957
tensor(0.1608, device='cuda:0', grad_fn=<AddBackward0>)
0.59897298
tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
0.59893566
tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>)
0.59884197
tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
0.59876257
tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
0.59869683
tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)
0.59858948
tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [30][  180/  196]   Loss 0.217370   Top1 92.656250   Top5 99.867622   BatchTime 0.272573   LR 0.000125
0.59857613
tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>)
0.59853321
tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
0.59839350
tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
0.59832770
tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
0.59835231
tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
0.59820902
tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
0.59813052
tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
0.59798658
tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)
0.59790117
tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
0.59772056
tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
0.59771919
tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
0.59771591
tensor(0.1725, device='cuda:0', grad_fn=<AddBackward0>)
0.59777194
tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
0.59772855
tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)
0.59773314
tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
0.59777373
tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 92.692    Top5: 99.868    Loss: 0.217
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.59771514
tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>)
0.59754801
tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 0.396642   Top1 88.085938   Top5 99.316406   BatchTime 0.117764
INFO - Validation [30][   40/   40]   Loss 0.383481   Top1 88.190000   Top5 99.540000   BatchTime 0.083878
INFO - ==> Top1: 88.190    Top5: 99.540    Loss: 0.383
INFO - ==> Sparsity : 0.611
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1562)
features.1.conv.0 tensor(0.0508)
features.1.conv.3 tensor(0.0671)
features.1.conv.6 tensor(0.1007)
features.2.conv.0 tensor(0.1039)
features.2.conv.3 tensor(0.3526)
features.2.conv.6 tensor(0.4899)
features.3.conv.0 tensor(0.0697)
features.3.conv.3 tensor(0.0779)
features.3.conv.6 tensor(0.1098)
features.4.conv.0 tensor(0.0757)
features.4.conv.3 tensor(0.3003)
features.4.conv.6 tensor(0.2944)
features.5.conv.0 tensor(0.2707)
features.5.conv.3 tensor(0.4132)
features.5.conv.6 tensor(0.1515)
features.6.conv.0 tensor(0.0518)
features.6.conv.3 tensor(0.0527)
features.6.conv.6 tensor(0.0857)
features.7.conv.0 tensor(0.2166)
features.7.conv.3 tensor(0.4468)
features.7.conv.6 tensor(0.6011)
features.8.conv.0 tensor(0.4956)
features.8.conv.3 tensor(0.5388)
features.8.conv.6 tensor(0.2476)
features.9.conv.0 tensor(0.4849)
features.9.conv.3 tensor(0.5628)
features.9.conv.6 tensor(0.7004)
features.10.conv.0 tensor(0.0703)
features.10.conv.3 tensor(0.0926)
features.10.conv.6 tensor(0.0694)
features.11.conv.0 tensor(0.7600)
features.11.conv.3 tensor(0.6453)
features.11.conv.6 tensor(0.8856)
features.12.conv.0 tensor(0.7353)
features.12.conv.3 tensor(0.6642)
features.12.conv.6 tensor(0.8405)
features.13.conv.0 tensor(0.2554)
features.13.conv.3 tensor(0.4877)
features.13.conv.6 tensor(0.4437)
features.14.conv.0 tensor(0.8927)
features.14.conv.3 tensor(0.8192)
features.14.conv.6 tensor(0.9498)
features.15.conv.0 tensor(0.8726)
features.15.conv.3 tensor(0.8266)
features.15.conv.6 tensor(0.9582)
features.16.conv.0 tensor(0.6692)
features.16.conv.3 tensor(0.7892)
features.16.conv.6 tensor(0.8831)
conv.0 tensor(0.1152)
tensor(1337906.) 2188896.0
0.59754103
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.59739953
tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>)
0.59741223
tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)
0.59737843
tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
0.59737217
tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>)
0.59738845
tensor(0.1764, device='cuda:0', grad_fn=<AddBackward0>)
0.59748292
tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>)
0.59750557
tensor(0.1662, device='cuda:0', grad_fn=<AddBackward0>)
0.59753764
tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>)
0.59757370
tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
0.59759659
tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
0.59749782
tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
0.59736025
tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
0.59734493
tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
0.59751618
tensor(0.1591, device='cuda:0', grad_fn=<AddBackward0>)
0.59714347
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
0.59707332
tensor(0.1677, device='cuda:0', grad_fn=<AddBackward0>)
0.59712082
tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
0.59713858
tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)
0.59715807
tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
0.59714782
tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [31][   20/  196]   Loss 0.205721   Top1 92.871094   Top5 99.843750   BatchTime 0.312624   LR 0.000125
0.59711808
tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
0.59711266
tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
0.59711814
tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
0.59717280
tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
0.59714085
tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
0.59732395
tensor(0.1600, device='cuda:0', grad_fn=<AddBackward0>)
0.59729367
tensor(0.1598, device='cuda:0', grad_fn=<AddBackward0>)
0.59733307
tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)
0.59727949
tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
0.59706718
tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
0.59711266
tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
0.59732592
tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>)
0.59713322
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.59687567
tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [31][   40/  196]   Loss 0.205065   Top1 93.037109   Top5 99.853516   BatchTime 0.294536   LR 0.000125
0.59679061
tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
0.59662104
tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
0.59656072
tensor(0.1825, device='cuda:0', grad_fn=<AddBackward0>)
0.59654754
tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
0.59661192
tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
0.59670067
tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
0.59665990
tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)
0.59672421
tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
0.59654725
tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
0.59661520
tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>)
0.59674197
tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
0.59694052
tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
0.59702152
tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
0.59695745
tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
0.59699577
tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
0.59686607
tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>)
0.59676045
tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)
0.59695488
tensor(0.2100, device='cuda:0', grad_fn=<AddBackward0>)
0.59676409
tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>)
0.59679413
tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>)
0.59669888
tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
0.59663045
tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [31][   60/  196]   Loss 0.205201   Top1 93.001302   Top5 99.843750   BatchTime 0.286509   LR 0.000125
0.59662575
tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>)
0.59669608
tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
0.59672523
tensor(0.1532, device='cuda:0', grad_fn=<AddBackward0>)
0.59671092
tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
0.59671509
tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
0.59672922
tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>)
0.59668857
tensor(0.1441, device='cuda:0', grad_fn=<AddBackward0>)
0.59662557
tensor(0.1691, device='cuda:0', grad_fn=<AddBackward0>)
0.59652883
tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)
0.59642285
tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
0.59639120
tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
0.59638166
tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)
0.59639585
tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
0.59636033
tensor(0.1570, device='cuda:0', grad_fn=<AddBackward0>)
0.59650576
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.59675741
tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
0.59698904
tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
0.59671795
tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
0.59663600
tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
0.59648043
tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
0.59652025
tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
0.59645766
tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
0.59619635
tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)
0.59608001
tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
0.59613955
tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [31][   80/  196]   Loss 0.208437   Top1 92.968750   Top5 99.858398   BatchTime 0.276434   LR 0.000125
0.59624451
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.59594733
tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>)
0.59553784
tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
0.59532243
tensor(0.1603, device='cuda:0', grad_fn=<AddBackward0>)
0.59519923
tensor(0.1745, device='cuda:0', grad_fn=<AddBackward0>)
0.59507233
tensor(0.1504, device='cuda:0', grad_fn=<AddBackward0>)
0.59494692
tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)
0.59460640
tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
0.59428507
tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
0.59427577
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.59428495
tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)
0.59426153
tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>)
0.59398258
tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
0.59391516
tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
0.59389162
tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
0.59372383
tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [31][  100/  196]   Loss 0.206521   Top1 93.039062   Top5 99.878906   BatchTime 0.271097   LR 0.000125
0.59343284
tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
0.59333509
tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>)
0.59326321
tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
0.59342343
tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)
0.59359986
tensor(0.1191, device='cuda:0', grad_fn=<AddBackward0>)
0.59335822
tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>)
0.59325373
tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
0.59302062
tensor(0.1766, device='cuda:0', grad_fn=<AddBackward0>)
0.59282601
tensor(0.1759, device='cuda:0', grad_fn=<AddBackward0>)
0.59263152
tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
0.59273905
tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
0.59266067
tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
0.59242356
tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)
0.59233737
tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
0.59222186
tensor(0.1575, device='cuda:0', grad_fn=<AddBackward0>)
0.59219289
tensor(0.1554, device='cuda:0', grad_fn=<AddBackward0>)
0.59209377
tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
0.59214753
tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)
0.59231770
tensor(0.1488, device='cuda:0', grad_fn=<AddBackward0>)
0.59228212
tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
0.59207118
tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)
0.59242630
tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
0.59244007
tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
0.59248006
tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [31][  120/  196]   Loss 0.206634   Top1 93.056641   Top5 99.879557   BatchTime 0.267841   LR 0.000125
0.59255546
tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)
0.59270149
tensor(0.1592, device='cuda:0', grad_fn=<AddBackward0>)
0.59279341
tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
0.59267271
tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)
0.59247375
tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
0.59253508
tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
0.59264231
tensor(0.1697, device='cuda:0', grad_fn=<AddBackward0>)
0.59268713
tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>)
0.59275550
tensor(0.1687, device='cuda:0', grad_fn=<AddBackward0>)
0.59279734
tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
0.59265697
tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
0.59256846
tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
0.59247005
tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>)
0.59244311
tensor(0.2854, device='cuda:0', grad_fn=<AddBackward0>)
0.59233588
tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
0.59219855
tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [31][  140/  196]   Loss 0.208723   Top1 93.002232   Top5 99.877232   BatchTime 0.265003   LR 0.000124
0.59235573
tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
0.59220940
tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
0.59209603
tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
0.59229624
tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
0.59278244
tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)
0.59286308
tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
0.59314758
tensor(0.1487, device='cuda:0', grad_fn=<AddBackward0>)
0.59329653
tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
0.59356475
tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
0.59383440
tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
0.59428197
tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
0.59424794
tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
0.59438300
tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>)
0.59471309
tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
0.59505820
tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>)
0.59537607
tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)
0.59584987
tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)
0.59610343
tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>)
0.59628171
tensor(0.1734, device='cuda:0', grad_fn=<AddBackward0>)
0.59665567
tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
0.59709793
tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)
0.59734905
tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)
0.59725785
tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [31][  160/  196]   Loss 0.211039   Top1 92.883301   Top5 99.873047   BatchTime 0.265021   LR 0.000124
0.59726888
tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)
0.59736019
tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
0.59750766
tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
0.59744638
tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
0.59734446
tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
0.59729970
tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
0.59733278
tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)
0.59720075
tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
0.59709346
tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
0.59732360
tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)
0.59737331
tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)
0.59730172
tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
0.59723204
tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
0.59706682
tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
0.59701008
tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
0.59711701
tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [31][  180/  196]   Loss 0.214181   Top1 92.747396   Top5 99.878472   BatchTime 0.263262   LR 0.000124
0.59714866
tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
0.59729421
tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
0.59739280
tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
0.59751308
tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
0.59732825
tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
0.59720290
tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
0.59731883
tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
0.59732145
tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
0.59724897
tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)
0.59713262
tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>)
0.59711468
tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
0.59705871
tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
0.59692860
tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
0.59677827
tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
0.59677619
tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
0.59677386
tensor(0.1437, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 92.710    Top5: 99.886    Loss: 0.215
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.59669161
tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
0.59686756
tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>)
0.59668505
tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [31][   20/   40]   Loss 0.397995   Top1 87.695312   Top5 99.453125   BatchTime 0.129973
INFO - Validation [31][   40/   40]   Loss 0.379565   Top1 87.980000   Top5 99.560000   BatchTime 0.091394
INFO - ==> Top1: 87.980    Top5: 99.560    Loss: 0.380
INFO - ==> Sparsity : 0.613
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2743)
features.0.conv.3 tensor(0.1504)
features.1.conv.0 tensor(0.0508)
features.1.conv.3 tensor(0.0671)
features.1.conv.6 tensor(0.0942)
features.2.conv.0 tensor(0.0955)
features.2.conv.3 tensor(0.3472)
features.2.conv.6 tensor(0.4876)
features.3.conv.0 tensor(0.0726)
features.3.conv.3 tensor(0.0725)
features.3.conv.6 tensor(0.1105)
features.4.conv.0 tensor(0.0773)
features.4.conv.3 tensor(0.2957)
features.4.conv.6 tensor(0.2965)
features.5.conv.0 tensor(0.3021)
features.5.conv.3 tensor(0.4155)
features.5.conv.6 tensor(0.1589)
features.6.conv.0 tensor(0.0480)
features.6.conv.3 tensor(0.0561)
features.6.conv.6 tensor(0.0840)
features.7.conv.0 tensor(0.2180)
features.7.conv.3 tensor(0.4479)
features.7.conv.6 tensor(0.6014)
features.8.conv.0 tensor(0.4914)
features.8.conv.3 tensor(0.5359)
features.8.conv.6 tensor(0.2710)
features.9.conv.0 tensor(0.4684)
features.9.conv.3 tensor(0.5663)
features.9.conv.6 tensor(0.7034)
features.10.conv.0 tensor(0.0671)
features.10.conv.3 tensor(0.0923)
features.10.conv.6 tensor(0.0691)
features.11.conv.0 tensor(0.7498)
features.11.conv.3 tensor(0.6453)
features.11.conv.6 tensor(0.8900)
features.12.conv.0 tensor(0.7248)
features.12.conv.3 tensor(0.6642)
features.12.conv.6 tensor(0.8452)
features.13.conv.0 tensor(0.2537)
features.13.conv.3 tensor(0.4869)
features.13.conv.6 tensor(0.4527)
features.14.conv.0 tensor(0.8951)
features.14.conv.3 tensor(0.8204)
features.14.conv.6 tensor(0.9527)
features.15.conv.0 tensor(0.8737)
features.15.conv.3 tensor(0.8272)
features.15.conv.6 tensor(0.9581)
features.16.conv.0 tensor(0.6616)
features.16.conv.3 tensor(0.7890)
features.16.conv.6 tensor(0.8809)
conv.0 tensor(0.1236)
tensor(1340822.) 2188896.0
0.59657264
tensor(0.1099, device='cuda:0', grad_fn=<AddBackward0>)
0.59644455
tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)
0.59631652
tensor(0.1516, device='cuda:0', grad_fn=<AddBackward0>)
0.59629726
tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
0.59619772
tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
0.59598744
tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
0.59590000
tensor(0.1736, device='cuda:0', grad_fn=<AddBackward0>)
0.59590197
tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
0.59588581
tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>)
0.59591341
tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
0.59591728
tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
0.59567600
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.59553736
tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
0.59542090
tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
0.59544730
tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [32][   20/  196]   Loss 0.215030   Top1 92.792969   Top5 99.824219   BatchTime 0.327308   LR 0.000124
0.59535730
tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)
0.59524083
tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>)
0.59512073
tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>)
0.59520233
tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)
0.59505212
tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
0.59487116
tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>)
0.59492838
tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
0.59486490
tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
0.59490085
tensor(0.1595, device='cuda:0', grad_fn=<AddBackward0>)
0.59472412
tensor(0.1483, device='cuda:0', grad_fn=<AddBackward0>)
0.59454370
tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
0.59420031
tensor(0.1770, device='cuda:0', grad_fn=<AddBackward0>)
0.59410632
tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
0.59399563
tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
0.59394431
tensor(0.1670, device='cuda:0', grad_fn=<AddBackward0>)
0.59384662
tensor(0.1674, device='cuda:0', grad_fn=<AddBackward0>)
0.59388518
tensor(0.1752, device='cuda:0', grad_fn=<AddBackward0>)
0.59394264
tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
0.59413415
tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
0.59430319
tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>)
0.59446198
tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
0.59472966
tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
0.59484708
tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [32][   40/  196]   Loss 0.203318   Top1 93.203125   Top5 99.882812   BatchTime 0.289540   LR 0.000124
0.59487188
tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
0.59492177
tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
0.59491688
tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
0.59492022
tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
0.59499973
tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
0.59493500
tensor(0.1878, device='cuda:0', grad_fn=<AddBackward0>)
0.59490663
tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
0.59493816
tensor(0.1661, device='cuda:0', grad_fn=<AddBackward0>)
0.59495884
tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
0.59493279
tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>)
0.59490520
tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
0.59486264
tensor(0.1513, device='cuda:0', grad_fn=<AddBackward0>)
0.59498787
tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
0.59528291
tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
0.59504855
tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
0.59511578
tensor(0.1665, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [32][   60/  196]   Loss 0.206740   Top1 93.131510   Top5 99.876302   BatchTime 0.276836   LR 0.000124
0.59521830
tensor(0.1344, device='cuda:0', grad_fn=<AddBackward0>)
0.59514201
tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)
0.59494495
tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
0.59513909
tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
0.59525579
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.59523606
tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
0.59513217
tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
0.59508109
tensor(0.1698, device='cuda:0', grad_fn=<AddBackward0>)
0.59518588
tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
0.59525251
tensor(0.1549, device='cuda:0', grad_fn=<AddBackward0>)
0.59524852
tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
0.59511667
tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)
0.59516221
tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
0.59517568
tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>)
0.59510982
tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>)
0.59502828
tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
0.59498674
tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
0.59495068
tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)
0.59497845
tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
0.59501696
tensor(0.2154, device='cuda:0', grad_fn=<AddBackward0>)
0.59504354
tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
0.59514380
tensor(0.1727, device='cuda:0', grad_fn=<AddBackward0>)
0.59519821
tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [32][   80/  196]   Loss 0.207877   Top1 93.017578   Top5 99.863281   BatchTime 0.274648   LR 0.000124
0.59527421
tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
0.59510040
tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
0.59490412
tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
0.59485525
tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)
0.59487087
tensor(0.1623, device='cuda:0', grad_fn=<AddBackward0>)
0.59495693
tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
0.59499055
tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
0.59498161
tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
0.59477061
tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>)
0.59479445
tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
0.59490091
tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)
0.59492642
tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>)
0.59490824
tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>)
0.59478414
tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)
0.59470379
tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
0.59452397
tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
0.59481072
tensor(0.1661, device='cuda:0', grad_fn=<AddBackward0>)
0.59477913
tensor(0.1557, device='cuda:0', grad_fn=<AddBackward0>)
0.59468144
tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)
0.59455389
tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
0.59444696
tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
0.59458607
tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [32][  100/  196]   Loss 0.208966   Top1 92.941406   Top5 99.859375   BatchTime 0.275315   LR 0.000124
0.59464461
tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
0.59456825
tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>)
0.59433758
tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)
0.59449935
tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
0.59469467
tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)
0.59452218
tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
0.59446549
tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
0.59455812
tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
0.59456879
tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
0.59456366
tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
0.59457755
tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
0.59458667
tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>)
0.59469277
tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
0.59474808
tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>)
0.59483480
tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [32][  120/  196]   Loss 0.214829   Top1 92.737630   Top5 99.853516   BatchTime 0.271553   LR 0.000124
0.59478849
tensor(0.1783, device='cuda:0', grad_fn=<AddBackward0>)
0.59454823
tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
0.59464175
tensor(0.1659, device='cuda:0', grad_fn=<AddBackward0>)
0.59477288
tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)
0.59483212
tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
0.59471411
tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
0.59441859
tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
0.59443164
tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)
0.59442383
tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
0.59441239
tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
0.59433913
tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)
0.59427422
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.59425163
tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
0.59419769
tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
0.59413415
tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>)
0.59405833
tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)
0.59401119
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.59400326
tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
0.59403461
tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
0.59413397
tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
0.59423983
tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
0.59428102
tensor(0.1466, device='cuda:0', grad_fn=<AddBackward0>)
0.59437203
tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>)
0.59454930
tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
0.59455746
tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [32][  140/  196]   Loss 0.215196   Top1 92.770647   Top5 99.849330   BatchTime 0.268623   LR 0.000124
0.59429485
tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
0.59404469
tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
0.59380203
tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
0.59382695
tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
0.59394699
tensor(0.1656, device='cuda:0', grad_fn=<AddBackward0>)
0.59410274
tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
0.59391141
tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
0.59398270
tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
0.59412891
tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>)
0.59393084
tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
0.59390169
tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
0.59387004
tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
0.59371525
tensor(0.1562, device='cuda:0', grad_fn=<AddBackward0>)
0.59364009
tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
0.59362030
tensor(0.1807, device='cuda:0', grad_fn=<AddBackward0>)
0.59364665
tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [32][  160/  196]   Loss 0.214314   Top1 92.763672   Top5 99.848633   BatchTime 0.266070   LR 0.000123
0.59372431
tensor(0.2201, device='cuda:0', grad_fn=<AddBackward0>)
0.59365016
tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>)
0.59359294
tensor(0.1887, device='cuda:0', grad_fn=<AddBackward0>)
0.59346730
tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
0.59338814
tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>)
0.59334207
tensor(0.2495, device='cuda:0', grad_fn=<AddBackward0>)
0.59324092
tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>)
0.59321201
tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
0.59311920
tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
0.59304184
tensor(0.1724, device='cuda:0', grad_fn=<AddBackward0>)
0.59307551
tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
0.59310132
tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
0.59360403
tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
0.59491706
tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
0.59504431
tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
0.59483606
tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
0.59485167
tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
0.59470356
tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
0.59441757
tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>)
0.59440255
tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
0.59423476
tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>)
0.59417635
tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
0.59409577
tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>)
0.59399521
tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [32][  180/  196]   Loss 0.215565   Top1 92.664931   Top5 99.863281   BatchTime 0.264271   LR 0.000123
0.59383965
tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
0.59370875
tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
0.59333074
tensor(0.1765, device='cuda:0', grad_fn=<AddBackward0>)
0.59319758
tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
0.59324712
tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
0.59313494
tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>)
0.59317386
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.59306562
tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
0.59282452
tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
0.59279114
tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
0.59283549
tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
0.59293514
tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
0.59286100
tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
0.59285599
tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
0.59262413
tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
0.59240216
tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 92.710    Top5: 99.858    Loss: 0.215
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.59252799
tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 0.389011   Top1 88.144531   Top5 99.492188   BatchTime 0.129023
INFO - Validation [32][   40/   40]   Loss 0.382280   Top1 88.130000   Top5 99.600000   BatchTime 0.091300
features.0.conv.0 tensor(0.2847)
features.0.conv.3 tensor(0.1660)
features.1.conv.0 tensor(0.0436)
features.1.conv.3 tensor(0.0694)
features.1.conv.6 tensor(0.0968)
features.2.conv.0 tensor(0.0885)
features.2.conv.3 tensor(0.3465)
features.2.conv.6 tensor(0.4919)
features.3.conv.0 tensor(0.0712)
features.3.conv.3 tensor(0.0787)
features.3.conv.6 tensor(0.1120)
features.4.conv.0 tensor(0.0695)
features.4.conv.3 tensor(0.2998)
features.4.conv.6 tensor(0.3140)
features.5.conv.0 tensor(0.2861)
features.5.conv.3 tensor(0.4155)
features.5.conv.6 tensor(0.1730)
features.6.conv.0 tensor(0.0518)
features.6.conv.3 tensor(0.0532)
features.6.conv.6 tensor(0.0828)
features.7.conv.0 tensor(0.2146)
features.7.conv.3 tensor(0.4491)
features.7.conv.6 tensor(0.6079)
features.8.conv.0 tensor(0.4882)
features.8.conv.3 tensor(0.5382)
features.8.conv.6 tensor(0.3417)
features.9.conv.0 tensor(0.4628)
features.9.conv.3 tensor(0.5677)
features.9.conv.6 tensor(0.7164)
features.10.conv.0 tensor(0.0640)
features.10.conv.3 tensor(0.0917)
features.10.conv.6 tensor(0.0697)
features.11.conv.0 tensor(0.7384)
features.11.conv.3 tensor(0.6445)
features.11.conv.6 tensor(0.8923)
features.12.conv.0 tensor(0.7153)
features.12.conv.3 tensor(0.6638)
features.12.conv.6 tensor(0.8496)
features.13.conv.0 tensor(0.2571)
features.13.conv.3 tensor(0.4846)
features.13.conv.6 tensor(0.4408)
features.14.conv.0 tensor(0.8953)
features.14.conv.3 tensor(0.8209)
features.14.conv.6 tensor(0.9524)
features.15.conv.0 tensor(0.8750)
features.15.conv.3 tensor(0.8271)
features.15.conv.6 tensor(0.9586)
features.16.conv.0 tensor(0.6635)
features.16.conv.3 tensor(0.7884)
features.16.conv.6 tensor(0.8817)
conv.0 tensor(0.1318)
tensor(1345224.) 2188896.0
INFO - ==> Top1: 88.130    Top5: 99.600    Loss: 0.382
INFO - ==> Sparsity : 0.615
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
0.59242505
tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
0.59237170
tensor(0.1687, device='cuda:0', grad_fn=<AddBackward0>)
0.59237492
tensor(0.1308, device='cuda:0', grad_fn=<AddBackward0>)
0.59240443
tensor(0.1270, device='cuda:0', grad_fn=<AddBackward0>)
0.59230918
tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>)
0.59232229
tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
0.59230983
tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)
0.59226340
tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
0.59208584
tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>)
0.59183043
tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>)
0.59194893
tensor(0.1534, device='cuda:0', grad_fn=<AddBackward0>)
0.59184939
tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
0.59177816
tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
0.59167796
tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
0.59153849
tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)
0.59152550
tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
0.59149933
tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
0.59143370
tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
0.59138429
tensor(0.1734, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [33][   20/  196]   Loss 0.187119   Top1 93.593750   Top5 99.960938   BatchTime 0.326253   LR 0.000123
0.59127408
tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
0.59129298
tensor(0.1724, device='cuda:0', grad_fn=<AddBackward0>)
0.59140658
tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>)
0.59132546
tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)
0.59117001
tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
0.59120315
tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
0.59130979
tensor(0.1714, device='cuda:0', grad_fn=<AddBackward0>)
0.59123921
tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
0.59114909
tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
0.59108633
tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)
0.59093595
tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)
0.59077430
tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>)
0.59064978
tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)
0.59059113
tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
0.59050906
tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
0.59041631
tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [33][   40/  196]   Loss 0.194563   Top1 93.349609   Top5 99.912109   BatchTime 0.288495   LR 0.000123
0.59037572
tensor(0.1864, device='cuda:0', grad_fn=<AddBackward0>)
0.59038675
tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
0.59036553
tensor(0.1580, device='cuda:0', grad_fn=<AddBackward0>)
0.59040028
tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
0.59054995
tensor(0.1606, device='cuda:0', grad_fn=<AddBackward0>)
0.59090763
tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
0.59096754
tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
0.59100944
tensor(0.1341, device='cuda:0', grad_fn=<AddBackward0>)
0.59105146
tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
0.59071922
tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
0.59050143
tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
0.59048247
tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
0.59056777
tensor(0.3278, device='cuda:0', grad_fn=<AddBackward0>)
0.59078920
tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)
0.59083802
tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
0.59076083
tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
0.59076220
tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
0.59084177
tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
0.59073323
tensor(0.1653, device='cuda:0', grad_fn=<AddBackward0>)
0.59069455
tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
0.59066254
tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
0.59073424
tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
0.59072787
tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
0.59085262
tensor(0.1783, device='cuda:0', grad_fn=<AddBackward0>)
0.59073704
tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [33][   60/  196]   Loss 0.200655   Top1 93.255208   Top5 99.895833   BatchTime 0.273824   LR 0.000123
0.59082025
tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)
0.59069496
tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)
0.59045339
tensor(0.2153, device='cuda:0', grad_fn=<AddBackward0>)
0.59035891
tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>)
0.59042513
tensor(0.1943, device='cuda:0', grad_fn=<AddBackward0>)
0.59044206
tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
0.59031528
tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
0.59024495
tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
0.59014386
tensor(0.1342, device='cuda:0', grad_fn=<AddBackward0>)
0.59011215
tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
0.59038866
tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>)
0.59028798
tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
0.59037268
tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>)
0.59049463
tensor(0.1724, device='cuda:0', grad_fn=<AddBackward0>)
0.59053183
tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [33][   80/  196]   Loss 0.202791   Top1 93.129883   Top5 99.892578   BatchTime 0.268907   LR 0.000123
0.59056067
tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
0.59065944
tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
0.59039754
tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
0.59010553
tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
0.59000164
tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
0.58996320
tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
0.58999175
tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
0.59002453
tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)
0.59007585
tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
0.59023267
tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
0.58999330
tensor(0.1688, device='cuda:0', grad_fn=<AddBackward0>)
0.59006917
tensor(0.1696, device='cuda:0', grad_fn=<AddBackward0>)
0.59024233
tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)
0.59024078
tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>)
0.59023088
tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
0.58995122
tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>)
0.58990985
tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
0.58986402
tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
0.58967298
tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)
0.58947909
tensor(0.1631, device='cuda:0', grad_fn=<AddBackward0>)
0.58931440
tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
0.58931226
tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>)
0.58931500
tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
0.58932686
tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>)
0.58935100
tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [33][  100/  196]   Loss 0.203711   Top1 93.125000   Top5 99.890625   BatchTime 0.263708   LR 0.000123
0.58959204
tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
0.58963948
tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)
0.58986932
tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
0.58975810
tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
0.58972192
tensor(0.1835, device='cuda:0', grad_fn=<AddBackward0>)
0.58989000
tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
0.59008074
tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
0.58988255
tensor(0.1709, device='cuda:0', grad_fn=<AddBackward0>)
0.58983952
tensor(0.1991, device='cuda:0', grad_fn=<AddBackward0>)
0.58977288
tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>)
0.58965033
tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>)
0.58970535
tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
0.58968055
tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)
0.58945304
tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
0.58936882
tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
0.58935457
tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
0.58936709
tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
0.58946681
tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [33][  120/  196]   Loss 0.206464   Top1 92.988281   Top5 99.882812   BatchTime 0.256397   LR 0.000123
0.58934617
tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
0.58938813
tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
0.58958203
tensor(0.1213, device='cuda:0', grad_fn=<AddBackward0>)
0.58958840
tensor(0.1585, device='cuda:0', grad_fn=<AddBackward0>)
0.58976984
tensor(0.2201, device='cuda:0', grad_fn=<AddBackward0>)
0.58971941
tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
0.58938986
tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
0.58929783
tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
0.58925754
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.58922589
tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)
0.58914441
tensor(0.1665, device='cuda:0', grad_fn=<AddBackward0>)
0.58910519
tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)
0.58907455
tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
0.58912975
tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>)
0.58918673
tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
0.58926100
tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
0.58916789
tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [33][  140/  196]   Loss 0.206803   Top1 93.021763   Top5 99.868862   BatchTime 0.252983   LR 0.000122
0.58930832
tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)
0.58949339
tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
0.58962798
tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
0.58961862
tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
0.58957303
tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
0.58957124
tensor(0.1662, device='cuda:0', grad_fn=<AddBackward0>)
0.58944237
tensor(0.1654, device='cuda:0', grad_fn=<AddBackward0>)
0.58928353
tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>)
0.58912796
tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
0.58917034
tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
0.58929163
tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>)
0.58937240
tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
0.58926952
tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
0.58923233
tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
0.58927011
tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
0.58929843
tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)
0.58939183
tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
0.58949429
tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
0.58941823
tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
0.58931404
tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
0.58917469
tensor(0.1426, device='cuda:0', grad_fn=<AddBackward0>)
0.58915633
tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
0.58913624
tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [33][  160/  196]   Loss 0.208419   Top1 92.946777   Top5 99.875488   BatchTime 0.255598   LR 0.000122
0.58916640
tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
0.58907354
tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)
0.58915848
tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
0.58936024
tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
0.58943993
tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>)
0.58928519
tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)
0.58930302
tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
0.58937395
tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
0.58942109
tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
0.58931583
tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
0.58918995
tensor(0.1774, device='cuda:0', grad_fn=<AddBackward0>)
0.58907330
tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>)
0.58905452
tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>)
0.58921820
tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
0.58932292
tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
0.58927029
tensor(0.1652, device='cuda:0', grad_fn=<AddBackward0>)
0.58913869
tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)
0.58910507
tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)
0.58904171
tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
0.58908081
tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)
0.58919001
tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)
0.58917642
tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
0.58911145
tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [33][  180/  196]   Loss 0.210237   Top1 92.868924   Top5 99.869792   BatchTime 0.255698   LR 0.000122
0.58911276
tensor(0.1689, device='cuda:0', grad_fn=<AddBackward0>)
0.58909047
tensor(0.1631, device='cuda:0', grad_fn=<AddBackward0>)
0.58910555
tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>)
0.58911741
tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
0.58890301
tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
0.58874142
tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)
0.58873558
tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)
0.58863091
tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
0.58865356
tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
0.58868814
tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
0.58869100
tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
0.58874327
tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)
0.58890188
tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
0.58917248
tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
0.58931988
tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 92.838    Top5: 99.866    Loss: 0.211
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [33][   20/   40]   Loss 0.403026   Top1 87.656250   Top5 99.472656   BatchTime 0.127231
INFO - Validation [33][   40/   40]   Loss 0.393693   Top1 87.690000   Top5 99.620000   BatchTime 0.092502
INFO - ==> Top1: 87.690    Top5: 99.620    Loss: 0.394
INFO - ==> Sparsity : 0.618
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2847)
features.0.conv.3 tensor(0.1602)
features.1.conv.0 tensor(0.0410)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.1003)
features.2.conv.0 tensor(0.0836)
features.2.conv.3 tensor(0.3441)
features.2.conv.6 tensor(0.4954)
features.3.conv.0 tensor(0.0747)
features.3.conv.3 tensor(0.0748)
features.3.conv.6 tensor(0.1063)
features.4.conv.0 tensor(0.0636)
features.4.conv.3 tensor(0.3021)
features.4.conv.6 tensor(0.3175)
features.5.conv.0 tensor(0.2865)
features.5.conv.3 tensor(0.4149)
features.5.conv.6 tensor(0.1805)
features.6.conv.0 tensor(0.0542)
features.6.conv.3 tensor(0.0584)
features.6.conv.6 tensor(0.0825)
features.7.conv.0 tensor(0.2129)
features.7.conv.3 tensor(0.4476)
features.7.conv.6 tensor(0.6102)
features.8.conv.0 tensor(0.5020)
features.8.conv.3 tensor(0.5402)
features.8.conv.6 tensor(0.3549)
features.9.conv.0 tensor(0.4641)
features.9.conv.3 tensor(0.5648)
features.9.conv.6 tensor(0.7238)
features.10.conv.0 tensor(0.0661)
features.10.conv.3 tensor(0.0926)
features.10.conv.6 tensor(0.0676)
features.11.conv.0 tensor(0.7382)
features.11.conv.3 tensor(0.6451)
features.11.conv.6 tensor(0.8950)
features.12.conv.0 tensor(0.7098)
features.12.conv.3 tensor(0.6613)
features.12.conv.6 tensor(0.8533)
features.13.conv.0 tensor(0.2581)
features.13.conv.3 tensor(0.4863)
features.13.conv.6 tensor(0.4483)
features.14.conv.0 tensor(0.8972)
features.14.conv.3 tensor(0.8215)
features.14.conv.6 tensor(0.9514)
features.15.conv.0 tensor(0.8770)
features.15.conv.3 tensor(0.8269)
features.15.conv.6 tensor(0.9586)
features.16.conv.0 tensor(0.6663)
features.16.conv.3 tensor(0.7889)
features.16.conv.6 tensor(0.8815)
conv.0 tensor(0.1439)
tensor(1352649.) 2188896.0
0.58926332
tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>)
0.58905858
tensor(0.1755, device='cuda:0', grad_fn=<AddBackward0>)
0.58900529
tensor(0.1689, device='cuda:0', grad_fn=<AddBackward0>)
0.58897007
tensor(0.1659, device='cuda:0', grad_fn=<AddBackward0>)
0.58887827
tensor(0.1654, device='cuda:0', grad_fn=<AddBackward0>)
0.58879650
tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
0.58885598
tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)
0.58885753
tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
0.58887351
tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
0.58902764
tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
0.58916700
tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
0.58901364
tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
0.58907509
tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)
0.58906364
tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
0.58915883
tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
0.58927923
tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>)
0.58901292
tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>)
0.58888966
tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
0.58897066
tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
0.58906257
tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [34][   20/  196]   Loss 0.203325   Top1 92.910156   Top5 99.921875   BatchTime 0.349393   LR 0.000122
0.58900350
tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
0.58930659
tensor(0.1778, device='cuda:0', grad_fn=<AddBackward0>)
0.58920246
tensor(0.1633, device='cuda:0', grad_fn=<AddBackward0>)
0.58908075
tensor(0.1762, device='cuda:0', grad_fn=<AddBackward0>)
0.58903885
tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
0.58905649
tensor(0.1821, device='cuda:0', grad_fn=<AddBackward0>)
0.58903718
tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
0.58898598
tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
0.58892715
tensor(0.1786, device='cuda:0', grad_fn=<AddBackward0>)
0.58906132
tensor(0.1631, device='cuda:0', grad_fn=<AddBackward0>)
0.58913565
tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)
0.58907193
tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
0.58881342
tensor(0.1121, device='cuda:0', grad_fn=<AddBackward0>)
0.58885509
tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
0.58880746
tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
0.58877540
tensor(0.1667, device='cuda:0', grad_fn=<AddBackward0>)
0.58873183
tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
0.58869731
tensor(0.1636, device='cuda:0', grad_fn=<AddBackward0>)
0.58875960
tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
0.58879685
tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [34][   40/  196]   Loss 0.198290   Top1 93.085938   Top5 99.941406   BatchTime 0.328121   LR 0.000122
0.58868629
tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
0.58880919
tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
0.58899397
tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
0.58887625
tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
0.58895075
tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>)
0.58877110
tensor(0.1508, device='cuda:0', grad_fn=<AddBackward0>)
0.58860785
tensor(0.1760, device='cuda:0', grad_fn=<AddBackward0>)
0.58852237
tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
0.58872378
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.58869284
tensor(0.2105, device='cuda:0', grad_fn=<AddBackward0>)
0.58856195
tensor(0.1625, device='cuda:0', grad_fn=<AddBackward0>)
0.58845770
tensor(0.1501, device='cuda:0', grad_fn=<AddBackward0>)
0.58830684
tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
0.58838284
tensor(0.1702, device='cuda:0', grad_fn=<AddBackward0>)
0.58843875
tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
0.58863920
tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
0.58855456
tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
0.58831954
tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)
0.58836389
tensor(0.1745, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [34][   60/  196]   Loss 0.195810   Top1 93.190104   Top5 99.941406   BatchTime 0.320474   LR 0.000121
0.58845097
tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
0.58852410
tensor(0.1663, device='cuda:0', grad_fn=<AddBackward0>)
0.58866036
tensor(0.1547, device='cuda:0', grad_fn=<AddBackward0>)
0.58854675
tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
0.58840483
tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
0.58814597
tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)
0.58817238
tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
0.58814263
tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)
0.58808208
tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
0.58805215
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.58804119
tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)
0.58793825
tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
0.58779168
tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
0.58797026
tensor(0.1562, device='cuda:0', grad_fn=<AddBackward0>)
0.58808798
tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
0.58804941
tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
0.58801675
tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
0.58794379
tensor(0.1655, device='cuda:0', grad_fn=<AddBackward0>)
0.58775526
tensor(0.1782, device='cuda:0', grad_fn=<AddBackward0>)
0.58800608
tensor(0.1826, device='cuda:0', grad_fn=<AddBackward0>)
0.58797908
tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [34][   80/  196]   Loss 0.196897   Top1 93.193359   Top5 99.931641   BatchTime 0.313556   LR 0.000121
0.58756179
tensor(0.1443, device='cuda:0', grad_fn=<AddBackward0>)
0.58737522
tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
0.58726048
tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
0.58723313
tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)
0.58716351
tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
0.58711904
tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
0.58710933
tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
0.58708620
tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
0.58691812
tensor(0.1359, device='cuda:0', grad_fn=<AddBackward0>)
0.58688879
tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
0.58685583
tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
0.58680022
tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)
0.58676833
tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)
0.58679694
tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
0.58683676
tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)
0.58686483
tensor(0.1587, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [34][  100/  196]   Loss 0.202043   Top1 93.070312   Top5 99.921875   BatchTime 0.300060   LR 0.000121
0.58679348
tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
0.58709794
tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
0.58741152
tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
0.58711678
tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
0.58702749
tensor(0.1704, device='cuda:0', grad_fn=<AddBackward0>)
0.58694482
tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
0.58689213
tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
0.58692509
tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>)
0.58689660
tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
0.58686316
tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
0.58680314
tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
0.58680493
tensor(0.1228, device='cuda:0', grad_fn=<AddBackward0>)
0.58677542
tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
0.58689988
tensor(0.1621, device='cuda:0', grad_fn=<AddBackward0>)
0.58688492
tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
0.58688462
tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
0.58687997
tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
0.58698678
tensor(0.1642, device='cuda:0', grad_fn=<AddBackward0>)
0.58703023
tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)
0.58702582
tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
0.58695012
tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
0.58697385
tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [34][  120/  196]   Loss 0.204364   Top1 93.050130   Top5 99.908854   BatchTime 0.297788   LR 0.000121
0.58693361
tensor(0.1633, device='cuda:0', grad_fn=<AddBackward0>)
0.58695984
tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
0.58698386
tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)
0.58698744
tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
0.58713830
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.58723980
tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>)
0.58730417
tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
0.58748984
tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
0.58725142
tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
0.58709294
tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>)
0.58699811
tensor(0.1709, device='cuda:0', grad_fn=<AddBackward0>)
0.58700460
tensor(0.1599, device='cuda:0', grad_fn=<AddBackward0>)
0.58699620
tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
0.58696645
tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)
0.58696115
tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
0.58717006
tensor(0.1492, device='cuda:0', grad_fn=<AddBackward0>)
0.58715487
tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>)
0.58717585
tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
0.58714032
tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
0.58711523
tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
0.58720905
tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [34][  140/  196]   Loss 0.203754   Top1 93.150112   Top5 99.902344   BatchTime 0.295602   LR 0.000121
0.58709359
tensor(0.1644, device='cuda:0', grad_fn=<AddBackward0>)
0.58684337
tensor(0.1698, device='cuda:0', grad_fn=<AddBackward0>)
0.58645469
tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)
0.58638728
tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
0.58629948
tensor(0.1729, device='cuda:0', grad_fn=<AddBackward0>)
0.58636892
tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>)
0.58640033
tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
0.58630043
tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>)
0.58616191
tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
0.58614093
tensor(0.1564, device='cuda:0', grad_fn=<AddBackward0>)
0.58619845
tensor(0.1194, device='cuda:0', grad_fn=<AddBackward0>)
0.58625466
tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)
0.58625984
tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
0.58623230
tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
0.58629650
tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
0.58664626
tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [34][  160/  196]   Loss 0.204896   Top1 93.122559   Top5 99.895020   BatchTime 0.289684   LR 0.000121
0.58672768
tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
0.58673817
tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
0.58660859
tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
0.58644181
tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
0.58632940
tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
0.58630699
tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)
0.58636981
tensor(0.1537, device='cuda:0', grad_fn=<AddBackward0>)
0.58641672
tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)
0.58637089
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.58615810
tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
0.58613122
tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
0.58630919
tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
0.58621979
tensor(0.1607, device='cuda:0', grad_fn=<AddBackward0>)
0.58620501
tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>)
0.58638537
tensor(0.1493, device='cuda:0', grad_fn=<AddBackward0>)
0.58654726
tensor(0.1850, device='cuda:0', grad_fn=<AddBackward0>)
0.58647740
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.58655602
tensor(0.2057, device='cuda:0', grad_fn=<AddBackward0>)
0.58642226
tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>)
0.58641446
tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
0.58635122
tensor(0.1665, device='cuda:0', grad_fn=<AddBackward0>)
0.58625269
tensor(0.1579, device='cuda:0', grad_fn=<AddBackward0>)
0.58622885
tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
0.58610421
tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [34][  180/  196]   Loss 0.203912   Top1 93.118490   Top5 99.889323   BatchTime 0.285543   LR 0.000120
0.58594209
tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
0.58605105
tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
0.58613777
tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>)
0.58607024
tensor(0.2143, device='cuda:0', grad_fn=<AddBackward0>)
0.58607626
tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
0.58599401
tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>)
0.58603740
tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>)
0.58618897
tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
0.58619279
tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)
0.58647048
tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
0.58639008
tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
0.58634317
tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
0.58626509
tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
0.58620858
tensor(0.1506, device='cuda:0', grad_fn=<AddBackward0>)
0.58612782
tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
0.58616012
tensor(0.1660, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 93.142    Top5: 99.890    Loss: 0.203
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.58619016
tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [34][   20/   40]   Loss 0.406247   Top1 87.753906   Top5 99.472656   BatchTime 0.121471
INFO - Validation [34][   40/   40]   Loss 0.395635   Top1 87.750000   Top5 99.640000   BatchTime 0.089650
INFO - ==> Top1: 87.750    Top5: 99.640    Loss: 0.396
INFO - ==> Sparsity : 0.620
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2674)
features.0.conv.3 tensor(0.1543)
features.1.conv.0 tensor(0.0430)
features.1.conv.3 tensor(0.0694)
features.1.conv.6 tensor(0.0946)
features.2.conv.0 tensor(0.1105)
features.2.conv.3 tensor(0.3441)
features.2.conv.6 tensor(0.4965)
features.3.conv.0 tensor(0.0723)
features.3.conv.3 tensor(0.0772)
features.3.conv.6 tensor(0.1074)
features.4.conv.0 tensor(0.0745)
features.4.conv.3 tensor(0.3038)
features.4.conv.6 tensor(0.3193)
features.5.conv.0 tensor(0.2695)
features.5.conv.3 tensor(0.4184)
features.5.conv.6 tensor(0.1808)
features.6.conv.0 tensor(0.0513)
features.6.conv.3 tensor(0.0573)
features.6.conv.6 tensor(0.0830)
features.7.conv.0 tensor(0.2260)
features.7.conv.3 tensor(0.4514)
features.7.conv.6 tensor(0.6071)
features.8.conv.0 tensor(0.5017)
features.8.conv.3 tensor(0.5373)
features.8.conv.6 tensor(0.3706)
features.9.conv.0 tensor(0.4590)
features.9.conv.3 tensor(0.5668)
features.9.conv.6 tensor(0.7286)
features.10.conv.0 tensor(0.0645)
features.10.conv.3 tensor(0.0952)
features.10.conv.6 tensor(0.0667)
features.11.conv.0 tensor(0.7374)
features.11.conv.3 tensor(0.6453)
features.11.conv.6 tensor(0.8929)
features.12.conv.0 tensor(0.7057)
features.12.conv.3 tensor(0.6640)
features.12.conv.6 tensor(0.8540)
features.13.conv.0 tensor(0.2706)
features.13.conv.3 tensor(0.4877)
features.13.conv.6 tensor(0.4569)
features.14.conv.0 tensor(0.8973)
features.14.conv.3 tensor(0.8216)
features.14.conv.6 tensor(0.9526)
features.15.conv.0 tensor(0.8757)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9584)
features.16.conv.0 tensor(0.6664)
features.16.conv.3 tensor(0.7888)
features.16.conv.6 tensor(0.8817)
conv.0 tensor(0.1498)
tensor(1356870.) 2188896.0
0.58615124
tensor(0.1810, device='cuda:0', grad_fn=<AddBackward0>)
0.58618248
tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
0.58593100
tensor(0.1879, device='cuda:0', grad_fn=<AddBackward0>)
0.58593613
tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
0.58596420
tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)
0.58594662
tensor(0.1369, device='cuda:0', grad_fn=<AddBackward0>)
0.58586442
tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
0.58597791
tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
0.58595628
tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
0.58608013
tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
0.58586240
tensor(0.3086, device='cuda:0', grad_fn=<AddBackward0>)
0.58584565
tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
0.58596498
tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
0.58607388
tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
0.58643025
tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
0.58607948
tensor(0.1398, device='cuda:0', grad_fn=<AddBackward0>)
0.58599865
tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [35][   20/  196]   Loss 0.199209   Top1 93.242188   Top5 99.882812   BatchTime 0.323277   LR 0.000120
0.58602041
tensor(0.1617, device='cuda:0', grad_fn=<AddBackward0>)
0.58586150
tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>)
0.58589226
tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
0.58578885
tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)
0.58558983
tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>)
0.58553952
tensor(0.1625, device='cuda:0', grad_fn=<AddBackward0>)
0.58566117
tensor(0.1693, device='cuda:0', grad_fn=<AddBackward0>)
0.58587927
tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
0.58716285
tensor(0.1657, device='cuda:0', grad_fn=<AddBackward0>)
0.58735645
tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
0.58720803
tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
0.58709693
tensor(0.1425, device='cuda:0', grad_fn=<AddBackward0>)
0.58711243
tensor(0.1570, device='cuda:0', grad_fn=<AddBackward0>)
0.58720350
tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
0.58703256
tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
0.58683866
tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
0.58681595
tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
0.58678269
tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>)
0.58669645
tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
0.58657217
tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
0.58655012
tensor(0.1564, device='cuda:0', grad_fn=<AddBackward0>)
0.58674049
tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
0.58671153
tensor(0.1683, device='cuda:0', grad_fn=<AddBackward0>)
0.58652097
tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [35][   40/  196]   Loss 0.199201   Top1 93.232422   Top5 99.863281   BatchTime 0.284184   LR 0.000120
0.58667463
tensor(0.1544, device='cuda:0', grad_fn=<AddBackward0>)
0.58690125
tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>)
0.58692819
tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>)
0.58691293
tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
0.58688962
tensor(0.1638, device='cuda:0', grad_fn=<AddBackward0>)
0.58692199
tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)
0.58689427
tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
0.58690828
tensor(0.1321, device='cuda:0', grad_fn=<AddBackward0>)
0.58692008
tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
0.58677727
tensor(0.1580, device='cuda:0', grad_fn=<AddBackward0>)
0.58666468
tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
0.58690119
tensor(0.1724, device='cuda:0', grad_fn=<AddBackward0>)
0.58688682
tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
0.58702809
tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>)
0.58704662
tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
0.58688438
tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [35][   60/  196]   Loss 0.197272   Top1 93.274740   Top5 99.876302   BatchTime 0.274518   LR 0.000120
0.58706117
tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
0.58710986
tensor(0.1664, device='cuda:0', grad_fn=<AddBackward0>)
0.58703953
tensor(0.1428, device='cuda:0', grad_fn=<AddBackward0>)
0.58694375
tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
0.58696973
tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)
0.58686763
tensor(0.1522, device='cuda:0', grad_fn=<AddBackward0>)
0.58680063
tensor(0.1561, device='cuda:0', grad_fn=<AddBackward0>)
0.58689082
tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
0.58681822
tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)
0.58687401
tensor(0.1579, device='cuda:0', grad_fn=<AddBackward0>)
0.58685672
tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
0.58677828
tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
0.58695811
tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)
0.58716440
tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
0.58698422
tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
0.58703649
tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)
0.58679616
tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
0.58672756
tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>)
0.58675492
tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
0.58673704
tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
0.58672261
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.58655107
tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
0.58651948
tensor(0.1760, device='cuda:0', grad_fn=<AddBackward0>)
0.58656716
tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [35][   80/  196]   Loss 0.195623   Top1 93.334961   Top5 99.873047   BatchTime 0.268199   LR 0.000119
0.58658397
tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
0.58668548
tensor(0.1480, device='cuda:0', grad_fn=<AddBackward0>)
0.58686590
tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)
0.58691871
tensor(0.1743, device='cuda:0', grad_fn=<AddBackward0>)
0.58697087
tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
0.58701676
tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
0.58712071
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.58733892
tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
0.58717108
tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
0.58699518
tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
0.58690453
tensor(0.1533, device='cuda:0', grad_fn=<AddBackward0>)
0.58678776
tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
0.58692580
tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)
0.58706844
tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
0.58692116
tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
0.58695453
tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [35][  100/  196]   Loss 0.196288   Top1 93.320312   Top5 99.875000   BatchTime 0.264302   LR 0.000119
0.58701384
tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>)
0.58696502
tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
0.58719784
tensor(0.1429, device='cuda:0', grad_fn=<AddBackward0>)
0.58719712
tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>)
0.58729649
tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
0.58725339
tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
0.58708471
tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
0.58706021
tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>)
0.58690029
tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)
0.58679199
tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
0.58684379
tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
0.58670580
tensor(0.1472, device='cuda:0', grad_fn=<AddBackward0>)
0.58662730
tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>)
0.58660555
tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
0.58652866
tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>)
0.58649433
tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
0.58630079
tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
0.58626753
tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
0.58618623
tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
0.58609635
tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)
0.58609384
tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
0.58623594
tensor(0.1821, device='cuda:0', grad_fn=<AddBackward0>)
0.58630812
tensor(0.1563, device='cuda:0', grad_fn=<AddBackward0>)
0.58647168
tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [35][  120/  196]   Loss 0.196569   Top1 93.294271   Top5 99.879557   BatchTime 0.261973   LR 0.000119
0.58641398
tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)
0.58645445
tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
0.58631104
tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
0.58627015
tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)
0.58619434
tensor(0.1497, device='cuda:0', grad_fn=<AddBackward0>)
0.58604038
tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
0.58601147
tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)
0.58610100
tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>)
0.58623749
tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
0.58618736
tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
0.58634007
tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
0.58627224
tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
0.58635032
tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
0.58638322
tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
0.58649671
tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
0.58630329
tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [35][  140/  196]   Loss 0.195919   Top1 93.348214   Top5 99.885603   BatchTime 0.260361   LR 0.000119
0.58627945
tensor(0.1062, device='cuda:0', grad_fn=<AddBackward0>)
0.58626062
tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>)
0.58615243
tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)
0.58605587
tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
0.58601391
tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)
0.58599204
tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
0.58608818
tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
0.58619773
tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>)
0.58631194
tensor(0.1869, device='cuda:0', grad_fn=<AddBackward0>)
0.58648813
tensor(0.1776, device='cuda:0', grad_fn=<AddBackward0>)
0.58662122
tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
0.58644831
tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
0.58669472
tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
0.58655685
tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
0.58643478
tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
0.58644354
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.58647400
tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
0.58633476
tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)
0.58627969
tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>)
0.58634937
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.58652192
tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
0.58668554
tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
0.58663136
tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>)
0.58645070
tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [35][  160/  196]   Loss 0.198170   Top1 93.254395   Top5 99.887695   BatchTime 0.258848   LR 0.000119
0.58632100
tensor(0.1814, device='cuda:0', grad_fn=<AddBackward0>)
0.58630371
tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
0.58629763
tensor(0.1083, device='cuda:0', grad_fn=<AddBackward0>)
0.58621192
tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
0.58613861
tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
0.58610481
tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
0.58602166
tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
0.58603579
tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
0.58621943
tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)
0.58625013
tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
0.58655840
tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
0.58633274
tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>)
0.58619529
tensor(0.1667, device='cuda:0', grad_fn=<AddBackward0>)
0.58628088
tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>)
0.58635181
tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [35][  180/  196]   Loss 0.200006   Top1 93.226997   Top5 99.893663   BatchTime 0.259447   LR 0.000118
0.58624685
tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
0.58628255
tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>)
0.58620530
tensor(0.1376, device='cuda:0', grad_fn=<AddBackward0>)
0.58607852
tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
0.58605003
tensor(0.1734, device='cuda:0', grad_fn=<AddBackward0>)
0.58600932
tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)
0.58597523
tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
0.58620989
tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
0.58629775
tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
0.58617479
tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)
0.58622956
tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
0.58618063
tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
0.58588856
tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
0.58569944
tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
0.58569926
tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
0.58568245
tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 93.206    Top5: 99.894    Loss: 0.201
0.58566183
tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
0.58580321
tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>)
0.58570606
tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>)
0.58565283
tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [35][   20/   40]   Loss 0.407659   Top1 87.441406   Top5 99.355469   BatchTime 0.117131
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1523)
features.1.conv.0 tensor(0.0547)
features.1.conv.3 tensor(0.0671)
features.1.conv.6 tensor(0.0968)
features.2.conv.0 tensor(0.0987)
features.2.conv.3 tensor(0.3441)
features.2.conv.6 tensor(0.5009)
features.3.conv.0 tensor(0.0761)
features.3.conv.3 tensor(0.0772)
features.3.conv.6 tensor(0.1096)
features.4.conv.0 tensor(0.0713)
features.4.conv.3 tensor(0.2975)
features.4.conv.6 tensor(0.3296)
features.5.conv.0 tensor(0.2643)
features.5.conv.3 tensor(0.4144)
features.5.conv.6 tensor(0.2052)
features.6.conv.0 tensor(0.0537)
features.6.conv.3 tensor(0.0544)
features.6.conv.6 tensor(0.0827)
features.7.conv.0 tensor(0.2118)
features.7.conv.3 tensor(0.4514)
features.7.conv.6 tensor(0.6086)
features.8.conv.0 tensor(0.4963)
features.8.conv.3 tensor(0.5373)
features.8.conv.6 tensor(0.3939)
features.9.conv.0 tensor(0.4611)
features.9.conv.3 tensor(0.5648)
features.9.conv.6 tensor(0.7343)
features.10.conv.0 tensor(0.0580)
features.10.conv.3 tensor(0.0929)
features.10.conv.6 tensor(0.0657)
features.11.conv.0 tensor(0.7369)
features.11.conv.3 tensor(0.6424)
features.11.conv.6 tensor(0.8970)
features.12.conv.0 tensor(0.7080)
features.12.conv.3 tensor(0.6640)
features.12.conv.6 tensor(0.8492)
features.13.conv.0 tensor(0.2724)
features.13.conv.3 tensor(0.4884)
features.13.conv.6 tensor(0.4622)
features.14.conv.0 tensor(0.8992)
features.14.conv.3 tensor(0.8219)
features.14.conv.6 tensor(0.9531)
features.15.conv.0 tensor(0.8766)
features.15.conv.3 tensor(0.8274)
features.15.conv.6 tensor(0.9586)
features.16.conv.0 tensor(0.6651)
features.16.conv.3 tensor(0.7890)
features.16.conv.6 tensor(0.8824)
conv.0 tensor(0.1574)
tensor(1361494.) 2188896.0
INFO - Validation [35][   40/   40]   Loss 0.396608   Top1 87.610000   Top5 99.560000   BatchTime 0.085072
INFO - ==> Top1: 87.610    Top5: 99.560    Loss: 0.397
INFO - ==> Sparsity : 0.622
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
0.58581096
tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
0.58587861
tensor(0.1736, device='cuda:0', grad_fn=<AddBackward0>)
0.58579892
tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>)
0.58599180
tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
0.58579028
tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
0.58588427
tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
0.58572394
tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>)
0.58571041
tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
0.58556610
tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
0.58556449
tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
0.58555681
tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>)
0.58573174
tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)
0.58590180
tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
0.58586186
tensor(0.1758, device='cuda:0', grad_fn=<AddBackward0>)
0.58589226
tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>)
0.58550686
tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>)
0.58541137
tensor(0.1188, device='cuda:0', grad_fn=<AddBackward0>)
0.58534938
tensor(0.1421, device='cuda:0', grad_fn=<AddBackward0>)
0.58545387
tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
0.58545148
tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [36][   20/  196]   Loss 0.201502   Top1 93.554688   Top5 99.843750   BatchTime 0.396960   LR 0.000118
0.58529276
tensor(0.1743, device='cuda:0', grad_fn=<AddBackward0>)
0.58528584
tensor(0.1655, device='cuda:0', grad_fn=<AddBackward0>)
0.58538616
tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
0.58544785
tensor(0.1393, device='cuda:0', grad_fn=<AddBackward0>)
0.58543289
tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>)
0.58523315
tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
0.58499372
tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)
0.58482224
tensor(0.1455, device='cuda:0', grad_fn=<AddBackward0>)
0.58469254
tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>)
0.58463943
tensor(0.1670, device='cuda:0', grad_fn=<AddBackward0>)
0.58450067
tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
0.58446288
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
0.58437222
tensor(0.1304, device='cuda:0', grad_fn=<AddBackward0>)
0.58437830
tensor(0.1694, device='cuda:0', grad_fn=<AddBackward0>)
0.58454448
tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
0.58455002
tensor(0.1664, device='cuda:0', grad_fn=<AddBackward0>)
0.58449894
tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
0.58432555
tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [36][   40/  196]   Loss 0.194624   Top1 93.720703   Top5 99.892578   BatchTime 0.366246   LR 0.000118
0.58428913
tensor(0.1544, device='cuda:0', grad_fn=<AddBackward0>)
0.58414268
tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>)
0.58407718
tensor(0.1372, device='cuda:0', grad_fn=<AddBackward0>)
0.58415443
tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>)
0.58393908
tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
0.58381855
tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
0.58364987
tensor(0.1795, device='cuda:0', grad_fn=<AddBackward0>)
0.58353335
tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
0.58346951
tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
0.58343583
tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>)
0.58337998
tensor(0.1637, device='cuda:0', grad_fn=<AddBackward0>)
0.58344793
tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
0.58341992
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.58341968
tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
0.58351475
tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>)
0.58348721
tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
0.58341652
tensor(0.1622, device='cuda:0', grad_fn=<AddBackward0>)
0.58325118
tensor(0.1554, device='cuda:0', grad_fn=<AddBackward0>)
0.58321863
tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
0.58352876
tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>)
0.58333749
tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)
0.58325833
tensor(0.1342, device='cuda:0', grad_fn=<AddBackward0>)
0.58301687
tensor(0.1569, device='cuda:0', grad_fn=<AddBackward0>)
0.58291972
tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [36][   60/  196]   Loss 0.190557   Top1 93.619792   Top5 99.895833   BatchTime 0.354481   LR 0.000117
0.58280247
tensor(0.1455, device='cuda:0', grad_fn=<AddBackward0>)
0.58281446
tensor(0.1744, device='cuda:0', grad_fn=<AddBackward0>)
0.58277696
tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
0.58266950
tensor(0.1294, device='cuda:0', grad_fn=<AddBackward0>)
0.58257824
tensor(0.1671, device='cuda:0', grad_fn=<AddBackward0>)
0.58257157
tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
0.58259469
tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
0.58259052
tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
0.58255208
tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>)
0.58236760
tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)
0.58245426
tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
0.58252102
tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
0.58258080
tensor(0.1808, device='cuda:0', grad_fn=<AddBackward0>)
0.58256060
tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>)
0.58252406
tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
0.58275670
tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
0.58300644
tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
0.58287370
tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [36][   80/  196]   Loss 0.189531   Top1 93.549805   Top5 99.912109   BatchTime 0.349316   LR 0.000117
0.58257139
tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
0.58236516
tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>)
0.58230287
tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
0.58236778
tensor(0.1671, device='cuda:0', grad_fn=<AddBackward0>)
0.58230394
tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>)
0.58224064
tensor(0.1587, device='cuda:0', grad_fn=<AddBackward0>)
0.58230770
tensor(0.1603, device='cuda:0', grad_fn=<AddBackward0>)
0.58227104
tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>)
0.58226222
tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
0.58227187
tensor(0.2024, device='cuda:0', grad_fn=<AddBackward0>)
0.58226544
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
0.58220911
tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
0.58224005
tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)
0.58217752
tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
0.58224869
tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
0.58222276
tensor(0.1764, device='cuda:0', grad_fn=<AddBackward0>)
0.58221716
tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
0.58226436
tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [36][  100/  196]   Loss 0.190444   Top1 93.539062   Top5 99.886719   BatchTime 0.346016   LR 0.000117
0.58233917
tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
0.58230644
tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
0.58253574
tensor(0.1274, device='cuda:0', grad_fn=<AddBackward0>)
0.58279574
tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
0.58308792
tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)
0.58282703
tensor(0.1606, device='cuda:0', grad_fn=<AddBackward0>)
0.58272856
tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)
0.58274561
tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
0.58264518
tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)
0.58258015
tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
0.58248812
tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
0.58238119
tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
0.58236080
tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>)
0.58240914
tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
0.58239037
tensor(0.1531, device='cuda:0', grad_fn=<AddBackward0>)
0.58243358
tensor(0.1496, device='cuda:0', grad_fn=<AddBackward0>)
0.58252108
tensor(0.1393, device='cuda:0', grad_fn=<AddBackward0>)
0.58240932
tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
0.58239931
tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)
0.58236986
tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>)
0.58231884
tensor(0.1623, device='cuda:0', grad_fn=<AddBackward0>)
0.58235198
tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
0.58252829
tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
0.58259386
tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [36][  120/  196]   Loss 0.191690   Top1 93.509115   Top5 99.879557   BatchTime 0.343855   LR 0.000117
0.58271557
tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
0.58268237
tensor(0.1755, device='cuda:0', grad_fn=<AddBackward0>)
0.58256269
tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
0.58252412
tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
0.58243334
tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>)
0.58255756
tensor(0.1669, device='cuda:0', grad_fn=<AddBackward0>)
0.58245713
tensor(0.1550, device='cuda:0', grad_fn=<AddBackward0>)
0.58230531
tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
0.58223587
tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
0.58216232
tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)
0.58217633
tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
0.58242184
tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
0.58242327
tensor(0.1732, device='cuda:0', grad_fn=<AddBackward0>)
0.58265644
tensor(0.1499, device='cuda:0', grad_fn=<AddBackward0>)
0.58266753
tensor(0.2014, device='cuda:0', grad_fn=<AddBackward0>)
0.58251619
tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>)
0.58236265
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
0.58224857
tensor(0.1601, device='cuda:0', grad_fn=<AddBackward0>)
0.58209497
tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
0.58197153
INFO - Training [36][  140/  196]   Loss 0.190419   Top1 93.529576   Top5 99.888393   BatchTime 0.340601   LR 0.000117
tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
0.58194429
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.58193386
tensor(0.1682, device='cuda:0', grad_fn=<AddBackward0>)
0.58189303
tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
0.58183962
tensor(0.1691, device='cuda:0', grad_fn=<AddBackward0>)
0.58192241
tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
0.58202016
tensor(0.1537, device='cuda:0', grad_fn=<AddBackward0>)
0.58216387
tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>)
0.58230561
tensor(0.1321, device='cuda:0', grad_fn=<AddBackward0>)
0.58231467
tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
0.58232409
tensor(0.1757, device='cuda:0', grad_fn=<AddBackward0>)
0.58238184
tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
0.58235413
tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
0.58242416
tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
0.58235282
tensor(0.1664, device='cuda:0', grad_fn=<AddBackward0>)
0.58226269
tensor(0.1703, device='cuda:0', grad_fn=<AddBackward0>)
0.58231366
tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [36][  160/  196]   Loss 0.188241   Top1 93.579102   Top5 99.895020   BatchTime 0.328883   LR 0.000116
0.58216995
tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)
0.58204699
tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
0.58202738
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
0.58237290
tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>)
0.58230752
tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>)
0.58242965
tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
0.58233058
tensor(0.1760, device='cuda:0', grad_fn=<AddBackward0>)
0.58231103
tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
0.58219236
tensor(0.1716, device='cuda:0', grad_fn=<AddBackward0>)
0.58215523
tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>)
0.58211958
tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>)
0.58208376
tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
0.58193588
tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
0.58193636
tensor(0.1633, device='cuda:0', grad_fn=<AddBackward0>)
0.58219755
tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>)
0.58238780
tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
0.58235192
tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
0.58224881
tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
0.58200902
tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>)
0.58198065
tensor(0.1588, device='cuda:0', grad_fn=<AddBackward0>)
0.58202422
tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)
0.58196896
tensor(0.1850, device='cuda:0', grad_fn=<AddBackward0>)
0.58190829
tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [36][  180/  196]   Loss 0.189739   Top1 93.556858   Top5 99.889323   BatchTime 0.320311   LR 0.000116
0.58190233
tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
0.58187705
tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
0.58183807
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
0.58194989
tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>)
0.58205754
tensor(0.1623, device='cuda:0', grad_fn=<AddBackward0>)
0.58228928
tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
0.58240581
tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
0.58268702
tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
0.58252680
tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
0.58243990
tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
0.58232582
tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)
0.58231938
tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>)
0.58222747
tensor(0.1398, device='cuda:0', grad_fn=<AddBackward0>)
0.58223039
tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
0.58231366
tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 93.488    Top5: 99.880    Loss: 0.191
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [36][   20/   40]   Loss 0.406247   Top1 87.343750   Top5 99.472656   BatchTime 0.133169
features.0.conv.0 tensor(0.2847)
features.0.conv.3 tensor(0.1543)
features.1.conv.0 tensor(0.0482)
features.1.conv.3 tensor(0.0579)
features.1.conv.6 tensor(0.0924)
features.2.conv.0 tensor(0.1065)
features.2.conv.3 tensor(0.3441)
features.2.conv.6 tensor(0.5026)
features.3.conv.0 tensor(0.0752)
features.3.conv.3 tensor(0.0733)
features.3.conv.6 tensor(0.1113)
features.4.conv.0 tensor(0.0729)
features.4.conv.3 tensor(0.2986)
features.4.conv.6 tensor(0.3286)
features.5.conv.0 tensor(0.2677)
features.5.conv.3 tensor(0.4155)
features.5.conv.6 tensor(0.2612)
features.6.conv.0 tensor(0.0522)
features.6.conv.3 tensor(0.0515)
features.6.conv.6 tensor(0.0812)
features.7.conv.0 tensor(0.2104)
features.7.conv.3 tensor(0.4485)
features.7.conv.6 tensor(0.6108)
features.8.conv.0 tensor(0.5121)
features.8.conv.3 tensor(0.5388)
features.8.conv.6 tensor(0.3972)
features.9.conv.0 tensor(0.4701)
features.9.conv.3 tensor(0.5671)
features.9.conv.6 tensor(0.7375)
features.10.conv.0 tensor(0.0606)
features.10.conv.3 tensor(0.0943)
features.10.conv.6 tensor(0.0656)
features.11.conv.0 tensor(0.7397)
features.11.conv.3 tensor(0.6435)
features.11.conv.6 tensor(0.8961)
features.12.conv.0 tensor(0.7108)
features.12.conv.3 tensor(0.6640)
features.12.conv.6 tensor(0.8530)
features.13.conv.0 tensor(0.2820)
features.13.conv.3 tensor(0.4871)
features.13.conv.6 tensor(0.4672)
features.14.conv.0 tensor(0.9002)
features.14.conv.3 tensor(0.8222)
features.14.conv.6 tensor(0.9539)
features.15.conv.0 tensor(0.8787)
features.15.conv.3 tensor(0.8275)
features.15.conv.6 tensor(0.9593)
features.16.conv.0 tensor(0.6692)
features.16.conv.3 tensor(0.7888)
features.16.conv.6 tensor(0.8833)
conv.0 tensor(0.1625)
tensor(1367838.) 2188896.0
INFO - Validation [36][   40/   40]   Loss 0.401844   Top1 87.430000   Top5 99.610000   BatchTime 0.094868
INFO - ==> Top1: 87.430    Top5: 99.610    Loss: 0.402
INFO - ==> Sparsity : 0.625
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
0.58235788
tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)
0.58232647
tensor(0.1704, device='cuda:0', grad_fn=<AddBackward0>)
0.58232242
tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>)
0.58252299
tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
0.58255774
tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>)
0.58246446
tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
0.58218002
tensor(0.1544, device='cuda:0', grad_fn=<AddBackward0>)
0.58225912
tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
0.58228314
tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
0.58231819
tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
0.58225960
tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
0.58216143
tensor(0.1543, device='cuda:0', grad_fn=<AddBackward0>)
0.58216751
tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
0.58239925
tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
0.58237040
tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>)
0.58245355
tensor(0.1556, device='cuda:0', grad_fn=<AddBackward0>)
0.58242202
tensor(0.1606, device='cuda:0', grad_fn=<AddBackward0>)
0.58237576
tensor(0.1652, device='cuda:0', grad_fn=<AddBackward0>)
0.58251888
tensor(0.0946, device='cuda:0', grad_fn=<AddBackward0>)
0.58225703
tensor(0.1683, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [37][   20/  196]   Loss 0.183356   Top1 93.730469   Top5 99.902344   BatchTime 0.314049   LR 0.000116
0.58232665
tensor(0.1677, device='cuda:0', grad_fn=<AddBackward0>)
0.58233935
tensor(0.1204, device='cuda:0', grad_fn=<AddBackward0>)
0.58232433
tensor(0.1606, device='cuda:0', grad_fn=<AddBackward0>)
0.58234841
tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
0.58236569
tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>)
0.58225858
tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
0.58224452
tensor(0.1732, device='cuda:0', grad_fn=<AddBackward0>)
0.58226001
tensor(0.1182, device='cuda:0', grad_fn=<AddBackward0>)
0.58219969
tensor(0.1404, device='cuda:0', grad_fn=<AddBackward0>)
0.58223289
tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
0.58206534
tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
0.58196628
tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>)
0.58214390
tensor(0.1277, device='cuda:0', grad_fn=<AddBackward0>)
0.58227593
tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)
0.58223540
tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>)
0.58224171
tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
0.58231699
tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
0.58210802
tensor(0.1548, device='cuda:0', grad_fn=<AddBackward0>)
0.58212817
tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)
0.58214331
tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
0.58211923
tensor(0.1675, device='cuda:0', grad_fn=<AddBackward0>)
0.58193296
tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [37][   40/  196]   Loss 0.179349   Top1 93.876953   Top5 99.912109   BatchTime 0.295016   LR 0.000115
0.58206034
tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)
0.58220208
tensor(0.1186, device='cuda:0', grad_fn=<AddBackward0>)
0.58223259
tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
0.58220482
tensor(0.1389, device='cuda:0', grad_fn=<AddBackward0>)
0.58223867
tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
0.58207661
tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)
0.58201140
tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
0.58201987
tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
0.58195633
tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
0.58191782
tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)
0.58189732
tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>)
0.58189094
tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
0.58190590
tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
0.58193952
tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
0.58185363
tensor(0.1563, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [37][   60/  196]   Loss 0.180412   Top1 93.925781   Top5 99.908854   BatchTime 0.283655   LR 0.000115
0.58193284
tensor(0.1689, device='cuda:0', grad_fn=<AddBackward0>)
0.58188212
tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
0.58185232
tensor(0.1650, device='cuda:0', grad_fn=<AddBackward0>)
0.58192235
tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>)
0.58197457
tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
0.58202434
tensor(0.1032, device='cuda:0', grad_fn=<AddBackward0>)
0.58215845
tensor(0.1828, device='cuda:0', grad_fn=<AddBackward0>)
0.58197826
tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>)
0.58199704
tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
0.58203453
tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)
0.58186996
tensor(0.1381, device='cuda:0', grad_fn=<AddBackward0>)
0.58172882
tensor(0.2163, device='cuda:0', grad_fn=<AddBackward0>)
0.58195901
tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>)
0.58189571
tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
0.58182669
tensor(0.1709, device='cuda:0', grad_fn=<AddBackward0>)
0.58198410
tensor(0.1438, device='cuda:0', grad_fn=<AddBackward0>)
0.58188361
tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
0.58198678
tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)
0.58200723
tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
0.58190346
tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>)
0.58190113
tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
0.58185399
tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>)
0.58182347
tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)
0.58198607
tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [37][   80/  196]   Loss 0.184131   Top1 93.784180   Top5 99.912109   BatchTime 0.276086   LR 0.000115
0.58189619
tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
0.58189136
tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)
0.58188200
tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
0.58193320
tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)
0.58196396
tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>)
0.58202660
tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
0.58189982
tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
0.58190203
tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
0.58211094
tensor(0.1426, device='cuda:0', grad_fn=<AddBackward0>)
0.58200300
tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
0.58188349
tensor(0.1392, device='cuda:0', grad_fn=<AddBackward0>)
0.58180845
tensor(0.1536, device='cuda:0', grad_fn=<AddBackward0>)
0.58179623
tensor(0.1258, device='cuda:0', grad_fn=<AddBackward0>)
0.58189911
tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
0.58191854
tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
0.58194542
tensor(0.1764, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [37][  100/  196]   Loss 0.184118   Top1 93.750000   Top5 99.910156   BatchTime 0.270702   LR 0.000114
0.58202410
tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
0.58205515
tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
0.58194131
tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)
0.58187711
tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
0.58187413
tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>)
0.58187252
tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)
0.58173954
tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>)
0.58161354
tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
0.58170891
tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
0.58176702
tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
0.58182657
tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>)
0.58200991
tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
0.58191258
tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
0.58176106
tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
0.58167219
tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
0.58164263
tensor(0.1435, device='cuda:0', grad_fn=<AddBackward0>)
0.58164638
tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
0.58158833
tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
0.58162457
tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
0.58160710
tensor(0.1480, device='cuda:0', grad_fn=<AddBackward0>)
0.58172965
tensor(0.1669, device='cuda:0', grad_fn=<AddBackward0>)
0.58167320
tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
0.58149993
tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
0.58141381
tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)
0.58151007
INFO - Training [37][  120/  196]   Loss 0.184845   Top1 93.717448   Top5 99.912109   BatchTime 0.266922   LR 0.000114
tensor(0.1746, device='cuda:0', grad_fn=<AddBackward0>)
0.58157980
tensor(0.1662, device='cuda:0', grad_fn=<AddBackward0>)
0.58161241
tensor(0.3197, device='cuda:0', grad_fn=<AddBackward0>)
0.58150548
tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>)
0.58150178
tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>)
0.58151919
tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>)
0.58150786
tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
0.58167112
tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>)
0.58175755
tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
0.58171147
tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>)
0.58179533
tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
0.58169276
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.58156288
tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>)
0.58147603
tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
0.58157212
tensor(0.1350, device='cuda:0', grad_fn=<AddBackward0>)
0.58178288
tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [37][  140/  196]   Loss 0.187618   Top1 93.674665   Top5 99.902344   BatchTime 0.264521   LR 0.000114
0.58159238
tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)
0.58128953
tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
0.58126980
tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)
0.58097333
tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>)
0.58039153
tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
0.58034194
tensor(0.1479, device='cuda:0', grad_fn=<AddBackward0>)
0.58033305
tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
0.58028889
tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
0.58041626
tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
0.58063930
tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
0.58053815
tensor(0.2013, device='cuda:0', grad_fn=<AddBackward0>)
0.58055168
tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
0.58039296
tensor(0.1955, device='cuda:0', grad_fn=<AddBackward0>)
0.58024812
tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
0.58038223
tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>)
0.58040303
tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
0.58043438
tensor(0.1677, device='cuda:0', grad_fn=<AddBackward0>)
0.58038187
tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
0.58025521
tensor(0.1343, device='cuda:0', grad_fn=<AddBackward0>)
0.58045632
tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
0.58053344
tensor(0.1682, device='cuda:0', grad_fn=<AddBackward0>)
0.58068210
tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
0.58033645
tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>)
0.58031625
tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
0.58022118
tensor(0.1716, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [37][  160/  196]   Loss 0.187078   Top1 93.684082   Top5 99.902344   BatchTime 0.262657   LR 0.000114
0.58021688
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
0.58022803
tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
0.58026683
tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
0.58029842
tensor(0.1946, device='cuda:0', grad_fn=<AddBackward0>)
0.58023840
tensor(0.1695, device='cuda:0', grad_fn=<AddBackward0>)
0.58017284
tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
0.58012336
tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
0.58001798
tensor(0.1727, device='cuda:0', grad_fn=<AddBackward0>)
0.58004564
tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>)
0.58020157
tensor(0.1729, device='cuda:0', grad_fn=<AddBackward0>)
0.58032632
tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
0.58037412
tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
0.58032906
tensor(0.1675, device='cuda:0', grad_fn=<AddBackward0>)
0.58011121
tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>)
0.58013594
tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [37][  180/  196]   Loss 0.187593   Top1 93.658854   Top5 99.904514   BatchTime 0.261843   LR 0.000113
0.58012831
tensor(0.1613, device='cuda:0', grad_fn=<AddBackward0>)
0.58003378
tensor(0.2063, device='cuda:0', grad_fn=<AddBackward0>)
0.58001417
tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>)
0.57994705
tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>)
0.57991749
tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>)
0.57994068
tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>)
0.58001137
tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)
0.58014625
tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)
0.58024448
tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>)
0.58012593
tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
0.58017081
tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>)
0.58014089
tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
0.58038300
tensor(0.1715, device='cuda:0', grad_fn=<AddBackward0>)
0.58010226
tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)
0.58001709
tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
0.57996714
tensor(0.1613, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 93.628    Top5: 99.906    Loss: 0.188
0.57984835
tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)
0.57976204
tensor(0.1692, device='cuda:0', grad_fn=<AddBackward0>)
0.57973611
tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [37][   20/   40]   Loss 0.382408   Top1 88.515625   Top5 99.472656   BatchTime 0.122637
INFO - Validation [37][   40/   40]   Loss 0.370638   Top1 88.450000   Top5 99.640000   BatchTime 0.088290
INFO - ==> Top1: 88.450    Top5: 99.640    Loss: 0.371
INFO - ==> Sparsity : 0.627
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2743)
features.0.conv.3 tensor(0.1621)
features.1.conv.0 tensor(0.0404)
features.1.conv.3 tensor(0.0602)
features.1.conv.6 tensor(0.0942)
features.2.conv.0 tensor(0.0984)
features.2.conv.3 tensor(0.3426)
features.2.conv.6 tensor(0.5035)
features.3.conv.0 tensor(0.0761)
features.3.conv.3 tensor(0.0741)
features.3.conv.6 tensor(0.1159)
features.4.conv.0 tensor(0.0841)
features.4.conv.3 tensor(0.3032)
features.4.conv.6 tensor(0.3345)
features.5.conv.0 tensor(0.2778)
features.5.conv.3 tensor(0.4144)
features.5.conv.6 tensor(0.2638)
features.6.conv.0 tensor(0.0456)
features.6.conv.3 tensor(0.0532)
features.6.conv.6 tensor(0.0840)
features.7.conv.0 tensor(0.2404)
features.7.conv.3 tensor(0.4505)
features.7.conv.6 tensor(0.6097)
features.8.conv.0 tensor(0.5013)
features.8.conv.3 tensor(0.5396)
features.8.conv.6 tensor(0.4129)
features.9.conv.0 tensor(0.4870)
features.9.conv.3 tensor(0.5637)
features.9.conv.6 tensor(0.7396)
features.10.conv.0 tensor(0.0599)
features.10.conv.3 tensor(0.0906)
features.10.conv.6 tensor(0.0668)
features.11.conv.0 tensor(0.7342)
features.11.conv.3 tensor(0.6447)
features.11.conv.6 tensor(0.8947)
features.12.conv.0 tensor(0.7182)
features.12.conv.3 tensor(0.6640)
features.12.conv.6 tensor(0.8544)
features.13.conv.0 tensor(0.2793)
features.13.conv.3 tensor(0.4869)
features.13.conv.6 tensor(0.4700)
features.14.conv.0 tensor(0.9008)
features.14.conv.3 tensor(0.8225)
features.14.conv.6 tensor(0.9548)
features.15.conv.0 tensor(0.8794)
features.15.conv.3 tensor(0.8280)
features.15.conv.6 tensor(0.9599)
features.16.conv.0 tensor(0.6685)
features.16.conv.3 tensor(0.7891)
features.16.conv.6 tensor(0.8838)
conv.0 tensor(0.1668)
tensor(1371805.) 2188896.0
0.57975119
tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
0.57969874
tensor(0.1450, device='cuda:0', grad_fn=<AddBackward0>)
0.57969183
tensor(0.1569, device='cuda:0', grad_fn=<AddBackward0>)
0.57972252
tensor(0.1556, device='cuda:0', grad_fn=<AddBackward0>)
0.57968712
tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>)
0.57973468
tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>)
0.57976764
tensor(0.1803, device='cuda:0', grad_fn=<AddBackward0>)
0.57968533
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.57966077
tensor(0.1774, device='cuda:0', grad_fn=<AddBackward0>)
0.57975852
tensor(0.1491, device='cuda:0', grad_fn=<AddBackward0>)
0.57971084
tensor(0.1355, device='cuda:0', grad_fn=<AddBackward0>)
0.57964766
tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
0.57963121
tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
0.57961720
tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
0.57951134
tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)
0.57949615
tensor(0.1443, device='cuda:0', grad_fn=<AddBackward0>)
0.57949680
tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>)
0.57963228
tensor(0.1345, device='cuda:0', grad_fn=<AddBackward0>)
0.57969022
tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>)
0.57988447
tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
0.57993084
tensor(0.1732, device='cuda:0', grad_fn=<AddBackward0>)
0.57982343
tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>)
0.57982254
tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)
0.57995743
tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [38][   20/  196]   Loss 0.168304   Top1 94.375000   Top5 99.921875   BatchTime 0.338453   LR 0.000113
0.58000654
tensor(0.1442, device='cuda:0', grad_fn=<AddBackward0>)
0.57994413
tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)
0.58003443
tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)
0.58012706
tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
0.58040005
tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
0.58027065
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.58017087
tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
0.58003557
tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
0.58001530
tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
0.57991797
tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>)
0.57980573
tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
0.57962811
tensor(0.1669, device='cuda:0', grad_fn=<AddBackward0>)
0.57959354
tensor(0.1623, device='cuda:0', grad_fn=<AddBackward0>)
0.57978606
tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>)
0.58005762
tensor(0.1760, device='cuda:0', grad_fn=<AddBackward0>)
0.58001757
tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [38][   40/  196]   Loss 0.182477   Top1 94.033203   Top5 99.882812   BatchTime 0.296217   LR 0.000112
0.57992643
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.58010495
tensor(0.1659, device='cuda:0', grad_fn=<AddBackward0>)
0.57993484
tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
0.57977706
tensor(0.1508, device='cuda:0', grad_fn=<AddBackward0>)
0.57981277
tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)
0.57989746
tensor(0.1130, device='cuda:0', grad_fn=<AddBackward0>)
0.57984239
tensor(0.1516, device='cuda:0', grad_fn=<AddBackward0>)
0.57962203
tensor(0.1663, device='cuda:0', grad_fn=<AddBackward0>)
0.57964861
tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>)
0.57994705
tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>)
0.57985085
tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
0.57965469
tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
0.57964301
tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
0.57948047
tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
0.57950521
tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
0.57957995
tensor(0.1664, device='cuda:0', grad_fn=<AddBackward0>)
0.57967627
tensor(0.1751, device='cuda:0', grad_fn=<AddBackward0>)
0.57966012
tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)
0.57956362
tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
0.57945454
tensor(0.1725, device='cuda:0', grad_fn=<AddBackward0>)
0.57942009
tensor(0.1842, device='cuda:0', grad_fn=<AddBackward0>)
0.57952231
tensor(0.1344, device='cuda:0', grad_fn=<AddBackward0>)
0.57954991
tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
0.57931864
tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [38][   60/  196]   Loss 0.175822   Top1 94.173177   Top5 99.902344   BatchTime 0.280366   LR 0.000112
0.57925218
tensor(0.1513, device='cuda:0', grad_fn=<AddBackward0>)
0.57924485
tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)
0.57914406
tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>)
0.57909679
tensor(0.1751, device='cuda:0', grad_fn=<AddBackward0>)
0.57913053
tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>)
0.57918024
tensor(0.1636, device='cuda:0', grad_fn=<AddBackward0>)
0.57913917
tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
0.57912761
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.57932842
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.57959360
tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>)
0.57938552
tensor(0.1504, device='cuda:0', grad_fn=<AddBackward0>)
0.57944506
tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>)
0.57957286
tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>)
0.57940680
tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>)
0.57921231
tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
0.57914376
tensor(0.1691, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [38][   80/  196]   Loss 0.176243   Top1 94.106445   Top5 99.921875   BatchTime 0.272707   LR 0.000112
0.57909787
tensor(0.1480, device='cuda:0', grad_fn=<AddBackward0>)
0.57910562
tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
0.57903242
tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)
0.57908881
tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
0.57920331
tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)
0.57933885
tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
0.57954109
tensor(0.1663, device='cuda:0', grad_fn=<AddBackward0>)
0.57950079
tensor(0.1703, device='cuda:0', grad_fn=<AddBackward0>)
0.57955521
tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
0.57951319
tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)
0.57989424
tensor(0.1318, device='cuda:0', grad_fn=<AddBackward0>)
0.58006263
tensor(0.1586, device='cuda:0', grad_fn=<AddBackward0>)
0.58028752
tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
0.58034539
tensor(0.1504, device='cuda:0', grad_fn=<AddBackward0>)
0.58041573
tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
0.58059514
tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>)
0.58059984
tensor(0.1814, device='cuda:0', grad_fn=<AddBackward0>)
0.58048540
tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>)
0.58055854
tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>)
0.58032185
tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>)
0.57997328
tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
0.57987297
tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [38][  100/  196]   Loss 0.179535   Top1 93.960938   Top5 99.921875   BatchTime 0.274042   LR 0.000112
0.57970953
tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>)
0.57958889
tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
0.57952887
tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)
0.57944727
tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>)
0.57940865
tensor(0.1457, device='cuda:0', grad_fn=<AddBackward0>)
0.57925653
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.57920772
tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
0.57920188
tensor(0.1661, device='cuda:0', grad_fn=<AddBackward0>)
0.57929856
tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
0.57921433
tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
0.57917976
tensor(0.1639, device='cuda:0', grad_fn=<AddBackward0>)
0.57926071
tensor(0.1711, device='cuda:0', grad_fn=<AddBackward0>)
0.57938707
tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
0.57943290
tensor(0.1169, device='cuda:0', grad_fn=<AddBackward0>)
0.57957846
tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>)
0.57956606
tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
0.57967621
tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
0.57955879
tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>)
0.57957596
tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
0.57948369
tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
0.57946444
tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
0.57920468
tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [38][  120/  196]   Loss 0.179188   Top1 93.925781   Top5 99.925130   BatchTime 0.273810   LR 0.000111
0.57912832
tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
0.57914495
tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
0.57914829
tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
0.57933635
tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>)
0.57936984
tensor(0.1476, device='cuda:0', grad_fn=<AddBackward0>)
0.57931286
tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>)
0.57913709
tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
0.57909477
tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>)
0.57905692
tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
0.57893431
tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)
0.57890540
tensor(0.1457, device='cuda:0', grad_fn=<AddBackward0>)
0.57891297
tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
0.57893550
tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
0.57880437
tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [38][  140/  196]   Loss 0.181323   Top1 93.830915   Top5 99.919085   BatchTime 0.274928   LR 0.000111
0.57863677
tensor(0.1640, device='cuda:0', grad_fn=<AddBackward0>)
0.57866353
tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>)
0.57881129
tensor(0.1615, device='cuda:0', grad_fn=<AddBackward0>)
0.57911021
tensor(0.1540, device='cuda:0', grad_fn=<AddBackward0>)
0.57872909
tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
0.57860678
tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>)
0.57862979
tensor(0.1292, device='cuda:0', grad_fn=<AddBackward0>)
0.57866466
tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
0.57870102
tensor(0.1759, device='cuda:0', grad_fn=<AddBackward0>)
0.57862842
tensor(0.1631, device='cuda:0', grad_fn=<AddBackward0>)
0.57856387
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.57853943
tensor(0.1692, device='cuda:0', grad_fn=<AddBackward0>)
0.57851040
tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
0.57846308
tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
0.57843918
tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
0.57841003
tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)
0.57849962
tensor(0.1775, device='cuda:0', grad_fn=<AddBackward0>)
0.57850033
tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
0.57870913
tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
0.57986522
tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [38][  160/  196]   Loss 0.181787   Top1 93.781738   Top5 99.919434   BatchTime 0.277601   LR 0.000111
0.57992029
tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>)
0.57989013
tensor(0.1609, device='cuda:0', grad_fn=<AddBackward0>)
0.57985777
tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
0.57998937
tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)
0.57986468
tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)
0.57969409
tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
0.57951504
tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
0.57946879
tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
0.57949078
tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)
0.57956988
tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
0.57967061
tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
0.57953203
tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
0.57959855
tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)
0.57955343
tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
0.57957864
tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
0.57922477
tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
0.57912344
tensor(0.1827, device='cuda:0', grad_fn=<AddBackward0>)
0.57910013
tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)
0.57904375
tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
0.57896239
tensor(0.1425, device='cuda:0', grad_fn=<AddBackward0>)
0.57894886
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [38][  180/  196]   Loss 0.183640   Top1 93.713108   Top5 99.917535   BatchTime 0.278683   LR 0.000110
0.57905525
tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>)
0.57916898
tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>)
0.57926303
tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
0.57928520
tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)
0.57932115
tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>)
0.57945466
tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>)
0.57932031
tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)
0.57921445
tensor(0.1527, device='cuda:0', grad_fn=<AddBackward0>)
0.57915139
tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
0.57914901
tensor(0.1807, device='cuda:0', grad_fn=<AddBackward0>)
0.57921720
tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)
0.57926571
tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)
0.57924038
tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)
0.57908869
tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)
0.57894516
tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>)
0.57892466
tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
0.57895672
tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 93.676    Top5: 99.918    Loss: 0.185
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [38][   20/   40]   Loss 0.403538   Top1 87.617188   Top5 99.453125   BatchTime 0.124293
INFO - Validation [38][   40/   40]   Loss 0.395563   Top1 87.790000   Top5 99.580000   BatchTime 0.085990
INFO - ==> Top1: 87.790    Top5: 99.580    Loss: 0.396
INFO - ==> Sparsity : 0.627
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2743)
features.0.conv.3 tensor(0.1562)
features.1.conv.0 tensor(0.0449)
features.1.conv.3 tensor(0.0625)
features.1.conv.6 tensor(0.0933)
features.2.conv.0 tensor(0.1042)
features.2.conv.3 tensor(0.3387)
features.2.conv.6 tensor(0.5049)
features.3.conv.0 tensor(0.0692)
features.3.conv.3 tensor(0.0772)
features.3.conv.6 tensor(0.1124)
features.4.conv.0 tensor(0.0765)
features.4.conv.3 tensor(0.3009)
features.4.conv.6 tensor(0.3354)
features.5.conv.0 tensor(0.2816)
features.5.conv.3 tensor(0.4115)
features.5.conv.6 tensor(0.2733)
features.6.conv.0 tensor(0.0490)
features.6.conv.3 tensor(0.0509)
features.6.conv.6 tensor(0.0825)
features.7.conv.0 tensor(0.2187)
features.7.conv.3 tensor(0.4514)
features.7.conv.6 tensor(0.6121)
features.8.conv.0 tensor(0.5171)
features.8.conv.3 tensor(0.5379)
features.8.conv.6 tensor(0.4458)
features.9.conv.0 tensor(0.4710)
features.9.conv.3 tensor(0.5642)
features.9.conv.6 tensor(0.7401)
features.10.conv.0 tensor(0.0654)
features.10.conv.3 tensor(0.0888)
features.10.conv.6 tensor(0.0666)
features.11.conv.0 tensor(0.7383)
features.11.conv.3 tensor(0.6451)
features.11.conv.6 tensor(0.8970)
features.12.conv.0 tensor(0.7184)
features.12.conv.3 tensor(0.6644)
features.12.conv.6 tensor(0.8564)
features.13.conv.0 tensor(0.2855)
features.13.conv.3 tensor(0.4857)
features.13.conv.6 tensor(0.4740)
features.14.conv.0 tensor(0.9024)
features.14.conv.3 tensor(0.8227)
features.14.conv.6 tensor(0.9550)
features.15.conv.0 tensor(0.8816)
features.15.conv.3 tensor(0.8280)
features.15.conv.6 tensor(0.9596)
features.16.conv.0 tensor(0.6713)
features.16.conv.3 tensor(0.7892)
features.16.conv.6 tensor(0.8838)
conv.0 tensor(0.1640)
tensor(1373307.) 2188896.0
0.57901078
tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
0.57901281
tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
0.57897669
tensor(0.1679, device='cuda:0', grad_fn=<AddBackward0>)
0.57897514
tensor(0.1572, device='cuda:0', grad_fn=<AddBackward0>)
0.57876623
tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)
0.57886368
tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
0.57887143
tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)
0.57878327
tensor(0.1137, device='cuda:0', grad_fn=<AddBackward0>)
0.57879275
tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>)
0.57871240
tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
0.57859826
tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
0.57858199
tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>)
0.57858479
tensor(0.1780, device='cuda:0', grad_fn=<AddBackward0>)
0.57870007
tensor(0.1079, device='cuda:0', grad_fn=<AddBackward0>)
0.57865882
tensor(0.1637, device='cuda:0', grad_fn=<AddBackward0>)
0.57861847
tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>)
0.57865793
tensor(0.1715, device='cuda:0', grad_fn=<AddBackward0>)
0.57865524
tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>)
0.57857972
tensor(0.1625, device='cuda:0', grad_fn=<AddBackward0>)
0.57850617
tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
0.57852799
tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [39][   20/  196]   Loss 0.166675   Top1 94.589844   Top5 99.882812   BatchTime 0.362875   LR 0.000110
0.57888693
tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)
0.57907510
tensor(0.1562, device='cuda:0', grad_fn=<AddBackward0>)
0.57890844
tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>)
0.57920164
tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)
0.57902628
tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
0.57872939
tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>)
0.57872176
tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
0.57873952
tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)
0.57883143
tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
0.57877719
tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>)
0.57868916
tensor(0.1767, device='cuda:0', grad_fn=<AddBackward0>)
0.57869083
tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
0.57863265
tensor(0.2036, device='cuda:0', grad_fn=<AddBackward0>)
0.57863784
tensor(0.1216, device='cuda:0', grad_fn=<AddBackward0>)
0.57878417
tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)
0.57893741
tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>)
0.57886922
tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
0.57879412
tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
0.57895362
tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
0.57872277
tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
0.57857096
tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)
0.57847327
tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [39][   40/  196]   Loss 0.170406   Top1 94.169922   Top5 99.902344   BatchTime 0.322121   LR 0.000109
0.57842755
tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>)
0.57845742
tensor(0.1369, device='cuda:0', grad_fn=<AddBackward0>)
0.57836300
tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
0.57836610
tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>)
0.57870078
tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
0.57883161
tensor(0.1803, device='cuda:0', grad_fn=<AddBackward0>)
0.57889253
tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
0.57895827
tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
0.57880116
tensor(0.1818, device='cuda:0', grad_fn=<AddBackward0>)
0.57873738
tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
0.57870585
tensor(0.1639, device='cuda:0', grad_fn=<AddBackward0>)
0.57875198
tensor(0.0804, device='cuda:0', grad_fn=<AddBackward0>)
0.57886541
tensor(0.1155, device='cuda:0', grad_fn=<AddBackward0>)
0.57870960
tensor(0.1671, device='cuda:0', grad_fn=<AddBackward0>)
0.57855719
tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
0.57864535
tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)
0.57892072
tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
0.57908469
tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>)
0.57901216
tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>)
0.57881606
tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
0.57853842
tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [39][   60/  196]   Loss 0.172790   Top1 94.082031   Top5 99.928385   BatchTime 0.308532   LR 0.000109
0.57850373
tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
0.57839602
tensor(0.1622, device='cuda:0', grad_fn=<AddBackward0>)
0.57824290
tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
0.57824856
tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
0.57828647
tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
0.57828087
tensor(0.1686, device='cuda:0', grad_fn=<AddBackward0>)
0.57840484
tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>)
0.57836431
tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
0.57841301
tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
0.57827961
tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>)
0.57827848
tensor(0.1499, device='cuda:0', grad_fn=<AddBackward0>)
0.57840055
tensor(0.1531, device='cuda:0', grad_fn=<AddBackward0>)
0.57845420
tensor(0.1417, device='cuda:0', grad_fn=<AddBackward0>)
0.57842505
tensor(0.1206, device='cuda:0', grad_fn=<AddBackward0>)
0.57840002
tensor(0.1475, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [39][   80/  196]   Loss 0.172013   Top1 94.155273   Top5 99.931641   BatchTime 0.297471   LR 0.000109
0.57844198
tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>)
0.57861203
tensor(0.1842, device='cuda:0', grad_fn=<AddBackward0>)
0.57848603
tensor(0.1602, device='cuda:0', grad_fn=<AddBackward0>)
0.57869887
tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
0.57882273
tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)
0.57858342
tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
0.57873243
tensor(0.1609, device='cuda:0', grad_fn=<AddBackward0>)
0.57876831
tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>)
0.57870603
tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
0.57854402
tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
0.57850963
tensor(0.1782, device='cuda:0', grad_fn=<AddBackward0>)
0.57872951
tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
0.57882655
tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
0.57874781
tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>)
0.57855761
tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>)
0.57844418
tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
0.57851875
tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
0.57841867
tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
0.57840222
tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
0.57834989
tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
0.57819039
tensor(0.1782, device='cuda:0', grad_fn=<AddBackward0>)
0.57855129
tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [39][  100/  196]   Loss 0.177339   Top1 94.015625   Top5 99.937500   BatchTime 0.294223   LR 0.000108
0.57843947
tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
0.57839400
tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)
0.57833070
tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
0.57835990
tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
0.57867742
tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
0.57862449
tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>)
0.57835495
tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>)
0.57813603
tensor(0.1629, device='cuda:0', grad_fn=<AddBackward0>)
0.57810318
tensor(0.1773, device='cuda:0', grad_fn=<AddBackward0>)
0.57809269
tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
0.57812995
tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
0.57821614
tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>)
0.57822031
tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
0.57816476
tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
0.57811689
tensor(0.1740, device='cuda:0', grad_fn=<AddBackward0>)
0.57811725
tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
0.57812107
tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)
0.57794988
tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)
0.57791102
tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
0.57794052
tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
0.57803053
tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [39][  120/  196]   Loss 0.179864   Top1 93.932292   Top5 99.938151   BatchTime 0.291588   LR 0.000108
0.57806206
tensor(0.1612, device='cuda:0', grad_fn=<AddBackward0>)
0.57795823
tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
0.57791555
tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
0.57790619
tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
0.57790715
tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>)
0.57791442
tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
0.57776570
tensor(0.1687, device='cuda:0', grad_fn=<AddBackward0>)
0.57775742
tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>)
0.57774639
tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>)
0.57779449
tensor(0.1433, device='cuda:0', grad_fn=<AddBackward0>)
0.57778072
tensor(0.1807, device='cuda:0', grad_fn=<AddBackward0>)
0.57768035
tensor(0.1298, device='cuda:0', grad_fn=<AddBackward0>)
0.57772827
tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
0.57825661
tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
0.57817864
tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
0.57825065
tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
0.57801402
tensor(0.1687, device='cuda:0', grad_fn=<AddBackward0>)
0.57791352
tensor(0.1050, device='cuda:0', grad_fn=<AddBackward0>)
0.57777780
tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
0.57764781
tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
0.57762372
tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [39][  140/  196]   Loss 0.180194   Top1 93.878348   Top5 99.938616   BatchTime 0.291520   LR 0.000108
0.57745790
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.57740831
tensor(0.1670, device='cuda:0', grad_fn=<AddBackward0>)
0.57741165
tensor(0.1627, device='cuda:0', grad_fn=<AddBackward0>)
0.57745939
tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
0.57756513
tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)
0.57756323
tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
0.57770479
tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
0.57753772
tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)
0.57745647
tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
0.57746595
tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
0.57749695
tensor(0.1389, device='cuda:0', grad_fn=<AddBackward0>)
0.57745552
tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
0.57743567
tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
0.57731825
tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>)
0.57735687
tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>)
0.57746094
tensor(0.1612, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [39][  160/  196]   Loss 0.180651   Top1 93.847656   Top5 99.929199   BatchTime 0.286819   LR 0.000107
0.57745445
tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>)
0.57756960
tensor(0.1752, device='cuda:0', grad_fn=<AddBackward0>)
0.57763535
tensor(0.1686, device='cuda:0', grad_fn=<AddBackward0>)
0.57745034
tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
0.57739633
tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)
0.57734108
tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>)
0.57726848
tensor(0.1487, device='cuda:0', grad_fn=<AddBackward0>)
0.57737112
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.57746464
tensor(0.1678, device='cuda:0', grad_fn=<AddBackward0>)
0.57712978
tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>)
0.57711923
tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
0.57711983
tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
0.57708287
tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
0.57703668
tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>)
0.57704121
tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
0.57706940
tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
0.57698506
tensor(0.1683, device='cuda:0', grad_fn=<AddBackward0>)
0.57705969
tensor(0.1116, device='cuda:0', grad_fn=<AddBackward0>)
0.57711452
tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
0.57740146
tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
0.57739598
tensor(0.1475, device='cuda:0', grad_fn=<AddBackward0>)
0.57709581
tensor(0.1588, device='cuda:0', grad_fn=<AddBackward0>)
0.57704401
tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [39][  180/  196]   Loss 0.180128   Top1 93.888889   Top5 99.928385   BatchTime 0.283528   LR 0.000107
0.57696396
tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
0.57680649
tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
0.57669491
tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>)
0.57665747
tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
0.57669133
tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
0.57681292
tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>)
0.57701021
tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>)
0.57704455
tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
0.57691813
tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>)
0.57680535
tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
0.57653213
tensor(0.1544, device='cuda:0', grad_fn=<AddBackward0>)
0.57636642
tensor(0.1321, device='cuda:0', grad_fn=<AddBackward0>)
0.57644653
tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
0.57649899
tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 93.836    Top5: 99.924    Loss: 0.181
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 0.398905   Top1 88.300781   Top5 99.433594   BatchTime 0.122657
INFO - Validation [39][   40/   40]   Loss 0.389115   Top1 88.310000   Top5 99.570000   BatchTime 0.086282
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1562)
features.1.conv.0 tensor(0.0436)
features.1.conv.3 tensor(0.0637)
features.1.conv.6 tensor(0.0964)
features.2.conv.0 tensor(0.1013)
features.2.conv.3 tensor(0.3395)
features.2.conv.6 tensor(0.5067)
features.3.conv.0 tensor(0.0732)
features.3.conv.3 tensor(0.0772)
features.3.conv.6 tensor(0.1122)
features.4.conv.0 tensor(0.0763)
features.4.conv.3 tensor(0.3009)
features.4.conv.6 tensor(0.3348)
features.5.conv.0 tensor(0.2835)
features.5.conv.3 tensor(0.4097)
features.5.conv.6 tensor(0.3105)
features.6.conv.0 tensor(0.0529)
features.6.conv.3 tensor(0.0561)
features.6.conv.6 tensor(0.0820)
features.7.conv.0 tensor(0.2175)
features.7.conv.3 tensor(0.4499)
features.7.conv.6 tensor(0.6125)
features.8.conv.0 tensor(0.5225)
features.8.conv.3 tensor(0.5365)
features.8.conv.6 tensor(0.4637)
features.9.conv.0 tensor(0.5044)
features.9.conv.3 tensor(0.5628)
features.9.conv.6 tensor(0.7428)
features.10.conv.0 tensor(0.0581)
features.10.conv.3 tensor(0.0891)
features.10.conv.6 tensor(0.0688)
features.11.conv.0 tensor(0.7363)
features.11.conv.3 tensor(0.6435)
features.11.conv.6 tensor(0.8966)
features.12.conv.0 tensor(0.7135)
features.12.conv.3 tensor(0.6622)
features.12.conv.6 tensor(0.8578)
features.13.conv.0 tensor(0.2838)
features.13.conv.3 tensor(0.4857)
features.13.conv.6 tensor(0.4772)
features.14.conv.0 tensor(0.9031)
features.14.conv.3 tensor(0.8225)
features.14.conv.6 tensor(0.9547)
features.15.conv.0 tensor(0.8838)
features.15.conv.3 tensor(0.8275)
features.15.conv.6 tensor(0.9609)
features.16.conv.0 tensor(0.6715)
features.16.conv.3 tensor(0.7884)
features.16.conv.6 tensor(0.8853)
conv.0 tensor(0.1694)
tensor(1378082.) 2188896.0
INFO - ==> Top1: 88.310    Top5: 99.570    Loss: 0.389
INFO - ==> Sparsity : 0.630
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
0.57647198
tensor(0.1595, device='cuda:0', grad_fn=<AddBackward0>)
0.57642120
tensor(0.1572, device='cuda:0', grad_fn=<AddBackward0>)
0.57650733
tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>)
0.57684344
tensor(0.2028, device='cuda:0', grad_fn=<AddBackward0>)
0.57666403
tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
0.57626826
tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
0.57622510
tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>)
0.57628936
tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
0.57617927
tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>)
0.57603240
tensor(0.1758, device='cuda:0', grad_fn=<AddBackward0>)
0.57595485
tensor(0.1728, device='cuda:0', grad_fn=<AddBackward0>)
0.57594746
tensor(0.1376, device='cuda:0', grad_fn=<AddBackward0>)
0.57607025
tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>)
0.57619905
tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
0.57620448
tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
0.57606477
tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
0.57597661
tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
0.57594007
tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
0.57592255
tensor(0.1415, device='cuda:0', grad_fn=<AddBackward0>)
0.57592374
tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
0.57593405
tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [40][   20/  196]   Loss 0.177472   Top1 94.082031   Top5 99.921875   BatchTime 0.348218   LR 0.000106
0.57580179
tensor(0.1229, device='cuda:0', grad_fn=<AddBackward0>)
0.57588089
tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>)
0.57618552
tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)
0.57616049
tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)
0.57601953
tensor(0.1776, device='cuda:0', grad_fn=<AddBackward0>)
0.57599127
tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
0.57597840
tensor(0.1586, device='cuda:0', grad_fn=<AddBackward0>)
0.57596326
tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
0.57588059
tensor(0.1496, device='cuda:0', grad_fn=<AddBackward0>)
0.57589698
tensor(0.1629, device='cuda:0', grad_fn=<AddBackward0>)
0.57606560
tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)
0.57605666
tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>)
0.57603353
tensor(0.1537, device='cuda:0', grad_fn=<AddBackward0>)
0.57605261
tensor(0.1435, device='cuda:0', grad_fn=<AddBackward0>)
0.57597339
tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)
0.57598490
tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>)
0.57612121
tensor(0.1527, device='cuda:0', grad_fn=<AddBackward0>)
0.57636106
tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
0.57632560
tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>)
0.57635635
tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>)
0.57632297
tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>)
0.57630962
tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [40][   40/  196]   Loss 0.170764   Top1 94.228516   Top5 99.941406   BatchTime 0.308768   LR 0.000106
0.57637632
tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>)
0.57631743
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.57616168
tensor(0.1307, device='cuda:0', grad_fn=<AddBackward0>)
0.57623714
tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>)
0.57623184
tensor(0.1436, device='cuda:0', grad_fn=<AddBackward0>)
0.57634199
tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
0.57635742
tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>)
0.57639879
tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
0.57632309
tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
0.57628602
tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
0.57614940
tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
0.57609576
tensor(0.1458, device='cuda:0', grad_fn=<AddBackward0>)
0.57613409
tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
0.57624489
tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>)
0.57632810
tensor(0.1574, device='cuda:0', grad_fn=<AddBackward0>)
0.57639760
tensor(0.1082, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [40][   60/  196]   Loss 0.171403   Top1 94.205729   Top5 99.941406   BatchTime 0.289508   LR 0.000106
0.57670450
tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
0.57671797
tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
0.57673389
tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
0.57688332
tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
0.57668835
tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
0.57659775
tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>)
0.57663852
tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
0.57663178
tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)
0.57654560
tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
0.57653034
tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
0.57666522
tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)
0.57679391
tensor(0.2011, device='cuda:0', grad_fn=<AddBackward0>)
0.57676798
tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
0.57668966
tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
0.57650161
tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
0.57649791
tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
0.57662570
tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
0.57650065
tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
0.57655019
tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>)
0.57643765
tensor(0.1671, device='cuda:0', grad_fn=<AddBackward0>)
0.57656503
tensor(0.1444, device='cuda:0', grad_fn=<AddBackward0>)
0.57658982
tensor(0.1677, device='cuda:0', grad_fn=<AddBackward0>)
0.57647514
tensor(0.1775, device='cuda:0', grad_fn=<AddBackward0>)
0.57654607
tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [40][   80/  196]   Loss 0.174891   Top1 94.135742   Top5 99.941406   BatchTime 0.300227   LR 0.000105
0.57642561
tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>)
0.57647961
tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>)
0.57646132
tensor(0.1631, device='cuda:0', grad_fn=<AddBackward0>)
0.57643193
tensor(0.1413, device='cuda:0', grad_fn=<AddBackward0>)
0.57619327
tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
0.57637155
tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
0.57641125
tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)
0.57645595
tensor(0.1949, device='cuda:0', grad_fn=<AddBackward0>)
0.57652360
tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)
0.57639045
tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
0.57636374
tensor(0.1884, device='cuda:0', grad_fn=<AddBackward0>)
0.57642871
tensor(0.1729, device='cuda:0', grad_fn=<AddBackward0>)
0.57630384
tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
0.57622564
tensor(0.1250, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [40][  100/  196]   Loss 0.176776   Top1 94.144531   Top5 99.925781   BatchTime 0.299028   LR 0.000105
0.57629913
tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>)
0.57630777
tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)
0.57626843
tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
0.57628709
tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
0.57639694
tensor(0.1666, device='cuda:0', grad_fn=<AddBackward0>)
0.57630199
tensor(0.1572, device='cuda:0', grad_fn=<AddBackward0>)
0.57637620
tensor(0.1638, device='cuda:0', grad_fn=<AddBackward0>)
0.57633853
tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
0.57627046
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.57624412
tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
0.57626420
tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
0.57624131
tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)
0.57615823
tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>)
0.57630277
tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
0.57616329
tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
0.57613689
tensor(0.1527, device='cuda:0', grad_fn=<AddBackward0>)
0.57639551
tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
0.57619476
tensor(0.1540, device='cuda:0', grad_fn=<AddBackward0>)
0.57616460
tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
0.57620198
tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
0.57618457
tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>)
0.57607150
tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
0.57600474
tensor(0.1728, device='cuda:0', grad_fn=<AddBackward0>)
0.57595104
tensor(0.1822, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [40][  120/  196]   Loss 0.176667   Top1 94.091797   Top5 99.928385   BatchTime 0.291992   LR 0.000105
0.57587582
tensor(0.1570, device='cuda:0', grad_fn=<AddBackward0>)
0.57603306
tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)
0.57612878
tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>)
0.57628739
tensor(0.1230, device='cuda:0', grad_fn=<AddBackward0>)
0.57632089
tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)
0.57624918
tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
0.57631856
tensor(0.1458, device='cuda:0', grad_fn=<AddBackward0>)
0.57609242
tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
0.57585031
tensor(0.1642, device='cuda:0', grad_fn=<AddBackward0>)
0.57575953
tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>)
0.57567412
tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
0.57560122
tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>)
0.57555586
tensor(0.1370, device='cuda:0', grad_fn=<AddBackward0>)
0.57571381
tensor(0.1744, device='cuda:0', grad_fn=<AddBackward0>)
0.57614529
tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>)
0.57601190
tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [40][  140/  196]   Loss 0.175449   Top1 94.126674   Top5 99.933036   BatchTime 0.285860   LR 0.000104
0.57598865
tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>)
0.57599115
tensor(0.1231, device='cuda:0', grad_fn=<AddBackward0>)
0.57592052
tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
0.57593417
tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
0.57587725
tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>)
0.57561582
tensor(0.1045, device='cuda:0', grad_fn=<AddBackward0>)
0.57558334
tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>)
0.57567024
tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>)
0.57563657
tensor(0.1187, device='cuda:0', grad_fn=<AddBackward0>)
0.57565838
tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)
0.57596993
tensor(0.1481, device='cuda:0', grad_fn=<AddBackward0>)
0.57596582
tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
0.57602215
tensor(0.1356, device='cuda:0', grad_fn=<AddBackward0>)
0.57590330
tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
0.57574695
tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)
0.57563412
tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>)
0.57570934
tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
0.57575321
tensor(0.1619, device='cuda:0', grad_fn=<AddBackward0>)
0.57583505
tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)
0.57589555
tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
0.57610279
tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>)
0.57769531
tensor(0.1409, device='cuda:0', grad_fn=<AddBackward0>)
0.57802886
tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
0.57806444
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [40][  160/  196]   Loss 0.174532   Top1 94.138184   Top5 99.929199   BatchTime 0.281109   LR 0.000104
0.57821691
tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
0.57808912
tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)
0.57796144
tensor(0.1757, device='cuda:0', grad_fn=<AddBackward0>)
0.57790464
tensor(0.1744, device='cuda:0', grad_fn=<AddBackward0>)
0.57774937
tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)
0.57770574
tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>)
0.57766950
tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>)
0.57760435
tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
0.57778329
tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
0.57748294
tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)
0.57762581
tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
0.57771516
tensor(0.1696, device='cuda:0', grad_fn=<AddBackward0>)
0.57767034
tensor(0.1236, device='cuda:0', grad_fn=<AddBackward0>)
0.57752162
tensor(0.1646, device='cuda:0', grad_fn=<AddBackward0>)
0.57759255
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.57774365
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [40][  180/  196]   Loss 0.175876   Top1 94.066840   Top5 99.926215   BatchTime 0.277698   LR 0.000103
0.57771719
tensor(0.1360, device='cuda:0', grad_fn=<AddBackward0>)
0.57758373
tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>)
0.57746834
tensor(0.1549, device='cuda:0', grad_fn=<AddBackward0>)
0.57741082
tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
0.57730234
tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>)
0.57725620
tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
0.57723945
tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>)
0.57722902
tensor(0.1694, device='cuda:0', grad_fn=<AddBackward0>)
0.57741702
tensor(0.1701, device='cuda:0', grad_fn=<AddBackward0>)
0.57742995
tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
0.57747513
tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>)
0.57747716
tensor(0.1220, device='cuda:0', grad_fn=<AddBackward0>)
0.57744181
tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
0.57747042
tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
0.57745856
tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 94.090    Top5: 99.926    Loss: 0.175
0.57758355
tensor(0.1552, device='cuda:0', grad_fn=<AddBackward0>)
0.57761818
tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
0.57770115
tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)
0.57777953
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [40][   20/   40]   Loss 0.388661   Top1 88.730469   Top5 99.492188   BatchTime 0.130753
INFO - Validation [40][   40/   40]   Loss 0.381138   Top1 88.670000   Top5 99.610000   BatchTime 0.094509
INFO - ==> Top1: 88.670    Top5: 99.610    Loss: 0.381
INFO - ==> Sparsity : 0.620
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1621)
features.1.conv.0 tensor(0.0410)
features.1.conv.3 tensor(0.0671)
features.1.conv.6 tensor(0.0942)
features.2.conv.0 tensor(0.1045)
features.2.conv.3 tensor(0.3426)
features.2.conv.6 tensor(0.5087)
features.3.conv.0 tensor(0.0761)
features.3.conv.3 tensor(0.0787)
features.3.conv.6 tensor(0.1102)
features.4.conv.0 tensor(0.0778)
features.4.conv.3 tensor(0.2998)
features.4.conv.6 tensor(0.3407)
features.5.conv.0 tensor(0.3019)
features.5.conv.3 tensor(0.4149)
features.5.conv.6 tensor(0.3185)
features.6.conv.0 tensor(0.0526)
features.6.conv.3 tensor(0.0498)
features.6.conv.6 tensor(0.0817)
features.7.conv.0 tensor(0.2163)
features.7.conv.3 tensor(0.4508)
features.7.conv.6 tensor(0.6176)
features.8.conv.0 tensor(0.5025)
features.8.conv.3 tensor(0.5388)
features.8.conv.6 tensor(0.4557)
features.9.conv.0 tensor(0.4753)
features.9.conv.3 tensor(0.5622)
features.9.conv.6 tensor(0.7412)
features.10.conv.0 tensor(0.0610)
features.10.conv.3 tensor(0.0923)
features.10.conv.6 tensor(0.0689)
features.11.conv.0 tensor(0.7353)
features.11.conv.3 tensor(0.6435)
features.11.conv.6 tensor(0.8978)
features.12.conv.0 tensor(0.7137)
features.12.conv.3 tensor(0.6607)
features.12.conv.6 tensor(0.8592)
features.13.conv.0 tensor(0.2765)
features.13.conv.3 tensor(0.4844)
features.13.conv.6 tensor(0.4810)
features.14.conv.0 tensor(0.9016)
features.14.conv.3 tensor(0.8234)
features.14.conv.6 tensor(0.9547)
features.15.conv.0 tensor(0.8855)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9618)
features.16.conv.0 tensor(0.6756)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.8860)
conv.0 tensor(0.1174)
tensor(1356776.) 2188896.0
0.57791817
tensor(0.1189, device='cuda:0', grad_fn=<AddBackward0>)
0.57782561
tensor(0.1417, device='cuda:0', grad_fn=<AddBackward0>)
0.57797933
tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
0.57789433
tensor(0.1704, device='cuda:0', grad_fn=<AddBackward0>)
0.57794112
tensor(0.1649, device='cuda:0', grad_fn=<AddBackward0>)
0.57798713
tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)
0.57806152
tensor(0.1495, device='cuda:0', grad_fn=<AddBackward0>)
0.57790905
tensor(0.1592, device='cuda:0', grad_fn=<AddBackward0>)
0.57790846
tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>)
0.57774311
tensor(0.1786, device='cuda:0', grad_fn=<AddBackward0>)
0.57779217
tensor(0.1144, device='cuda:0', grad_fn=<AddBackward0>)
0.57787424
tensor(0.1490, device='cuda:0', grad_fn=<AddBackward0>)
0.57786787
tensor(0.1767, device='cuda:0', grad_fn=<AddBackward0>)
0.57780319
tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
0.57794845
tensor(0.1282, device='cuda:0', grad_fn=<AddBackward0>)
0.57794315
tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
0.57796770
tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)
0.57796055
tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
0.57777733
tensor(0.1646, device='cuda:0', grad_fn=<AddBackward0>)
0.57765073
tensor(0.1665, device='cuda:0', grad_fn=<AddBackward0>)
0.57752854
tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>)
0.57753485
tensor(0.1487, device='cuda:0', grad_fn=<AddBackward0>)
0.57755727
tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
0.57753998
tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [41][   20/  196]   Loss 0.159706   Top1 94.394531   Top5 99.882812   BatchTime 0.317892   LR 0.000103
0.57753658
tensor(0.1490, device='cuda:0', grad_fn=<AddBackward0>)
0.57755697
tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
0.57776016
tensor(0.1282, device='cuda:0', grad_fn=<AddBackward0>)
0.57749385
tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>)
0.57726014
tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)
0.57708597
tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)
0.57705927
tensor(0.1839, device='cuda:0', grad_fn=<AddBackward0>)
0.57707220
tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>)
0.57701504
tensor(0.1446, device='cuda:0', grad_fn=<AddBackward0>)
0.57708454
tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
0.57693249
tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
0.57676327
tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
0.57658362
tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)
0.57653213
tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
0.57648879
tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>)
0.57642984
tensor(0.1495, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [41][   40/  196]   Loss 0.163081   Top1 94.384766   Top5 99.892578   BatchTime 0.287629   LR 0.000102
0.57632130
tensor(0.1557, device='cuda:0', grad_fn=<AddBackward0>)
0.57615876
tensor(0.1565, device='cuda:0', grad_fn=<AddBackward0>)
0.57599556
tensor(0.1628, device='cuda:0', grad_fn=<AddBackward0>)
0.57560974
tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
0.57520550
tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>)
0.57510716
tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
0.57503676
tensor(0.1793, device='cuda:0', grad_fn=<AddBackward0>)
0.57503116
tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
0.57506526
tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
0.57526547
tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>)
0.57516986
tensor(0.1651, device='cuda:0', grad_fn=<AddBackward0>)
0.57514775
tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)
0.57503051
tensor(0.1587, device='cuda:0', grad_fn=<AddBackward0>)
0.57491249
tensor(0.1637, device='cuda:0', grad_fn=<AddBackward0>)
0.57488006
tensor(0.2129, device='cuda:0', grad_fn=<AddBackward0>)
0.57484055
tensor(0.1341, device='cuda:0', grad_fn=<AddBackward0>)
0.57477647
tensor(0.1572, device='cuda:0', grad_fn=<AddBackward0>)
0.57469249
tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
0.57462656
tensor(0.1483, device='cuda:0', grad_fn=<AddBackward0>)
0.57459855
tensor(0.1574, device='cuda:0', grad_fn=<AddBackward0>)
0.57441127
tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>)
0.57436270
tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>)
0.57432985
tensor(0.1312, device='cuda:0', grad_fn=<AddBackward0>)
0.57408345
tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [41][   60/  196]   Loss 0.165568   Top1 94.231771   Top5 99.895833   BatchTime 0.276035   LR 0.000102
0.57388926
tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
0.57386613
tensor(0.1326, device='cuda:0', grad_fn=<AddBackward0>)
0.57375592
tensor(0.1584, device='cuda:0', grad_fn=<AddBackward0>)
0.57376099
tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
0.57385474
tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
0.57383102
tensor(0.1560, device='cuda:0', grad_fn=<AddBackward0>)
0.57362366
tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
0.57344484
tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>)
0.57335252
tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
0.57334858
tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
0.57328540
tensor(0.1294, device='cuda:0', grad_fn=<AddBackward0>)
0.57333487
tensor(0.1312, device='cuda:0', grad_fn=<AddBackward0>)
0.57337004
tensor(0.1033, device='cuda:0', grad_fn=<AddBackward0>)
0.57312733
tensor(0.1208, device='cuda:0', grad_fn=<AddBackward0>)
0.57304269
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.57291245
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [41][   80/  196]   Loss 0.164209   Top1 94.291992   Top5 99.907227   BatchTime 0.269340   LR 0.000102
0.57276970
tensor(0.1110, device='cuda:0', grad_fn=<AddBackward0>)
0.57270956
tensor(0.1514, device='cuda:0', grad_fn=<AddBackward0>)
0.57265764
tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
0.57256216
tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
0.57256836
tensor(0.1451, device='cuda:0', grad_fn=<AddBackward0>)
0.57255363
tensor(0.1778, device='cuda:0', grad_fn=<AddBackward0>)
0.57247376
tensor(0.1231, device='cuda:0', grad_fn=<AddBackward0>)
0.57235122
tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
0.57219023
tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
0.57220227
tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>)
0.57222211
tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)
0.57216978
tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
0.57226098
tensor(0.1277, device='cuda:0', grad_fn=<AddBackward0>)
0.57236123
tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>)
0.57235515
tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
0.57219201
tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
0.57232094
tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
0.57229143
tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
0.57246083
tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
0.57240039
tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
0.57230622
tensor(0.1653, device='cuda:0', grad_fn=<AddBackward0>)
0.57232004
tensor(0.2463, device='cuda:0', grad_fn=<AddBackward0>)
0.57221907
tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
0.57227236
tensor(0.1119, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [41][  100/  196]   Loss 0.165773   Top1 94.250000   Top5 99.910156   BatchTime 0.265548   LR 0.000101
0.57223129
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
0.57231009
tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
0.57218581
tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
0.57223666
tensor(0.1628, device='cuda:0', grad_fn=<AddBackward0>)
0.57225674
tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
0.57228261
tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>)
0.57236576
tensor(0.1223, device='cuda:0', grad_fn=<AddBackward0>)
0.57246727
tensor(0.1497, device='cuda:0', grad_fn=<AddBackward0>)
0.57243884
tensor(0.1374, device='cuda:0', grad_fn=<AddBackward0>)
0.57254982
tensor(0.1406, device='cuda:0', grad_fn=<AddBackward0>)
0.57240307
tensor(0.1528, device='cuda:0', grad_fn=<AddBackward0>)
0.57225996
tensor(0.1562, device='cuda:0', grad_fn=<AddBackward0>)
0.57237637
tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
0.57237107
tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
0.57241315
tensor(0.0798, device='cuda:0', grad_fn=<AddBackward0>)
0.57236999
tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [41][  120/  196]   Loss 0.164971   Top1 94.355469   Top5 99.921875   BatchTime 0.262617   LR 0.000101
0.57372791
tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
0.57390386
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
0.57385796
tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
0.57378107
tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
0.57383740
tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
0.57381129
tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
0.57367426
tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
0.57360041
tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
0.57366848
tensor(0.1740, device='cuda:0', grad_fn=<AddBackward0>)
0.57370543
tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
0.57369089
tensor(0.2201, device='cuda:0', grad_fn=<AddBackward0>)
0.57336664
tensor(0.1444, device='cuda:0', grad_fn=<AddBackward0>)
0.57312375
tensor(0.1607, device='cuda:0', grad_fn=<AddBackward0>)
0.57318991
tensor(0.2186, device='cuda:0', grad_fn=<AddBackward0>)
0.57312912
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.57299286
tensor(0.1685, device='cuda:0', grad_fn=<AddBackward0>)
0.57290316
tensor(0.1655, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [41][  140/  196]   Loss 0.166363   Top1 94.308036   Top5 99.916295   BatchTime 0.260986   LR 0.000100
0.57281888
tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
0.57274258
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.57275927
tensor(0.1558, device='cuda:0', grad_fn=<AddBackward0>)
0.57281488
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.57281983
tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
0.57286346
tensor(0.1472, device='cuda:0', grad_fn=<AddBackward0>)
0.57278365
tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)
0.57262045
tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>)
0.57259339
tensor(0.1519, device='cuda:0', grad_fn=<AddBackward0>)
0.57254720
tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>)
0.57250899
tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)
0.57253724
tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)
0.57249790
tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
0.57243395
tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>)
0.57238513
tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)
0.57242107
tensor(0.0824, device='cuda:0', grad_fn=<AddBackward0>)
0.57249600
tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>)
0.57257235
tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
0.57257169
tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
0.57263917
tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
0.57269168
tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>)
0.57292140
tensor(0.1299, device='cuda:0', grad_fn=<AddBackward0>)
0.57320237
tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [41][  160/  196]   Loss 0.165937   Top1 94.357910   Top5 99.914551   BatchTime 0.259681   LR 0.000100
0.57311755
tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)
0.57300526
tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
0.57280904
tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>)
0.57287455
tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>)
0.57269806
tensor(0.1181, device='cuda:0', grad_fn=<AddBackward0>)
0.57262331
tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
0.57280898
tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>)
0.57281643
tensor(0.1644, device='cuda:0', grad_fn=<AddBackward0>)
0.57284290
tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
0.57301003
tensor(0.1163, device='cuda:0', grad_fn=<AddBackward0>)
0.57271916
tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>)
0.57254368
tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
0.57254046
tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
0.57260114
tensor(0.1585, device='cuda:0', grad_fn=<AddBackward0>)
0.57267338
tensor(0.1372, device='cuda:0', grad_fn=<AddBackward0>)
0.57268208
tensor(0.1782, device='cuda:0', grad_fn=<AddBackward0>)
0.57269454
tensor(0.1425, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [41][  180/  196]   Loss 0.164898   Top1 94.429253   Top5 99.919705   BatchTime 0.258710   LR 0.000100
0.57248390
tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>)
0.57255274
tensor(0.1756, device='cuda:0', grad_fn=<AddBackward0>)
0.57271427
tensor(0.1696, device='cuda:0', grad_fn=<AddBackward0>)
0.57275152
tensor(0.1248, device='cuda:0', grad_fn=<AddBackward0>)
0.57239854
tensor(0.1773, device='cuda:0', grad_fn=<AddBackward0>)
0.57234621
tensor(0.1780, device='cuda:0', grad_fn=<AddBackward0>)
0.57232296
tensor(0.1616, device='cuda:0', grad_fn=<AddBackward0>)
0.57236248
tensor(0.1028, device='cuda:0', grad_fn=<AddBackward0>)
0.57234687
tensor(0.1514, device='cuda:0', grad_fn=<AddBackward0>)
0.57233530
tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>)
0.57229704
tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)
0.57242876
tensor(0.1689, device='cuda:0', grad_fn=<AddBackward0>)
0.57247233
tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)
0.57249635
tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>)
0.57260907
tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
0.57260555
tensor(0.1674, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 94.432    Top5: 99.924    Loss: 0.165
0.57264721
tensor(0.1693, device='cuda:0', grad_fn=<AddBackward0>)
0.57268333
tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>)
0.57246470
tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [41][   20/   40]   Loss 0.391635   Top1 88.339844   Top5 99.511719   BatchTime 0.123322
INFO - Validation [41][   40/   40]   Loss 0.381008   Top1 88.440000   Top5 99.600000   BatchTime 0.086307
INFO - ==> Top1: 88.440    Top5: 99.600    Loss: 0.381
INFO - ==> Sparsity : 0.616
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1543)
features.1.conv.0 tensor(0.0436)
features.1.conv.3 tensor(0.0694)
features.1.conv.6 tensor(0.0981)
features.2.conv.0 tensor(0.0885)
features.2.conv.3 tensor(0.3410)
features.2.conv.6 tensor(0.5133)
features.3.conv.0 tensor(0.0726)
features.3.conv.3 tensor(0.0802)
features.3.conv.6 tensor(0.1107)
features.4.conv.0 tensor(0.0819)
features.4.conv.3 tensor(0.3021)
features.4.conv.6 tensor(0.3416)
features.5.conv.0 tensor(0.2964)
features.5.conv.3 tensor(0.4167)
features.5.conv.6 tensor(0.4227)
features.6.conv.0 tensor(0.0511)
features.6.conv.3 tensor(0.0498)
features.6.conv.6 tensor(0.0803)
features.7.conv.0 tensor(0.2163)
features.7.conv.3 tensor(0.4499)
features.7.conv.6 tensor(0.6169)
features.8.conv.0 tensor(0.5155)
features.8.conv.3 tensor(0.5379)
features.8.conv.6 tensor(0.4714)
features.9.conv.0 tensor(0.4786)
features.9.conv.3 tensor(0.5645)
features.9.conv.6 tensor(0.7412)
features.10.conv.0 tensor(0.0623)
features.10.conv.3 tensor(0.0883)
features.10.conv.6 tensor(0.0695)
features.11.conv.0 tensor(0.7399)
features.11.conv.3 tensor(0.6433)
features.11.conv.6 tensor(0.8976)
features.12.conv.0 tensor(0.7118)
features.12.conv.3 tensor(0.6620)
features.12.conv.6 tensor(0.8561)
features.13.conv.0 tensor(0.2735)
features.13.conv.3 tensor(0.4865)
features.13.conv.6 tensor(0.4848)
features.14.conv.0 tensor(0.9031)
features.14.conv.3 tensor(0.8234)
features.14.conv.6 tensor(0.9556)
features.15.conv.0 tensor(0.8872)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9621)
features.16.conv.0 tensor(0.6720)
features.16.conv.3 tensor(0.7883)
features.16.conv.6 tensor(0.8867)
conv.0 tensor(0.0947)
tensor(1349347.) 2188896.0
0.57256007
tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
0.57253474
tensor(0.1455, device='cuda:0', grad_fn=<AddBackward0>)
0.57244909
tensor(0.1325, device='cuda:0', grad_fn=<AddBackward0>)
0.57252175
tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>)
0.57240230
tensor(0.1082, device='cuda:0', grad_fn=<AddBackward0>)
0.57234508
tensor(0.1625, device='cuda:0', grad_fn=<AddBackward0>)
0.57231289
tensor(0.1118, device='cuda:0', grad_fn=<AddBackward0>)
0.57240379
tensor(0.1623, device='cuda:0', grad_fn=<AddBackward0>)
0.57254529
tensor(0.1365, device='cuda:0', grad_fn=<AddBackward0>)
0.57229239
tensor(0.1519, device='cuda:0', grad_fn=<AddBackward0>)
0.57221812
tensor(0.1514, device='cuda:0', grad_fn=<AddBackward0>)
0.57216656
tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)
0.57213390
tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
0.57208526
tensor(0.1137, device='cuda:0', grad_fn=<AddBackward0>)
0.57210660
tensor(0.1640, device='cuda:0', grad_fn=<AddBackward0>)
0.57219720
tensor(0.1504, device='cuda:0', grad_fn=<AddBackward0>)
0.57244170
tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
0.57231790
tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
0.57231808
tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>)
0.57198983
tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [42][   20/  196]   Loss 0.150784   Top1 95.058594   Top5 100.000000   BatchTime 0.380810   LR 0.000099
0.57183295
tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>)
0.57182658
tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
0.57180578
tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
0.57180482
tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>)
0.57183188
tensor(0.1835, device='cuda:0', grad_fn=<AddBackward0>)
0.57172394
tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)
0.57165474
tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
0.57191139
tensor(0.1714, device='cuda:0', grad_fn=<AddBackward0>)
0.57189119
tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
0.57173520
tensor(0.0968, device='cuda:0', grad_fn=<AddBackward0>)
0.57164508
tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>)
0.57175076
tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
0.57204348
tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
0.57236600
tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
0.57238179
tensor(0.1220, device='cuda:0', grad_fn=<AddBackward0>)
0.57194811
tensor(0.1223, device='cuda:0', grad_fn=<AddBackward0>)
0.57170570
tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>)
0.57174903
tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [42][   40/  196]   Loss 0.152151   Top1 94.824219   Top5 99.980469   BatchTime 0.355691   LR 0.000098
0.57172459
tensor(0.1087, device='cuda:0', grad_fn=<AddBackward0>)
0.57164532
tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
0.57159078
tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
0.57154971
tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
0.57156754
tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
0.57165945
tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)
0.57168174
tensor(0.1743, device='cuda:0', grad_fn=<AddBackward0>)
0.57171220
tensor(0.1479, device='cuda:0', grad_fn=<AddBackward0>)
0.57185161
tensor(0.1617, device='cuda:0', grad_fn=<AddBackward0>)
0.57226723
tensor(0.1420, device='cuda:0', grad_fn=<AddBackward0>)
0.57237965
tensor(0.1489, device='cuda:0', grad_fn=<AddBackward0>)
0.57236236
tensor(0.1313, device='cuda:0', grad_fn=<AddBackward0>)
0.57219738
tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>)
0.57197750
tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>)
0.57200062
tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
0.57193977
tensor(0.1716, device='cuda:0', grad_fn=<AddBackward0>)
0.57199430
tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
0.57195085
tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)
0.57217282
tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
0.57221812
tensor(0.1486, device='cuda:0', grad_fn=<AddBackward0>)
0.57198447
tensor(0.1434, device='cuda:0', grad_fn=<AddBackward0>)
0.57190382
tensor(0.1277, device='cuda:0', grad_fn=<AddBackward0>)
0.57195485
tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
0.57199603
tensor(0.1663, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [42][   60/  196]   Loss 0.159519   Top1 94.531250   Top5 99.960938   BatchTime 0.349191   LR 0.000098
0.57196581
tensor(0.1327, device='cuda:0', grad_fn=<AddBackward0>)
0.57203788
tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)
0.57203197
tensor(0.1606, device='cuda:0', grad_fn=<AddBackward0>)
0.57201284
tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>)
0.57218921
tensor(0.1273, device='cuda:0', grad_fn=<AddBackward0>)
0.57228440
tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
0.57210845
tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)
0.57222795
tensor(0.1376, device='cuda:0', grad_fn=<AddBackward0>)
0.57242024
tensor(0.1492, device='cuda:0', grad_fn=<AddBackward0>)
0.57224661
tensor(0.1609, device='cuda:0', grad_fn=<AddBackward0>)
0.57219708
tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
0.57219368
tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
0.57207918
tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
0.57205540
tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)
0.57208681
tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
0.57213163
tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
0.57222414
tensor(0.1206, device='cuda:0', grad_fn=<AddBackward0>)
0.57218391
tensor(0.1609, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [42][   80/  196]   Loss 0.160148   Top1 94.453125   Top5 99.946289   BatchTime 0.345021   LR 0.000098
0.57212526
tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>)
0.57209253
tensor(0.1625, device='cuda:0', grad_fn=<AddBackward0>)
0.57204920
tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)
0.57189417
tensor(0.1795, device='cuda:0', grad_fn=<AddBackward0>)
0.57197189
tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
0.57191193
tensor(0.1636, device='cuda:0', grad_fn=<AddBackward0>)
0.57186610
tensor(0.1365, device='cuda:0', grad_fn=<AddBackward0>)
0.57195842
tensor(0.1529, device='cuda:0', grad_fn=<AddBackward0>)
0.57189870
tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>)
0.57217610
tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
0.57194173
tensor(0.1814, device='cuda:0', grad_fn=<AddBackward0>)
0.57197720
tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>)
0.57203943
tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
0.57193100
tensor(0.1293, device='cuda:0', grad_fn=<AddBackward0>)
0.57181090
tensor(0.1731, device='cuda:0', grad_fn=<AddBackward0>)
0.57171160
tensor(0.1778, device='cuda:0', grad_fn=<AddBackward0>)
0.57163894
tensor(0.1483, device='cuda:0', grad_fn=<AddBackward0>)
0.57176721
tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [42][  100/  196]   Loss 0.161575   Top1 94.417969   Top5 99.949219   BatchTime 0.342869   LR 0.000097
0.57160765
tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)
0.57151133
tensor(0.1610, device='cuda:0', grad_fn=<AddBackward0>)
0.57155782
tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
0.57173717
tensor(0.1782, device='cuda:0', grad_fn=<AddBackward0>)
0.57192504
tensor(0.1765, device='cuda:0', grad_fn=<AddBackward0>)
0.57173491
tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
0.57177377
tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>)
0.57189083
tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
0.57168579
tensor(0.1594, device='cuda:0', grad_fn=<AddBackward0>)
0.57153130
tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)
0.57145637
tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
0.57146764
tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)
0.57142353
tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)
0.57142949
tensor(0.1752, device='cuda:0', grad_fn=<AddBackward0>)
0.57157862
tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>)
0.57158661
tensor(0.0958, device='cuda:0', grad_fn=<AddBackward0>)
0.57156742
tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
0.57152045
tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
0.57148570
tensor(0.1423, device='cuda:0', grad_fn=<AddBackward0>)
0.57138580
tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>)
0.57137644
tensor(0.1267, device='cuda:0', grad_fn=<AddBackward0>)
0.57134908
tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
0.57129967
tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>)
0.57130849
tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>)
0.57125932
tensor(0.1775, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [42][  120/  196]   Loss 0.160962   Top1 94.462891   Top5 99.951172   BatchTime 0.339611   LR 0.000097
0.57125372
tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>)
0.57121694
tensor(0.1293, device='cuda:0', grad_fn=<AddBackward0>)
0.57120711
tensor(0.1396, device='cuda:0', grad_fn=<AddBackward0>)
0.57122993
tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
0.57125396
tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>)
0.57127827
tensor(0.1651, device='cuda:0', grad_fn=<AddBackward0>)
0.57143086
tensor(0.0991, device='cuda:0', grad_fn=<AddBackward0>)
0.57159019
tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>)
0.57181793
tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
0.57162130
tensor(0.1191, device='cuda:0', grad_fn=<AddBackward0>)
0.57158357
tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>)
0.57151657
tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
0.57152325
tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
0.57146692
tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>)
0.57139713
tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>)
0.57134134
tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>)
0.57130134
tensor(0.1756, device='cuda:0', grad_fn=<AddBackward0>)
0.57131720
tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [42][  140/  196]   Loss 0.161322   Top1 94.453125   Top5 99.944196   BatchTime 0.338613   LR 0.000096
0.57133448
tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>)
0.57119966
tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
0.57118136
tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
0.57120889
tensor(0.1227, device='cuda:0', grad_fn=<AddBackward0>)
0.57119864
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.57117599
tensor(0.1667, device='cuda:0', grad_fn=<AddBackward0>)
0.57117450
tensor(0.1412, device='cuda:0', grad_fn=<AddBackward0>)
0.57120788
tensor(0.1360, device='cuda:0', grad_fn=<AddBackward0>)
0.57121754
tensor(0.1674, device='cuda:0', grad_fn=<AddBackward0>)
0.57109106
tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
0.57097471
tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>)
0.57096201
tensor(0.1793, device='cuda:0', grad_fn=<AddBackward0>)
0.57094890
tensor(0.1497, device='cuda:0', grad_fn=<AddBackward0>)
0.57089174
tensor(0.1293, device='cuda:0', grad_fn=<AddBackward0>)
0.57079774
tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)
0.57086319
tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
0.57091850
tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>)
0.57110202
tensor(0.1670, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [42][  160/  196]   Loss 0.161487   Top1 94.492188   Top5 99.946289   BatchTime 0.337794   LR 0.000096
0.57108337
tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)
0.57108814
tensor(0.1495, device='cuda:0', grad_fn=<AddBackward0>)
0.57113999
tensor(0.1685, device='cuda:0', grad_fn=<AddBackward0>)
0.57105500
tensor(0.1389, device='cuda:0', grad_fn=<AddBackward0>)
0.57106650
tensor(0.1681, device='cuda:0', grad_fn=<AddBackward0>)
0.57107723
tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>)
0.57117611
tensor(0.1543, device='cuda:0', grad_fn=<AddBackward0>)
0.57150054
tensor(0.1378, device='cuda:0', grad_fn=<AddBackward0>)
0.57188171
tensor(0.1814, device='cuda:0', grad_fn=<AddBackward0>)
0.57257789
tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
0.57382709
tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
0.57390732
tensor(0.1422, device='cuda:0', grad_fn=<AddBackward0>)
0.57424659
tensor(0.1474, device='cuda:0', grad_fn=<AddBackward0>)
0.57422042
tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
0.57406986
tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>)
0.57405841
tensor(0.1621, device='cuda:0', grad_fn=<AddBackward0>)
0.57391560
tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
0.57391697
tensor(0.1086, device='cuda:0', grad_fn=<AddBackward0>)
0.57376289
tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
0.57369059
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
0.57364273
tensor(0.1517, device='cuda:0', grad_fn=<AddBackward0>)
0.57360786
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
0.57368284
tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>)
0.57375532
tensor(0.1455, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [42][  180/  196]   Loss 0.161522   Top1 94.557292   Top5 99.941406   BatchTime 0.337456   LR 0.000096
0.57353628
tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
0.57351094
tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
0.57344604
tensor(0.1622, device='cuda:0', grad_fn=<AddBackward0>)
0.57344896
tensor(0.1703, device='cuda:0', grad_fn=<AddBackward0>)
0.57352477
tensor(0.1661, device='cuda:0', grad_fn=<AddBackward0>)
0.57365930
tensor(0.1537, device='cuda:0', grad_fn=<AddBackward0>)
0.57365465
tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
0.57336932
tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
0.57336873
tensor(0.1650, device='cuda:0', grad_fn=<AddBackward0>)
0.57337391
tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
0.57337344
tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)
0.57337326
tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
0.57346314
tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 94.534    Top5: 99.940    Loss: 0.162
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [42][   20/   40]   Loss 0.389799   Top1 88.300781   Top5 99.550781   BatchTime 0.122296
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1543)
features.1.conv.0 tensor(0.0384)
features.1.conv.3 tensor(0.0741)
features.1.conv.6 tensor(0.0946)
features.2.conv.0 tensor(0.1010)
features.2.conv.3 tensor(0.3418)
features.2.conv.6 tensor(0.5168)
features.3.conv.0 tensor(0.0735)
features.3.conv.3 tensor(0.0795)
features.3.conv.6 tensor(0.1100)
features.4.conv.0 tensor(0.0902)
features.4.conv.3 tensor(0.3003)
features.4.conv.6 tensor(0.3426)
features.5.conv.0 tensor(0.3070)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4367)
features.6.conv.0 tensor(0.0552)
features.6.conv.3 tensor(0.0521)
features.6.conv.6 tensor(0.0836)
features.7.conv.0 tensor(0.2157)
features.7.conv.3 tensor(0.4499)
features.7.conv.6 tensor(0.6219)
features.8.conv.0 tensor(0.5258)
features.8.conv.3 tensor(0.5370)
features.8.conv.6 tensor(0.4840)
features.9.conv.0 tensor(0.4636)
features.9.conv.3 tensor(0.5654)
features.9.conv.6 tensor(0.7426)
features.10.conv.0 tensor(0.0629)
features.10.conv.3 tensor(0.0883)
features.10.conv.6 tensor(0.0695)
features.11.conv.0 tensor(0.7454)
features.11.conv.3 tensor(0.6443)
features.11.conv.6 tensor(0.8988)
features.12.conv.0 tensor(0.7070)
features.12.conv.3 tensor(0.6630)
features.12.conv.6 tensor(0.8596)
features.13.conv.0 tensor(0.2600)
features.13.conv.3 tensor(0.4859)
features.13.conv.6 tensor(0.4877)
features.14.conv.0 tensor(0.9044)
features.14.conv.3 tensor(0.8233)
features.14.conv.6 tensor(0.9554)
features.15.conv.0 tensor(0.8883)
features.15.conv.3 tensor(0.8275)
features.15.conv.6 tensor(0.9616)
features.16.conv.0 tensor(0.6738)
features.16.conv.3 tensor(0.7883)
features.16.conv.6 tensor(0.8883)
conv.0 tensor(0.0909)
tensor(1349369.) 2188896.0
INFO - Validation [42][   40/   40]   Loss 0.379779   Top1 88.520000   Top5 99.650000   BatchTime 0.088848
INFO - ==> Top1: 88.520    Top5: 99.650    Loss: 0.380
INFO - ==> Sparsity : 0.616
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
0.57355249
tensor(0.1793, device='cuda:0', grad_fn=<AddBackward0>)
0.57354867
tensor(0.1488, device='cuda:0', grad_fn=<AddBackward0>)
0.57345825
tensor(0.1364, device='cuda:0', grad_fn=<AddBackward0>)
0.57339627
tensor(0.1723, device='cuda:0', grad_fn=<AddBackward0>)
0.57337493
tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
0.57336986
tensor(0.1213, device='cuda:0', grad_fn=<AddBackward0>)
0.57355857
tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
0.57355362
tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
0.57347167
tensor(0.1460, device='cuda:0', grad_fn=<AddBackward0>)
0.57345760
tensor(0.1432, device='cuda:0', grad_fn=<AddBackward0>)
0.57349563
tensor(0.1557, device='cuda:0', grad_fn=<AddBackward0>)
0.57359254
tensor(0.1318, device='cuda:0', grad_fn=<AddBackward0>)
0.57360673
tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
0.57380325
tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>)
0.57341188
tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>)
0.57326752
tensor(0.1729, device='cuda:0', grad_fn=<AddBackward0>)
0.57320571
tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>)
0.57326776
tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>)
0.57370925
tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)
0.57358176
tensor(0.1547, device='cuda:0', grad_fn=<AddBackward0>)
0.57344377
tensor(0.1574, device='cuda:0', grad_fn=<AddBackward0>)
0.57342249
tensor(0.1292, device='cuda:0', grad_fn=<AddBackward0>)
0.57357103
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
0.57358730
tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
0.57352132
tensor(0.1565, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [43][   20/  196]   Loss 0.156413   Top1 94.960938   Top5 99.921875   BatchTime 0.346851   LR 0.000095
0.57353050
tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>)
0.57353884
tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>)
0.57340395
tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>)
0.57332635
tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>)
0.57342714
tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)
0.57339340
tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
0.57329065
tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
0.57345200
tensor(0.1542, device='cuda:0', grad_fn=<AddBackward0>)
0.57334757
tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
0.57354581
tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
0.57365209
tensor(0.1698, device='cuda:0', grad_fn=<AddBackward0>)
0.57347262
tensor(0.1549, device='cuda:0', grad_fn=<AddBackward0>)
0.57350820
tensor(0.1686, device='cuda:0', grad_fn=<AddBackward0>)
0.57335317
tensor(0.1667, device='cuda:0', grad_fn=<AddBackward0>)
0.57325816
tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [43][   40/  196]   Loss 0.155638   Top1 94.824219   Top5 99.902344   BatchTime 0.312867   LR 0.000094
0.57323837
tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
0.57319480
tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
0.57305586
tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>)
0.57302564
tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>)
0.57311672
tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
0.57310200
tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>)
0.57323456
tensor(0.1603, device='cuda:0', grad_fn=<AddBackward0>)
0.57346481
tensor(0.1363, device='cuda:0', grad_fn=<AddBackward0>)
0.57350504
tensor(0.1415, device='cuda:0', grad_fn=<AddBackward0>)
0.57342148
tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
0.57309568
tensor(0.1424, device='cuda:0', grad_fn=<AddBackward0>)
0.57303864
tensor(0.1645, device='cuda:0', grad_fn=<AddBackward0>)
0.57293332
tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
0.57284200
tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
0.57278115
tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
0.57283771
tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>)
0.57294118
tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)
0.57294536
tensor(0.1752, device='cuda:0', grad_fn=<AddBackward0>)
0.57291704
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.57282513
tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)
0.57277763
tensor(0.1176, device='cuda:0', grad_fn=<AddBackward0>)
0.57269585
tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>)
0.57266563
tensor(0.1228, device='cuda:0', grad_fn=<AddBackward0>)
0.57262242
tensor(0.1882, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [43][   60/  196]   Loss 0.159578   Top1 94.654948   Top5 99.928385   BatchTime 0.291883   LR 0.000094
0.57267463
tensor(0.1533, device='cuda:0', grad_fn=<AddBackward0>)
0.57268089
tensor(0.1480, device='cuda:0', grad_fn=<AddBackward0>)
0.57282609
tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>)
0.57324564
tensor(0.1681, device='cuda:0', grad_fn=<AddBackward0>)
0.57318842
tensor(0.1188, device='cuda:0', grad_fn=<AddBackward0>)
0.57316118
tensor(0.1163, device='cuda:0', grad_fn=<AddBackward0>)
0.57296902
tensor(0.1492, device='cuda:0', grad_fn=<AddBackward0>)
0.57289720
tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
0.57296282
tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
0.57284653
tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>)
0.57275277
tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>)
0.57272482
tensor(0.1146, device='cuda:0', grad_fn=<AddBackward0>)
0.57281089
tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>)
0.57272810
tensor(0.1343, device='cuda:0', grad_fn=<AddBackward0>)
0.57266504
tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>)
0.57252747
tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [43][   80/  196]   Loss 0.155767   Top1 94.755859   Top5 99.946289   BatchTime 0.281829   LR 0.000093
0.57259333
tensor(0.1587, device='cuda:0', grad_fn=<AddBackward0>)
0.57266670
tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>)
0.57279038
tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>)
0.57279146
tensor(0.1751, device='cuda:0', grad_fn=<AddBackward0>)
0.57293749
tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
0.57309127
tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>)
0.57303858
tensor(0.1294, device='cuda:0', grad_fn=<AddBackward0>)
0.57313001
tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
0.57308936
tensor(0.1550, device='cuda:0', grad_fn=<AddBackward0>)
0.57331395
tensor(0.1041, device='cuda:0', grad_fn=<AddBackward0>)
0.57323140
tensor(0.1518, device='cuda:0', grad_fn=<AddBackward0>)
0.57317787
tensor(0.1644, device='cuda:0', grad_fn=<AddBackward0>)
0.57316935
tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>)
0.57318169
tensor(0.1021, device='cuda:0', grad_fn=<AddBackward0>)
0.57338661
tensor(0.1602, device='cuda:0', grad_fn=<AddBackward0>)
0.57326251
tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
0.57331294
tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>)
0.57335728
tensor(0.1565, device='cuda:0', grad_fn=<AddBackward0>)
0.57341295
tensor(0.1242, device='cuda:0', grad_fn=<AddBackward0>)
0.57329369
tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>)
0.57315695
tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
0.57314324
tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
0.57332063
tensor(0.1016, device='cuda:0', grad_fn=<AddBackward0>)
0.57326257
tensor(0.1121, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [43][  100/  196]   Loss 0.155041   Top1 94.746094   Top5 99.953125   BatchTime 0.274893   LR 0.000093
0.57316381
tensor(0.1515, device='cuda:0', grad_fn=<AddBackward0>)
0.57310122
tensor(0.1186, device='cuda:0', grad_fn=<AddBackward0>)
0.57304341
tensor(0.1543, device='cuda:0', grad_fn=<AddBackward0>)
0.57321191
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.57326305
tensor(0.1780, device='cuda:0', grad_fn=<AddBackward0>)
0.57313192
tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)
0.57309109
tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>)
0.57305133
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.57273769
tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>)
0.57252508
tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
0.57244629
tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>)
0.57237720
tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>)
0.57238507
tensor(0.2201, device='cuda:0', grad_fn=<AddBackward0>)
0.57243693
tensor(0.1658, device='cuda:0', grad_fn=<AddBackward0>)
0.57240254
tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
0.57239842
tensor(0.1725, device='cuda:0', grad_fn=<AddBackward0>)
0.57246178
tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
0.57246494
tensor(0.1360, device='cuda:0', grad_fn=<AddBackward0>)
0.57234818
tensor(0.1534, device='cuda:0', grad_fn=<AddBackward0>)
0.57229370
tensor(0.1818, device='cuda:0', grad_fn=<AddBackward0>)
0.57227588
tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [43][  120/  196]   Loss 0.153604   Top1 94.778646   Top5 99.951172   BatchTime 0.275624   LR 0.000093
0.57219595
tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
0.57218027
tensor(0.1094, device='cuda:0', grad_fn=<AddBackward0>)
0.57220125
tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
0.57222414
tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
0.57222795
tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)
0.57221466
tensor(0.1406, device='cuda:0', grad_fn=<AddBackward0>)
0.57219696
tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>)
0.57219863
tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
0.57210249
tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
0.57203323
tensor(0.1105, device='cuda:0', grad_fn=<AddBackward0>)
0.57201779
tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>)
0.57198906
tensor(0.1600, device='cuda:0', grad_fn=<AddBackward0>)
0.57196224
tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
0.57199490
tensor(0.1669, device='cuda:0', grad_fn=<AddBackward0>)
0.57196873
tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>)
0.57195097
tensor(0.1653, device='cuda:0', grad_fn=<AddBackward0>)
0.57202727
tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
0.57209957
tensor(0.1482, device='cuda:0', grad_fn=<AddBackward0>)
0.57210654
tensor(0.1733, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [43][  140/  196]   Loss 0.154520   Top1 94.746094   Top5 99.952567   BatchTime 0.280777   LR 0.000092
0.57207042
tensor(0.1953, device='cuda:0', grad_fn=<AddBackward0>)
0.57201028
tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
0.57220286
tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>)
0.57259554
tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
0.57248741
tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)
0.57272780
tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)
0.57272404
tensor(0.1586, device='cuda:0', grad_fn=<AddBackward0>)
0.57270187
tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
0.57250661
tensor(0.1067, device='cuda:0', grad_fn=<AddBackward0>)
0.57222193
tensor(0.1667, device='cuda:0', grad_fn=<AddBackward0>)
0.57216758
tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>)
0.57223946
tensor(0.1488, device='cuda:0', grad_fn=<AddBackward0>)
0.57226425
tensor(0.0976, device='cuda:0', grad_fn=<AddBackward0>)
0.57230604
tensor(0.1550, device='cuda:0', grad_fn=<AddBackward0>)
0.57248807
tensor(0.1382, device='cuda:0', grad_fn=<AddBackward0>)
0.57208443
tensor(0.1938, device='cuda:0', grad_fn=<AddBackward0>)
0.57203114
tensor(0.1016, device='cuda:0', grad_fn=<AddBackward0>)
0.57199186
tensor(0.1725, device='cuda:0', grad_fn=<AddBackward0>)
0.57200736
tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>)
0.57205611
tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
0.57206208
tensor(0.1435, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [43][  160/  196]   Loss 0.156501   Top1 94.670410   Top5 99.953613   BatchTime 0.281263   LR 0.000092
0.57201153
tensor(0.1645, device='cuda:0', grad_fn=<AddBackward0>)
0.57194227
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.57181132
tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
0.57171804
tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
0.57164311
tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>)
0.57155734
tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>)
0.57150704
tensor(0.1227, device='cuda:0', grad_fn=<AddBackward0>)
0.57147831
tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>)
0.57147616
tensor(0.1534, device='cuda:0', grad_fn=<AddBackward0>)
0.57144433
tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>)
0.57136112
tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
0.57129556
tensor(0.1436, device='cuda:0', grad_fn=<AddBackward0>)
0.57125640
tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>)
0.57124168
tensor(0.1382, device='cuda:0', grad_fn=<AddBackward0>)
0.57125068
tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
0.57123142
tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
0.57125819
tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
0.57126391
tensor(0.1441, device='cuda:0', grad_fn=<AddBackward0>)
0.57126874
tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
0.57138276
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [43][  180/  196]   Loss 0.156687   Top1 94.680990   Top5 99.954427   BatchTime 0.284188   LR 0.000091
0.57164878
tensor(0.1144, device='cuda:0', grad_fn=<AddBackward0>)
0.57157189
tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>)
0.57143694
tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
0.57139868
tensor(0.1644, device='cuda:0', grad_fn=<AddBackward0>)
0.57133776
tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
0.57129014
tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
0.57127368
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
0.57122982
tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
0.57119423
tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>)
0.57117677
tensor(0.1261, device='cuda:0', grad_fn=<AddBackward0>)
0.57122093
tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 94.636    Top5: 99.952    Loss: 0.157
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [43][   20/   40]   Loss 0.390497   Top1 88.730469   Top5 99.472656   BatchTime 0.121498
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1543)
features.1.conv.0 tensor(0.0482)
features.1.conv.3 tensor(0.0741)
features.1.conv.6 tensor(0.0938)
features.2.conv.0 tensor(0.0932)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.5226)
features.3.conv.0 tensor(0.0703)
features.3.conv.3 tensor(0.0772)
features.3.conv.6 tensor(0.1083)
features.4.conv.0 tensor(0.0835)
features.4.conv.3 tensor(0.3021)
features.4.conv.6 tensor(0.3517)
features.5.conv.0 tensor(0.3009)
features.5.conv.3 tensor(0.4161)
features.5.conv.6 tensor(0.4469)
features.6.conv.0 tensor(0.0544)
features.6.conv.3 tensor(0.0503)
features.6.conv.6 tensor(0.0836)
features.7.conv.0 tensor(0.2151)
features.7.conv.3 tensor(0.4468)
features.7.conv.6 tensor(0.6257)
features.8.conv.0 tensor(0.5138)
features.8.conv.3 tensor(0.5394)
features.8.conv.6 tensor(0.4906)
features.9.conv.0 tensor(0.4800)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.7418)
features.10.conv.0 tensor(0.0604)
features.10.conv.3 tensor(0.0909)
features.10.conv.6 tensor(0.0694)
features.11.conv.0 tensor(0.7484)
features.11.conv.3 tensor(0.6439)
features.11.conv.6 tensor(0.9018)
features.12.conv.0 tensor(0.7075)
features.12.conv.3 tensor(0.6622)
features.12.conv.6 tensor(0.8614)
features.13.conv.0 tensor(0.2534)
features.13.conv.3 tensor(0.4836)
features.13.conv.6 tensor(0.4917)
features.14.conv.0 tensor(0.9057)
features.14.conv.3 tensor(0.8227)
features.14.conv.6 tensor(0.9559)
features.15.conv.0 tensor(0.8893)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9622)
features.16.conv.0 tensor(0.6749)
features.16.conv.3 tensor(0.7883)
features.16.conv.6 tensor(0.8895)
conv.0 tensor(0.0886)
tensor(1350175.) 2188896.0
INFO - Validation [43][   40/   40]   Loss 0.383262   Top1 88.610000   Top5 99.660000   BatchTime 0.086800
INFO - ==> Top1: 88.610    Top5: 99.660    Loss: 0.383
INFO - ==> Sparsity : 0.617
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
0.57142609
tensor(0.1432, device='cuda:0', grad_fn=<AddBackward0>)
0.57156068
tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
0.57164192
tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
0.57198042
tensor(0.1664, device='cuda:0', grad_fn=<AddBackward0>)
0.57195038
tensor(0.0997, device='cuda:0', grad_fn=<AddBackward0>)
0.57189226
tensor(0.1429, device='cuda:0', grad_fn=<AddBackward0>)
0.57209486
tensor(0.1687, device='cuda:0', grad_fn=<AddBackward0>)
0.57224286
tensor(0.1439, device='cuda:0', grad_fn=<AddBackward0>)
0.57233155
tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
0.57227045
tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)
0.57235134
tensor(0.1518, device='cuda:0', grad_fn=<AddBackward0>)
0.57222623
tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>)
0.57218820
tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>)
0.57186931
tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)
0.57178229
tensor(0.1663, device='cuda:0', grad_fn=<AddBackward0>)
0.57183558
tensor(0.1569, device='cuda:0', grad_fn=<AddBackward0>)
0.57192880
tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
0.57194579
tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
0.57198232
tensor(0.1638, device='cuda:0', grad_fn=<AddBackward0>)
0.57196134
tensor(0.1296, device='cuda:0', grad_fn=<AddBackward0>)
0.57215184
tensor(0.1510, device='cuda:0', grad_fn=<AddBackward0>)
0.57219905
tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
0.57209969
tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [44][   20/  196]   Loss 0.151179   Top1 95.117188   Top5 99.941406   BatchTime 0.315658   LR 0.000090
0.57193208
tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
0.57187164
tensor(0.1401, device='cuda:0', grad_fn=<AddBackward0>)
0.57179987
tensor(0.1318, device='cuda:0', grad_fn=<AddBackward0>)
0.57170975
tensor(0.1008, device='cuda:0', grad_fn=<AddBackward0>)
0.57163674
tensor(0.1092, device='cuda:0', grad_fn=<AddBackward0>)
0.57161289
tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
0.57159334
tensor(0.1204, device='cuda:0', grad_fn=<AddBackward0>)
0.57167917
tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
0.57178622
tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>)
0.57182389
tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>)
0.57171845
tensor(0.1344, device='cuda:0', grad_fn=<AddBackward0>)
0.57162327
tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
0.57170826
tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)
0.57185912
tensor(0.1673, device='cuda:0', grad_fn=<AddBackward0>)
0.57198572
tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>)
0.57184297
tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [44][   40/  196]   Loss 0.151630   Top1 94.960938   Top5 99.951172   BatchTime 0.283032   LR 0.000090
0.57190067
tensor(0.1295, device='cuda:0', grad_fn=<AddBackward0>)
0.57208902
tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
0.57205743
tensor(0.1380, device='cuda:0', grad_fn=<AddBackward0>)
0.57192808
tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>)
0.57151800
tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>)
0.57137477
tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>)
0.57095170
tensor(0.1361, device='cuda:0', grad_fn=<AddBackward0>)
0.57064724
tensor(0.1240, device='cuda:0', grad_fn=<AddBackward0>)
0.57056224
tensor(0.1146, device='cuda:0', grad_fn=<AddBackward0>)
0.57065731
tensor(0.1217, device='cuda:0', grad_fn=<AddBackward0>)
0.57080162
tensor(0.1017, device='cuda:0', grad_fn=<AddBackward0>)
0.57079047
tensor(0.1497, device='cuda:0', grad_fn=<AddBackward0>)
0.57057506
tensor(0.1656, device='cuda:0', grad_fn=<AddBackward0>)
0.57068312
tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
0.57061470
tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
0.57067543
tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>)
0.57065684
tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>)
0.57067531
tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>)
0.57055563
tensor(0.1330, device='cuda:0', grad_fn=<AddBackward0>)
0.57057089
tensor(0.1808, device='cuda:0', grad_fn=<AddBackward0>)
0.57057834
tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)
0.57083881
tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>)
0.57074261
tensor(0.1649, device='cuda:0', grad_fn=<AddBackward0>)
0.57082939
tensor(0.1444, device='cuda:0', grad_fn=<AddBackward0>)
0.57068723
INFO - Training [44][   60/  196]   Loss 0.148688   Top1 95.084635   Top5 99.934896   BatchTime 0.272002   LR 0.000090
tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
0.57063037
tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
0.57054883
tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
0.57046878
tensor(0.1683, device='cuda:0', grad_fn=<AddBackward0>)
0.57041943
tensor(0.1867, device='cuda:0', grad_fn=<AddBackward0>)
0.57042199
tensor(0.1649, device='cuda:0', grad_fn=<AddBackward0>)
0.57050115
tensor(0.1600, device='cuda:0', grad_fn=<AddBackward0>)
0.57047147
tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>)
0.57041264
tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>)
0.57045925
tensor(0.1888, device='cuda:0', grad_fn=<AddBackward0>)
0.57062948
tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
0.57053596
tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
0.57039362
tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>)
0.57027203
tensor(0.1864, device='cuda:0', grad_fn=<AddBackward0>)
0.57018918
tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>)
0.57013589
tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>)
0.57020313
tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [44][   80/  196]   Loss 0.153254   Top1 94.931641   Top5 99.931641   BatchTime 0.265819   LR 0.000089
0.57015860
tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
0.57003170
tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>)
0.56999904
tensor(0.1867, device='cuda:0', grad_fn=<AddBackward0>)
0.57006204
tensor(0.1490, device='cuda:0', grad_fn=<AddBackward0>)
0.56997859
tensor(0.1330, device='cuda:0', grad_fn=<AddBackward0>)
0.56999701
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.57003570
tensor(0.1116, device='cuda:0', grad_fn=<AddBackward0>)
0.57001293
tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>)
0.56991494
tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
0.56984514
tensor(0.1652, device='cuda:0', grad_fn=<AddBackward0>)
0.56985962
tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>)
0.56987125
tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
0.56975800
tensor(0.1125, device='cuda:0', grad_fn=<AddBackward0>)
0.56955516
tensor(0.1151, device='cuda:0', grad_fn=<AddBackward0>)
0.56957203
tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)
0.56946427
tensor(0.1099, device='cuda:0', grad_fn=<AddBackward0>)
0.56953669
tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)
0.56953532
tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
0.56953555
tensor(0.1826, device='cuda:0', grad_fn=<AddBackward0>)
0.56958926
tensor(0.1529, device='cuda:0', grad_fn=<AddBackward0>)
0.56966358
tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
0.56983942
tensor(0.1692, device='cuda:0', grad_fn=<AddBackward0>)
0.56966186
tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>)
0.56953150
tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [44][  100/  196]   Loss 0.154487   Top1 94.863281   Top5 99.945312   BatchTime 0.263154   LR 0.000089
0.56961393
tensor(0.1877, device='cuda:0', grad_fn=<AddBackward0>)
0.56972885
tensor(0.1464, device='cuda:0', grad_fn=<AddBackward0>)
0.56975234
tensor(0.1457, device='cuda:0', grad_fn=<AddBackward0>)
0.56965393
tensor(0.0967, device='cuda:0', grad_fn=<AddBackward0>)
0.56965661
tensor(0.1309, device='cuda:0', grad_fn=<AddBackward0>)
0.56986290
tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
0.56989658
tensor(0.1572, device='cuda:0', grad_fn=<AddBackward0>)
0.56998938
tensor(0.1610, device='cuda:0', grad_fn=<AddBackward0>)
0.57000643
tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>)
0.57013094
tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
0.56997573
tensor(0.1372, device='cuda:0', grad_fn=<AddBackward0>)
0.56975275
tensor(0.1574, device='cuda:0', grad_fn=<AddBackward0>)
0.56950182
tensor(0.1450, device='cuda:0', grad_fn=<AddBackward0>)
0.56935316
tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)
0.56933880
tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
0.56931430
tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
0.56931281
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.56917870
tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
0.56916046
tensor(0.0857, device='cuda:0', grad_fn=<AddBackward0>)
0.56912804
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.56915134
tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [44][  120/  196]   Loss 0.155458   Top1 94.801432   Top5 99.944661   BatchTime 0.265736   LR 0.000088
0.56923836
tensor(0.1502, device='cuda:0', grad_fn=<AddBackward0>)
0.56920809
tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>)
0.56913793
tensor(0.1487, device='cuda:0', grad_fn=<AddBackward0>)
0.56907463
tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>)
0.56897455
tensor(0.1413, device='cuda:0', grad_fn=<AddBackward0>)
0.56887025
tensor(0.1127, device='cuda:0', grad_fn=<AddBackward0>)
0.56923038
tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>)
0.56881738
tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>)
0.56849110
tensor(0.1633, device='cuda:0', grad_fn=<AddBackward0>)
0.56845897
tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)
0.56853110
tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
0.56842834
tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>)
0.56822985
tensor(0.1732, device='cuda:0', grad_fn=<AddBackward0>)
0.56812048
tensor(0.1508, device='cuda:0', grad_fn=<AddBackward0>)
0.56805342
tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
0.56797272
tensor(0.1079, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [44][  140/  196]   Loss 0.155146   Top1 94.782366   Top5 99.941406   BatchTime 0.264734   LR 0.000088
0.56797636
tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>)
0.56809694
tensor(0.1727, device='cuda:0', grad_fn=<AddBackward0>)
0.56817102
tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>)
0.56806785
tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
0.56807512
tensor(0.1394, device='cuda:0', grad_fn=<AddBackward0>)
0.56847125
tensor(0.1403, device='cuda:0', grad_fn=<AddBackward0>)
0.56812245
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.56795502
tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)
0.56798172
tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)
0.56789768
tensor(0.1510, device='cuda:0', grad_fn=<AddBackward0>)
0.56788635
tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
0.56790870
tensor(0.1166, device='cuda:0', grad_fn=<AddBackward0>)
0.56792396
tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>)
0.56780201
tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>)
0.56782883
tensor(0.1670, device='cuda:0', grad_fn=<AddBackward0>)
0.56788927
tensor(0.1563, device='cuda:0', grad_fn=<AddBackward0>)
0.56785500
tensor(0.1454, device='cuda:0', grad_fn=<AddBackward0>)
0.56782585
tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
0.56790113
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.56837934
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
0.56831598
tensor(0.1627, device='cuda:0', grad_fn=<AddBackward0>)
0.56812912
tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [44][  160/  196]   Loss 0.154779   Top1 94.809570   Top5 99.931641   BatchTime 0.263863   LR 0.000087
0.56800336
tensor(0.1495, device='cuda:0', grad_fn=<AddBackward0>)
0.56803906
tensor(0.1363, device='cuda:0', grad_fn=<AddBackward0>)
0.56796879
tensor(0.1466, device='cuda:0', grad_fn=<AddBackward0>)
0.56790203
tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>)
0.56789809
tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
0.56777847
tensor(0.1515, device='cuda:0', grad_fn=<AddBackward0>)
0.56771785
tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)
0.56780964
tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
0.56800991
tensor(0.1695, device='cuda:0', grad_fn=<AddBackward0>)
0.56782365
tensor(0.1704, device='cuda:0', grad_fn=<AddBackward0>)
0.56771821
tensor(0.1577, device='cuda:0', grad_fn=<AddBackward0>)
0.56720746
tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
0.56701231
tensor(0.1020, device='cuda:0', grad_fn=<AddBackward0>)
0.56689811
tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)
0.56688118
tensor(0.1591, device='cuda:0', grad_fn=<AddBackward0>)
0.56685543
tensor(0.1629, device='cuda:0', grad_fn=<AddBackward0>)
0.56685805
tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>)
0.56672353
tensor(0.1658, device='cuda:0', grad_fn=<AddBackward0>)
0.56665266
tensor(0.1628, device='cuda:0', grad_fn=<AddBackward0>)
0.56660002
tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [44][  180/  196]   Loss 0.155685   Top1 94.789497   Top5 99.934896   BatchTime 0.268598   LR 0.000087
0.56648993
tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
0.56642419
tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>)
0.56645632
tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>)
0.56640822
tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>)
0.56640130
tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
0.56647331
tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>)
0.56638211
tensor(0.1685, device='cuda:0', grad_fn=<AddBackward0>)
0.56626004
tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
0.56616837
tensor(0.1774, device='cuda:0', grad_fn=<AddBackward0>)
0.56610560
tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>)
0.56607348
tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>)
0.56620729
tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
0.56627440
tensor(0.0857, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 94.766    Top5: 99.934    Loss: 0.156
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2951)
features.0.conv.3 tensor(0.1543)
features.1.conv.0 tensor(0.0508)
features.1.conv.3 tensor(0.0660)
features.1.conv.6 tensor(0.0924)
features.2.conv.0 tensor(0.0935)
features.2.conv.3 tensor(0.3426)
features.2.conv.6 tensor(0.5214)
features.3.conv.0 tensor(0.0692)
features.3.conv.3 tensor(0.0756)
features.3.conv.6 tensor(0.1085)
features.4.conv.0 tensor(0.0827)
features.4.conv.3 tensor(0.3009)
features.4.conv.6 tensor(0.3613)
features.5.conv.0 tensor(0.3107)
features.5.conv.3 tensor(0.4167)
features.5.conv.6 tensor(0.4458)
features.6.conv.0 tensor(0.0549)
features.6.conv.3 tensor(0.0527)
features.6.conv.6 tensor(0.0822)
features.7.conv.0 tensor(0.2404)
INFO - Validation [44][   20/   40]   Loss 0.384043   Top1 88.437500   Top5 99.589844   BatchTime 0.143180
INFO - Validation [44][   40/   40]   Loss 0.372875   Top1 88.620000   Top5 99.650000   BatchTime 0.099718
INFO - ==> Top1: 88.620    Top5: 99.650    Loss: 0.373
INFO - ==> Sparsity : 0.624
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
features.7.conv.3 tensor(0.4453)
features.7.conv.6 tensor(0.6259)
features.8.conv.0 tensor(0.5416)
features.8.conv.3 tensor(0.5367)
features.8.conv.6 tensor(0.4849)
features.9.conv.0 tensor(0.4778)
features.9.conv.3 tensor(0.5651)
features.9.conv.6 tensor(0.7436)
features.10.conv.0 tensor(0.0573)
features.10.conv.3 tensor(0.0911)
features.10.conv.6 tensor(0.0668)
features.11.conv.0 tensor(0.7488)
features.11.conv.3 tensor(0.6422)
features.11.conv.6 tensor(0.9009)
features.12.conv.0 tensor(0.7141)
features.12.conv.3 tensor(0.6622)
features.12.conv.6 tensor(0.8631)
features.13.conv.0 tensor(0.2568)
features.13.conv.3 tensor(0.4851)
features.13.conv.6 tensor(0.4886)
features.14.conv.0 tensor(0.9080)
features.14.conv.3 tensor(0.8230)
features.14.conv.6 tensor(0.9559)
features.15.conv.0 tensor(0.8899)
features.15.conv.3 tensor(0.8274)
features.15.conv.6 tensor(0.9621)
features.16.conv.0 tensor(0.6778)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.8906)
conv.0 tensor(0.1182)
tensor(1364914.) 2188896.0
0.56626534
tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
0.56593728
tensor(0.1358, device='cuda:0', grad_fn=<AddBackward0>)
0.56574804
tensor(0.1057, device='cuda:0', grad_fn=<AddBackward0>)
0.56574345
tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>)
0.56571543
tensor(0.1117, device='cuda:0', grad_fn=<AddBackward0>)
0.56572008
tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>)
0.56568694
tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
0.56570202
tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>)
0.56585109
tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>)
0.56601340
tensor(0.1312, device='cuda:0', grad_fn=<AddBackward0>)
0.56575006
tensor(0.1610, device='cuda:0', grad_fn=<AddBackward0>)
0.56583643
tensor(0.1027, device='cuda:0', grad_fn=<AddBackward0>)
0.56601918
tensor(0.1415, device='cuda:0', grad_fn=<AddBackward0>)
0.56591439
tensor(0.1454, device='cuda:0', grad_fn=<AddBackward0>)
0.56570363
tensor(0.1401, device='cuda:0', grad_fn=<AddBackward0>)
0.56572014
tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
0.56563812
tensor(0.1329, device='cuda:0', grad_fn=<AddBackward0>)
0.56569356
tensor(0.1557, device='cuda:0', grad_fn=<AddBackward0>)
0.56589192
tensor(0.1701, device='cuda:0', grad_fn=<AddBackward0>)
0.56585580
tensor(0.1671, device='cuda:0', grad_fn=<AddBackward0>)
0.56570208
tensor(0.1359, device='cuda:0', grad_fn=<AddBackward0>)
0.56585902
tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
0.56617099
tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [45][   20/  196]   Loss 0.151313   Top1 95.039062   Top5 99.941406   BatchTime 0.346281   LR 0.000086
0.56616312
tensor(0.0812, device='cuda:0', grad_fn=<AddBackward0>)
0.56590211
tensor(0.1382, device='cuda:0', grad_fn=<AddBackward0>)
0.56598848
tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)
0.56602490
tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
0.56600189
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
0.56569093
tensor(0.1920, device='cuda:0', grad_fn=<AddBackward0>)
0.56557143
tensor(0.1077, device='cuda:0', grad_fn=<AddBackward0>)
0.56553876
tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>)
0.56567264
tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
0.56574970
tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>)
0.56563008
tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>)
0.56583965
tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>)
0.56566870
tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
0.56562632
tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
0.56564254
tensor(0.1671, device='cuda:0', grad_fn=<AddBackward0>)
0.56550080
tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [45][   40/  196]   Loss 0.150050   Top1 94.960938   Top5 99.941406   BatchTime 0.297543   LR 0.000086
0.56550956
tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
0.56551331
tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>)
0.56548387
tensor(0.1353, device='cuda:0', grad_fn=<AddBackward0>)
0.56549335
tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>)
0.56537765
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.56542540
tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>)
0.56535977
tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>)
0.56527835
tensor(0.1345, device='cuda:0', grad_fn=<AddBackward0>)
0.56529856
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.56515557
tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>)
0.56514615
tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
0.56512314
tensor(0.1165, device='cuda:0', grad_fn=<AddBackward0>)
0.56513000
tensor(0.1579, device='cuda:0', grad_fn=<AddBackward0>)
0.56511265
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.56508106
tensor(0.2026, device='cuda:0', grad_fn=<AddBackward0>)
0.56499314
tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
0.56507975
tensor(0.1381, device='cuda:0', grad_fn=<AddBackward0>)
0.56510556
tensor(0.1278, device='cuda:0', grad_fn=<AddBackward0>)
0.56521392
tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>)
0.56532085
tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)
0.56531399
tensor(0.1131, device='cuda:0', grad_fn=<AddBackward0>)
0.56518197
tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
0.56533772
tensor(0.1107, device='cuda:0', grad_fn=<AddBackward0>)
0.56525242
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [45][   60/  196]   Loss 0.143735   Top1 95.162760   Top5 99.941406   BatchTime 0.281574   LR 0.000085
0.56518501
tensor(0.1404, device='cuda:0', grad_fn=<AddBackward0>)
0.56513458
tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>)
0.56532973
tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>)
0.56530964
tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>)
0.56523389
tensor(0.1415, device='cuda:0', grad_fn=<AddBackward0>)
0.56504047
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.56510907
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.56486756
tensor(0.1608, device='cuda:0', grad_fn=<AddBackward0>)
0.56471026
tensor(0.1163, device='cuda:0', grad_fn=<AddBackward0>)
0.56471920
tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
0.56483799
tensor(0.1517, device='cuda:0', grad_fn=<AddBackward0>)
0.56487411
tensor(0.1569, device='cuda:0', grad_fn=<AddBackward0>)
0.56484807
tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>)
0.56481606
tensor(0.1269, device='cuda:0', grad_fn=<AddBackward0>)
0.56475496
tensor(0.1674, device='cuda:0', grad_fn=<AddBackward0>)
0.56474900
tensor(0.1679, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [45][   80/  196]   Loss 0.146351   Top1 95.043945   Top5 99.946289   BatchTime 0.273866   LR 0.000085
0.56474054
tensor(0.1017, device='cuda:0', grad_fn=<AddBackward0>)
0.56470835
tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>)
0.56471062
tensor(0.1614, device='cuda:0', grad_fn=<AddBackward0>)
0.56473899
tensor(0.1277, device='cuda:0', grad_fn=<AddBackward0>)
0.56476045
tensor(0.1161, device='cuda:0', grad_fn=<AddBackward0>)
0.56468582
tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
0.56471610
tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>)
0.56463206
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
0.56461841
tensor(0.2121, device='cuda:0', grad_fn=<AddBackward0>)
0.56459492
tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)
0.56468385
tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
0.56482697
tensor(0.1398, device='cuda:0', grad_fn=<AddBackward0>)
0.56483352
tensor(0.1355, device='cuda:0', grad_fn=<AddBackward0>)
0.56471264
tensor(0.1243, device='cuda:0', grad_fn=<AddBackward0>)
0.56466275
tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>)
0.56468379
tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)
0.56465197
tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
0.56461608
tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
0.56468743
tensor(0.1569, device='cuda:0', grad_fn=<AddBackward0>)
0.56454021
tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>)
0.56442958
tensor(0.1318, device='cuda:0', grad_fn=<AddBackward0>)
0.56454301
tensor(0.1299, device='cuda:0', grad_fn=<AddBackward0>)
0.56472373
tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
0.56492066
tensor(0.1350, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [45][  100/  196]   Loss 0.145131   Top1 95.031250   Top5 99.949219   BatchTime 0.268983   LR 0.000084
0.56492478
tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>)
0.56503928
tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>)
0.56492245
tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>)
0.56465155
tensor(0.1585, device='cuda:0', grad_fn=<AddBackward0>)
0.56457096
tensor(0.1775, device='cuda:0', grad_fn=<AddBackward0>)
0.56456965
tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
0.56452829
tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
0.56444293
tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
0.56446439
tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>)
0.56462646
tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>)
0.56465274
tensor(0.1654, device='cuda:0', grad_fn=<AddBackward0>)
0.56470537
tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)
0.56487048
tensor(0.1278, device='cuda:0', grad_fn=<AddBackward0>)
0.56482589
tensor(0.1316, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [45][  120/  196]   Loss 0.145524   Top1 95.000000   Top5 99.941406   BatchTime 0.265821   LR 0.000084
0.56484044
tensor(0.1406, device='cuda:0', grad_fn=<AddBackward0>)
0.56486487
tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
0.56489551
tensor(0.1231, device='cuda:0', grad_fn=<AddBackward0>)
0.56482935
tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)
0.56504744
tensor(0.1521, device='cuda:0', grad_fn=<AddBackward0>)
0.56508267
tensor(0.0908, device='cuda:0', grad_fn=<AddBackward0>)
0.56500256
tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
0.56499088
tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
0.56483793
tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>)
0.56471664
tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)
0.56448990
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
0.56482440
tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>)
0.56461722
tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>)
0.56459373
tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)
0.56458110
tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
0.56446224
tensor(0.1442, device='cuda:0', grad_fn=<AddBackward0>)
0.56446344
tensor(0.1487, device='cuda:0', grad_fn=<AddBackward0>)
0.56449217
tensor(0.1189, device='cuda:0', grad_fn=<AddBackward0>)
0.56442767
tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
0.56437486
tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>)
0.56438035
tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)
0.56467140
tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>)
0.56476331
tensor(0.1127, device='cuda:0', grad_fn=<AddBackward0>)
0.56497878
tensor(0.2089, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [45][  140/  196]   Loss 0.147481   Top1 94.946987   Top5 99.944196   BatchTime 0.263703   LR 0.000083
0.56484872
tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>)
0.56470442
tensor(0.1401, device='cuda:0', grad_fn=<AddBackward0>)
0.56477141
tensor(0.1384, device='cuda:0', grad_fn=<AddBackward0>)
0.56483907
tensor(0.1055, device='cuda:0', grad_fn=<AddBackward0>)
0.56460851
tensor(0.1510, device='cuda:0', grad_fn=<AddBackward0>)
0.56449658
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
0.56462926
tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
0.56448716
tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>)
0.56451905
tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)
0.56462616
tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)
0.56472069
tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
0.56481606
tensor(0.1655, device='cuda:0', grad_fn=<AddBackward0>)
0.56472796
tensor(0.1106, device='cuda:0', grad_fn=<AddBackward0>)
0.56479490
tensor(0.1481, device='cuda:0', grad_fn=<AddBackward0>)
0.56481951
tensor(0.1423, device='cuda:0', grad_fn=<AddBackward0>)
0.56476134
tensor(0.1674, device='cuda:0', grad_fn=<AddBackward0>)
0.56474352
tensor(0.1411, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [45][  160/  196]   Loss 0.147531   Top1 94.992676   Top5 99.934082   BatchTime 0.261906   LR 0.000083
0.56454915
tensor(0.1088, device='cuda:0', grad_fn=<AddBackward0>)
0.56432188
tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>)
0.56430292
tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>)
0.56432295
tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>)
0.56443924
tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>)
0.56453949
tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
0.56443328
tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
0.56432039
tensor(0.1330, device='cuda:0', grad_fn=<AddBackward0>)
0.56431031
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
0.56441826
tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
0.56452817
tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>)
0.56462240
tensor(0.1814, device='cuda:0', grad_fn=<AddBackward0>)
0.56479818
tensor(0.1384, device='cuda:0', grad_fn=<AddBackward0>)
0.56454116
tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
0.56483740
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.56457555
tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>)
0.56438398
tensor(0.1345, device='cuda:0', grad_fn=<AddBackward0>)
0.56437010
tensor(0.1516, device='cuda:0', grad_fn=<AddBackward0>)
0.56421077
tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
0.56422573
tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
0.56422722
tensor(0.1665, device='cuda:0', grad_fn=<AddBackward0>)
0.56407523
tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
0.56414181
tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>)
0.56403452
tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [45][  180/  196]   Loss 0.148060   Top1 94.939236   Top5 99.937066   BatchTime 0.260485   LR 0.000082
0.56406659
tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
0.56405777
tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)
0.56398612
tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)
0.56399244
tensor(0.1642, device='cuda:0', grad_fn=<AddBackward0>)
0.56410730
tensor(0.1725, device='cuda:0', grad_fn=<AddBackward0>)
0.56429285
tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>)
0.56450212
tensor(0.1432, device='cuda:0', grad_fn=<AddBackward0>)
0.56452239
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.56452262
tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)
0.56441003
tensor(0.1374, device='cuda:0', grad_fn=<AddBackward0>)
0.56435251
tensor(0.1744, device='cuda:0', grad_fn=<AddBackward0>)
0.56450254
tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>)
0.56466210
tensor(0.1384, device='cuda:0', grad_fn=<AddBackward0>)
0.56476223
tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 94.964    Top5: 99.936    Loss: 0.149
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 0.394741   Top1 88.457031   Top5 99.550781   BatchTime 0.125187
INFO - Validation [45][   40/   40]   Loss 0.385088   Top1 88.390000   Top5 99.630000   BatchTime 0.090898
features.0.conv.0 tensor(0.2743)
features.0.conv.3 tensor(0.1602)
features.1.conv.0 tensor(0.0456)
features.1.conv.3 tensor(0.0637)
features.1.conv.6 tensor(0.0938)
features.2.conv.0 tensor(0.0998)
features.2.conv.3 tensor(0.3418)
features.2.conv.6 tensor(0.5211)
features.3.conv.0 tensor(0.0671)
features.3.conv.3 tensor(0.0764)
features.3.conv.6 tensor(0.1094)
features.4.conv.0 tensor(0.0677)
features.4.conv.3 tensor(0.2986)
features.4.conv.6 tensor(0.3641)
features.5.conv.0 tensor(0.3096)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4453)
features.6.conv.0 tensor(0.0540)
features.6.conv.3 tensor(0.0538)
features.6.conv.6 tensor(0.0803)
features.7.conv.0 tensor(0.2368)
features.7.conv.3 tensor(0.4459)
features.7.conv.6 tensor(0.6261)
features.8.conv.0 tensor(0.5442)
features.8.conv.3 tensor(0.5359)
features.8.conv.6 tensor(0.4880)
features.9.conv.0 tensor(0.4823)
features.9.conv.3 tensor(0.5648)
features.9.conv.6 tensor(0.7448)
features.10.conv.0 tensor(0.0562)
features.10.conv.3 tensor(0.0906)
features.10.conv.6 tensor(0.0675)
features.11.conv.0 tensor(0.7503)
features.11.conv.3 tensor(0.6431)
features.11.conv.6 tensor(0.8998)
features.12.conv.0 tensor(0.7172)
features.12.conv.3 tensor(0.6615)
features.12.conv.6 tensor(0.8611)
features.13.conv.0 tensor(0.2460)
features.13.conv.3 tensor(0.4848)
features.13.conv.6 tensor(0.4936)
features.14.conv.0 tensor(0.9082)
features.14.conv.3 tensor(0.8233)
features.14.conv.6 tensor(0.9553)
features.15.conv.0 tensor(0.8918)
features.15.conv.3 tensor(0.8269)
features.15.conv.6 tensor(0.9616)
features.16.conv.0 tensor(0.6801)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.8914)
conv.0 tensor(0.1227)
tensor(1367545.) 2188896.0
INFO - ==> Top1: 88.390    Top5: 99.630    Loss: 0.385
INFO - ==> Sparsity : 0.625
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
0.56473732
tensor(0.1016, device='cuda:0', grad_fn=<AddBackward0>)
0.56471050
tensor(0.1273, device='cuda:0', grad_fn=<AddBackward0>)
0.56461930
tensor(0.1225, device='cuda:0', grad_fn=<AddBackward0>)
0.56446379
tensor(0.1076, device='cuda:0', grad_fn=<AddBackward0>)
0.56448632
tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)
0.56450421
tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
0.56460977
tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)
0.56473184
tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
0.56459385
tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
0.56436807
tensor(0.1744, device='cuda:0', grad_fn=<AddBackward0>)
0.56428683
tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>)
0.56418878
tensor(0.1585, device='cuda:0', grad_fn=<AddBackward0>)
0.56408274
tensor(0.1570, device='cuda:0', grad_fn=<AddBackward0>)
0.56407928
tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>)
0.56408113
tensor(0.1384, device='cuda:0', grad_fn=<AddBackward0>)
0.56403983
tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>)
0.56404072
tensor(0.0708, device='cuda:0', grad_fn=<AddBackward0>)
0.56401038
tensor(0.1196, device='cuda:0', grad_fn=<AddBackward0>)
0.56401163
tensor(0.1087, device='cuda:0', grad_fn=<AddBackward0>)
0.56408715
tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>)
0.56415009
tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>)
0.56422269
tensor(0.0981, device='cuda:0', grad_fn=<AddBackward0>)
0.56431246
tensor(0.1027, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [46][   20/  196]   Loss 0.143625   Top1 95.292969   Top5 99.941406   BatchTime 0.314892   LR 0.000081
0.56449479
tensor(0.1376, device='cuda:0', grad_fn=<AddBackward0>)
0.56477243
tensor(0.1146, device='cuda:0', grad_fn=<AddBackward0>)
0.56500536
tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>)
0.56518137
tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
0.56573600
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
0.56583512
tensor(0.1425, device='cuda:0', grad_fn=<AddBackward0>)
0.56590092
tensor(0.1627, device='cuda:0', grad_fn=<AddBackward0>)
0.56586790
tensor(0.1184, device='cuda:0', grad_fn=<AddBackward0>)
0.56587750
tensor(0.1420, device='cuda:0', grad_fn=<AddBackward0>)
0.56578267
tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
0.56588417
tensor(0.1766, device='cuda:0', grad_fn=<AddBackward0>)
0.56561029
tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>)
0.56557131
tensor(0.1709, device='cuda:0', grad_fn=<AddBackward0>)
0.56568354
tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>)
0.56574893
tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
0.56569421
tensor(0.1723, device='cuda:0', grad_fn=<AddBackward0>)
0.56565458
tensor(0.1319, device='cuda:0', grad_fn=<AddBackward0>)
0.56561619
tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)
0.56567836
tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>)
0.56572944
tensor(0.1606, device='cuda:0', grad_fn=<AddBackward0>)
0.56581211
tensor(0.1155, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [46][   40/  196]   Loss 0.145589   Top1 95.146484   Top5 99.970703   BatchTime 0.297816   LR 0.000081
0.56596792
tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)
0.56611824
tensor(0.1149, device='cuda:0', grad_fn=<AddBackward0>)
0.56587625
tensor(0.1223, device='cuda:0', grad_fn=<AddBackward0>)
0.56590992
tensor(0.1685, device='cuda:0', grad_fn=<AddBackward0>)
0.56586605
tensor(0.1045, device='cuda:0', grad_fn=<AddBackward0>)
0.56581110
tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
0.56580704
tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)
0.56590474
tensor(0.1308, device='cuda:0', grad_fn=<AddBackward0>)
0.56595105
tensor(0.1319, device='cuda:0', grad_fn=<AddBackward0>)
0.56595296
tensor(0.1270, device='cuda:0', grad_fn=<AddBackward0>)
0.56607842
tensor(0.1536, device='cuda:0', grad_fn=<AddBackward0>)
0.56605154
tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
0.56611955
tensor(0.1308, device='cuda:0', grad_fn=<AddBackward0>)
0.56606483
tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>)
0.56589860
tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
0.56580275
tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [46][   60/  196]   Loss 0.144994   Top1 95.091146   Top5 99.973958   BatchTime 0.286315   LR 0.000080
0.56581771
tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)
0.56580901
tensor(0.1179, device='cuda:0', grad_fn=<AddBackward0>)
0.56581688
tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>)
0.56604642
tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>)
0.56625694
tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>)
0.56634390
tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>)
0.56608999
tensor(0.1386, device='cuda:0', grad_fn=<AddBackward0>)
0.56599784
tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>)
0.56587499
tensor(0.0989, device='cuda:0', grad_fn=<AddBackward0>)
0.56593472
tensor(0.1001, device='cuda:0', grad_fn=<AddBackward0>)
0.56612134
tensor(0.1381, device='cuda:0', grad_fn=<AddBackward0>)
0.56609601
tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>)
0.56585848
tensor(0.1464, device='cuda:0', grad_fn=<AddBackward0>)
0.56585062
tensor(0.1622, device='cuda:0', grad_fn=<AddBackward0>)
0.56605315
tensor(0.1529, device='cuda:0', grad_fn=<AddBackward0>)
0.56610352
tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
0.56588519
tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>)
0.56581521
tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
0.56588131
tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)
0.56594336
tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>)
0.56590235
tensor(0.1145, device='cuda:0', grad_fn=<AddBackward0>)
0.56569839
tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
0.56550956
tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>)
0.56553185
tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [46][   80/  196]   Loss 0.143705   Top1 95.112305   Top5 99.970703   BatchTime 0.277257   LR 0.000080
0.56563926
tensor(0.1032, device='cuda:0', grad_fn=<AddBackward0>)
0.56565166
tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>)
0.56572610
tensor(0.0896, device='cuda:0', grad_fn=<AddBackward0>)
0.56569135
tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>)
0.56572449
tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>)
0.56573766
tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
0.56574225
tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>)
0.56566596
tensor(0.1110, device='cuda:0', grad_fn=<AddBackward0>)
0.56584775
tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>)
0.56595796
tensor(0.1439, device='cuda:0', grad_fn=<AddBackward0>)
0.56590134
tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
0.56590891
tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>)
0.56570083
tensor(0.1187, device='cuda:0', grad_fn=<AddBackward0>)
0.56573600
tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>)
0.56578803
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.56598371
tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [46][  100/  196]   Loss 0.142586   Top1 95.167969   Top5 99.964844   BatchTime 0.271779   LR 0.000079
0.56619179
tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>)
0.56597835
tensor(0.1540, device='cuda:0', grad_fn=<AddBackward0>)
0.56620878
tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)
0.56635529
tensor(0.1600, device='cuda:0', grad_fn=<AddBackward0>)
0.56649548
tensor(0.1619, device='cuda:0', grad_fn=<AddBackward0>)
0.56648946
tensor(0.1881, device='cuda:0', grad_fn=<AddBackward0>)
0.56657636
tensor(0.1396, device='cuda:0', grad_fn=<AddBackward0>)
0.56678832
tensor(0.1307, device='cuda:0', grad_fn=<AddBackward0>)
0.56691194
tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
0.56667972
tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>)
0.56682140
tensor(0.1556, device='cuda:0', grad_fn=<AddBackward0>)
0.56668460
tensor(0.1396, device='cuda:0', grad_fn=<AddBackward0>)
0.56647670
tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>)
0.56629407
tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>)
0.56633592
tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
0.56622690
tensor(0.1017, device='cuda:0', grad_fn=<AddBackward0>)
0.56617671
tensor(0.1169, device='cuda:0', grad_fn=<AddBackward0>)
0.56626511
tensor(0.1366, device='cuda:0', grad_fn=<AddBackward0>)
0.56614876
tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>)
0.56603825
tensor(0.1571, device='cuda:0', grad_fn=<AddBackward0>)
0.56608474
tensor(0.1348, device='cuda:0', grad_fn=<AddBackward0>)
0.56605613
tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
0.56593782
tensor(0.1757, device='cuda:0', grad_fn=<AddBackward0>)
0.56577301
tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
0.56582487
tensor(0.1295, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [46][  120/  196]   Loss 0.143925   Top1 95.120443   Top5 99.960938   BatchTime 0.267665   LR 0.000079
0.56587529
tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>)
0.56603086
tensor(0.0895, device='cuda:0', grad_fn=<AddBackward0>)
0.56590158
tensor(0.1562, device='cuda:0', grad_fn=<AddBackward0>)
0.56598908
tensor(0.1670, device='cuda:0', grad_fn=<AddBackward0>)
0.56585199
tensor(0.1327, device='cuda:0', grad_fn=<AddBackward0>)
0.56587946
tensor(0.1510, device='cuda:0', grad_fn=<AddBackward0>)
0.56589794
tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
0.56574810
tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)
0.56572926
tensor(0.1555, device='cuda:0', grad_fn=<AddBackward0>)
0.56572342
tensor(0.1318, device='cuda:0', grad_fn=<AddBackward0>)
0.56567103
tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
0.56577736
tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>)
0.56569272
tensor(0.1234, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [46][  140/  196]   Loss 0.145264   Top1 95.044643   Top5 99.966518   BatchTime 0.269979   LR 0.000078
0.56565624
tensor(0.1602, device='cuda:0', grad_fn=<AddBackward0>)
0.56568933
tensor(0.1665, device='cuda:0', grad_fn=<AddBackward0>)
0.56602031
tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>)
0.56591082
tensor(0.1144, device='cuda:0', grad_fn=<AddBackward0>)
0.56592232
tensor(0.1681, device='cuda:0', grad_fn=<AddBackward0>)
0.56566280
tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>)
0.56581390
tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)
0.56563145
tensor(0.1292, device='cuda:0', grad_fn=<AddBackward0>)
0.56547493
tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>)
0.56536084
tensor(0.1755, device='cuda:0', grad_fn=<AddBackward0>)
0.56528372
tensor(0.1835, device='cuda:0', grad_fn=<AddBackward0>)
0.56534517
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.56554765
tensor(0.1415, device='cuda:0', grad_fn=<AddBackward0>)
0.56545365
tensor(0.1380, device='cuda:0', grad_fn=<AddBackward0>)
0.56538677
tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>)
0.56543779
tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>)
0.56535441
tensor(0.1637, device='cuda:0', grad_fn=<AddBackward0>)
0.56550598
tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>)
0.56581402
tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>)
0.56577706
tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>)
0.56551921
tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>)
0.56537968
tensor(0.1144, device='cuda:0', grad_fn=<AddBackward0>)
0.56547570
tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
0.56546146
tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
0.56529069
tensor(0.0976, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [46][  160/  196]   Loss 0.146455   Top1 95.002441   Top5 99.970703   BatchTime 0.275509   LR 0.000078
0.56522334
tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>)
0.56509978
tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>)
0.56528038
tensor(0.1591, device='cuda:0', grad_fn=<AddBackward0>)
0.56526458
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
0.56534606
tensor(0.1062, device='cuda:0', grad_fn=<AddBackward0>)
0.56533098
tensor(0.1342, device='cuda:0', grad_fn=<AddBackward0>)
0.56530821
tensor(0.1071, device='cuda:0', grad_fn=<AddBackward0>)
0.56544924
tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>)
0.56560463
tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>)
0.56549746
tensor(0.1282, device='cuda:0', grad_fn=<AddBackward0>)
0.56517613
tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)
0.56508911
tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
0.56508374
tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)
0.56502014
tensor(0.1618, device='cuda:0', grad_fn=<AddBackward0>)
0.56497437
tensor(0.1398, device='cuda:0', grad_fn=<AddBackward0>)
0.56489116
tensor(0.1502, device='cuda:0', grad_fn=<AddBackward0>)
0.56484538
tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>)
0.56485152
tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>)
0.56479883
tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
0.56472874
tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [46][  180/  196]   Loss 0.146947   Top1 94.989149   Top5 99.967448   BatchTime 0.278956   LR 0.000077
0.56478161
tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)
0.56482619
tensor(0.1591, device='cuda:0', grad_fn=<AddBackward0>)
0.56488138
tensor(0.1158, device='cuda:0', grad_fn=<AddBackward0>)
0.56499946
tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
0.56506020
tensor(0.1660, device='cuda:0', grad_fn=<AddBackward0>)
0.56505340
tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
0.56507277
tensor(0.1151, device='cuda:0', grad_fn=<AddBackward0>)
0.56521618
tensor(0.1759, device='cuda:0', grad_fn=<AddBackward0>)
0.56541872
tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
0.56554592
tensor(0.1344, device='cuda:0', grad_fn=<AddBackward0>)
0.56537986
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
0.56529856
tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
0.56514204
tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 94.950    Top5: 99.966    Loss: 0.148
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 0.395551   Top1 87.929688   Top5 99.609375   BatchTime 0.122306
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1504)
features.1.conv.0 tensor(0.0449)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0907)
features.2.conv.0 tensor(0.1059)
features.2.conv.3 tensor(0.3418)
features.2.conv.6 tensor(0.5231)
features.3.conv.0 tensor(0.0666)
features.3.conv.3 tensor(0.0748)
features.3.conv.6 tensor(0.1089)
features.4.conv.0 tensor(0.0728)
features.4.conv.3 tensor(0.2986)
features.4.conv.6 tensor(0.3654)
features.5.conv.0 tensor(0.3413)
features.5.conv.3 tensor(0.4155)
features.5.conv.6 tensor(0.4492)
features.6.conv.0 tensor(0.0508)
features.6.conv.3 tensor(0.0550)
features.6.conv.6 tensor(0.0824)
features.7.conv.0 tensor(0.2096)
features.7.conv.3 tensor(0.4494)
features.7.conv.6 tensor(0.6254)
features.8.conv.0 tensor(0.5369)
features.8.conv.3 tensor(0.5396)
features.8.conv.6 tensor(0.4880)
features.9.conv.0 tensor(0.4777)
features.9.conv.3 tensor(0.5631)
features.9.conv.6 tensor(0.7465)
features.10.conv.0 tensor(0.0579)
features.10.conv.3 tensor(0.0932)
features.10.conv.6 tensor(0.0666)
features.11.conv.0 tensor(0.7540)
features.11.conv.3 tensor(0.6437)
features.11.conv.6 tensor(0.9004)
features.12.conv.0 tensor(0.7170)
features.12.conv.3 tensor(0.6634)
features.12.conv.6 tensor(0.8637)
features.13.conv.0 tensor(0.2787)
features.13.conv.3 tensor(0.4844)
features.13.conv.6 tensor(0.4960)
features.14.conv.0 tensor(0.9083)
features.14.conv.3 tensor(0.8228)
features.14.conv.6 tensor(0.9553)
features.15.conv.0 tensor(0.8921)
features.15.conv.3 tensor(0.8269)
features.15.conv.6 tensor(0.9625)
features.16.conv.0 tensor(0.6797)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.8920)
conv.0 tensor(0.1217)
tensor(1369273.) 2188896.0
INFO - Validation [46][   40/   40]   Loss 0.382993   Top1 88.200000   Top5 99.670000   BatchTime 0.089858
INFO - ==> Top1: 88.200    Top5: 99.670    Loss: 0.383
INFO - ==> Sparsity : 0.626
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
0.56516099
tensor(0.1601, device='cuda:0', grad_fn=<AddBackward0>)
0.56521124
tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
0.56531513
tensor(0.1436, device='cuda:0', grad_fn=<AddBackward0>)
0.56537461
tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
0.56531405
tensor(0.1240, device='cuda:0', grad_fn=<AddBackward0>)
0.56528360
tensor(0.1169, device='cuda:0', grad_fn=<AddBackward0>)
0.56512350
tensor(0.0762, device='cuda:0', grad_fn=<AddBackward0>)
0.56507206
tensor(0.1121, device='cuda:0', grad_fn=<AddBackward0>)
0.56510991
tensor(0.0947, device='cuda:0', grad_fn=<AddBackward0>)
0.56500882
tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>)
0.56518209
tensor(0.1298, device='cuda:0', grad_fn=<AddBackward0>)
0.56518543
tensor(0.1316, device='cuda:0', grad_fn=<AddBackward0>)
0.56526238
tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>)
0.56513405
tensor(0.1189, device='cuda:0', grad_fn=<AddBackward0>)
0.56511647
tensor(0.0913, device='cuda:0', grad_fn=<AddBackward0>)
0.56529212
tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
0.56523579
tensor(0.1059, device='cuda:0', grad_fn=<AddBackward0>)
0.56530648
tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>)
0.56521821
tensor(0.1569, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [47][   20/  196]   Loss 0.130478   Top1 95.800781   Top5 99.941406   BatchTime 0.326292   LR 0.000077
0.56514895
tensor(0.1184, device='cuda:0', grad_fn=<AddBackward0>)
0.56519288
tensor(0.1069, device='cuda:0', grad_fn=<AddBackward0>)
0.56519532
tensor(0.1656, device='cuda:0', grad_fn=<AddBackward0>)
0.56525260
tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
0.56516612
tensor(0.1423, device='cuda:0', grad_fn=<AddBackward0>)
0.56518656
tensor(0.1401, device='cuda:0', grad_fn=<AddBackward0>)
0.56521338
tensor(0.1421, device='cuda:0', grad_fn=<AddBackward0>)
0.56522799
tensor(0.1273, device='cuda:0', grad_fn=<AddBackward0>)
0.56529605
tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>)
0.56535488
tensor(0.0992, device='cuda:0', grad_fn=<AddBackward0>)
0.56540787
tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>)
0.56520247
tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
0.56515461
tensor(0.1656, device='cuda:0', grad_fn=<AddBackward0>)
0.56515831
tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>)
0.56523877
tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>)
0.56524903
tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>)
0.56509030
tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)
0.56534547
tensor(0.1412, device='cuda:0', grad_fn=<AddBackward0>)
0.56520885
tensor(0.1585, device='cuda:0', grad_fn=<AddBackward0>)
0.56531578
tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
0.56520480
tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [47][   40/  196]   Loss 0.139009   Top1 95.507812   Top5 99.941406   BatchTime 0.302647   LR 0.000076
0.56517130
tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
0.56508863
tensor(0.1585, device='cuda:0', grad_fn=<AddBackward0>)
0.56489140
tensor(0.1685, device='cuda:0', grad_fn=<AddBackward0>)
0.56483459
tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
0.56498712
tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>)
0.56510806
tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)
0.56520212
tensor(0.1698, device='cuda:0', grad_fn=<AddBackward0>)
0.56521177
tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>)
0.56520802
tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)
0.56546563
tensor(0.1403, device='cuda:0', grad_fn=<AddBackward0>)
0.56547922
tensor(0.1318, device='cuda:0', grad_fn=<AddBackward0>)
0.56518632
tensor(0.1589, device='cuda:0', grad_fn=<AddBackward0>)
0.56499988
tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
0.56483865
tensor(0.1603, device='cuda:0', grad_fn=<AddBackward0>)
0.56474262
tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)
0.56481200
tensor(0.1261, device='cuda:0', grad_fn=<AddBackward0>)
0.56472588
tensor(0.1069, device='cuda:0', grad_fn=<AddBackward0>)
0.56475419
tensor(0.1315, device='cuda:0', grad_fn=<AddBackward0>)
0.56486219
tensor(0.1412, device='cuda:0', grad_fn=<AddBackward0>)
0.56502032
tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
0.56495190
tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)
0.56525278
tensor(0.1502, device='cuda:0', grad_fn=<AddBackward0>)
0.56506485
tensor(0.1676, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [47][   60/  196]   Loss 0.138082   Top1 95.345052   Top5 99.941406   BatchTime 0.293670   LR 0.000076
0.56504720
tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>)
0.56498224
tensor(0.1283, device='cuda:0', grad_fn=<AddBackward0>)
0.56499726
tensor(0.1077, device='cuda:0', grad_fn=<AddBackward0>)
0.56496519
tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>)
0.56469989
tensor(0.1337, device='cuda:0', grad_fn=<AddBackward0>)
0.56464309
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
0.56465781
tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>)
0.56475753
tensor(0.2008, device='cuda:0', grad_fn=<AddBackward0>)
0.56498069
tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>)
0.56502831
tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>)
0.56506181
tensor(0.1793, device='cuda:0', grad_fn=<AddBackward0>)
0.56512052
tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
0.56505531
tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
0.56485415
tensor(0.1299, device='cuda:0', grad_fn=<AddBackward0>)
0.56461412
tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
0.56458676
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [47][   80/  196]   Loss 0.140555   Top1 95.317383   Top5 99.931641   BatchTime 0.282248   LR 0.000075
0.56452799
tensor(0.1274, device='cuda:0', grad_fn=<AddBackward0>)
0.56458956
tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>)
0.56460840
tensor(0.1672, device='cuda:0', grad_fn=<AddBackward0>)
0.56477040
tensor(0.1145, device='cuda:0', grad_fn=<AddBackward0>)
0.56495196
tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)
0.56484562
tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
0.56490862
tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>)
0.56527340
tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>)
0.56531006
tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>)
0.56510955
tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)
0.56511629
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
0.56508160
tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
0.56483799
tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
0.56476122
tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
0.56484306
tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
0.56479359
tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
0.56470609
tensor(0.1513, device='cuda:0', grad_fn=<AddBackward0>)
0.56470436
tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>)
0.56474835
tensor(0.1576, device='cuda:0', grad_fn=<AddBackward0>)
0.56479132
tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
0.56479198
tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)
0.56475395
tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>)
0.56497788
tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>)
0.56506944
tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [47][  100/  196]   Loss 0.142827   Top1 95.242188   Top5 99.925781   BatchTime 0.275595   LR 0.000075
0.56491494
tensor(0.1698, device='cuda:0', grad_fn=<AddBackward0>)
0.56481880
tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>)
0.56457520
tensor(0.1238, device='cuda:0', grad_fn=<AddBackward0>)
0.56458551
tensor(0.1326, device='cuda:0', grad_fn=<AddBackward0>)
0.56457067
tensor(0.0954, device='cuda:0', grad_fn=<AddBackward0>)
0.56447089
tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>)
0.56439507
tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>)
0.56431538
tensor(0.1253, device='cuda:0', grad_fn=<AddBackward0>)
0.56427020
tensor(0.1341, device='cuda:0', grad_fn=<AddBackward0>)
0.56424767
tensor(0.1629, device='cuda:0', grad_fn=<AddBackward0>)
0.56418180
tensor(0.1206, device='cuda:0', grad_fn=<AddBackward0>)
0.56409389
tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>)
0.56409019
tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>)
0.56412226
tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)
0.56413221
tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)
0.56412160
tensor(0.1613, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [47][  120/  196]   Loss 0.142879   Top1 95.185547   Top5 99.931641   BatchTime 0.271698   LR 0.000074
0.56411070
tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
0.56413913
tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)
0.56422687
tensor(0.1442, device='cuda:0', grad_fn=<AddBackward0>)
0.56439650
tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
0.56457257
tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>)
0.56454426
tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
0.56461334
tensor(0.1711, device='cuda:0', grad_fn=<AddBackward0>)
0.56468952
tensor(0.1309, device='cuda:0', grad_fn=<AddBackward0>)
0.56452096
tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
0.56439221
tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
0.56422579
tensor(0.1442, device='cuda:0', grad_fn=<AddBackward0>)
0.56410503
tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
0.56403244
tensor(0.1057, device='cuda:0', grad_fn=<AddBackward0>)
0.56406653
tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>)
0.56412572
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.56426990
tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
0.56427956
tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
0.56439066
tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
0.56422728
tensor(0.1125, device='cuda:0', grad_fn=<AddBackward0>)
0.56423354
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.56416565
tensor(0.1627, device='cuda:0', grad_fn=<AddBackward0>)
0.56411850
tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>)
0.56404769
tensor(0.1527, device='cuda:0', grad_fn=<AddBackward0>)
0.56398571
tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [47][  140/  196]   Loss 0.141404   Top1 95.242746   Top5 99.935826   BatchTime 0.268584   LR 0.000074
0.56401253
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.56415063
tensor(0.1267, device='cuda:0', grad_fn=<AddBackward0>)
0.56415844
tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>)
0.56404698
tensor(0.1378, device='cuda:0', grad_fn=<AddBackward0>)
0.56423932
tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
0.56445479
tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
0.56464404
tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>)
0.56460840
tensor(0.1522, device='cuda:0', grad_fn=<AddBackward0>)
0.56455976
tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
0.56444079
tensor(0.1556, device='cuda:0', grad_fn=<AddBackward0>)
0.56427532
tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>)
0.56393409
tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
0.56389821
tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>)
0.56412369
tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>)
0.56398445
tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
0.56391704
tensor(0.1201, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [47][  160/  196]   Loss 0.141800   Top1 95.229492   Top5 99.929199   BatchTime 0.266200   LR 0.000073
0.56376159
tensor(0.1274, device='cuda:0', grad_fn=<AddBackward0>)
0.56372613
tensor(0.1017, device='cuda:0', grad_fn=<AddBackward0>)
0.56371433
tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
0.56368351
tensor(0.1480, device='cuda:0', grad_fn=<AddBackward0>)
0.56372118
tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>)
0.56382000
tensor(0.0717, device='cuda:0', grad_fn=<AddBackward0>)
0.56405866
tensor(0.0877, device='cuda:0', grad_fn=<AddBackward0>)
0.56402123
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.56387293
tensor(0.1337, device='cuda:0', grad_fn=<AddBackward0>)
0.56371242
tensor(0.1013, device='cuda:0', grad_fn=<AddBackward0>)
0.56363976
tensor(0.1372, device='cuda:0', grad_fn=<AddBackward0>)
0.56368822
tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
0.56372792
tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>)
0.56376398
tensor(0.2065, device='cuda:0', grad_fn=<AddBackward0>)
0.56390584
tensor(0.1125, device='cuda:0', grad_fn=<AddBackward0>)
0.56384861
tensor(0.1483, device='cuda:0', grad_fn=<AddBackward0>)
0.56382078
tensor(0.1100, device='cuda:0', grad_fn=<AddBackward0>)
0.56378895
tensor(0.1415, device='cuda:0', grad_fn=<AddBackward0>)
0.56379330
tensor(0.1101, device='cuda:0', grad_fn=<AddBackward0>)
0.56368357
tensor(0.1279, device='cuda:0', grad_fn=<AddBackward0>)
0.56365466
tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>)
0.56366068
tensor(0.1360, device='cuda:0', grad_fn=<AddBackward0>)
0.56374079
tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [47][  180/  196]   Loss 0.140626   Top1 95.284288   Top5 99.937066   BatchTime 0.265303   LR 0.000073
0.56374699
tensor(0.1702, device='cuda:0', grad_fn=<AddBackward0>)
0.56407851
tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>)
0.56407946
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.56402850
tensor(0.1466, device='cuda:0', grad_fn=<AddBackward0>)
0.56391448
tensor(0.1740, device='cuda:0', grad_fn=<AddBackward0>)
0.56374687
tensor(0.1048, device='cuda:0', grad_fn=<AddBackward0>)
0.56381428
tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
0.56378043
tensor(0.1751, device='cuda:0', grad_fn=<AddBackward0>)
0.56381774
tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
0.56374741
tensor(0.1516, device='cuda:0', grad_fn=<AddBackward0>)
0.56374741
tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>)
0.56363231
tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
0.56361973
tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>)
0.56365657
tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 95.256    Top5: 99.940    Loss: 0.142
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 0.399162   Top1 88.339844   Top5 99.628906   BatchTime 0.126106
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1582)
features.1.conv.0 tensor(0.0449)
features.1.conv.3 tensor(0.0694)
features.1.conv.6 tensor(0.0916)
features.2.conv.0 tensor(0.1126)
features.2.conv.3 tensor(0.3434)
features.2.conv.6 tensor(0.5269)
features.3.conv.0 tensor(0.0694)
features.3.conv.3 tensor(0.0733)
features.3.conv.6 tensor(0.1072)
features.4.conv.0 tensor(0.0848)
features.4.conv.3 tensor(0.2986)
features.4.conv.6 tensor(0.3667)
features.5.conv.0 tensor(0.3267)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4521)
features.6.conv.0 tensor(0.0493)
features.6.conv.3 tensor(0.0527)
features.6.conv.6 tensor(0.0820)
features.7.conv.0 tensor(0.2085)
features.7.conv.3 tensor(0.4473)
features.7.conv.6 tensor(0.6347)
features.8.conv.0 tensor(0.5321)
features.8.conv.3 tensor(0.5396)
features.8.conv.6 tensor(0.5179)
features.9.conv.0 tensor(0.4870)
features.9.conv.3 tensor(0.5654)
features.9.conv.6 tensor(0.7486)
features.10.conv.0 tensor(0.0600)
features.10.conv.3 tensor(0.0917)
features.10.conv.6 tensor(0.0661)
features.11.conv.0 tensor(0.7567)
features.11.conv.3 tensor(0.6437)
features.11.conv.6 tensor(0.9006)
features.12.conv.0 tensor(0.7177)
features.12.conv.3 tensor(0.6624)
features.12.conv.6 tensor(0.8624)
features.13.conv.0 tensor(0.2655)
features.13.conv.3 tensor(0.4848)
features.13.conv.6 tensor(0.4966)
features.14.conv.0 tensor(0.9091)
features.14.conv.3 tensor(0.8237)
features.14.conv.6 tensor(0.9561)
features.15.conv.0 tensor(0.8929)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9627)
features.16.conv.0 tensor(0.6827)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.8936)
conv.0 tensor(0.1362)
tensor(1377165.) 2188896.0
INFO - Validation [47][   40/   40]   Loss 0.384777   Top1 88.680000   Top5 99.700000   BatchTime 0.090246
INFO - ==> Top1: 88.680    Top5: 99.700    Loss: 0.385
INFO - ==> Sparsity : 0.629
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
0.56368691
tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
0.56365305
tensor(0.1701, device='cuda:0', grad_fn=<AddBackward0>)
0.56413573
tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)
0.56405312
tensor(0.1006, device='cuda:0', grad_fn=<AddBackward0>)
0.56381500
tensor(0.1412, device='cuda:0', grad_fn=<AddBackward0>)
0.56381989
tensor(0.1261, device='cuda:0', grad_fn=<AddBackward0>)
0.56385362
tensor(0.1668, device='cuda:0', grad_fn=<AddBackward0>)
0.56396604
tensor(0.1294, device='cuda:0', grad_fn=<AddBackward0>)
0.56391495
tensor(0.0949, device='cuda:0', grad_fn=<AddBackward0>)
0.56386179
tensor(0.1335, device='cuda:0', grad_fn=<AddBackward0>)
0.56401175
tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>)
0.56387448
tensor(0.0877, device='cuda:0', grad_fn=<AddBackward0>)
0.56362128
tensor(0.1121, device='cuda:0', grad_fn=<AddBackward0>)
0.56369156
tensor(0.1424, device='cuda:0', grad_fn=<AddBackward0>)
0.56370157
tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>)
0.56362295
tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
0.56375587
tensor(0.1150, device='cuda:0', grad_fn=<AddBackward0>)
0.56385279
tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
0.56385851
tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>)
0.56383508
tensor(0.1506, device='cuda:0', grad_fn=<AddBackward0>)
0.56375062
tensor(0.1613, device='cuda:0', grad_fn=<AddBackward0>)
0.56354243
tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [48][   20/  196]   Loss 0.127349   Top1 95.957031   Top5 99.941406   BatchTime 0.319465   LR 0.000072
0.56354707
tensor(0.1040, device='cuda:0', grad_fn=<AddBackward0>)
0.56370336
tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>)
0.56384426
tensor(0.1077, device='cuda:0', grad_fn=<AddBackward0>)
0.56358188
tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
0.56331819
tensor(0.1365, device='cuda:0', grad_fn=<AddBackward0>)
0.56325197
tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>)
0.56321824
tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>)
0.56321359
tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>)
0.56326318
tensor(0.1429, device='cuda:0', grad_fn=<AddBackward0>)
0.56343228
tensor(0.1704, device='cuda:0', grad_fn=<AddBackward0>)
0.56329668
tensor(0.1549, device='cuda:0', grad_fn=<AddBackward0>)
0.56332666
tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
0.56337202
tensor(0.1818, device='cuda:0', grad_fn=<AddBackward0>)
0.56332928
tensor(0.1433, device='cuda:0', grad_fn=<AddBackward0>)
0.56332928
tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>)
0.56329715
tensor(0.1286, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [48][   40/  196]   Loss 0.127027   Top1 95.791016   Top5 99.941406   BatchTime 0.285261   LR 0.000071
0.56322646
tensor(0.1491, device='cuda:0', grad_fn=<AddBackward0>)
0.56335568
tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>)
0.56341588
tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)
0.56348896
tensor(0.1263, device='cuda:0', grad_fn=<AddBackward0>)
0.56364965
tensor(0.0949, device='cuda:0', grad_fn=<AddBackward0>)
0.56370622
tensor(0.1191, device='cuda:0', grad_fn=<AddBackward0>)
0.56378078
tensor(0.1591, device='cuda:0', grad_fn=<AddBackward0>)
0.56381083
tensor(0.1650, device='cuda:0', grad_fn=<AddBackward0>)
0.56345862
tensor(0.1556, device='cuda:0', grad_fn=<AddBackward0>)
0.56335056
tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
0.56342000
tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>)
0.56353682
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
0.56353444
tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
0.56356674
tensor(0.1194, device='cuda:0', grad_fn=<AddBackward0>)
0.56358296
tensor(0.0717, device='cuda:0', grad_fn=<AddBackward0>)
0.56357890
tensor(0.1106, device='cuda:0', grad_fn=<AddBackward0>)
0.56353527
tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)
0.56350923
tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>)
0.56353235
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.56343049
tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>)
0.56332183
tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
0.56326485
tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>)
0.56329685
tensor(0.1216, device='cuda:0', grad_fn=<AddBackward0>)
0.56329918
tensor(0.1130, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [48][   60/  196]   Loss 0.129006   Top1 95.774740   Top5 99.941406   BatchTime 0.274556   LR 0.000071
0.56300277
tensor(0.1204, device='cuda:0', grad_fn=<AddBackward0>)
0.56294018
tensor(0.1822, device='cuda:0', grad_fn=<AddBackward0>)
0.56306332
tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>)
0.56312817
tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>)
0.56308991
tensor(0.1380, device='cuda:0', grad_fn=<AddBackward0>)
0.56309813
tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>)
0.56326419
tensor(0.1206, device='cuda:0', grad_fn=<AddBackward0>)
0.56314063
tensor(0.1105, device='cuda:0', grad_fn=<AddBackward0>)
0.56300467
tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
0.56299740
tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>)
0.56306088
tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
0.56305701
tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
0.56298953
tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>)
0.56292105
tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
0.56297076
tensor(0.1528, device='cuda:0', grad_fn=<AddBackward0>)
0.56299782
tensor(0.1204, device='cuda:0', grad_fn=<AddBackward0>)
0.56305504
tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>)
0.56281924
tensor(0.1435, device='cuda:0', grad_fn=<AddBackward0>)
0.56293386
tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>)
0.56306493
tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
0.56302285
tensor(0.1697, device='cuda:0', grad_fn=<AddBackward0>)
0.56291294
tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
0.56285250
tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)
0.56276959
tensor(0.1208, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [48][   80/  196]   Loss 0.129701   Top1 95.678711   Top5 99.946289   BatchTime 0.269474   LR 0.000070
0.56264853
tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
0.56259167
tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>)
0.56265348
tensor(0.1184, device='cuda:0', grad_fn=<AddBackward0>)
0.56260180
tensor(0.1116, device='cuda:0', grad_fn=<AddBackward0>)
0.56267852
tensor(0.1472, device='cuda:0', grad_fn=<AddBackward0>)
0.56262606
tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
0.56262642
tensor(0.1769, device='cuda:0', grad_fn=<AddBackward0>)
0.56271380
tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>)
0.56275463
tensor(0.1217, device='cuda:0', grad_fn=<AddBackward0>)
0.56277817
tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
0.56283391
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.56285554
tensor(0.1429, device='cuda:0', grad_fn=<AddBackward0>)
0.56275803
tensor(0.0993, device='cuda:0', grad_fn=<AddBackward0>)
0.56263930
tensor(0.1088, device='cuda:0', grad_fn=<AddBackward0>)
0.56253850
tensor(0.1354, device='cuda:0', grad_fn=<AddBackward0>)
0.56258810
tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
0.56266540
tensor(0.1027, device='cuda:0', grad_fn=<AddBackward0>)
0.56255585
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
0.56249148
tensor(0.1815, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [48][  100/  196]   Loss 0.130686   Top1 95.664062   Top5 99.953125   BatchTime 0.274872   LR 0.000070
0.56289357
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
0.56291920
tensor(0.1005, device='cuda:0', grad_fn=<AddBackward0>)
0.56296611
tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
0.56298304
tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
0.56268257
tensor(0.1413, device='cuda:0', grad_fn=<AddBackward0>)
0.56252795
tensor(0.1079, device='cuda:0', grad_fn=<AddBackward0>)
0.56260699
tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
0.56281650
tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
0.56273168
tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>)
0.56268078
tensor(0.1751, device='cuda:0', grad_fn=<AddBackward0>)
0.56279111
tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>)
0.56257868
tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)
0.56241113
tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>)
0.56230617
tensor(0.1179, device='cuda:0', grad_fn=<AddBackward0>)
0.56233954
tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>)
0.56238323
tensor(0.1148, device='cuda:0', grad_fn=<AddBackward0>)
0.56244111
tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [48][  120/  196]   Loss 0.132312   Top1 95.589193   Top5 99.954427   BatchTime 0.285085   LR 0.000069
0.56253040
tensor(0.1386, device='cuda:0', grad_fn=<AddBackward0>)
0.56257361
tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
0.56248999
tensor(0.1639, device='cuda:0', grad_fn=<AddBackward0>)
0.56234723
tensor(0.1497, device='cuda:0', grad_fn=<AddBackward0>)
0.56237710
tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)
0.56237656
tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
0.56231046
tensor(0.1277, device='cuda:0', grad_fn=<AddBackward0>)
0.56225002
tensor(0.1067, device='cuda:0', grad_fn=<AddBackward0>)
0.56218404
tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>)
0.56217498
tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>)
0.56224883
tensor(0.1271, device='cuda:0', grad_fn=<AddBackward0>)
0.56218809
tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
0.56218272
tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)
0.56225783
tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>)
0.56235552
tensor(0.1357, device='cuda:0', grad_fn=<AddBackward0>)
0.56222755
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.56209296
tensor(0.1477, device='cuda:0', grad_fn=<AddBackward0>)
0.56209725
tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>)
0.56214100
tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [48][  140/  196]   Loss 0.132243   Top1 95.625000   Top5 99.955357   BatchTime 0.291931   LR 0.000069
0.56231743
tensor(0.1253, device='cuda:0', grad_fn=<AddBackward0>)
0.56268603
tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>)
0.56234372
tensor(0.1228, device='cuda:0', grad_fn=<AddBackward0>)
0.56246454
tensor(0.1286, device='cuda:0', grad_fn=<AddBackward0>)
0.56240034
tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>)
0.56230545
tensor(0.1752, device='cuda:0', grad_fn=<AddBackward0>)
0.56219089
tensor(0.1218, device='cuda:0', grad_fn=<AddBackward0>)
0.56210202
tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
0.56211472
tensor(0.1148, device='cuda:0', grad_fn=<AddBackward0>)
0.56213838
tensor(0.1594, device='cuda:0', grad_fn=<AddBackward0>)
0.56234497
tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
0.56242520
tensor(0.0983, device='cuda:0', grad_fn=<AddBackward0>)
0.56262040
tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>)
0.56247687
tensor(0.1510, device='cuda:0', grad_fn=<AddBackward0>)
0.56236428
tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
0.56221884
tensor(0.1528, device='cuda:0', grad_fn=<AddBackward0>)
0.56215376
tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
0.56209886
tensor(0.1359, device='cuda:0', grad_fn=<AddBackward0>)
0.56204432
tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>)
0.56207466
tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [48][  160/  196]   Loss 0.132738   Top1 95.620117   Top5 99.956055   BatchTime 0.292230   LR 0.000068
0.56197482
tensor(0.1229, device='cuda:0', grad_fn=<AddBackward0>)
0.56185454
tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)
0.56190336
tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
0.56192482
tensor(0.1096, device='cuda:0', grad_fn=<AddBackward0>)
0.56181568
tensor(0.1293, device='cuda:0', grad_fn=<AddBackward0>)
0.56169277
tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)
0.56158990
tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>)
0.56154680
tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)
0.56150454
tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)
0.56090087
tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>)
0.56093854
tensor(0.1571, device='cuda:0', grad_fn=<AddBackward0>)
0.56091678
tensor(0.0728, device='cuda:0', grad_fn=<AddBackward0>)
0.56092811
tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>)
0.56108862
tensor(0.1048, device='cuda:0', grad_fn=<AddBackward0>)
0.56106305
tensor(0.1230, device='cuda:0', grad_fn=<AddBackward0>)
0.56093484
tensor(0.1482, device='cuda:0', grad_fn=<AddBackward0>)
0.56071490
tensor(0.1376, device='cuda:0', grad_fn=<AddBackward0>)
0.56053257
tensor(0.1062, device='cuda:0', grad_fn=<AddBackward0>)
0.56062543
tensor(0.1673, device='cuda:0', grad_fn=<AddBackward0>)
0.56064755
tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>)
0.56077296
tensor(0.1587, device='cuda:0', grad_fn=<AddBackward0>)
0.56057513
tensor(0.1809, device='cuda:0', grad_fn=<AddBackward0>)
0.56056178
tensor(0.1549, device='cuda:0', grad_fn=<AddBackward0>)
0.56038755
tensor(0.1346, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [48][  180/  196]   Loss 0.132549   Top1 95.625000   Top5 99.956597   BatchTime 0.288530   LR 0.000068
0.56032419
tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>)
0.56031686
tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>)
0.56029958
tensor(0.1309, device='cuda:0', grad_fn=<AddBackward0>)
0.56028467
tensor(0.1480, device='cuda:0', grad_fn=<AddBackward0>)
0.56046575
tensor(0.1130, device='cuda:0', grad_fn=<AddBackward0>)
0.56043679
tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>)
0.56037760
tensor(0.1335, device='cuda:0', grad_fn=<AddBackward0>)
0.56031322
tensor(0.1412, device='cuda:0', grad_fn=<AddBackward0>)
0.56041127
tensor(0.1623, device='cuda:0', grad_fn=<AddBackward0>)
0.56066918
tensor(0.1650, device='cuda:0', grad_fn=<AddBackward0>)
0.56046200
tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 95.610    Top5: 99.956    Loss: 0.133
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 0.389645   Top1 88.554688   Top5 99.609375   BatchTime 0.130538
features.0.conv.0 tensor(0.2743)
features.0.conv.3 tensor(0.1523)
features.1.conv.0 tensor(0.0475)
features.1.conv.3 tensor(0.0718)
features.1.conv.6 tensor(0.0903)
features.2.conv.0 tensor(0.1149)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.5284)
features.3.conv.0 tensor(0.0709)
features.3.conv.3 tensor(0.0718)
features.3.conv.6 tensor(0.1066)
features.4.conv.0 tensor(0.0817)
features.4.conv.3 tensor(0.3027)
features.4.conv.6 tensor(0.3724)
features.5.conv.0 tensor(0.3273)
features.5.conv.3 tensor(0.4155)
features.5.conv.6 tensor(0.4554)
features.6.conv.0 tensor(0.0493)
features.6.conv.3 tensor(0.0515)
features.6.conv.6 tensor(0.0819)
features.7.conv.0 tensor(0.2170)
features.7.conv.3 tensor(0.4468)
features.7.conv.6 tensor(0.6341)
features.8.conv.0 tensor(0.5349)
features.8.conv.3 tensor(0.5394)
features.8.conv.6 tensor(0.5449)
features.9.conv.0 tensor(0.4895)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.7498)
features.10.conv.0 tensor(0.0581)
features.10.conv.3 tensor(0.0940)
features.10.conv.6 tensor(0.0669)
features.11.conv.0 tensor(0.7615)
features.11.conv.3 tensor(0.6437)
features.11.conv.6 tensor(0.9003)
features.12.conv.0 tensor(0.7187)
features.12.conv.3 tensor(0.6624)
features.12.conv.6 tensor(0.8631)
features.13.conv.0 tensor(0.2721)
features.13.conv.3 tensor(0.4850)
features.13.conv.6 tensor(0.4998)
features.14.conv.0 tensor(0.9098)
features.14.conv.3 tensor(0.8244)
features.14.conv.6 tensor(0.9562)
features.15.conv.0 tensor(0.8936)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9627)
features.16.conv.0 tensor(0.6896)
features.16.conv.3 tensor(0.7885)
features.16.conv.6 tensor(0.8946)
conv.0 tensor(0.1422)
tensor(1383313.) 2188896.0
INFO - Validation [48][   40/   40]   Loss 0.376505   Top1 88.830000   Top5 99.670000   BatchTime 0.092141
INFO - ==> Top1: 88.830    Top5: 99.670    Loss: 0.377
INFO - ==> Sparsity : 0.632
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 88.960   Top5: 99.720]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 88.960   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
0.56051487
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.56037444
tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)
0.56036288
tensor(0.0980, device='cuda:0', grad_fn=<AddBackward0>)
0.56017643
tensor(0.0822, device='cuda:0', grad_fn=<AddBackward0>)
0.56013507
tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
0.56010884
tensor(0.1216, device='cuda:0', grad_fn=<AddBackward0>)
0.56005341
tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
0.55997962
tensor(0.1161, device='cuda:0', grad_fn=<AddBackward0>)
0.55986023
tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>)
0.55982554
tensor(0.1538, device='cuda:0', grad_fn=<AddBackward0>)
0.55983597
tensor(0.1425, device='cuda:0', grad_fn=<AddBackward0>)
0.55986178
tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>)
0.55984610
tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>)
0.55991435
tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
0.55993325
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
0.55992782
tensor(0.1594, device='cuda:0', grad_fn=<AddBackward0>)
0.55997211
tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>)
0.56021118
tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>)
0.56001359
tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
0.56012428
tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>)
0.56015074
tensor(0.1652, device='cuda:0', grad_fn=<AddBackward0>)
0.56009692
tensor(0.1020, device='cuda:0', grad_fn=<AddBackward0>)
0.56008852
tensor(0.1043, device='cuda:0', grad_fn=<AddBackward0>)
0.56015068
tensor(0.1309, device='cuda:0', grad_fn=<AddBackward0>)
0.55990869
tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [49][   20/  196]   Loss 0.118697   Top1 96.093750   Top5 100.000000   BatchTime 0.299731   LR 0.000067
0.55988258
tensor(0.0873, device='cuda:0', grad_fn=<AddBackward0>)
0.55998147
tensor(0.1401, device='cuda:0', grad_fn=<AddBackward0>)
0.55990267
tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>)
0.55977780
tensor(0.1380, device='cuda:0', grad_fn=<AddBackward0>)
0.55970025
tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>)
0.55987459
tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>)
0.55969596
tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>)
0.55960518
tensor(0.1502, device='cuda:0', grad_fn=<AddBackward0>)
0.55954415
tensor(0.1476, device='cuda:0', grad_fn=<AddBackward0>)
0.55953205
tensor(0.1189, device='cuda:0', grad_fn=<AddBackward0>)
0.55952698
tensor(0.0969, device='cuda:0', grad_fn=<AddBackward0>)
0.55950099
tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
0.55956954
tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
0.55963010
tensor(0.1269, device='cuda:0', grad_fn=<AddBackward0>)
0.55953890
tensor(0.1245, device='cuda:0', grad_fn=<AddBackward0>)
0.55969727
tensor(0.1394, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [49][   40/  196]   Loss 0.120310   Top1 96.074219   Top5 99.980469   BatchTime 0.272449   LR 0.000066
0.55975395
tensor(0.1651, device='cuda:0', grad_fn=<AddBackward0>)
0.55973691
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.55970955
tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
0.55971128
tensor(0.1251, device='cuda:0', grad_fn=<AddBackward0>)
0.55970055
tensor(0.1335, device='cuda:0', grad_fn=<AddBackward0>)
0.55955720
tensor(0.1359, device='cuda:0', grad_fn=<AddBackward0>)
0.55951780
tensor(0.1271, device='cuda:0', grad_fn=<AddBackward0>)
0.55949658
tensor(0.1205, device='cuda:0', grad_fn=<AddBackward0>)
0.55935854
tensor(0.1061, device='cuda:0', grad_fn=<AddBackward0>)
0.55926144
tensor(0.1160, device='cuda:0', grad_fn=<AddBackward0>)
0.55921733
tensor(0.1693, device='cuda:0', grad_fn=<AddBackward0>)
0.55919129
tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
0.55928856
tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>)
0.55936903
tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>)
0.55919892
tensor(0.1321, device='cuda:0', grad_fn=<AddBackward0>)
0.55929106
tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>)
0.55946714
tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
0.55937678
tensor(0.1523, device='cuda:0', grad_fn=<AddBackward0>)
0.55942613
tensor(0.1702, device='cuda:0', grad_fn=<AddBackward0>)
0.55952710
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
0.55961472
tensor(0.1118, device='cuda:0', grad_fn=<AddBackward0>)
0.55949515
tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>)
0.55944687
tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
0.55949003
tensor(0.1443, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [49][   60/  196]   Loss 0.123569   Top1 95.898438   Top5 99.967448   BatchTime 0.263775   LR 0.000066
0.55961227
tensor(0.1132, device='cuda:0', grad_fn=<AddBackward0>)
0.55969769
tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
0.55970848
tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
0.55986542
tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)
0.55979562
tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>)
0.55982769
tensor(0.1234, device='cuda:0', grad_fn=<AddBackward0>)
0.55961812
tensor(0.1312, device='cuda:0', grad_fn=<AddBackward0>)
0.55952966
tensor(0.1736, device='cuda:0', grad_fn=<AddBackward0>)
0.55944914
tensor(0.1258, device='cuda:0', grad_fn=<AddBackward0>)
0.55942374
tensor(0.1460, device='cuda:0', grad_fn=<AddBackward0>)
0.55941921
tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>)
0.55934846
tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
0.55928469
tensor(0.0843, device='cuda:0', grad_fn=<AddBackward0>)
0.55932003
tensor(0.1383, device='cuda:0', grad_fn=<AddBackward0>)
0.55917990
tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>)
0.55910599
tensor(0.1004, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [49][   80/  196]   Loss 0.124650   Top1 95.874023   Top5 99.965820   BatchTime 0.260470   LR 0.000065
0.55917495
tensor(0.1022, device='cuda:0', grad_fn=<AddBackward0>)
0.55920690
tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>)
0.55925715
tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>)
0.55943799
tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
0.55939215
tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
0.55936879
tensor(0.1496, device='cuda:0', grad_fn=<AddBackward0>)
0.55936331
tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>)
0.55950439
tensor(0.0986, device='cuda:0', grad_fn=<AddBackward0>)
0.55948102
tensor(0.0993, device='cuda:0', grad_fn=<AddBackward0>)
0.55925107
tensor(0.0867, device='cuda:0', grad_fn=<AddBackward0>)
0.55918109
tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>)
0.55910629
tensor(0.1552, device='cuda:0', grad_fn=<AddBackward0>)
0.55910093
tensor(0.1032, device='cuda:0', grad_fn=<AddBackward0>)
0.55914432
tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>)
0.55907959
tensor(0.1519, device='cuda:0', grad_fn=<AddBackward0>)
0.55919695
tensor(0.1269, device='cuda:0', grad_fn=<AddBackward0>)
0.55901664
tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>)
0.55893439
tensor(0.1663, device='cuda:0', grad_fn=<AddBackward0>)
0.55898017
tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
0.55899489
tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
0.55916017
tensor(0.1110, device='cuda:0', grad_fn=<AddBackward0>)
0.55916089
tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
0.55907023
tensor(0.0964, device='cuda:0', grad_fn=<AddBackward0>)
0.55894786
tensor(0.1086, device='cuda:0', grad_fn=<AddBackward0>)
0.55889565
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [49][  100/  196]   Loss 0.124400   Top1 95.859375   Top5 99.972656   BatchTime 0.258237   LR 0.000065
0.55889457
tensor(0.1220, device='cuda:0', grad_fn=<AddBackward0>)
0.55880558
tensor(0.1214, device='cuda:0', grad_fn=<AddBackward0>)
0.55875421
tensor(0.1016, device='cuda:0', grad_fn=<AddBackward0>)
0.55878097
tensor(0.0833, device='cuda:0', grad_fn=<AddBackward0>)
0.55870140
tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>)
0.55866009
tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
0.55860478
tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
0.55866468
tensor(0.1392, device='cuda:0', grad_fn=<AddBackward0>)
0.55875188
tensor(0.1560, device='cuda:0', grad_fn=<AddBackward0>)
0.55875534
tensor(0.1555, device='cuda:0', grad_fn=<AddBackward0>)
0.55864239
tensor(0.1335, device='cuda:0', grad_fn=<AddBackward0>)
0.55858326
tensor(0.1770, device='cuda:0', grad_fn=<AddBackward0>)
0.55847114
tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
0.55842566
tensor(0.1521, device='cuda:0', grad_fn=<AddBackward0>)
0.55839831
tensor(0.1186, device='cuda:0', grad_fn=<AddBackward0>)
0.55834514
tensor(0.1570, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [49][  120/  196]   Loss 0.123993   Top1 95.865885   Top5 99.970703   BatchTime 0.256785   LR 0.000064
0.55829436
tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)
0.55826408
tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
0.55830389
tensor(0.1024, device='cuda:0', grad_fn=<AddBackward0>)
0.55840564
tensor(0.1170, device='cuda:0', grad_fn=<AddBackward0>)
0.55842268
tensor(0.1227, device='cuda:0', grad_fn=<AddBackward0>)
0.55840582
tensor(0.1181, device='cuda:0', grad_fn=<AddBackward0>)
0.55830634
tensor(0.0926, device='cuda:0', grad_fn=<AddBackward0>)
0.55829293
tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>)
0.55822778
tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>)
0.55811167
tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>)
0.55805534
tensor(0.1131, device='cuda:0', grad_fn=<AddBackward0>)
0.55805993
tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
0.55812079
tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)
0.55821115
tensor(0.1193, device='cuda:0', grad_fn=<AddBackward0>)
0.55830508
tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
0.55840534
tensor(0.0957, device='cuda:0', grad_fn=<AddBackward0>)
0.55868495
tensor(0.1482, device='cuda:0', grad_fn=<AddBackward0>)
0.55851620
tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
0.55856127
tensor(0.1017, device='cuda:0', grad_fn=<AddBackward0>)
0.55863404
tensor(0.1169, device='cuda:0', grad_fn=<AddBackward0>)
0.55842936
tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
0.55849671
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.55831641
tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>)
0.55832189
tensor(0.1321, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [49][  140/  196]   Loss 0.124247   Top1 95.873326   Top5 99.972098   BatchTime 0.256017   LR 0.000064
0.55840325
tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>)
0.55836093
tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>)
0.55847394
tensor(0.1329, device='cuda:0', grad_fn=<AddBackward0>)
0.55854529
tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
0.55853891
tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>)
0.55840850
tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)
0.55836803
tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>)
0.55836159
tensor(0.1386, device='cuda:0', grad_fn=<AddBackward0>)
0.55847234
tensor(0.1415, device='cuda:0', grad_fn=<AddBackward0>)
0.55845720
tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
0.55841422
tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
0.55840886
tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
0.55838019
tensor(0.1814, device='cuda:0', grad_fn=<AddBackward0>)
0.55829901
tensor(0.1550, device='cuda:0', grad_fn=<AddBackward0>)
0.55836743
tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>)
0.55858928
tensor(0.1532, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [49][  160/  196]   Loss 0.126195   Top1 95.793457   Top5 99.965820   BatchTime 0.255198   LR 0.000063
0.55842781
tensor(0.1346, device='cuda:0', grad_fn=<AddBackward0>)
0.55825788
tensor(0.1044, device='cuda:0', grad_fn=<AddBackward0>)
0.55813444
tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>)
0.55803782
tensor(0.1204, device='cuda:0', grad_fn=<AddBackward0>)
0.55797106
tensor(0.1096, device='cuda:0', grad_fn=<AddBackward0>)
0.55790585
tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
0.55796432
tensor(0.1094, device='cuda:0', grad_fn=<AddBackward0>)
0.55798334
tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
0.55800563
tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>)
0.55814862
tensor(0.1737, device='cuda:0', grad_fn=<AddBackward0>)
0.55826116
tensor(0.1263, device='cuda:0', grad_fn=<AddBackward0>)
0.55834037
tensor(0.1190, device='cuda:0', grad_fn=<AddBackward0>)
0.55822128
tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
0.55812949
tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)
0.55807650
tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>)
0.55799508
tensor(0.1592, device='cuda:0', grad_fn=<AddBackward0>)
0.55803740
tensor(0.1466, device='cuda:0', grad_fn=<AddBackward0>)
0.55798692
tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
0.55797511
tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
0.55798918
tensor(0.1462, device='cuda:0', grad_fn=<AddBackward0>)
0.55788803
tensor(0.1207, device='cuda:0', grad_fn=<AddBackward0>)
0.55789143
tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)
0.55786031
tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>)
0.55799037
tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [49][  180/  196]   Loss 0.127495   Top1 95.740017   Top5 99.965278   BatchTime 0.254615   LR 0.000063
0.55806977
tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>)
0.55826032
tensor(0.1148, device='cuda:0', grad_fn=<AddBackward0>)
0.55849624
tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)
0.55857903
tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>)
0.55849051
tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>)
0.55824989
tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>)
0.55808014
tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
0.55807102
tensor(0.1327, device='cuda:0', grad_fn=<AddBackward0>)
0.55811995
tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>)
0.55811673
tensor(0.4656, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 95.708    Top5: 99.964    Loss: 0.129
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1562)
features.1.conv.0 tensor(0.0501)
features.1.conv.3 tensor(0.0729)
features.1.conv.6 tensor(0.0881)
features.2.conv.0 tensor(0.1126)
features.2.conv.3 tensor(0.3403)
features.2.conv.6 tensor(0.5286)
features.3.conv.0 tensor(0.0686)
features.3.conv.3 tensor(0.0725)
features.3.conv.6 tensor(0.1087)
features.4.conv.0 tensor(0.0788)
features.4.conv.3 tensor(0.3015)
features.4.conv.6 tensor(0.3822)
features.5.conv.0 tensor(0.3221)
features.5.conv.3 tensor(0.4161)
features.5.conv.6 tensor(0.4606)
features.6.conv.0 tensor(0.0519)
features.6.conv.3 tensor(0.0503)
features.6.conv.6 tensor(0.0843)
features.7.conv.0 tensor(0.2918)
features.7.conv.3 tensor(0.4462)
features.7.conv.6 tensor(0.6295)
features.8.conv.0 tensor(0.5522)
features.8.conv.3
INFO - Validation [49][   20/   40]   Loss 0.391274   Top1 89.121094   Top5 99.628906   BatchTime 0.127421
INFO - Validation [49][   40/   40]   Loss 0.380267   Top1 88.970000   Top5 99.690000   BatchTime 0.086945
INFO - ==> Top1: 88.970    Top5: 99.690    Loss: 0.380
INFO - ==> Sparsity : 0.634
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 88.970   Top5: 99.690]
features.8.conv.3 tensor(0.5376)
features.8.conv.6 tensor(0.5547)
features.9.conv.0 tensor(0.5000)
features.9.conv.3 tensor(0.5639)
features.9.conv.6 tensor(0.7493)
features.10.conv.0 tensor(0.0587)
features.10.conv.3 tensor(0.0949)
features.10.conv.6 tensor(0.0662)
features.11.conv.0 tensor(0.7648)
features.11.conv.3 tensor(0.6429)
features.11.conv.6 tensor(0.9000)
features.12.conv.0 tensor(0.7195)
features.12.conv.3 tensor(0.6630)
features.12.conv.6 tensor(0.8631)
features.13.conv.0 tensor(0.2750)
features.13.conv.3 tensor(0.4850)
features.13.conv.6 tensor(0.5025)
features.14.conv.0 tensor(0.9100)
features.14.conv.3 tensor(0.8231)
features.14.conv.6 tensor(0.9560)
features.15.conv.0 tensor(0.8956)
features.15.conv.3 tensor(0.8277)
features.15.conv.6 tensor(0.9628)
features.16.conv.0 tensor(0.6858)
features.16.conv.3 tensor(0.7890)
features.16.conv.6 tensor(0.8949)
conv.0 tensor(0.1458)
tensor(1387928.) 2188896.0
0.55815345
tensor(0.0991, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
0.55799687
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.55786991
tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
0.55777824
tensor(0.1220, device='cuda:0', grad_fn=<AddBackward0>)
0.55775005
tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
0.55781060
tensor(0.1067, device='cuda:0', grad_fn=<AddBackward0>)
0.55775130
tensor(0.0987, device='cuda:0', grad_fn=<AddBackward0>)
0.55785125
tensor(0.1099, device='cuda:0', grad_fn=<AddBackward0>)
0.55773902
tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>)
0.55784631
tensor(0.1528, device='cuda:0', grad_fn=<AddBackward0>)
0.55793267
tensor(0.1409, device='cuda:0', grad_fn=<AddBackward0>)
0.55790102
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.55801964
tensor(0.1607, device='cuda:0', grad_fn=<AddBackward0>)
0.55801702
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.55799228
tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
0.55799931
tensor(0.1335, device='cuda:0', grad_fn=<AddBackward0>)
0.55798924
tensor(0.1361, device='cuda:0', grad_fn=<AddBackward0>)
0.55792624
tensor(0.1161, device='cuda:0', grad_fn=<AddBackward0>)
0.55792534
tensor(0.1613, device='cuda:0', grad_fn=<AddBackward0>)
0.55800110
tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>)
0.55797023
tensor(0.1092, device='cuda:0', grad_fn=<AddBackward0>)
0.55798358
tensor(0.1249, device='cuda:0', grad_fn=<AddBackward0>)
0.55796731
tensor(0.1263, device='cuda:0', grad_fn=<AddBackward0>)
0.55788469
tensor(0.1607, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [50][   20/  196]   Loss 0.119636   Top1 95.917969   Top5 99.921875   BatchTime 0.334405   LR 0.000062
0.55773151
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.55777758
tensor(0.1318, device='cuda:0', grad_fn=<AddBackward0>)
0.55799192
tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>)
0.55799377
tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>)
0.55804557
tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)
0.55806744
tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)
0.55821395
tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)
0.55823058
tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
0.55792171
tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
0.55785376
tensor(0.1477, device='cuda:0', grad_fn=<AddBackward0>)
0.55786961
tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
0.55804908
tensor(0.1326, device='cuda:0', grad_fn=<AddBackward0>)
0.55814850
tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>)
0.55810338
tensor(0.1104, device='cuda:0', grad_fn=<AddBackward0>)
0.55810040
tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>)
0.55795926
tensor(0.1007, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [50][   40/  196]   Loss 0.121659   Top1 96.083984   Top5 99.941406   BatchTime 0.292041   LR 0.000062
0.55815083
tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
0.55799145
tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
0.55794078
tensor(0.1451, device='cuda:0', grad_fn=<AddBackward0>)
0.55788445
tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
0.55784786
tensor(0.1378, device='cuda:0', grad_fn=<AddBackward0>)
0.55782598
tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
0.55781287
tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>)
0.55806541
tensor(0.1279, device='cuda:0', grad_fn=<AddBackward0>)
0.55805564
tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
0.55789995
tensor(0.1234, device='cuda:0', grad_fn=<AddBackward0>)
0.55803764
tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>)
0.55792910
tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)
0.55795640
tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
0.55806309
tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>)
0.55811566
tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>)
0.55804050
tensor(0.1433, device='cuda:0', grad_fn=<AddBackward0>)
0.55795270
tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
0.55793256
tensor(0.0871, device='cuda:0', grad_fn=<AddBackward0>)
0.55790001
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.55807316
tensor(0.1127, device='cuda:0', grad_fn=<AddBackward0>)
0.55802548
tensor(0.1458, device='cuda:0', grad_fn=<AddBackward0>)
0.55786741
tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>)
0.55784720
tensor(0.1212, device='cuda:0', grad_fn=<AddBackward0>)
0.55788261
tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [50][   60/  196]   Loss 0.120224   Top1 96.158854   Top5 99.954427   BatchTime 0.277933   LR 0.000061
0.55798531
tensor(0.0820, device='cuda:0', grad_fn=<AddBackward0>)
0.55795515
tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>)
0.55785513
tensor(0.1162, device='cuda:0', grad_fn=<AddBackward0>)
0.55789256
tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
0.55796814
tensor(0.0909, device='cuda:0', grad_fn=<AddBackward0>)
0.55788505
tensor(0.1533, device='cuda:0', grad_fn=<AddBackward0>)
0.55771041
tensor(0.1050, device='cuda:0', grad_fn=<AddBackward0>)
0.55777699
tensor(0.1365, device='cuda:0', grad_fn=<AddBackward0>)
0.55782181
tensor(0.1145, device='cuda:0', grad_fn=<AddBackward0>)
0.55782586
tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)
0.55783069
tensor(0.1518, device='cuda:0', grad_fn=<AddBackward0>)
0.55782115
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.55792087
tensor(0.1311, device='cuda:0', grad_fn=<AddBackward0>)
0.55782086
tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>)
0.55784184
tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
0.55785906
tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [50][   80/  196]   Loss 0.119860   Top1 96.162109   Top5 99.941406   BatchTime 0.270908   LR 0.000061
0.55783617
tensor(0.1092, device='cuda:0', grad_fn=<AddBackward0>)
0.55784750
tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>)
0.55790347
tensor(0.1489, device='cuda:0', grad_fn=<AddBackward0>)
0.55778003
tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)
0.55780268
tensor(0.1204, device='cuda:0', grad_fn=<AddBackward0>)
0.55775642
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.55766869
tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>)
0.55773121
tensor(0.1222, device='cuda:0', grad_fn=<AddBackward0>)
0.55778593
tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>)
0.55768460
tensor(0.0865, device='cuda:0', grad_fn=<AddBackward0>)
0.55760014
tensor(0.1372, device='cuda:0', grad_fn=<AddBackward0>)
0.55741763
tensor(0.1383, device='cuda:0', grad_fn=<AddBackward0>)
0.55745262
tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>)
0.55751961
tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>)
0.55765980
tensor(0.0867, device='cuda:0', grad_fn=<AddBackward0>)
0.55774158
tensor(0.1008, device='cuda:0', grad_fn=<AddBackward0>)
0.55786020
tensor(0.1586, device='cuda:0', grad_fn=<AddBackward0>)
0.55799615
tensor(0.1409, device='cuda:0', grad_fn=<AddBackward0>)
0.55791157
tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
0.55787343
tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
0.55799085
tensor(0.1299, device='cuda:0', grad_fn=<AddBackward0>)
0.55777580
tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
0.55780429
tensor(0.1286, device='cuda:0', grad_fn=<AddBackward0>)
0.55784076
tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [50][  100/  196]   Loss 0.118835   Top1 96.136719   Top5 99.941406   BatchTime 0.267246   LR 0.000060
0.55788314
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
0.55778211
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.55782408
tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>)
0.55780500
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
0.55779606
tensor(0.1016, device='cuda:0', grad_fn=<AddBackward0>)
0.55754232
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
0.55760819
tensor(0.0932, device='cuda:0', grad_fn=<AddBackward0>)
0.55744779
tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>)
0.55746394
tensor(0.1094, device='cuda:0', grad_fn=<AddBackward0>)
0.55747455
tensor(0.1444, device='cuda:0', grad_fn=<AddBackward0>)
0.55737358
tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)
0.55733258
tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
0.55739599
tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>)
0.55736768
tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>)
0.55731875
tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>)
0.55729723
tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [50][  120/  196]   Loss 0.118955   Top1 96.067708   Top5 99.947917   BatchTime 0.263511   LR 0.000060
0.55740207
tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)
0.55758399
tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>)
0.55773222
tensor(0.1212, device='cuda:0', grad_fn=<AddBackward0>)
0.55763119
tensor(0.1052, device='cuda:0', grad_fn=<AddBackward0>)
0.55762112
tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)
0.55757689
tensor(0.1398, device='cuda:0', grad_fn=<AddBackward0>)
0.55743188
tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>)
0.55737364
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.55736554
tensor(0.1600, device='cuda:0', grad_fn=<AddBackward0>)
0.55734718
tensor(0.1036, device='cuda:0', grad_fn=<AddBackward0>)
0.55738717
tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>)
0.55739850
tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>)
0.55738115
tensor(0.1472, device='cuda:0', grad_fn=<AddBackward0>)
0.55742890
tensor(0.0907, device='cuda:0', grad_fn=<AddBackward0>)
0.55734789
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
0.55751157
tensor(0.1403, device='cuda:0', grad_fn=<AddBackward0>)
0.55754942
tensor(0.1169, device='cuda:0', grad_fn=<AddBackward0>)
0.55753165
tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>)
0.55755681
tensor(0.1114, device='cuda:0', grad_fn=<AddBackward0>)
0.55757862
tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>)
0.55758542
tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
0.55750090
tensor(0.1392, device='cuda:0', grad_fn=<AddBackward0>)
0.55769235
tensor(0.1585, device='cuda:0', grad_fn=<AddBackward0>)
0.55771339
tensor(0.1709, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [50][  140/  196]   Loss 0.120009   Top1 96.018415   Top5 99.949777   BatchTime 0.262079   LR 0.000059
0.55754095
tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
0.55767912
tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
0.55754811
tensor(0.1745, device='cuda:0', grad_fn=<AddBackward0>)
0.55745083
tensor(0.0858, device='cuda:0', grad_fn=<AddBackward0>)
0.55734694
tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>)
0.55732453
tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>)
0.55739981
tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>)
0.55752277
tensor(0.1441, device='cuda:0', grad_fn=<AddBackward0>)
0.55773127
tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
0.55758762
tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>)
0.55736226
tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>)
0.55725938
tensor(0.1022, device='cuda:0', grad_fn=<AddBackward0>)
0.55719894
tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>)
0.55713832
tensor(0.1045, device='cuda:0', grad_fn=<AddBackward0>)
0.55707920
tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
0.55696130
tensor(0.1757, device='cuda:0', grad_fn=<AddBackward0>)
0.55689496
tensor(0.1441, device='cuda:0', grad_fn=<AddBackward0>)
0.55686814
tensor(0.1393, device='cuda:0', grad_fn=<AddBackward0>)
0.55690169
tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
0.55697447
tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
0.55701768
tensor(0.1206, device='cuda:0', grad_fn=<AddBackward0>)
0.55715632
tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [50][  160/  196]   Loss 0.119722   Top1 96.025391   Top5 99.953613   BatchTime 0.263160   LR 0.000059
0.55697453
tensor(0.1646, device='cuda:0', grad_fn=<AddBackward0>)
0.55710793
tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)
0.55710411
tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>)
0.55714720
tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>)
0.55724627
tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>)
0.55725044
tensor(0.0992, device='cuda:0', grad_fn=<AddBackward0>)
0.55734223
tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
0.55765748
tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>)
0.55752808
tensor(0.1234, device='cuda:0', grad_fn=<AddBackward0>)
0.55747229
tensor(0.0816, device='cuda:0', grad_fn=<AddBackward0>)
0.55743408
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
0.55728328
tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
0.55731308
tensor(0.1726, device='cuda:0', grad_fn=<AddBackward0>)
0.55730337
tensor(0.1054, device='cuda:0', grad_fn=<AddBackward0>)
0.55722576
tensor(0.1193, device='cuda:0', grad_fn=<AddBackward0>)
0.55720347
tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
0.55727386
tensor(0.0898, device='cuda:0', grad_fn=<AddBackward0>)
0.55728477
tensor(0.1132, device='cuda:0', grad_fn=<AddBackward0>)
0.55752254
tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [50][  180/  196]   Loss 0.120318   Top1 96.002604   Top5 99.954427   BatchTime 0.266883   LR 0.000058
0.55738831
tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>)
0.55735356
tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
0.55738550
tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>)
0.55739486
tensor(0.1334, device='cuda:0', grad_fn=<AddBackward0>)
0.55742633
tensor(0.1363, device='cuda:0', grad_fn=<AddBackward0>)
0.55727959
tensor(0.0812, device='cuda:0', grad_fn=<AddBackward0>)
0.55719405
tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
0.55714262
tensor(0.1646, device='cuda:0', grad_fn=<AddBackward0>)
0.55712837
tensor(0.1412, device='cuda:0', grad_fn=<AddBackward0>)
0.55703253
tensor(0.1607, device='cuda:0', grad_fn=<AddBackward0>)
0.55711073
tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 95.974    Top5: 99.954    Loss: 0.121
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [50][   20/   40]   Loss 0.394669   Top1 88.964844   Top5 99.589844   BatchTime 0.127517
features.0.conv.0 tensor(0.2743)
features.0.conv.3 tensor(0.1523)
features.1.conv.0 tensor(0.0462)
features.1.conv.3 tensor(0.0775)
features.1.conv.6 tensor(0.0885)
features.2.conv.0 tensor(0.1111)
features.2.conv.3 tensor(0.3410)
features.2.conv.6 tensor(0.5281)
features.3.conv.0 tensor(0.0709)
features.3.conv.3 tensor(0.0687)
features.3.conv.6 tensor(0.1111)
features.4.conv.0 tensor(0.0788)
features.4.conv.3 tensor(0.2980)
features.4.conv.6 tensor(0.3849)
features.5.conv.0 tensor(0.3265)
features.5.conv.3 tensor(0.4103)
features.5.conv.6 tensor(0.4639)
features.6.conv.0 tensor(0.0513)
features.6.conv.3 tensor(0.0498)
features.6.conv.6 tensor(0.0851)
features.7.conv.0 tensor(0.2603)
features.7.conv.3 tensor(0.4453)
features.7.conv.6 tensor(0.6358)
features.8.conv.0 tensor(0.5511)
features.8.conv.3 tensor(0.5359)
features.8.conv.6 tensor(0.5692)
features.9.conv.0 tensor(0.5079)
features.9.conv.3 tensor(0.5639)
features.9.conv.6 tensor(0.7492)
features.10.conv.0 tensor(0.0602)
features.10.conv.3 tensor(0.0926)
features.10.conv.6 tensor(0.0669)
features.11.conv.0 tensor(0.7619)
features.11.conv.3 tensor(0.6439)
features.11.conv.6 tensor(0.9008)
features.12.conv.0 tensor(0.7225)
features.12.conv.3 tensor(0.6632)
features.12.conv.6 tensor(0.8630)
features.13.conv.0 tensor(0.2688)
features.13.conv.3 tensor(0.4848)
features.13.conv.6 tensor(0.5074)
features.14.conv.0 tensor(0.9106)
features.14.conv.3 tensor(0.8230)
features.14.conv.6 tensor(0.9569)
features.15.conv.0 tensor(0.8961)
features.15.conv.3 tensor(0.8278)
features.15.conv.6 tensor(0.9630)
features.16.conv.0 tensor(0.6891)
features.16.conv.3 tensor(0.7884)
features.16.conv.6 tensor(0.8963)
conv.0 tensor(0.1508)
tensor(1391387.) 2188896.0
INFO - Validation [50][   40/   40]   Loss 0.377344   Top1 88.990000   Top5 99.630000   BatchTime 0.089804
INFO - ==> Top1: 88.990    Top5: 99.630    Loss: 0.377
INFO - ==> Sparsity : 0.636
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 88.990   Top5: 99.630]
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 88.970   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
0.55719185
tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>)
0.55705851
tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>)
0.55701482
tensor(0.1679, device='cuda:0', grad_fn=<AddBackward0>)
0.55688888
tensor(0.1063, device='cuda:0', grad_fn=<AddBackward0>)
0.55684561
tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>)
0.55680209
tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>)
0.55687064
tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
0.55691022
tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>)
0.55690706
tensor(0.1094, device='cuda:0', grad_fn=<AddBackward0>)
0.55697787
tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>)
0.55698562
tensor(0.1055, device='cuda:0', grad_fn=<AddBackward0>)
0.55725253
tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
0.55705947
tensor(0.1476, device='cuda:0', grad_fn=<AddBackward0>)
0.55691004
tensor(0.1382, device='cuda:0', grad_fn=<AddBackward0>)
0.55683327
tensor(0.1738, device='cuda:0', grad_fn=<AddBackward0>)
0.55701816
tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>)
0.55690861
tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)
0.55702513
tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
0.55723268
tensor(0.1243, device='cuda:0', grad_fn=<AddBackward0>)
0.55723482
tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [51][   20/  196]   Loss 0.121035   Top1 95.937500   Top5 100.000000   BatchTime 0.362970   LR 0.000057
0.55713773
tensor(0.0997, device='cuda:0', grad_fn=<AddBackward0>)
0.55683482
tensor(0.1193, device='cuda:0', grad_fn=<AddBackward0>)
0.55677670
tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
0.55688560
tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>)
0.55687219
tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
0.55679739
tensor(0.1428, device='cuda:0', grad_fn=<AddBackward0>)
0.55677027
tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
0.55697554
tensor(0.1858, device='cuda:0', grad_fn=<AddBackward0>)
0.55704564
tensor(0.0922, device='cuda:0', grad_fn=<AddBackward0>)
0.55685502
tensor(0.1119, device='cuda:0', grad_fn=<AddBackward0>)
0.55701220
tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
0.55674529
tensor(0.1504, device='cuda:0', grad_fn=<AddBackward0>)
0.55672318
tensor(0.1644, device='cuda:0', grad_fn=<AddBackward0>)
0.55691814
tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>)
0.55688542
tensor(0.1405, device='cuda:0', grad_fn=<AddBackward0>)
0.55670244
tensor(0.0861, device='cuda:0', grad_fn=<AddBackward0>)
0.55679446
tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>)
0.55664307
tensor(0.1263, device='cuda:0', grad_fn=<AddBackward0>)
0.55657589
tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
0.55641478
tensor(0.1010, device='cuda:0', grad_fn=<AddBackward0>)
0.55631948
tensor(0.1304, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [51][   40/  196]   Loss 0.123305   Top1 95.781250   Top5 99.980469   BatchTime 0.324986   LR 0.000057
0.55631071
tensor(0.1783, device='cuda:0', grad_fn=<AddBackward0>)
0.55646205
tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
0.55649668
tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
0.55644202
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.55638796
tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>)
0.55657870
tensor(0.0997, device='cuda:0', grad_fn=<AddBackward0>)
0.55668521
tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>)
0.55659270
tensor(0.1229, device='cuda:0', grad_fn=<AddBackward0>)
0.55660313
tensor(0.1082, device='cuda:0', grad_fn=<AddBackward0>)
0.55628133
tensor(0.1038, device='cuda:0', grad_fn=<AddBackward0>)
0.55623740
tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>)
0.55638808
tensor(0.0884, device='cuda:0', grad_fn=<AddBackward0>)
0.55634785
tensor(0.1536, device='cuda:0', grad_fn=<AddBackward0>)
0.55637640
tensor(0.1576, device='cuda:0', grad_fn=<AddBackward0>)
0.55629963
tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>)
0.55630928
tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>)
0.55631238
tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>)
0.55642670
tensor(0.0762, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [51][   60/  196]   Loss 0.123240   Top1 95.644531   Top5 99.973958   BatchTime 0.325905   LR 0.000056
0.55649817
tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)
0.55623925
tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
0.55626959
tensor(0.0989, device='cuda:0', grad_fn=<AddBackward0>)
0.55617195
tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
0.55600637
tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)
0.55611444
tensor(0.0887, device='cuda:0', grad_fn=<AddBackward0>)
0.55626446
tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>)
0.55604541
tensor(0.1326, device='cuda:0', grad_fn=<AddBackward0>)
0.55598170
tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>)
0.55621076
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.55601734
tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>)
0.55588365
tensor(0.0976, device='cuda:0', grad_fn=<AddBackward0>)
0.55597091
tensor(0.1061, device='cuda:0', grad_fn=<AddBackward0>)
0.55611557
tensor(0.1028, device='cuda:0', grad_fn=<AddBackward0>)
0.55591488
tensor(0.0804, device='cuda:0', grad_fn=<AddBackward0>)
0.55578727
tensor(0.1351, device='cuda:0', grad_fn=<AddBackward0>)
0.55597019
tensor(0.1636, device='cuda:0', grad_fn=<AddBackward0>)
0.55594444
tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
0.55584794
tensor(0.1518, device='cuda:0', grad_fn=<AddBackward0>)
0.55573422
tensor(0.0743, device='cuda:0', grad_fn=<AddBackward0>)
0.55543792
tensor(0.1059, device='cuda:0', grad_fn=<AddBackward0>)
0.55531883
tensor(0.1165, device='cuda:0', grad_fn=<AddBackward0>)
0.55538213
tensor(0.1330, device='cuda:0', grad_fn=<AddBackward0>)
0.55528504
tensor(0.0715, device='cuda:0', grad_fn=<AddBackward0>)
0.55511290
tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [51][   80/  196]   Loss 0.119015   Top1 95.859375   Top5 99.975586   BatchTime 0.327443   LR 0.000056
0.55488420
tensor(0.1315, device='cuda:0', grad_fn=<AddBackward0>)
0.55452728
tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>)
0.55437291
tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>)
0.55440652
tensor(0.1208, device='cuda:0', grad_fn=<AddBackward0>)
0.55438983
tensor(0.1428, device='cuda:0', grad_fn=<AddBackward0>)
0.55427545
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.55417520
tensor(0.1077, device='cuda:0', grad_fn=<AddBackward0>)
0.55410677
tensor(0.1107, device='cuda:0', grad_fn=<AddBackward0>)
0.55403906
tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>)
0.55402076
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.55399340
tensor(0.1006, device='cuda:0', grad_fn=<AddBackward0>)
0.55396593
tensor(0.0705, device='cuda:0', grad_fn=<AddBackward0>)
0.55395341
tensor(0.1466, device='cuda:0', grad_fn=<AddBackward0>)
0.55396295
tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
0.55392456
tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>)
0.55392987
tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
0.55436462
tensor(0.1085, device='cuda:0', grad_fn=<AddBackward0>)
0.55429852
tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [51][  100/  196]   Loss 0.119487   Top1 95.882812   Top5 99.972656   BatchTime 0.326624   LR 0.000055
0.55410284
tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>)
0.55383569
tensor(0.0743, device='cuda:0', grad_fn=<AddBackward0>)
0.55370688
tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>)
0.55373722
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.55379629
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
0.55374402
tensor(0.1205, device='cuda:0', grad_fn=<AddBackward0>)
0.55365521
tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
0.55365962
tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
0.55361211
tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
0.55353016
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.55353266
tensor(0.1070, device='cuda:0', grad_fn=<AddBackward0>)
0.55361456
tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>)
0.55361688
tensor(0.0912, device='cuda:0', grad_fn=<AddBackward0>)
0.55359715
tensor(0.1554, device='cuda:0', grad_fn=<AddBackward0>)
0.55356890
tensor(0.1076, device='cuda:0', grad_fn=<AddBackward0>)
0.55368942
tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
0.55398786
tensor(0.1258, device='cuda:0', grad_fn=<AddBackward0>)
0.55411947
tensor(0.1137, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [51][  120/  196]   Loss 0.118824   Top1 95.921224   Top5 99.977214   BatchTime 0.328183   LR 0.000055
0.55389422
tensor(0.1793, device='cuda:0', grad_fn=<AddBackward0>)
0.55369812
tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
0.55369341
tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>)
0.55363423
tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
0.55366290
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
0.55366540
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.55364078
tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
0.55346256
tensor(0.1293, device='cuda:0', grad_fn=<AddBackward0>)
0.55340332
tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
0.55337089
tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)
0.55336303
tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>)
0.55329078
tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
0.55318594
tensor(0.1389, device='cuda:0', grad_fn=<AddBackward0>)
0.55307114
tensor(0.1144, device='cuda:0', grad_fn=<AddBackward0>)
0.55292928
tensor(0.1426, device='cuda:0', grad_fn=<AddBackward0>)
0.55277079
tensor(0.1425, device='cuda:0', grad_fn=<AddBackward0>)
0.55258316
tensor(0.1223, device='cuda:0', grad_fn=<AddBackward0>)
0.55268234
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
0.55285984
tensor(0.1249, device='cuda:0', grad_fn=<AddBackward0>)
0.55466145
tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
0.55472630
tensor(0.1534, device='cuda:0', grad_fn=<AddBackward0>)
0.55469662
tensor(0.1475, device='cuda:0', grad_fn=<AddBackward0>)
0.55464709
tensor(0.1393, device='cuda:0', grad_fn=<AddBackward0>)
0.55462199
tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [51][  140/  196]   Loss 0.119896   Top1 95.881696   Top5 99.966518   BatchTime 0.328575   LR 0.000054
0.55459511
tensor(0.1414, device='cuda:0', grad_fn=<AddBackward0>)
0.55449492
tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>)
0.55440992
tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>)
0.55439842
tensor(0.1657, device='cuda:0', grad_fn=<AddBackward0>)
0.55441844
tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
0.55446023
tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>)
0.55450982
tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>)
0.55497104
tensor(0.1014, device='cuda:0', grad_fn=<AddBackward0>)
0.55493742
tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
0.55497229
tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>)
0.55500704
tensor(0.1358, device='cuda:0', grad_fn=<AddBackward0>)
0.55497199
tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)
0.55496180
tensor(0.1072, device='cuda:0', grad_fn=<AddBackward0>)
0.55481553
tensor(0.1198, device='cuda:0', grad_fn=<AddBackward0>)
0.55480790
tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
0.55474317
tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)
0.55471736
tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)
0.55481726
tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [51][  160/  196]   Loss 0.120528   Top1 95.881348   Top5 99.965820   BatchTime 0.329169   LR 0.000054
0.55487245
tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)
0.55503994
tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)
0.55491763
tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>)
0.55498791
tensor(0.1603, device='cuda:0', grad_fn=<AddBackward0>)
0.55481201
tensor(0.1645, device='cuda:0', grad_fn=<AddBackward0>)
0.55478883
tensor(0.1357, device='cuda:0', grad_fn=<AddBackward0>)
0.55473250
tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>)
0.55469388
tensor(0.1380, device='cuda:0', grad_fn=<AddBackward0>)
0.55468637
tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
0.55480236
tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
0.55504686
tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)
0.55498999
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.55500078
tensor(0.1179, device='cuda:0', grad_fn=<AddBackward0>)
0.55504924
tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>)
0.55486840
tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
0.55465323
tensor(0.1500, device='cuda:0', grad_fn=<AddBackward0>)
0.55456060
tensor(0.1396, device='cuda:0', grad_fn=<AddBackward0>)
0.55456656
tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [51][  180/  196]   Loss 0.120630   Top1 95.889757   Top5 99.967448   BatchTime 0.329770   LR 0.000053
0.55446970
tensor(0.1065, device='cuda:0', grad_fn=<AddBackward0>)
0.55436659
tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
0.55426621
tensor(0.1217, device='cuda:0', grad_fn=<AddBackward0>)
0.55413973
tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
0.55418068
tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
0.55434746
tensor(0.1085, device='cuda:0', grad_fn=<AddBackward0>)
0.55438650
tensor(0.1214, device='cuda:0', grad_fn=<AddBackward0>)
0.55440086
tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>)
0.55455661
tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
0.55439532
tensor(0.1315, device='cuda:0', grad_fn=<AddBackward0>)
0.55439717
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.55442077
tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>)
0.55449915
tensor(0.1311, device='cuda:0', grad_fn=<AddBackward0>)
0.55429214
tensor(0.1226, device='cuda:0', grad_fn=<AddBackward0>)
0.55421960
tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>)
0.55415291
tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 95.898    Top5: 99.960    Loss: 0.121
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [51][   20/   40]   Loss 0.409377   Top1 88.300781   Top5 99.531250   BatchTime 0.128976
features.0.conv.0 tensor(0.2674)
features.0.conv.3 tensor(0.1484)
features.1.conv.0 tensor(0.0488)
features.1.conv.3 tensor(0.0729)
features.1.conv.6 tensor(0.0868)
features.2.conv.0 tensor(0.1146)
features.2.conv.3 tensor(0.3410)
features.2.conv.6 tensor(0.5321)
features.3.conv.0 tensor(0.0680)
features.3.conv.3 tensor(0.0718)
features.3.conv.6 tensor(0.1068)
features.4.conv.0 tensor(0.0786)
features.4.conv.3 tensor(0.2957)
features.4.conv.6 tensor(0.3976)
features.5.conv.0 tensor(0.3164)
features.5.conv.3 tensor(0.4115)
features.5.conv.6 tensor(0.4691)
features.6.conv.0 tensor(0.0526)
features.6.conv.3 tensor(0.0469)
features.6.conv.6 tensor(0.0850)
features.7.conv.0 tensor(0.2635)
features.7.conv.3 tensor(0.4470)
features.7.conv.6 tensor(0.6399)
features.8.conv.0 tensor(0.5355)
features.8.conv.3 tensor(0.5362)
features.8.conv.6 tensor(0.5931)
features.9.conv.0 tensor(0.5188)
features.9.conv.3 tensor(0.5654)
features.9.conv.6 tensor(0.7505)
features.10.conv.0 tensor(0.0608)
features.10.conv.3 tensor(0.0929)
features.10.conv.6 tensor(0.0677)
features.11.conv.0 tensor(0.7604)
features.11.conv.3 tensor(0.6443)
features.11.conv.6 tensor(0.9015)
features.12.conv.0 tensor(0.7220)
features.12.conv.3 tensor(0.6649)
features.12.conv.6 tensor(0.8642)
features.13.conv.0 tensor(0.2942)
features.13.conv.3 tensor(0.4846)
features.13.conv.6 tensor(0.5086)
features.14.conv.0 tensor(0.9113)
features.14.conv.3 tensor(0.8229)
features.14.conv.6 tensor(0.9571)
features.15.conv.0 tensor(0.8966)
features.15.conv.3 tensor(0.8280)
features.15.conv.6 tensor(0.9631)
features.16.conv.0 tensor(0.6910)
features.16.conv.3 tensor(0.7885)
features.16.conv.6 tensor(0.8982)
conv.0 tensor(0.1580)
tensor(1397755.) 2188896.0
INFO - Validation [51][   40/   40]   Loss 0.384697   Top1 88.720000   Top5 99.620000   BatchTime 0.091190
INFO - ==> Top1: 88.720    Top5: 99.620    Loss: 0.385
INFO - ==> Sparsity : 0.639
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 88.990   Top5: 99.630]
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 88.970   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
0.55409408
tensor(0.0961, device='cuda:0', grad_fn=<AddBackward0>)
0.55405551
tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
0.55412036
tensor(0.1346, device='cuda:0', grad_fn=<AddBackward0>)
0.55420184
tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>)
0.55423915
tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>)
0.55425948
tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
0.55429047
tensor(0.1116, device='cuda:0', grad_fn=<AddBackward0>)
0.55436379
tensor(0.0778, device='cuda:0', grad_fn=<AddBackward0>)
0.55439180
tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
0.55439144
tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)
0.55438995
tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
0.55464196
tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>)
0.55452144
tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
0.55437529
tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
0.55431414
tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
0.55427897
tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)
0.55435425
tensor(0.1114, device='cuda:0', grad_fn=<AddBackward0>)
0.55474275
tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>)
0.55463970
tensor(0.1297, device='cuda:0', grad_fn=<AddBackward0>)
0.55448008
tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>)
0.55439353
tensor(0.1704, device='cuda:0', grad_fn=<AddBackward0>)
0.55429947
tensor(0.1187, device='cuda:0', grad_fn=<AddBackward0>)
0.55438191
tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [52][   20/  196]   Loss 0.106061   Top1 96.269531   Top5 100.000000   BatchTime 0.395224   LR 0.000052
0.55439299
tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>)
0.55423117
tensor(0.1300, device='cuda:0', grad_fn=<AddBackward0>)
0.55432022
tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
0.55438310
tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>)
0.55444235
tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)
0.55442357
tensor(0.1117, device='cuda:0', grad_fn=<AddBackward0>)
0.55433917
tensor(0.0932, device='cuda:0', grad_fn=<AddBackward0>)
0.55426264
tensor(0.1297, device='cuda:0', grad_fn=<AddBackward0>)
0.55427659
tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>)
0.55427831
tensor(0.1274, device='cuda:0', grad_fn=<AddBackward0>)
0.55428267
tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>)
0.55423599
tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
0.55418384
tensor(0.1508, device='cuda:0', grad_fn=<AddBackward0>)
0.55413055
tensor(0.0756, device='cuda:0', grad_fn=<AddBackward0>)
0.55391812
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.55386502
tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>)
0.55391997
tensor(0.1016, device='cuda:0', grad_fn=<AddBackward0>)
0.55390382
tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [52][   40/  196]   Loss 0.112845   Top1 96.064453   Top5 99.980469   BatchTime 0.368826   LR 0.000052
0.55385751
tensor(0.1213, device='cuda:0', grad_fn=<AddBackward0>)
0.55385184
tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>)
0.55380017
tensor(0.1111, device='cuda:0', grad_fn=<AddBackward0>)
0.55370510
tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>)
0.55363578
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.55371988
tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>)
0.55376285
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.55357236
tensor(0.1691, device='cuda:0', grad_fn=<AddBackward0>)
0.55357879
tensor(0.1325, device='cuda:0', grad_fn=<AddBackward0>)
0.55370915
tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
0.55384886
tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)
0.55415779
tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>)
0.55410194
tensor(0.1500, device='cuda:0', grad_fn=<AddBackward0>)
0.55386484
tensor(0.1248, device='cuda:0', grad_fn=<AddBackward0>)
0.55398327
tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)
0.55389005
tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>)
0.55400342
tensor(0.0968, device='cuda:0', grad_fn=<AddBackward0>)
0.55397689
tensor(0.1013, device='cuda:0', grad_fn=<AddBackward0>)
0.55397201
tensor(0.0812, device='cuda:0', grad_fn=<AddBackward0>)
0.55382591
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.55368692
tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
0.55361265
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.55356175
tensor(0.0940, device='cuda:0', grad_fn=<AddBackward0>)
0.55353570
tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [52][   60/  196]   Loss 0.111870   Top1 96.074219   Top5 99.980469   BatchTime 0.356096   LR 0.000051
0.55348963
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.55358845
tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>)
0.55392033
tensor(0.1355, device='cuda:0', grad_fn=<AddBackward0>)
0.55400926
tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>)
0.55358666
tensor(0.1116, device='cuda:0', grad_fn=<AddBackward0>)
0.55349082
tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>)
0.55343783
tensor(0.0987, device='cuda:0', grad_fn=<AddBackward0>)
0.55340981
tensor(0.1270, device='cuda:0', grad_fn=<AddBackward0>)
0.55334979
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.55327457
tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
0.55326295
tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)
0.55331892
tensor(0.1273, device='cuda:0', grad_fn=<AddBackward0>)
0.55339849
tensor(0.1492, device='cuda:0', grad_fn=<AddBackward0>)
0.55353385
tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>)
0.55343604
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.55329210
tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>)
0.55318838
tensor(0.1241, device='cuda:0', grad_fn=<AddBackward0>)
0.55318868
tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [52][   80/  196]   Loss 0.112978   Top1 96.064453   Top5 99.985352   BatchTime 0.350354   LR 0.000051
0.55320734
tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
0.55323905
tensor(0.0980, device='cuda:0', grad_fn=<AddBackward0>)
0.55329984
tensor(0.0980, device='cuda:0', grad_fn=<AddBackward0>)
0.55326754
tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>)
0.55350053
tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
0.55343413
tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>)
0.55384403
tensor(0.1065, device='cuda:0', grad_fn=<AddBackward0>)
0.55350083
tensor(0.1321, device='cuda:0', grad_fn=<AddBackward0>)
0.55352283
tensor(0.1466, device='cuda:0', grad_fn=<AddBackward0>)
0.55353594
tensor(0.1612, device='cuda:0', grad_fn=<AddBackward0>)
0.55341631
tensor(0.1176, device='cuda:0', grad_fn=<AddBackward0>)
0.55345422
tensor(0.0950, device='cuda:0', grad_fn=<AddBackward0>)
0.55367231
tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>)
0.55339903
tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
0.55357218
tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>)
0.55354792
tensor(0.1451, device='cuda:0', grad_fn=<AddBackward0>)
0.55347967
tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
0.55346644
tensor(0.1592, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [52][  100/  196]   Loss 0.113583   Top1 96.042969   Top5 99.980469   BatchTime 0.345468   LR 0.000050
0.55337000
tensor(0.1442, device='cuda:0', grad_fn=<AddBackward0>)
0.55345809
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
0.55349529
tensor(0.1283, device='cuda:0', grad_fn=<AddBackward0>)
0.55341828
tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)
0.55351603
tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
0.55356914
tensor(0.0996, device='cuda:0', grad_fn=<AddBackward0>)
0.55328506
tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>)
0.55325317
tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
0.55331153
tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
0.55329132
tensor(0.1473, device='cuda:0', grad_fn=<AddBackward0>)
0.55321819
tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>)
0.55312967
tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>)
0.55314630
tensor(0.1158, device='cuda:0', grad_fn=<AddBackward0>)
0.55306423
tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>)
0.55307370
tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>)
0.55321079
tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>)
0.55323774
tensor(0.1069, device='cuda:0', grad_fn=<AddBackward0>)
0.55309308
tensor(0.1506, device='cuda:0', grad_fn=<AddBackward0>)
0.55310661
tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>)
0.55301535
tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)
0.55325776
tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
0.55333745
tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>)
0.55313355
tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
0.55330426
tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [52][  120/  196]   Loss 0.113057   Top1 96.110026   Top5 99.973958   BatchTime 0.343372   LR 0.000050
0.55305457
tensor(0.1166, device='cuda:0', grad_fn=<AddBackward0>)
0.55285013
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.55288416
tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)
0.55290091
tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>)
0.55287367
tensor(0.1072, device='cuda:0', grad_fn=<AddBackward0>)
0.55288404
tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>)
0.55287284
tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)
0.55289721
tensor(0.1370, device='cuda:0', grad_fn=<AddBackward0>)
0.55299187
tensor(0.1223, device='cuda:0', grad_fn=<AddBackward0>)
0.55297482
tensor(0.1326, device='cuda:0', grad_fn=<AddBackward0>)
0.55310702
tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
0.55312574
tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
0.55304283
tensor(0.1409, device='cuda:0', grad_fn=<AddBackward0>)
0.55316240
tensor(0.0860, device='cuda:0', grad_fn=<AddBackward0>)
0.55320096
tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>)
0.55288458
tensor(0.1273, device='cuda:0', grad_fn=<AddBackward0>)
0.55287248
tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
0.55279917
tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
0.55289465
tensor(0.1446, device='cuda:0', grad_fn=<AddBackward0>)
0.55318487
tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
0.55295146
tensor(0.0906, device='cuda:0', grad_fn=<AddBackward0>)
0.55304021
tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [52][  140/  196]   Loss 0.113482   Top1 96.096540   Top5 99.966518   BatchTime 0.336657   LR 0.000049
0.55317402
tensor(0.1618, device='cuda:0', grad_fn=<AddBackward0>)
0.55328864
tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
0.55322975
tensor(0.1565, device='cuda:0', grad_fn=<AddBackward0>)
0.55328459
tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)
0.55301630
tensor(0.1279, device='cuda:0', grad_fn=<AddBackward0>)
0.55298680
tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>)
0.55295223
tensor(0.1353, device='cuda:0', grad_fn=<AddBackward0>)
0.55297154
tensor(0.1223, device='cuda:0', grad_fn=<AddBackward0>)
0.55301106
tensor(0.1318, device='cuda:0', grad_fn=<AddBackward0>)
0.55305278
tensor(0.1162, device='cuda:0', grad_fn=<AddBackward0>)
0.55304247
tensor(0.0861, device='cuda:0', grad_fn=<AddBackward0>)
0.55299038
tensor(0.1446, device='cuda:0', grad_fn=<AddBackward0>)
0.55297858
tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>)
0.55281878
tensor(0.1261, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [52][  160/  196]   Loss 0.114890   Top1 96.042480   Top5 99.960938   BatchTime 0.329603   LR 0.000049
0.55276299
tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>)
0.55264449
tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>)
0.55266196
tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
0.55268937
tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
0.55263746
tensor(0.1118, device='cuda:0', grad_fn=<AddBackward0>)
0.55261362
tensor(0.1185, device='cuda:0', grad_fn=<AddBackward0>)
0.55262512
tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>)
0.55271828
tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>)
0.55277842
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
0.55287981
tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>)
0.55275780
tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>)
0.55279642
tensor(0.1011, device='cuda:0', grad_fn=<AddBackward0>)
0.55259436
tensor(0.1430, device='cuda:0', grad_fn=<AddBackward0>)
0.55248880
tensor(0.1055, device='cuda:0', grad_fn=<AddBackward0>)
0.55243313
tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
0.55228394
tensor(0.1105, device='cuda:0', grad_fn=<AddBackward0>)
0.55229014
tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
0.55238771
tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>)
0.55250829
tensor(0.1392, device='cuda:0', grad_fn=<AddBackward0>)
0.55255646
tensor(0.0843, device='cuda:0', grad_fn=<AddBackward0>)
0.55263096
tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
0.55252349
tensor(0.1396, device='cuda:0', grad_fn=<AddBackward0>)
0.55252177
tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>)
0.55240065
tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [52][  180/  196]   Loss 0.115079   Top1 96.050347   Top5 99.958767   BatchTime 0.320860   LR 0.000048
0.55229336
tensor(0.1319, device='cuda:0', grad_fn=<AddBackward0>)
0.55219311
tensor(0.1516, device='cuda:0', grad_fn=<AddBackward0>)
0.55219001
tensor(0.1030, device='cuda:0', grad_fn=<AddBackward0>)
0.55230385
tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
0.55244750
tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
0.55250275
tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>)
0.55255872
tensor(0.1422, device='cuda:0', grad_fn=<AddBackward0>)
0.55267924
tensor(0.0907, device='cuda:0', grad_fn=<AddBackward0>)
0.55276275
tensor(0.1359, device='cuda:0', grad_fn=<AddBackward0>)
0.55270189
tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
0.55257982
tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 96.034    Top5: 99.960    Loss: 0.116
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2708)
features.0.conv.3 tensor(0.1523)
features.1.conv.0 tensor(0.0501)
features.1.conv.3 tensor(0.0752)
features.1.conv.6 tensor(0.0890)
features.2.conv.0 tensor(0.1172)
features.2.conv.3 tensor(0.3410)
features.2.conv.6 tensor(0.5333)
features.3.conv.0 tensor(0.0689)
features.3.conv.3 tensor(0.0756)
features.3.conv.6 tensor(0.1076)
features.4.conv.0 tensor(0.0859)
features.4.conv.3 tensor(0.3015)
features.4.conv.6 tensor(0.3986)
features.5.conv.0 tensor(0.3296)
features.5.conv.3 tensor(0.4120)
features.5.conv.6 tensor(0.4696)
features.6.conv.0 tensor(0.0514)
features.6.conv.3 tensor(0.0509)
features.6.conv.6 tensor(0.0859)
features.7.conv.0 tensor(0.2602)
features.7.conv.3 tensor(0.4465)
features.7.conv.6 tensor(0.6408)
features.8.conv.0 tensor(0.5400)
features.8.conv.3 tensor(0.5370)
features.8.conv.6 tensor(0.6040)
features.9.conv.0 tensor(0.5396)
features.9.conv.3 tensor(0.5645)
features.9.conv.6 tensor(0.7520)
features.10.conv.0 tensor(0.0622)
features.10.conv.3 tensor(0.0900)
features.10.conv.6 tensor(0.0669)
features.11.conv.0 tensor(0.7645)
features.11.conv.3 tensor(0.6426)
features.11.conv.6 tensor(0.9020)
features.12.conv.0 tensor(0.7205)
features.12.conv.3 tensor(0.6638)
features.12.conv.6 tensor(0.8647)
features.13.conv.0 tensor(0.2766)
features.13.conv.3 tensor(0.4851)
INFO - Validation [52][   20/   40]   Loss 0.424312   Top1 88.398438   Top5 99.492188   BatchTime 0.114417
INFO - Validation [52][   40/   40]   Loss 0.399006   Top1 88.860000   Top5 99.620000   BatchTime 0.084998
features.13.conv.6 tensor(0.5290)
features.14.conv.0 tensor(0.9121)
features.14.conv.3 tensor(0.8220)
features.14.conv.6 tensor(0.9568)
features.15.conv.0 tensor(0.8968)
features.15.conv.3 tensor(0.8271)
features.15.conv.6 tensor(0.9633)
features.16.conv.0 tensor(0.6942)
features.16.conv.3 tensor(0.7885)
features.16.conv.6 tensor(0.9015)
conv.0 tensor(0.1617)
tensor(1403057.) 2188896.0
0.55244625
tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
0.55239093
tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 88.860    Top5: 99.620    Loss: 0.399
INFO - ==> Sparsity : 0.641
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 88.990   Top5: 99.630]
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 88.970   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
0.55234492
tensor(0.0873, device='cuda:0', grad_fn=<AddBackward0>)
0.55233127
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.55239689
tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>)
0.55226123
tensor(0.1283, device='cuda:0', grad_fn=<AddBackward0>)
0.55214173
tensor(0.0804, device='cuda:0', grad_fn=<AddBackward0>)
0.55216992
tensor(0.1560, device='cuda:0', grad_fn=<AddBackward0>)
0.55213010
tensor(0.0922, device='cuda:0', grad_fn=<AddBackward0>)
0.55209273
tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
0.55218840
tensor(0.1036, device='cuda:0', grad_fn=<AddBackward0>)
0.55218804
tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
0.55228931
tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
0.55238336
tensor(0.0998, device='cuda:0', grad_fn=<AddBackward0>)
0.55247933
tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>)
0.55256146
tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)
0.55246049
tensor(0.1282, device='cuda:0', grad_fn=<AddBackward0>)
0.55234849
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.55210918
tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
0.55195284
tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>)
0.55197883
tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>)
0.55219525
tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>)
0.55222803
tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)
0.55218947
tensor(0.1739, device='cuda:0', grad_fn=<AddBackward0>)
0.55197841
tensor(0.1146, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [53][   20/  196]   Loss 0.105874   Top1 96.503906   Top5 100.000000   BatchTime 0.328688   LR 0.000047
0.55212647
tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
0.55229378
tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>)
0.55204076
tensor(0.1228, device='cuda:0', grad_fn=<AddBackward0>)
0.55191904
tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>)
0.55193835
tensor(0.1343, device='cuda:0', grad_fn=<AddBackward0>)
0.55202949
tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>)
0.55205572
tensor(0.1135, device='cuda:0', grad_fn=<AddBackward0>)
0.55215693
tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>)
0.55203104
tensor(0.1885, device='cuda:0', grad_fn=<AddBackward0>)
0.55209416
tensor(0.0854, device='cuda:0', grad_fn=<AddBackward0>)
0.55221707
tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
0.55215573
tensor(0.1228, device='cuda:0', grad_fn=<AddBackward0>)
0.55201513
tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
0.55177826
tensor(0.1464, device='cuda:0', grad_fn=<AddBackward0>)
0.55169028
tensor(0.1036, device='cuda:0', grad_fn=<AddBackward0>)
0.55179113
tensor(0.1196, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [53][   40/  196]   Loss 0.112494   Top1 96.250000   Top5 99.990234   BatchTime 0.289528   LR 0.000047
0.55186898
tensor(0.1145, device='cuda:0', grad_fn=<AddBackward0>)
0.55188203
tensor(0.1104, device='cuda:0', grad_fn=<AddBackward0>)
0.55193716
tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)
0.55211276
tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>)
0.55187172
tensor(0.1711, device='cuda:0', grad_fn=<AddBackward0>)
0.55190176
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
0.55216241
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.55203396
tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)
0.55181748
tensor(0.1126, device='cuda:0', grad_fn=<AddBackward0>)
0.55178899
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.55194867
tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>)
0.55201203
tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
0.55183113
tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>)
0.55216843
tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>)
0.55203098
tensor(0.1346, device='cuda:0', grad_fn=<AddBackward0>)
0.55193293
tensor(0.1234, device='cuda:0', grad_fn=<AddBackward0>)
0.55203629
tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
0.55211872
tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>)
0.55202192
tensor(0.0778, device='cuda:0', grad_fn=<AddBackward0>)
0.55188727
tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
0.55188018
tensor(0.1490, device='cuda:0', grad_fn=<AddBackward0>)
0.55189389
tensor(0.1121, device='cuda:0', grad_fn=<AddBackward0>)
0.55180591
tensor(0.0879, device='cuda:0', grad_fn=<AddBackward0>)
0.55172348
tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [53][   60/  196]   Loss 0.111138   Top1 96.354167   Top5 99.986979   BatchTime 0.276629   LR 0.000046
0.55164170
tensor(0.0918, device='cuda:0', grad_fn=<AddBackward0>)
0.55158108
tensor(0.1137, device='cuda:0', grad_fn=<AddBackward0>)
0.55155867
tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>)
0.55158174
tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>)
0.55166125
tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>)
0.55182451
tensor(0.1241, device='cuda:0', grad_fn=<AddBackward0>)
0.55172157
tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
0.55147398
tensor(0.1101, device='cuda:0', grad_fn=<AddBackward0>)
0.55162704
tensor(0.1474, device='cuda:0', grad_fn=<AddBackward0>)
0.55158448
tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
0.55162346
tensor(0.0776, device='cuda:0', grad_fn=<AddBackward0>)
0.55145347
tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
0.55146307
tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)
0.55141908
tensor(0.1496, device='cuda:0', grad_fn=<AddBackward0>)
0.55135572
tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>)
0.55130076
tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)
0.55114037
tensor(0.1574, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [53][   80/  196]   Loss 0.112569   Top1 96.298828   Top5 99.975586   BatchTime 0.269591   LR 0.000046
0.55106282
tensor(0.1278, device='cuda:0', grad_fn=<AddBackward0>)
0.55103427
tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
0.55104595
tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)
0.55107743
tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>)
0.55108476
tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>)
0.55101866
tensor(0.1499, device='cuda:0', grad_fn=<AddBackward0>)
0.55101460
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.55110788
tensor(0.1245, device='cuda:0', grad_fn=<AddBackward0>)
0.55128324
tensor(0.1493, device='cuda:0', grad_fn=<AddBackward0>)
0.55161017
tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)
0.55174839
tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>)
0.55161786
tensor(0.0899, device='cuda:0', grad_fn=<AddBackward0>)
0.55144542
tensor(0.1149, device='cuda:0', grad_fn=<AddBackward0>)
0.55129546
tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>)
0.55115867
tensor(0.1279, device='cuda:0', grad_fn=<AddBackward0>)
0.55116045
tensor(0.1267, device='cuda:0', grad_fn=<AddBackward0>)
0.55121547
tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)
0.55116910
tensor(0.1021, device='cuda:0', grad_fn=<AddBackward0>)
0.55106878
tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
0.55113012
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.55147099
tensor(0.0996, device='cuda:0', grad_fn=<AddBackward0>)
0.55144036
tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>)
0.55136460
tensor(0.1511, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [53][  100/  196]   Loss 0.115111   Top1 96.230469   Top5 99.980469   BatchTime 0.265906   LR 0.000046
0.55116355
tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>)
0.55097938
tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>)
0.55104798
tensor(0.1439, device='cuda:0', grad_fn=<AddBackward0>)
0.55109394
tensor(0.0962, device='cuda:0', grad_fn=<AddBackward0>)
0.55116040
tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
0.55113465
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
0.55097795
tensor(0.1003, device='cuda:0', grad_fn=<AddBackward0>)
0.55118430
tensor(0.1278, device='cuda:0', grad_fn=<AddBackward0>)
0.55125481
tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>)
0.55126846
tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>)
0.55117720
tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>)
0.55107039
tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>)
0.55117208
tensor(0.0854, device='cuda:0', grad_fn=<AddBackward0>)
0.55129486
tensor(0.0964, device='cuda:0', grad_fn=<AddBackward0>)
0.55110985
tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)
0.55119860
tensor(0.1384, device='cuda:0', grad_fn=<AddBackward0>)
0.55117333
tensor(0.0835, device='cuda:0', grad_fn=<AddBackward0>)
0.55122256
tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>)
0.55129230
tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
0.55108666
tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [53][  120/  196]   Loss 0.114732   Top1 96.259766   Top5 99.973958   BatchTime 0.270789   LR 0.000045
0.55087173
tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
0.55083191
tensor(0.0919, device='cuda:0', grad_fn=<AddBackward0>)
0.55080181
tensor(0.1131, device='cuda:0', grad_fn=<AddBackward0>)
0.55081278
tensor(0.1160, device='cuda:0', grad_fn=<AddBackward0>)
0.55084360
tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>)
0.55086273
tensor(0.0917, device='cuda:0', grad_fn=<AddBackward0>)
0.55098277
tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
0.55102682
tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
0.55085331
tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>)
0.55087739
tensor(0.0875, device='cuda:0', grad_fn=<AddBackward0>)
0.55083394
tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>)
0.55073601
tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>)
0.55068797
tensor(0.1119, device='cuda:0', grad_fn=<AddBackward0>)
0.55067199
tensor(0.1198, device='cuda:0', grad_fn=<AddBackward0>)
0.55058360
tensor(0.1282, device='cuda:0', grad_fn=<AddBackward0>)
0.55051368
tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>)
0.55055290
tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [53][  140/  196]   Loss 0.113328   Top1 96.272321   Top5 99.972098   BatchTime 0.268656   LR 0.000045
0.55071497
tensor(0.1451, device='cuda:0', grad_fn=<AddBackward0>)
0.55080354
tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>)
0.55098891
tensor(0.0958, device='cuda:0', grad_fn=<AddBackward0>)
0.55089682
tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>)
0.55097145
tensor(0.1223, device='cuda:0', grad_fn=<AddBackward0>)
0.55109370
tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>)
0.55093932
tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>)
0.55087328
tensor(0.0738, device='cuda:0', grad_fn=<AddBackward0>)
0.55088532
tensor(0.1185, device='cuda:0', grad_fn=<AddBackward0>)
0.55085146
tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
0.55074573
tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
0.55077732
tensor(0.1240, device='cuda:0', grad_fn=<AddBackward0>)
0.55070823
tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>)
0.55066705
tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
0.55084103
tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
0.55082029
tensor(0.1107, device='cuda:0', grad_fn=<AddBackward0>)
0.55088747
tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>)
0.55101991
tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>)
0.55099231
tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)
0.55087125
tensor(0.1191, device='cuda:0', grad_fn=<AddBackward0>)
0.55081874
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.55076849
tensor(0.1082, device='cuda:0', grad_fn=<AddBackward0>)
0.55069023
tensor(0.1437, device='cuda:0', grad_fn=<AddBackward0>)
0.55070090
tensor(0.1013, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [53][  160/  196]   Loss 0.113768   Top1 96.250000   Top5 99.973145   BatchTime 0.266142   LR 0.000044
0.55091977
tensor(0.1363, device='cuda:0', grad_fn=<AddBackward0>)
0.55071628
tensor(0.1248, device='cuda:0', grad_fn=<AddBackward0>)
0.55066592
tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>)
0.55079651
tensor(0.1106, device='cuda:0', grad_fn=<AddBackward0>)
0.55108762
tensor(0.1061, device='cuda:0', grad_fn=<AddBackward0>)
0.55102080
tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
0.55088836
tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>)
0.55081928
tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>)
0.55073410
tensor(0.0989, device='cuda:0', grad_fn=<AddBackward0>)
0.55084640
tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>)
0.55060059
tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>)
0.55063498
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.55075175
tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>)
0.55070233
tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)
0.55063462
tensor(0.1413, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [53][  180/  196]   Loss 0.113719   Top1 96.217448   Top5 99.973958   BatchTime 0.265456   LR 0.000044
0.55073076
tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
0.55085683
tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
0.55079460
tensor(0.1316, device='cuda:0', grad_fn=<AddBackward0>)
0.55082971
tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>)
0.55058849
tensor(0.0997, device='cuda:0', grad_fn=<AddBackward0>)
0.55041331
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.55040175
tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>)
0.55037320
tensor(0.1435, device='cuda:0', grad_fn=<AddBackward0>)
0.55039930
tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)
0.55058217
tensor(0.0997, device='cuda:0', grad_fn=<AddBackward0>)
0.55067974
tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
0.55067253
tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
0.55093765
tensor(0.1266, device='cuda:0', grad_fn=<AddBackward0>)
0.55108166
tensor(0.1188, device='cuda:0', grad_fn=<AddBackward0>)
0.55081069
tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 96.224    Top5: 99.974    Loss: 0.114
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 0.416583   Top1 88.652344   Top5 99.609375   BatchTime 0.119603
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1562)
features.1.conv.0 tensor(0.0514)
features.1.conv.3 tensor(0.0775)
features.1.conv.6 tensor(0.0907)
features.2.conv.0 tensor(0.1178)
features.2.conv.3 tensor(0.3410)
features.2.conv.6 tensor(0.5301)
features.3.conv.0 tensor(0.0709)
features.3.conv.3 tensor(0.0733)
features.3.conv.6 tensor(0.1089)
features.4.conv.0 tensor(0.0895)
features.4.conv.3 tensor(0.3009)
features.4.conv.6 tensor(0.3997)
features.5.conv.0 tensor(0.3315)
features.5.conv.3 tensor(0.4126)
features.5.conv.6 tensor(0.4697)
features.6.conv.0 tensor(0.0563)
features.6.conv.3 tensor(0.0503)
features.6.conv.6 tensor(0.0856)
features.7.conv.0 tensor(0.2561)
features.7.conv.3 tensor(0.4459)
features.7.conv.6 tensor(0.6412)
features.8.conv.0 tensor(0.5394)
features.8.conv.3 tensor(0.5362)
features.8.conv.6 tensor(0.6056)
features.9.conv.0 tensor(0.5372)
features.9.conv.3 tensor(0.5660)
features.9.conv.6 tensor(0.7547)
features.10.conv.0 tensor(0.0605)
features.10.conv.3 tensor(0.0885)
features.10.conv.6 tensor(0.0669)
features.11.conv.0 tensor(0.7641)
features.11.conv.3 tensor(0.6426)
features.11.conv.6 tensor(0.9026)
features.12.conv.0 tensor(0.7241)
features.12.conv.3 tensor(0.6636)
features.12.conv.6 tensor(0.8653)
features.13.conv.0 tensor(0.2803)
features.13.conv.3 tensor(0.4842)
features.13.conv.6 tensor(0.5576)
features.14.conv.0 tensor(0.9125)
features.14.conv.3 tensor(0.8218)
features.14.conv.6 tensor(0.9562)
features.15.conv.0 tensor(0.8977)
features.15.conv.3 tensor(0.8272)
features.15.conv.6 tensor(0.9626)
features.16.conv.0 tensor(0.6956)
features.16.conv.3 tensor(0.7888)
features.16.conv.6 tensor(0.9041)
conv.0 tensor(0.1682)
tensor(1409780.) 2188896.0
INFO - Validation [53][   40/   40]   Loss 0.399095   Top1 88.820000   Top5 99.670000   BatchTime 0.084409
INFO - ==> Top1: 88.820    Top5: 99.670    Loss: 0.399
INFO - ==> Sparsity : 0.644
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 88.990   Top5: 99.630]
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 88.970   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
0.55080777
tensor(0.1119, device='cuda:0', grad_fn=<AddBackward0>)
0.55085135
tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
0.55080360
tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)
0.55073702
tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
0.55068797
tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
0.55097842
tensor(0.1344, device='cuda:0', grad_fn=<AddBackward0>)
0.55105197
tensor(0.0890, device='cuda:0', grad_fn=<AddBackward0>)
0.55075544
tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>)
0.55059201
tensor(0.1085, device='cuda:0', grad_fn=<AddBackward0>)
0.55067521
tensor(0.0912, device='cuda:0', grad_fn=<AddBackward0>)
0.55048162
tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
0.55042553
tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
0.55045110
tensor(0.1511, device='cuda:0', grad_fn=<AddBackward0>)
0.55082959
tensor(0.1266, device='cuda:0', grad_fn=<AddBackward0>)
0.55087429
tensor(0.1011, device='cuda:0', grad_fn=<AddBackward0>)
0.55083901
tensor(0.0950, device='cuda:0', grad_fn=<AddBackward0>)
0.55078393
tensor(0.1008, device='cuda:0', grad_fn=<AddBackward0>)
0.55060077
tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
0.55082715
tensor(0.0967, device='cuda:0', grad_fn=<AddBackward0>)
0.55061764
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.55066574
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.55067581
tensor(0.0890, device='cuda:0', grad_fn=<AddBackward0>)
0.55055499
tensor(0.0929, device='cuda:0', grad_fn=<AddBackward0>)
0.55042171
tensor(0.0594, device='cuda:0', grad_fn=<AddBackward0>)
0.55029446
tensor(0.1011, device='cuda:0', grad_fn=<AddBackward0>)
0.55025727
tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [54][   20/  196]   Loss 0.112493   Top1 96.289062   Top5 99.960938   BatchTime 0.351016   LR 0.000043
0.55021495
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
0.55028051
tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
0.55032140
tensor(0.0556, device='cuda:0', grad_fn=<AddBackward0>)
0.54996091
tensor(0.0912, device='cuda:0', grad_fn=<AddBackward0>)
0.54961801
tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)
0.54890400
tensor(0.1188, device='cuda:0', grad_fn=<AddBackward0>)
0.54869294
tensor(0.1261, device='cuda:0', grad_fn=<AddBackward0>)
0.54861856
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.54859710
tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
0.54867226
tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>)
0.54872614
tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>)
0.54872167
tensor(0.1582, device='cuda:0', grad_fn=<AddBackward0>)
0.54874980
tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>)
0.54870087
tensor(0.1126, device='cuda:0', grad_fn=<AddBackward0>)
0.54870373
tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [54][   40/  196]   Loss 0.107580   Top1 96.445312   Top5 99.980469   BatchTime 0.313770   LR 0.000042
0.54866165
tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
0.54864019
tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>)
0.54862708
tensor(0.0756, device='cuda:0', grad_fn=<AddBackward0>)
0.54857510
tensor(0.0907, device='cuda:0', grad_fn=<AddBackward0>)
0.54851055
tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
0.54852051
tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
0.54855978
tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)
0.54850370
tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>)
0.54855132
tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
0.54853415
tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)
0.54849678
tensor(0.1052, device='cuda:0', grad_fn=<AddBackward0>)
0.54846257
tensor(0.1393, device='cuda:0', grad_fn=<AddBackward0>)
0.54845548
tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>)
0.54843342
tensor(0.1117, device='cuda:0', grad_fn=<AddBackward0>)
0.54845631
tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>)
0.54852432
tensor(0.1006, device='cuda:0', grad_fn=<AddBackward0>)
0.54849267
tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>)
0.54848677
tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>)
0.54843098
tensor(0.0679, device='cuda:0', grad_fn=<AddBackward0>)
0.54849470
tensor(0.1069, device='cuda:0', grad_fn=<AddBackward0>)
0.54849416
tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>)
0.54846472
tensor(0.1661, device='cuda:0', grad_fn=<AddBackward0>)
0.54843247
tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
0.54841572
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [54][   60/  196]   Loss 0.107649   Top1 96.445312   Top5 99.973958   BatchTime 0.292796   LR 0.000042
0.54851240
tensor(0.1006, device='cuda:0', grad_fn=<AddBackward0>)
0.54854369
tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
0.54851961
tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>)
0.54850131
tensor(0.1078, device='cuda:0', grad_fn=<AddBackward0>)
0.54850072
tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)
0.54853016
tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>)
0.54839337
tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
0.54830104
tensor(0.0774, device='cuda:0', grad_fn=<AddBackward0>)
0.54826152
tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>)
0.54825658
tensor(0.1187, device='cuda:0', grad_fn=<AddBackward0>)
0.54826963
tensor(0.1472, device='cuda:0', grad_fn=<AddBackward0>)
0.54826492
tensor(0.1701, device='cuda:0', grad_fn=<AddBackward0>)
0.54829764
tensor(0.1981, device='cuda:0', grad_fn=<AddBackward0>)
0.54840893
tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>)
0.54855114
tensor(0.0986, device='cuda:0', grad_fn=<AddBackward0>)
0.54855895
tensor(0.1396, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [54][   80/  196]   Loss 0.109684   Top1 96.391602   Top5 99.965820   BatchTime 0.281891   LR 0.000041
0.54848421
tensor(0.1099, device='cuda:0', grad_fn=<AddBackward0>)
0.54844439
tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>)
0.54844773
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.54849631
tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
0.54844052
tensor(0.1696, device='cuda:0', grad_fn=<AddBackward0>)
0.54848480
tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)
0.54849201
tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
0.54848480
tensor(0.0754, device='cuda:0', grad_fn=<AddBackward0>)
0.54844171
tensor(0.1413, device='cuda:0', grad_fn=<AddBackward0>)
0.54850942
tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>)
0.54839706
tensor(0.1543, device='cuda:0', grad_fn=<AddBackward0>)
0.54833376
tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>)
0.54832369
tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>)
0.54831457
tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
0.54825056
tensor(0.1011, device='cuda:0', grad_fn=<AddBackward0>)
0.54816335
tensor(0.1383, device='cuda:0', grad_fn=<AddBackward0>)
0.54811418
tensor(0.1348, device='cuda:0', grad_fn=<AddBackward0>)
0.54811537
tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)
0.54817086
tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>)
0.54822028
tensor(0.1366, device='cuda:0', grad_fn=<AddBackward0>)
0.54826546
tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>)
0.54817760
tensor(0.0847, device='cuda:0', grad_fn=<AddBackward0>)
0.54816455
tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>)
0.54824883
INFO - Training [54][  100/  196]   Loss 0.108380   Top1 96.414062   Top5 99.968750   BatchTime 0.275757   LR 0.000041
tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)
0.54825616
tensor(0.1009, device='cuda:0', grad_fn=<AddBackward0>)
0.54824764
tensor(0.1160, device='cuda:0', grad_fn=<AddBackward0>)
0.54822487
tensor(0.0812, device='cuda:0', grad_fn=<AddBackward0>)
0.54811484
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.54802954
tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
0.54801905
tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>)
0.54801619
tensor(0.1118, device='cuda:0', grad_fn=<AddBackward0>)
0.54800808
tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>)
0.54804313
tensor(0.1104, device='cuda:0', grad_fn=<AddBackward0>)
0.54816645
tensor(0.1598, device='cuda:0', grad_fn=<AddBackward0>)
0.54818112
tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>)
0.54806483
tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>)
0.54806215
tensor(0.1550, device='cuda:0', grad_fn=<AddBackward0>)
0.54809511
tensor(0.1849, device='cuda:0', grad_fn=<AddBackward0>)
0.54813141
tensor(0.1047, device='cuda:0', grad_fn=<AddBackward0>)
0.54808223
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.54810482
tensor(0.0831, device='cuda:0', grad_fn=<AddBackward0>)
0.54810482
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.54804343
tensor(0.0858, device='cuda:0', grad_fn=<AddBackward0>)
0.54812777
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [54][  120/  196]   Loss 0.108684   Top1 96.419271   Top5 99.964193   BatchTime 0.277265   LR 0.000040
0.54817259
tensor(0.0824, device='cuda:0', grad_fn=<AddBackward0>)
0.54815251
tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>)
0.54805237
tensor(0.1354, device='cuda:0', grad_fn=<AddBackward0>)
0.54798776
tensor(0.1273, device='cuda:0', grad_fn=<AddBackward0>)
0.54800266
tensor(0.1355, device='cuda:0', grad_fn=<AddBackward0>)
0.54803711
tensor(0.0789, device='cuda:0', grad_fn=<AddBackward0>)
0.54812354
tensor(0.1182, device='cuda:0', grad_fn=<AddBackward0>)
0.54817152
tensor(0.0989, device='cuda:0', grad_fn=<AddBackward0>)
0.54819524
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
0.54808116
tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
0.54798251
tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>)
0.54798675
tensor(0.0877, device='cuda:0', grad_fn=<AddBackward0>)
0.54797602
tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)
0.54793912
tensor(0.1234, device='cuda:0', grad_fn=<AddBackward0>)
0.54795510
tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>)
0.54799461
tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>)
0.54800534
tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>)
0.54804564
tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>)
0.54797041
tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
0.54796445
tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [54][  140/  196]   Loss 0.107873   Top1 96.434152   Top5 99.966518   BatchTime 0.281656   LR 0.000040
0.54799092
tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
0.54802310
tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>)
0.54788041
tensor(0.1214, device='cuda:0', grad_fn=<AddBackward0>)
0.54783845
tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>)
0.54789263
tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>)
0.54798621
tensor(0.1479, device='cuda:0', grad_fn=<AddBackward0>)
0.54796940
tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
0.54799199
tensor(0.1222, device='cuda:0', grad_fn=<AddBackward0>)
0.54800898
tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
0.54797328
tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
0.54788005
tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
0.54788291
tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
0.54782152
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
0.54781276
tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>)
0.54781199
tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
0.54774362
tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>)
0.54773021
tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>)
0.54786879
tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
0.54782003
tensor(0.1249, device='cuda:0', grad_fn=<AddBackward0>)
0.54775316
tensor(0.0776, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [54][  160/  196]   Loss 0.108241   Top1 96.435547   Top5 99.963379   BatchTime 0.284125   LR 0.000039
0.54770470
tensor(0.0417, device='cuda:0', grad_fn=<AddBackward0>)
0.54767537
tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>)
0.54770738
tensor(0.1001, device='cuda:0', grad_fn=<AddBackward0>)
0.54771513
tensor(0.0867, device='cuda:0', grad_fn=<AddBackward0>)
0.54773736
tensor(0.0789, device='cuda:0', grad_fn=<AddBackward0>)
0.54782248
tensor(0.1101, device='cuda:0', grad_fn=<AddBackward0>)
0.54782456
tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
0.54766721
tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
0.54761970
tensor(0.0881, device='cuda:0', grad_fn=<AddBackward0>)
0.54761362
tensor(0.1196, device='cuda:0', grad_fn=<AddBackward0>)
0.54761517
tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>)
0.54762232
tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
0.54762089
tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>)
0.54767513
tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>)
0.54767781
tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>)
0.54765821
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.54774278
tensor(0.1243, device='cuda:0', grad_fn=<AddBackward0>)
0.54766816
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
0.54766732
tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>)
0.54769671
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [54][  180/  196]   Loss 0.108026   Top1 96.486545   Top5 99.967448   BatchTime 0.285764   LR 0.000039
0.54764432
tensor(0.1519, device='cuda:0', grad_fn=<AddBackward0>)
0.54757601
tensor(0.1229, device='cuda:0', grad_fn=<AddBackward0>)
0.54763347
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.54765612
tensor(0.1161, device='cuda:0', grad_fn=<AddBackward0>)
0.54762197
tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>)
0.54763567
tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>)
0.54766047
tensor(0.1067, device='cuda:0', grad_fn=<AddBackward0>)
0.54759938
tensor(0.1423, device='cuda:0', grad_fn=<AddBackward0>)
0.54759210
tensor(0.0705, device='cuda:0', grad_fn=<AddBackward0>)
0.54761863
tensor(0.1361, device='cuda:0', grad_fn=<AddBackward0>)
0.54753542
tensor(0.0532, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 96.468    Top5: 99.968    Loss: 0.109
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [54][   20/   40]   Loss 0.409909   Top1 88.554688   Top5 99.550781   BatchTime 0.123440
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1660)
features.1.conv.0 tensor(0.0482)
features.1.conv.3 tensor(0.0752)
features.1.conv.6 tensor(0.0890)
features.2.conv.0 tensor(0.1181)
features.2.conv.3 tensor(0.3426)
features.2.conv.6 tensor(0.5327)
features.3.conv.0 tensor(0.0703)
features.3.conv.3 tensor(0.0772)
features.3.conv.6 tensor(0.1079)
features.4.conv.0 tensor(0.0892)
features.4.conv.3 tensor(0.3003)
features.4.conv.6 tensor(0.4040)
features.5.conv.0 tensor(0.3472)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4705)
features.6.conv.0 tensor(0.0550)
features.6.conv.3 tensor(0.0509)
features.6.conv.6 tensor(0.0845)
features.7.conv.0 tensor(0.2621)
features.7.conv.3 tensor(0.4450)
features.7.conv.6 tensor(0.6438)
features.8.conv.0 tensor(0.5441)
features.8.conv.3 tensor(0.5388)
features.8.conv.6 tensor(0.6075)
features.9.conv.0 tensor(0.5323)
features.9.conv.3 tensor(0.5657)
features.9.conv.6 tensor(0.7557)
features.10.conv.0 tensor(0.0594)
features.10.conv.3 tensor(0.0900)
features.10.conv.6 tensor(0.0679)
features.11.conv.0 tensor(0.7672)
features.11.conv.3 tensor(0.6429)
features.11.conv.6 tensor(0.9025)
features.12.conv.0 tensor(0.7281)
features.12.conv.3 tensor(0.6642)
features.12.conv.6 tensor(0.8664)
features.13.conv.0 tensor(0.2976)
features.13.conv.3 tensor(0.4832)
features.13.conv.6 tensor(0.5695)
features.14.conv.0 tensor(0.9126)
features.14.conv.3 tensor(0.8218)
features.14.conv.6 tensor(0.9570)
features.15.conv.0 tensor(0.8989)
features.15.conv.3 tensor(0.8269)
features.15.conv.6 tensor(0.9632)
features.16.conv.0 tensor(0.6977)
features.16.conv.3 tensor(0.7889)
features.16.conv.6 tensor(0.9060)
conv.0 tensor(0.1751)
tensor(1416846.) 2188896.0
INFO - Validation [54][   40/   40]   Loss 0.393569   Top1 88.950000   Top5 99.680000   BatchTime 0.089348
INFO - ==> Top1: 88.950    Top5: 99.680    Loss: 0.394
INFO - ==> Sparsity : 0.647
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 88.990   Top5: 99.630]
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 88.970   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
0.54754966
tensor(0.0961, device='cuda:0', grad_fn=<AddBackward0>)
0.54754311
tensor(0.0760, device='cuda:0', grad_fn=<AddBackward0>)
0.54748392
tensor(0.1155, device='cuda:0', grad_fn=<AddBackward0>)
0.54739815
tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>)
0.54740560
tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)
0.54750854
tensor(0.1586, device='cuda:0', grad_fn=<AddBackward0>)
0.54734552
tensor(0.0825, device='cuda:0', grad_fn=<AddBackward0>)
0.54728526
tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>)
0.54731506
tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
0.54734284
tensor(0.1307, device='cuda:0', grad_fn=<AddBackward0>)
0.54729468
tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)
0.54724699
tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
0.54730856
tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)
0.54737478
tensor(0.1001, device='cuda:0', grad_fn=<AddBackward0>)
0.54729348
tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>)
0.54725236
tensor(0.0692, device='cuda:0', grad_fn=<AddBackward0>)
0.54725653
tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>)
0.54725629
tensor(0.0690, device='cuda:0', grad_fn=<AddBackward0>)
0.54721910
tensor(0.0914, device='cuda:0', grad_fn=<AddBackward0>)
0.54721224
tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
0.54725736
tensor(0.0863, device='cuda:0', grad_fn=<AddBackward0>)
0.54731041
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
0.54727429
tensor(0.1057, device='cuda:0', grad_fn=<AddBackward0>)
0.54727060
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.54727679
tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [55][   20/  196]   Loss 0.090847   Top1 97.167969   Top5 99.980469   BatchTime 0.371502   LR 0.000038
0.54734129
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.54728347
tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>)
0.54722929
tensor(0.1188, device='cuda:0', grad_fn=<AddBackward0>)
0.54724121
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
0.54727030
tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
0.54730159
tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>)
0.54723877
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.54722327
tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
0.54713076
tensor(0.0535, device='cuda:0', grad_fn=<AddBackward0>)
0.54705673
tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)
0.54710996
tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
0.54714352
tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)
0.54713386
tensor(0.1001, device='cuda:0', grad_fn=<AddBackward0>)
0.54712540
tensor(0.0738, device='cuda:0', grad_fn=<AddBackward0>)
0.54710078
tensor(0.1043, device='cuda:0', grad_fn=<AddBackward0>)
0.54726040
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.54732305
tensor(0.0863, device='cuda:0', grad_fn=<AddBackward0>)
0.54722250
tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>)
0.54718566
tensor(0.1587, device='cuda:0', grad_fn=<AddBackward0>)
0.54718357
tensor(0.0702, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [55][   40/  196]   Loss 0.093132   Top1 97.041016   Top5 99.990234   BatchTime 0.338907   LR 0.000038
0.54714608
tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)
0.54711658
tensor(0.1277, device='cuda:0', grad_fn=<AddBackward0>)
0.54709488
tensor(0.1193, device='cuda:0', grad_fn=<AddBackward0>)
0.54697901
tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
0.54692680
tensor(0.0825, device='cuda:0', grad_fn=<AddBackward0>)
0.54694462
tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
0.54700267
tensor(0.1001, device='cuda:0', grad_fn=<AddBackward0>)
0.54706681
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
0.54701412
tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>)
0.54699183
tensor(0.0890, device='cuda:0', grad_fn=<AddBackward0>)
0.54715079
tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)
0.54709482
tensor(0.0946, device='cuda:0', grad_fn=<AddBackward0>)
0.54706252
tensor(0.0729, device='cuda:0', grad_fn=<AddBackward0>)
0.54706591
tensor(0.1043, device='cuda:0', grad_fn=<AddBackward0>)
0.54701167
tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
0.54706627
tensor(0.0732, device='cuda:0', grad_fn=<AddBackward0>)
0.54704374
tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>)
0.54703957
tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
0.54705161
tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
0.54700625
tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
0.54709131
tensor(0.0959, device='cuda:0', grad_fn=<AddBackward0>)
0.54703671
tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [55][   60/  196]   Loss 0.094645   Top1 96.933594   Top5 99.986979   BatchTime 0.322035   LR 0.000037
0.54696655
tensor(0.1405, device='cuda:0', grad_fn=<AddBackward0>)
0.54687780
tensor(0.0820, device='cuda:0', grad_fn=<AddBackward0>)
0.54687530
tensor(0.1248, device='cuda:0', grad_fn=<AddBackward0>)
0.54691881
tensor(0.1304, device='cuda:0', grad_fn=<AddBackward0>)
0.54687172
tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>)
0.54682958
tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>)
0.54683465
tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
0.54685438
tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
0.54693943
tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>)
0.54687196
tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
0.54682869
tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
0.54677236
tensor(0.1374, device='cuda:0', grad_fn=<AddBackward0>)
0.54676259
tensor(0.1253, device='cuda:0', grad_fn=<AddBackward0>)
0.54678583
tensor(0.1476, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [55][   80/  196]   Loss 0.097748   Top1 96.791992   Top5 99.975586   BatchTime 0.310129   LR 0.000037
0.54671073
tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
0.54669279
tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
0.54665005
tensor(0.1184, device='cuda:0', grad_fn=<AddBackward0>)
0.54668069
tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>)
0.54672277
tensor(0.1038, device='cuda:0', grad_fn=<AddBackward0>)
0.54677367
tensor(0.1253, device='cuda:0', grad_fn=<AddBackward0>)
0.54679614
tensor(0.0808, device='cuda:0', grad_fn=<AddBackward0>)
0.54690468
tensor(0.1381, device='cuda:0', grad_fn=<AddBackward0>)
0.54678881
tensor(0.0812, device='cuda:0', grad_fn=<AddBackward0>)
0.54676712
tensor(0.1155, device='cuda:0', grad_fn=<AddBackward0>)
0.54687285
tensor(0.1425, device='cuda:0', grad_fn=<AddBackward0>)
0.54678732
tensor(0.1393, device='cuda:0', grad_fn=<AddBackward0>)
0.54672223
tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>)
0.54670274
tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
0.54668516
tensor(0.0954, device='cuda:0', grad_fn=<AddBackward0>)
0.54671317
tensor(0.1286, device='cuda:0', grad_fn=<AddBackward0>)
0.54675394
tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>)
0.54674447
tensor(0.1011, device='cuda:0', grad_fn=<AddBackward0>)
0.54676098
tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>)
0.54672521
tensor(0.1616, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [55][  100/  196]   Loss 0.100182   Top1 96.722656   Top5 99.980469   BatchTime 0.306942   LR 0.000036
0.54676735
tensor(0.1198, device='cuda:0', grad_fn=<AddBackward0>)
0.54667836
tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
0.54667842
tensor(0.1158, device='cuda:0', grad_fn=<AddBackward0>)
0.54668230
tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>)
0.54666108
tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
0.54667592
tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>)
0.54679972
tensor(0.1297, device='cuda:0', grad_fn=<AddBackward0>)
0.54680878
tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)
0.54682577
tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
0.54668069
tensor(0.0906, device='cuda:0', grad_fn=<AddBackward0>)
0.54667711
tensor(0.1573, device='cuda:0', grad_fn=<AddBackward0>)
0.54663521
tensor(0.1160, device='cuda:0', grad_fn=<AddBackward0>)
0.54654765
tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)
0.54651606
tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>)
0.54650539
tensor(0.1158, device='cuda:0', grad_fn=<AddBackward0>)
0.54653674
tensor(0.1006, device='cuda:0', grad_fn=<AddBackward0>)
0.54660660
tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>)
0.54663843
tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>)
0.54662561
tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
0.54661679
tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
0.54662657
tensor(0.1450, device='cuda:0', grad_fn=<AddBackward0>)
0.54661512
tensor(0.0790, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [55][  120/  196]   Loss 0.101779   Top1 96.634115   Top5 99.983724   BatchTime 0.302655   LR 0.000036
0.54652017
tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>)
0.54646593
tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
0.54644829
tensor(0.1207, device='cuda:0', grad_fn=<AddBackward0>)
0.54643172
tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
0.54640746
tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
0.54640025
tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
0.54644775
tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
0.54652935
tensor(0.0749, device='cuda:0', grad_fn=<AddBackward0>)
0.54653621
tensor(0.1110, device='cuda:0', grad_fn=<AddBackward0>)
0.54652178
tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
0.54653877
tensor(0.1116, device='cuda:0', grad_fn=<AddBackward0>)
0.54650348
tensor(0.1569, device='cuda:0', grad_fn=<AddBackward0>)
0.54646462
tensor(0.1360, device='cuda:0', grad_fn=<AddBackward0>)
0.54647422
tensor(0.1030, device='cuda:0', grad_fn=<AddBackward0>)
0.54643869
tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)
0.54647553
tensor(0.0893, device='cuda:0', grad_fn=<AddBackward0>)
0.54643273
tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>)
0.54635811
tensor(0.1282, device='cuda:0', grad_fn=<AddBackward0>)
0.54631042
tensor(0.0779, device='cuda:0', grad_fn=<AddBackward0>)
0.54632413
tensor(0.0776, device='cuda:0', grad_fn=<AddBackward0>)
0.54634732
tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>)
0.54641676
tensor(0.1762, device='cuda:0', grad_fn=<AddBackward0>)
0.54638368
tensor(0.1329, device='cuda:0', grad_fn=<AddBackward0>)
0.54636407
tensor(0.1055, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [55][  140/  196]   Loss 0.103192   Top1 96.595982   Top5 99.986049   BatchTime 0.294763   LR 0.000035
0.54637372
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
0.54643416
tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>)
0.54642224
tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
0.54639202
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.54633170
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
0.54629248
tensor(0.1018, device='cuda:0', grad_fn=<AddBackward0>)
0.54623604
tensor(0.0762, device='cuda:0', grad_fn=<AddBackward0>)
0.54621941
tensor(0.1414, device='cuda:0', grad_fn=<AddBackward0>)
0.54620570
tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>)
0.54616332
tensor(0.1423, device='cuda:0', grad_fn=<AddBackward0>)
0.54616785
tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>)
0.54619843
tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>)
0.54627264
tensor(0.0645, device='cuda:0', grad_fn=<AddBackward0>)
0.54627329
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.54622781
tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
0.54632735
tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [55][  160/  196]   Loss 0.104044   Top1 96.564941   Top5 99.982910   BatchTime 0.289130   LR 0.000035
0.54626042
tensor(0.1947, device='cuda:0', grad_fn=<AddBackward0>)
0.54628766
tensor(0.1351, device='cuda:0', grad_fn=<AddBackward0>)
0.54626137
tensor(0.0888, device='cuda:0', grad_fn=<AddBackward0>)
0.54624403
tensor(0.1364, device='cuda:0', grad_fn=<AddBackward0>)
0.54623693
tensor(0.1298, device='cuda:0', grad_fn=<AddBackward0>)
0.54621482
tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>)
0.54622030
tensor(0.0867, device='cuda:0', grad_fn=<AddBackward0>)
0.54627734
tensor(0.1182, device='cuda:0', grad_fn=<AddBackward0>)
0.54623824
tensor(0.1477, device='cuda:0', grad_fn=<AddBackward0>)
0.54621202
tensor(0.0710, device='cuda:0', grad_fn=<AddBackward0>)
0.54627186
tensor(0.1308, device='cuda:0', grad_fn=<AddBackward0>)
0.54623491
tensor(0.1117, device='cuda:0', grad_fn=<AddBackward0>)
0.54618609
tensor(0.0484, device='cuda:0', grad_fn=<AddBackward0>)
0.54616076
tensor(0.1131, device='cuda:0', grad_fn=<AddBackward0>)
0.54614735
tensor(0.1231, device='cuda:0', grad_fn=<AddBackward0>)
0.54606092
tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
0.54609156
tensor(0.1096, device='cuda:0', grad_fn=<AddBackward0>)
0.54610795
tensor(0.1429, device='cuda:0', grad_fn=<AddBackward0>)
0.54610080
tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>)
0.54615873
tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
0.54610562
tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
0.54608530
tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
0.54603106
tensor(0.0993, device='cuda:0', grad_fn=<AddBackward0>)
0.54596239
tensor(0.1023, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [55][  180/  196]   Loss 0.104625   Top1 96.555990   Top5 99.980469   BatchTime 0.284874   LR 0.000034
0.54596275
tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>)
0.54598749
tensor(0.0720, device='cuda:0', grad_fn=<AddBackward0>)
0.54603231
tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)
0.54592091
tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
0.54590923
tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>)
0.54587084
tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>)
0.54592836
tensor(0.1446, device='cuda:0', grad_fn=<AddBackward0>)
0.54593432
tensor(0.1308, device='cuda:0', grad_fn=<AddBackward0>)
0.54591715
tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 96.550    Top5: 99.980    Loss: 0.105
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2986)
features.0.conv.3 tensor(0.1602)
features.1.conv.0 tensor(0.0501)
features.1.conv.3 tensor(0.0752)
features.1.conv.6 tensor(0.0894)
features.2.conv.0 tensor(0.1247)
features.2.conv.3 tensor(0.3441)
features.2.conv.6 tensor(0.5321)
features.3.conv.0 tensor(0.0703)
features.3.conv.3 tensor(0.0748)
features.3.conv.6 tensor(0.1081)
features.4.conv.0 tensor(0.0918)
features.4.conv.3 tensor(0.3003)
features.4.conv.6 tensor(0.4048)
features.5.conv.0 tensor(0.3573)
features.5.conv.3 tensor(0.4120)
features.5.conv.6 tensor(0.4717)
features.6.conv.0 tensor(0.0550)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0837)
features.7.conv.0 tensor(0.2664)
features.7.conv.3 tensor(0.4459)
features.7.conv.6 tensor(0.6489)
features.8.conv.0 tensor(0.5416)
features.8.conv.3 tensor(0.5382)
features.8.conv.6 tensor(0.6086)
features.9.conv.0 tensor(0.5290)
features.9.conv.3 tensor(0.5666)
features.9.conv.6 tensor(0.7564)
features.10.conv.0 tensor(0.0603)
features.10.conv.3 tensor(0.0897)
features.10.conv.6 tensor(0.0675)
features.11.conv.0 tensor(0.7681)
features.11.conv.3 tensor(0.6429)
features.11.conv.6 tensor(0.9023)
features.12.conv.0 tensor(0.7314)
features.12.conv.3 tensor(0.6630)
features.12.conv.6 tensor(0.8659)
features.13.conv.0 tensor(0.3074)
features.13.conv.3 tensor(0.4842)
features.13.conv.6 tensor(0.5858)
features.14.conv.0 tensor(0.9135)
features.14.conv.3 tensor(0.8220)
features.14.conv.6 tensor(0.9573)
features.15.conv.0 tensor(0.8995)
features.15.conv.3 tensor(0.8271)
features.15.conv.6 tensor(0.9634)
features.16.conv.0 tensor(0.7012)
features.16.conv.3 tensor(0.7890)
features.16.conv.6 tensor(0.9081)
conv.0 tensor(0.1759)
tensor(1421116.) 2188896.0
INFO - Validation [55][   20/   40]   Loss 0.399591   Top1 89.003906   Top5 99.550781   BatchTime 0.122135
INFO - Validation [55][   40/   40]   Loss 0.386799   Top1 89.100000   Top5 99.690000   BatchTime 0.089638
INFO - ==> Top1: 89.100    Top5: 99.690    Loss: 0.387
INFO - ==> Sparsity : 0.649
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [55][Top1: 89.100   Top5: 99.690]
INFO - Scoreboard best 3 ==> Epoch [50][Top1: 88.990   Top5: 99.630]
0.54600573
tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
0.54611331
tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)
0.54606998
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
0.54605561
tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
0.54601991
tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
0.54599011
tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
0.54597342
tensor(0.0993, device='cuda:0', grad_fn=<AddBackward0>)
0.54597443
tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)
0.54601705
tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)
0.54599297
tensor(0.1363, device='cuda:0', grad_fn=<AddBackward0>)
0.54600513
tensor(0.1150, device='cuda:0', grad_fn=<AddBackward0>)
0.54592133
tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
0.54582572
tensor(0.1071, device='cuda:0', grad_fn=<AddBackward0>)
0.54581046
tensor(0.0863, device='cuda:0', grad_fn=<AddBackward0>)
0.54584175
tensor(0.0844, device='cuda:0', grad_fn=<AddBackward0>)
0.54582644
tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>)
0.54579908
tensor(0.1076, device='cuda:0', grad_fn=<AddBackward0>)
0.54588115
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.54587209
tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>)
0.54589957
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.54591286
tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>)
0.54585713
tensor(0.1014, device='cuda:0', grad_fn=<AddBackward0>)
0.54579884
tensor(0.1228, device='cuda:0', grad_fn=<AddBackward0>)
0.54575080
tensor(0.0915, device='cuda:0', grad_fn=<AddBackward0>)
0.54582238
tensor(0.0962, device='cuda:0', grad_fn=<AddBackward0>)
0.54584467
tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)
0.54578906
tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [56][   20/  196]   Loss 0.094886   Top1 96.972656   Top5 100.000000   BatchTime 0.330676   LR 0.000034
0.54576916
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.54573798
tensor(0.0676, device='cuda:0', grad_fn=<AddBackward0>)
0.54566121
tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)
0.54564703
tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
0.54566568
tensor(0.1207, device='cuda:0', grad_fn=<AddBackward0>)
0.54557574
tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
0.54553396
tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>)
0.54550314
tensor(0.0902, device='cuda:0', grad_fn=<AddBackward0>)
0.54544550
tensor(0.1662, device='cuda:0', grad_fn=<AddBackward0>)
0.54543328
tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>)
0.54542691
tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>)
0.54536104
tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>)
0.54529071
tensor(0.1005, device='cuda:0', grad_fn=<AddBackward0>)
0.54520899
tensor(0.0871, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [56][   40/  196]   Loss 0.099974   Top1 96.806641   Top5 99.990234   BatchTime 0.296764   LR 0.000033
0.54522896
tensor(0.1050, device='cuda:0', grad_fn=<AddBackward0>)
0.54518205
tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>)
0.54519290
tensor(0.1105, device='cuda:0', grad_fn=<AddBackward0>)
0.54520899
tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
0.54529089
tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>)
0.54525143
tensor(0.1104, device='cuda:0', grad_fn=<AddBackward0>)
0.54508549
tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>)
0.54493511
tensor(0.0820, device='cuda:0', grad_fn=<AddBackward0>)
0.54476023
tensor(0.0862, device='cuda:0', grad_fn=<AddBackward0>)
0.54443336
tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>)
0.54428107
tensor(0.1441, device='cuda:0', grad_fn=<AddBackward0>)
0.54420334
tensor(0.0776, device='cuda:0', grad_fn=<AddBackward0>)
0.54423320
tensor(0.1179, device='cuda:0', grad_fn=<AddBackward0>)
0.54419756
tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>)
0.54407549
tensor(0.1000, device='cuda:0', grad_fn=<AddBackward0>)
0.54404813
tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
0.54398036
tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
0.54391569
tensor(0.0623, device='cuda:0', grad_fn=<AddBackward0>)
0.54388100
tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
0.54381132
tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>)
0.54363084
tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
0.54357749
tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [56][   60/  196]   Loss 0.097481   Top1 96.861979   Top5 99.986979   BatchTime 0.293189   LR 0.000033
0.54356807
tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
0.54360795
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
0.54355568
tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>)
0.54348397
tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)
0.54345232
tensor(0.1261, device='cuda:0', grad_fn=<AddBackward0>)
0.54344136
tensor(0.1150, device='cuda:0', grad_fn=<AddBackward0>)
0.54347855
tensor(0.1298, device='cuda:0', grad_fn=<AddBackward0>)
0.54343945
tensor(0.1645, device='cuda:0', grad_fn=<AddBackward0>)
0.54338127
tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)
0.54333937
tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
0.54333889
tensor(0.0771, device='cuda:0', grad_fn=<AddBackward0>)
0.54330963
tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>)
0.54328167
tensor(0.1489, device='cuda:0', grad_fn=<AddBackward0>)
0.54329002
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.54327875
tensor(0.0993, device='cuda:0', grad_fn=<AddBackward0>)
0.54327565
tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
0.54327488
tensor(0.1325, device='cuda:0', grad_fn=<AddBackward0>)
0.54327410
tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)
0.54326260
tensor(0.1126, device='cuda:0', grad_fn=<AddBackward0>)
0.54324156
tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>)
0.54322106
tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [56][   80/  196]   Loss 0.100329   Top1 96.752930   Top5 99.990234   BatchTime 0.286820   LR 0.000032
0.54322928
tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
0.54322404
tensor(0.0911, device='cuda:0', grad_fn=<AddBackward0>)
0.54322284
tensor(0.0861, device='cuda:0', grad_fn=<AddBackward0>)
0.54322207
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
0.54320675
tensor(0.1000, device='cuda:0', grad_fn=<AddBackward0>)
0.54320055
tensor(0.1196, device='cuda:0', grad_fn=<AddBackward0>)
0.54320955
tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>)
0.54320455
tensor(0.1072, device='cuda:0', grad_fn=<AddBackward0>)
0.54320401
tensor(0.0822, device='cuda:0', grad_fn=<AddBackward0>)
0.54320198
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.54318959
tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>)
0.54317904
tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>)
0.54317772
tensor(0.0749, device='cuda:0', grad_fn=<AddBackward0>)
0.54316479
tensor(0.1496, device='cuda:0', grad_fn=<AddBackward0>)
0.54315388
tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
0.54315174
tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>)
0.54313207
tensor(0.0865, device='cuda:0', grad_fn=<AddBackward0>)
0.54309720
tensor(0.1116, device='cuda:0', grad_fn=<AddBackward0>)
0.54308456
tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>)
0.54308176
tensor(0.0798, device='cuda:0', grad_fn=<AddBackward0>)
0.54306614
tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>)
0.54305810
tensor(0.0707, device='cuda:0', grad_fn=<AddBackward0>)
0.54305220
tensor(0.1420, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [56][  100/  196]   Loss 0.099815   Top1 96.746094   Top5 99.988281   BatchTime 0.285704   LR 0.000032
0.54304314
tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)
0.54303336
tensor(0.1045, device='cuda:0', grad_fn=<AddBackward0>)
0.54301989
tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>)
0.54302329
tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>)
0.54301691
tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
0.54300082
tensor(0.0757, device='cuda:0', grad_fn=<AddBackward0>)
0.54298306
tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
0.54296565
tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>)
0.54295695
tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
0.54294497
tensor(0.1405, device='cuda:0', grad_fn=<AddBackward0>)
0.54293340
tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>)
0.54294205
tensor(0.0853, device='cuda:0', grad_fn=<AddBackward0>)
0.54294229
tensor(0.0707, device='cuda:0', grad_fn=<AddBackward0>)
0.54293787
tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [56][  120/  196]   Loss 0.098223   Top1 96.822917   Top5 99.986979   BatchTime 0.282620   LR 0.000031
0.54293168
tensor(0.0907, device='cuda:0', grad_fn=<AddBackward0>)
0.54293305
tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)
0.54294020
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
0.54293084
tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
0.54293078
tensor(0.0588, device='cuda:0', grad_fn=<AddBackward0>)
0.54292065
tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>)
0.54291838
tensor(0.1024, device='cuda:0', grad_fn=<AddBackward0>)
0.54291075
tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
0.54291153
tensor(0.1348, device='cuda:0', grad_fn=<AddBackward0>)
0.54289514
tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>)
0.54289895
tensor(0.1538, device='cuda:0', grad_fn=<AddBackward0>)
0.54289120
tensor(0.1316, device='cuda:0', grad_fn=<AddBackward0>)
0.54289639
tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)
0.54289740
tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>)
0.54289150
tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>)
0.54287565
tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
0.54286557
tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
0.54286027
tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
0.54284859
tensor(0.0926, device='cuda:0', grad_fn=<AddBackward0>)
0.54283369
tensor(0.0902, device='cuda:0', grad_fn=<AddBackward0>)
0.54281527
tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)
0.54280531
tensor(0.0865, device='cuda:0', grad_fn=<AddBackward0>)
0.54280603
tensor(0.1158, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [56][  140/  196]   Loss 0.098262   Top1 96.813616   Top5 99.983259   BatchTime 0.281105   LR 0.000031
0.54280591
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
0.54279941
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.54279464
tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
0.54277891
tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>)
0.54276913
tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>)
0.54276669
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.54276222
tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
0.54275870
tensor(0.0907, device='cuda:0', grad_fn=<AddBackward0>)
0.54275435
tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
0.54274547
tensor(0.1205, device='cuda:0', grad_fn=<AddBackward0>)
0.54274434
tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>)
0.54273897
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.54273921
tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>)
0.54273695
tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)
0.54273582
tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>)
0.54273278
tensor(0.0991, device='cuda:0', grad_fn=<AddBackward0>)
0.54272014
tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
0.54270911
tensor(0.0981, device='cuda:0', grad_fn=<AddBackward0>)
0.54270416
tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>)
0.54272109
tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
0.54271787
tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>)
0.54269880
tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
0.54269302
tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>)
0.54269826
tensor(0.0806, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [56][  160/  196]   Loss 0.098203   Top1 96.823730   Top5 99.978027   BatchTime 0.276980   LR 0.000031
0.54269147
tensor(0.1278, device='cuda:0', grad_fn=<AddBackward0>)
0.54267257
tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>)
0.54265988
tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>)
0.54265380
tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>)
0.54264718
tensor(0.0917, device='cuda:0', grad_fn=<AddBackward0>)
0.54263979
tensor(0.1041, device='cuda:0', grad_fn=<AddBackward0>)
0.54262972
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.54261792
tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>)
0.54260778
tensor(0.1126, device='cuda:0', grad_fn=<AddBackward0>)
0.54258859
tensor(0.1093, device='cuda:0', grad_fn=<AddBackward0>)
0.54258519
tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>)
0.54259121
tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>)
0.54258251
tensor(0.0816, device='cuda:0', grad_fn=<AddBackward0>)
0.54256892
tensor(0.1042, device='cuda:0', grad_fn=<AddBackward0>)
0.54254615
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.54254073
tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [56][  180/  196]   Loss 0.098608   Top1 96.809896   Top5 99.978299   BatchTime 0.274012   LR 0.000030
0.54252380
tensor(0.1659, device='cuda:0', grad_fn=<AddBackward0>)
0.54251391
tensor(0.1361, device='cuda:0', grad_fn=<AddBackward0>)
0.54249460
tensor(0.0992, device='cuda:0', grad_fn=<AddBackward0>)
0.54248488
tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
0.54247487
tensor(0.0987, device='cuda:0', grad_fn=<AddBackward0>)
0.54246253
tensor(0.1444, device='cuda:0', grad_fn=<AddBackward0>)
0.54245198
tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
0.54244477
tensor(0.1150, device='cuda:0', grad_fn=<AddBackward0>)
0.54244339
tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)
0.54243237
tensor(0.1543, device='cuda:0', grad_fn=<AddBackward0>)
0.54243118
tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
0.54242080
tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 96.780    Top5: 99.974    Loss: 0.100
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 0.403601   Top1 88.906250   Top5 99.589844   BatchTime 0.126412
INFO - Validation [56][   40/   40]   Loss 0.389197   Top1 89.140000   Top5 99.650000   BatchTime 0.089784
INFO - ==> Top1: 89.140    Top5: 99.650    Loss: 0.389
INFO - ==> Sparsity : 0.652
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [56][Top1: 89.140   Top5: 99.650]
INFO - Scoreboard best 3 ==> Epoch [55][Top1: 89.100   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1719)
features.1.conv.0 tensor(0.0534)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0933)
features.2.conv.0 tensor(0.1227)
features.2.conv.3 tensor(0.3441)
features.2.conv.6 tensor(0.5330)
features.3.conv.0 tensor(0.0729)
features.3.conv.3 tensor(0.0756)
features.3.conv.6 tensor(0.1107)
features.4.conv.0 tensor(0.0959)
features.4.conv.3 tensor(0.3027)
features.4.conv.6 tensor(0.4071)
features.5.conv.0 tensor(0.3576)
features.5.conv.3 tensor(0.4115)
features.5.conv.6 tensor(0.4748)
features.6.conv.0 tensor(0.0565)
features.6.conv.3 tensor(0.0492)
features.6.conv.6 tensor(0.0828)
features.7.conv.0 tensor(0.2776)
features.7.conv.3 tensor(0.4459)
features.7.conv.6 tensor(0.6517)
features.8.conv.0 tensor(0.5516)
features.8.conv.3 tensor(0.5376)
features.8.conv.6 tensor(0.6142)
features.9.conv.0 tensor(0.5330)
features.9.conv.3 tensor(0.5660)
features.9.conv.6 tensor(0.7580)
features.10.conv.0 tensor(0.0632)
features.10.conv.3 tensor(0.0903)
features.10.conv.6 tensor(0.0675)
features.11.conv.0 tensor(0.7706)
features.11.conv.3 tensor(0.6431)
features.11.conv.6 tensor(0.9020)
features.12.conv.0 tensor(0.7341)
features.12.conv.3 tensor(0.6632)
features.12.conv.6 tensor(0.8672)
features.13.conv.0 tensor(0.3152)
features.13.conv.3 tensor(0.4838)
features.13.conv.6 tensor(0.5939)
features.14.conv.0 tensor(0.9137)
features.14.conv.3 tensor(0.8218)
features.14.conv.6 tensor(0.9576)
features.15.conv.0 tensor(0.9001)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9635)
features.16.conv.0 tensor(0.7054)
features.16.conv.3 tensor(0.7888)
features.16.conv.6 tensor(0.9106)
conv.0 tensor(0.1821)
tensor(1427804.) 2188896.0
0.54243022
tensor(0.1040, device='cuda:0', grad_fn=<AddBackward0>)
0.54242301
tensor(0.0873, device='cuda:0', grad_fn=<AddBackward0>)
0.54241008
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.54241091
tensor(0.1486, device='cuda:0', grad_fn=<AddBackward0>)
0.54241258
tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
0.54241264
tensor(0.1078, device='cuda:0', grad_fn=<AddBackward0>)
0.54240781
tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)
0.54241067
tensor(0.1513, device='cuda:0', grad_fn=<AddBackward0>)
0.54240471
tensor(0.1758, device='cuda:0', grad_fn=<AddBackward0>)
0.54239458
tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)
0.54238915
tensor(0.1072, device='cuda:0', grad_fn=<AddBackward0>)
0.54238790
tensor(0.1145, device='cuda:0', grad_fn=<AddBackward0>)
0.54237533
tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>)
0.54235917
tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
0.54233915
tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [57][   20/  196]   Loss 0.098414   Top1 96.953125   Top5 100.000000   BatchTime 0.305841   LR 0.000029
0.54233849
tensor(0.0453, device='cuda:0', grad_fn=<AddBackward0>)
0.54233229
tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>)
0.54232383
tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)
0.54230791
tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
0.54229045
tensor(0.0862, device='cuda:0', grad_fn=<AddBackward0>)
0.54228044
tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>)
0.54226941
tensor(0.0798, device='cuda:0', grad_fn=<AddBackward0>)
0.54226547
tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
0.54224664
tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
0.54223305
tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
0.54221684
tensor(0.0708, device='cuda:0', grad_fn=<AddBackward0>)
0.54220617
tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
0.54219711
tensor(0.1204, device='cuda:0', grad_fn=<AddBackward0>)
0.54218769
tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>)
0.54217196
tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
0.54216397
tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
0.54215759
tensor(0.0884, device='cuda:0', grad_fn=<AddBackward0>)
0.54215342
tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)
0.54213101
tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>)
0.54211092
tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)
0.54209483
tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
0.54208106
tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>)
0.54206467
tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [57][   40/  196]   Loss 0.094731   Top1 97.031250   Top5 99.990234   BatchTime 0.292796   LR 0.000029
0.54203916
tensor(0.0946, device='cuda:0', grad_fn=<AddBackward0>)
0.54201734
tensor(0.0435, device='cuda:0', grad_fn=<AddBackward0>)
0.54200441
tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
0.54199642
tensor(0.1253, device='cuda:0', grad_fn=<AddBackward0>)
0.54199129
tensor(0.1047, device='cuda:0', grad_fn=<AddBackward0>)
0.54198259
tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
0.54197520
tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
0.54197007
tensor(0.0892, device='cuda:0', grad_fn=<AddBackward0>)
0.54196537
tensor(0.0756, device='cuda:0', grad_fn=<AddBackward0>)
0.54195404
tensor(0.1217, device='cuda:0', grad_fn=<AddBackward0>)
0.54194707
tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>)
0.54193270
tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>)
0.54192299
tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
0.54191417
tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>)
0.54190743
tensor(0.1118, device='cuda:0', grad_fn=<AddBackward0>)
0.54190075
tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
0.54188472
tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
0.54187447
tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>)
0.54186571
tensor(0.1413, device='cuda:0', grad_fn=<AddBackward0>)
0.54186034
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
0.54185581
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
0.54185039
tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>)
0.54183728
tensor(0.1245, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [57][   60/  196]   Loss 0.095368   Top1 96.966146   Top5 99.980469   BatchTime 0.278625   LR 0.000029
0.54183209
tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>)
0.54183251
tensor(0.1271, device='cuda:0', grad_fn=<AddBackward0>)
0.54182267
tensor(0.0707, device='cuda:0', grad_fn=<AddBackward0>)
0.54181933
tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>)
0.54181033
tensor(0.1106, device='cuda:0', grad_fn=<AddBackward0>)
0.54181468
tensor(0.0729, device='cuda:0', grad_fn=<AddBackward0>)
0.54180908
tensor(0.0709, device='cuda:0', grad_fn=<AddBackward0>)
0.54179543
tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
0.54179913
tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)
0.54179025
tensor(0.1241, device='cuda:0', grad_fn=<AddBackward0>)
0.54178798
tensor(0.0684, device='cuda:0', grad_fn=<AddBackward0>)
0.54179043
tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>)
0.54177791
tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
0.54177171
tensor(0.0873, device='cuda:0', grad_fn=<AddBackward0>)
0.54176480
tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>)
0.54175705
tensor(0.0964, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [57][   80/  196]   Loss 0.095298   Top1 96.884766   Top5 99.980469   BatchTime 0.271676   LR 0.000028
0.54175538
tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
0.54174167
tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
0.54173827
tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
0.54173481
tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)
0.54174227
tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>)
0.54172951
tensor(0.0650, device='cuda:0', grad_fn=<AddBackward0>)
0.54171145
tensor(0.1016, device='cuda:0', grad_fn=<AddBackward0>)
0.54168648
tensor(0.0690, device='cuda:0', grad_fn=<AddBackward0>)
0.54166752
tensor(0.1514, device='cuda:0', grad_fn=<AddBackward0>)
0.54165924
tensor(0.0983, device='cuda:0', grad_fn=<AddBackward0>)
0.54164511
tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>)
0.54162824
tensor(0.0506, device='cuda:0', grad_fn=<AddBackward0>)
0.54161632
tensor(0.0650, device='cuda:0', grad_fn=<AddBackward0>)
0.54161108
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.54160899
tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>)
0.54160792
tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>)
0.54160285
tensor(0.1132, device='cuda:0', grad_fn=<AddBackward0>)
0.54160035
tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>)
0.54160357
tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>)
0.54160064
tensor(0.1214, device='cuda:0', grad_fn=<AddBackward0>)
0.54159033
tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)
0.54157853
tensor(0.0349, device='cuda:0', grad_fn=<AddBackward0>)
0.54156286
tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
0.54155958
tensor(0.0958, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [57][  100/  196]   Loss 0.094665   Top1 96.894531   Top5 99.980469   BatchTime 0.267678   LR 0.000028
0.54155505
tensor(0.1055, device='cuda:0', grad_fn=<AddBackward0>)
0.54155469
tensor(0.0815, device='cuda:0', grad_fn=<AddBackward0>)
0.54154372
tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>)
0.54152983
tensor(0.0841, device='cuda:0', grad_fn=<AddBackward0>)
0.54151636
tensor(0.0860, device='cuda:0', grad_fn=<AddBackward0>)
0.54150689
tensor(0.0877, device='cuda:0', grad_fn=<AddBackward0>)
0.54150033
tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
0.54148316
tensor(0.0556, device='cuda:0', grad_fn=<AddBackward0>)
0.54147208
tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>)
0.54145861
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.54145980
tensor(0.0749, device='cuda:0', grad_fn=<AddBackward0>)
0.54145950
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.54146665
tensor(0.1404, device='cuda:0', grad_fn=<AddBackward0>)
0.54145736
tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
0.54146004
tensor(0.1302, device='cuda:0', grad_fn=<AddBackward0>)
0.54147547
tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [57][  120/  196]   Loss 0.094204   Top1 96.920573   Top5 99.983724   BatchTime 0.264425   LR 0.000027
0.54148728
tensor(0.0798, device='cuda:0', grad_fn=<AddBackward0>)
0.54151607
tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
0.54151630
tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
0.54153484
tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
0.54151028
tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
0.54151863
tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>)
0.54152340
tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
0.54151636
tensor(0.1100, device='cuda:0', grad_fn=<AddBackward0>)
0.54151428
tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>)
0.54151738
tensor(0.0836, device='cuda:0', grad_fn=<AddBackward0>)
0.54152715
tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
0.54154497
tensor(0.0421, device='cuda:0', grad_fn=<AddBackward0>)
0.54149991
tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>)
0.54147792
tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>)
0.54149014
tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
0.54145908
tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>)
0.54148090
tensor(0.1160, device='cuda:0', grad_fn=<AddBackward0>)
0.54145795
tensor(0.0941, device='cuda:0', grad_fn=<AddBackward0>)
0.54145515
tensor(0.1186, device='cuda:0', grad_fn=<AddBackward0>)
0.54142976
tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>)
0.54142255
tensor(0.1149, device='cuda:0', grad_fn=<AddBackward0>)
0.54140872
tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>)
0.54140335
tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
0.54139864
tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [57][  140/  196]   Loss 0.094022   Top1 96.964286   Top5 99.983259   BatchTime 0.264311   LR 0.000027
0.54139262
tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
0.54138422
tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
0.54136920
tensor(0.1117, device='cuda:0', grad_fn=<AddBackward0>)
0.54136556
tensor(0.1411, device='cuda:0', grad_fn=<AddBackward0>)
0.54135156
tensor(0.0940, device='cuda:0', grad_fn=<AddBackward0>)
0.54135072
tensor(0.0720, device='cuda:0', grad_fn=<AddBackward0>)
0.54134804
tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>)
0.54135275
tensor(0.0729, device='cuda:0', grad_fn=<AddBackward0>)
0.54134572
tensor(0.1001, device='cuda:0', grad_fn=<AddBackward0>)
0.54134494
tensor(0.0785, device='cuda:0', grad_fn=<AddBackward0>)
0.54133356
tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>)
0.54132390
tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>)
0.54132181
tensor(0.1145, device='cuda:0', grad_fn=<AddBackward0>)
0.54132038
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.54131848
tensor(0.1041, device='cuda:0', grad_fn=<AddBackward0>)
0.54131562
tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [57][  160/  196]   Loss 0.094858   Top1 96.940918   Top5 99.980469   BatchTime 0.262454   LR 0.000027
0.54131281
tensor(0.1263, device='cuda:0', grad_fn=<AddBackward0>)
0.54130989
tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
0.54130608
tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
0.54130858
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
0.54131013
tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>)
0.54130113
tensor(0.0959, device='cuda:0', grad_fn=<AddBackward0>)
0.54129344
tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>)
0.54128051
tensor(0.1334, device='cuda:0', grad_fn=<AddBackward0>)
0.54127169
tensor(0.0987, device='cuda:0', grad_fn=<AddBackward0>)
0.54125965
tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
0.54125178
tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
0.54124355
tensor(0.1008, device='cuda:0', grad_fn=<AddBackward0>)
0.54123354
tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>)
0.54123074
tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
0.54123765
tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
0.54123884
tensor(0.1201, device='cuda:0', grad_fn=<AddBackward0>)
0.54123604
tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
0.54122949
tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
0.54122275
tensor(0.0962, device='cuda:0', grad_fn=<AddBackward0>)
0.54123455
tensor(0.1258, device='cuda:0', grad_fn=<AddBackward0>)
0.54124075
tensor(0.0906, device='cuda:0', grad_fn=<AddBackward0>)
0.54124117
tensor(0.1020, device='cuda:0', grad_fn=<AddBackward0>)
0.54124564
tensor(0.0835, device='cuda:0', grad_fn=<AddBackward0>)
0.54124528
tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [57][  180/  196]   Loss 0.095387   Top1 96.916233   Top5 99.980469   BatchTime 0.260486   LR 0.000026
0.54124504
tensor(0.0538, device='cuda:0', grad_fn=<AddBackward0>)
0.54124933
tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)
0.54124808
tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>)
0.54124504
tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>)
0.54124850
tensor(0.0684, device='cuda:0', grad_fn=<AddBackward0>)
0.54124933
tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
0.54124790
tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)
0.54123855
tensor(0.1122, device='cuda:0', grad_fn=<AddBackward0>)
0.54122609
tensor(0.0890, device='cuda:0', grad_fn=<AddBackward0>)
0.54121369
tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)
0.54121131
tensor(0.0744, device='cuda:0', grad_fn=<AddBackward0>)
0.54121071
tensor(0.1600, device='cuda:0', grad_fn=<AddBackward0>)
0.54119748
tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>)
0.54119003
tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
0.54118323
tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 96.898    Top5: 99.980    Loss: 0.095
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [57][   20/   40]   Loss 0.419247   Top1 88.417969   Top5 99.531250   BatchTime 0.120064
INFO - Validation [57][   40/   40]   Loss 0.398020   Top1 88.890000   Top5 99.640000   BatchTime 0.086295
INFO - ==> Top1: 88.890    Top5: 99.640    Loss: 0.398
INFO - ==> Sparsity : 0.654
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [56][Top1: 89.140   Top5: 99.650]
INFO - Scoreboard best 3 ==> Epoch [55][Top1: 89.100   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.3021)
features.0.conv.3 tensor(0.1719)
features.1.conv.0 tensor(0.0462)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0951)
features.2.conv.0 tensor(0.1163)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.5324)
features.3.conv.0 tensor(0.0738)
features.3.conv.3 tensor(0.0741)
features.3.conv.6 tensor(0.1107)
features.4.conv.0 tensor(0.1014)
features.4.conv.3 tensor(0.2998)
features.4.conv.6 tensor(0.4100)
features.5.conv.0 tensor(0.3665)
features.5.conv.3 tensor(0.4126)
features.5.conv.6 tensor(0.4749)
features.6.conv.0 tensor(0.0573)
features.6.conv.3 tensor(0.0480)
features.6.conv.6 tensor(0.0823)
features.7.conv.0 tensor(0.2784)
features.7.conv.3 tensor(0.4465)
features.7.conv.6 tensor(0.6517)
features.8.conv.0 tensor(0.5546)
features.8.conv.3 tensor(0.5373)
features.8.conv.6 tensor(0.6206)
features.9.conv.0 tensor(0.5344)
features.9.conv.3 tensor(0.5660)
features.9.conv.6 tensor(0.7583)
features.10.conv.0 tensor(0.0625)
features.10.conv.3 tensor(0.0903)
features.10.conv.6 tensor(0.0682)
features.11.conv.0 tensor(0.7720)
features.11.conv.3 tensor(0.6439)
features.11.conv.6 tensor(0.9022)
features.12.conv.0 tensor(0.7359)
features.12.conv.3 tensor(0.6630)
features.12.conv.6 tensor(0.8680)
features.13.conv.0 tensor(0.3103)
features.13.conv.3 tensor(0.4821)
features.13.conv.6 tensor(0.6017)
features.14.conv.0 tensor(0.9139)
features.14.conv.3 tensor(0.8225)
features.14.conv.6 tensor(0.9579)
features.15.conv.0 tensor(0.9007)
features.15.conv.3 tensor(0.8271)
features.15.conv.6 tensor(0.9638)
features.16.conv.0 tensor(0.7106)
features.16.conv.3 tensor(0.7884)
features.16.conv.6 tensor(0.9126)
conv.0 tensor(0.1845)
tensor(1431489.) 2188896.0
0.54117382
tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>)
0.54116416
tensor(0.1077, device='cuda:0', grad_fn=<AddBackward0>)
0.54115433
tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>)
0.54114658
tensor(0.1052, device='cuda:0', grad_fn=<AddBackward0>)
0.54114050
tensor(0.1023, device='cuda:0', grad_fn=<AddBackward0>)
0.54113418
tensor(0.1241, device='cuda:0', grad_fn=<AddBackward0>)
0.54114205
tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>)
0.54114830
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
0.54114497
tensor(0.0456, device='cuda:0', grad_fn=<AddBackward0>)
0.54113835
tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
0.54113752
tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
0.54114401
tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)
0.54113448
tensor(0.1273, device='cuda:0', grad_fn=<AddBackward0>)
0.54112524
tensor(0.0884, device='cuda:0', grad_fn=<AddBackward0>)
0.54111469
tensor(0.1190, device='cuda:0', grad_fn=<AddBackward0>)
0.54110110
tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
0.54109818
tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
0.54109257
tensor(0.0774, device='cuda:0', grad_fn=<AddBackward0>)
0.54108709
tensor(0.1047, device='cuda:0', grad_fn=<AddBackward0>)
0.54107261
tensor(0.0673, device='cuda:0', grad_fn=<AddBackward0>)
0.54107434
tensor(0.0720, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [58][   20/  196]   Loss 0.092341   Top1 96.875000   Top5 99.960938   BatchTime 0.333479   LR 0.000025
0.54106522
tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
0.54105073
tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)
0.54104269
tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
0.54102945
tensor(0.1442, device='cuda:0', grad_fn=<AddBackward0>)
0.54101807
tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>)
0.54100490
tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>)
0.54099220
tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>)
0.54098421
tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)
0.54097277
tensor(0.0754, device='cuda:0', grad_fn=<AddBackward0>)
0.54096925
tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>)
0.54097414
tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
0.54096442
tensor(0.0912, device='cuda:0', grad_fn=<AddBackward0>)
0.54096079
tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
0.54095030
tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>)
0.54094386
tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>)
0.54094023
tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [58][   40/  196]   Loss 0.094652   Top1 96.806641   Top5 99.951172   BatchTime 0.287975   LR 0.000025
0.54092604
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
0.54091930
tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)
0.54091042
tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>)
0.54090410
tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>)
0.54089701
tensor(0.1111, device='cuda:0', grad_fn=<AddBackward0>)
0.54089862
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
0.54090017
tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>)
0.54090095
tensor(0.0918, device='cuda:0', grad_fn=<AddBackward0>)
0.54090154
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.54089594
tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>)
0.54088223
tensor(0.0964, device='cuda:0', grad_fn=<AddBackward0>)
0.54088694
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
0.54088932
tensor(0.0899, device='cuda:0', grad_fn=<AddBackward0>)
0.54089195
tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)
0.54089719
tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
0.54088926
tensor(0.1078, device='cuda:0', grad_fn=<AddBackward0>)
0.54088074
tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
0.54086816
tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)
0.54087335
tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
0.54086953
tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>)
0.54086733
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.54086632
tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>)
0.54086369
tensor(0.1190, device='cuda:0', grad_fn=<AddBackward0>)
0.54086339
tensor(0.1003, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [58][   60/  196]   Loss 0.096597   Top1 96.738281   Top5 99.960938   BatchTime 0.279042   LR 0.000025
0.54085726
tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>)
0.54084450
tensor(0.1261, device='cuda:0', grad_fn=<AddBackward0>)
0.54081815
tensor(0.1062, device='cuda:0', grad_fn=<AddBackward0>)
0.54080600
tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>)
0.54079610
tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)
0.54079264
tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
0.54077768
tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>)
0.54076600
tensor(0.1598, device='cuda:0', grad_fn=<AddBackward0>)
0.54076004
tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
0.54075527
tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
0.54074490
tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>)
0.54074425
tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
0.54073870
tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>)
0.54073966
tensor(0.1213, device='cuda:0', grad_fn=<AddBackward0>)
0.54074132
tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>)
0.54075372
tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>)
0.54075599
tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>)
0.54076153
tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>)
0.54077399
tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>)
0.54077452
tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [58][   80/  196]   Loss 0.097667   Top1 96.787109   Top5 99.960938   BatchTime 0.280787   LR 0.000024
0.54076993
tensor(0.1319, device='cuda:0', grad_fn=<AddBackward0>)
0.54076630
tensor(0.1304, device='cuda:0', grad_fn=<AddBackward0>)
0.54075408
tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>)
0.54074669
tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)
0.54073608
tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
0.54072291
tensor(0.0425, device='cuda:0', grad_fn=<AddBackward0>)
0.54071152
tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>)
0.54069889
tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>)
0.54068029
tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>)
0.54067385
tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>)
0.54067010
tensor(0.0789, device='cuda:0', grad_fn=<AddBackward0>)
0.54066372
tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>)
0.54065573
tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [58][  100/  196]   Loss 0.095665   Top1 96.816406   Top5 99.964844   BatchTime 0.283483   LR 0.000024
0.54065716
tensor(0.0715, device='cuda:0', grad_fn=<AddBackward0>)
0.54065400
tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>)
0.54064924
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.54064494
tensor(0.0884, device='cuda:0', grad_fn=<AddBackward0>)
0.54063022
tensor(0.0879, device='cuda:0', grad_fn=<AddBackward0>)
0.54062253
tensor(0.1160, device='cuda:0', grad_fn=<AddBackward0>)
0.54061252
tensor(0.0825, device='cuda:0', grad_fn=<AddBackward0>)
0.54060847
tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
0.54060519
tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>)
0.54059827
tensor(0.1223, device='cuda:0', grad_fn=<AddBackward0>)
0.54058695
tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
0.54058492
tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>)
0.54058009
tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)
0.54057717
tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>)
0.54055935
tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>)
0.54055381
tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
0.54054469
tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
0.54053241
tensor(0.1629, device='cuda:0', grad_fn=<AddBackward0>)
0.54051828
tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
0.54050410
tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
0.54049313
tensor(0.0812, device='cuda:0', grad_fn=<AddBackward0>)
0.54048729
tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>)
0.54047978
tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>)
0.54047638
tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [58][  120/  196]   Loss 0.095610   Top1 96.822917   Top5 99.970703   BatchTime 0.278029   LR 0.000023
0.54046756
tensor(0.0843, device='cuda:0', grad_fn=<AddBackward0>)
0.54046029
tensor(0.0678, device='cuda:0', grad_fn=<AddBackward0>)
0.54045576
tensor(0.0809, device='cuda:0', grad_fn=<AddBackward0>)
0.54045153
tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
0.54043698
tensor(0.0959, device='cuda:0', grad_fn=<AddBackward0>)
0.54042214
tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)
0.54041243
tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
0.54040295
tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>)
0.54039472
tensor(0.1131, device='cuda:0', grad_fn=<AddBackward0>)
0.54038262
tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>)
0.54036945
tensor(0.0757, device='cuda:0', grad_fn=<AddBackward0>)
0.54035127
tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>)
0.54035223
tensor(0.1130, device='cuda:0', grad_fn=<AddBackward0>)
0.54034770
tensor(0.1085, device='cuda:0', grad_fn=<AddBackward0>)
0.54033506
tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>)
0.54032892
tensor(0.0954, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [58][  140/  196]   Loss 0.096768   Top1 96.749442   Top5 99.974888   BatchTime 0.274398   LR 0.000023
0.54033333
tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>)
0.54032815
tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>)
0.54032564
tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
0.54032105
tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>)
0.54030561
tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
0.54028797
tensor(0.0917, device='cuda:0', grad_fn=<AddBackward0>)
0.54028219
tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>)
0.54028255
tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
0.54028350
tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)
0.54027581
tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
0.54027128
tensor(0.1042, device='cuda:0', grad_fn=<AddBackward0>)
0.54026413
tensor(0.1279, device='cuda:0', grad_fn=<AddBackward0>)
0.54026514
tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>)
0.54026163
tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
0.54026234
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
0.54025167
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
0.54024559
tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
0.54023969
tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
0.54023504
tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)
0.54022992
tensor(0.0914, device='cuda:0', grad_fn=<AddBackward0>)
0.54021668
tensor(0.1350, device='cuda:0', grad_fn=<AddBackward0>)
0.54020905
tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
0.54019636
tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
0.54018480
tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [58][  160/  196]   Loss 0.096186   Top1 96.765137   Top5 99.973145   BatchTime 0.270867   LR 0.000023
0.54017299
tensor(0.1118, device='cuda:0', grad_fn=<AddBackward0>)
0.54016811
tensor(0.0987, device='cuda:0', grad_fn=<AddBackward0>)
0.54016244
tensor(0.1207, device='cuda:0', grad_fn=<AddBackward0>)
0.54015899
tensor(0.0695, device='cuda:0', grad_fn=<AddBackward0>)
0.54015422
tensor(0.0915, device='cuda:0', grad_fn=<AddBackward0>)
0.54013652
tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>)
0.54011762
tensor(0.1372, device='cuda:0', grad_fn=<AddBackward0>)
0.54010677
tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>)
0.54009378
tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>)
0.54008424
tensor(0.0831, device='cuda:0', grad_fn=<AddBackward0>)
0.54006577
tensor(0.0833, device='cuda:0', grad_fn=<AddBackward0>)
0.54005599
tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>)
0.54004556
tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)
0.54004478
tensor(0.1045, device='cuda:0', grad_fn=<AddBackward0>)
0.54003960
tensor(0.0778, device='cuda:0', grad_fn=<AddBackward0>)
0.54002911
tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)
0.54000992
tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
0.54000515
tensor(0.1162, device='cuda:0', grad_fn=<AddBackward0>)
0.53999519
tensor(0.0954, device='cuda:0', grad_fn=<AddBackward0>)
0.53998673
tensor(0.0554, device='cuda:0', grad_fn=<AddBackward0>)
0.53998804
tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [58][  180/  196]   Loss 0.096886   Top1 96.744792   Top5 99.976128   BatchTime 0.273053   LR 0.000022
0.53998464
tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>)
0.53998733
tensor(0.0933, device='cuda:0', grad_fn=<AddBackward0>)
0.53998071
tensor(0.0887, device='cuda:0', grad_fn=<AddBackward0>)
0.53996795
tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)
0.53997022
tensor(0.0844, device='cuda:0', grad_fn=<AddBackward0>)
0.53996527
tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)
0.53995281
tensor(0.0652, device='cuda:0', grad_fn=<AddBackward0>)
0.53995514
tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
0.53995645
tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>)
0.53994828
tensor(0.1042, device='cuda:0', grad_fn=<AddBackward0>)
0.53993815
tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>)
0.53992552
tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>)
0.53991491
tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)
0.53991365
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
0.53990626
tensor(0.0968, device='cuda:0', grad_fn=<AddBackward0>)
0.53989875
tensor(0.1045, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 96.768    Top5: 99.978    Loss: 0.096
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.53990418
tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [58][   20/   40]   Loss 0.403270   Top1 89.062500   Top5 99.550781   BatchTime 0.118012
INFO - Validation [58][   40/   40]   Loss 0.388633   Top1 89.190000   Top5 99.660000   BatchTime 0.085294
INFO - ==> Top1: 89.190    Top5: 99.660    Loss: 0.389
INFO - ==> Sparsity : 0.656
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [58][Top1: 89.190   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [56][Top1: 89.140   Top5: 99.650]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1680)
features.1.conv.0 tensor(0.0508)
features.1.conv.3 tensor(0.0775)
features.1.conv.6 tensor(0.0911)
features.2.conv.0 tensor(0.1201)
features.2.conv.3 tensor(0.3457)
features.2.conv.6 tensor(0.5327)
features.3.conv.0 tensor(0.0729)
features.3.conv.3 tensor(0.0764)
features.3.conv.6 tensor(0.1113)
features.4.conv.0 tensor(0.1027)
features.4.conv.3 tensor(0.3009)
features.4.conv.6 tensor(0.4149)
features.5.conv.0 tensor(0.3716)
features.5.conv.3 tensor(0.4126)
features.5.conv.6 tensor(0.4746)
features.6.conv.0 tensor(0.0547)
features.6.conv.3 tensor(0.0475)
features.6.conv.6 tensor(0.0819)
features.7.conv.0 tensor(0.2807)
features.7.conv.3 tensor(0.4450)
features.7.conv.6 tensor(0.6530)
features.8.conv.0 tensor(0.5595)
features.8.conv.3 tensor(0.5376)
features.8.conv.6 tensor(0.6261)
features.9.conv.0 tensor(0.5389)
features.9.conv.3 tensor(0.5660)
features.9.conv.6 tensor(0.7581)
features.10.conv.0 tensor(0.0621)
features.10.conv.3 tensor(0.0883)
features.10.conv.6 tensor(0.0685)
features.11.conv.0 tensor(0.7734)
features.11.conv.3 tensor(0.6433)
features.11.conv.6 tensor(0.9019)
features.12.conv.0 tensor(0.7410)
features.12.conv.3 tensor(0.6630)
features.12.conv.6 tensor(0.8688)
features.13.conv.0 tensor(0.3161)
features.13.conv.3 tensor(0.4830)
features.13.conv.6 tensor(0.6084)
features.14.conv.0 tensor(0.9140)
features.14.conv.3 tensor(0.8222)
features.14.conv.6 tensor(0.9576)
features.15.conv.0 tensor(0.9009)
features.15.conv.3 tensor(0.8272)
features.15.conv.6 tensor(0.9637)
features.16.conv.0 tensor(0.7144)
features.16.conv.3 tensor(0.7888)
features.16.conv.6 tensor(0.9144)
conv.0 tensor(0.1900)
tensor(1436718.) 2188896.0
0.53989100
tensor(0.1983, device='cuda:0', grad_fn=<AddBackward0>)
0.53988099
tensor(0.0483, device='cuda:0', grad_fn=<AddBackward0>)
0.53987092
tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
0.53986031
tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
0.53986073
tensor(0.0968, device='cuda:0', grad_fn=<AddBackward0>)
0.53986102
tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
0.53984791
tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
0.53984386
tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>)
0.53983504
tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
0.53982723
tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
0.53982931
tensor(0.0709, device='cuda:0', grad_fn=<AddBackward0>)
0.53982300
tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>)
0.53981972
tensor(0.0790, device='cuda:0', grad_fn=<AddBackward0>)
0.53981173
tensor(0.0695, device='cuda:0', grad_fn=<AddBackward0>)
0.53980684
tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
0.53980511
tensor(0.0372, device='cuda:0', grad_fn=<AddBackward0>)
0.53979164
tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>)
0.53977621
tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
0.53977084
tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>)
0.53976768
tensor(0.1249, device='cuda:0', grad_fn=<AddBackward0>)
0.53976160
tensor(0.1575, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [59][   20/  196]   Loss 0.089107   Top1 97.207031   Top5 99.980469   BatchTime 0.312664   LR 0.000022
0.53974837
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
0.53972781
tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
0.53971493
tensor(0.0702, device='cuda:0', grad_fn=<AddBackward0>)
0.53971153
tensor(0.1163, device='cuda:0', grad_fn=<AddBackward0>)
0.53971303
tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
0.53970957
tensor(0.0495, device='cuda:0', grad_fn=<AddBackward0>)
0.53970212
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
0.53968805
tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>)
0.53967375
tensor(0.1062, device='cuda:0', grad_fn=<AddBackward0>)
0.53966314
tensor(0.0836, device='cuda:0', grad_fn=<AddBackward0>)
0.53965098
tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)
0.53963929
tensor(0.0895, device='cuda:0', grad_fn=<AddBackward0>)
0.53962821
tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
0.53961712
tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
0.53961271
tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [59][   40/  196]   Loss 0.086899   Top1 97.197266   Top5 99.990234   BatchTime 0.292309   LR 0.000021
0.53959423
tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>)
0.53958881
tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>)
0.53959137
tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)
0.53959060
tensor(0.0696, device='cuda:0', grad_fn=<AddBackward0>)
0.53958535
tensor(0.1021, device='cuda:0', grad_fn=<AddBackward0>)
0.53957433
tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>)
0.53956568
tensor(0.1011, device='cuda:0', grad_fn=<AddBackward0>)
0.53956169
tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>)
0.53955626
tensor(0.0482, device='cuda:0', grad_fn=<AddBackward0>)
0.53954148
tensor(0.1687, device='cuda:0', grad_fn=<AddBackward0>)
0.53953439
tensor(0.0908, device='cuda:0', grad_fn=<AddBackward0>)
0.53952873
tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
0.53953034
tensor(0.0853, device='cuda:0', grad_fn=<AddBackward0>)
0.53952694
tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)
0.53952944
tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>)
0.53953952
tensor(0.0799, device='cuda:0', grad_fn=<AddBackward0>)
0.53952748
tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
0.53951716
tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
0.53952247
tensor(0.0782, device='cuda:0', grad_fn=<AddBackward0>)
0.53952432
tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
0.53952038
tensor(0.0754, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [59][   60/  196]   Loss 0.087024   Top1 97.154948   Top5 99.980469   BatchTime 0.291876   LR 0.000021
0.53951782
tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)
0.53951418
tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>)
0.53951365
tensor(0.0645, device='cuda:0', grad_fn=<AddBackward0>)
0.53951985
tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)
0.53950751
tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
0.53948814
tensor(0.1059, device='cuda:0', grad_fn=<AddBackward0>)
0.53947395
tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>)
0.53946149
tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>)
0.53945279
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
0.53944552
tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>)
0.53944457
tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
0.53942758
tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
0.53942174
tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
0.53939754
tensor(0.0967, device='cuda:0', grad_fn=<AddBackward0>)
0.53939134
tensor(0.0753, device='cuda:0', grad_fn=<AddBackward0>)
0.53938305
tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
0.53937578
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
0.53936517
tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>)
0.53934032
tensor(0.1111, device='cuda:0', grad_fn=<AddBackward0>)
0.53932840
tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>)
0.53932887
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.53932470
tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>)
0.53932500
tensor(0.0415, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [59][   80/  196]   Loss 0.087475   Top1 97.163086   Top5 99.980469   BatchTime 0.284155   LR 0.000020
0.53931010
tensor(0.0754, device='cuda:0', grad_fn=<AddBackward0>)
0.53930879
tensor(0.0923, device='cuda:0', grad_fn=<AddBackward0>)
0.53930640
tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
0.53930420
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.53930885
tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
0.53930229
tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
0.53931212
tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
0.53930509
tensor(0.0941, device='cuda:0', grad_fn=<AddBackward0>)
0.53931439
tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
0.53931898
tensor(0.1110, device='cuda:0', grad_fn=<AddBackward0>)
0.53931791
tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>)
0.53931308
tensor(0.0750, device='cuda:0', grad_fn=<AddBackward0>)
0.53930765
tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
0.53929764
tensor(0.1230, device='cuda:0', grad_fn=<AddBackward0>)
0.53928477
tensor(0.0799, device='cuda:0', grad_fn=<AddBackward0>)
0.53928214
tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [59][  100/  196]   Loss 0.088696   Top1 97.054688   Top5 99.984375   BatchTime 0.277754   LR 0.000020
0.53927767
tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
0.53928357
tensor(0.1096, device='cuda:0', grad_fn=<AddBackward0>)
0.53927189
tensor(0.0808, device='cuda:0', grad_fn=<AddBackward0>)
0.53927529
tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>)
0.53928769
tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>)
0.53928286
tensor(0.0995, device='cuda:0', grad_fn=<AddBackward0>)
0.53926337
tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
0.53926903
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.53926891
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.53926635
tensor(0.1067, device='cuda:0', grad_fn=<AddBackward0>)
0.53925872
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
0.53923708
tensor(0.1067, device='cuda:0', grad_fn=<AddBackward0>)
0.53923470
tensor(0.1355, device='cuda:0', grad_fn=<AddBackward0>)
0.53923392
tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>)
0.53922433
tensor(0.1595, device='cuda:0', grad_fn=<AddBackward0>)
0.53922397
tensor(0.0860, device='cuda:0', grad_fn=<AddBackward0>)
0.53921610
tensor(0.0743, device='cuda:0', grad_fn=<AddBackward0>)
0.53921962
tensor(0.0958, device='cuda:0', grad_fn=<AddBackward0>)
0.53921914
tensor(0.1052, device='cuda:0', grad_fn=<AddBackward0>)
0.53921866
tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>)
0.53921610
tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>)
0.53921533
tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)
0.53921235
tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [59][  120/  196]   Loss 0.089369   Top1 97.034505   Top5 99.983724   BatchTime 0.276419   LR 0.000020
0.53920907
tensor(0.0949, device='cuda:0', grad_fn=<AddBackward0>)
0.53920788
tensor(0.1068, device='cuda:0', grad_fn=<AddBackward0>)
0.53920084
tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
0.53919679
tensor(0.0655, device='cuda:0', grad_fn=<AddBackward0>)
0.53919363
tensor(0.1043, device='cuda:0', grad_fn=<AddBackward0>)
0.53918934
tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
0.53918236
tensor(0.1176, device='cuda:0', grad_fn=<AddBackward0>)
0.53918511
tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
0.53918159
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
0.53917181
tensor(0.1086, device='cuda:0', grad_fn=<AddBackward0>)
0.53917325
tensor(0.0790, device='cuda:0', grad_fn=<AddBackward0>)
0.53916967
tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
0.53916746
tensor(0.1429, device='cuda:0', grad_fn=<AddBackward0>)
0.53916216
tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>)
0.53915310
tensor(0.1160, device='cuda:0', grad_fn=<AddBackward0>)
0.53914768
tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
0.53915203
tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
0.53914791
tensor(0.0790, device='cuda:0', grad_fn=<AddBackward0>)
0.53914422
tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [59][  140/  196]   Loss 0.089783   Top1 97.025670   Top5 99.983259   BatchTime 0.281348   LR 0.000019
0.53914028
tensor(0.0763, device='cuda:0', grad_fn=<AddBackward0>)
0.53914326
tensor(0.1010, device='cuda:0', grad_fn=<AddBackward0>)
0.53914511
tensor(0.1135, device='cuda:0', grad_fn=<AddBackward0>)
0.53914148
tensor(0.0710, device='cuda:0', grad_fn=<AddBackward0>)
0.53913510
tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>)
0.53912431
tensor(0.1059, device='cuda:0', grad_fn=<AddBackward0>)
0.53911018
tensor(0.1337, device='cuda:0', grad_fn=<AddBackward0>)
0.53911132
tensor(0.0594, device='cuda:0', grad_fn=<AddBackward0>)
0.53910118
tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>)
0.53909743
tensor(0.1556, device='cuda:0', grad_fn=<AddBackward0>)
0.53908432
tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
0.53907800
tensor(0.1261, device='cuda:0', grad_fn=<AddBackward0>)
0.53906375
tensor(0.0645, device='cuda:0', grad_fn=<AddBackward0>)
0.53904212
tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
0.53902727
tensor(0.0476, device='cuda:0', grad_fn=<AddBackward0>)
0.53901619
tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
0.53900152
tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
0.53898293
tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>)
0.53897500
tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [59][  160/  196]   Loss 0.090401   Top1 97.026367   Top5 99.985352   BatchTime 0.286054   LR 0.000019
0.53896004
tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>)
0.53895366
tensor(0.1166, device='cuda:0', grad_fn=<AddBackward0>)
0.53894460
tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
0.53893274
tensor(0.1196, device='cuda:0', grad_fn=<AddBackward0>)
0.53893119
tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>)
0.53893363
tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
0.53892606
tensor(0.1099, device='cuda:0', grad_fn=<AddBackward0>)
0.53892642
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.53891909
tensor(0.0987, device='cuda:0', grad_fn=<AddBackward0>)
0.53891116
tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>)
0.53889924
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.53888798
tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>)
0.53888249
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.53887236
tensor(0.0860, device='cuda:0', grad_fn=<AddBackward0>)
0.53886646
tensor(0.0675, device='cuda:0', grad_fn=<AddBackward0>)
0.53885323
tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>)
0.53883946
tensor(0.0738, device='cuda:0', grad_fn=<AddBackward0>)
0.53882796
tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>)
0.53882504
tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [59][  180/  196]   Loss 0.090112   Top1 97.050781   Top5 99.984809   BatchTime 0.288269   LR 0.000019
0.53882176
tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
0.53881049
tensor(0.0750, device='cuda:0', grad_fn=<AddBackward0>)
0.53881103
tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
0.53879499
tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>)
0.53878742
tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
0.53877366
tensor(0.1263, device='cuda:0', grad_fn=<AddBackward0>)
0.53876251
tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>)
0.53875500
tensor(0.1130, device='cuda:0', grad_fn=<AddBackward0>)
0.53875345
tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)
0.53875697
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
0.53875989
tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
0.53876722
tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>)
0.53876632
tensor(0.0666, device='cuda:0', grad_fn=<AddBackward0>)
0.53876531
tensor(0.1615, device='cuda:0', grad_fn=<AddBackward0>)
0.53876644
tensor(0.0892, device='cuda:0', grad_fn=<AddBackward0>)
0.53875959
tensor(0.1008, device='cuda:0', grad_fn=<AddBackward0>)
0.53875089
tensor(0.0559, device='cuda:0', grad_fn=<AddBackward0>)
0.53875303
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
0.53876406
tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
0.53876245
tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 97.026    Top5: 99.978    Loss: 0.091
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [59][   20/   40]   Loss 0.405697   Top1 89.296875   Top5 99.570312   BatchTime 0.128390
features.0.conv.0 tensor(0.2917)
features.0.conv.3 tensor(0.1699)
features.1.conv.0 tensor(0.0482)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0959)
features.2.conv.0 tensor(0.1224)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.5339)
features.3.conv.0 tensor(0.0738)
features.3.conv.3 tensor(0.0772)
features.3.conv.6 tensor(0.1118)
features.4.conv.0 tensor(0.1004)
INFO - Validation [59][   40/   40]   Loss 0.394434   Top1 89.310000   Top5 99.640000   BatchTime 0.094027
INFO - ==> Top1: 89.310    Top5: 99.640    Loss: 0.394
INFO - ==> Sparsity : 0.658
INFO - Scoreboard best 1 ==> Epoch [59][Top1: 89.310   Top5: 99.640]
INFO - Scoreboard best 2 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
INFO - Scoreboard best 3 ==> Epoch [58][Top1: 89.190   Top5: 99.660]
features.4.conv.3 tensor(0.3009)
features.4.conv.6 tensor(0.4193)
features.5.conv.0 tensor(0.3792)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4746)
features.6.conv.0 tensor(0.0560)
features.6.conv.3 tensor(0.0475)
features.6.conv.6 tensor(0.0818)
features.7.conv.0 tensor(0.2840)
features.7.conv.3 tensor(0.4465)
features.7.conv.6 tensor(0.6542)
features.8.conv.0 tensor(0.5633)
features.8.conv.3 tensor(0.5356)
features.8.conv.6 tensor(0.6364)
features.9.conv.0 tensor(0.5401)
features.9.conv.3 tensor(0.5689)
features.9.conv.6 tensor(0.7585)
features.10.conv.0 tensor(0.0623)
features.10.conv.3 tensor(0.0900)
features.10.conv.6 tensor(0.0680)
features.11.conv.0 tensor(0.7739)
features.11.conv.3 tensor(0.6433)
features.11.conv.6 tensor(0.9022)
features.12.conv.0 tensor(0.7412)
features.12.conv.3 tensor(0.6632)
features.12.conv.6 tensor(0.8687)
features.13.conv.0 tensor(0.3185)
features.13.conv.3 tensor(0.4838)
features.13.conv.6 tensor(0.6128)
features.14.conv.0 tensor(0.9143)
features.14.conv.3 tensor(0.8219)
features.14.conv.6 tensor(0.9579)
features.15.conv.0 tensor(0.9016)
features.15.conv.3 tensor(0.8269)
features.15.conv.6 tensor(0.9637)
features.16.conv.0 tensor(0.7180)
features.16.conv.3 tensor(0.7885)
features.16.conv.6 tensor(0.9158)
conv.0 tensor(0.1924)
tensor(1440034.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  60
INFO - Training: 50000 samples (256 per mini-batch)
0.53874844
tensor(0.0707, device='cuda:0', grad_fn=<AddBackward0>)
0.53873253
tensor(0.0879, device='cuda:0', grad_fn=<AddBackward0>)
0.53871661
tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)
0.53870302
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
0.53869301
tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
0.53867811
tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
0.53866696
tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
0.53866768
tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>)
0.53865874
tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>)
0.53864825
tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)
0.53863454
tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>)
0.53861576
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.53860027
tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>)
0.53858942
tensor(0.0950, device='cuda:0', grad_fn=<AddBackward0>)
0.53858811
tensor(0.0968, device='cuda:0', grad_fn=<AddBackward0>)
0.53857905
tensor(0.1067, device='cuda:0', grad_fn=<AddBackward0>)
0.53857177
tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
0.53856403
tensor(0.1079, device='cuda:0', grad_fn=<AddBackward0>)
0.53855515
tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>)
0.53854400
tensor(0.0809, device='cuda:0', grad_fn=<AddBackward0>)
0.53853935
tensor(0.0623, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [60][   20/  196]   Loss 0.087427   Top1 97.050781   Top5 100.000000   BatchTime 0.325235   LR 0.000018
0.53852588
tensor(0.1018, device='cuda:0', grad_fn=<AddBackward0>)
0.53851563
tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)
0.53849906
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
0.53849292
tensor(0.0820, device='cuda:0', grad_fn=<AddBackward0>)
0.53849578
tensor(0.0475, device='cuda:0', grad_fn=<AddBackward0>)
0.53848493
tensor(0.1117, device='cuda:0', grad_fn=<AddBackward0>)
0.53848320
tensor(0.0867, device='cuda:0', grad_fn=<AddBackward0>)
0.53848177
tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)
0.53846753
tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>)
0.53846157
tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
0.53845102
tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)
0.53844106
tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
0.53843778
tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)
0.53843200
tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
0.53841847
tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)
0.53840709
tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>)
0.53839856
tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
0.53839815
tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>)
0.53840828
tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [60][   40/  196]   Loss 0.088875   Top1 97.011719   Top5 100.000000   BatchTime 0.316268   LR 0.000018
0.53840256
tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
0.53839564
tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>)
0.53839165
tensor(0.0710, device='cuda:0', grad_fn=<AddBackward0>)
0.53838784
tensor(0.0835, device='cuda:0', grad_fn=<AddBackward0>)
0.53838658
tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
0.53838801
tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>)
0.53837901
tensor(0.0773, device='cuda:0', grad_fn=<AddBackward0>)
0.53837794
tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
0.53837657
tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>)
0.53837115
tensor(0.0476, device='cuda:0', grad_fn=<AddBackward0>)
0.53835958
tensor(0.0476, device='cuda:0', grad_fn=<AddBackward0>)
0.53836119
tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
0.53836298
tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>)
0.53836656
tensor(0.1517, device='cuda:0', grad_fn=<AddBackward0>)
0.53837228
tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>)
0.53836185
tensor(0.0924, device='cuda:0', grad_fn=<AddBackward0>)
0.53835219
tensor(0.1436, device='cuda:0', grad_fn=<AddBackward0>)
0.53835499
tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
0.53835028
tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>)
0.53835624
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
0.53834563
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.53833961
INFO - Training [60][   60/  196]   Loss 0.090941   Top1 97.024740   Top5 99.993490   BatchTime 0.305693   LR 0.000017
tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
0.53835070
tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>)
0.53836012
tensor(0.0785, device='cuda:0', grad_fn=<AddBackward0>)
0.53835094
tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>)
0.53835464
tensor(0.0676, device='cuda:0', grad_fn=<AddBackward0>)
0.53836161
tensor(0.1054, device='cuda:0', grad_fn=<AddBackward0>)
0.53835464
tensor(0.0666, device='cuda:0', grad_fn=<AddBackward0>)
0.53835487
tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)
0.53835970
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.53835285
tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
0.53834909
tensor(0.1229, device='cuda:0', grad_fn=<AddBackward0>)
0.53835058
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
0.53834701
tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)
0.53835106
tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
0.53834599
tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>)
0.53833717
tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>)
0.53832269
tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [60][   80/  196]   Loss 0.090094   Top1 97.065430   Top5 99.990234   BatchTime 0.291972   LR 0.000017
0.53831786
tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>)
0.53832006
tensor(0.1065, device='cuda:0', grad_fn=<AddBackward0>)
0.53832299
tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>)
0.53831381
tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
0.53830487
tensor(0.1190, device='cuda:0', grad_fn=<AddBackward0>)
0.53829294
tensor(0.1038, device='cuda:0', grad_fn=<AddBackward0>)
0.53828436
tensor(0.1045, device='cuda:0', grad_fn=<AddBackward0>)
0.53826869
tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
0.53826386
tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>)
0.53825355
tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>)
0.53824592
tensor(0.0857, device='cuda:0', grad_fn=<AddBackward0>)
0.53824484
tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>)
0.53823811
tensor(0.0466, device='cuda:0', grad_fn=<AddBackward0>)
0.53823942
tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>)
0.53824091
tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
0.53824145
tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
0.53823429
tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
0.53822476
tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)
0.53821510
tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>)
0.53821671
tensor(0.0847, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [60][  100/  196]   Loss 0.089986   Top1 97.082031   Top5 99.992188   BatchTime 0.293112   LR 0.000017
0.53820819
tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)
0.53820205
tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>)
0.53819990
tensor(0.0898, device='cuda:0', grad_fn=<AddBackward0>)
0.53819627
tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
0.53818643
tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
0.53817648
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.53816783
tensor(0.0871, device='cuda:0', grad_fn=<AddBackward0>)
0.53815818
tensor(0.1125, device='cuda:0', grad_fn=<AddBackward0>)
0.53814995
tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
0.53814179
tensor(0.0908, device='cuda:0', grad_fn=<AddBackward0>)
0.53814882
tensor(0.1248, device='cuda:0', grad_fn=<AddBackward0>)
0.53815132
tensor(0.1116, device='cuda:0', grad_fn=<AddBackward0>)
0.53814542
tensor(0.0313, device='cuda:0', grad_fn=<AddBackward0>)
0.53814894
tensor(0.0782, device='cuda:0', grad_fn=<AddBackward0>)
0.53814399
tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>)
0.53814286
tensor(0.1083, device='cuda:0', grad_fn=<AddBackward0>)
0.53814417
tensor(0.0961, device='cuda:0', grad_fn=<AddBackward0>)
0.53814137
tensor(0.1548, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [60][  120/  196]   Loss 0.091087   Top1 97.041016   Top5 99.993490   BatchTime 0.300298   LR 0.000016
0.53813696
tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
0.53813410
tensor(0.1187, device='cuda:0', grad_fn=<AddBackward0>)
0.53813457
tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)
0.53813326
tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>)
0.53811759
tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)
0.53810817
tensor(0.0655, device='cuda:0', grad_fn=<AddBackward0>)
0.53810167
tensor(0.1126, device='cuda:0', grad_fn=<AddBackward0>)
0.53810245
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
0.53809595
tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)
0.53809464
tensor(0.0841, device='cuda:0', grad_fn=<AddBackward0>)
0.53808570
tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)
0.53807819
tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
0.53807664
tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
0.53807729
tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>)
0.53807092
tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
0.53806967
tensor(0.1027, device='cuda:0', grad_fn=<AddBackward0>)
0.53806037
tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)
0.53804964
tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)
0.53804868
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.53804743
tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>)
0.53804547
tensor(0.0480, device='cuda:0', grad_fn=<AddBackward0>)
0.53803539
tensor(0.0895, device='cuda:0', grad_fn=<AddBackward0>)
0.53802890
tensor(0.0584, device='cuda:0', grad_fn=<AddBackward0>)
0.53802145
tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [60][  140/  196]   Loss 0.088878   Top1 97.126116   Top5 99.991629   BatchTime 0.304980   LR 0.000016
0.53801823
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.53800333
tensor(0.0825, device='cuda:0', grad_fn=<AddBackward0>)
0.53800267
tensor(0.0813, device='cuda:0', grad_fn=<AddBackward0>)
0.53799212
tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
0.53799206
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
0.53798652
tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)
0.53798521
tensor(0.1190, device='cuda:0', grad_fn=<AddBackward0>)
0.53798360
tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)
0.53798127
tensor(0.1432, device='cuda:0', grad_fn=<AddBackward0>)
0.53797293
tensor(0.1010, device='cuda:0', grad_fn=<AddBackward0>)
0.53796405
tensor(0.0806, device='cuda:0', grad_fn=<AddBackward0>)
0.53795981
tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
0.53796017
tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>)
0.53796124
tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
0.53796440
tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
0.53796983
tensor(0.0836, device='cuda:0', grad_fn=<AddBackward0>)
0.53796691
tensor(0.1083, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [60][  160/  196]   Loss 0.089775   Top1 97.111816   Top5 99.987793   BatchTime 0.307283   LR 0.000016
0.53795934
tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>)
0.53795600
tensor(0.1243, device='cuda:0', grad_fn=<AddBackward0>)
0.53795826
tensor(0.0875, device='cuda:0', grad_fn=<AddBackward0>)
0.53795570
tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
0.53794771
tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
0.53794730
tensor(0.1072, device='cuda:0', grad_fn=<AddBackward0>)
0.53793752
tensor(0.1488, device='cuda:0', grad_fn=<AddBackward0>)
0.53792763
tensor(0.0667, device='cuda:0', grad_fn=<AddBackward0>)
0.53792530
tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>)
0.53791440
tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)
0.53790528
tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>)
0.53790128
tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>)
0.53789139
tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
0.53788239
tensor(0.0678, device='cuda:0', grad_fn=<AddBackward0>)
0.53787762
tensor(0.1127, device='cuda:0', grad_fn=<AddBackward0>)
0.53787434
tensor(0.1420, device='cuda:0', grad_fn=<AddBackward0>)
0.53786689
tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>)
0.53785741
tensor(0.0413, device='cuda:0', grad_fn=<AddBackward0>)
0.53785402
tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>)
0.53784180
tensor(0.0760, device='cuda:0', grad_fn=<AddBackward0>)
0.53783655
tensor(0.0483, device='cuda:0', grad_fn=<AddBackward0>)
0.53783530
tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [60][  180/  196]   Loss 0.089512   Top1 97.102865   Top5 99.986979   BatchTime 0.302021   LR 0.000015
0.53782755
tensor(0.1038, device='cuda:0', grad_fn=<AddBackward0>)
0.53782094
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
0.53781879
tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
0.53781366
tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>)
0.53781468
tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)
0.53781086
tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
0.53779906
tensor(0.0804, device='cuda:0', grad_fn=<AddBackward0>)
0.53779030
tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>)
0.53777850
tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>)
0.53776413
tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>)
0.53775531
tensor(0.0922, device='cuda:0', grad_fn=<AddBackward0>)
0.53775024
tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)
0.53774583
tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>)
0.53774905
tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
0.53774977
tensor(0.1027, device='cuda:0', grad_fn=<AddBackward0>)
0.53774709
tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>)
0.53774250
tensor(0.1405, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 97.108    Top5: 99.986    Loss: 0.089
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [60][   20/   40]   Loss 0.411958   Top1 89.218750   Top5 99.492188   BatchTime 0.117006
INFO - Validation [60][   40/   40]   Loss 0.396924   Top1 89.350000   Top5 99.650000   BatchTime 0.083673
INFO - ==> Top1: 89.350    Top5: 99.650    Loss: 0.397
INFO - ==> Sparsity : 0.660
INFO - Scoreboard best 1 ==> Epoch [60][Top1: 89.350   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [59][Top1: 89.310   Top5: 99.640]
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 89.210   Top5: 99.690]
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1699)
features.1.conv.0 tensor(0.0462)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0964)
features.2.conv.0 tensor(0.1212)
features.2.conv.3 tensor(0.3426)
features.2.conv.6 tensor(0.5356)
features.3.conv.0 tensor(0.0703)
features.3.conv.3 tensor(0.0748)
features.3.conv.6 tensor(0.1157)
features.4.conv.0 tensor(0.1014)
features.4.conv.3 tensor(0.3015)
features.4.conv.6 tensor(0.4220)
features.5.conv.0 tensor(0.3861)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4749)
features.6.conv.0 tensor(0.0555)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0814)
features.7.conv.0 tensor(0.2912)
features.7.conv.3 tensor(0.4465)
features.7.conv.6 tensor(0.6547)
features.8.conv.0 tensor(0.5672)
features.8.conv.3 tensor(0.5370)
features.8.conv.6 tensor(0.6444)
features.9.conv.0 tensor(0.5389)
features.9.conv.3 tensor(0.5677)
features.9.conv.6 tensor(0.7589)
features.10.conv.0 tensor(0.0617)
features.10.conv.3 tensor(0.0903)
features.10.conv.6 tensor(0.0678)
features.11.conv.0 tensor(0.7749)
features.11.conv.3 tensor(0.6437)
features.11.conv.6 tensor(0.9020)
features.12.conv.0 tensor(0.7401)
features.12.conv.3 tensor(0.6634)
features.12.conv.6 tensor(0.8691)
features.13.conv.0 tensor(0.3260)
features.13.conv.3 tensor(0.4828)
features.13.conv.6 tensor(0.6169)
features.14.conv.0 tensor(0.9145)
features.14.conv.3 tensor(0.8215)
features.14.conv.6 tensor(0.9580)
features.15.conv.0 tensor(0.9018)
features.15.conv.3 tensor(0.8271)
features.15.conv.6 tensor(0.9640)
features.16.conv.0 tensor(0.7218)
features.16.conv.3 tensor(0.7884)
features.16.conv.6 tensor(0.9167)
conv.0 tensor(0.1967)
tensor(1444049.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  61
INFO - Training: 50000 samples (256 per mini-batch)
0.53773457
tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>)
0.53772521
tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)
0.53772074
tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>)
0.53771842
tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
0.53770107
tensor(0.0857, device='cuda:0', grad_fn=<AddBackward0>)
0.53769171
tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
0.53768027
tensor(0.1198, device='cuda:0', grad_fn=<AddBackward0>)
0.53768033
tensor(0.0895, device='cuda:0', grad_fn=<AddBackward0>)
0.53766847
tensor(0.0796, device='cuda:0', grad_fn=<AddBackward0>)
0.53766149
tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>)
0.53765547
tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>)
0.53765315
tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)
0.53765666
tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>)
0.53765678
tensor(0.0474, device='cuda:0', grad_fn=<AddBackward0>)
0.53765333
tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
0.53764403
tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [61][   20/  196]   Loss 0.086253   Top1 97.246094   Top5 99.921875   BatchTime 0.335235   LR 0.000015
0.53764290
tensor(0.0770, device='cuda:0', grad_fn=<AddBackward0>)
0.53763598
tensor(0.0958, device='cuda:0', grad_fn=<AddBackward0>)
0.53762841
tensor(0.1344, device='cuda:0', grad_fn=<AddBackward0>)
0.53761834
tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
0.53761327
tensor(0.0913, device='cuda:0', grad_fn=<AddBackward0>)
0.53760809
tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
0.53760916
tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
0.53761327
tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
0.53761381
tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>)
0.53760439
tensor(0.0976, device='cuda:0', grad_fn=<AddBackward0>)
0.53759801
tensor(0.0399, device='cuda:0', grad_fn=<AddBackward0>)
0.53759640
tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
0.53759229
tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>)
0.53758544
tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
0.53758031
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
0.53757352
tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
0.53756988
tensor(0.0569, device='cuda:0', grad_fn=<AddBackward0>)
0.53756547
tensor(0.0981, device='cuda:0', grad_fn=<AddBackward0>)
0.53755850
tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
0.53754723
tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [61][   40/  196]   Loss 0.084265   Top1 97.275391   Top5 99.960938   BatchTime 0.310213   LR 0.000014
0.53753674
tensor(0.0781, device='cuda:0', grad_fn=<AddBackward0>)
0.53752971
tensor(0.1010, device='cuda:0', grad_fn=<AddBackward0>)
0.53752995
tensor(0.0969, device='cuda:0', grad_fn=<AddBackward0>)
0.53752071
tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)
0.53750807
tensor(0.0666, device='cuda:0', grad_fn=<AddBackward0>)
0.53749925
tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
0.53749257
tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)
0.53749412
tensor(0.0806, device='cuda:0', grad_fn=<AddBackward0>)
0.53748918
tensor(0.0649, device='cuda:0', grad_fn=<AddBackward0>)
0.53747928
tensor(0.1009, device='cuda:0', grad_fn=<AddBackward0>)
0.53746945
tensor(0.1094, device='cuda:0', grad_fn=<AddBackward0>)
0.53746670
tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
0.53746492
tensor(0.1008, device='cuda:0', grad_fn=<AddBackward0>)
0.53745997
tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>)
0.53744698
tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>)
0.53744811
tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)
0.53743798
tensor(0.1050, device='cuda:0', grad_fn=<AddBackward0>)
0.53742844
tensor(0.0744, device='cuda:0', grad_fn=<AddBackward0>)
0.53742129
tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>)
0.53741264
tensor(0.1231, device='cuda:0', grad_fn=<AddBackward0>)
0.53740942
tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
0.53740489
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
0.53740376
tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>)
0.53739303
tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [61][   60/  196]   Loss 0.083192   Top1 97.337240   Top5 99.967448   BatchTime 0.289333   LR 0.000014
0.53739613
tensor(0.1079, device='cuda:0', grad_fn=<AddBackward0>)
0.53739351
tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>)
0.53738844
tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>)
0.53738469
tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
0.53737259
tensor(0.0818, device='cuda:0', grad_fn=<AddBackward0>)
0.53736061
tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>)
0.53735477
tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>)
0.53735250
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
0.53735632
tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>)
0.53734946
tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>)
0.53735197
tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
0.53735167
tensor(0.1033, device='cuda:0', grad_fn=<AddBackward0>)
0.53735429
tensor(0.1093, device='cuda:0', grad_fn=<AddBackward0>)
0.53736079
tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
0.53735632
tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
0.53735220
tensor(0.1093, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [61][   80/  196]   Loss 0.085771   Top1 97.250977   Top5 99.975586   BatchTime 0.279719   LR 0.000014
0.53735757
tensor(0.0746, device='cuda:0', grad_fn=<AddBackward0>)
0.53735578
tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
0.53735495
tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
0.53735936
tensor(0.0912, device='cuda:0', grad_fn=<AddBackward0>)
0.53735477
tensor(0.0478, device='cuda:0', grad_fn=<AddBackward0>)
0.53735161
tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)
0.53734362
tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
0.53733021
tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>)
0.53732735
tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>)
0.53733283
tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
0.53732073
tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
0.53731936
tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
0.53730589
tensor(0.0783, device='cuda:0', grad_fn=<AddBackward0>)
0.53730249
tensor(0.1552, device='cuda:0', grad_fn=<AddBackward0>)
0.53729624
tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>)
0.53729737
tensor(0.0865, device='cuda:0', grad_fn=<AddBackward0>)
0.53729057
tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
0.53728169
tensor(0.0760, device='cuda:0', grad_fn=<AddBackward0>)
0.53727615
tensor(0.0698, device='cuda:0', grad_fn=<AddBackward0>)
0.53726566
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
0.53725666
tensor(0.1150, device='cuda:0', grad_fn=<AddBackward0>)
0.53725201
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
0.53725308
tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
0.53724307
tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>)
0.53723305
tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [61][  100/  196]   Loss 0.085420   Top1 97.238281   Top5 99.976562   BatchTime 0.273640   LR 0.000013
0.53723133
tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
0.53722560
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.53721946
tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>)
0.53720987
tensor(0.1308, device='cuda:0', grad_fn=<AddBackward0>)
0.53720427
tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
0.53718668
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.53718644
tensor(0.0861, device='cuda:0', grad_fn=<AddBackward0>)
0.53717691
tensor(0.0436, device='cuda:0', grad_fn=<AddBackward0>)
0.53717649
tensor(0.1248, device='cuda:0', grad_fn=<AddBackward0>)
0.53716391
tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>)
0.53716516
tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
0.53715545
tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>)
0.53715205
tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
0.53715569
tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>)
0.53714687
tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
0.53714794
tensor(0.0996, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [61][  120/  196]   Loss 0.085881   Top1 97.236328   Top5 99.977214   BatchTime 0.269528   LR 0.000013
0.53714544
tensor(0.0649, device='cuda:0', grad_fn=<AddBackward0>)
0.53715116
tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>)
0.53714830
tensor(0.1330, device='cuda:0', grad_fn=<AddBackward0>)
0.53714472
tensor(0.0915, device='cuda:0', grad_fn=<AddBackward0>)
0.53714508
tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>)
0.53714317
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
0.53714269
tensor(0.0533, device='cuda:0', grad_fn=<AddBackward0>)
0.53713405
tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
0.53713274
tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>)
0.53712910
tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
0.53711808
tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>)
0.53711826
tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>)
0.53711176
tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)
0.53710455
tensor(0.0564, device='cuda:0', grad_fn=<AddBackward0>)
0.53709948
tensor(0.1196, device='cuda:0', grad_fn=<AddBackward0>)
0.53709197
tensor(0.0779, device='cuda:0', grad_fn=<AddBackward0>)
0.53708994
tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)
0.53709006
tensor(0.0494, device='cuda:0', grad_fn=<AddBackward0>)
0.53708887
tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>)
0.53708130
tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>)
0.53707850
tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>)
0.53707808
tensor(0.0824, device='cuda:0', grad_fn=<AddBackward0>)
0.53707695
tensor(0.0929, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [61][  140/  196]   Loss 0.085416   Top1 97.279576   Top5 99.977679   BatchTime 0.267698   LR 0.000013
0.53706855
tensor(0.1006, device='cuda:0', grad_fn=<AddBackward0>)
0.53705496
tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
0.53704089
tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
0.53703570
tensor(0.0705, device='cuda:0', grad_fn=<AddBackward0>)
0.53702635
tensor(0.0922, device='cuda:0', grad_fn=<AddBackward0>)
0.53701580
tensor(0.0949, device='cuda:0', grad_fn=<AddBackward0>)
0.53700382
tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
0.53699785
tensor(0.0737, device='cuda:0', grad_fn=<AddBackward0>)
0.53700048
tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
0.53699583
tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)
0.53698689
tensor(0.0679, device='cuda:0', grad_fn=<AddBackward0>)
0.53698593
tensor(0.0865, device='cuda:0', grad_fn=<AddBackward0>)
0.53698593
tensor(0.1504, device='cuda:0', grad_fn=<AddBackward0>)
0.53697544
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
0.53696913
tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
0.53695852
tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
0.53695542
tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
0.53695685
tensor(0.0906, device='cuda:0', grad_fn=<AddBackward0>)
0.53695524
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
0.53695267
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [61][  160/  196]   Loss 0.086364   Top1 97.255859   Top5 99.980469   BatchTime 0.271576   LR 0.000012
0.53694075
tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>)
0.53693885
tensor(0.1277, device='cuda:0', grad_fn=<AddBackward0>)
0.53693634
tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>)
0.53692722
tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)
0.53691906
tensor(0.0893, device='cuda:0', grad_fn=<AddBackward0>)
0.53690886
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
0.53689349
tensor(0.1044, device='cuda:0', grad_fn=<AddBackward0>)
0.53689140
tensor(0.0672, device='cuda:0', grad_fn=<AddBackward0>)
0.53688151
tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>)
0.53687632
tensor(0.0377, device='cuda:0', grad_fn=<AddBackward0>)
0.53686959
tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)
0.53687626
tensor(0.0763, device='cuda:0', grad_fn=<AddBackward0>)
0.53687292
tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>)
0.53686953
tensor(0.1057, device='cuda:0', grad_fn=<AddBackward0>)
0.53686762
tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
0.53686112
tensor(0.0662, device='cuda:0', grad_fn=<AddBackward0>)
0.53685290
tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
0.53684688
tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
0.53684640
tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>)
0.53684413
tensor(0.1292, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [61][  180/  196]   Loss 0.086213   Top1 97.235243   Top5 99.976128   BatchTime 0.275580   LR 0.000012
0.53682733
tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
0.53683329
tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)
0.53682864
tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>)
0.53682637
tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)
0.53681904
tensor(0.1145, device='cuda:0', grad_fn=<AddBackward0>)
0.53681684
tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
0.53681141
tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>)
0.53681344
tensor(0.1003, device='cuda:0', grad_fn=<AddBackward0>)
0.53681237
tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>)
0.53680736
tensor(0.0933, device='cuda:0', grad_fn=<AddBackward0>)
0.53681147
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.53680187
tensor(0.0492, device='cuda:0', grad_fn=<AddBackward0>)
0.53680295
tensor(0.1018, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 97.200    Top5: 99.976    Loss: 0.087
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.53679311
tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
0.53679031
tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
0.53678012
tensor(0.0309, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [61][   20/   40]   Loss 0.408729   Top1 89.121094   Top5 99.511719   BatchTime 0.121080
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1738)
features.1.conv.0 tensor(0.0501)
features.1.conv.3 tensor(0.0775)
features.1.conv.6 tensor(0.0951)
features.2.conv.0 tensor(0.1291)
features.2.conv.3 tensor(0.3441)
features.2.conv.6 tensor(0.5367)
features.3.conv.0 tensor(0.0715)
features.3.conv.3 tensor(0.0748)
features.3.conv.6 tensor(0.1137)
features.4.conv.0 tensor(0.0996)
features.4.conv.3 tensor(0.3003)
features.4.conv.6 tensor(0.4250)
features.5.conv.0 tensor(0.3870)
features.5.conv.3 tensor(0.4132)
features.5.conv.6 tensor(0.4759)
features.6.conv.0 tensor(0.0558)
features.6.conv.3 tensor(0.0475)
features.6.conv.6 tensor(0.0815)
features.7.conv.0 tensor(0.2938)
features.7.conv.3 tensor(0.4465)
features.7.conv.6 tensor(0.6553)
features.8.conv.0 tensor(0.5700)
features.8.conv.3 tensor(0.5376)
features.8.conv.6 tensor(0.6528)
features.9.conv.0 tensor(0.5396)
features.9.conv.3 tensor(0.5680)
features.9.conv.6 tensor(0.7592)
features.10.conv.0 tensor(0.0618)
features.10.conv.3 tensor(0.0900)
features.10.conv.6 tensor(0.0682)
features.11.conv.0 tensor(0.7761)
features.11.conv.3 tensor(0.6433)
features.11.conv.6 tensor(0.9019)
features.12.conv.0 tensor(0.7408)
features.12.conv.3 tensor(0.6630)
features.12.conv.6 tensor(0.8693)
features.13.conv.0 tensor(0.3278)
features.13.conv.3 tensor(0.4821)
features.13.conv.6 tensor(0.6207)
features.14.conv.0 tensor(0.9147)
features.14.conv.3 tensor(0.8221)
features.14.conv.6 tensor(0.9583)
features.15.conv.0 tensor(0.9023)
features.15.conv.3 tensor(0.8269)
features.15.conv.6 tensor(0.9640)
features.16.conv.0 tensor(0.7252)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.9176)
conv.0 tensor(0.2005)
tensor(1447557.) 2188896.0
INFO - Validation [61][   40/   40]   Loss 0.395400   Top1 89.240000   Top5 99.640000   BatchTime 0.086313
INFO - ==> Top1: 89.240    Top5: 99.640    Loss: 0.395
INFO - ==> Sparsity : 0.661
INFO - Scoreboard best 1 ==> Epoch [60][Top1: 89.350   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [59][Top1: 89.310   Top5: 99.640]
INFO - Scoreboard best 3 ==> Epoch [61][Top1: 89.240   Top5: 99.640]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  62
INFO - Training: 50000 samples (256 per mini-batch)
0.53678119
tensor(0.0438, device='cuda:0', grad_fn=<AddBackward0>)
0.53678119
tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
0.53676796
tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>)
0.53676420
tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
0.53676289
tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
0.53675419
tensor(0.0771, device='cuda:0', grad_fn=<AddBackward0>)
0.53675330
tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
0.53675216
tensor(0.0806, device='cuda:0', grad_fn=<AddBackward0>)
0.53674543
tensor(0.0896, device='cuda:0', grad_fn=<AddBackward0>)
0.53674495
tensor(0.0986, device='cuda:0', grad_fn=<AddBackward0>)
0.53673786
tensor(0.1036, device='cuda:0', grad_fn=<AddBackward0>)
0.53673005
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
0.53672129
tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
0.53671044
tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>)
0.53670084
tensor(0.0560, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [62][   20/  196]   Loss 0.081093   Top1 97.519531   Top5 99.960938   BatchTime 0.366516   LR 0.000012
0.53669906
tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
0.53669965
tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)
0.53669965
tensor(0.1011, device='cuda:0', grad_fn=<AddBackward0>)
0.53668493
tensor(0.1169, device='cuda:0', grad_fn=<AddBackward0>)
0.53667712
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
0.53667527
tensor(0.0958, device='cuda:0', grad_fn=<AddBackward0>)
0.53666615
tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
0.53666055
tensor(0.0858, device='cuda:0', grad_fn=<AddBackward0>)
0.53665316
tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>)
0.53664917
tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>)
0.53664428
tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)
0.53663260
tensor(0.1218, device='cuda:0', grad_fn=<AddBackward0>)
0.53663319
tensor(0.1203, device='cuda:0', grad_fn=<AddBackward0>)
0.53662151
tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
0.53659451
tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
0.53658587
tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>)
0.53657967
tensor(0.0344, device='cuda:0', grad_fn=<AddBackward0>)
0.53655928
tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>)
0.53655487
tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>)
0.53653020
tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
0.53651607
tensor(0.1345, device='cuda:0', grad_fn=<AddBackward0>)
0.53650653
tensor(0.1105, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [62][   40/  196]   Loss 0.085258   Top1 97.412109   Top5 99.960938   BatchTime 0.315214   LR 0.000011
0.53649700
tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>)
0.53648484
tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)
0.53647959
tensor(0.0809, device='cuda:0', grad_fn=<AddBackward0>)
0.53646755
tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
0.53645617
tensor(0.0412, device='cuda:0', grad_fn=<AddBackward0>)
0.53644818
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
0.53644019
tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)
0.53642082
tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
0.53641051
tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>)
0.53641164
tensor(0.0709, device='cuda:0', grad_fn=<AddBackward0>)
0.53640997
tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>)
0.53640813
tensor(0.1014, device='cuda:0', grad_fn=<AddBackward0>)
0.53640276
tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>)
0.53640330
tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>)
0.53640515
tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>)
0.53640819
tensor(0.0490, device='cuda:0', grad_fn=<AddBackward0>)
0.53640318
tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
0.53639477
tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>)
0.53638941
tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
0.53638709
tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>)
0.53638417
tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>)
0.53638124
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
0.53637373
tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [62][   60/  196]   Loss 0.085432   Top1 97.382812   Top5 99.967448   BatchTime 0.297448   LR 0.000011
0.53637069
tensor(0.0564, device='cuda:0', grad_fn=<AddBackward0>)
0.53636479
tensor(0.0584, device='cuda:0', grad_fn=<AddBackward0>)
0.53635365
tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
0.53634882
tensor(0.0932, device='cuda:0', grad_fn=<AddBackward0>)
0.53634340
tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
0.53633291
tensor(0.1004, device='cuda:0', grad_fn=<AddBackward0>)
0.53632343
tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>)
0.53631192
tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
0.53630036
tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
0.53629166
tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>)
0.53628212
tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>)
0.53626686
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.53626406
tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
0.53624791
tensor(0.0704, device='cuda:0', grad_fn=<AddBackward0>)
0.53623456
tensor(0.0673, device='cuda:0', grad_fn=<AddBackward0>)
0.53619379
tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [62][   80/  196]   Loss 0.084387   Top1 97.382812   Top5 99.970703   BatchTime 0.289890   LR 0.000011
0.53616345
tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
0.53612137
tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)
0.53609252
tensor(0.0608, device='cuda:0', grad_fn=<AddBackward0>)
0.53604543
tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
0.53599143
tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)
0.53595597
tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
0.53592306
tensor(0.1533, device='cuda:0', grad_fn=<AddBackward0>)
0.53590155
tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>)
0.53589272
tensor(0.0808, device='cuda:0', grad_fn=<AddBackward0>)
0.53589678
tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>)
0.53591156
tensor(0.0655, device='cuda:0', grad_fn=<AddBackward0>)
0.53592861
tensor(0.1358, device='cuda:0', grad_fn=<AddBackward0>)
0.53593189
tensor(0.1096, device='cuda:0', grad_fn=<AddBackward0>)
0.53592306
tensor(0.1151, device='cuda:0', grad_fn=<AddBackward0>)
0.53592247
tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
0.53591198
tensor(0.0950, device='cuda:0', grad_fn=<AddBackward0>)
0.53590357
tensor(0.0492, device='cuda:0', grad_fn=<AddBackward0>)
0.53588086
tensor(0.0890, device='cuda:0', grad_fn=<AddBackward0>)
0.53586006
tensor(0.1000, device='cuda:0', grad_fn=<AddBackward0>)
0.53584898
tensor(0.0462, device='cuda:0', grad_fn=<AddBackward0>)
0.53583658
tensor(0.1068, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [62][  100/  196]   Loss 0.084588   Top1 97.363281   Top5 99.976562   BatchTime 0.287455   LR 0.000011
0.53582084
tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
0.53582537
tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
0.53581172
tensor(0.0395, device='cuda:0', grad_fn=<AddBackward0>)
0.53580803
tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>)
0.53579861
tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
0.53578317
tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
0.53577054
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
0.53574741
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
0.53570378
tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>)
0.53566742
tensor(0.1216, device='cuda:0', grad_fn=<AddBackward0>)
0.53562474
tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>)
0.53558248
tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>)
0.53552097
tensor(0.0773, device='cuda:0', grad_fn=<AddBackward0>)
0.53548491
tensor(0.1996, device='cuda:0', grad_fn=<AddBackward0>)
0.53545970
tensor(0.0673, device='cuda:0', grad_fn=<AddBackward0>)
0.53545046
tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)
0.53544432
tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>)
0.53542560
tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>)
0.53540677
tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>)
0.53537989
tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
0.53536069
tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)
0.53533554
tensor(0.0820, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [62][  120/  196]   Loss 0.085037   Top1 97.343750   Top5 99.977214   BatchTime 0.285893   LR 0.000010
0.53532767
tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
0.53533226
tensor(0.1374, device='cuda:0', grad_fn=<AddBackward0>)
0.53532743
tensor(0.0992, device='cuda:0', grad_fn=<AddBackward0>)
0.53533322
tensor(0.0750, device='cuda:0', grad_fn=<AddBackward0>)
0.53531712
tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
0.53530335
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
0.53528661
tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
0.53527373
tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)
0.53527087
tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
0.53525668
tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
0.53524923
tensor(0.0981, device='cuda:0', grad_fn=<AddBackward0>)
0.53523839
tensor(0.1077, device='cuda:0', grad_fn=<AddBackward0>)
0.53522992
tensor(0.0779, device='cuda:0', grad_fn=<AddBackward0>)
0.53522199
tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
0.53520638
tensor(0.0774, device='cuda:0', grad_fn=<AddBackward0>)
0.53519201
tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
0.53518713
tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
0.53517443
tensor(0.0987, device='cuda:0', grad_fn=<AddBackward0>)
0.53516924
tensor(0.1106, device='cuda:0', grad_fn=<AddBackward0>)
0.53517658
tensor(0.0779, device='cuda:0', grad_fn=<AddBackward0>)
0.53517342
tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [62][  140/  196]   Loss 0.085241   Top1 97.321429   Top5 99.980469   BatchTime 0.285453   LR 0.000010
0.53517449
tensor(0.1070, device='cuda:0', grad_fn=<AddBackward0>)
0.53515780
tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>)
0.53514796
tensor(0.0997, device='cuda:0', grad_fn=<AddBackward0>)
0.53514147
tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)
0.53513360
tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
0.53512812
tensor(0.0902, device='cuda:0', grad_fn=<AddBackward0>)
0.53511924
tensor(0.0430, device='cuda:0', grad_fn=<AddBackward0>)
0.53510600
tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
0.53509897
tensor(0.0880, device='cuda:0', grad_fn=<AddBackward0>)
0.53509104
tensor(0.0464, device='cuda:0', grad_fn=<AddBackward0>)
0.53508633
tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>)
0.53507870
tensor(0.0666, device='cuda:0', grad_fn=<AddBackward0>)
0.53506863
tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)
0.53506029
tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)
0.53505480
tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
0.53504777
tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [62][  160/  196]   Loss 0.084953   Top1 97.319336   Top5 99.980469   BatchTime 0.280637   LR 0.000010
0.53505111
tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>)
0.53504229
tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)
0.53502995
tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>)
0.53502029
tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>)
0.53502256
tensor(0.0692, device='cuda:0', grad_fn=<AddBackward0>)
0.53501111
tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)
0.53501964
tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
0.53501147
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
0.53500241
tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
0.53498918
tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>)
0.53499079
tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>)
0.53497863
tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
0.53498214
tensor(0.1188, device='cuda:0', grad_fn=<AddBackward0>)
0.53497481
tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
0.53497338
tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)
0.53496897
tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)
0.53496569
tensor(0.1360, device='cuda:0', grad_fn=<AddBackward0>)
0.53495520
tensor(0.0708, device='cuda:0', grad_fn=<AddBackward0>)
0.53494740
tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
0.53494042
tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)
0.53493971
tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
0.53493494
tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>)
0.53492457
tensor(0.0853, device='cuda:0', grad_fn=<AddBackward0>)
0.53491592
tensor(0.0749, device='cuda:0', grad_fn=<AddBackward0>)
0.53490514
tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [62][  180/  196]   Loss 0.084898   Top1 97.306858   Top5 99.978299   BatchTime 0.277075   LR 0.000009
0.53489774
tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>)
0.53489393
tensor(0.1183, device='cuda:0', grad_fn=<AddBackward0>)
0.53488946
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
0.53488427
tensor(0.1007, device='cuda:0', grad_fn=<AddBackward0>)
0.53487527
tensor(0.0924, device='cuda:0', grad_fn=<AddBackward0>)
0.53486836
tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>)
0.53485996
tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>)
0.53485411
tensor(0.1238, device='cuda:0', grad_fn=<AddBackward0>)
0.53484601
tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>)
0.53484780
tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
0.53485197
tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>)
0.53484279
tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
0.53484470
tensor(0.0779, device='cuda:0', grad_fn=<AddBackward0>)
0.53483605
tensor(0.0635, device='cuda:0', grad_fn=<AddBackward0>)
0.53482383
tensor(0.0477, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 97.316    Top5: 99.972    Loss: 0.084
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [62][   20/   40]   Loss 0.408623   Top1 89.199219   Top5 99.570312   BatchTime 0.126464
INFO - Validation [62][   40/   40]   Loss 0.400815   Top1 89.280000   Top5 99.630000   BatchTime 0.089874
INFO - ==> Top1: 89.280    Top5: 99.630    Loss: 0.401
INFO - ==> Sparsity : 0.663
INFO - Scoreboard best 1 ==> Epoch [60][Top1: 89.350   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [59][Top1: 89.310   Top5: 99.640]
INFO - Scoreboard best 3 ==> Epoch [62][Top1: 89.280   Top5: 99.630]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  63
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1777)
features.1.conv.0 tensor(0.0501)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0951)
features.2.conv.0 tensor(0.1308)
features.2.conv.3 tensor(0.3434)
features.2.conv.6 tensor(0.5376)
features.3.conv.0 tensor(0.0692)
features.3.conv.3 tensor(0.0764)
features.3.conv.6 tensor(0.1124)
features.4.conv.0 tensor(0.1011)
features.4.conv.3 tensor(0.2998)
features.4.conv.6 tensor(0.4287)
features.5.conv.0 tensor(0.3879)
features.5.conv.3 tensor(0.4132)
features.5.conv.6 tensor(0.4774)
features.6.conv.0 tensor(0.0555)
features.6.conv.3 tensor(0.0480)
features.6.conv.6 tensor(0.0811)
features.7.conv.0 tensor(0.2990)
features.7.conv.3 tensor(0.4462)
features.7.conv.6 tensor(0.6558)
features.8.conv.0 tensor(0.5752)
features.8.conv.3 tensor(0.5379)
features.8.conv.6 tensor(0.6583)
features.9.conv.0 tensor(0.5424)
features.9.conv.3 tensor(0.5666)
features.9.conv.6 tensor(0.7594)
features.10.conv.0 tensor(0.0612)
features.10.conv.3 tensor(0.0909)
features.10.conv.6 tensor(0.0684)
features.11.conv.0 tensor(0.7764)
features.11.conv.3 tensor(0.6435)
features.11.conv.6 tensor(0.9021)
features.12.conv.0 tensor(0.7415)
features.12.conv.3 tensor(0.6634)
features.12.conv.6 tensor(0.8697)
features.13.conv.0 tensor(0.3271)
features.13.conv.3 tensor(0.4824)
features.13.conv.6 tensor(0.6241)
features.14.conv.0 tensor(0.9148)
features.14.conv.3 tensor(0.8225)
features.14.conv.6 tensor(0.9583)
features.15.conv.0 tensor(0.9024)
features.15.conv.3 tensor(0.8269)
features.15.conv.6 tensor(0.9640)
features.16.conv.0 tensor(0.7275)
features.16.conv.3 tensor(0.7883)
features.16.conv.6 tensor(0.9185)
conv.0 tensor(0.2032)
tensor(1450195.) 2188896.0
0.53481978
tensor(0.0773, device='cuda:0', grad_fn=<AddBackward0>)
0.53481185
tensor(0.0873, device='cuda:0', grad_fn=<AddBackward0>)
0.53480601
tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
0.53479785
tensor(0.1416, device='cuda:0', grad_fn=<AddBackward0>)
0.53480220
tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>)
0.53479487
tensor(0.1033, device='cuda:0', grad_fn=<AddBackward0>)
0.53478378
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
0.53478074
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
0.53476852
tensor(0.0415, device='cuda:0', grad_fn=<AddBackward0>)
0.53476530
tensor(0.0396, device='cuda:0', grad_fn=<AddBackward0>)
0.53475845
tensor(0.0914, device='cuda:0', grad_fn=<AddBackward0>)
0.53475529
tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
0.53475928
tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)
0.53475344
tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>)
0.53474057
tensor(0.0902, device='cuda:0', grad_fn=<AddBackward0>)
0.53473908
tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
0.53473830
tensor(0.0926, device='cuda:0', grad_fn=<AddBackward0>)
0.53473347
tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
0.53472269
tensor(0.0763, device='cuda:0', grad_fn=<AddBackward0>)
0.53471589
tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)
0.53471196
tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [63][   20/  196]   Loss 0.079084   Top1 97.597656   Top5 99.980469   BatchTime 0.320494   LR 0.000009
0.53470975
tensor(0.0820, device='cuda:0', grad_fn=<AddBackward0>)
0.53471196
tensor(0.0776, device='cuda:0', grad_fn=<AddBackward0>)
0.53471649
tensor(0.0793, device='cuda:0', grad_fn=<AddBackward0>)
0.53472096
tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>)
0.53472477
tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)
0.53472060
tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>)
0.53471893
tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>)
0.53471601
tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
0.53471029
tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>)
0.53469723
tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>)
0.53469241
tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>)
0.53469127
tensor(0.1132, device='cuda:0', grad_fn=<AddBackward0>)
0.53468716
tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>)
0.53469366
tensor(0.0556, device='cuda:0', grad_fn=<AddBackward0>)
0.53469253
tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
0.53469002
tensor(0.0860, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [63][   40/  196]   Loss 0.080883   Top1 97.392578   Top5 99.970703   BatchTime 0.281961   LR 0.000009
0.53467637
tensor(0.0923, device='cuda:0', grad_fn=<AddBackward0>)
0.53467846
tensor(0.1193, device='cuda:0', grad_fn=<AddBackward0>)
0.53467321
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.53466874
tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>)
0.53466851
tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)
0.53465629
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
0.53465587
tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)
0.53464806
tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)
0.53464288
tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>)
0.53463078
tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
0.53463411
tensor(0.1069, device='cuda:0', grad_fn=<AddBackward0>)
0.53463882
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
0.53463519
tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>)
0.53463274
tensor(0.0991, device='cuda:0', grad_fn=<AddBackward0>)
0.53462958
tensor(0.0932, device='cuda:0', grad_fn=<AddBackward0>)
0.53463143
tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>)
0.53462791
tensor(0.1044, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [63][   60/  196]   Loss 0.081495   Top1 97.337240   Top5 99.980469   BatchTime 0.269589   LR 0.000008
0.53462559
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.53462553
tensor(0.0841, device='cuda:0', grad_fn=<AddBackward0>)
0.53462154
tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
0.53460848
tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
0.53460276
tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>)
0.53459513
tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
0.53459507
tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
0.53459275
tensor(0.0499, device='cuda:0', grad_fn=<AddBackward0>)
0.53458995
tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
0.53458875
tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
0.53457856
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.53457665
tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>)
0.53457171
tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>)
0.53456968
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
0.53456444
tensor(0.1577, device='cuda:0', grad_fn=<AddBackward0>)
0.53456330
tensor(0.0494, device='cuda:0', grad_fn=<AddBackward0>)
0.53455675
tensor(0.1077, device='cuda:0', grad_fn=<AddBackward0>)
0.53456110
tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
0.53455120
tensor(0.1040, device='cuda:0', grad_fn=<AddBackward0>)
0.53454119
tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>)
0.53453720
tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)
0.53453565
tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>)
0.53453022
tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>)
0.53452832
tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [63][   80/  196]   Loss 0.082791   Top1 97.329102   Top5 99.970703   BatchTime 0.263852   LR 0.000008
0.53451991
tensor(0.0753, device='cuda:0', grad_fn=<AddBackward0>)
0.53451735
tensor(0.1131, device='cuda:0', grad_fn=<AddBackward0>)
0.53451067
tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
0.53450984
tensor(0.0598, device='cuda:0', grad_fn=<AddBackward0>)
0.53451145
tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
0.53450590
tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>)
0.53450102
tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>)
0.53450406
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
0.53450435
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
0.53450459
tensor(0.1068, device='cuda:0', grad_fn=<AddBackward0>)
0.53450978
tensor(0.0470, device='cuda:0', grad_fn=<AddBackward0>)
0.53449845
tensor(0.0959, device='cuda:0', grad_fn=<AddBackward0>)
0.53450269
tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
0.53450495
tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>)
0.53450102
tensor(0.0880, device='cuda:0', grad_fn=<AddBackward0>)
0.53449792
tensor(0.0825, device='cuda:0', grad_fn=<AddBackward0>)
0.53449541
tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
0.53448796
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.53448606
tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)
0.53447896
tensor(0.0785, device='cuda:0', grad_fn=<AddBackward0>)
0.53447855
tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
0.53447163
tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [63][  100/  196]   Loss 0.084334   Top1 97.281250   Top5 99.976562   BatchTime 0.267852   LR 0.000008
0.53445190
tensor(0.0863, device='cuda:0', grad_fn=<AddBackward0>)
0.53444415
tensor(0.0393, device='cuda:0', grad_fn=<AddBackward0>)
0.53444940
tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)
0.53444213
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
0.53444606
tensor(0.0579, device='cuda:0', grad_fn=<AddBackward0>)
0.53444618
tensor(0.0750, device='cuda:0', grad_fn=<AddBackward0>)
0.53443408
tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)
0.53443259
tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
0.53442359
tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
0.53442788
tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
0.53442538
tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
0.53442532
tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)
0.53442812
tensor(0.0933, device='cuda:0', grad_fn=<AddBackward0>)
0.53443211
tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>)
0.53443551
tensor(0.1125, device='cuda:0', grad_fn=<AddBackward0>)
0.53443044
tensor(0.1099, device='cuda:0', grad_fn=<AddBackward0>)
0.53442395
tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>)
0.53442371
tensor(0.0941, device='cuda:0', grad_fn=<AddBackward0>)
0.53442490
tensor(0.1534, device='cuda:0', grad_fn=<AddBackward0>)
0.53442508
tensor(0.0861, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [63][  120/  196]   Loss 0.084709   Top1 97.262370   Top5 99.977214   BatchTime 0.271888   LR 0.000008
0.53441125
tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)
0.53441006
tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
0.53440207
tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>)
0.53439474
tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>)
0.53439605
tensor(0.0995, device='cuda:0', grad_fn=<AddBackward0>)
0.53439480
tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>)
0.53438926
tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>)
0.53438556
tensor(0.0507, device='cuda:0', grad_fn=<AddBackward0>)
0.53438467
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
0.53438723
tensor(0.0781, device='cuda:0', grad_fn=<AddBackward0>)
0.53438300
tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)
0.53438556
tensor(0.0941, device='cuda:0', grad_fn=<AddBackward0>)
0.53438503
tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>)
0.53438401
tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
0.53438789
tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
0.53438419
tensor(0.0875, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [63][  140/  196]   Loss 0.084157   Top1 97.265625   Top5 99.974888   BatchTime 0.269374   LR 0.000007
0.53438002
tensor(0.0560, device='cuda:0', grad_fn=<AddBackward0>)
0.53437990
tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
0.53437346
tensor(0.0941, device='cuda:0', grad_fn=<AddBackward0>)
0.53436643
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
0.53436464
tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>)
0.53436381
tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)
0.53436571
tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>)
0.53436154
tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
0.53435665
tensor(0.0785, device='cuda:0', grad_fn=<AddBackward0>)
0.53436160
tensor(0.0799, device='cuda:0', grad_fn=<AddBackward0>)
0.53436023
tensor(0.1158, device='cuda:0', grad_fn=<AddBackward0>)
0.53436148
tensor(0.0890, device='cuda:0', grad_fn=<AddBackward0>)
0.53436661
tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
0.53437352
tensor(0.1065, device='cuda:0', grad_fn=<AddBackward0>)
0.53437096
tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
0.53437477
tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
0.53436345
tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
0.53436202
tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>)
0.53435886
tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)
0.53436214
tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)
0.53435796
tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>)
0.53435743
tensor(0.0798, device='cuda:0', grad_fn=<AddBackward0>)
0.53435975
tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>)
0.53436685
tensor(0.0493, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [63][  160/  196]   Loss 0.083971   Top1 97.268066   Top5 99.978027   BatchTime 0.267126   LR 0.000007
0.53436357
tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>)
0.53436542
tensor(0.0961, device='cuda:0', grad_fn=<AddBackward0>)
0.53436315
tensor(0.0666, device='cuda:0', grad_fn=<AddBackward0>)
0.53436226
tensor(0.1161, device='cuda:0', grad_fn=<AddBackward0>)
0.53436518
tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
0.53436053
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
0.53435630
tensor(0.0863, device='cuda:0', grad_fn=<AddBackward0>)
0.53435761
tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>)
0.53435022
tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>)
0.53434539
tensor(0.1258, device='cuda:0', grad_fn=<AddBackward0>)
0.53434259
tensor(0.0402, device='cuda:0', grad_fn=<AddBackward0>)
0.53434128
tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
0.53433323
tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
0.53433776
tensor(0.1236, device='cuda:0', grad_fn=<AddBackward0>)
0.53433955
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.53432775
tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [63][  180/  196]   Loss 0.083945   Top1 97.282986   Top5 99.976128   BatchTime 0.264652   LR 0.000007
0.53431964
tensor(0.0728, device='cuda:0', grad_fn=<AddBackward0>)
0.53431636
tensor(0.1378, device='cuda:0', grad_fn=<AddBackward0>)
0.53431529
tensor(0.0472, device='cuda:0', grad_fn=<AddBackward0>)
0.53431308
tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
0.53430420
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
0.53430283
tensor(0.0383, device='cuda:0', grad_fn=<AddBackward0>)
0.53430152
tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>)
0.53429937
tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>)
0.53429538
tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
0.53429347
tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
0.53428560
tensor(0.0451, device='cuda:0', grad_fn=<AddBackward0>)
0.53428191
tensor(0.0401, device='cuda:0', grad_fn=<AddBackward0>)
0.53427577
tensor(0.1179, device='cuda:0', grad_fn=<AddBackward0>)
0.53426212
tensor(0.0492, device='cuda:0', grad_fn=<AddBackward0>)
0.53425872
tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
0.53424811
tensor(0.0729, device='cuda:0', grad_fn=<AddBackward0>)
0.53424758
tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 97.336    Top5: 99.976    Loss: 0.083
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.53424346
tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)
0.53424311
tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>)
0.53424668
tensor(0.0888, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [63][   20/   40]   Loss 0.407703   Top1 88.984375   Top5 99.589844   BatchTime 0.123719
INFO - Validation [63][   40/   40]   Loss 0.392123   Top1 89.260000   Top5 99.650000   BatchTime 0.088621
INFO - ==> Top1: 89.260    Top5: 99.650    Loss: 0.392
INFO - ==> Sparsity : 0.663
INFO - Scoreboard best 1 ==> Epoch [60][Top1: 89.350   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [59][Top1: 89.310   Top5: 99.640]
INFO - Scoreboard best 3 ==> Epoch [62][Top1: 89.280   Top5: 99.630]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  64
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2812)
features.0.conv.3 tensor(0.1719)
features.1.conv.0 tensor(0.0527)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0968)
features.2.conv.0 tensor(0.1317)
features.2.conv.3 tensor(0.3441)
features.2.conv.6 tensor(0.5376)
features.3.conv.0 tensor(0.0706)
features.3.conv.3 tensor(0.0764)
features.3.conv.6 tensor(0.1128)
features.4.conv.0 tensor(0.1003)
features.4.conv.3 tensor(0.2986)
features.4.conv.6 tensor(0.4323)
features.5.conv.0 tensor(0.3921)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4788)
features.6.conv.0 tensor(0.0535)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0805)
features.7.conv.0 tensor(0.2991)
features.7.conv.3 tensor(0.4468)
features.7.conv.6 tensor(0.6567)
features.8.conv.0 tensor(0.5762)
features.8.conv.3 tensor(0.5370)
features.8.conv.6 tensor(0.6613)
features.9.conv.0 tensor(0.5423)
features.9.conv.3 tensor(0.5674)
features.9.conv.6 tensor(0.7595)
features.10.conv.0 tensor(0.0611)
features.10.conv.3 tensor(0.0903)
features.10.conv.6 tensor(0.0684)
features.11.conv.0 tensor(0.7768)
features.11.conv.3 tensor(0.6435)
features.11.conv.6 tensor(0.9022)
features.12.conv.0 tensor(0.7420)
features.12.conv.3 tensor(0.6636)
features.12.conv.6 tensor(0.8701)
features.13.conv.0 tensor(0.3254)
features.13.conv.3 tensor(0.4823)
features.13.conv.6 tensor(0.6262)
features.14.conv.0 tensor(0.9149)
features.14.conv.3 tensor(0.8223)
features.14.conv.6 tensor(0.9583)
features.15.conv.0 tensor(0.9024)
features.15.conv.3 tensor(0.8269)
features.15.conv.6 tensor(0.9641)
features.16.conv.0 tensor(0.7291)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.9189)
conv.0 tensor(0.2055)
tensor(1451906.) 2188896.0
0.53425348
tensor(0.1020, device='cuda:0', grad_fn=<AddBackward0>)
0.53425330
tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>)
0.53424317
tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>)
0.53424317
tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>)
0.53424221
tensor(0.0793, device='cuda:0', grad_fn=<AddBackward0>)
0.53423887
tensor(0.0946, device='cuda:0', grad_fn=<AddBackward0>)
0.53423524
tensor(0.0598, device='cuda:0', grad_fn=<AddBackward0>)
0.53422993
tensor(0.0690, device='cuda:0', grad_fn=<AddBackward0>)
0.53422850
tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
0.53422397
tensor(0.1065, device='cuda:0', grad_fn=<AddBackward0>)
0.53422862
tensor(0.0394, device='cuda:0', grad_fn=<AddBackward0>)
0.53422189
tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
0.53422058
tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>)
0.53421068
tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
0.53420675
tensor(0.1043, device='cuda:0', grad_fn=<AddBackward0>)
0.53421307
tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
0.53421009
tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>)
0.53420174
tensor(0.0650, device='cuda:0', grad_fn=<AddBackward0>)
0.53420156
tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
0.53419930
tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
0.53419954
tensor(0.0377, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [64][   20/  196]   Loss 0.082888   Top1 97.050781   Top5 99.980469   BatchTime 0.350345   LR 0.000007
0.53418940
tensor(0.1001, device='cuda:0', grad_fn=<AddBackward0>)
0.53418589
tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
0.53417736
tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>)
0.53417569
tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
0.53417188
tensor(0.0841, device='cuda:0', grad_fn=<AddBackward0>)
0.53416580
tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
0.53416806
tensor(0.0450, device='cuda:0', grad_fn=<AddBackward0>)
0.53415829
tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
0.53415304
tensor(0.0959, device='cuda:0', grad_fn=<AddBackward0>)
0.53414971
tensor(0.0717, device='cuda:0', grad_fn=<AddBackward0>)
0.53414237
tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
0.53414041
tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
0.53413188
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
0.53413695
tensor(0.1036, device='cuda:0', grad_fn=<AddBackward0>)
0.53413123
tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [64][   40/  196]   Loss 0.081745   Top1 97.187500   Top5 99.990234   BatchTime 0.304508   LR 0.000006
0.53412771
tensor(0.1067, device='cuda:0', grad_fn=<AddBackward0>)
0.53412199
tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>)
0.53411126
tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
0.53410858
tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>)
0.53410542
tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>)
0.53409404
tensor(0.1018, device='cuda:0', grad_fn=<AddBackward0>)
0.53409350
tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>)
0.53409600
tensor(0.1515, device='cuda:0', grad_fn=<AddBackward0>)
0.53409261
tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
0.53408492
tensor(0.1020, device='cuda:0', grad_fn=<AddBackward0>)
0.53407669
tensor(0.0776, device='cuda:0', grad_fn=<AddBackward0>)
0.53407305
tensor(0.0962, device='cuda:0', grad_fn=<AddBackward0>)
0.53406572
tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>)
0.53406662
tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>)
0.53405774
tensor(0.0881, device='cuda:0', grad_fn=<AddBackward0>)
0.53405672
tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>)
0.53405654
tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
0.53405637
tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
0.53405875
tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>)
0.53405875
tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)
0.53405583
tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
0.53404760
tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
0.53404325
tensor(0.0430, device='cuda:0', grad_fn=<AddBackward0>)
0.53404540
tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [64][   60/  196]   Loss 0.082442   Top1 97.187500   Top5 99.986979   BatchTime 0.287325   LR 0.000006
0.53404170
tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)
0.53404826
tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
0.53404844
tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
0.53404260
tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)
0.53403777
tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)
0.53402930
tensor(0.0907, device='cuda:0', grad_fn=<AddBackward0>)
0.53403300
tensor(0.0702, device='cuda:0', grad_fn=<AddBackward0>)
0.53402483
tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>)
0.53401685
tensor(0.1013, device='cuda:0', grad_fn=<AddBackward0>)
0.53401440
tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
0.53401667
tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>)
0.53401190
tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
0.53401923
tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
0.53401530
tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)
0.53401548
tensor(0.0530, device='cuda:0', grad_fn=<AddBackward0>)
0.53401154
tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>)
0.53400487
tensor(0.1253, device='cuda:0', grad_fn=<AddBackward0>)
0.53400832
tensor(0.0412, device='cuda:0', grad_fn=<AddBackward0>)
0.53399771
tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>)
0.53399241
tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
0.53398550
tensor(0.0991, device='cuda:0', grad_fn=<AddBackward0>)
0.53398949
tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [64][   80/  196]   Loss 0.082049   Top1 97.260742   Top5 99.990234   BatchTime 0.285434   LR 0.000006
0.53398943
tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>)
0.53398615
tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
0.53398424
tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
0.53397882
tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
0.53398061
tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>)
0.53397411
tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
0.53397220
tensor(0.0573, device='cuda:0', grad_fn=<AddBackward0>)
0.53396308
tensor(0.0449, device='cuda:0', grad_fn=<AddBackward0>)
0.53396040
tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>)
0.53396243
tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
0.53395128
tensor(0.0673, device='cuda:0', grad_fn=<AddBackward0>)
0.53394979
tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
0.53395039
tensor(0.1638, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [64][  100/  196]   Loss 0.081267   Top1 97.312500   Top5 99.992188   BatchTime 0.286950   LR 0.000006
0.53394777
tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
0.53394657
tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>)
0.53393799
tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
0.53393340
tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
0.53393376
tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
0.53392977
tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)
0.53393072
tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
0.53393131
tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
0.53393656
tensor(0.0605, device='cuda:0', grad_fn=<AddBackward0>)
0.53393096
tensor(0.0389, device='cuda:0', grad_fn=<AddBackward0>)
0.53393030
tensor(0.0470, device='cuda:0', grad_fn=<AddBackward0>)
0.53392875
tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>)
0.53392768
tensor(0.1036, device='cuda:0', grad_fn=<AddBackward0>)
0.53392649
tensor(0.0288, device='cuda:0', grad_fn=<AddBackward0>)
0.53391773
tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)
0.53391343
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
0.53391695
tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
0.53391176
tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
0.53390747
tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
0.53390980
tensor(0.0806, device='cuda:0', grad_fn=<AddBackward0>)
0.53390658
tensor(0.0750, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [64][  120/  196]   Loss 0.080252   Top1 97.369792   Top5 99.990234   BatchTime 0.288846   LR 0.000006
0.53390110
tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
0.53390610
tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
0.53390050
tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>)
0.53390080
tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)
0.53389841
tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
0.53389585
tensor(0.0913, device='cuda:0', grad_fn=<AddBackward0>)
0.53389657
tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
0.53390640
tensor(0.1472, device='cuda:0', grad_fn=<AddBackward0>)
0.53390038
tensor(0.0798, device='cuda:0', grad_fn=<AddBackward0>)
0.53389931
tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>)
0.53389782
tensor(0.0815, device='cuda:0', grad_fn=<AddBackward0>)
0.53389084
tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)
0.53389072
tensor(0.0393, device='cuda:0', grad_fn=<AddBackward0>)
0.53389156
tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)
0.53388125
tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
0.53387082
tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
0.53386724
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
0.53386599
tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)
0.53386486
tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>)
0.53386009
tensor(0.0887, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [64][  140/  196]   Loss 0.080947   Top1 97.343750   Top5 99.988839   BatchTime 0.289816   LR 0.000005
0.53385544
tensor(0.1316, device='cuda:0', grad_fn=<AddBackward0>)
0.53385222
tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)
0.53385365
tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>)
0.53385741
tensor(0.0744, device='cuda:0', grad_fn=<AddBackward0>)
0.53385890
tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>)
0.53385162
tensor(0.0709, device='cuda:0', grad_fn=<AddBackward0>)
0.53384864
tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)
0.53384233
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.53384435
tensor(0.1054, device='cuda:0', grad_fn=<AddBackward0>)
0.53384280
tensor(0.1021, device='cuda:0', grad_fn=<AddBackward0>)
0.53384376
tensor(0.0449, device='cuda:0', grad_fn=<AddBackward0>)
0.53384221
tensor(0.0881, device='cuda:0', grad_fn=<AddBackward0>)
0.53384441
tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
0.53384691
tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
0.53384668
tensor(0.0529, device='cuda:0', grad_fn=<AddBackward0>)
0.53384399
tensor(0.0435, device='cuda:0', grad_fn=<AddBackward0>)
0.53384578
tensor(0.0326, device='cuda:0', grad_fn=<AddBackward0>)
0.53383154
tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
0.53382760
tensor(0.0991, device='cuda:0', grad_fn=<AddBackward0>)
0.53383446
tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [64][  160/  196]   Loss 0.080311   Top1 97.360840   Top5 99.985352   BatchTime 0.290016   LR 0.000005
0.53382939
tensor(0.0789, device='cuda:0', grad_fn=<AddBackward0>)
0.53382456
tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)
0.53383070
tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
0.53383034
tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>)
0.53382891
tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
0.53382772
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.53382772
tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)
0.53382397
tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)
0.53382194
tensor(0.0690, device='cuda:0', grad_fn=<AddBackward0>)
0.53381425
tensor(0.0743, device='cuda:0', grad_fn=<AddBackward0>)
0.53380930
tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
0.53380460
tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)
0.53380382
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
0.53380197
tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>)
0.53379941
tensor(0.0913, device='cuda:0', grad_fn=<AddBackward0>)
0.53379929
tensor(0.0456, device='cuda:0', grad_fn=<AddBackward0>)
0.53379959
tensor(0.1185, device='cuda:0', grad_fn=<AddBackward0>)
0.53379214
tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
0.53378665
tensor(0.0441, device='cuda:0', grad_fn=<AddBackward0>)
0.53378332
tensor(0.0862, device='cuda:0', grad_fn=<AddBackward0>)
0.53378338
tensor(0.0782, device='cuda:0', grad_fn=<AddBackward0>)
0.53377652
tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [64][  180/  196]   Loss 0.079601   Top1 97.378472   Top5 99.986979   BatchTime 0.289959   LR 0.000005
0.53377098
tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>)
0.53376997
tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
0.53375971
tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>)
0.53375936
tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
0.53375328
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
0.53375155
tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>)
0.53375131
tensor(0.1033, device='cuda:0', grad_fn=<AddBackward0>)
0.53374702
tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>)
0.53373474
tensor(0.1028, device='cuda:0', grad_fn=<AddBackward0>)
0.53373104
tensor(0.1122, device='cuda:0', grad_fn=<AddBackward0>)
0.53372782
tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
0.53372771
tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>)
0.53372520
tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
0.53372300
tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
0.53371781
tensor(0.0605, device='cuda:0', grad_fn=<AddBackward0>)
0.53372079
tensor(0.1063, device='cuda:0', grad_fn=<AddBackward0>)
0.53372180
tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
0.53371674
tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 97.344    Top5: 99.984    Loss: 0.080
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [64][   20/   40]   Loss 0.411708   Top1 89.335938   Top5 99.589844   BatchTime 0.130651
INFO - Validation [64][   40/   40]   Loss 0.392614   Top1 89.660000   Top5 99.650000   BatchTime 0.090809
INFO - ==> Top1: 89.660    Top5: 99.650    Loss: 0.393
INFO - ==> Sparsity : 0.664
INFO - Scoreboard best 1 ==> Epoch [64][Top1: 89.660   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [60][Top1: 89.350   Top5: 99.650]
INFO - Scoreboard best 3 ==> Epoch [59][Top1: 89.310   Top5: 99.640]
features.0.conv.0 tensor(0.2882)
features.0.conv.3 tensor(0.1738)
features.1.conv.0 tensor(0.0521)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0968)
features.2.conv.0 tensor(0.1314)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.5385)
features.3.conv.0 tensor(0.0700)
features.3.conv.3 tensor(0.0764)
features.3.conv.6 tensor(0.1128)
features.4.conv.0 tensor(0.1016)
features.4.conv.3 tensor(0.2986)
features.4.conv.6 tensor(0.4338)
features.5.conv.0 tensor(0.3913)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4798)
features.6.conv.0 tensor(0.0539)
features.6.conv.3 tensor(0.0480)
features.6.conv.6 tensor(0.0801)
features.7.conv.0 tensor(0.3027)
features.7.conv.3 tensor(0.4465)
features.7.conv.6 tensor(0.6569)
features.8.conv.0 tensor(0.5769)
features.8.conv.3 tensor(0.5370)
features.8.conv.6 tensor(0.6638)
features.9.conv.0 tensor(0.5445)
features.9.conv.3 tensor(0.5666)
features.9.conv.6 tensor(0.7598)
features.10.conv.0 tensor(0.0605)
features.10.conv.3 tensor(0.0900)
features.10.conv.6 tensor(0.0684)
features.11.conv.0 tensor(0.7771)
features.11.conv.3 tensor(0.6435)
features.11.conv.6 tensor(0.9023)
features.12.conv.0 tensor(0.7423)
features.12.conv.3 tensor(0.6636)
features.12.conv.6 tensor(0.8702)
features.13.conv.0 tensor(0.3290)
features.13.conv.3 tensor(0.4824)
features.13.conv.6 tensor(0.6276)
features.14.conv.0 tensor(0.9149)
features.14.conv.3 tensor(0.8223)
features.14.conv.6 tensor(0.9583)
features.15.conv.0 tensor(0.9026)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9641)
features.16.conv.0 tensor(0.7304)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.9193)
conv.0 tensor(0.2073)
tensor(1453630.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  65
INFO - Training: 50000 samples (256 per mini-batch)
0.53371203
tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)
0.53371304
tensor(0.0483, device='cuda:0', grad_fn=<AddBackward0>)
0.53371322
tensor(0.1274, device='cuda:0', grad_fn=<AddBackward0>)
0.53371173
tensor(0.0729, device='cuda:0', grad_fn=<AddBackward0>)
0.53371960
tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
0.53371668
tensor(0.0635, device='cuda:0', grad_fn=<AddBackward0>)
0.53371227
tensor(0.0908, device='cuda:0', grad_fn=<AddBackward0>)
0.53372252
tensor(0.0438, device='cuda:0', grad_fn=<AddBackward0>)
0.53371835
tensor(0.1137, device='cuda:0', grad_fn=<AddBackward0>)
0.53371876
tensor(0.0445, device='cuda:0', grad_fn=<AddBackward0>)
0.53370756
tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>)
0.53371048
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
0.53370720
tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>)
0.53370553
tensor(0.0783, device='cuda:0', grad_fn=<AddBackward0>)
0.53370404
tensor(0.0532, device='cuda:0', grad_fn=<AddBackward0>)
0.53370267
tensor(0.1122, device='cuda:0', grad_fn=<AddBackward0>)
0.53369486
tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
0.53369719
tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)
0.53369319
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
0.53368527
tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [65][   20/  196]   Loss 0.075799   Top1 97.695312   Top5 100.000000   BatchTime 0.343831   LR 0.000005
0.53368580
tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>)
0.53368533
tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>)
0.53368568
tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>)
0.53368348
tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
0.53368324
tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>)
0.53368598
tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>)
0.53368467
tensor(0.0993, device='cuda:0', grad_fn=<AddBackward0>)
0.53369039
tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
0.53368926
tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
0.53368556
tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)
0.53368890
tensor(0.1033, device='cuda:0', grad_fn=<AddBackward0>)
0.53368914
tensor(0.0998, device='cuda:0', grad_fn=<AddBackward0>)
0.53368974
tensor(0.1218, device='cuda:0', grad_fn=<AddBackward0>)
0.53368795
tensor(0.0487, device='cuda:0', grad_fn=<AddBackward0>)
0.53368610
tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [65][   40/  196]   Loss 0.078392   Top1 97.402344   Top5 100.000000   BatchTime 0.300406   LR 0.000004
0.53368813
tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
0.53369105
tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
0.53368998
tensor(0.0594, device='cuda:0', grad_fn=<AddBackward0>)
0.53369290
tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>)
0.53368455
tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
0.53368938
tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
0.53368080
tensor(0.0854, device='cuda:0', grad_fn=<AddBackward0>)
0.53367692
tensor(0.1020, device='cuda:0', grad_fn=<AddBackward0>)
0.53367651
tensor(0.0770, device='cuda:0', grad_fn=<AddBackward0>)
0.53366816
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
0.53366560
tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>)
0.53366458
tensor(0.0947, device='cuda:0', grad_fn=<AddBackward0>)
0.53365850
tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>)
0.53365755
tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)
0.53365302
tensor(0.0980, device='cuda:0', grad_fn=<AddBackward0>)
0.53364879
tensor(0.1000, device='cuda:0', grad_fn=<AddBackward0>)
0.53364909
tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
0.53365034
tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>)
0.53364688
tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)
0.53364223
tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
0.53364116
tensor(0.0584, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [65][   60/  196]   Loss 0.079926   Top1 97.389323   Top5 99.973958   BatchTime 0.296168   LR 0.000004
0.53364211
tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
0.53363764
tensor(0.1150, device='cuda:0', grad_fn=<AddBackward0>)
0.53363514
tensor(0.0749, device='cuda:0', grad_fn=<AddBackward0>)
0.53363508
tensor(0.0954, device='cuda:0', grad_fn=<AddBackward0>)
0.53363532
tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
0.53363580
tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)
0.53363669
tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
0.53363717
tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
0.53363729
tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>)
0.53363633
tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
0.53363562
tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>)
0.53362989
tensor(0.0757, device='cuda:0', grad_fn=<AddBackward0>)
0.53363037
tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>)
0.53362781
tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>)
0.53363001
tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>)
0.53362411
tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)
0.53362042
tensor(0.0959, device='cuda:0', grad_fn=<AddBackward0>)
0.53363186
tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
0.53362995
tensor(0.0720, device='cuda:0', grad_fn=<AddBackward0>)
0.53362399
tensor(0.0655, device='cuda:0', grad_fn=<AddBackward0>)
0.53362679
tensor(0.0858, device='cuda:0', grad_fn=<AddBackward0>)
0.53362519
tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)
0.53361970
tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [65][   80/  196]   Loss 0.079410   Top1 97.392578   Top5 99.975586   BatchTime 0.287037   LR 0.000004
0.53362632
tensor(0.1238, device='cuda:0', grad_fn=<AddBackward0>)
0.53362632
tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>)
0.53362161
tensor(0.1196, device='cuda:0', grad_fn=<AddBackward0>)
0.53361905
tensor(0.0564, device='cuda:0', grad_fn=<AddBackward0>)
0.53361553
tensor(0.0957, device='cuda:0', grad_fn=<AddBackward0>)
0.53361881
tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)
0.53360242
tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>)
0.53360099
tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
0.53360248
tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
0.53360415
tensor(0.0389, device='cuda:0', grad_fn=<AddBackward0>)
0.53360140
tensor(0.0506, device='cuda:0', grad_fn=<AddBackward0>)
0.53360546
tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)
0.53360814
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
0.53359848
tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)
0.53359717
tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
0.53358907
tensor(0.0438, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [65][  100/  196]   Loss 0.078193   Top1 97.410156   Top5 99.980469   BatchTime 0.279532   LR 0.000004
0.53358787
tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>)
0.53358227
tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
0.53357673
tensor(0.0987, device='cuda:0', grad_fn=<AddBackward0>)
0.53358191
tensor(0.0649, device='cuda:0', grad_fn=<AddBackward0>)
0.53358388
tensor(0.0628, device='cuda:0', grad_fn=<AddBackward0>)
0.53358167
tensor(0.1086, device='cuda:0', grad_fn=<AddBackward0>)
0.53358608
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.53358346
tensor(0.0532, device='cuda:0', grad_fn=<AddBackward0>)
0.53357673
tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
0.53358918
tensor(0.0381, device='cuda:0', grad_fn=<AddBackward0>)
0.53358370
tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>)
0.53358126
tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
0.53357470
tensor(0.1024, device='cuda:0', grad_fn=<AddBackward0>)
0.53357917
tensor(0.0873, device='cuda:0', grad_fn=<AddBackward0>)
0.53357023
tensor(0.0466, device='cuda:0', grad_fn=<AddBackward0>)
0.53357208
tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>)
0.53356981
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
0.53357178
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
0.53357369
tensor(0.1226, device='cuda:0', grad_fn=<AddBackward0>)
0.53357631
tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
0.53357720
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
0.53357869
tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
0.53357702
tensor(0.0932, device='cuda:0', grad_fn=<AddBackward0>)
0.53357714
tensor(0.0570, device='cuda:0', grad_fn=<AddBackward0>)
0.53357130
tensor(0.0781, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [65][  120/  196]   Loss 0.077808   Top1 97.467448   Top5 99.983724   BatchTime 0.274713   LR 0.000004
0.53356439
tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
0.53356075
tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)
0.53355730
tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)
0.53355116
tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>)
0.53355879
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
0.53355891
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
0.53356606
tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>)
0.53356361
tensor(0.1062, device='cuda:0', grad_fn=<AddBackward0>)
0.53355598
tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
0.53355193
tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>)
0.53355080
tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
0.53354770
tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>)
0.53354311
tensor(0.0492, device='cuda:0', grad_fn=<AddBackward0>)
0.53354490
tensor(0.0695, device='cuda:0', grad_fn=<AddBackward0>)
0.53354263
tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
0.53353614
tensor(0.1354, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [65][  140/  196]   Loss 0.078908   Top1 97.441406   Top5 99.977679   BatchTime 0.271137   LR 0.000004
0.53353268
tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>)
0.53353161
tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>)
0.53353453
tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>)
0.53354281
tensor(0.1043, device='cuda:0', grad_fn=<AddBackward0>)
0.53353262
tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
0.53353214
tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>)
0.53352863
tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)
0.53352374
tensor(0.0833, device='cuda:0', grad_fn=<AddBackward0>)
0.53352410
tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>)
0.53351647
tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
0.53351671
tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)
0.53351414
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.53351253
tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>)
0.53351897
tensor(0.0783, device='cuda:0', grad_fn=<AddBackward0>)
0.53351563
tensor(0.0980, device='cuda:0', grad_fn=<AddBackward0>)
0.53351593
tensor(0.0918, device='cuda:0', grad_fn=<AddBackward0>)
0.53351557
tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
0.53350830
tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
0.53350335
tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>)
0.53351164
tensor(0.0961, device='cuda:0', grad_fn=<AddBackward0>)
0.53351593
tensor(0.0557, device='cuda:0', grad_fn=<AddBackward0>)
0.53351641
tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
0.53351581
tensor(0.0898, device='cuda:0', grad_fn=<AddBackward0>)
0.53351563
tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [65][  160/  196]   Loss 0.079920   Top1 97.387695   Top5 99.975586   BatchTime 0.268466   LR 0.000003
0.53352141
tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)
0.53351629
tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>)
0.53351688
tensor(0.0469, device='cuda:0', grad_fn=<AddBackward0>)
0.53352123
tensor(0.0729, device='cuda:0', grad_fn=<AddBackward0>)
0.53351676
tensor(0.0550, device='cuda:0', grad_fn=<AddBackward0>)
0.53351051
tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
0.53351331
tensor(0.1000, device='cuda:0', grad_fn=<AddBackward0>)
0.53351629
tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>)
0.53351825
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.53351158
tensor(0.0558, device='cuda:0', grad_fn=<AddBackward0>)
0.53351212
tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)
0.53350604
tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
0.53350866
tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
0.53350294
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.53350359
tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>)
0.53350085
tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [65][  180/  196]   Loss 0.080015   Top1 97.402344   Top5 99.978299   BatchTime 0.266450   LR 0.000003
0.53350133
tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>)
0.53350455
tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)
0.53349912
tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>)
0.53350002
tensor(0.1415, device='cuda:0', grad_fn=<AddBackward0>)
0.53349280
tensor(0.0888, device='cuda:0', grad_fn=<AddBackward0>)
0.53349257
tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>)
0.53348488
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
0.53348047
tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
0.53348237
tensor(0.0857, device='cuda:0', grad_fn=<AddBackward0>)
0.53348106
tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
0.53347778
tensor(0.0538, device='cuda:0', grad_fn=<AddBackward0>)
0.53348315
tensor(0.0451, device='cuda:0', grad_fn=<AddBackward0>)
0.53347439
tensor(0.0987, device='cuda:0', grad_fn=<AddBackward0>)
0.53346938
tensor(0.0918, device='cuda:0', grad_fn=<AddBackward0>)
0.53346556
tensor(0.0912, device='cuda:0', grad_fn=<AddBackward0>)
0.53346127
tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 97.404    Top5: 99.978    Loss: 0.080
0.53346872
tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>)
0.53346932
tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>)
0.53347272
tensor(0.0729, device='cuda:0', grad_fn=<AddBackward0>)
0.53347099
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [65][   20/   40]   Loss 0.412515   Top1 89.238281   Top5 99.589844   BatchTime 0.117484
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1738)
features.1.conv.0 tensor(0.0514)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0955)
features.2.conv.0 tensor(0.1314)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.5385)
features.3.conv.0 tensor(0.0720)
features.3.conv.3 tensor(0.0756)
features.3.conv.6 tensor(0.1120)
features.4.conv.0 tensor(0.1017)
features.4.conv.3 tensor(0.2992)
features.4.conv.6 tensor(0.4342)
features.5.conv.0 tensor(0.3926)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4801)
features.6.conv.0 tensor(0.0545)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0806)
features.7.conv.0 tensor(0.3011)
features.7.conv.3 tensor(0.4479)
features.7.conv.6 tensor(0.6571)
features.8.conv.0 tensor(0.5770)
features.8.conv.3 tensor(0.5367)
features.8.conv.6 tensor(0.6651)
features.9.conv.0 tensor(0.5450)
features.9.conv.3 tensor(0.5668)
features.9.conv.6 tensor(0.7599)
features.10.conv.0 tensor(0.0610)
features.10.conv.3 tensor(0.0894)
features.10.conv.6 tensor(0.0683)
features.11.conv.0 tensor(0.7773)
features.11.conv.3 tensor(0.6431)
features.11.conv.6 tensor(0.9023)
features.12.conv.0 tensor(0.7427)
features.12.conv.3 tensor(0.6636)
features.12.conv.6 tensor(0.8705)
features.13.conv.0 tensor(0.3322)
features.13.conv.3 tensor(0.4821)
features.13.conv.6 tensor(0.6287)
features.14.conv.0 tensor(0.9149)
features.14.conv.3 tensor(0.8223)
features.14.conv.6 tensor(0.9583)
features.15.conv.0 tensor(0.9027)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9641)
features.16.conv.0 tensor(0.7312)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.9196)
conv.0 tensor(0.2080)
tensor(1454478.) 2188896.0
INFO - Validation [65][   40/   40]   Loss 0.397212   Top1 89.500000   Top5 99.670000   BatchTime 0.084604
INFO - ==> Top1: 89.500    Top5: 99.670    Loss: 0.397
INFO - ==> Sparsity : 0.664
INFO - Scoreboard best 1 ==> Epoch [64][Top1: 89.660   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [65][Top1: 89.500   Top5: 99.670]
INFO - Scoreboard best 3 ==> Epoch [60][Top1: 89.350   Top5: 99.650]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  66
INFO - Training: 50000 samples (256 per mini-batch)
0.53347397
tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>)
0.53347361
tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
0.53347468
tensor(0.0779, device='cuda:0', grad_fn=<AddBackward0>)
0.53347367
tensor(0.0940, device='cuda:0', grad_fn=<AddBackward0>)
0.53346169
tensor(0.0533, device='cuda:0', grad_fn=<AddBackward0>)
0.53346080
tensor(0.0354, device='cuda:0', grad_fn=<AddBackward0>)
0.53346258
tensor(0.0783, device='cuda:0', grad_fn=<AddBackward0>)
0.53346163
tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
0.53346562
tensor(0.1117, device='cuda:0', grad_fn=<AddBackward0>)
0.53345948
tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
0.53345668
tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
0.53345746
tensor(0.0418, device='cuda:0', grad_fn=<AddBackward0>)
0.53345412
tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>)
0.53345507
tensor(0.1364, device='cuda:0', grad_fn=<AddBackward0>)
0.53345436
tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
0.53345406
tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>)
0.53344631
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [66][   20/  196]   Loss 0.079986   Top1 97.421875   Top5 99.960938   BatchTime 0.344796   LR 0.000003
0.53344661
tensor(0.0588, device='cuda:0', grad_fn=<AddBackward0>)
0.53344983
tensor(0.1042, device='cuda:0', grad_fn=<AddBackward0>)
0.53345048
tensor(0.0462, device='cuda:0', grad_fn=<AddBackward0>)
0.53345054
tensor(0.0702, device='cuda:0', grad_fn=<AddBackward0>)
0.53345311
tensor(0.0584, device='cuda:0', grad_fn=<AddBackward0>)
0.53345466
tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
0.53346485
tensor(0.0774, device='cuda:0', grad_fn=<AddBackward0>)
0.53345925
tensor(0.0728, device='cuda:0', grad_fn=<AddBackward0>)
0.53344935
tensor(0.0560, device='cuda:0', grad_fn=<AddBackward0>)
0.53345054
tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>)
0.53344411
tensor(0.0861, device='cuda:0', grad_fn=<AddBackward0>)
0.53344905
tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
0.53345275
tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
0.53344625
tensor(0.0478, device='cuda:0', grad_fn=<AddBackward0>)
0.53344876
tensor(0.0352, device='cuda:0', grad_fn=<AddBackward0>)
0.53344476
tensor(0.0987, device='cuda:0', grad_fn=<AddBackward0>)
0.53344643
tensor(0.0992, device='cuda:0', grad_fn=<AddBackward0>)
0.53344631
tensor(0.0367, device='cuda:0', grad_fn=<AddBackward0>)
0.53344637
tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>)
0.53344482
tensor(0.0796, device='cuda:0', grad_fn=<AddBackward0>)
0.53344291
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
0.53344208
tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
0.53343076
tensor(0.0470, device='cuda:0', grad_fn=<AddBackward0>)
0.53343099
tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [66][   40/  196]   Loss 0.075892   Top1 97.646484   Top5 99.960938   BatchTime 0.297011   LR 0.000003
0.53342587
tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
0.53342587
tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>)
0.53341711
tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
0.53341335
tensor(0.0825, device='cuda:0', grad_fn=<AddBackward0>)
0.53341210
tensor(0.0964, device='cuda:0', grad_fn=<AddBackward0>)
0.53341305
tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
0.53341365
tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
0.53341472
tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)
0.53341401
tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
0.53341138
tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>)
0.53340638
tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>)
0.53340977
tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)
0.53340542
tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>)
0.53340912
tensor(0.1132, device='cuda:0', grad_fn=<AddBackward0>)
0.53340644
tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>)
0.53340805
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [66][   60/  196]   Loss 0.076782   Top1 97.630208   Top5 99.960938   BatchTime 0.280883   LR 0.000003
0.53340948
tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)
0.53340572
tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
0.53340274
tensor(0.0494, device='cuda:0', grad_fn=<AddBackward0>)
0.53339505
tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>)
0.53339863
tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>)
0.53339881
tensor(0.0312, device='cuda:0', grad_fn=<AddBackward0>)
0.53339338
tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>)
0.53338498
tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
0.53338826
tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
0.53339064
tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>)
0.53338945
tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>)
0.53338963
tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>)
0.53338915
tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>)
0.53338844
tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
0.53337765
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
0.53338331
tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)
0.53339279
tensor(0.0737, device='cuda:0', grad_fn=<AddBackward0>)
0.53338391
tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
0.53338599
tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>)
0.53338742
tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
0.53339058
tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>)
0.53339094
tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>)
0.53339314
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
0.53338903
tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [66][   80/  196]   Loss 0.078199   Top1 97.573242   Top5 99.965820   BatchTime 0.273313   LR 0.000002
0.53338963
tensor(0.1230, device='cuda:0', grad_fn=<AddBackward0>)
0.53338319
tensor(0.0645, device='cuda:0', grad_fn=<AddBackward0>)
0.53338671
tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)
0.53337532
tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>)
0.53336883
tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
0.53337979
tensor(0.0824, device='cuda:0', grad_fn=<AddBackward0>)
0.53337693
tensor(0.0628, device='cuda:0', grad_fn=<AddBackward0>)
0.53337079
tensor(0.0573, device='cuda:0', grad_fn=<AddBackward0>)
0.53337443
tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
0.53337079
tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
0.53336412
tensor(0.0705, device='cuda:0', grad_fn=<AddBackward0>)
0.53337276
tensor(0.0926, device='cuda:0', grad_fn=<AddBackward0>)
0.53336740
tensor(0.0584, device='cuda:0', grad_fn=<AddBackward0>)
0.53337431
tensor(0.0796, device='cuda:0', grad_fn=<AddBackward0>)
0.53337342
tensor(0.0462, device='cuda:0', grad_fn=<AddBackward0>)
0.53337717
tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [66][  100/  196]   Loss 0.077118   Top1 97.601562   Top5 99.968750   BatchTime 0.268803   LR 0.000002
0.53338534
tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>)
0.53337848
tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
0.53337228
tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
0.53336340
tensor(0.0958, device='cuda:0', grad_fn=<AddBackward0>)
0.53336239
tensor(0.0459, device='cuda:0', grad_fn=<AddBackward0>)
0.53335547
tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
0.53335023
tensor(0.0836, device='cuda:0', grad_fn=<AddBackward0>)
0.53334945
tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>)
0.53334624
tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
0.53335226
tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
0.53335690
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.53335416
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
0.53334332
tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
0.53334260
tensor(0.1048, device='cuda:0', grad_fn=<AddBackward0>)
0.53334117
tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
0.53334004
tensor(0.0923, device='cuda:0', grad_fn=<AddBackward0>)
0.53334475
tensor(0.0318, device='cuda:0', grad_fn=<AddBackward0>)
0.53334135
tensor(0.1041, device='cuda:0', grad_fn=<AddBackward0>)
0.53334475
tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)
0.53335285
tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
0.53334904
tensor(0.0841, device='cuda:0', grad_fn=<AddBackward0>)
0.53334731
tensor(0.0439, device='cuda:0', grad_fn=<AddBackward0>)
0.53334349
tensor(0.0949, device='cuda:0', grad_fn=<AddBackward0>)
0.53334427
tensor(0.0902, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [66][  120/  196]   Loss 0.077603   Top1 97.587891   Top5 99.970703   BatchTime 0.265274   LR 0.000002
0.53334385
tensor(0.0715, device='cuda:0', grad_fn=<AddBackward0>)
0.53334242
tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>)
0.53333724
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
0.53334832
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.53334385
tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
0.53333962
tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>)
0.53334546
tensor(0.0524, device='cuda:0', grad_fn=<AddBackward0>)
0.53334796
tensor(0.0594, device='cuda:0', grad_fn=<AddBackward0>)
0.53334504
tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>)
0.53333873
tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)
0.53334141
tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>)
0.53333813
tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>)
0.53333032
tensor(0.1430, device='cuda:0', grad_fn=<AddBackward0>)
0.53333116
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.53332990
tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>)
0.53332275
tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [66][  140/  196]   Loss 0.077009   Top1 97.600446   Top5 99.972098   BatchTime 0.265007   LR 0.000002
0.53332621
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
0.53332704
tensor(0.0704, device='cuda:0', grad_fn=<AddBackward0>)
0.53333163
tensor(0.0911, device='cuda:0', grad_fn=<AddBackward0>)
0.53332824
tensor(0.0918, device='cuda:0', grad_fn=<AddBackward0>)
0.53332710
tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
0.53332013
tensor(0.0420, device='cuda:0', grad_fn=<AddBackward0>)
0.53332072
tensor(0.0770, device='cuda:0', grad_fn=<AddBackward0>)
0.53332508
tensor(0.1431, device='cuda:0', grad_fn=<AddBackward0>)
0.53332341
tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>)
0.53333676
tensor(0.0650, device='cuda:0', grad_fn=<AddBackward0>)
0.53334004
tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
0.53334683
tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>)
0.53333759
tensor(0.0672, device='cuda:0', grad_fn=<AddBackward0>)
0.53333610
tensor(0.0698, device='cuda:0', grad_fn=<AddBackward0>)
0.53333545
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
0.53333420
tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>)
0.53333372
tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)
0.53333336
tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
0.53333861
tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
0.53333050
tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
0.53332561
tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
0.53332531
tensor(0.0379, device='cuda:0', grad_fn=<AddBackward0>)
0.53332758
tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>)
0.53332698
tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [66][  160/  196]   Loss 0.077920   Top1 97.558594   Top5 99.975586   BatchTime 0.263011   LR 0.000002
0.53332263
tensor(0.0825, device='cuda:0', grad_fn=<AddBackward0>)
0.53332132
tensor(0.0976, device='cuda:0', grad_fn=<AddBackward0>)
0.53332955
tensor(0.1294, device='cuda:0', grad_fn=<AddBackward0>)
0.53332502
tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)
0.53333104
tensor(0.0924, device='cuda:0', grad_fn=<AddBackward0>)
0.53333861
tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)
0.53332901
tensor(0.0961, device='cuda:0', grad_fn=<AddBackward0>)
0.53333014
tensor(0.0715, device='cuda:0', grad_fn=<AddBackward0>)
0.53333342
tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
0.53333181
tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>)
0.53333431
tensor(0.0774, device='cuda:0', grad_fn=<AddBackward0>)
0.53333926
tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>)
0.53333753
tensor(0.0918, device='cuda:0', grad_fn=<AddBackward0>)
0.53333110
tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
0.53333336
tensor(0.1044, device='cuda:0', grad_fn=<AddBackward0>)
0.53333420
INFO - Training [66][  180/  196]   Loss 0.078584   Top1 97.519531   Top5 99.978299   BatchTime 0.261767   LR 0.000002
tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>)
0.53332645
tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>)
0.53333390
tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>)
0.53332639
tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>)
0.53332543
tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>)
0.53332436
tensor(0.0880, device='cuda:0', grad_fn=<AddBackward0>)
0.53331399
tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>)
0.53332061
tensor(0.0744, device='cuda:0', grad_fn=<AddBackward0>)
0.53332239
tensor(0.0880, device='cuda:0', grad_fn=<AddBackward0>)
0.53332722
tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>)
0.53331822
tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>)
0.53332829
tensor(0.0890, device='cuda:0', grad_fn=<AddBackward0>)
0.53332973
tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
0.53332752
tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)
0.53332561
tensor(0.0841, device='cuda:0', grad_fn=<AddBackward0>)
0.53332400
tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
0.53332216
tensor(0.1206, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 97.466    Top5: 99.976    Loss: 0.080
0.53332084
tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>)
0.53332019
tensor(0.0592, device='cuda:0', grad_fn=<AddBackward0>)
0.53332657
tensor(0.0892, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [66][   20/   40]   Loss 0.415126   Top1 89.238281   Top5 99.550781   BatchTime 0.124918
INFO - Validation [66][   40/   40]   Loss 0.400389   Top1 89.290000   Top5 99.640000   BatchTime 0.090597
INFO - ==> Top1: 89.290    Top5: 99.640    Loss: 0.400
INFO - ==> Sparsity : 0.665
INFO - Scoreboard best 1 ==> Epoch [64][Top1: 89.660   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [65][Top1: 89.500   Top5: 99.670]
INFO - Scoreboard best 3 ==> Epoch [60][Top1: 89.350   Top5: 99.650]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  67
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1738)
features.1.conv.0 tensor(0.0514)
features.1.conv.3 tensor(0.0775)
features.1.conv.6 tensor(0.0955)
features.2.conv.0 tensor(0.1325)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.5385)
features.3.conv.0 tensor(0.0715)
features.3.conv.3 tensor(0.0756)
features.3.conv.6 tensor(0.1118)
features.4.conv.0 tensor(0.1025)
features.4.conv.3 tensor(0.2992)
features.4.conv.6 tensor(0.4341)
features.5.conv.0 tensor(0.3937)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4803)
features.6.conv.0 tensor(0.0544)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0799)
features.7.conv.0 tensor(0.3026)
features.7.conv.3 tensor(0.4470)
features.7.conv.6 tensor(0.6571)
features.8.conv.0 tensor(0.5769)
features.8.conv.3 tensor(0.5367)
features.8.conv.6 tensor(0.6659)
features.9.conv.0 tensor(0.5451)
features.9.conv.3 tensor(0.5668)
features.9.conv.6 tensor(0.7602)
features.10.conv.0 tensor(0.0612)
features.10.conv.3 tensor(0.0900)
features.10.conv.6 tensor(0.0683)
features.11.conv.0 tensor(0.7773)
features.11.conv.3 tensor(0.6433)
features.11.conv.6 tensor(0.9022)
features.12.conv.0 tensor(0.7430)
features.12.conv.3 tensor(0.6634)
features.12.conv.6 tensor(0.8706)
features.13.conv.0 tensor(0.3324)
features.13.conv.3 tensor(0.4823)
features.13.conv.6 tensor(0.6290)
features.14.conv.0 tensor(0.9150)
features.14.conv.3 tensor(0.8223)
features.14.conv.6 tensor(0.9584)
features.15.conv.0 tensor(0.9027)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9641)
features.16.conv.0 tensor(0.7318)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.9197)
conv.0 tensor(0.2090)
tensor(1455169.) 2188896.0
0.53334868
tensor(0.0454, device='cuda:0', grad_fn=<AddBackward0>)
0.53334016
tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>)
0.53334099
tensor(0.0847, device='cuda:0', grad_fn=<AddBackward0>)
0.53333598
tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>)
0.53332978
tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
0.53332514
tensor(0.0969, device='cuda:0', grad_fn=<AddBackward0>)
0.53331780
tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>)
0.53331149
tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>)
0.53331274
tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>)
0.53330827
tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
0.53330600
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
0.53330457
tensor(0.0847, device='cuda:0', grad_fn=<AddBackward0>)
0.53330994
tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
0.53331441
tensor(0.0662, device='cuda:0', grad_fn=<AddBackward0>)
0.53331453
tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>)
0.53331363
tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
0.53330624
tensor(0.1032, device='cuda:0', grad_fn=<AddBackward0>)
0.53331119
tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
0.53330982
tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
0.53330880
tensor(0.0454, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [67][   20/  196]   Loss 0.074127   Top1 97.382812   Top5 99.980469   BatchTime 0.376795   LR 0.000002
0.53330511
tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
0.53331107
tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)
0.53332442
tensor(0.1476, device='cuda:0', grad_fn=<AddBackward0>)
0.53332949
tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
0.53332859
tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>)
0.53332973
tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>)
0.53333187
tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
0.53333563
tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
0.53332990
tensor(0.0649, device='cuda:0', grad_fn=<AddBackward0>)
0.53333157
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.53333431
tensor(0.0770, device='cuda:0', grad_fn=<AddBackward0>)
0.53333235
tensor(0.0434, device='cuda:0', grad_fn=<AddBackward0>)
0.53332639
tensor(0.1151, device='cuda:0', grad_fn=<AddBackward0>)
0.53332126
tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)
0.53331745
tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>)
0.53331780
tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)
0.53331697
tensor(0.0770, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [67][   40/  196]   Loss 0.079757   Top1 97.294922   Top5 99.980469   BatchTime 0.353208   LR 0.000002
0.53332114
tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
0.53331578
tensor(0.1357, device='cuda:0', grad_fn=<AddBackward0>)
0.53331947
tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
0.53331667
tensor(0.0449, device='cuda:0', grad_fn=<AddBackward0>)
0.53331691
tensor(0.0425, device='cuda:0', grad_fn=<AddBackward0>)
0.53332305
tensor(0.0946, device='cuda:0', grad_fn=<AddBackward0>)
0.53332108
tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
0.53332567
tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
0.53332222
tensor(0.1430, device='cuda:0', grad_fn=<AddBackward0>)
0.53332049
tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>)
0.53332669
tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>)
0.53332072
tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
0.53333229
tensor(0.1022, device='cuda:0', grad_fn=<AddBackward0>)
0.53332758
tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
0.53333330
tensor(0.1266, device='cuda:0', grad_fn=<AddBackward0>)
0.53332609
tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
0.53332466
tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>)
0.53332371
tensor(0.1166, device='cuda:0', grad_fn=<AddBackward0>)
0.53332001
tensor(0.0997, device='cuda:0', grad_fn=<AddBackward0>)
0.53331864
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
0.53331846
tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)
0.53331590
tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
0.53331298
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
0.53331763
tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [67][   60/  196]   Loss 0.082051   Top1 97.304688   Top5 99.980469   BatchTime 0.320048   LR 0.000001
0.53331542
tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
0.53331453
tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>)
0.53332001
tensor(0.1005, device='cuda:0', grad_fn=<AddBackward0>)
0.53332877
tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>)
0.53333515
tensor(0.1234, device='cuda:0', grad_fn=<AddBackward0>)
0.53333282
tensor(0.0732, device='cuda:0', grad_fn=<AddBackward0>)
0.53332371
tensor(0.1165, device='cuda:0', grad_fn=<AddBackward0>)
0.53331411
tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)
0.53331512
tensor(0.0858, device='cuda:0', grad_fn=<AddBackward0>)
0.53330386
tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
0.53331316
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
0.53331262
tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
0.53330636
tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>)
0.53331697
tensor(0.1005, device='cuda:0', grad_fn=<AddBackward0>)
0.53331870
tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)
0.53330159
tensor(0.0980, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [67][   80/  196]   Loss 0.083206   Top1 97.294922   Top5 99.980469   BatchTime 0.302913   LR 0.000001
0.53329837
tensor(0.0655, device='cuda:0', grad_fn=<AddBackward0>)
0.53329378
tensor(0.0623, device='cuda:0', grad_fn=<AddBackward0>)
0.53328830
tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
0.53328925
tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>)
0.53329706
tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
0.53329432
tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>)
0.53329206
tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
0.53328693
tensor(0.0341, device='cuda:0', grad_fn=<AddBackward0>)
0.53328985
tensor(0.0476, device='cuda:0', grad_fn=<AddBackward0>)
0.53328991
tensor(0.0933, device='cuda:0', grad_fn=<AddBackward0>)
0.53329605
tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
0.53329688
tensor(0.1023, device='cuda:0', grad_fn=<AddBackward0>)
0.53329635
tensor(0.0605, device='cuda:0', grad_fn=<AddBackward0>)
0.53330207
tensor(0.1000, device='cuda:0', grad_fn=<AddBackward0>)
0.53330702
tensor(0.1063, device='cuda:0', grad_fn=<AddBackward0>)
0.53330004
tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
0.53330320
tensor(0.0650, device='cuda:0', grad_fn=<AddBackward0>)
0.53330189
tensor(0.0604, device='cuda:0', grad_fn=<AddBackward0>)
0.53329831
tensor(0.0530, device='cuda:0', grad_fn=<AddBackward0>)
0.53329819
tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
0.53330129
tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>)
0.53329611
tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
0.53329515
tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [67][  100/  196]   Loss 0.082658   Top1 97.320312   Top5 99.984375   BatchTime 0.293346   LR 0.000001
0.53329521
tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>)
0.53328961
tensor(0.1072, device='cuda:0', grad_fn=<AddBackward0>)
0.53328961
tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
0.53328615
tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)
0.53328860
tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)
0.53328764
tensor(0.0899, device='cuda:0', grad_fn=<AddBackward0>)
0.53328425
tensor(0.0579, device='cuda:0', grad_fn=<AddBackward0>)
0.53328997
tensor(0.1071, device='cuda:0', grad_fn=<AddBackward0>)
0.53329593
tensor(0.0348, device='cuda:0', grad_fn=<AddBackward0>)
0.53329515
tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)
0.53329545
tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
0.53329903
tensor(0.0467, device='cuda:0', grad_fn=<AddBackward0>)
0.53329521
tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>)
0.53329444
tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>)
0.53329641
tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
0.53329515
tensor(0.0359, device='cuda:0', grad_fn=<AddBackward0>)
0.53329849
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
0.53329402
tensor(0.1182, device='cuda:0', grad_fn=<AddBackward0>)
0.53329253
tensor(0.0818, device='cuda:0', grad_fn=<AddBackward0>)
0.53328788
tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>)
0.53328794
tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>)
0.53329009
tensor(0.0810, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [67][  120/  196]   Loss 0.081695   Top1 97.356771   Top5 99.977214   BatchTime 0.290085   LR 0.000001
0.53329343
tensor(0.0479, device='cuda:0', grad_fn=<AddBackward0>)
0.53328866
tensor(0.0323, device='cuda:0', grad_fn=<AddBackward0>)
0.53329527
tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>)
0.53329849
tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>)
0.53329587
tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>)
0.53329706
tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>)
0.53329521
tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>)
0.53329682
tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)
0.53330177
tensor(0.0717, device='cuda:0', grad_fn=<AddBackward0>)
0.53329521
tensor(0.0793, device='cuda:0', grad_fn=<AddBackward0>)
0.53330344
tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>)
0.53329843
tensor(0.0444, device='cuda:0', grad_fn=<AddBackward0>)
0.53329706
tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>)
0.53329492
tensor(0.0959, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [67][  140/  196]   Loss 0.080705   Top1 97.393973   Top5 99.977679   BatchTime 0.287879   LR 0.000001
0.53329581
tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
0.53329504
tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
0.53330016
tensor(0.1096, device='cuda:0', grad_fn=<AddBackward0>)
0.53329897
tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
0.53328878
tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>)
0.53329772
tensor(0.0763, device='cuda:0', grad_fn=<AddBackward0>)
0.53330237
tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)
0.53329605
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
0.53329444
tensor(0.0822, device='cuda:0', grad_fn=<AddBackward0>)
0.53329849
tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
0.53329533
tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
0.53330201
tensor(0.0341, device='cuda:0', grad_fn=<AddBackward0>)
0.53330672
tensor(0.1022, device='cuda:0', grad_fn=<AddBackward0>)
0.53329986
tensor(0.0450, device='cuda:0', grad_fn=<AddBackward0>)
0.53329736
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
0.53329140
tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
0.53329724
tensor(0.1052, device='cuda:0', grad_fn=<AddBackward0>)
0.53329688
tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
0.53329188
tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)
0.53329706
tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
0.53330320
tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [67][  160/  196]   Loss 0.080223   Top1 97.421875   Top5 99.978027   BatchTime 0.290466   LR 0.000001
0.53330469
tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>)
0.53331000
tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
0.53330499
tensor(0.1203, device='cuda:0', grad_fn=<AddBackward0>)
0.53330380
tensor(0.0877, device='cuda:0', grad_fn=<AddBackward0>)
0.53329897
tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>)
0.53329235
tensor(0.0831, device='cuda:0', grad_fn=<AddBackward0>)
0.53329045
tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)
0.53328699
tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
0.53328425
tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>)
0.53328300
tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>)
0.53328329
tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
0.53329009
tensor(0.0692, device='cuda:0', grad_fn=<AddBackward0>)
0.53328854
tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
0.53328788
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
0.53328949
tensor(0.1055, device='cuda:0', grad_fn=<AddBackward0>)
0.53329182
tensor(0.0537, device='cuda:0', grad_fn=<AddBackward0>)
0.53329313
tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
0.53328979
tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)
0.53328592
tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)
0.53328615
tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>)
0.53328663
tensor(0.0946, device='cuda:0', grad_fn=<AddBackward0>)
0.53328151
tensor(0.0863, device='cuda:0', grad_fn=<AddBackward0>)
0.53327876
tensor(0.1022, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [67][  180/  196]   Loss 0.079912   Top1 97.430556   Top5 99.978299   BatchTime 0.286566   LR 0.000001
0.53327417
tensor(0.1240, device='cuda:0', grad_fn=<AddBackward0>)
0.53328484
tensor(0.1092, device='cuda:0', grad_fn=<AddBackward0>)
0.53328276
tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)
0.53328133
tensor(0.0867, device='cuda:0', grad_fn=<AddBackward0>)
0.53328389
tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
0.53328818
tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>)
0.53327715
tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
0.53326821
tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
0.53327489
tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)
0.53327090
tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
0.53326541
tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
0.53326392
tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
0.53325683
tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>)
0.53325856
tensor(0.0728, device='cuda:0', grad_fn=<AddBackward0>)
0.53326476
tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>)
0.53326374
tensor(0.1230, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - ==> Top1: 97.404    Top5: 99.980    Loss: 0.080
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [67][   20/   40]   Loss 0.408449   Top1 89.121094   Top5 99.531250   BatchTime 0.116563
INFO - Validation [67][   40/   40]   Loss 0.394008   Top1 89.370000   Top5 99.650000   BatchTime 0.082515
INFO - ==> Top1: 89.370    Top5: 99.650    Loss: 0.394
INFO - ==> Sparsity : 0.665
INFO - Scoreboard best 1 ==> Epoch [64][Top1: 89.660   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [65][Top1: 89.500   Top5: 99.670]
INFO - Scoreboard best 3 ==> Epoch [67][Top1: 89.370   Top5: 99.650]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  68
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1738)
features.1.conv.0 tensor(0.0521)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0955)
features.2.conv.0 tensor(0.1337)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.5385)
features.3.conv.0 tensor(0.0706)
features.3.conv.3 tensor(0.0756)
features.3.conv.6 tensor(0.1122)
features.4.conv.0 tensor(0.1016)
features.4.conv.3 tensor(0.2992)
features.4.conv.6 tensor(0.4347)
features.5.conv.0 tensor(0.3942)
features.5.conv.3 tensor(0.4144)
features.5.conv.6 tensor(0.4805)
features.6.conv.0 tensor(0.0540)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0802)
features.7.conv.0 tensor(0.3025)
features.7.conv.3 tensor(0.4470)
features.7.conv.6 tensor(0.6572)
features.8.conv.0 tensor(0.5770)
features.8.conv.3 tensor(0.5367)
features.8.conv.6 tensor(0.6661)
features.9.conv.0 tensor(0.5453)
features.9.conv.3 tensor(0.5660)
features.9.conv.6 tensor(0.7601)
features.10.conv.0 tensor(0.0610)
features.10.conv.3 tensor(0.0897)
features.10.conv.6 tensor(0.0682)
features.11.conv.0 tensor(0.7774)
features.11.conv.3 tensor(0.6433)
features.11.conv.6 tensor(0.9022)
features.12.conv.0 tensor(0.7429)
features.12.conv.3 tensor(0.6634)
features.12.conv.6 tensor(0.8706)
features.13.conv.0 tensor(0.3334)
features.13.conv.3 tensor(0.4821)
features.13.conv.6 tensor(0.6295)
features.14.conv.0 tensor(0.9150)
features.14.conv.3 tensor(0.8223)
features.14.conv.6 tensor(0.9584)
features.15.conv.0 tensor(0.9028)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9641)
features.16.conv.0 tensor(0.7320)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.9198)
conv.0 tensor(0.2093)
tensor(1455471.) 2188896.0
0.53326595
tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>)
0.53325880
tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>)
0.53326309
tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)
0.53326499
tensor(0.0464, device='cuda:0', grad_fn=<AddBackward0>)
0.53325969
tensor(0.1044, device='cuda:0', grad_fn=<AddBackward0>)
0.53326714
tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>)
0.53327006
tensor(0.0684, device='cuda:0', grad_fn=<AddBackward0>)
0.53327745
tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
0.53327900
tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>)
0.53328109
tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
0.53328001
tensor(0.0923, device='cuda:0', grad_fn=<AddBackward0>)
0.53327215
tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>)
0.53326720
tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
0.53326952
tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
0.53326362
tensor(0.0804, device='cuda:0', grad_fn=<AddBackward0>)
0.53326839
tensor(0.0940, device='cuda:0', grad_fn=<AddBackward0>)
0.53326833
tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
0.53326696
tensor(0.1475, device='cuda:0', grad_fn=<AddBackward0>)
0.53326750
tensor(0.1343, device='cuda:0', grad_fn=<AddBackward0>)
0.53326541
tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
0.53326350
tensor(0.1188, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [68][   20/  196]   Loss 0.087522   Top1 96.933594   Top5 99.980469   BatchTime 0.366060   LR 0.000001
0.53325868
tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>)
0.53327042
tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>)
0.53328145
tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
0.53328389
tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
0.53327811
tensor(0.0847, device='cuda:0', grad_fn=<AddBackward0>)
0.53328353
tensor(0.1101, device='cuda:0', grad_fn=<AddBackward0>)
0.53328651
tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
0.53327912
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
0.53328115
tensor(0.0824, device='cuda:0', grad_fn=<AddBackward0>)
0.53328222
tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>)
0.53328174
tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>)
0.53328502
tensor(0.1389, device='cuda:0', grad_fn=<AddBackward0>)
0.53328741
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
0.53328478
tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [68][   40/  196]   Loss 0.090870   Top1 96.884766   Top5 99.980469   BatchTime 0.323326   LR 0.000001
0.53328311
tensor(0.1100, device='cuda:0', grad_fn=<AddBackward0>)
0.53328782
tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)
0.53328222
tensor(0.1417, device='cuda:0', grad_fn=<AddBackward0>)
0.53328907
tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>)
0.53328288
tensor(0.1125, device='cuda:0', grad_fn=<AddBackward0>)
0.53327644
tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>)
0.53327024
tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
0.53326452
tensor(0.0341, device='cuda:0', grad_fn=<AddBackward0>)
0.53326565
tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>)
0.53326398
tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)
0.53326327
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
0.53327537
tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
0.53326946
tensor(0.0728, device='cuda:0', grad_fn=<AddBackward0>)
0.53326786
tensor(0.0806, device='cuda:0', grad_fn=<AddBackward0>)
0.53326595
tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
0.53326893
tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
0.53325868
tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)
0.53325540
tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
0.53326237
tensor(0.0455, device='cuda:0', grad_fn=<AddBackward0>)
0.53326195
tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
0.53325808
tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
0.53326046
tensor(0.0895, device='cuda:0', grad_fn=<AddBackward0>)
0.53326130
tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
0.53326666
tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [68][   60/  196]   Loss 0.084060   Top1 97.213542   Top5 99.973958   BatchTime 0.299618   LR 0.000001
0.53326440
tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
0.53326058
tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)
0.53326976
tensor(0.0854, device='cuda:0', grad_fn=<AddBackward0>)
0.53327131
tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
0.53326619
tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>)
0.53326744
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.53326803
tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
0.53326708
tensor(0.0469, device='cuda:0', grad_fn=<AddBackward0>)
0.53325647
tensor(0.0756, device='cuda:0', grad_fn=<AddBackward0>)
0.53326315
tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
0.53325558
tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
0.53325778
tensor(0.0604, device='cuda:0', grad_fn=<AddBackward0>)
0.53326249
tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>)
0.53327042
tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
0.53327817
tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>)
0.53327549
tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)
0.53326875
tensor(0.1132, device='cuda:0', grad_fn=<AddBackward0>)
0.53325987
tensor(0.1027, device='cuda:0', grad_fn=<AddBackward0>)
0.53326303
tensor(0.0844, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [68][   80/  196]   Loss 0.082522   Top1 97.236328   Top5 99.980469   BatchTime 0.303218   LR 0.000000
0.53325498
tensor(0.0918, device='cuda:0', grad_fn=<AddBackward0>)
0.53325331
tensor(0.1068, device='cuda:0', grad_fn=<AddBackward0>)
0.53325421
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
0.53325665
tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
0.53325367
tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>)
0.53324777
tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
0.53324318
tensor(0.0550, device='cuda:0', grad_fn=<AddBackward0>)
0.53324777
tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
0.53324360
tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>)
0.53324002
tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
0.53324777
tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>)
0.53324509
tensor(0.0893, device='cuda:0', grad_fn=<AddBackward0>)
0.53324419
tensor(0.0391, device='cuda:0', grad_fn=<AddBackward0>)
0.53324997
tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>)
0.53325266
tensor(0.0989, device='cuda:0', grad_fn=<AddBackward0>)
0.53325319
tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)
0.53325421
tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
0.53324759
tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>)
0.53324479
tensor(0.0749, device='cuda:0', grad_fn=<AddBackward0>)
0.53324002
tensor(0.0989, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [68][  100/  196]   Loss 0.080865   Top1 97.339844   Top5 99.976562   BatchTime 0.302318   LR 0.000000
0.53323942
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.53324205
tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>)
0.53324425
tensor(0.0756, device='cuda:0', grad_fn=<AddBackward0>)
0.53324854
tensor(0.0584, device='cuda:0', grad_fn=<AddBackward0>)
0.53325510
tensor(0.0320, device='cuda:0', grad_fn=<AddBackward0>)
0.53325170
tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>)
0.53324419
tensor(0.0708, device='cuda:0', grad_fn=<AddBackward0>)
0.53324127
tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
0.53324848
tensor(0.0841, device='cuda:0', grad_fn=<AddBackward0>)
0.53324592
tensor(0.0390, device='cuda:0', grad_fn=<AddBackward0>)
0.53324771
tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
0.53324598
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
0.53323931
tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>)
0.53324431
tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
0.53324926
tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)
0.53324413
tensor(0.0835, device='cuda:0', grad_fn=<AddBackward0>)
0.53324127
tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)
0.53324109
tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
0.53324091
tensor(0.0708, device='cuda:0', grad_fn=<AddBackward0>)
0.53325206
tensor(0.0436, device='cuda:0', grad_fn=<AddBackward0>)
0.53324926
tensor(0.0451, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [68][  120/  196]   Loss 0.078992   Top1 97.399089   Top5 99.973958   BatchTime 0.299992   LR 0.000000
0.53324944
tensor(0.0981, device='cuda:0', grad_fn=<AddBackward0>)
0.53325784
tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
0.53326195
tensor(0.1036, device='cuda:0', grad_fn=<AddBackward0>)
0.53326690
tensor(0.1309, device='cuda:0', grad_fn=<AddBackward0>)
0.53326088
tensor(0.0499, device='cuda:0', grad_fn=<AddBackward0>)
0.53324741
tensor(0.0560, device='cuda:0', grad_fn=<AddBackward0>)
0.53324151
tensor(0.0728, device='cuda:0', grad_fn=<AddBackward0>)
0.53324407
tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)
0.53324425
tensor(0.0964, device='cuda:0', grad_fn=<AddBackward0>)
0.53324759
tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
0.53325105
tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
0.53324080
tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>)
0.53323871
tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>)
0.53324366
tensor(0.0992, device='cuda:0', grad_fn=<AddBackward0>)
0.53324908
tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
0.53324413
tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
0.53325069
tensor(0.1083, device='cuda:0', grad_fn=<AddBackward0>)
0.53324878
tensor(0.0967, device='cuda:0', grad_fn=<AddBackward0>)
0.53324783
tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>)
0.53324866
tensor(0.0749, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [68][  140/  196]   Loss 0.079474   Top1 97.366071   Top5 99.972098   BatchTime 0.300736   LR 0.000000
0.53326118
tensor(0.0443, device='cuda:0', grad_fn=<AddBackward0>)
0.53325224
tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
0.53325218
tensor(0.0847, device='cuda:0', grad_fn=<AddBackward0>)
0.53324991
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
0.53324467
tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)
0.53324914
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
0.53324676
tensor(0.0918, device='cuda:0', grad_fn=<AddBackward0>)
0.53324240
tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
0.53324461
tensor(0.0524, device='cuda:0', grad_fn=<AddBackward0>)
0.53324789
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
0.53324997
tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>)
0.53325588
tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>)
0.53325796
tensor(0.0605, device='cuda:0', grad_fn=<AddBackward0>)
0.53326088
tensor(0.0265, device='cuda:0', grad_fn=<AddBackward0>)
0.53326750
tensor(0.0330, device='cuda:0', grad_fn=<AddBackward0>)
0.53326887
tensor(0.1042, device='cuda:0', grad_fn=<AddBackward0>)
0.53326750
tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)
0.53326184
tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [68][  160/  196]   Loss 0.078496   Top1 97.414551   Top5 99.975586   BatchTime 0.304743   LR 0.000000
0.53326327
tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>)
0.53326404
tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
0.53326648
tensor(0.0698, device='cuda:0', grad_fn=<AddBackward0>)
0.53326422
tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
0.53326964
tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
0.53326988
tensor(0.0705, device='cuda:0', grad_fn=<AddBackward0>)
0.53326637
tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)
0.53326029
tensor(0.1335, device='cuda:0', grad_fn=<AddBackward0>)
0.53327042
tensor(0.0347, device='cuda:0', grad_fn=<AddBackward0>)
0.53327084
tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>)
0.53326732
tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>)
0.53326434
tensor(0.0454, device='cuda:0', grad_fn=<AddBackward0>)
0.53326559
tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>)
0.53326082
tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
0.53326213
tensor(0.1072, device='cuda:0', grad_fn=<AddBackward0>)
0.53327316
tensor(0.1067, device='cuda:0', grad_fn=<AddBackward0>)
0.53326339
tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>)
0.53326583
tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
0.53326637
tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [68][  180/  196]   Loss 0.079035   Top1 97.400174   Top5 99.973958   BatchTime 0.304976   LR 0.000000
0.53325474
tensor(0.0861, device='cuda:0', grad_fn=<AddBackward0>)
0.53326625
tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>)
0.53326893
tensor(0.1044, device='cuda:0', grad_fn=<AddBackward0>)
0.53326279
tensor(0.1008, device='cuda:0', grad_fn=<AddBackward0>)
0.53326660
tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
0.53326273
tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
0.53326201
tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>)
0.53326452
tensor(0.1006, device='cuda:0', grad_fn=<AddBackward0>)
0.53325844
tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>)
0.53325814
tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>)
0.53326494
tensor(0.0418, device='cuda:0', grad_fn=<AddBackward0>)
0.53325379
tensor(0.1348, device='cuda:0', grad_fn=<AddBackward0>)
0.53325158
tensor(0.0363, device='cuda:0', grad_fn=<AddBackward0>)
0.53325897
tensor(0.1127, device='cuda:0', grad_fn=<AddBackward0>)
0.53326029
tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
0.53326911
tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>)
0.53326529
tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
0.53326601
tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
0.53326374
tensor(0.1169, device='cuda:0', grad_fn=<AddBackward0>)
0.53325880
tensor(0.1088, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 97.388    Top5: 99.974    Loss: 0.080
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [68][   20/   40]   Loss 0.411695   Top1 89.335938   Top5 99.550781   BatchTime 0.120291
INFO - Validation [68][   40/   40]   Loss 0.395923   Top1 89.580000   Top5 99.640000   BatchTime 0.086734
INFO - ==> Top1: 89.580    Top5: 99.640    Loss: 0.396
INFO - ==> Sparsity : 0.665
INFO - Scoreboard best 1 ==> Epoch [64][Top1: 89.660   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [68][Top1: 89.580   Top5: 99.640]
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 89.500   Top5: 99.670]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch  69
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1738)
features.1.conv.0 tensor(0.0521)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0959)
features.2.conv.0 tensor(0.1325)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.5385)
features.3.conv.0 tensor(0.0712)
features.3.conv.3 tensor(0.0756)
features.3.conv.6 tensor(0.1113)
features.4.conv.0 tensor(0.1019)
features.4.conv.3 tensor(0.2992)
features.4.conv.6 tensor(0.4346)
features.5.conv.0 tensor(0.3945)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4803)
features.6.conv.0 tensor(0.0539)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0803)
features.7.conv.0 tensor(0.3029)
features.7.conv.3 tensor(0.4470)
features.7.conv.6 tensor(0.6572)
features.8.conv.0 tensor(0.5769)
features.8.conv.3 tensor(0.5367)
features.8.conv.6 tensor(0.6661)
features.9.conv.0 tensor(0.5453)
features.9.conv.3 tensor(0.5660)
features.9.conv.6 tensor(0.7601)
features.10.conv.0 tensor(0.0613)
features.10.conv.3 tensor(0.0897)
features.10.conv.6 tensor(0.0681)
features.11.conv.0 tensor(0.7774)
features.11.conv.3 tensor(0.6433)
features.11.conv.6 tensor(0.9022)
features.12.conv.0 tensor(0.7430)
features.12.conv.3 tensor(0.6634)
features.12.conv.6 tensor(0.8706)
features.13.conv.0 tensor(0.3334)
features.13.conv.3 tensor(0.4823)
features.13.conv.6 tensor(0.6296)
features.14.conv.0 tensor(0.9151)
features.14.conv.3 tensor(0.8223)
features.14.conv.6 tensor(0.9585)
features.15.conv.0 tensor(0.9027)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9641)
features.16.conv.0 tensor(0.7320)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.9198)
conv.0 tensor(0.2093)
tensor(1455535.) 2188896.0
0.53326774
tensor(0.0924, device='cuda:0', grad_fn=<AddBackward0>)
0.53327119
tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>)
0.53327245
tensor(0.0854, device='cuda:0', grad_fn=<AddBackward0>)
0.53327042
tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
0.53326839
tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>)
0.53326935
tensor(0.1069, device='cuda:0', grad_fn=<AddBackward0>)
0.53326684
tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>)
0.53326392
tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)
0.53325993
tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
0.53327090
tensor(0.0734, device='cuda:0', grad_fn=<AddBackward0>)
0.53326148
tensor(0.0441, device='cuda:0', grad_fn=<AddBackward0>)
0.53326249
tensor(0.0678, device='cuda:0', grad_fn=<AddBackward0>)
0.53325349
tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
0.53326261
tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)
0.53326023
tensor(0.0929, device='cuda:0', grad_fn=<AddBackward0>)
0.53326094
tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
0.53326505
tensor(0.0627, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [69][   20/  196]   Loss 0.081837   Top1 97.226562   Top5 100.000000   BatchTime 0.374073   LR 0.000000
0.53327227
tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)
0.53327513
tensor(0.0967, device='cuda:0', grad_fn=<AddBackward0>)
0.53326941
tensor(0.0922, device='cuda:0', grad_fn=<AddBackward0>)
0.53326184
tensor(0.1148, device='cuda:0', grad_fn=<AddBackward0>)
0.53326750
tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
0.53326684
tensor(0.1054, device='cuda:0', grad_fn=<AddBackward0>)
0.53326911
tensor(0.0906, device='cuda:0', grad_fn=<AddBackward0>)
0.53326362
tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>)
0.53326350
tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>)
0.53326058
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
0.53326166
tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)
0.53327030
tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>)
0.53325653
tensor(0.0453, device='cuda:0', grad_fn=<AddBackward0>)
0.53325206
tensor(0.0678, device='cuda:0', grad_fn=<AddBackward0>)
0.53324825
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
0.53324044
tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)
0.53324836
tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
0.53324789
tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>)
0.53324902
tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [69][   40/  196]   Loss 0.082724   Top1 97.158203   Top5 99.990234   BatchTime 0.345121   LR 0.000000
0.53325069
tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
0.53325361
tensor(0.0863, device='cuda:0', grad_fn=<AddBackward0>)
0.53325540
tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
0.53325403
tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)
0.53325576
tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
0.53325558
tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>)
0.53325725
tensor(0.0919, device='cuda:0', grad_fn=<AddBackward0>)
0.53326160
tensor(0.0304, device='cuda:0', grad_fn=<AddBackward0>)
0.53325963
tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
0.53325361
tensor(0.1208, device='cuda:0', grad_fn=<AddBackward0>)
0.53324777
tensor(0.0822, device='cuda:0', grad_fn=<AddBackward0>)
0.53325164
tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>)
0.53325474
tensor(0.0967, device='cuda:0', grad_fn=<AddBackward0>)
0.53325731
tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>)
0.53326011
tensor(0.0508, device='cuda:0', grad_fn=<AddBackward0>)
0.53324801
tensor(0.0569, device='cuda:0', grad_fn=<AddBackward0>)
0.53324294
tensor(0.1114, device='cuda:0', grad_fn=<AddBackward0>)
0.53324276
tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>)
0.53325027
tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>)
0.53325027
tensor(0.0472, device='cuda:0', grad_fn=<AddBackward0>)
0.53324944
tensor(0.1096, device='cuda:0', grad_fn=<AddBackward0>)
0.53324515
tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)
0.53324330
tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
0.53325135
tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>)
0.53324777
tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>)
0.53324497
INFO - Training [69][   60/  196]   Loss 0.079602   Top1 97.350260   Top5 99.980469   BatchTime 0.335836   LR 0.000000
tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
0.53324556
tensor(0.1122, device='cuda:0', grad_fn=<AddBackward0>)
0.53325069
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
0.53325480
tensor(0.0704, device='cuda:0', grad_fn=<AddBackward0>)
0.53326356
tensor(0.0363, device='cuda:0', grad_fn=<AddBackward0>)
0.53324974
tensor(0.0881, device='cuda:0', grad_fn=<AddBackward0>)
0.53325683
tensor(0.0962, device='cuda:0', grad_fn=<AddBackward0>)
0.53325766
tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>)
0.53326350
tensor(0.0427, device='cuda:0', grad_fn=<AddBackward0>)
0.53326058
tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
0.53326458
tensor(0.0915, device='cuda:0', grad_fn=<AddBackward0>)
0.53326243
tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
0.53325790
tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)
0.53326643
tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
0.53326452
tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)
0.53326279
tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)
0.53325170
tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
0.53325719
tensor(0.0628, device='cuda:0', grad_fn=<AddBackward0>)
0.53326148
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.53326470
tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [69][   80/  196]   Loss 0.077509   Top1 97.421875   Top5 99.980469   BatchTime 0.328894   LR 0.000000
0.53325731
tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>)
0.53325313
tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
0.53325462
tensor(0.0813, device='cuda:0', grad_fn=<AddBackward0>)
0.53324652
tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)
0.53325093
tensor(0.0356, device='cuda:0', grad_fn=<AddBackward0>)
0.53324616
tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)
0.53324252
tensor(0.0893, device='cuda:0', grad_fn=<AddBackward0>)
0.53323430
tensor(0.1014, device='cuda:0', grad_fn=<AddBackward0>)
0.53324145
tensor(0.0732, device='cuda:0', grad_fn=<AddBackward0>)
0.53323990
tensor(0.1071, device='cuda:0', grad_fn=<AddBackward0>)
0.53323817
tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
0.53323692
tensor(0.1132, device='cuda:0', grad_fn=<AddBackward0>)
0.53323388
tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>)
0.53324407
tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)
0.53324121
tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
0.53324431
tensor(0.1166, device='cuda:0', grad_fn=<AddBackward0>)
0.53323019
tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>)
0.53323501
tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>)
0.53323698
tensor(0.1369, device='cuda:0', grad_fn=<AddBackward0>)
0.53323692
tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [69][  100/  196]   Loss 0.078972   Top1 97.363281   Top5 99.980469   BatchTime 0.324817   LR 0.000000
0.53324419
tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>)
0.53324562
tensor(0.0899, device='cuda:0', grad_fn=<AddBackward0>)
0.53324157
tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
0.53324246
tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>)
0.53323364
tensor(0.0484, device='cuda:0', grad_fn=<AddBackward0>)
0.53323478
tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>)
0.53323698
tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>)
0.53323412
tensor(0.0548, device='cuda:0', grad_fn=<AddBackward0>)
0.53323174
tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
0.53323984
tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
0.53324473
tensor(0.0781, device='cuda:0', grad_fn=<AddBackward0>)
0.53325206
tensor(0.0818, device='cuda:0', grad_fn=<AddBackward0>)
0.53324658
tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
0.53324306
tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
0.53324687
tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
0.53324866
tensor(0.1036, device='cuda:0', grad_fn=<AddBackward0>)
0.53324711
tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>)
0.53324264
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
0.53324753
tensor(0.0437, device='cuda:0', grad_fn=<AddBackward0>)
0.53323376
tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [69][  120/  196]   Loss 0.078321   Top1 97.402344   Top5 99.983724   BatchTime 0.319521   LR 0.000000
0.53323781
tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)
0.53323609
tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)
0.53323287
tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>)
0.53323424
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
0.53323936
tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)
0.53324157
tensor(0.0996, device='cuda:0', grad_fn=<AddBackward0>)
0.53324372
tensor(0.0734, device='cuda:0', grad_fn=<AddBackward0>)
0.53324521
tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
0.53324854
tensor(0.0871, device='cuda:0', grad_fn=<AddBackward0>)
0.53324878
tensor(0.1063, device='cuda:0', grad_fn=<AddBackward0>)
0.53324223
tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>)
0.53323990
tensor(0.0783, device='cuda:0', grad_fn=<AddBackward0>)
0.53324425
tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
0.53323978
tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>)
0.53323942
tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [69][  140/  196]   Loss 0.078270   Top1 97.382812   Top5 99.980469   BatchTime 0.314095   LR 0.000000
0.53323543
tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
0.53323954
tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
0.53323740
tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>)
0.53324270
tensor(0.0991, device='cuda:0', grad_fn=<AddBackward0>)
0.53324693
tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)
0.53324836
tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
0.53324991
tensor(0.1027, device='cuda:0', grad_fn=<AddBackward0>)
0.53324521
tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
0.53324533
tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)
0.53324354
tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
0.53324926
tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)
0.53325045
tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>)
0.53325540
tensor(0.0776, device='cuda:0', grad_fn=<AddBackward0>)
0.53326130
tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
0.53325665
tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>)
0.53324753
tensor(0.0757, device='cuda:0', grad_fn=<AddBackward0>)
0.53325301
tensor(0.0519, device='cuda:0', grad_fn=<AddBackward0>)
0.53325588
tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
0.53325468
tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>)
0.53325397
tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>)
0.53325421
tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)
0.53325176
tensor(0.1253, device='cuda:0', grad_fn=<AddBackward0>)
0.53325284
tensor(0.1126, device='cuda:0', grad_fn=<AddBackward0>)
0.53326035
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
0.53326416
tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [69][  160/  196]   Loss 0.078358   Top1 97.397461   Top5 99.978027   BatchTime 0.314667   LR 0.000000
0.53326935
tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
0.53326428
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
0.53326565
tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
0.53326613
tensor(0.0732, device='cuda:0', grad_fn=<AddBackward0>)
0.53326756
tensor(0.0675, device='cuda:0', grad_fn=<AddBackward0>)
0.53327554
tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>)
0.53327042
tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>)
0.53326565
tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
0.53325969
tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
0.53325629
tensor(0.1213, device='cuda:0', grad_fn=<AddBackward0>)
0.53326023
tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
0.53326690
tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
0.53326231
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
0.53325939
tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>)
0.53326106
tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>)
0.53326631
tensor(0.0413, device='cuda:0', grad_fn=<AddBackward0>)
0.53326279
tensor(0.1040, device='cuda:0', grad_fn=<AddBackward0>)
0.53326946
tensor(0.0746, device='cuda:0', grad_fn=<AddBackward0>)
0.53326881
tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
0.53326738
tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>)
INFO - Training [69][  180/  196]   Loss 0.078301   Top1 97.400174   Top5 99.980469   BatchTime 0.314095   LR 0.000000
0.53326786
tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>)
0.53326339
tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>)
0.53325844
tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>)
0.53325802
tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)
0.53324634
tensor(0.0679, device='cuda:0', grad_fn=<AddBackward0>)
0.53324485
tensor(0.1004, device='cuda:0', grad_fn=<AddBackward0>)
0.53325272
tensor(0.1099, device='cuda:0', grad_fn=<AddBackward0>)
0.53325707
tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>)
0.53325671
tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
0.53325564
tensor(0.1242, device='cuda:0', grad_fn=<AddBackward0>)
0.53325564
tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>)
0.53325385
tensor(0.0412, device='cuda:0', grad_fn=<AddBackward0>)
0.53325349
tensor(0.0896, device='cuda:0', grad_fn=<AddBackward0>)
INFO - ==> Top1: 97.384    Top5: 99.982    Loss: 0.079
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.53324550
tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
0.53324467
tensor(0.0860, device='cuda:0', grad_fn=<AddBackward0>)
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [69][   20/   40]   Loss 0.411422   Top1 88.964844   Top5 99.570312   BatchTime 0.125013
features.0.conv.0 tensor(0.2778)
features.0.conv.3 tensor(0.1738)
features.1.conv.0 tensor(0.0521)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0959)
features.2.conv.0 tensor(0.1331)
features.2.conv.3 tensor(0.3449)
features.2.conv.6 tensor(0.5385)
features.3.conv.0 tensor(0.0720)
features.3.conv.3 tensor(0.0756)
features.3.conv.6 tensor(0.1115)
features.4.conv.0 tensor(0.1017)
features.4.conv.3 tensor(0.2992)
features.4.conv.6 tensor(0.4346)
features.5.conv.0 tensor(0.3947)
features.5.conv.3 tensor(0.4138)
features.5.conv.6 tensor(0.4805)
features.6.conv.0 tensor(0.0539)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0804)
features.7.conv.0 tensor(0.3029)
features.7.conv.3 tensor(0.4470)
features.7.conv.6 tensor(0.6573)
features.8.conv.0 tensor(0.5769)
features.8.conv.3 tensor(0.5367)
features.8.conv.6 tensor(0.6661)
features.9.conv.0 tensor(0.5453)
features.9.conv.3 tensor(0.5660)
features.9.conv.6 tensor(0.7601)
INFO - Validation [69][   40/   40]   Loss 0.398178   Top1 89.150000   Top5 99.650000   BatchTime 0.088686
INFO - ==> Top1: 89.150    Top5: 99.650    Loss: 0.398
INFO - ==> Sparsity : 0.665
INFO - Scoreboard best 1 ==> Epoch [64][Top1: 89.660   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [68][Top1: 89.580   Top5: 99.640]
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 89.500   Top5: 99.670]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-040648/_checkpoint.pth.tar
INFO - >>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
features.10.conv.0 tensor(0.0612)
features.10.conv.3 tensor(0.0897)
features.10.conv.6 tensor(0.0680)
features.11.conv.0 tensor(0.7774)
features.11.conv.3 tensor(0.6433)
features.11.conv.6 tensor(0.9022)
features.12.conv.0 tensor(0.7430)
features.12.conv.3 tensor(0.6634)
features.12.conv.6 tensor(0.8706)
features.13.conv.0 tensor(0.3334)
features.13.conv.3 tensor(0.4824)
features.13.conv.6 tensor(0.6295)
features.14.conv.0 tensor(0.9151)
features.14.conv.3 tensor(0.8223)
features.14.conv.6 tensor(0.9585)
features.15.conv.0 tensor(0.9027)
features.15.conv.3 tensor(0.8270)
features.15.conv.6 tensor(0.9641)
features.16.conv.0 tensor(0.7320)
features.16.conv.3 tensor(0.7882)
features.16.conv.6 tensor(0.9198)
conv.0 tensor(0.2095)
tensor(1455604.) 2188896.0
INFO - Validation [   20/   40]   Loss 0.411422   Top1 88.964844   Top5 99.570312   BatchTime 0.160264
INFO - Validation [   40/   40]   Loss 0.398178   Top1 89.150000   Top5 99.650000   BatchTime 0.108250
INFO - ==> Top1: 89.150    Top5: 99.650    Loss: 0.398
INFO - ==> Sparsity : 0.000
INFO - Program completed sucessfully ... exiting ...
Traceback (most recent call last):
  File "main_slsq.py", line 79, in <module>
    main()
  File "main_slsq.py", line 76, in main
    optimzier, lr_scheduler, args.epochs, monitors, args, init_qparams = False, hard_pruning = True)
NameError: name 'optimzier' is not defined
*************hard_pruning_mode*******************