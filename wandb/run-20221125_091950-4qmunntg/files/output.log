Files already downloaded and verified
Files already downloaded and verified
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
********************pre-trained*****************
*************soft_pruning_mode*******************
INFO - Created `MobileNetv2` model
          Use pre-trained model = True
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
  warnings.warn(
INFO - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005
INFO - >>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.95438832
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
0.95019770
0.92644632
0.92214799
0.90980536
0.89388973
0.89316696
0.88634056
0.87891662
0.87647611
0.87636298
INFO - Training [0][   20/  196]   Loss 1.617165   Top1 53.769531   Top5 89.238281   BatchTime 0.456481   LR 0.004999
0.87788260
0.87867123
0.87811464
0.87739980
0.87751824
0.87863213
0.88071543
0.88074929
0.88033944
0.88030076
0.87989199
0.87972379
0.87916625
0.88021928
0.88067013
0.88109899
0.88232982
0.88458544
0.88668001
0.88800669
INFO - Training [0][   40/  196]   Loss 1.543151   Top1 52.753906   Top5 89.638672   BatchTime 0.427218   LR 0.004995
0.88896674
0.88965631
0.89005536
0.89063448
0.89104086
0.89104617
0.89131111
0.89139336
0.88620335
0.87597412
0.88528407
0.88743728
0.88837212
0.88777405
0.88612491
0.88456780
0.88310021
0.88205260
0.87912977
INFO - Training [0][   60/  196]   Loss 1.453205   Top1 54.511719   Top5 90.677083   BatchTime 0.421763   LR 0.004989
0.87618780
0.87126344
0.86657971
0.86497217
0.86412102
0.86439562
0.86547357
0.86858803
0.87329620
0.87690210
0.87769753
0.87004179
0.85832042
0.85658568
0.85069436
0.85008800
0.84556651
0.84586620
0.84511924
0.84386611
INFO - Training [0][   80/  196]   Loss 1.382449   Top1 56.533203   Top5 91.640625   BatchTime 0.417060   LR 0.004980
0.84399098
0.84450948
0.84525579
0.85179025
0.85692555
0.86016256
0.86126626
0.85647535
0.85126787
0.84579885
0.84462339
0.84551710
0.83882630
0.81222010
0.80720443
0.80366004
0.80167633
0.80321229
0.80505610
0.80586588
INFO - Training [0][  100/  196]   Loss 1.326930   Top1 58.218750   Top5 92.316406   BatchTime 0.415371   LR 0.004968
0.80624938
0.80717760
0.80891085
0.81143224
0.81388235
0.81467235
0.81287700
0.81074709
0.81035846
0.80660224
0.80470657
0.80727583
0.80617660
0.80802077
0.80882549
0.80928355
0.81158906
0.81485033
0.81548667
0.81590909
INFO - Training [0][  120/  196]   Loss 1.280253   Top1 59.798177   Top5 92.822266   BatchTime 0.411155   LR 0.004954
0.81676978
0.81754386
0.81947494
0.82148540
0.82232785
0.82284129
0.82342303
0.82372242
0.82414395
0.82437617
0.82535350
0.82627970
0.82734555
0.82848716
0.83009416
0.83154607
0.83289194
0.83392423
0.82940060
0.81724161
INFO - Training [0][  140/  196]   Loss 1.248320   Top1 60.856585   Top5 93.180804   BatchTime 0.410318   LR 0.004938
0.81130344
0.81528038
0.82369494
0.83098650
0.83421093
0.83631361
0.83733606
0.83770502
0.83774972
0.83731592
0.83698452
0.83646274
0.83595717
0.83538884
0.83532101
0.83469850
0.83344650
0.83268529
0.83079523
0.82734299
0.82505953
INFO - Training [0][  160/  196]   Loss 1.226075   Top1 61.542969   Top5 93.383789   BatchTime 0.407063   LR 0.004919
0.82197660
0.82027823
0.81730610
0.81787002
0.81761140
0.81794578
0.81751925
0.81660622
0.81581706
0.81474572
0.81360149
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [0][  180/  196]   Loss nan   Top1 60.249566   Top5 92.120226   BatchTime 0.396757   LR 0.004897
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 56.326    Top5: 88.796    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 5.589599   Top1 10.253906   Top5 50.488281   BatchTime 0.108195
INFO - Validation [0][   40/   40]   Loss 5.617839   Top1 10.000000   Top5 50.000000   BatchTime 0.079454
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0243)
features.16.conv.3 tensor(0.0340)
features.16.conv.6 tensor(0.9986)
conv.0 tensor(0.0611)
tensor(335829.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 5.618
INFO - ==> Sparsity : 0.153
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 10.000   Top5: 50.000]
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)
  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-091948/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-091948/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [1][   20/  196]   Loss nan   Top1 9.316406   Top5 49.082031   BatchTime 0.425837   LR 0.004853
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [1][   40/  196]   Loss nan   Top1 9.667969   Top5 49.667969   BatchTime 0.386422   LR 0.004825
nan
nan
nan
nan
nan
nan
Traceback (most recent call last):
  File "main_slsq.py", line 91, in <module>
    main()
  File "main_slsq.py", line 77, in main
    trainer.train_qat_slsq(train_loader, val_loader, test_loader,qat_model, teacher_model,criterion,
  File "/home/ilena7440/LSQ_FakeQuant/trainer/process.py", line 53, in train_qat_slsq
    t_top1, t_top5, t_loss = train_one_epoch_slsq(train_loader, qat_model,
  File "/home/ilena7440/LSQ_FakeQuant/trainer/process.py", line 186, in train_one_epoch_slsq
    loss.backward()
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
nan