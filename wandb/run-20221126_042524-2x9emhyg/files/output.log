Files already downloaded and verified
Files already downloaded and verified
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = True
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
  warnings.warn(
INFO - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005
INFO - >>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
*************soft_pruning_mode*******************
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
0.00000000
0.00000000
0.00000000
0.95438832
0.95021045
0.92755443
0.91471022
0.90123749
0.90503782
INFO - Training [0][   20/  196]   Loss 1.580746   Top1 53.750000   Top5 88.906250   BatchTime 0.337854   LR 0.004999
0.90641540
0.90134126
0.89556539
0.88884884
0.88344133
0.87544692
0.86762244
0.85841447
0.85139370
0.84991431
0.84883749
0.84840989
0.84764898
0.84751576
0.84745932
0.84770012
0.84699821
0.84714723
0.84728253
0.84772927
0.84767747
0.84785205
INFO - Training [0][   40/  196]   Loss 1.496292   Top1 52.783203   Top5 89.541016   BatchTime 0.300083   LR 0.004995
0.84824044
0.84893280
0.84982848
0.85083044
0.85152739
0.85230750
0.85317343
0.85377175
0.85432863
0.85480702
0.85506654
0.85519385
0.85504186
0.85492861
0.85527241
0.85523123
0.85523081
0.85539746
0.85578686
0.85621393
0.85661298
0.85742342
0.85796887
0.85859084
INFO - Training [0][   60/  196]   Loss 1.397735   Top1 55.123698   Top5 90.703125   BatchTime 0.285327   LR 0.004989
0.85932428
0.86056018
0.86196631
0.86374635
0.86549121
0.86701810
0.86846787
0.87002194
0.87558430
0.88309526
0.88791603
0.88967437
0.89220792
0.89558583
0.89705074
INFO - Training [0][   80/  196]   Loss 1.336352   Top1 56.752930   Top5 91.464844   BatchTime 0.278193   LR 0.004980
0.90338469
0.90629810
0.90224886
0.89482623
0.88793284
0.88379949
0.88519847
0.88369226
0.88358963
0.88232732
0.88045311
0.88126844
0.88333559
0.88535500
0.88933414
0.89112711
0.89235228
0.89251631
0.89169425
0.88913494
0.88938385
0.88771498
0.88412750
0.88226926
0.87971902
INFO - Training [0][  100/  196]   Loss 1.275738   Top1 58.519531   Top5 92.171875   BatchTime 0.272514   LR 0.004968
0.87883806
0.87786347
0.87803614
0.87725449
0.87626672
0.87529862
0.87509841
0.87506086
0.87525314
0.87548447
0.87547195
0.87597805
0.87648392
0.87798417
0.87813371
0.87871665
INFO - Training [0][  120/  196]   Loss 1.222449   Top1 60.185547   Top5 92.783203   BatchTime 0.268482   LR 0.004954
0.87938076
0.88013637
0.88099897
0.88192081
0.88325942
0.88434649
0.88493156
0.88538164
0.88602865
0.88656616
0.88684672
0.88712525
0.88748825
0.88763630
0.88807786
0.88820517
0.88865113
0.88953650
0.89175314
0.89485180
0.89789760
0.89836174
0.89798456
0.89781147
INFO - Training [0][  140/  196]   Loss 1.190312   Top1 61.163504   Top5 93.164062   BatchTime 0.265878   LR 0.004938
0.89789635
0.89773411
0.89776820
0.89798945
0.89771694
0.89771652
0.89763802
0.89742851
0.89763838
0.89762980
0.89779168
0.89751220
0.89733082
0.89602274
INFO - Training [0][  160/  196]   Loss 1.166264   Top1 61.916504   Top5 93.393555   BatchTime 0.267086   LR 0.004919
0.89456326
0.89556938
0.89688593
0.89768666
0.89751887
0.89749235
0.89725167
0.89722264
0.89737600
0.89725357
0.89737260
0.89747709
0.89748931
0.89755678
0.89743143
0.89768410
0.89767164
0.89769721
0.89774561
0.89767343
0.89749068
0.89621317
0.89764333
INFO - Training [0][  180/  196]   Loss 1.144198   Top1 62.465278   Top5 93.576389   BatchTime 0.265958   LR 0.004897
0.89756393
0.89768153
0.89767098
0.89770275
0.89730555
0.89718115
0.89718896
0.89691186
0.89657205
0.89647639
0.89650059
0.89651632
0.89640325
0.89642245
0.89621198
0.89621216
INFO - ==> Top1: 62.964    Top5: 93.760    Loss: 1.126
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.895440   Top1 70.957031   Top5 97.363281   BatchTime 0.109425
INFO - Validation [0][   40/   40]   Loss 0.906538   Top1 70.790000   Top5 97.130000   BatchTime 0.081704
INFO - ==> Top1: 70.790    Top5: 97.130    Loss: 0.907
INFO - ==> Sparsity : 0.225
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
features.0.conv.0 tensor(0.5486)
features.0.conv.3 tensor(0.3535)
features.1.conv.0 tensor(0.0365)
features.1.conv.3 tensor(0.0903)
features.1.conv.6 tensor(0.0686)
features.2.conv.0 tensor(0.0414)
features.2.conv.3 tensor(0.0664)
features.2.conv.6 tensor(0.0871)
features.3.conv.0 tensor(0.0422)
features.3.conv.3 tensor(0.0594)
features.3.conv.6 tensor(0.0658)
features.4.conv.0 tensor(0.0527)
features.4.conv.3 tensor(0.0949)
features.4.conv.6 tensor(0.1123)
features.5.conv.0 tensor(0.0645)
features.5.conv.3 tensor(0.0677)
features.5.conv.6 tensor(0.1063)
features.6.conv.0 tensor(0.0563)
features.6.conv.3 tensor(0.0469)
features.6.conv.6 tensor(0.0862)
features.7.conv.0 tensor(0.0916)
features.7.conv.3 tensor(0.1013)
features.7.conv.6 tensor(0.1271)
features.8.conv.0 tensor(0.0964)
features.8.conv.3 tensor(0.0975)
features.8.conv.6 tensor(0.1436)
features.9.conv.0 tensor(0.1285)
features.9.conv.3 tensor(0.1105)
features.9.conv.6 tensor(0.1383)
features.10.conv.0 tensor(0.0751)
features.10.conv.3 tensor(0.0938)
features.10.conv.6 tensor(0.1040)
features.11.conv.0 tensor(0.1446)
features.11.conv.3 tensor(0.0802)
features.11.conv.6 tensor(0.1720)
features.12.conv.0 tensor(0.1680)
features.12.conv.3 tensor(0.1042)
features.12.conv.6 tensor(0.1583)
features.13.conv.0 tensor(0.0941)
features.13.conv.3 tensor(0.1291)
features.13.conv.6 tensor(0.1253)
features.14.conv.0 tensor(0.7595)
features.14.conv.3 tensor(0.0803)
features.14.conv.6 tensor(0.3205)
features.15.conv.0 tensor(0.8313)
features.15.conv.3 tensor(0.0678)
features.15.conv.6 tensor(0.3043)
features.16.conv.0 tensor(0.0804)
features.16.conv.3 tensor(0.0800)
features.16.conv.6 tensor(0.0903)
conv.0 tensor(0.0647)
tensor(493247.) 2188896.0
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)
  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
0.89609325
0.89594609
0.89615989
0.89620119
0.89598870
0.89590847
0.89600718
0.89613700
0.89603931
0.89606565
0.89607674
0.89617079
0.89645821
0.89652228
0.89655071
0.89648581
0.89625657
0.89618421
0.89620715
0.90734649
0.90849823
INFO - Training [1][   20/  196]   Loss 0.946618   Top1 68.535156   Top5 95.253906   BatchTime 0.314045   LR 0.004853
0.90874547
0.90879822
0.90891558
0.90871888
0.90863407
0.90855312
0.90840733
0.90833688
0.90846944
0.90852123
0.90841925
0.90826321
0.90817696
0.90814477
0.90819031
0.90845877
INFO - Training [1][   40/  196]   Loss 0.953847   Top1 68.359375   Top5 95.478516   BatchTime 0.284068   LR 0.004825
0.90830910
0.90812963
0.90798926
0.90797698
0.90818173
0.90737355
0.90572548
0.90455300
0.89879429
0.90364897
0.90231526
0.90341139
0.90366620
0.90632468
0.90484107
0.90252161
0.90326005
0.90457517
0.90600723
0.90755987
0.90745330
0.90749973
0.90761429
0.90737969
INFO - Training [1][   60/  196]   Loss 0.943377   Top1 68.483073   Top5 95.598958   BatchTime 0.272115   LR 0.004794
0.90758139
0.90750813
0.90733826
0.90740901
0.90746564
0.90731823
0.90745074
0.90757400
0.90747696
0.90725350
0.90704668
0.90703541
0.90689749
0.90689081
0.90695137
0.90701157
INFO - Training [1][   80/  196]   Loss 0.927948   Top1 69.140625   Top5 95.732422   BatchTime 0.266802   LR 0.004761
0.90689200
0.90691555
0.90673572
0.90670341
0.90685278
0.90569788
0.89061779
0.90679193
0.90653592
0.90643489
0.90644413
0.90592778
0.90590549
0.90573347
0.90571338
0.90583193
0.90587872
0.90540916
0.90538144
0.90553939
0.90559530
0.90548164
0.90035379
0.89330965
INFO - Training [1][  100/  196]   Loss 0.908337   Top1 69.964844   Top5 95.863281   BatchTime 0.263901   LR 0.004725
0.90130782
0.90528470
0.90596628
0.90572512
0.90554351
0.90544641
0.90502250
0.90460593
0.90444607
0.90456909
0.90445739
0.90454346
0.90437716
0.90418392
0.90397125
0.90394360
0.90388489
INFO - Training [1][  120/  196]   Loss 0.899003   Top1 70.335286   Top5 96.083984   BatchTime 0.261057   LR 0.004687
0.90352648
0.90093678
0.90357894
0.90369183
0.90374881
0.90401149
0.90383703
0.90372664
0.90376103
0.90358883
0.90337044
0.90322852
0.90284514
0.90270537
0.90253627
0.90262008
0.90256220
0.90238267
0.90197283
0.90150315
0.90123010
0.90124053
0.90131634
INFO - Training [1][  140/  196]   Loss 0.890353   Top1 70.638951   Top5 96.202567   BatchTime 0.259502   LR 0.004647
0.90089494
0.90099412
0.90133351
0.90098840
0.89874405
0.90098673
0.90138209
0.90134257
0.90123677
0.90141416
0.90120780
0.90101451
0.90080392
0.90066987
0.90057123
0.89813226
INFO - Training [1][  160/  196]   Loss 0.884566   Top1 70.859375   Top5 96.230469   BatchTime 0.258969   LR 0.004605
0.88397455
0.87492067
0.87370211
0.87189919
0.87444890
0.88359302
0.89247864
0.89764869
0.89867741
0.89838016
0.89814049
0.89806515
0.89796042
0.89757389
0.89732128
0.89654374
0.89632541
0.89606273
0.89583600
0.89556515
0.89537507
0.89458501
0.89371163
0.89298558
0.89194727
INFO - Training [1][  180/  196]   Loss 0.872594   Top1 71.276042   Top5 96.250000   BatchTime 0.257038   LR 0.004560
0.89084107
0.88975370
0.88826990
0.88649446
0.88472682
0.88272893
0.88062787
0.87854183
0.87668633
0.87521714
0.87373084
0.87209356
0.86340415
0.87114364
********************pre-trained*****************
INFO - ==> Top1: 71.470    Top5: 96.278    Loss: 0.867
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [1][   20/   40]   Loss 0.754639   Top1 75.839844   Top5 97.753906   BatchTime 0.110950
INFO - Validation [1][   40/   40]   Loss 0.738611   Top1 76.020000   Top5 97.780000   BatchTime 0.082332
INFO - ==> Top1: 76.020    Top5: 97.780    Loss: 0.739
INFO - ==> Sparsity : 0.286
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
features.0.conv.0 tensor(0.5312)
features.0.conv.3 tensor(0.1230)
features.1.conv.0 tensor(0.0339)
features.1.conv.3 tensor(0.0961)
features.1.conv.6 tensor(0.0625)
features.2.conv.0 tensor(0.0408)
features.2.conv.3 tensor(0.0679)
features.2.conv.6 tensor(0.0992)
features.3.conv.0 tensor(0.0414)
features.3.conv.3 tensor(0.0517)
features.3.conv.6 tensor(0.0738)
features.4.conv.0 tensor(0.0492)
features.4.conv.3 tensor(0.1001)
features.4.conv.6 tensor(0.1175)
features.5.conv.0 tensor(0.0537)
features.5.conv.3 tensor(0.0671)
features.5.conv.6 tensor(0.1060)
features.6.conv.0 tensor(0.0407)
features.6.conv.3 tensor(0.0440)
features.6.conv.6 tensor(0.0876)
features.7.conv.0 tensor(0.0775)
features.7.conv.3 tensor(0.1016)
features.7.conv.6 tensor(0.1302)
features.8.conv.0 tensor(0.0971)
features.8.conv.3 tensor(0.1178)
features.8.conv.6 tensor(0.1316)
features.9.conv.0 tensor(0.1101)
features.9.conv.3 tensor(0.1291)
features.9.conv.6 tensor(0.1349)
features.10.conv.0 tensor(0.0573)
features.10.conv.3 tensor(0.0943)
features.10.conv.6 tensor(0.0988)
features.11.conv.0 tensor(0.1618)
features.11.conv.3 tensor(0.0934)
features.11.conv.6 tensor(0.1943)
features.12.conv.0 tensor(0.0970)
features.12.conv.3 tensor(0.1449)
features.12.conv.6 tensor(0.3062)
features.13.conv.0 tensor(0.0825)
features.13.conv.3 tensor(0.1507)
features.13.conv.6 tensor(0.1347)
features.14.conv.0 tensor(0.8152)
features.14.conv.3 tensor(0.0825)
features.14.conv.6 tensor(0.3775)
features.15.conv.0 tensor(0.8822)
features.15.conv.3 tensor(0.0716)
features.15.conv.6 tensor(0.9051)
features.16.conv.0 tensor(0.0908)
features.16.conv.3 tensor(0.0869)
features.16.conv.6 tensor(0.0794)
conv.0 tensor(0.0960)
tensor(627070.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
0.87336552
0.87384260
0.87424618
0.87431037
0.87479591
0.87476450
0.87482309
0.87478918
0.87500286
0.87471730
0.87458396
0.87443477
0.87431210
0.87394017
0.87399024
0.87406117
0.87398732
0.87417978
0.87468493
0.87445754
0.87460500
0.87494302
0.87486583
INFO - Training [2][   20/  196]   Loss 0.832800   Top1 72.089844   Top5 95.664062   BatchTime 0.317256   LR 0.004477
0.87357193
0.88142776
0.86579818
0.88112134
0.87835693
0.87602419
0.87802333
0.88584024
0.88551867
0.88037002
0.88238764
0.88263780
0.88270128
0.88302165
0.88317108
0.88471478
INFO - Training [2][   40/  196]   Loss 1.570073   Top1 45.703125   Top5 78.193359   BatchTime 0.284491   LR 0.004426
0.88628119
0.88817137
0.88997793
0.89176041
0.89321560
0.89461929
0.89605963
0.89240801
0.89068848
0.88970929
0.88879716
0.88808984
0.88735628
0.88617837
0.88501114
0.88317734
0.88488084
0.88241750
0.88057923
0.87838632
0.87558079
0.87512183
0.87536770
0.87628931
INFO - Training [2][   60/  196]   Loss 1.832511   Top1 33.645833   Top5 68.906250   BatchTime 0.272824   LR 0.004374
0.87713760
0.87762040
0.87770283
0.87796706
0.87812257
0.87808847
0.87796551
0.87794453
0.87792319
0.87783891
0.87783802
0.87782645
0.87782937
0.87789559
0.87801939
0.87817341
INFO - Training [2][   80/  196]   Loss 1.960379   Top1 27.607422   Top5 64.360352   BatchTime 0.266854   LR 0.004320
0.87847656
0.87867749
0.87897068
0.87900674
0.87912118
0.87923533
0.87914240
0.87905616
0.87876511
0.87881732
0.87894046
0.87906611
0.87927365
0.87918764
0.87915111
0.87904674
0.87898523
0.87905514
0.87918019
0.87934160
0.87931377
0.87930208
0.87938029
0.87948406
INFO - Training [2][  100/  196]   Loss 2.036684   Top1 24.125000   Top5 61.625000   BatchTime 0.263485   LR 0.004264
0.87926370
0.87499613
0.85373163
0.85177904
0.85186821
0.85180700
0.85169524
0.85172689
0.85187429
0.85175639
0.85154277
0.83037430
0.82412112
0.82949483
0.85322654
0.85504377
0.85746372
INFO - Training [2][  120/  196]   Loss 2.087516   Top1 21.725260   Top5 59.667969   BatchTime 0.260860   LR 0.004206
0.85944229
0.86144340
0.86309862
0.86451310
0.86562705
0.86629987
0.86678702
0.86729646
0.86734098
0.86720771
0.86696833
0.86645883
0.86584437
0.86524463
0.86469561
0.86445904
0.86441487
0.86383593
0.86373717
0.86365741
0.86387205
0.86367452
0.86224854
0.86201024
INFO - Training [2][  140/  196]   Loss 2.123092   Top1 20.011161   Top5 58.317522   BatchTime 0.259225   LR 0.004146
0.86124599
0.86083132
0.86059976
0.86116964
0.86229002
0.86236000
0.86267978
0.86194950
0.86202812
0.86261380
0.86352831
0.86348552
0.86359137
0.86393332
0.86408764
0.86409163
INFO - Training [2][  160/  196]   Loss 2.149865   Top1 18.747559   Top5 57.438965   BatchTime 0.258367   LR 0.004085
0.86379558
0.86349308
0.86364156
0.86357379
0.86337990
0.86352324
0.86377066
0.86374247
0.86352974
0.86350501
0.86351222
0.86347914
0.86346662
0.86344576
0.86355275
0.86371094
INFO - Training [2][  180/  196]   Loss 2.170433   Top1 17.849392   Top5 56.733941   BatchTime 0.256013   LR 0.004022
0.86355716
0.86368001
0.86375767
0.86366093
0.86362928
0.86372316
0.86380094
0.86384475
0.86380255
0.86381429
0.86395615
0.86420262
0.86434478
0.86453450
0.86437899
0.86475676
0.86458415
INFO - ==> Top1: 17.166    Top5: 56.140    Loss: 2.184
0.86463404
0.86449379
0.86448801
********************pre-trained*****************
validation quantized model on cpu
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 2.389739   Top1 10.253906   Top5 50.078125   BatchTime 0.110394
features.0.conv.0 tensor(0.1215)
features.0.conv.3 tensor(0.0098)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.0255)
features.1.conv.6 tensor(0.0868)
features.2.conv.0 tensor(0.0477)
features.2.conv.3 tensor(0.0664)
features.2.conv.6 tensor(0.1340)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.0085)
features.3.conv.6 tensor(0.0469)
features.4.conv.0 tensor(0.0236)
features.4.conv.3 tensor(0.0845)
features.4.conv.6 tensor(0.1160)
features.5.conv.0 tensor(0.0433)
features.5.conv.3 tensor(0.0764)
features.5.conv.6 tensor(0.1037)
features.6.conv.0 tensor(0.0282)
features.6.conv.3 tensor(0.0515)
features.6.conv.6 tensor(0.0627)
features.7.conv.0 tensor(0.0444)
features.7.conv.3 tensor(0.0110)
features.7.conv.6 tensor(0.0050)
features.8.conv.0 tensor(0.0684)
features.8.conv.3 tensor(0.1508)
features.8.conv.6 tensor(0.7542)
features.9.conv.0 tensor(0.0610)
features.9.conv.3 tensor(0.1600)
features.9.conv.6 tensor(0.1676)
features.10.conv.0 tensor(0.0482)
features.10.conv.3 tensor(0.1053)
features.10.conv.6 tensor(0.0861)
features.11.conv.0 tensor(0.0835)
features.11.conv.3 tensor(0.1501)
features.11.conv.6 tensor(0.1949)
features.12.conv.0 tensor(0.0709)
features.12.conv.3 tensor(0.2126)
features.12.conv.6 tensor(0.1872)
features.13.conv.0 tensor(0.7431)
features.13.conv.3 tensor(0.1302)
features.13.conv.6 tensor(0.0630)
features.14.conv.0 tensor(0.1522)
features.14.conv.3 tensor(0.1079)
features.14.conv.6 tensor(0.0148)
features.15.conv.0 tensor(0.7018)
features.15.conv.3 tensor(0.0832)
features.15.conv.6 tensor(0.1551)
features.16.conv.0 tensor(0.0541)
features.16.conv.3 tensor(0.0764)
features.16.conv.6 tensor(0.8457)
conv.0 tensor(0.3569)
tensor(690151.) 2188896.0
INFO - Validation [2][   40/   40]   Loss 2.390388   Top1 10.000000   Top5 50.000000   BatchTime 0.081450
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.390
INFO - ==> Sparsity : 0.315
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
0.86486411
0.86488420
0.86486489
0.86473072
0.86441261
0.86440593
0.86440521
0.86413145
0.86398566
0.86381060
0.86348504
0.86299503
0.86284250
0.86260176
0.86226898
0.86207169
0.86203247
0.86195040
0.86182576
0.86164886
INFO - Training [3][   20/  196]   Loss 2.336336   Top1 10.195312   Top5 51.250000   BatchTime 0.315892   LR 0.003907
0.86157352
0.86126012
0.86115938
0.86107719
0.86104727
0.86092687
0.86092204
0.86127704
0.86145759
0.86125571
0.86101490
0.86086595
0.86092174
0.86097181
0.86081576
0.86070764
0.86073083
0.86083019
0.86082798
0.86096436
0.86110532
0.86114103
0.86131489
0.86135423
INFO - Training [3][   40/  196]   Loss 2.334600   Top1 10.195312   Top5 50.830078   BatchTime 0.286778   LR 0.003840
0.86121631
0.86105168
0.86107659
0.86089605
0.86074930
0.86085612
0.86090583
0.86067986
0.86066693
0.86058146
0.86082292
0.86079395
0.86085379
0.86083293
0.86100113
0.86114019
INFO - Training [3][   60/  196]   Loss 2.335026   Top1 10.221354   Top5 50.631510   BatchTime 0.272883   LR 0.003771
0.86116493
0.86098748
0.86077756
0.86041558
0.86041629
0.86046571
0.86073756
0.86079937
0.86094320
0.86109924
0.86092025
0.86104029
0.86160505
0.86220872
0.86297786
0.86332375
INFO - Training [3][   80/  196]   Loss 2.334255   Top1 10.288086   Top5 50.751953   BatchTime 0.267673   LR 0.003701
0.86399418
0.86420518
0.86428601
0.86477423
0.86503869
0.86502206
0.86442274
0.86465955
0.86491734
0.86505151
0.86496836
0.86449569
0.86416399
0.86338609
0.86288673
0.86169428
0.86000657
0.85825926
0.85711336
0.85678852
0.85642731
0.85671413
0.85694790
0.85677552
INFO - Training [3][  100/  196]   Loss 2.333834   Top1 10.238281   Top5 50.617188   BatchTime 0.264754   LR 0.003630
0.85697931
0.85614508
0.85530412
0.85465872
0.85378277
0.85309017
0.85173249
0.85012525
0.84840673
0.84664208
0.84446675
0.84256011
0.84035808
0.83811820
0.83772355
0.83718306
0.83686215
0.83657122
0.83680421
0.83684134
0.83654290
0.83644331
0.83605450
0.83611345
INFO - Training [3][  120/  196]   Loss 2.334353   Top1 10.006510   Top5 50.442708   BatchTime 0.262457   LR 0.003558
0.83608472
0.83625764
0.83598465
0.83597398
0.83553249
0.83505654
0.83518881
0.83527052
0.83453518
0.83491695
0.83505684
0.83529317
0.83514631
0.83499920
0.83488107
0.83484578
INFO - Training [3][  140/  196]   Loss 2.333774   Top1 9.991629   Top5 50.432478   BatchTime 0.260045   LR 0.003484
0.83463043
0.83446574
0.83443755
0.83384472
0.83315635
0.83261818
0.83195782
0.83137536
0.83080429
0.83012456
0.82941145
0.82922530
0.82931000
0.82953399
0.82964760
0.82834601
INFO - Training [3][  160/  196]   Loss 2.333644   Top1 10.100098   Top5 50.397949   BatchTime 0.259301   LR 0.003410
0.82739842
0.82560962
0.82439166
0.82387298
0.82358211
0.82365185
0.82502997
0.82710105
0.82886988
0.83020276
0.83153999
0.83369529
0.83515561
0.83583921
0.83646506
0.83681715
0.83704251
0.83712149
0.83737171
0.83771402
0.83793747
0.83801627
0.83798546
0.83805555
INFO - Training [3][  180/  196]   Loss 2.333907   Top1 10.023872   Top5 50.221354   BatchTime 0.257578   LR 0.003335
0.83808303
0.83827060
0.83825904
0.83803397
0.83764815
0.83755988
0.83747345
0.83746940
0.83763838
0.83772200
0.83716637
0.83702165
0.83663195
0.83657080
0.83648920
0.83651143
INFO - ==> Top1: 10.074    Top5: 50.112    Loss: 2.334
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 2.335316   Top1 9.863281   Top5 50.078125   BatchTime 0.111593
INFO - Validation [3][   40/   40]   Loss 2.335024   Top1 10.000000   Top5 50.000000   BatchTime 0.084020
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.335
INFO - ==> Sparsity : 0.260
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.1215)
features.0.conv.3 tensor(0.0137)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.0266)
features.1.conv.6 tensor(0.0885)
features.2.conv.0 tensor(0.0477)
features.2.conv.3 tensor(0.0671)
features.2.conv.6 tensor(0.1354)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.0085)
features.3.conv.6 tensor(0.0475)
features.4.conv.0 tensor(0.0239)
features.4.conv.3 tensor(0.0856)
features.4.conv.6 tensor(0.1178)
features.5.conv.0 tensor(0.0433)
features.5.conv.3 tensor(0.0752)
features.5.conv.6 tensor(0.1082)
features.6.conv.0 tensor(0.0283)
features.6.conv.3 tensor(0.0527)
features.6.conv.6 tensor(0.0653)
features.7.conv.0 tensor(0.0455)
features.7.conv.3 tensor(0.0104)
features.7.conv.6 tensor(0.0052)
features.8.conv.0 tensor(0.0688)
features.8.conv.3 tensor(0.1516)
features.8.conv.6 tensor(0.7563)
features.9.conv.0 tensor(0.0632)
features.9.conv.3 tensor(0.1591)
features.9.conv.6 tensor(0.9115)
features.10.conv.0 tensor(0.0493)
features.10.conv.3 tensor(0.1065)
features.10.conv.6 tensor(0.8388)
features.11.conv.0 tensor(0.0839)
features.11.conv.3 tensor(0.1526)
features.11.conv.6 tensor(0.2014)
features.12.conv.0 tensor(0.0713)
features.12.conv.3 tensor(0.2132)
features.12.conv.6 tensor(0.1860)
features.13.conv.0 tensor(0.7243)
features.13.conv.3 tensor(0.1291)
features.13.conv.6 tensor(0.0668)
features.14.conv.0 tensor(0.1632)
features.14.conv.3 tensor(0.1086)
features.14.conv.6 tensor(0.0196)
features.15.conv.0 tensor(0.7286)
features.15.conv.3 tensor(0.0812)
features.15.conv.6 tensor(0.1780)
features.16.conv.0 tensor(0.0643)
features.16.conv.3 tensor(0.0775)
features.16.conv.6 tensor(0.1985)
conv.0 tensor(0.4071)
tensor(569459.) 2188896.0
0.83642066
0.83637160
0.83632696
0.83650333
0.83661777
0.83655995
0.83673722
0.83687508
0.83716506
0.83727324
0.83703619
0.83681601
0.83704478
0.83681041
0.83670235
0.83652008
0.83644915
0.83639503
0.83627439
0.83619142
0.83614939
0.83594817
INFO - Training [4][   20/  196]   Loss 2.331820   Top1 10.039062   Top5 50.429688   BatchTime 0.320308   LR 0.003200
0.83584225
0.83566189
0.83563483
0.83581996
0.83592212
0.83576274
0.83567733
0.83559823
0.83551866
0.83553088
0.83555686
0.83557487
0.83588129
0.83545238
0.83550400
0.83548123
0.83553302
INFO - Training [4][   40/  196]   Loss 2.330997   Top1 10.078125   Top5 50.126953   BatchTime 0.280793   LR 0.003122
0.83533221
0.83524346
0.83572537
0.83543801
0.83569431
0.83553076
0.83544803
0.83552700
0.83546889
0.83560479
0.83559555
0.83549726
0.83549666
0.83539480
0.83541232
0.83519340
0.83503681
0.83507985
0.83510172
0.83505160
0.83512264
0.83522308
0.83512586
0.83492517
0.83486325
INFO - Training [4][   60/  196]   Loss 2.330936   Top1 10.026042   Top5 50.104167   BatchTime 0.269060   LR 0.003044
0.83494753
0.83494657
0.83493602
0.83489823
0.83491385
0.83489430
0.83478177
0.83467364
0.83477259
0.83475685
0.83508551
0.83515668
0.83528572
0.83545774
0.83550793
0.83559465
INFO - Training [4][   80/  196]   Loss 2.330542   Top1 10.078125   Top5 50.146484   BatchTime 0.264556   LR 0.002965
0.83560169
0.83544451
0.83537757
0.83536655
0.83540273
0.83570081
0.83582735
0.83603746
0.83624297
0.83639109
0.83680522
0.83672410
0.83686393
0.83705354
0.83718956
0.83700103
0.83667541
0.83663052
0.83663189
0.83647382
0.83647954
0.83652574
0.83642918
INFO - Training [4][  100/  196]   Loss 2.330757   Top1 9.992188   Top5 50.046875   BatchTime 0.263103   LR 0.002886
0.83640975
0.83657849
0.83626831
0.83623534
0.83612871
0.83610868
0.83599931
0.83598226
0.83572972
0.83557612
0.83563417
0.83541662
0.83529812
0.83509105
0.83506864
0.83483899
INFO - Training [4][  120/  196]   Loss 2.330412   Top1 10.065104   Top5 50.166016   BatchTime 0.261972   LR 0.002806
0.83480799
0.83500874
0.83486992
0.83481205
0.83464539
0.83442265
0.83429921
0.83437765
0.83435559
0.83436835
0.83433765
0.83432180
0.83425051
0.83428293
0.83432817
0.83430248
0.83426088
0.83410901
0.83401746
0.83401126
0.83378428
0.83371651
0.83400756
0.83392078
INFO - Training [4][  140/  196]   Loss 2.330398   Top1 9.997210   Top5 50.206473   BatchTime 0.260225   LR 0.002726
0.83405393
0.83401096
0.83399063
0.83385783
0.83385843
0.83389193
0.83385694
0.83370996
0.83357865
0.83352661
0.83347112
0.83346313
0.83328617
0.83317542
0.83308476
0.83305842
INFO - Training [4][  160/  196]   Loss 2.330355   Top1 10.053711   Top5 50.014648   BatchTime 0.258974   LR 0.002646
0.83308327
0.83289701
0.83289695
0.83285344
0.83278781
0.83245248
0.83233958
0.83254266
0.83229899
0.83212405
0.83190089
0.83157951
0.83138299
0.83111173
0.83079624
0.83065087
0.83044469
0.83019418
0.82987505
0.82950538
0.82914513
0.82874703
0.82816291
0.82744813
0.82672530
INFO - Training [4][  180/  196]   Loss 2.330298   Top1 10.054253   Top5 50.015191   BatchTime 0.256624   LR 0.002566
0.82589072
0.82498127
0.82405823
0.82316738
0.82190180
0.82056862
0.81902176
0.81743228
0.81526512
0.81180662
0.80820513
0.80544543
********************pre-trained*****************
INFO - ==> Top1: 10.146    Top5: 49.976    Loss: 2.330
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [4][   20/   40]   Loss 2.450002   Top1 10.078125   Top5 49.960938   BatchTime 0.117240
INFO - Validation [4][   40/   40]   Loss 2.451310   Top1 10.000000   Top5 50.000000   BatchTime 0.085462
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.451
INFO - ==> Sparsity : 0.291
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.1215)
features.0.conv.3 tensor(0.0566)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.0266)
features.1.conv.6 tensor(0.0885)
features.2.conv.0 tensor(0.0477)
features.2.conv.3 tensor(0.0671)
features.2.conv.6 tensor(0.1360)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.0085)
features.3.conv.6 tensor(0.0482)
features.4.conv.0 tensor(0.0233)
features.4.conv.3 tensor(0.0851)
features.4.conv.6 tensor(0.1191)
features.5.conv.0 tensor(0.0438)
features.5.conv.3 tensor(0.0781)
features.5.conv.6 tensor(0.1112)
features.6.conv.0 tensor(0.0282)
features.6.conv.3 tensor(0.0515)
features.6.conv.6 tensor(0.0659)
features.7.conv.0 tensor(0.0463)
features.7.conv.3 tensor(0.0104)
features.7.conv.6 tensor(0.0071)
features.8.conv.0 tensor(0.0701)
features.8.conv.3 tensor(0.1499)
features.8.conv.6 tensor(0.7607)
features.9.conv.0 tensor(0.8333)
features.9.conv.3 tensor(0.1586)
features.9.conv.6 tensor(0.8680)
features.10.conv.0 tensor(0.0490)
features.10.conv.3 tensor(0.1059)
features.10.conv.6 tensor(0.8578)
features.11.conv.0 tensor(0.0857)
features.11.conv.3 tensor(0.1503)
features.11.conv.6 tensor(0.3051)
features.12.conv.0 tensor(0.0757)
features.12.conv.3 tensor(0.2122)
features.12.conv.6 tensor(0.1856)
features.13.conv.0 tensor(0.7224)
features.13.conv.3 tensor(0.1331)
features.13.conv.6 tensor(0.0660)
features.14.conv.0 tensor(0.1682)
features.14.conv.3 tensor(0.1073)
features.14.conv.6 tensor(0.0235)
features.15.conv.0 tensor(0.7416)
features.15.conv.3 tensor(0.0816)
features.15.conv.6 tensor(0.2759)
features.16.conv.0 tensor(0.0762)
features.16.conv.3 tensor(0.0762)
features.16.conv.6 tensor(0.2178)
conv.0 tensor(0.4486)
tensor(637274.) 2188896.0
0.80382514
0.80302483
0.80235165
0.80179745
0.80146182
0.80102289
0.80075753
0.80078697
0.80068320
0.80055541
0.80038428
0.80035657
0.80031353
0.80028725
0.80036861
0.80085588
0.80080956
0.80077755
0.80056417
0.80052215
0.80035412
0.80032045
0.80072266
0.80116808
INFO - Training [5][   20/  196]   Loss 2.329710   Top1 9.414062   Top5 50.527344   BatchTime 0.320341   LR 0.002424
0.80148757
0.80186510
0.80184466
0.80183452
0.80191118
0.80186027
0.80175108
0.80176705
0.80181360
0.80204147
0.80216485
0.80223972
0.80219042
0.80220509
0.80205601
INFO - Training [5][   40/  196]   Loss 2.329541   Top1 9.453125   Top5 49.648438   BatchTime 0.292377   LR 0.002343
0.80200297
0.80190808
0.80194712
0.80190849
0.80189991
0.80192339
0.80189681
0.80177182
0.80182749
0.80170006
0.80191702
0.80196172
0.80179369
0.80174124
0.80185497
0.80162293
INFO - Training [5][   60/  196]   Loss 2.329656   Top1 9.583333   Top5 49.674479   BatchTime 0.277534   LR 0.002263
0.80123937
0.80115563
0.80080056
0.80060160
0.80041009
0.80009067
0.80008107
0.80004781
0.79990524
0.79984707
0.79973274
0.79970604
0.79951650
0.79962307
0.79945207
0.79925865
0.79898208
0.79896182
0.79879463
0.79842782
0.79818398
0.79772860
0.79741770
0.79759747
INFO - Training [5][   80/  196]   Loss 2.329465   Top1 9.643555   Top5 49.487305   BatchTime 0.271357   LR 0.002183
0.79715830
0.79706538
0.79685479
0.79674274
0.79644853
0.79633570
0.79634351
0.79640538
0.79627156
0.79601276
0.79592252
0.79590911
0.79601914
0.79607648
0.79589391
0.79588491
INFO - Training [5][  100/  196]   Loss 2.329218   Top1 9.675781   Top5 49.519531   BatchTime 0.267551   LR 0.002104
0.79588830
0.79597855
0.79579443
0.79572153
0.79578030
0.79623955
0.79574734
0.79611027
0.79615074
0.79606855
0.79611903
0.79615635
0.79618448
0.79630798
0.79653579
0.79683703
0.79714251
0.79740822
0.79771084
0.79805207
0.79829329
0.79861623
0.79890174
0.79899663
INFO - Training [5][  120/  196]   Loss 2.328998   Top1 9.847005   Top5 49.615885   BatchTime 0.264592   LR 0.002024
0.79921818
0.79956526
0.79949939
0.79952842
0.79984909
0.79857230
0.79020017
0.79109818
0.79147756
0.79196954
0.79255968
0.79304081
0.79343212
0.79381651
0.79417658
0.79453689
INFO - Training [5][  140/  196]   Loss 2.328809   Top1 9.729353   Top5 49.631696   BatchTime 0.262612   LR 0.001946
0.79535687
0.79545438
0.79572767
0.79592943
0.79633486
0.79671746
0.79688716
0.79702890
0.79706794
0.79725069
0.79724908
0.79721349
0.79724950
0.79724032
0.79736149
0.79749829
0.79750532
0.79757482
0.79761922
0.79765874
0.79771006
0.79782730
0.79784101
INFO - Training [5][  160/  196]   Loss 2.328715   Top1 9.770508   Top5 49.665527   BatchTime 0.261450   LR 0.001868
0.79790998
0.79807395
0.79809147
0.79810214
0.79818285
0.79778570
0.79772502
0.79786694
0.79780251
0.79776865
0.79775804
0.79780692
0.79775059
0.79777199
0.79799575
0.79769170
0.79755276
INFO - Training [5][  180/  196]   Loss 2.328701   Top1 9.817708   Top5 49.659288   BatchTime 0.259923   LR 0.001790
0.79744828
0.79729420
0.79727668
0.79728663
0.79718971
0.79710597
0.79696006
0.79688281
0.79681462
0.79674602
0.79649633
0.79646152
0.79640388
0.79626709
0.79615057
0.79605979
INFO - ==> Top1: 9.842    Top5: 49.576    Loss: 2.329
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.79598379
0.79607952
0.79600781
0.79593807
0.79592967
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [5][   20/   40]   Loss 2.772228   Top1 10.078125   Top5 49.980469   BatchTime 0.116093
INFO - Validation [5][   40/   40]   Loss 2.775725   Top1 10.000000   Top5 50.000000   BatchTime 0.088094
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.776
INFO - ==> Sparsity : 0.339
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.1215)
features.0.conv.3 tensor(0.0605)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.0255)
features.1.conv.6 tensor(0.0885)
features.2.conv.0 tensor(0.0477)
features.2.conv.3 tensor(0.0671)
features.2.conv.6 tensor(0.1374)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.0077)
features.3.conv.6 tensor(0.0480)
features.4.conv.0 tensor(0.0234)
features.4.conv.3 tensor(0.0862)
features.4.conv.6 tensor(0.1190)
features.5.conv.0 tensor(0.0439)
features.5.conv.3 tensor(0.0770)
features.5.conv.6 tensor(0.1151)
features.6.conv.0 tensor(0.0283)
features.6.conv.3 tensor(0.0521)
features.6.conv.6 tensor(0.0675)
features.7.conv.0 tensor(0.0471)
features.7.conv.3 tensor(0.0104)
features.7.conv.6 tensor(0.0107)
features.8.conv.0 tensor(0.0842)
features.8.conv.3 tensor(0.1508)
features.8.conv.6 tensor(0.7616)
features.9.conv.0 tensor(0.1849)
features.9.conv.3 tensor(0.0938)
features.9.conv.6 tensor(0.9043)
features.10.conv.0 tensor(0.0490)
features.10.conv.3 tensor(0.1065)
features.10.conv.6 tensor(0.8619)
features.11.conv.0 tensor(0.0909)
features.11.conv.3 tensor(0.1491)
features.11.conv.6 tensor(0.5322)
features.12.conv.0 tensor(0.0877)
features.12.conv.3 tensor(0.2126)
features.12.conv.6 tensor(0.1850)
features.13.conv.0 tensor(0.7199)
features.13.conv.3 tensor(0.1331)
features.13.conv.6 tensor(0.0678)
features.14.conv.0 tensor(0.1680)
features.14.conv.3 tensor(0.1079)
features.14.conv.6 tensor(0.0265)
features.15.conv.0 tensor(0.7565)
features.15.conv.3 tensor(0.0793)
features.15.conv.6 tensor(0.8518)
features.16.conv.0 tensor(0.0816)
features.16.conv.3 tensor(0.0760)
features.16.conv.6 tensor(0.2355)
conv.0 tensor(0.4677)
tensor(741471.) 2188896.0
0.79564190
0.79557282
0.79577786
0.79589117
0.79572469
0.79580510
0.79562581
0.79536331
0.79526454
0.79525417
0.79502994
0.79483378
0.79472047
0.79452246
0.79437399
0.79435372
0.79419291
0.79439121
0.79432452
0.79414034
0.79396349
0.79368639
0.79343307
INFO - Training [6][   20/  196]   Loss 2.327092   Top1 10.058594   Top5 50.742188   BatchTime 0.318947   LR 0.001655
0.79324138
0.79314113
0.79312074
0.79302937
0.79276049
0.79271352
0.79243731
0.79238093
0.79227245
0.79209620
0.79186505
0.79181260
0.79181933
0.79173225
0.79172754
0.79161769
INFO - Training [6][   40/  196]   Loss 2.327177   Top1 9.912109   Top5 50.341797   BatchTime 0.291233   LR 0.001580
0.79152638
0.79139948
0.79132897
0.79104930
0.79088151
0.79047608
0.79028177
0.79019094
0.79012394
0.78999966
0.78981549
0.78978211
0.78969717
0.78936726
0.78907800
0.78917819
0.78914809
0.78914684
0.78899056
0.78878450
0.78879941
0.78874356
0.78870076
INFO - Training [6][   60/  196]   Loss 2.327333   Top1 10.058594   Top5 49.921875   BatchTime 0.277467   LR 0.001506
0.78850859
0.78827697
0.78820544
0.78806448
0.78784919
0.78764451
0.78751194
0.78736645
0.78718334
0.78695244
0.78690070
0.78678340
0.78666878
0.78648561
0.78633934
0.78607231
0.78590733
INFO - Training [6][   80/  196]   Loss 2.327353   Top1 9.985352   Top5 50.053711   BatchTime 0.269894   LR 0.001432
0.78578252
0.78569216
0.78560042
0.78537446
0.78529030
0.78511345
0.78499019
0.78479153
0.78463036
0.78456551
0.78440630
0.78427207
0.78424364
0.78406292
0.78384244
0.78369439
0.78377652
0.78358287
0.78333628
0.78333622
0.78332555
0.78292423
0.78367132
0.78351551
INFO - Training [6][  100/  196]   Loss 2.327241   Top1 9.968750   Top5 50.031250   BatchTime 0.266500   LR 0.001360
0.78332239
0.78325790
0.78316242
0.78320545
0.78313828
0.78311086
0.78289270
0.78277677
0.78263927
0.78240943
0.78238541
0.78225309
0.78218830
0.78210914
INFO - Training [6][  120/  196]   Loss 2.327253   Top1 9.951172   Top5 49.918620   BatchTime 0.264040   LR 0.001289
0.78203219
0.78198713
0.78187966
0.78174269
0.78160310
0.78147775
0.78139907
0.78131676
0.78106117
0.78108394
0.78095776
0.78087986
0.78075540
0.78065085
0.78059959
0.78052777
0.78041124
0.78023189
0.78029162
0.78007591
0.77995259
0.77989829
0.77976233
0.77964669
INFO - Training [6][  140/  196]   Loss 2.327224   Top1 9.958147   Top5 49.963728   BatchTime 0.261849   LR 0.001220
0.77952123
0.77944642
0.77922213
0.77910811
0.77897388
0.77881837
0.77867621
0.77844781
0.77818263
0.77830034
0.77799785
0.77754658
0.77786118
0.77767718
0.77748817
0.77723074
INFO - Training [6][  160/  196]   Loss 2.327277   Top1 9.926758   Top5 49.904785   BatchTime 0.259642   LR 0.001151
0.77712458
0.77698237
0.77668440
0.77644169
0.77638626
0.77604538
0.77579802
0.77559203
0.77535522
0.77492166
0.77459145
0.77414155
0.77391559
0.77365029
0.77330583
0.77299702
0.77254164
0.77205157
0.77134800
0.77087611
0.77020431
0.76952255
0.76891375
0.76827413
0.76754314
INFO - Training [6][  180/  196]   Loss 2.327204   Top1 9.976128   Top5 49.989149   BatchTime 0.257982   LR 0.001084
0.76670200
0.76596785
0.76522219
0.76453149
0.76424271
0.76343536
0.76267344
0.76156193
0.76076627
INFO - ==> Top1: 9.964    Top5: 49.906    Loss: 2.327
0.76051050
0.76045060
0.76040745
0.76087219
0.76121765
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [6][   20/   40]   Loss 2.457179   Top1 10.078125   Top5 49.960938   BatchTime 0.115347
INFO - Validation [6][   40/   40]   Loss 2.458518   Top1 10.000000   Top5 50.000000   BatchTime 0.086530
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.459
INFO - ==> Sparsity : 0.419
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.1215)
features.0.conv.3 tensor(0.0234)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.0255)
features.1.conv.6 tensor(0.0885)
features.2.conv.0 tensor(0.0477)
features.2.conv.3 tensor(0.0671)
features.2.conv.6 tensor(0.1392)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.0077)
features.3.conv.6 tensor(0.0477)
features.4.conv.0 tensor(0.0236)
features.4.conv.3 tensor(0.0856)
features.4.conv.6 tensor(0.1196)
features.5.conv.0 tensor(0.0441)
features.5.conv.3 tensor(0.0764)
features.5.conv.6 tensor(0.1649)
features.6.conv.0 tensor(0.0283)
features.6.conv.3 tensor(0.0527)
features.6.conv.6 tensor(0.0674)
features.7.conv.0 tensor(0.0488)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(0.0101)
features.8.conv.0 tensor(0.1398)
features.8.conv.3 tensor(0.1502)
features.8.conv.6 tensor(0.7607)
features.9.conv.0 tensor(0.1581)
features.9.conv.3 tensor(0.0764)
features.9.conv.6 tensor(0.9178)
features.10.conv.0 tensor(0.0491)
features.10.conv.3 tensor(0.1065)
features.10.conv.6 tensor(0.8625)
features.11.conv.0 tensor(0.1012)
features.11.conv.3 tensor(0.1476)
features.11.conv.6 tensor(0.8542)
features.12.conv.0 tensor(0.1308)
features.12.conv.3 tensor(0.2139)
features.12.conv.6 tensor(0.1851)
features.13.conv.0 tensor(0.7149)
features.13.conv.3 tensor(0.1335)
features.13.conv.6 tensor(0.0676)
features.14.conv.0 tensor(0.1674)
features.14.conv.3 tensor(0.1086)
features.14.conv.6 tensor(0.0306)
features.15.conv.0 tensor(0.7584)
features.15.conv.3 tensor(0.0791)
features.15.conv.6 tensor(0.9048)
features.16.conv.0 tensor(0.0893)
features.16.conv.3 tensor(0.0762)
features.16.conv.6 tensor(0.6707)
conv.0 tensor(0.4942)
tensor(917974.) 2188896.0
0.76168275
0.76200670
0.76225042
0.76243758
0.76234865
0.76221043
0.76197273
0.76165599
0.76113564
0.76080865
0.76038462
0.75980008
0.75930935
0.75934029
0.75899523
0.75905675
0.75864446
INFO - Training [7][   20/  196]   Loss 2.325562   Top1 10.136719   Top5 51.171875   BatchTime 0.318724   LR 0.000969
0.75823301
0.75845844
0.75860423
0.75866753
0.75885546
0.75907755
0.75888765
0.75899941
0.75874001
0.75862223
0.75834000
0.75797129
0.75770861
0.75718451
0.75646263
0.75598079
0.75556827
0.75512064
0.75477815
0.75428349
0.75404704
0.75364131
0.75336117
INFO - Training [7][   40/  196]   Loss 2.326406   Top1 9.638672   Top5 50.078125   BatchTime 0.289165   LR 0.000907
0.75326526
0.75301784
0.75289333
0.75276786
0.75279820
0.75266850
0.75229478
0.75204086
0.75200647
0.75192219
0.75208002
0.75204301
0.75188625
0.75168639
0.75149691
INFO - Training [7][   60/  196]   Loss 2.326418   Top1 9.687500   Top5 50.136719   BatchTime 0.278737   LR 0.000845
0.75135434
0.75115484
0.75084120
0.75048310
0.75028658
0.75012392
0.74993193
0.74968797
0.74955308
0.74936056
0.74928737
0.74891406
0.74895310
0.74921376
0.74908465
0.74891359
0.74884468
0.74871856
0.74836564
0.74811965
0.74819070
0.74814391
0.74801725
0.74782097
INFO - Training [7][   80/  196]   Loss 2.326537   Top1 9.638672   Top5 49.907227   BatchTime 0.271547   LR 0.000786
0.74767673
0.74765164
0.74766952
0.74753302
0.74752730
0.74719059
0.74646479
0.74693519
0.74688077
0.74683052
0.74665356
0.74651313
0.74631584
0.74612081
0.74577522
0.74551958
0.74527860
INFO - Training [7][  100/  196]   Loss 2.326726   Top1 9.570312   Top5 49.628906   BatchTime 0.267087   LR 0.000728
0.74503541
0.74482036
0.74442661
0.74416834
0.74390590
0.74371964
0.74344003
0.74317193
0.74299634
0.74277443
0.74227840
0.74185318
0.74220723
0.74213624
0.74208981
0.74178898
0.74130374
0.74108595
0.74079794
0.74055958
0.74029428
0.73996824
0.73958856
0.73909324
INFO - Training [7][  120/  196]   Loss 2.326489   Top1 9.739583   Top5 49.609375   BatchTime 0.264422   LR 0.000673
0.73844576
0.73863512
0.73868203
0.73841959
0.73829323
0.73800915
0.73759514
0.73734128
0.73695809
0.73663950
0.73634899
0.73589033
0.73552144
0.73505360
0.73470825
0.73451769
INFO - Training [7][  140/  196]   Loss 2.326233   Top1 9.726562   Top5 49.966518   BatchTime 0.262344   LR 0.000619
0.73434031
0.73429769
0.73411673
0.73377538
0.73297256
0.73226559
0.73246205
0.73246157
0.73241234
0.73205566
0.73176545
0.73140514
0.73096645
0.73066163
0.73030156
0.73001480
0.72988659
0.72972232
0.72945213
0.72881252
0.72830033
0.72778815
0.72717816
0.72640771
INFO - Training [7][  160/  196]   Loss 2.326057   Top1 9.758301   Top5 50.146484   BatchTime 0.260508   LR 0.000567
0.72583127
0.72556692
0.72552842
0.72540247
0.72520953
0.72487837
0.72446907
0.72420084
0.72365737
0.72318089
0.72265369
0.72221130
0.72168815
0.72131693
0.72074342
0.72006583
INFO - Training [7][  180/  196]   Loss 2.325981   Top1 9.780816   Top5 50.026042   BatchTime 0.259156   LR 0.000517
0.71951622
0.71854353
0.71784693
0.71812767
0.71798569
0.71772599
0.71723831
0.71662277
0.71599466
0.71553731
0.71482503
0.71402067
0.71326321
0.71236366
0.71125501
0.71025556
INFO - ==> Top1: 9.824    Top5: 50.064    Loss: 2.326
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.70956832
0.70862335
0.70778745
0.70694262
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [7][   20/   40]   Loss 2.393330   Top1 10.078125   Top5 49.804688   BatchTime 0.112903
features.0.conv.0 tensor(0.1215)
features.0.conv.3 tensor(0.0527)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.0266)
features.1.conv.6 tensor(0.0885)
features.2.conv.0 tensor(0.0480)
features.2.conv.3 tensor(0.0671)
features.2.conv.6 tensor(0.1383)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.0085)
features.3.conv.6 tensor(0.0484)
features.4.conv.0 tensor(0.0246)
features.4.conv.3 tensor(0.0862)
features.4.conv.6 tensor(0.1203)
features.5.conv.0 tensor(0.0435)
features.5.conv.3 tensor(0.0775)
features.5.conv.6 tensor(0.4398)
features.6.conv.0 tensor(0.0286)
features.6.conv.3 tensor(0.0521)
features.6.conv.6 tensor(0.0705)
features.7.conv.0 tensor(0.4277)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(0.0426)
features.8.conv.0 tensor(0.6034)
features.8.conv.3 tensor(0.1496)
features.8.conv.6 tensor(0.7613)
features.9.conv.0 tensor(0.1068)
features.9.conv.3 tensor(0.0674)
features.9.conv.6 tensor(0.9132)
features.10.conv.0 tensor(0.0493)
features.10.conv.3 tensor(0.1036)
features.10.conv.6 tensor(0.8552)
features.11.conv.0 tensor(0.1154)
features.11.conv.3 tensor(0.1478)
features.11.conv.6 tensor(0.8900)
features.12.conv.0 tensor(0.2230)
features.12.conv.3
INFO - Validation [7][   40/   40]   Loss 2.394332   Top1 10.000000   Top5 50.000000   BatchTime 0.083664
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.394
INFO - ==> Sparsity : 0.494
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch   8
features.12.conv.3 tensor(0.2122)
features.12.conv.6 tensor(0.1857)
features.13.conv.0 tensor(0.7112)
features.13.conv.3 tensor(0.1306)
features.13.conv.6 tensor(0.0672)
features.14.conv.0 tensor(0.1674)
features.14.conv.3 tensor(0.1079)
features.14.conv.6 tensor(0.0358)
features.15.conv.0 tensor(0.7594)
features.15.conv.3 tensor(0.0789)
features.15.conv.6 tensor(0.9195)
features.16.conv.0 tensor(0.0932)
features.16.conv.3 tensor(0.0769)
features.16.conv.6 tensor(0.8852)
conv.0 tensor(0.6533)
tensor(1082075.) 2188896.0
0.70599747
0.70517159
0.70411390
0.70325518
0.70242947
0.70152563
0.70064211
0.69982737
0.69932485
0.69871086
0.69831502
0.69760853
0.69679314
0.69587642
0.69526428
0.69445205
0.69349986
0.69280189
0.69223535
INFO - Training [8][   20/  196]   Loss 2.324335   Top1 9.882812   Top5 50.156250   BatchTime 0.303175   LR 0.000434
0.69132477
0.69028163
0.68965679
0.68883955
0.68818265
0.68765169
0.68701208
0.68696189
0.68655926
0.68623972
0.68559915
0.68494856
0.68452281
0.68403244
0.68337500
0.68275833
INFO - Training [8][   40/  196]   Loss 2.323811   Top1 10.029297   Top5 50.058594   BatchTime 0.281285   LR 0.000389
0.68207133
0.68163085
0.68100828
0.68052536
0.68016750
0.68015772
0.67986476
0.67955804
0.67924565
0.67886788
0.67859477
0.67828113
0.67798668
0.67778444
0.67732239
0.67698365
0.67665470
0.67637378
0.67613524
0.67578471
0.67543614
0.67533070
0.67508757
INFO - Training [8][   60/  196]   Loss 2.323574   Top1 9.980469   Top5 50.312500   BatchTime 0.273023   LR 0.000347
0.67487741
0.67465055
0.67442375
0.67401665
0.67386019
0.67378640
0.67368925
0.67337656
0.67320353
0.67293406
0.67288411
0.67271751
0.67244554
0.67227572
0.67184186
0.67149216
0.67117286
0.67091393
0.67081887
0.67065066
0.67069381
0.67057073
0.67042404
0.67019200
INFO - Training [8][   80/  196]   Loss 2.323600   Top1 9.858398   Top5 50.185547   BatchTime 0.268068   LR 0.000308
0.66997206
0.66986096
0.66944808
0.66933107
0.66909224
0.66874999
0.66865242
0.66846573
0.66849518
0.66833627
0.66835386
0.66815478
0.66809750
0.66801941
0.66805863
0.66800487
INFO - Training [8][  100/  196]   Loss 2.323787   Top1 9.773438   Top5 49.914062   BatchTime 0.264813   LR 0.000270
0.66794562
0.66791308
0.66782564
0.66767961
0.66748595
0.66738826
0.66724318
0.66712254
0.66719604
0.66715717
0.66697550
0.66684121
0.66665292
0.66643488
0.66625386
0.66603011
0.66583449
0.66566426
0.66555464
0.66542763
0.66530848
0.66525459
0.66519272
0.66509014
INFO - Training [8][  120/  196]   Loss 2.323505   Top1 9.915365   Top5 50.074870   BatchTime 0.262063   LR 0.000235
0.66500950
0.66509408
0.66499162
0.66492027
0.66490638
0.66491485
0.66502619
0.66503042
0.66507447
0.66493243
0.66492993
0.66481054
0.66478074
0.66470736
0.66464990
0.66477370
INFO - Training [8][  140/  196]   Loss 2.323463   Top1 9.888393   Top5 50.011161   BatchTime 0.260094   LR 0.000202
0.66465670
0.66465861
0.66463906
0.66464722
0.66452134
0.66447830
0.66447014
0.66433311
0.66452432
0.66450828
0.66452241
0.66438508
0.66426325
0.66422296
0.66424268
0.66414094
0.66395760
0.66394186
0.66396874
0.66390264
0.66377920
0.66368520
0.66361421
0.66351789
INFO - Training [8][  160/  196]   Loss 2.323501   Top1 9.853516   Top5 49.882812   BatchTime 0.258827   LR 0.000172
0.66341448
0.66336054
0.66330618
0.66334498
0.66343385
0.66332966
0.66331708
0.66322893
0.66319615
0.66315460
0.66319603
0.66316503
0.66311610
0.66299492
0.66303492
0.66286981
INFO - Training [8][  180/  196]   Loss 2.323520   Top1 9.863281   Top5 49.811198   BatchTime 0.257405   LR 0.000143
0.66288501
0.66284442
0.66276795
0.66269094
0.66264290
0.66257262
0.66246760
0.66222203
0.66212660
0.66206580
0.66195643
0.66197383
0.66192436
0.66184562
0.66194153
0.66202807
INFO - ==> Top1: 9.914    Top5: 49.818    Loss: 2.323
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.66181731
0.66157562
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 2.410998   Top1 10.078125   Top5 49.804688   BatchTime 0.114878
INFO - Validation [8][   40/   40]   Loss 2.412194   Top1 10.000000   Top5 50.000000   BatchTime 0.084693
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.412
INFO - ==> Sparsity : 0.536
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.1215)
features.0.conv.3 tensor(0.0566)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.0266)
features.1.conv.6 tensor(0.0885)
features.2.conv.0 tensor(0.0480)
features.2.conv.3 tensor(0.0671)
features.2.conv.6 tensor(0.1383)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.0085)
features.3.conv.6 tensor(0.0484)
features.4.conv.0 tensor(0.0249)
features.4.conv.3 tensor(0.0856)
features.4.conv.6 tensor(0.1204)
features.5.conv.0 tensor(0.0436)
features.5.conv.3 tensor(0.0770)
features.5.conv.6 tensor(0.5444)
features.6.conv.0 tensor(0.0288)
features.6.conv.3 tensor(0.0532)
features.6.conv.6 tensor(0.0708)
features.7.conv.0 tensor(0.7747)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(0.0557)
features.8.conv.0 tensor(0.7661)
features.8.conv.3 tensor(0.1461)
features.8.conv.6 tensor(0.7618)
features.9.conv.0 tensor(0.1012)
features.9.conv.3 tensor(0.0642)
features.9.conv.6 tensor(0.9113)
features.10.conv.0 tensor(0.0495)
features.10.conv.3 tensor(0.1027)
features.10.conv.6 tensor(0.8511)
features.11.conv.0 tensor(0.1312)
features.11.conv.3 tensor(0.1470)
features.11.conv.6 tensor(0.8921)
features.12.conv.0 tensor(0.3571)
features.12.conv.3 tensor(0.2139)
features.12.conv.6 tensor(0.1866)
features.13.conv.0 tensor(0.7095)
features.13.conv.3 tensor(0.1294)
features.13.conv.6 tensor(0.0672)
features.14.conv.0 tensor(0.1664)
features.14.conv.3 tensor(0.1069)
features.14.conv.6 tensor(0.0454)
features.15.conv.0 tensor(0.7609)
features.15.conv.3 tensor(0.0794)
features.15.conv.6 tensor(0.9154)
features.16.conv.0 tensor(0.0939)
features.16.conv.3 tensor(0.0764)
features.16.conv.6 tensor(0.9068)
conv.0 tensor(0.8026)
tensor(1172347.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
0.66147923
0.66131085
0.66118103
0.66108197
0.66103661
0.66100723
0.66086131
0.66084945
0.66087359
0.66092312
0.66095072
0.66098529
0.66087914
0.66092747
0.66095227
0.66097975
0.66088778
0.66093469
0.66083348
0.66076839
INFO - Training [9][   20/  196]   Loss 2.322635   Top1 10.195312   Top5 49.882812   BatchTime 0.314839   LR 0.000100
0.66075283
0.66061944
0.66051698
0.66039151
0.66032422
0.66028202
0.66027945
0.66032016
0.66028327
0.66031593
0.66037148
0.66024297
0.66018385
0.66009969
0.65988690
0.65981179
INFO - Training [9][   40/  196]   Loss 2.322728   Top1 9.785156   Top5 50.253906   BatchTime 0.282275   LR 0.000079
0.65988225
0.65981609
0.65988773
0.65980351
0.65982550
0.65979654
0.65965158
0.65953153
0.65957975
0.65951574
0.65948105
0.65961468
0.65952992
0.65948522
0.65947706
0.65942842
INFO - Training [9][   60/  196]   Loss 2.322871   Top1 9.765625   Top5 50.162760   BatchTime 0.271567   LR 0.000060
0.65939927
0.65944773
0.65936136
0.65929121
0.65931159
0.65930110
0.65916228
0.65901399
0.65894783
0.65887147
0.65897101
0.65903562
0.65907431
0.65906078
0.65886915
0.65896589
0.65895534
0.65905190
0.65900755
0.65900522
0.65885311
0.65886790
0.65888840
0.65890008
0.65888572
INFO - Training [9][   80/  196]   Loss 2.322592   Top1 9.951172   Top5 50.434570   BatchTime 0.265939   LR 0.000044
0.65888047
0.65874100
0.65868807
0.65883291
0.65873462
0.65866327
0.65874636
0.65869957
0.65872705
0.65865844
0.65862185
0.65852070
0.65847868
0.65851563
0.65842450
0.65845519
0.65831280
0.65823925
0.65817094
0.65824127
0.65832168
0.65810424
0.65809500
INFO - Training [9][  100/  196]   Loss 2.322683   Top1 9.917969   Top5 50.363281   BatchTime 0.263980   LR 0.000030
0.65802568
0.65804833
0.65794128
0.65804070
0.65811861
0.65814775
0.65796244
0.65802622
0.65800118
0.65789670
0.65806502
0.65812868
0.65809518
0.65816611
0.65820366
0.65829366
INFO - Training [9][  120/  196]   Loss 2.322750   Top1 10.009766   Top5 50.224609   BatchTime 0.260778   LR 0.000019
0.65813398
0.65807468
0.65809977
0.65801698
0.65793455
0.65791804
0.65782046
0.65788954
0.65794808
0.65800166
0.65807700
0.65815860
0.65808743
0.65811765
0.65800041
0.65805829
INFO - Training [9][  140/  196]   Loss 2.322739   Top1 9.969308   Top5 50.186942   BatchTime 0.258989   LR 0.000010
0.65804839
0.65798849
0.65798271
0.65798235
0.65787786
0.65798622
0.65803427
0.65795368
0.65775681
0.65780091
0.65788919
0.65784413
0.65777165
0.65783191
0.65782517
0.65789682
0.65786743
0.65778261
0.65791994
0.65784925
0.65772742
0.65773827
0.65756840
0.65761489
0.65762430
INFO - Training [9][  160/  196]   Loss 2.322728   Top1 9.987793   Top5 50.046387   BatchTime 0.258055   LR 0.000004
0.65767497
0.65766716
0.65754557
0.65764594
0.65762520
0.65775973
0.65785980
0.65792727
0.65798968
0.65796471
0.65788180
0.65774548
0.65769917
0.65765727
0.65765297
0.65757817
INFO - Training [9][  180/  196]   Loss 2.322721   Top1 9.954427   Top5 50.080295   BatchTime 0.256959   LR 0.000001
0.65757698
0.65763348
0.65764660
0.65775996
0.65773237
0.65778124
0.65774828
0.65777677
0.65773529
0.65771252
0.65778381
0.65772074
0.65770197
0.65775055
0.65769184
INFO - ==> Top1: 9.958    Top5: 50.108    Loss: 2.323
0.65774661
0.65778178
0.65765548
0.65764135
0.65765256
0.65762848
0.65764123
0.65767419
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [9][   20/   40]   Loss 2.347614   Top1 10.078125   Top5 49.804688   BatchTime 0.112784
INFO - Validation [9][   40/   40]   Loss 2.347898   Top1 10.000000   Top5 50.000000   BatchTime 0.084036
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.348
INFO - ==> Sparsity : 0.540
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.1215)
features.0.conv.3 tensor(0.0566)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.0266)
features.1.conv.6 tensor(0.0885)
features.2.conv.0 tensor(0.0477)
features.2.conv.3 tensor(0.0671)
features.2.conv.6 tensor(0.1383)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.0085)
features.3.conv.6 tensor(0.0486)
features.4.conv.0 tensor(0.0247)
features.4.conv.3 tensor(0.0851)
features.4.conv.6 tensor(0.1200)
features.5.conv.0 tensor(0.0433)
features.5.conv.3 tensor(0.0770)
features.5.conv.6 tensor(0.5636)
features.6.conv.0 tensor(0.0286)
features.6.conv.3 tensor(0.0544)
features.6.conv.6 tensor(0.0706)
features.7.conv.0 tensor(0.7734)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(0.0558)
features.8.conv.0 tensor(0.7714)
features.8.conv.3 tensor(0.1467)
features.8.conv.6 tensor(0.7633)
features.9.conv.0 tensor(0.1007)
features.9.conv.3 tensor(0.0642)
features.9.conv.6 tensor(0.9106)
features.10.conv.0 tensor(0.0496)
features.10.conv.3 tensor(0.1042)
features.10.conv.6 tensor(0.8498)
features.11.conv.0 tensor(0.1333)
features.11.conv.3 tensor(0.1462)
features.11.conv.6 tensor(0.8926)
features.12.conv.0 tensor(0.3932)
features.12.conv.3 tensor(0.2139)
features.12.conv.6 tensor(0.1860)
features.13.conv.0 tensor(0.7083)
features.13.conv.3 tensor(0.1275)
features.13.conv.6 tensor(0.0674)
features.14.conv.0 tensor(0.1661)
features.14.conv.3 tensor(0.1073)
features.14.conv.6 tensor(0.0499)
features.15.conv.0 tensor(0.7610)
features.15.conv.3 tensor(0.0785)
features.15.conv.6 tensor(0.9203)
features.16.conv.0 tensor(0.0932)
features.16.conv.3 tensor(0.0762)
features.16.conv.6 tensor(0.9093)
conv.0 tensor(0.8146)
tensor(1181575.) 2188896.0
0.65759254
0.66059101
0.65840864
0.65645057
0.65469122
0.65310723
0.65124923
0.64984339
0.64864087
0.64781719
0.64704436
0.64519173
0.64344150
0.64190227
0.64037299
INFO - Training [10][   20/  196]   Loss 2.324797   Top1 10.253906   Top5 50.136719   BatchTime 0.322575   LR 0.002500
0.63882810
0.63708091
0.63558060
0.63437217
0.63331467
0.63251764
0.63205594
0.63175213
0.63126493
0.63060719
0.63024396
0.63011032
0.62998730
0.62987554
0.62963295
0.62964797
0.62961662
0.62954873
0.62940937
0.62953186
0.62934786
0.62916452
0.62936300
INFO - Training [10][   40/  196]   Loss 2.324550   Top1 10.244141   Top5 49.521484   BatchTime 0.291542   LR 0.002499
0.62944943
0.62940252
0.62969077
0.62942755
0.62920648
0.62892759
0.62873423
0.62869722
0.62855899
0.62820715
0.62797427
0.62741184
0.62704909
0.62703180
0.62710851
INFO - Training [10][   60/  196]   Loss 2.323934   Top1 10.247396   Top5 49.563802   BatchTime 0.284020   LR 0.002499
0.62710053
0.62732852
0.62759739
0.62782145
0.62735492
0.62719446
0.62722737
0.62728107
0.62712377
0.62726402
0.62771010
0.62788355
0.62790775
0.62844670
0.62810975
0.62763482
0.62713927
0.62691075
0.62629598
0.62574857
0.62501377
0.62441540
0.62379098
0.62316728
INFO - Training [10][   80/  196]   Loss 2.323447   Top1 10.117188   Top5 49.448242   BatchTime 0.274578   LR 0.002497
0.62271887
0.62218755
0.62182182
0.62124699
0.62056309
0.61987883
0.61907381
0.61816746
0.61762899
0.61730784
0.61658531
0.61550862
0.61417669
0.61318845
0.61218989
0.61149800
INFO - Training [10][  100/  196]   Loss 2.323314   Top1 10.117188   Top5 49.546875   BatchTime 0.269578   LR 0.002496
0.61095005
0.61015809
0.60961366
0.60994083
0.61012316
0.60988349
0.60946476
0.60881358
0.60824931
0.60897577
0.60925752
0.60932988
0.60982144
0.61036003
0.61039674
0.61029726
0.61038208
0.61205220
0.61310393
0.61363673
0.61384392
0.61390930
0.61416471
INFO - Training [10][  120/  196]   Loss 2.323090   Top1 10.078125   Top5 49.707031   BatchTime 0.268256   LR 0.002494
0.61434656
0.61412185
0.61401916
0.61413670
0.61397892
0.61399037
0.61493450
0.61541641
0.61601067
0.61647528
0.61681139
0.61696678
0.61706066
0.61779279
0.61890626
0.61913073
0.61879754
0.61794460
0.61663204
0.61490679
0.61317444
0.61197126
0.61084878
0.60751647
INFO - Training [10][  140/  196]   Loss 2.323033   Top1 10.094866   Top5 49.732143   BatchTime 0.265737   LR 0.002492
0.60364556
0.59930956
0.59565270
0.59357631
0.58989453
0.58757299
0.58684909
0.58641815
0.58612400
0.58522451
0.58391166
0.58342510
0.58266139
0.58319438
0.58337730
0.58343077
INFO - Training [10][  160/  196]   Loss 2.322860   Top1 10.085449   Top5 49.812012   BatchTime 0.264129   LR 0.002490
0.58316088
0.58218867
0.58116710
0.58054388
0.57968748
0.57898116
0.57804132
0.57849658
0.57797611
0.57733876
0.57710618
0.57693696
0.57681745
0.57682312
0.57643133
0.57642519
0.57628781
INFO - Training [10][  180/  196]   Loss 2.322767   Top1 10.010851   Top5 49.789497   BatchTime 0.260735   LR 0.002487
0.57622749
0.57609749
0.57587564
0.57608479
0.57594860
0.57624888
0.57670945
0.57728153
0.57773393
0.57797188
0.57799870
0.57797021
0.57813722
0.57807505
0.57812274
0.57801139
INFO - ==> Top1: 9.974    Top5: 49.876    Loss: 2.323
0.57803792
0.57808453
0.57807505
0.57797867
0.57797623
0.57765967
0.57790077
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [10][   20/   40]   Loss 2.309767   Top1 10.253906   Top5 49.960938   BatchTime 0.116592
INFO - Validation [10][   40/   40]   Loss 2.310188   Top1 10.000000   Top5 50.000000   BatchTime 0.085947
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.310
INFO - ==> Sparsity : 0.592
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.1215)
features.0.conv.3 tensor(0.0547)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.0266)
features.1.conv.6 tensor(0.0885)
features.2.conv.0 tensor(0.0480)
features.2.conv.3 tensor(0.0671)
features.2.conv.6 tensor(0.1386)
features.3.conv.0 tensor(0.0003)
features.3.conv.3 tensor(0.0085)
features.3.conv.6 tensor(0.0486)
features.4.conv.0 tensor(0.0674)
features.4.conv.3 tensor(0.0862)
features.4.conv.6 tensor(0.1201)
features.5.conv.0 tensor(0.7591)
features.5.conv.3 tensor(0.0787)
features.5.conv.6 tensor(0.6751)
features.6.conv.0 tensor(0.0298)
features.6.conv.3 tensor(0.0527)
features.6.conv.6 tensor(0.0680)
features.7.conv.0 tensor(0.7737)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(0.0890)
features.8.conv.0 tensor(0.8339)
features.8.conv.3 tensor(0.1453)
features.8.conv.6 tensor(0.7641)
features.9.conv.0 tensor(0.1353)
features.9.conv.3 tensor(0.0715)
features.9.conv.6 tensor(0.9258)
features.10.conv.0 tensor(0.0506)
features.10.conv.3 tensor(0.1036)
features.10.conv.6 tensor(0.8451)
features.11.conv.0 tensor(0.8829)
features.11.conv.3 tensor(0.1495)
features.11.conv.6 tensor(0.9503)
features.12.conv.0 tensor(0.8386)
features.12.conv.3 tensor(0.2139)
features.12.conv.6 tensor(0.1792)
features.13.conv.0 tensor(0.7101)
features.13.conv.3 tensor(0.1296)
features.13.conv.6 tensor(0.0593)
features.14.conv.0 tensor(0.1669)
features.14.conv.3 tensor(0.1073)
features.14.conv.6 tensor(0.0217)
features.15.conv.0 tensor(0.7815)
features.15.conv.3 tensor(0.0785)
features.15.conv.6 tensor(0.9326)
features.16.conv.0 tensor(0.1081)
features.16.conv.3 tensor(0.0755)
features.16.conv.6 tensor(0.9200)
conv.0 tensor(0.8874)
tensor(1294902.) 2188896.0
0.57865894
0.57895768
0.57963061
0.57975155
0.57993603
0.57984155
0.57990849
0.58016664
0.58017045
0.58028096
0.58033371
0.58034223
0.58059448
0.58118427
0.58131552
INFO - Training [11][   20/  196]   Loss 2.320538   Top1 9.687500   Top5 50.976562   BatchTime 0.307869   LR 0.002481
0.58154154
0.58174390
0.58230090
0.58249056
0.58255488
0.58248419
0.58250529
0.58226639
0.58229774
0.58229053
0.58250868
0.58227658
0.58234841
0.58275539
0.58327955
0.58369255
0.58389533
0.58431232
0.58480346
0.58535981
0.58582246
0.58737814
0.58859974
0.58945119
INFO - Training [11][   40/  196]   Loss 2.321561   Top1 9.453125   Top5 50.136719   BatchTime 0.280720   LR 0.002478
0.58987272
0.58997881
0.58964646
0.58944660
0.58883381
0.58822167
0.58767772
0.58699930
0.58609253
0.58512092
0.58432132
0.58337009
0.58286780
0.58212465
0.58129245
0.58076406
INFO - Training [11][   60/  196]   Loss 2.321331   Top1 9.856771   Top5 50.247396   BatchTime 0.270477   LR 0.002474
0.58002180
0.57930237
0.57897627
0.57838619
0.57777226
0.57714480
0.57659024
0.57599235
0.57539254
0.57459933
0.57368851
0.57273149
0.57177025
0.57046688
0.56907499
0.56679195
0.56549186
0.56333852
0.56137061
0.56090826
0.56128806
0.56128579
0.56023598
0.55897605
INFO - Training [11][   80/  196]   Loss 2.321360   Top1 9.863281   Top5 50.092773   BatchTime 0.265444   LR 0.002470
0.55725312
0.55557960
0.55467343
0.55699742
0.55864739
0.55925858
0.55965000
0.55993420
0.56001216
0.56060064
0.56140685
0.56080711
0.56045634
0.56015068
0.55981898
0.55869633
INFO - Training [11][  100/  196]   Loss 2.321396   Top1 9.839844   Top5 49.957031   BatchTime 0.261416   LR 0.002465
0.55817503
0.55803895
0.55794197
0.55753988
0.55670726
0.55558980
0.55472463
0.55479306
0.55384403
0.55360872
0.55335009
0.55355328
0.55407566
0.55435765
0.55486375
0.55540627
0.55579823
0.55618262
0.55669093
0.55683810
0.55729485
0.55787641
0.55862749
0.55924779
INFO - Training [11][  120/  196]   Loss 2.321296   Top1 9.820964   Top5 49.873047   BatchTime 0.259444   LR 0.002460
0.55962729
0.55986011
0.56006432
0.56025416
0.56040806
0.56043673
0.56047088
0.56082636
0.56092036
0.56097615
0.56107777
0.56104344
0.56170660
0.56204480
0.56215501
0.56214297
INFO - Training [11][  140/  196]   Loss 2.321158   Top1 9.885603   Top5 49.840960   BatchTime 0.258461   LR 0.002455
0.56240255
0.56235802
0.56254178
0.56261307
0.56264782
0.56259269
0.56274182
0.56271541
0.56268364
0.56254297
0.56250328
0.56235462
0.56232220
0.56224835
0.56226224
0.56235623
0.56241095
0.56235099
0.56215453
0.56215835
0.56225801
0.56230485
0.56248027
0.56260914
INFO - Training [11][  160/  196]   Loss 2.321138   Top1 9.848633   Top5 49.770508   BatchTime 0.257752   LR 0.002450
0.56238979
0.56244904
0.56254792
0.56254947
0.56324011
0.56346011
0.56391376
0.56443757
0.56464422
0.56475854
0.56469011
0.56521213
0.56508219
0.56530136
0.56549227
0.56581551
0.56615663
INFO - Training [11][  180/  196]   Loss 2.321145   Top1 9.878472   Top5 49.717882   BatchTime 0.256128   LR 0.002444
0.56623769
0.56628674
0.56631428
0.56634748
0.56665921
0.56690431
0.56706768
0.56712776
0.56757414
0.56795895
0.56823868
0.56842828
0.56866193
0.56894529
0.56916672
0.56949675
INFO - ==> Top1: 9.846    Top5: 49.698    Loss: 2.321
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.56970394
0.57000786
0.57042766
0.57080799
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [11][   20/   40]   Loss 2.340532   Top1 9.882812   Top5 49.785156   BatchTime 0.113829
INFO - Validation [11][   40/   40]   Loss 2.339230   Top1 10.000000   Top5 50.000000   BatchTime 0.084231
features.0.conv.0 tensor(0.1215)
features.0.conv.3 tensor(0.0293)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.0255)
features.1.conv.6 tensor(0.0885)
features.2.conv.0 tensor(0.0483)
features.2.conv.3 tensor(0.0671)
features.2.conv.6 tensor(0.1392)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.0085)
features.3.conv.6 tensor(0.0486)
features.4.conv.0 tensor(0.6883)
features.4.conv.3 tensor(0.0891)
features.4.conv.6 tensor(0.1183)
features.5.conv.0 tensor(0.7996)
features.5.conv.3 tensor(0.0770)
features.5.conv.6 tensor(0.7834)
features.6.conv.0 tensor(0.0322)
features.6.conv.3 tensor(0.0515)
features.6.conv.6 tensor(0.0672)
features.7.conv.0 tensor(0.5623)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(0.1503)
features.8.conv.0 tensor(0.8540)
features.8.conv.3 tensor(0.1464)
features.8.conv.6 tensor(0.7634)
features.9.conv.0 tensor(0.1716)
features.9.conv.3 tensor(0.0828)
features.9.conv.6 tensor(0.9414)
features.10.conv.0 tensor(0.0973)
features.10.conv.3 tensor(0.1024)
features.10.conv.6 tensor(0.8471)
features.11.conv.0 tensor(0.8707)
features.11.conv.3 tensor(0.1474)
features.11.conv.6 tensor(0.9543)
features.12.conv.0 tensor(0.8486)
features.12.conv.3 tensor(0.2122)
features.12.conv.6 tensor(0.1812)
features.13.conv.0 tensor(0.7203)
features.13.conv.3 tensor(0.1306)
features.13.conv.6 tensor(0.0635)
features.14.conv.0 tensor(0.1658)
features.14.conv.3 tensor(0.1090)
features.14.conv.6 tensor(0.0201)
features.15.conv.0 tensor(0.7877)
features.15.conv.3 tensor(0.0777)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.1343)
features.16.conv.3 tensor(0.0760)
features.16.conv.6 tensor(0.9290)
conv.0 tensor(0.8879)
tensor(1317958.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.339
INFO - ==> Sparsity : 0.602
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
0.57048172
0.57055885
0.57045120
0.57074702
0.57096821
0.57140011
0.57175130
0.57207495
0.57257587
0.57330430
0.57383639
0.57441252
0.57517290
0.57561243
0.57617146
0.57658476
0.57707721
0.57753181
INFO - Training [12][   20/  196]   Loss 2.320659   Top1 9.804688   Top5 49.785156   BatchTime 0.313290   LR 0.002433
0.57764393
0.57799119
0.57814574
0.57831436
0.57841831
0.57850623
0.57865626
0.57873136
0.57893991
0.57883656
0.57887000
0.57899475
0.57980502
0.58029068
0.58052301
0.58066714
INFO - Training [12][   40/  196]   Loss 2.321080   Top1 9.882812   Top5 49.873047   BatchTime 0.280785   LR 0.002426
0.58075118
0.58091974
0.58113545
0.58116734
0.58120131
0.58144528
0.58159852
0.58186394
0.58220059
0.58235222
0.58252043
0.58266592
0.58277380
0.58279514
0.58307695
0.58321005
0.58336055
0.58332688
0.58349353
0.58352679
0.58338726
0.58336234
0.58334595
0.58340859
INFO - Training [12][   60/  196]   Loss 2.320868   Top1 9.928385   Top5 50.286458   BatchTime 0.270260   LR 0.002419
0.58334500
0.58322966
0.58323938
0.58341175
0.58334464
0.58328396
0.58336687
0.58331949
0.58295554
0.58312452
0.58318728
0.58311033
0.58317548
0.58327687
0.58345616
0.58330828
INFO - Training [12][   80/  196]   Loss 2.321086   Top1 9.814453   Top5 50.000000   BatchTime 0.265089   LR 0.002412
0.58370525
0.58357912
0.58365756
0.58323479
0.58291250
0.58286613
0.58292818
0.58285213
0.58287328
0.58272034
0.58264607
0.58250409
0.58246160
0.58223683
0.58228165
0.58222204
0.58230948
0.58218652
0.58187658
0.58192873
0.58188587
0.58171922
0.58161634
0.58137590
INFO - Training [12][  100/  196]   Loss 2.321078   Top1 9.968750   Top5 50.179688   BatchTime 0.263406   LR 0.002404
0.58132863
0.58129448
0.58099693
0.58073664
0.58056390
0.58011234
0.57981557
0.57963026
0.57932395
0.57901084
0.57872683
0.57843399
0.57807469
0.57763559
0.57720703
0.57738656
INFO - Training [12][  120/  196]   Loss 2.321136   Top1 10.058594   Top5 50.042318   BatchTime 0.261564   LR 0.002396
0.57752430
0.57767218
0.57778436
0.57771653
0.57761908
0.57717311
0.57655740
0.57579023
0.57489085
0.57419199
0.57313436
0.57187092
0.56942034
0.56595099
0.56242257
0.56161791
0.56098837
0.56045109
nan
nan
nan
nan
nan
nan
INFO - Training [12][  140/  196]   Loss nan   Top1 10.041853   Top5 49.944196   BatchTime 0.259862   LR 0.002388
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [12][  160/  196]   Loss nan   Top1 10.085449   Top5 49.975586   BatchTime 0.258833   LR 0.002380
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [12][  180/  196]   Loss nan   Top1 10.071615   Top5 49.852431   BatchTime 0.256222   LR 0.002371
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.038    Top5: 49.842    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 2.350814   Top1 9.882812   Top5 49.785156   BatchTime 0.113033
INFO - Validation [12][   40/   40]   Loss 2.349360   Top1 10.000000   Top5 50.000000   BatchTime 0.082378
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.349
INFO - ==> Sparsity : 0.609
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(0.0706)
features.8.conv.3 tensor(0.0466)
features.8.conv.6 tensor(0.6368)
features.9.conv.0 tensor(0.0948)
features.9.conv.3 tensor(0.0608)
features.9.conv.6 tensor(0.9101)
features.10.conv.0 tensor(0.4880)
features.10.conv.3 tensor(0.0987)
features.10.conv.6 tensor(0.7770)
features.11.conv.0 tensor(0.8800)
features.11.conv.3 tensor(0.1468)
features.11.conv.6 tensor(0.9628)
features.12.conv.0 tensor(0.8583)
features.12.conv.3 tensor(0.2126)
features.12.conv.6 tensor(0.1783)
features.13.conv.0 tensor(0.7452)
features.13.conv.3 tensor(0.1310)
features.13.conv.6 tensor(0.0687)
features.14.conv.0 tensor(0.1687)
features.14.conv.3 tensor(0.1071)
features.14.conv.6 tensor(0.0201)
features.15.conv.0 tensor(0.8114)
features.15.conv.3 tensor(0.0753)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.3265)
features.16.conv.3 tensor(0.0757)
features.16.conv.6 tensor(0.9347)
conv.0 tensor(0.8987)
tensor(1332182.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [13][   20/  196]   Loss nan   Top1 9.960938   Top5 50.390625   BatchTime 0.315049   LR 0.002355
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [13][   40/  196]   Loss nan   Top1 9.941406   Top5 49.570312   BatchTime 0.293236   LR 0.002345
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [13][   60/  196]   Loss nan   Top1 10.130208   Top5 49.524740   BatchTime 0.280347   LR 0.002336
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [13][   80/  196]   Loss nan   Top1 9.990234   Top5 49.570312   BatchTime 0.272945   LR 0.002325
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [13][  100/  196]   Loss nan   Top1 9.988281   Top5 49.535156   BatchTime 0.268212   LR 0.002315
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [13][  120/  196]   Loss nan   Top1 9.921875   Top5 49.567057   BatchTime 0.264685   LR 0.002304
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [13][  140/  196]   Loss nan   Top1 9.952567   Top5 49.536830   BatchTime 0.262517   LR 0.002293
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [13][  160/  196]   Loss nan   Top1 9.938965   Top5 49.599609   BatchTime 0.261357   LR 0.002282
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [13][  180/  196]   Loss nan   Top1 9.954427   Top5 49.594184   BatchTime 0.258777   LR 0.002271
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.998    Top5: 49.784    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [13][   20/   40]   Loss 2.347446   Top1 9.882812   Top5 49.785156   BatchTime 0.116962
INFO - Validation [13][   40/   40]   Loss 2.346011   Top1 10.000000   Top5 50.000000   BatchTime 0.086119
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.346
INFO - ==> Sparsity : 0.634
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(0.0560)
features.8.conv.3 tensor(0.0440)
features.8.conv.6 tensor(0.6400)
features.9.conv.0 tensor(0.0946)
features.9.conv.3 tensor(0.0616)
features.9.conv.6 tensor(0.9128)
features.10.conv.0 tensor(0.2751)
features.10.conv.3 tensor(0.0836)
features.10.conv.6 tensor(0.5668)
features.11.conv.0 tensor(0.8780)
features.11.conv.3 tensor(0.1454)
features.11.conv.6 tensor(0.9662)
features.12.conv.0 tensor(0.8636)
features.12.conv.3 tensor(0.2118)
features.12.conv.6 tensor(0.1782)
features.13.conv.0 tensor(0.7548)
features.13.conv.3 tensor(0.1329)
features.13.conv.6 tensor(0.0710)
features.14.conv.0 tensor(0.1678)
features.14.conv.3 tensor(0.1063)
features.14.conv.6 tensor(0.0204)
features.15.conv.0 tensor(0.8266)
features.15.conv.3 tensor(0.0737)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.7495)
features.16.conv.3 tensor(0.0688)
features.16.conv.6 tensor(0.9374)
conv.0 tensor(0.8975)
tensor(1387535.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [14][   20/  196]   Loss nan   Top1 9.531250   Top5 50.429688   BatchTime 0.327093   LR 0.002250
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [14][   40/  196]   Loss nan   Top1 9.804688   Top5 50.341797   BatchTime 0.291065   LR 0.002238
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [14][   60/  196]   Loss nan   Top1 9.791667   Top5 50.045573   BatchTime 0.278210   LR 0.002225
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [14][   80/  196]   Loss nan   Top1 9.858398   Top5 50.048828   BatchTime 0.272559   LR 0.002213
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [14][  100/  196]   Loss nan   Top1 9.843750   Top5 50.101562   BatchTime 0.267974   LR 0.002200
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [14][  120/  196]   Loss nan   Top1 9.967448   Top5 50.263672   BatchTime 0.264993   LR 0.002186
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [14][  140/  196]   Loss nan   Top1 9.972098   Top5 50.245536   BatchTime 0.262721   LR 0.002173
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [14][  160/  196]   Loss nan   Top1 9.992676   Top5 50.090332   BatchTime 0.261066   LR 0.002159
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [14][  180/  196]   Loss nan   Top1 9.939236   Top5 50.082465   BatchTime 0.260118   LR 0.002145
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.972    Top5: 50.078    Loss: nan
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [14][   20/   40]   Loss 2.346487   Top1 9.882812   Top5 49.785156   BatchTime 0.124505
INFO - Validation [14][   40/   40]   Loss 2.345050   Top1 10.000000   Top5 50.000000   BatchTime 0.090011
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.345
INFO - ==> Sparsity : 0.619
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0443)
features.8.conv.6 tensor(0.6420)
features.9.conv.0 tensor(0.0931)
features.9.conv.3 tensor(0.0605)
features.9.conv.6 tensor(0.9146)
features.10.conv.0 tensor(0.3272)
features.10.conv.3 tensor(0.0845)
features.10.conv.6 tensor(0.2690)
features.11.conv.0 tensor(0.8569)
features.11.conv.3 tensor(0.1458)
features.11.conv.6 tensor(0.9710)
features.12.conv.0 tensor(0.8472)
features.12.conv.3 tensor(0.2070)
features.12.conv.6 tensor(0.1785)
features.13.conv.0 tensor(0.7296)
features.13.conv.3 tensor(0.1289)
features.13.conv.6 tensor(0.0715)
features.14.conv.0 tensor(0.1690)
features.14.conv.3 tensor(0.1061)
features.14.conv.6 tensor(0.0199)
features.15.conv.0 tensor(0.8382)
features.15.conv.3 tensor(0.0749)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.4372)
features.16.conv.3 tensor(0.0478)
features.16.conv.6 tensor(0.9360)
conv.0 tensor(0.9064)
tensor(1354849.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [15][   20/  196]   Loss nan   Top1 9.726562   Top5 50.449219   BatchTime 0.322186   LR 0.002120
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [15][   40/  196]   Loss nan   Top1 9.423828   Top5 50.224609   BatchTime 0.288993   LR 0.002106
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [15][   60/  196]   Loss nan   Top1 9.791667   Top5 49.980469   BatchTime 0.274437   LR 0.002091
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [15][   80/  196]   Loss nan   Top1 9.682617   Top5 49.907227   BatchTime 0.269514   LR 0.002076
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [15][  100/  196]   Loss nan   Top1 9.769531   Top5 49.722656   BatchTime 0.265661   LR 0.002061
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [15][  120/  196]   Loss nan   Top1 9.882812   Top5 49.694010   BatchTime 0.262994   LR 0.002045
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [15][  140/  196]   Loss nan   Top1 9.891183   Top5 49.589844   BatchTime 0.261165   LR 0.002030
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [15][  160/  196]   Loss nan   Top1 9.892578   Top5 49.536133   BatchTime 0.259229   LR 0.002014
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [15][  180/  196]   Loss nan   Top1 9.861111   Top5 49.602865   BatchTime 0.257306   LR 0.001998
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.886    Top5: 49.558    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [15][   20/   40]   Loss 2.343832   Top1 9.882812   Top5 49.785156   BatchTime 0.116628
INFO - Validation [15][   40/   40]   Loss 2.342511   Top1 10.000000   Top5 50.000000   BatchTime 0.085652
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.343
INFO - ==> Sparsity : 0.622
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0440)
features.8.conv.6 tensor(0.6439)
features.9.conv.0 tensor(0.0944)
features.9.conv.3 tensor(0.0605)
features.9.conv.6 tensor(0.9206)
features.10.conv.0 tensor(0.3243)
features.10.conv.3 tensor(0.0836)
features.10.conv.6 tensor(0.2383)
features.11.conv.0 tensor(0.8521)
features.11.conv.3 tensor(0.1441)
features.11.conv.6 tensor(0.9726)
features.12.conv.0 tensor(0.8444)
features.12.conv.3 tensor(0.2085)
features.12.conv.6 tensor(0.1826)
features.13.conv.0 tensor(0.7210)
features.13.conv.3 tensor(0.1337)
features.13.conv.6 tensor(0.0717)
features.14.conv.0 tensor(0.1681)
features.14.conv.3 tensor(0.1053)
features.14.conv.6 tensor(0.0202)
features.15.conv.0 tensor(0.8459)
features.15.conv.3 tensor(0.0731)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.4625)
features.16.conv.3 tensor(0.0462)
features.16.conv.6 tensor(0.9411)
conv.0 tensor(0.9094)
tensor(1361073.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [16][   20/  196]   Loss nan   Top1 9.765625   Top5 49.960938   BatchTime 0.332871   LR 0.001969
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [16][   40/  196]   Loss nan   Top1 9.921875   Top5 49.580078   BatchTime 0.291767   LR 0.001953
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [16][   60/  196]   Loss nan   Top1 9.882812   Top5 49.615885   BatchTime 0.280113   LR 0.001936
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [16][   80/  196]   Loss nan   Top1 9.794922   Top5 49.589844   BatchTime 0.272240   LR 0.001919
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [16][  100/  196]   Loss nan   Top1 9.925781   Top5 49.546875   BatchTime 0.266844   LR 0.001902
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [16][  120/  196]   Loss nan   Top1 9.856771   Top5 49.583333   BatchTime 0.264454   LR 0.001885
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [16][  140/  196]   Loss nan   Top1 9.840960   Top5 49.430804   BatchTime 0.262032   LR 0.001867
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [16][  160/  196]   Loss nan   Top1 9.777832   Top5 49.270020   BatchTime 0.260779   LR 0.001850
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [16][  180/  196]   Loss nan   Top1 9.815538   Top5 49.296875   BatchTime 0.259484   LR 0.001832
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.814    Top5: 49.244    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [16][   20/   40]   Loss 2.332541   Top1 9.882812   Top5 49.785156   BatchTime 0.113423
INFO - Validation [16][   40/   40]   Loss 2.331517   Top1 10.000000   Top5 50.000000   BatchTime 0.083093
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.332
INFO - ==> Sparsity : 0.625
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0440)
features.8.conv.6 tensor(0.6455)
features.9.conv.0 tensor(0.0951)
features.9.conv.3 tensor(0.0613)
features.9.conv.6 tensor(0.9257)
features.10.conv.0 tensor(0.3199)
features.10.conv.3 tensor(0.0830)
features.10.conv.6 tensor(0.2180)
features.11.conv.0 tensor(0.8448)
features.11.conv.3 tensor(0.1431)
features.11.conv.6 tensor(0.9755)
features.12.conv.0 tensor(0.8379)
features.12.conv.3 tensor(0.2052)
features.12.conv.6 tensor(0.1808)
features.13.conv.0 tensor(0.7098)
features.13.conv.3 tensor(0.1321)
features.13.conv.6 tensor(0.0720)
features.14.conv.0 tensor(0.1678)
features.14.conv.3 tensor(0.1061)
features.14.conv.6 tensor(0.0202)
features.15.conv.0 tensor(0.8536)
features.15.conv.3 tensor(0.0736)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.4812)
features.16.conv.3 tensor(0.0462)
features.16.conv.6 tensor(0.9487)
conv.0 tensor(0.9171)
tensor(1368597.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [17][   20/  196]   Loss nan   Top1 10.683594   Top5 50.039062   BatchTime 0.322243   LR 0.001800
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [17][   40/  196]   Loss nan   Top1 10.341797   Top5 49.785156   BatchTime 0.294563   LR 0.001782
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [17][   60/  196]   Loss nan   Top1 10.208333   Top5 49.596354   BatchTime 0.282672   LR 0.001764
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [17][   80/  196]   Loss nan   Top1 10.205078   Top5 49.658203   BatchTime 0.274241   LR 0.001746
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [17][  100/  196]   Loss nan   Top1 10.199219   Top5 49.398438   BatchTime 0.269539   LR 0.001727
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [17][  120/  196]   Loss nan   Top1 10.081380   Top5 49.492188   BatchTime 0.266095   LR 0.001708
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [17][  140/  196]   Loss nan   Top1 10.097656   Top5 49.575893   BatchTime 0.263905   LR 0.001690
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [17][  160/  196]   Loss nan   Top1 10.153809   Top5 49.519043   BatchTime 0.261975   LR 0.001671
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [17][  180/  196]   Loss nan   Top1 10.099826   Top5 49.635417   BatchTime 0.261316   LR 0.001652
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.164    Top5: 49.674    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [17][   20/   40]   Loss 2.306973   Top1 9.882812   Top5 49.804688   BatchTime 0.115444
INFO - Validation [17][   40/   40]   Loss 2.306331   Top1 10.000000   Top5 50.000000   BatchTime 0.085444
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.306
INFO - ==> Sparsity : 0.623
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0440)
features.8.conv.6 tensor(0.6472)
features.9.conv.0 tensor(0.0958)
features.9.conv.3 tensor(0.0616)
features.9.conv.6 tensor(0.9270)
features.10.conv.0 tensor(0.3144)
features.10.conv.3 tensor(0.0828)
features.10.conv.6 tensor(0.1603)
features.11.conv.0 tensor(0.8001)
features.11.conv.3 tensor(0.1433)
features.11.conv.6 tensor(0.9778)
features.12.conv.0 tensor(0.8026)
features.12.conv.3 tensor(0.2043)
features.12.conv.6 tensor(0.1774)
features.13.conv.0 tensor(0.6688)
features.13.conv.3 tensor(0.1335)
features.13.conv.6 tensor(0.0714)
features.14.conv.0 tensor(0.1680)
features.14.conv.3 tensor(0.1056)
features.14.conv.6 tensor(0.0201)
features.15.conv.0 tensor(0.8592)
features.15.conv.3 tensor(0.0740)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.4945)
features.16.conv.3 tensor(0.0454)
features.16.conv.6 tensor(0.9499)
conv.0 tensor(0.9184)
tensor(1363443.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [18][   20/  196]   Loss nan   Top1 10.410156   Top5 50.332031   BatchTime 0.292430   LR 0.001618
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [18][   40/  196]   Loss nan   Top1 10.175781   Top5 49.853516   BatchTime 0.265595   LR 0.001599
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [18][   60/  196]   Loss nan   Top1 10.156250   Top5 50.156250   BatchTime 0.259369   LR 0.001579
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [18][   80/  196]   Loss nan   Top1 10.092773   Top5 50.209961   BatchTime 0.250144   LR 0.001560
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [18][  100/  196]   Loss nan   Top1 10.085938   Top5 50.300781   BatchTime 0.246824   LR 0.001540
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [18][  120/  196]   Loss nan   Top1 9.977214   Top5 50.247396   BatchTime 0.247841   LR 0.001521
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [18][  140/  196]   Loss nan   Top1 9.980469   Top5 50.217634   BatchTime 0.246303   LR 0.001501
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [18][  160/  196]   Loss nan   Top1 9.931641   Top5 50.117188   BatchTime 0.246662   LR 0.001482
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [18][  180/  196]   Loss nan   Top1 9.963108   Top5 50.028212   BatchTime 0.245641   LR 0.001462
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.962    Top5: 50.070    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [18][   20/   40]   Loss 2.311844   Top1 9.882812   Top5 49.882812   BatchTime 0.116539
INFO - Validation [18][   40/   40]   Loss 2.311126   Top1 10.000000   Top5 50.000000   BatchTime 0.086128
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.311
INFO - ==> Sparsity : 0.626
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0434)
features.8.conv.6 tensor(0.6488)
features.9.conv.0 tensor(0.0961)
features.9.conv.3 tensor(0.0613)
features.9.conv.6 tensor(0.9271)
features.10.conv.0 tensor(0.3062)
features.10.conv.3 tensor(0.0819)
features.10.conv.6 tensor(0.1735)
features.11.conv.0 tensor(0.8264)
features.11.conv.3 tensor(0.1416)
features.11.conv.6 tensor(0.9781)
features.12.conv.0 tensor(0.8170)
features.12.conv.3 tensor(0.2058)
features.12.conv.6 tensor(0.1762)
features.13.conv.0 tensor(0.6944)
features.13.conv.3 tensor(0.1308)
features.13.conv.6 tensor(0.0712)
features.14.conv.0 tensor(0.1681)
features.14.conv.3 tensor(0.1065)
features.14.conv.6 tensor(0.0202)
features.15.conv.0 tensor(0.8611)
features.15.conv.3 tensor(0.0718)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5068)
features.16.conv.3 tensor(0.0437)
features.16.conv.6 tensor(0.9487)
conv.0 tensor(0.9193)
tensor(1369528.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [19][   20/  196]   Loss nan   Top1 10.390625   Top5 50.488281   BatchTime 0.321363   LR 0.001427
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [19][   40/  196]   Loss nan   Top1 10.107422   Top5 49.697266   BatchTime 0.285133   LR 0.001407
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [19][   60/  196]   Loss nan   Top1 10.286458   Top5 49.791667   BatchTime 0.273409   LR 0.001387
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [19][   80/  196]   Loss nan   Top1 10.151367   Top5 49.741211   BatchTime 0.267424   LR 0.001367
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [19][  100/  196]   Loss nan   Top1 9.976562   Top5 49.273438   BatchTime 0.264763   LR 0.001347
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [19][  120/  196]   Loss nan   Top1 10.019531   Top5 49.449870   BatchTime 0.262185   LR 0.001327
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [19][  140/  196]   Loss nan   Top1 9.960938   Top5 49.511719   BatchTime 0.260067   LR 0.001307
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [19][  160/  196]   Loss nan   Top1 9.936523   Top5 49.638672   BatchTime 0.259002   LR 0.001287
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [19][  180/  196]   Loss nan   Top1 9.911024   Top5 49.633247   BatchTime 0.257638   LR 0.001266
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.868    Top5: 49.750    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [19][   20/   40]   Loss 2.320097   Top1 9.882812   Top5 49.785156   BatchTime 0.118027
INFO - Validation [19][   40/   40]   Loss 2.319094   Top1 10.000000   Top5 50.000000   BatchTime 0.085095
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.319
INFO - ==> Sparsity : 0.630
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  20
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0437)
features.8.conv.6 tensor(0.6501)
features.9.conv.0 tensor(0.0970)
features.9.conv.3 tensor(0.0611)
features.9.conv.6 tensor(0.9277)
features.10.conv.0 tensor(0.2985)
features.10.conv.3 tensor(0.0810)
features.10.conv.6 tensor(0.1744)
features.11.conv.0 tensor(0.8251)
features.11.conv.3 tensor(0.1418)
features.11.conv.6 tensor(0.9794)
features.12.conv.0 tensor(0.8187)
features.12.conv.3 tensor(0.2002)
features.12.conv.6 tensor(0.1742)
features.13.conv.0 tensor(0.6910)
features.13.conv.3 tensor(0.1304)
features.13.conv.6 tensor(0.0716)
features.14.conv.0 tensor(0.1677)
features.14.conv.3 tensor(0.1064)
features.14.conv.6 tensor(0.0219)
features.15.conv.0 tensor(0.8670)
features.15.conv.3 tensor(0.0712)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5209)
features.16.conv.3 tensor(0.0436)
features.16.conv.6 tensor(0.9564)
conv.0 tensor(0.9291)
tensor(1378846.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [20][   20/  196]   Loss nan   Top1 9.570312   Top5 50.097656   BatchTime 0.312299   LR 0.001231
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [20][   40/  196]   Loss nan   Top1 10.048828   Top5 49.511719   BatchTime 0.283863   LR 0.001211
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [20][   60/  196]   Loss nan   Top1 10.019531   Top5 49.433594   BatchTime 0.272773   LR 0.001191
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [20][   80/  196]   Loss nan   Top1 10.068359   Top5 49.296875   BatchTime 0.267377   LR 0.001171
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [20][  100/  196]   Loss nan   Top1 9.929688   Top5 49.398438   BatchTime 0.263652   LR 0.001151
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [20][  120/  196]   Loss nan   Top1 9.882812   Top5 49.423828   BatchTime 0.261331   LR 0.001131
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [20][  140/  196]   Loss nan   Top1 9.893973   Top5 49.447545   BatchTime 0.259631   LR 0.001111
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [20][  160/  196]   Loss nan   Top1 9.841309   Top5 49.494629   BatchTime 0.260160   LR 0.001091
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [20][  180/  196]   Loss nan   Top1 9.822049   Top5 49.578993   BatchTime 0.259646   LR 0.001071
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.836    Top5: 49.616    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [20][   20/   40]   Loss 2.303959   Top1 9.882812   Top5 50.019531   BatchTime 0.117863
INFO - Validation [20][   40/   40]   Loss 2.303690   Top1 10.000000   Top5 50.000000   BatchTime 0.086442
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0440)
features.8.conv.6 tensor(0.6516)
features.9.conv.0 tensor(0.0973)
features.9.conv.3 tensor(0.0611)
features.9.conv.6 tensor(0.9285)
features.10.conv.0 tensor(0.2930)
features.10.conv.3 tensor(0.0799)
features.10.conv.6 tensor(0.1502)
features.11.conv.0 tensor(0.7830)
features.11.conv.3 tensor(0.1389)
features.11.conv.6 tensor(0.9787)
features.12.conv.0 tensor(0.7843)
features.12.conv.3 tensor(0.2010)
features.12.conv.6 tensor(0.1736)
features.13.conv.0 tensor(0.6485)
features.13.conv.3 tensor(0.1304)
features.13.conv.6 tensor(0.0714)
features.14.conv.0 tensor(0.1686)
features.14.conv.3 tensor(0.1067)
features.14.conv.6 tensor(0.0217)
features.15.conv.0 tensor(0.8693)
features.15.conv.3 tensor(0.0718)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5321)
features.16.conv.3 tensor(0.0411)
features.16.conv.6 tensor(0.9546)
conv.0 tensor(0.9289)
tensor(1372757.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.304
INFO - ==> Sparsity : 0.627
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [21][   20/  196]   Loss nan   Top1 10.371094   Top5 50.605469   BatchTime 0.307571   LR 0.001036
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [21][   40/  196]   Loss nan   Top1 10.166016   Top5 50.234375   BatchTime 0.277477   LR 0.001016
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [21][   60/  196]   Loss nan   Top1 10.045573   Top5 50.136719   BatchTime 0.268639   LR 0.000996
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [21][   80/  196]   Loss nan   Top1 10.092773   Top5 50.209961   BatchTime 0.264367   LR 0.000976
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [21][  100/  196]   Loss nan   Top1 10.054688   Top5 50.261719   BatchTime 0.260689   LR 0.000957
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [21][  120/  196]   Loss nan   Top1 10.058594   Top5 50.104167   BatchTime 0.261408   LR 0.000937
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [21][  140/  196]   Loss nan   Top1 10.027902   Top5 49.983259   BatchTime 0.259588   LR 0.000918
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [21][  160/  196]   Loss nan   Top1 10.061035   Top5 50.031738   BatchTime 0.258224   LR 0.000899
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [21][  180/  196]   Loss nan   Top1 10.023872   Top5 49.947917   BatchTime 0.258834   LR 0.000879
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.088    Top5: 49.980    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 2.307700   Top1 9.882812   Top5 49.882812   BatchTime 0.115536
INFO - Validation [21][   40/   40]   Loss 2.307280   Top1 10.000000   Top5 50.000000   BatchTime 0.085006
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.307
INFO - ==> Sparsity : 0.629
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0440)
features.8.conv.6 tensor(0.6526)
features.9.conv.0 tensor(0.0977)
features.9.conv.3 tensor(0.0613)
features.9.conv.6 tensor(0.9291)
features.10.conv.0 tensor(0.2882)
features.10.conv.3 tensor(0.0804)
features.10.conv.6 tensor(0.1417)
features.11.conv.0 tensor(0.7564)
features.11.conv.3 tensor(0.1395)
features.11.conv.6 tensor(0.9782)
features.12.conv.0 tensor(0.7697)
features.12.conv.3 tensor(0.1993)
features.12.conv.6 tensor(0.1738)
features.13.conv.0 tensor(0.6292)
features.13.conv.3 tensor(0.1325)
features.13.conv.6 tensor(0.0709)
features.14.conv.0 tensor(0.1684)
features.14.conv.3 tensor(0.1059)
features.14.conv.6 tensor(0.0229)
features.15.conv.0 tensor(0.8734)
features.15.conv.3 tensor(0.0721)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5422)
features.16.conv.3 tensor(0.0412)
features.16.conv.6 tensor(0.9587)
conv.0 tensor(0.9367)
tensor(1375737.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [22][   20/  196]   Loss nan   Top1 9.570312   Top5 50.371094   BatchTime 0.317234   LR 0.000846
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [22][   40/  196]   Loss nan   Top1 9.628906   Top5 51.230469   BatchTime 0.280759   LR 0.000827
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [22][   60/  196]   Loss nan   Top1 9.726562   Top5 50.755208   BatchTime 0.267317   LR 0.000808
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [22][   80/  196]   Loss nan   Top1 9.804688   Top5 50.732422   BatchTime 0.256294   LR 0.000789
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [22][  100/  196]   Loss nan   Top1 9.761719   Top5 50.640625   BatchTime 0.255041   LR 0.000770
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [22][  120/  196]   Loss nan   Top1 9.716797   Top5 50.338542   BatchTime 0.254081   LR 0.000752
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [22][  140/  196]   Loss nan   Top1 9.679129   Top5 50.276228   BatchTime 0.253530   LR 0.000734
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [22][  160/  196]   Loss nan   Top1 9.702148   Top5 50.100098   BatchTime 0.253021   LR 0.000715
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [22][  180/  196]   Loss nan   Top1 9.752604   Top5 49.980469   BatchTime 0.252257   LR 0.000697
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.750    Top5: 49.908    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [22][   20/   40]   Loss 2.306795   Top1 9.882812   Top5 49.765625   BatchTime 0.112528
INFO - Validation [22][   40/   40]   Loss 2.306219   Top1 10.000000   Top5 50.000000   BatchTime 0.082931
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.306
INFO - ==> Sparsity : 0.631
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0434)
features.8.conv.6 tensor(0.6538)
features.9.conv.0 tensor(0.0979)
features.9.conv.3 tensor(0.0608)
features.9.conv.6 tensor(0.9296)
features.10.conv.0 tensor(0.2824)
features.10.conv.3 tensor(0.0793)
features.10.conv.6 tensor(0.1484)
features.11.conv.0 tensor(0.7907)
features.11.conv.3 tensor(0.1381)
features.11.conv.6 tensor(0.9808)
features.12.conv.0 tensor(0.7898)
features.12.conv.3 tensor(0.1997)
features.12.conv.6 tensor(0.1766)
features.13.conv.0 tensor(0.6596)
features.13.conv.3 tensor(0.1331)
features.13.conv.6 tensor(0.0709)
features.14.conv.0 tensor(0.1685)
features.14.conv.3 tensor(0.1065)
features.14.conv.6 tensor(0.0253)
features.15.conv.0 tensor(0.8765)
features.15.conv.3 tensor(0.0703)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5481)
features.16.conv.3 tensor(0.0404)
features.16.conv.6 tensor(0.9601)
conv.0 tensor(0.9335)
tensor(1381794.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [23][   20/  196]   Loss nan   Top1 9.921875   Top5 49.609375   BatchTime 0.292106   LR 0.000666
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [23][   40/  196]   Loss nan   Top1 9.912109   Top5 49.453125   BatchTime 0.274181   LR 0.000648
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [23][   60/  196]   Loss nan   Top1 9.934896   Top5 49.127604   BatchTime 0.265792   LR 0.000630
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [23][   80/  196]   Loss nan   Top1 9.965820   Top5 49.155273   BatchTime 0.261656   LR 0.000613
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [23][  100/  196]   Loss nan   Top1 10.058594   Top5 49.355469   BatchTime 0.259205   LR 0.000596
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [23][  120/  196]   Loss nan   Top1 9.954427   Top5 49.498698   BatchTime 0.257648   LR 0.000579
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [23][  140/  196]   Loss nan   Top1 9.807478   Top5 49.469866   BatchTime 0.256627   LR 0.000562
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [23][  160/  196]   Loss nan   Top1 9.877930   Top5 49.426270   BatchTime 0.255759   LR 0.000545
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [23][  180/  196]   Loss nan   Top1 9.830729   Top5 49.526910   BatchTime 0.254729   LR 0.000529
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.810    Top5: 49.530    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [23][   20/   40]   Loss 2.306856   Top1 9.882812   Top5 50.039062   BatchTime 0.117562
INFO - Validation [23][   40/   40]   Loss 2.306343   Top1 10.000000   Top5 50.000000   BatchTime 0.086294
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.306
INFO - ==> Sparsity : 0.631
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0440)
features.8.conv.6 tensor(0.6549)
features.9.conv.0 tensor(0.0975)
features.9.conv.3 tensor(0.0608)
features.9.conv.6 tensor(0.9298)
features.10.conv.0 tensor(0.2770)
features.10.conv.3 tensor(0.0781)
features.10.conv.6 tensor(0.1458)
features.11.conv.0 tensor(0.7760)
features.11.conv.3 tensor(0.1393)
features.11.conv.6 tensor(0.9806)
features.12.conv.0 tensor(0.7771)
features.12.conv.3 tensor(0.1995)
features.12.conv.6 tensor(0.1814)
features.13.conv.0 tensor(0.6436)
features.13.conv.3 tensor(0.1337)
features.13.conv.6 tensor(0.0707)
features.14.conv.0 tensor(0.1678)
features.14.conv.3 tensor(0.1059)
features.14.conv.6 tensor(0.0281)
features.15.conv.0 tensor(0.8770)
features.15.conv.3 tensor(0.0701)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5529)
features.16.conv.3 tensor(0.0403)
features.16.conv.6 tensor(0.9628)
conv.0 tensor(0.9357)
tensor(1382266.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [24][   20/  196]   Loss nan   Top1 9.824219   Top5 50.234375   BatchTime 0.298753   LR 0.000500
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [24][   40/  196]   Loss nan   Top1 10.087891   Top5 50.498047   BatchTime 0.271322   LR 0.000484
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [24][   60/  196]   Loss nan   Top1 10.130208   Top5 50.774740   BatchTime 0.259247   LR 0.000468
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [24][   80/  196]   Loss nan   Top1 10.126953   Top5 50.341797   BatchTime 0.256649   LR 0.000453
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [24][  100/  196]   Loss nan   Top1 10.097656   Top5 50.265625   BatchTime 0.255159   LR 0.000437
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [24][  120/  196]   Loss nan   Top1 9.964193   Top5 50.009766   BatchTime 0.254140   LR 0.000422
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [24][  140/  196]   Loss nan   Top1 9.969308   Top5 49.938616   BatchTime 0.253573   LR 0.000407
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [24][  160/  196]   Loss nan   Top1 9.958496   Top5 49.938965   BatchTime 0.253075   LR 0.000392
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [24][  180/  196]   Loss nan   Top1 9.950087   Top5 49.950087   BatchTime 0.251357   LR 0.000378
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.012    Top5: 49.910    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [24][   20/   40]   Loss 2.313929   Top1 9.882812   Top5 50.039062   BatchTime 0.114245
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0431)
features.8.conv.6 tensor(0.6555)
features.9.conv.0 tensor(0.0979)
features.9.conv.3 tensor(0.0608)
features.9.conv.6 tensor(0.9305)
features.10.conv.0 tensor(0.2710)
features.10.conv.3 tensor(0.0778)
features.10.conv.6 tensor(0.1437)
features.11.conv.0 tensor(0.7716)
features.11.conv.3 tensor(0.1395)
features.11.conv.6 tensor(0.9806)
features.12.conv.0 tensor(0.7706)
features.12.conv.3 tensor(0.1997)
features.12.conv.6 tensor(0.1814)
INFO - Validation [24][   40/   40]   Loss 2.313251   Top1 10.000000   Top5 50.000000   BatchTime 0.085077
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.313
INFO - ==> Sparsity : 0.632
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
features.13.conv.0 tensor(0.6396)
features.13.conv.3 tensor(0.1329)
features.13.conv.6 tensor(0.0705)
features.14.conv.0 tensor(0.1674)
features.14.conv.3 tensor(0.1056)
features.14.conv.6 tensor(0.0338)
features.15.conv.0 tensor(0.8767)
features.15.conv.3 tensor(0.0698)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5561)
features.16.conv.3 tensor(0.0400)
features.16.conv.6 tensor(0.9651)
conv.0 tensor(0.9383)
tensor(1384232.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [25][   20/  196]   Loss nan   Top1 9.843750   Top5 50.000000   BatchTime 0.316287   LR 0.000353
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [25][   40/  196]   Loss nan   Top1 9.960938   Top5 49.804688   BatchTime 0.278776   LR 0.000339
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [25][   60/  196]   Loss nan   Top1 10.039062   Top5 49.889323   BatchTime 0.269100   LR 0.000325
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [25][   80/  196]   Loss nan   Top1 9.980469   Top5 49.912109   BatchTime 0.267483   LR 0.000312
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [25][  100/  196]   Loss nan   Top1 10.015625   Top5 49.933594   BatchTime 0.263229   LR 0.000299
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [25][  120/  196]   Loss nan   Top1 10.058594   Top5 49.895833   BatchTime 0.260096   LR 0.000286
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [25][  140/  196]   Loss nan   Top1 9.991629   Top5 49.743304   BatchTime 0.257641   LR 0.000273
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [25][  160/  196]   Loss nan   Top1 9.946289   Top5 49.743652   BatchTime 0.256288   LR 0.000261
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [25][  180/  196]   Loss nan   Top1 9.989149   Top5 49.743924   BatchTime 0.254390   LR 0.000248
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.988    Top5: 49.732    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [25][   20/   40]   Loss 2.304977   Top1 9.882812   Top5 50.039062   BatchTime 0.114415
INFO - Validation [25][   40/   40]   Loss 2.304803   Top1 10.000000   Top5 50.000000   BatchTime 0.084921
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305
INFO - ==> Sparsity : 0.632
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0440)
features.8.conv.6 tensor(0.6565)
features.9.conv.0 tensor(0.0983)
features.9.conv.3 tensor(0.0608)
features.9.conv.6 tensor(0.9310)
features.10.conv.0 tensor(0.2688)
features.10.conv.3 tensor(0.0784)
features.10.conv.6 tensor(0.1399)
features.11.conv.0 tensor(0.7429)
features.11.conv.3 tensor(0.1395)
features.11.conv.6 tensor(0.9809)
features.12.conv.0 tensor(0.7492)
features.12.conv.3 tensor(0.1993)
features.12.conv.6 tensor(0.1847)
features.13.conv.0 tensor(0.6195)
features.13.conv.3 tensor(0.1339)
features.13.conv.6 tensor(0.0706)
features.14.conv.0 tensor(0.1678)
features.14.conv.3 tensor(0.1053)
features.14.conv.6 tensor(0.0419)
features.15.conv.0 tensor(0.8767)
features.15.conv.3 tensor(0.0693)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5577)
features.16.conv.3 tensor(0.0395)
features.16.conv.6 tensor(0.9660)
conv.0 tensor(0.9404)
tensor(1383096.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [26][   20/  196]   Loss nan   Top1 9.492188   Top5 49.179688   BatchTime 0.325590   LR 0.000228
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [26][   40/  196]   Loss nan   Top1 9.228516   Top5 48.847656   BatchTime 0.288602   LR 0.000216
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [26][   60/  196]   Loss nan   Top1 9.472656   Top5 48.997396   BatchTime 0.274994   LR 0.000205
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [26][   80/  196]   Loss nan   Top1 9.599609   Top5 49.267578   BatchTime 0.269315   LR 0.000194
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [26][  100/  196]   Loss nan   Top1 9.636719   Top5 49.312500   BatchTime 0.264997   LR 0.000183
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [26][  120/  196]   Loss nan   Top1 9.739583   Top5 49.335938   BatchTime 0.263335   LR 0.000173
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [26][  140/  196]   Loss nan   Top1 9.796317   Top5 49.416853   BatchTime 0.261584   LR 0.000163
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [26][  160/  196]   Loss nan   Top1 9.877930   Top5 49.729004   BatchTime 0.259964   LR 0.000153
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [26][  180/  196]   Loss nan   Top1 9.832899   Top5 49.796007   BatchTime 0.257502   LR 0.000144
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.826    Top5: 49.792    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [26][   20/   40]   Loss 2.305283   Top1 9.882812   Top5 50.039062   BatchTime 0.115489
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0434)
features.8.conv.6 tensor(0.6569)
features.9.conv.0 tensor(0.0984)
features.9.conv.3 tensor(0.0605)
features.9.conv.6 tensor(0.9306)
features.10.conv.0 tensor(0.2668)
features.10.conv.3 tensor(0.0781)
features.10.conv.6 tensor(0.1373)
features.11.conv.0 tensor(0.7235)
features.11.conv.3 tensor(0.1375)
features.11.conv.6 tensor(0.9810)
features.12.conv.0 tensor(0.7333)
features.12.conv.3 tensor(0.2002)
features.12.conv.6 tensor(0.1855)
features.13.conv.0 tensor(0.6081)
features.13.conv.3 tensor(0.1319)
features.13.conv.6 tensor(0.0710)
features.14.conv.0 tensor(0.1685)
features.14.conv.3 tensor(0.1066)
features.14.conv.6 tensor(0.0558)
features.15.conv.0 tensor(0.8781)
features.15.conv.3 tensor(0.0704)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5599)
features.16.conv.3 tensor(0.0399)
features.16.conv.6 tensor(0.9664)
conv.0 tensor(0.9415)
tensor(1383850.) 2188896.0
INFO - Validation [26][   40/   40]   Loss 2.305098   Top1 10.000000   Top5 50.000000   BatchTime 0.085232
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305
INFO - ==> Sparsity : 0.632
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [27][   20/  196]   Loss nan   Top1 10.019531   Top5 50.585938   BatchTime 0.313123   LR 0.000128
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [27][   40/  196]   Loss nan   Top1 10.283203   Top5 50.107422   BatchTime 0.282505   LR 0.000119
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [27][   60/  196]   Loss nan   Top1 10.156250   Top5 50.084635   BatchTime 0.270892   LR 0.000111
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [27][   80/  196]   Loss nan   Top1 10.058594   Top5 49.965820   BatchTime 0.265456   LR 0.000102
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [27][  100/  196]   Loss nan   Top1 10.074219   Top5 50.031250   BatchTime 0.261829   LR 0.000095
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [27][  120/  196]   Loss nan   Top1 10.139974   Top5 49.899089   BatchTime 0.260231   LR 0.000087
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [27][  140/  196]   Loss nan   Top1 10.119978   Top5 49.751674   BatchTime 0.259689   LR 0.000080
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [27][  160/  196]   Loss nan   Top1 10.085449   Top5 49.755859   BatchTime 0.258319   LR 0.000073
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [27][  180/  196]   Loss nan   Top1 10.010851   Top5 49.720052   BatchTime 0.256170   LR 0.000066
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.978    Top5: 49.706    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [27][   20/   40]   Loss 2.305041   Top1 9.882812   Top5 50.039062   BatchTime 0.114206
INFO - Validation [27][   40/   40]   Loss 2.304821   Top1 10.000000   Top5 50.000000   BatchTime 0.085501
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305
INFO - ==> Sparsity : 0.633
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0437)
features.8.conv.6 tensor(0.6567)
features.9.conv.0 tensor(0.0986)
features.9.conv.3 tensor(0.0605)
features.9.conv.6 tensor(0.9312)
features.10.conv.0 tensor(0.2655)
features.10.conv.3 tensor(0.0770)
features.10.conv.6 tensor(0.1372)
features.11.conv.0 tensor(0.7224)
features.11.conv.3 tensor(0.1368)
features.11.conv.6 tensor(0.9812)
features.12.conv.0 tensor(0.7325)
features.12.conv.3 tensor(0.1985)
features.12.conv.6 tensor(0.1852)
features.13.conv.0 tensor(0.6097)
features.13.conv.3 tensor(0.1323)
features.13.conv.6 tensor(0.0709)
features.14.conv.0 tensor(0.1686)
features.14.conv.3 tensor(0.1063)
features.14.conv.6 tensor(0.0574)
features.15.conv.0 tensor(0.8787)
features.15.conv.3 tensor(0.0700)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5612)
features.16.conv.3 tensor(0.0394)
features.16.conv.6 tensor(0.9668)
conv.0 tensor(0.9430)
tensor(1385050.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [28][   20/  196]   Loss nan   Top1 9.609375   Top5 49.433594   BatchTime 0.325457   LR 0.000055
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [28][   40/  196]   Loss nan   Top1 10.000000   Top5 50.263672   BatchTime 0.286910   LR 0.000050
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [28][   60/  196]   Loss nan   Top1 9.928385   Top5 50.423177   BatchTime 0.275793   LR 0.000044
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [28][   80/  196]   Loss nan   Top1 10.053711   Top5 50.322266   BatchTime 0.269517   LR 0.000039
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [28][  100/  196]   Loss nan   Top1 9.921875   Top5 50.160156   BatchTime 0.265360   LR 0.000034
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [28][  120/  196]   Loss nan   Top1 9.899089   Top5 50.139974   BatchTime 0.262928   LR 0.000030
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [28][  140/  196]   Loss nan   Top1 9.972098   Top5 50.234375   BatchTime 0.260305   LR 0.000026
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [28][  160/  196]   Loss nan   Top1 9.860840   Top5 50.153809   BatchTime 0.258906   LR 0.000022
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [28][  180/  196]   Loss nan   Top1 9.841580   Top5 49.997830   BatchTime 0.258049   LR 0.000018
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - ==> Top1: 9.816    Top5: 50.010    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [28][   20/   40]   Loss 2.305744   Top1 9.882812   Top5 50.039062   BatchTime 0.117200
INFO - Validation [28][   40/   40]   Loss 2.305485   Top1 10.000000   Top5 50.000000   BatchTime 0.086858
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305
INFO - ==> Sparsity : 0.633
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0443)
features.8.conv.6 tensor(0.6569)
features.9.conv.0 tensor(0.0988)
features.9.conv.3 tensor(0.0605)
features.9.conv.6 tensor(0.9311)
features.10.conv.0 tensor(0.2642)
features.10.conv.3 tensor(0.0778)
features.10.conv.6 tensor(0.1368)
features.11.conv.0 tensor(0.7199)
features.11.conv.3 tensor(0.1372)
features.11.conv.6 tensor(0.9805)
features.12.conv.0 tensor(0.7295)
features.12.conv.3 tensor(0.1995)
features.12.conv.6 tensor(0.1875)
features.13.conv.0 tensor(0.6047)
features.13.conv.3 tensor(0.1325)
features.13.conv.6 tensor(0.0706)
features.14.conv.0 tensor(0.1682)
features.14.conv.3 tensor(0.1068)
features.14.conv.6 tensor(0.0577)
features.15.conv.0 tensor(0.8783)
features.15.conv.3 tensor(0.0701)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5618)
features.16.conv.3 tensor(0.0395)
features.16.conv.6 tensor(0.9672)
conv.0 tensor(0.9432)
tensor(1384748.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [29][   20/  196]   Loss nan   Top1 10.117188   Top5 49.726562   BatchTime 0.317442   LR 0.000013
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [29][   40/  196]   Loss nan   Top1 10.185547   Top5 49.794922   BatchTime 0.285571   LR 0.000010
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [29][   60/  196]   Loss nan   Top1 9.934896   Top5 50.123698   BatchTime 0.274168   LR 0.000008
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [29][   80/  196]   Loss nan   Top1 10.000000   Top5 50.053711   BatchTime 0.267671   LR 0.000005
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [29][  100/  196]   Loss nan   Top1 9.992188   Top5 50.175781   BatchTime 0.264320   LR 0.000004
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [29][  120/  196]   Loss nan   Top1 10.130208   Top5 50.309245   BatchTime 0.261939   LR 0.000002
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [29][  140/  196]   Loss nan   Top1 10.069754   Top5 50.270647   BatchTime 0.260266   LR 0.000001
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [29][  160/  196]   Loss nan   Top1 10.019531   Top5 50.217285   BatchTime 0.258844   LR 0.000001
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [29][  180/  196]   Loss nan   Top1 9.997830   Top5 50.223524   BatchTime 0.256756   LR 0.000000
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.966    Top5: 50.250    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [29][   20/   40]   Loss 2.314708   Top1 9.882812   Top5 50.039062   BatchTime 0.115800
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0440)
features.8.conv.6 tensor(0.6571)
features.9.conv.0 tensor(0.0989)
features.9.conv.3 tensor(0.0605)
features.9.conv.6 tensor(0.9317)
features.10.conv.0 tensor(0.2644)
features.10.conv.3 tensor(0.0778)
features.10.conv.6 tensor(0.1368)
features.11.conv.0 tensor(0.7174)
features.11.conv.3 tensor(0.1356)
INFO - Validation [29][   40/   40]   Loss 2.314089   Top1 10.000000   Top5 50.000000   BatchTime 0.085792
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.314
INFO - ==> Sparsity : 0.632
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [29][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
features.11.conv.6 tensor(0.9810)
features.12.conv.0 tensor(0.7283)
features.12.conv.3 tensor(0.1993)
features.12.conv.6 tensor(0.1861)
features.13.conv.0 tensor(0.6024)
features.13.conv.3 tensor(0.1327)
features.13.conv.6 tensor(0.0710)
features.14.conv.0 tensor(0.1677)
features.14.conv.3 tensor(0.1061)
features.14.conv.6 tensor(0.0578)
features.15.conv.0 tensor(0.8793)
features.15.conv.3 tensor(0.0699)
features.15.conv.6 tensor(1.)
features.16.conv.0 tensor(0.5614)
features.16.conv.3 tensor(0.0391)
features.16.conv.6 tensor(0.9669)
conv.0 tensor(0.9432)
tensor(1384356.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [30][   20/  196]   Loss nan   Top1 9.238281   Top5 49.199219   BatchTime 0.305617   LR 0.001250
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [30][   40/  196]   Loss nan   Top1 9.824219   Top5 49.736328   BatchTime 0.271261   LR 0.001250
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [30][   60/  196]   Loss nan   Top1 10.097656   Top5 50.097656   BatchTime 0.260130   LR 0.001250
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [30][   80/  196]   Loss nan   Top1 10.004883   Top5 49.711914   BatchTime 0.253518   LR 0.001250
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [30][  100/  196]   Loss nan   Top1 9.902344   Top5 49.503906   BatchTime 0.252909   LR 0.001250
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [30][  120/  196]   Loss nan   Top1 9.899089   Top5 49.619141   BatchTime 0.253071   LR 0.001249
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [30][  140/  196]   Loss nan   Top1 9.913504   Top5 49.595424   BatchTime 0.253242   LR 0.001249
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [30][  160/  196]   Loss nan   Top1 9.968262   Top5 49.687500   BatchTime 0.254401   LR 0.001249
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [30][  180/  196]   Loss nan   Top1 9.958767   Top5 49.552951   BatchTime 0.253148   LR 0.001248
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - ==> Top1: 9.968    Top5: 49.522    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [30][   20/   40]   Loss 2.313959   Top1 10.078125   Top5 50.058594   BatchTime 0.110748
INFO - Validation [30][   40/   40]   Loss 2.314514   Top1 10.000000   Top5 50.000000   BatchTime 0.082010
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.315
INFO - ==> Sparsity : 0.594
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0443)
features.8.conv.6 tensor(0.6586)
features.9.conv.0 tensor(0.0957)
features.9.conv.3 tensor(0.0582)
features.9.conv.6 tensor(0.9269)
features.10.conv.0 tensor(0.2554)
features.10.conv.3 tensor(0.0767)
features.10.conv.6 tensor(0.1346)
features.11.conv.0 tensor(0.6738)
features.11.conv.3 tensor(0.1331)
features.11.conv.6 tensor(0.9816)
features.12.conv.0 tensor(0.6830)
features.12.conv.3 tensor(0.1948)
features.12.conv.6 tensor(0.2003)
features.13.conv.0 tensor(0.5779)
features.13.conv.3 tensor(0.1325)
features.13.conv.6 tensor(0.0447)
features.14.conv.0 tensor(0.1599)
features.14.conv.3 tensor(0.1067)
features.14.conv.6 tensor(0.0601)
features.15.conv.0 tensor(0.8848)
features.15.conv.3 tensor(0.0703)
features.15.conv.6 tensor(0.5758)
features.16.conv.0 tensor(0.5572)
features.16.conv.3 tensor(0.0337)
features.16.conv.6 tensor(0.9568)
conv.0 tensor(0.9290)
tensor(1301217.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [31][   20/  196]   Loss nan   Top1 10.507812   Top5 49.687500   BatchTime 0.325905   LR 0.001248
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [31][   40/  196]   Loss nan   Top1 10.527344   Top5 50.439453   BatchTime 0.288588   LR 0.001247
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [31][   60/  196]   Loss nan   Top1 10.397135   Top5 50.364583   BatchTime 0.274961   LR 0.001247
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [31][   80/  196]   Loss nan   Top1 10.283203   Top5 50.546875   BatchTime 0.268097   LR 0.001246
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [31][  100/  196]   Loss nan   Top1 10.167969   Top5 50.328125   BatchTime 0.264135   LR 0.001246
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [31][  120/  196]   Loss nan   Top1 10.299479   Top5 50.410156   BatchTime 0.262125   LR 0.001245
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [31][  140/  196]   Loss nan   Top1 10.167411   Top5 50.365513   BatchTime 0.260112   LR 0.001244
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [31][  160/  196]   Loss nan   Top1 10.153809   Top5 50.231934   BatchTime 0.259248   LR 0.001244
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [31][  180/  196]   Loss nan   Top1 10.067274   Top5 50.156250   BatchTime 0.258102   LR 0.001243
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.094    Top5: 50.316    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [31][   20/   40]   Loss 2.391478   Top1 10.078125   Top5 50.058594   BatchTime 0.111111
INFO - Validation [31][   40/   40]   Loss 2.393134   Top1 10.000000   Top5 50.000000   BatchTime 0.081607
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.393
INFO - ==> Sparsity : 0.608
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [31][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0443)
features.8.conv.6 tensor(0.6623)
features.9.conv.0 tensor(0.0976)
features.9.conv.3 tensor(0.0584)
features.9.conv.6 tensor(0.9260)
features.10.conv.0 tensor(0.2483)
features.10.conv.3 tensor(0.0758)
features.10.conv.6 tensor(0.1428)
features.11.conv.0 tensor(0.7684)
features.11.conv.3 tensor(0.1352)
features.11.conv.6 tensor(0.9802)
features.12.conv.0 tensor(0.7414)
features.12.conv.3 tensor(0.1916)
features.12.conv.6 tensor(0.2155)
features.13.conv.0 tensor(0.6441)
features.13.conv.3 tensor(0.1287)
features.13.conv.6 tensor(0.0508)
features.14.conv.0 tensor(0.1615)
features.14.conv.3 tensor(0.1081)
features.14.conv.6 tensor(0.0792)
features.15.conv.0 tensor(0.8892)
features.15.conv.3 tensor(0.0692)
features.15.conv.6 tensor(0.6087)
features.16.conv.0 tensor(0.5765)
features.16.conv.3 tensor(0.0343)
features.16.conv.6 tensor(0.9595)
conv.0 tensor(0.9369)
tensor(1330801.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [32][   20/  196]   Loss nan   Top1 9.960938   Top5 50.000000   BatchTime 0.324148   LR 0.001242
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [32][   40/  196]   Loss nan   Top1 9.804688   Top5 50.078125   BatchTime 0.284980   LR 0.001241
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [32][   60/  196]   Loss nan   Top1 9.674479   Top5 49.746094   BatchTime 0.269235   LR 0.001240
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [32][   80/  196]   Loss nan   Top1 9.960938   Top5 49.833984   BatchTime 0.265433   LR 0.001239
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [32][  100/  196]   Loss nan   Top1 10.062500   Top5 49.847656   BatchTime 0.261624   LR 0.001238
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [32][  120/  196]   Loss nan   Top1 10.110677   Top5 49.619141   BatchTime 0.259791   LR 0.001237
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [32][  140/  196]   Loss nan   Top1 10.114397   Top5 49.760045   BatchTime 0.258329   LR 0.001236
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [32][  160/  196]   Loss nan   Top1 10.112305   Top5 49.812012   BatchTime 0.257242   LR 0.001235
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [32][  180/  196]   Loss nan   Top1 10.052083   Top5 49.759115   BatchTime 0.256259   LR 0.001234
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.990    Top5: 49.668    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [32][   20/   40]   Loss 2.307618   Top1 10.078125   Top5 50.058594   BatchTime 0.115030
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0443)
features.8.conv.6 tensor(0.6665)
features.9.conv.0 tensor(0.0979)
features.9.conv.3 tensor(0.0579)
features.9.conv.6 tensor(0.9267)
features.10.conv.0 tensor(0.2402)
features.10.conv.3 tensor(0.0735)
features.10.conv.6 tensor(0.1540)
features.11.conv.0 tensor(0.7932)
features.11.conv.3 tensor(0.1379)
features.11.conv.6 tensor(0.9795)
features.12.conv.0 tensor(0.7483)
features.12.conv.3 tensor(0.1925)
features.12.conv.6 tensor(0.2483)
features.13.conv.0 tensor(0.6588)
features.13.conv.3 tensor(0.1318)
features.13.conv.6 tensor(0.0556)
features.14.conv.0 tensor(0.1623)
features.14.conv.3 tensor(0.1088)
features.14.conv.6 tensor(0.1040)
features.15.conv.0 tensor(0.8928)
features.15.conv.3 tensor(0.0677)
features.15.conv.6 tensor(0.6294)
features.16.conv.0 tensor(0.5968)
features.16.conv.3 tensor(0.0336)
features.16.conv.6 tensor(0.9648)
conv.0 tensor(0.9434)
tensor(1351013.) 2188896.0
INFO - Validation [32][   40/   40]   Loss 2.307892   Top1 10.000000   Top5 50.000000   BatchTime 0.084198
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.308
INFO - ==> Sparsity : 0.617
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [33][   20/  196]   Loss nan   Top1 9.921875   Top5 50.019531   BatchTime 0.328789   LR 0.001232
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [33][   40/  196]   Loss nan   Top1 9.785156   Top5 49.433594   BatchTime 0.289254   LR 0.001230
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [33][   60/  196]   Loss nan   Top1 9.739583   Top5 49.544271   BatchTime 0.274436   LR 0.001229
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [33][   80/  196]   Loss nan   Top1 9.980469   Top5 49.731445   BatchTime 0.271134   LR 0.001228
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [33][  100/  196]   Loss nan   Top1 9.878906   Top5 49.546875   BatchTime 0.267707   LR 0.001226
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [33][  120/  196]   Loss nan   Top1 9.895833   Top5 49.765625   BatchTime 0.264748   LR 0.001225
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [33][  140/  196]   Loss nan   Top1 9.933036   Top5 49.829799   BatchTime 0.262183   LR 0.001224
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [33][  160/  196]   Loss nan   Top1 9.968262   Top5 49.721680   BatchTime 0.260934   LR 0.001222
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [33][  180/  196]   Loss nan   Top1 9.945747   Top5 49.683160   BatchTime 0.257827   LR 0.001221
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.936    Top5: 49.708    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [33][   20/   40]   Loss 2.377448   Top1 10.078125   Top5 50.214844   BatchTime 0.117259
INFO - Validation [33][   40/   40]   Loss 2.378859   Top1 10.000000   Top5 50.000000   BatchTime 0.084941
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.379
INFO - ==> Sparsity : 0.624
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.0107)
features.7.conv.6 tensor(1.)
features.8.conv.0 tensor(1.)
features.8.conv.3 tensor(0.0446)
features.8.conv.6 tensor(0.6715)
features.9.conv.0 tensor(0.1001)
features.9.conv.3 tensor(0.0584)
features.9.conv.6 tensor(0.9295)
features.10.conv.0 tensor(0.2352)
features.10.conv.3 tensor(0.0726)
features.10.conv.6 tensor(0.1552)
features.11.conv.0 tensor(0.8013)
features.11.conv.3 tensor(0.1348)
features.11.conv.6 tensor(0.9808)
features.12.conv.0 tensor(0.7319)
features.12.conv.3 tensor(0.1908)
features.12.conv.6 tensor(0.3089)
features.13.conv.0 tensor(0.6669)
features.13.conv.3 tensor(0.1310)
features.13.conv.6 tensor(0.0574)
features.14.conv.0 tensor(0.1622)
features.14.conv.3 tensor(0.1103)
features.14.conv.6 tensor(0.1432)
features.15.conv.0 tensor(0.8937)
features.15.conv.3 tensor(0.0669)
features.15.conv.6 tensor(0.6429)
features.16.conv.0 tensor(0.6089)
features.16.conv.3 tensor(0.0322)
features.16.conv.6 tensor(0.9653)
conv.0 tensor(0.9451)
tensor(1365676.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [34][   20/  196]   Loss nan   Top1 11.152344   Top5 51.132812   BatchTime 0.316758   LR 0.001218
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [34][   40/  196]   Loss nan   Top1 10.673828   Top5 50.703125   BatchTime 0.281184   LR 0.001216
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [34][   60/  196]   Loss nan   Top1 10.214844   Top5 50.377604   BatchTime 0.271751   LR 0.001215
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [34][   80/  196]   Loss nan   Top1 10.092773   Top5 50.419922   BatchTime 0.266380   LR 0.001213
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [34][  100/  196]   Loss nan   Top1 10.027344   Top5 50.242188   BatchTime 0.262858   LR 0.001211
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [34][  120/  196]   Loss nan   Top1 9.951172   Top5 50.120443   BatchTime 0.260980   LR 0.001209
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [34][  140/  196]   Loss nan   Top1 9.866071   Top5 50.025112   BatchTime 0.258979   LR 0.001208
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [34][  160/  196]   Loss nan   Top1 9.973145   Top5 49.943848   BatchTime 0.259235   LR 0.001206
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [34][  180/  196]   Loss nan   Top1 10.019531   Top5 49.917535   BatchTime 0.258999   LR 0.001204
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.988    Top5: 49.904    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [34][   20/   40]   Loss 16.407087   Top1 10.078125   Top5 50.195312   BatchTime 0.112271
INFO - Validation [34][   40/   40]   Loss 16.444496   Top1 10.000000   Top5 50.000000   BatchTime 0.082976
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 16.444
INFO - ==> Sparsity : 0.459
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.8039)
features.15.conv.3 tensor(0.0538)
features.15.conv.6 tensor(0.6532)
features.16.conv.0 tensor(0.6108)
features.16.conv.3 tensor(0.0275)
features.16.conv.6 tensor(0.9658)
conv.0 tensor(0.9503)
tensor(1004266.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [35][   20/  196]   Loss nan   Top1 9.375000   Top5 50.136719   BatchTime 0.302857   LR 0.001201
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [35][   40/  196]   Loss nan   Top1 9.697266   Top5 50.000000   BatchTime 0.277589   LR 0.001199
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [35][   60/  196]   Loss nan   Top1 9.804688   Top5 50.039062   BatchTime 0.266447   LR 0.001197
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [35][   80/  196]   Loss nan   Top1 9.648438   Top5 49.790039   BatchTime 0.262312   LR 0.001195
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [35][  100/  196]   Loss nan   Top1 9.621094   Top5 49.929688   BatchTime 0.260835   LR 0.001192
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [35][  120/  196]   Loss nan   Top1 9.710286   Top5 49.990234   BatchTime 0.258308   LR 0.001190
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [35][  140/  196]   Loss nan   Top1 9.737723   Top5 49.963728   BatchTime 0.257221   LR 0.001188
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [35][  160/  196]   Loss nan   Top1 9.807129   Top5 49.924316   BatchTime 0.256347   LR 0.001186
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [35][  180/  196]   Loss nan   Top1 9.730903   Top5 49.947917   BatchTime 0.253903   LR 0.001184
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.674    Top5: 49.956    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 12.463055   Top1 10.078125   Top5 50.058594   BatchTime 0.113112
INFO - Validation [35][   40/   40]   Loss 12.490792   Top1 10.000000   Top5 50.000000   BatchTime 0.084009
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 12.491
INFO - ==> Sparsity : 0.464
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.8310)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.6640)
features.16.conv.0 tensor(0.6258)
features.16.conv.3 tensor(0.0275)
features.16.conv.6 tensor(0.9697)
conv.0 tensor(0.9541)
tensor(1015178.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [36][   20/  196]   Loss nan   Top1 9.960938   Top5 50.996094   BatchTime 0.313339   LR 0.001180
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [36][   40/  196]   Loss nan   Top1 10.205078   Top5 51.142578   BatchTime 0.282696   LR 0.001177
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [36][   60/  196]   Loss nan   Top1 9.960938   Top5 50.455729   BatchTime 0.271111   LR 0.001175
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [36][   80/  196]   Loss nan   Top1 9.995117   Top5 50.122070   BatchTime 0.266085   LR 0.001173
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [36][  100/  196]   Loss nan   Top1 9.902344   Top5 50.183594   BatchTime 0.262842   LR 0.001170
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [36][  120/  196]   Loss nan   Top1 9.837240   Top5 49.977214   BatchTime 0.261236   LR 0.001168
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [36][  140/  196]   Loss nan   Top1 9.801897   Top5 49.785156   BatchTime 0.258505   LR 0.001165
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [36][  160/  196]   Loss nan   Top1 9.797363   Top5 49.770508   BatchTime 0.256163   LR 0.001163
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [36][  180/  196]   Loss nan   Top1 9.772135   Top5 49.698351   BatchTime 0.255755   LR 0.001160
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.760    Top5: 49.634    Loss: nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [36][   20/   40]   Loss 10.397360   Top1 10.078125   Top5 50.058594   BatchTime 0.111975
INFO - Validation [36][   40/   40]   Loss 10.419389   Top1 10.000000   Top5 50.000000   BatchTime 0.080097
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 10.419
INFO - ==> Sparsity : 0.467
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.8467)
features.15.conv.3 tensor(0.0539)
features.15.conv.6 tensor(0.6731)
features.16.conv.0 tensor(0.6400)
features.16.conv.3 tensor(0.0271)
features.16.conv.6 tensor(0.9736)
conv.0 tensor(0.9552)
tensor(1022783.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [37][   20/  196]   Loss nan   Top1 9.492188   Top5 50.175781   BatchTime 0.309870   LR 0.001155
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [37][   40/  196]   Loss nan   Top1 9.433594   Top5 50.058594   BatchTime 0.283085   LR 0.001153
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [37][   60/  196]   Loss nan   Top1 9.472656   Top5 49.947917   BatchTime 0.278925   LR 0.001150
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [37][   80/  196]   Loss nan   Top1 9.501953   Top5 50.029297   BatchTime 0.274193   LR 0.001147
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [37][  100/  196]   Loss nan   Top1 9.742188   Top5 50.183594   BatchTime 0.269168   LR 0.001144
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [37][  120/  196]   Loss nan   Top1 9.788411   Top5 50.231120   BatchTime 0.266092   LR 0.001142
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [37][  140/  196]   Loss nan   Top1 9.796317   Top5 50.234375   BatchTime 0.265044   LR 0.001139
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [37][  160/  196]   Loss nan   Top1 9.799805   Top5 50.253906   BatchTime 0.265334   LR 0.001136
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [37][  180/  196]   Loss nan   Top1 9.759115   Top5 50.115017   BatchTime 0.262908   LR 0.001133
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - ==> Top1: 9.690    Top5: 50.188    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [37][   20/   40]   Loss 5.650106   Top1 10.078125   Top5 50.195312   BatchTime 0.110246
INFO - Validation [37][   40/   40]   Loss 5.661198   Top1 10.000000   Top5 50.000000   BatchTime 0.083064
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 5.661
INFO - ==> Sparsity : 0.480
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [37][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.6858)
features.16.conv.0 tensor(0.6564)
features.16.conv.3 tensor(0.0275)
features.16.conv.6 tensor(0.9738)
conv.0 tensor(0.9570)
tensor(1051610.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [38][   20/  196]   Loss nan   Top1 10.156250   Top5 50.195312   BatchTime 0.306477   LR 0.001128
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [38][   40/  196]   Loss nan   Top1 9.794922   Top5 50.302734   BatchTime 0.275389   LR 0.001125
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [38][   60/  196]   Loss nan   Top1 9.993490   Top5 50.371094   BatchTime 0.264671   LR 0.001122
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [38][   80/  196]   Loss nan   Top1 9.941406   Top5 50.258789   BatchTime 0.260731   LR 0.001119
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [38][  100/  196]   Loss nan   Top1 9.960938   Top5 50.230469   BatchTime 0.258569   LR 0.001116
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [38][  120/  196]   Loss nan   Top1 9.964193   Top5 50.130208   BatchTime 0.258676   LR 0.001112
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [38][  140/  196]   Loss nan   Top1 10.027902   Top5 50.072545   BatchTime 0.257863   LR 0.001109
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [38][  160/  196]   Loss nan   Top1 10.036621   Top5 50.036621   BatchTime 0.256824   LR 0.001106
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [38][  180/  196]   Loss nan   Top1 10.010851   Top5 50.002170   BatchTime 0.255785   LR 0.001103
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.974    Top5: 49.994    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [38][   20/   40]   Loss 7.848091   Top1 10.078125   Top5 50.195312   BatchTime 0.113587
INFO - Validation [38][   40/   40]   Loss 7.863141   Top1 10.000000   Top5 50.000000   BatchTime 0.083036
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 7.863
INFO - ==> Sparsity : 0.483
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0543)
features.15.conv.6 tensor(0.6944)
features.16.conv.0 tensor(0.6714)
features.16.conv.3 tensor(0.0281)
features.16.conv.6 tensor(0.9758)
conv.0 tensor(0.9621)
tensor(1057923.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [39][   20/  196]   Loss nan   Top1 10.136719   Top5 49.960938   BatchTime 0.319415   LR 0.001097
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [39][   40/  196]   Loss nan   Top1 9.736328   Top5 49.570312   BatchTime 0.284637   LR 0.001094
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [39][   60/  196]   Loss nan   Top1 9.928385   Top5 49.622396   BatchTime 0.272497   LR 0.001090
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [39][   80/  196]   Loss nan   Top1 9.980469   Top5 49.780273   BatchTime 0.268175   LR 0.001087
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [39][  100/  196]   Loss nan   Top1 9.937500   Top5 49.718750   BatchTime 0.264380   LR 0.001084
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [39][  120/  196]   Loss nan   Top1 9.853516   Top5 49.742839   BatchTime 0.261862   LR 0.001080
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [39][  140/  196]   Loss nan   Top1 9.919085   Top5 49.815848   BatchTime 0.261463   LR 0.001077
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [39][  160/  196]   Loss nan   Top1 9.914551   Top5 49.855957   BatchTime 0.259555   LR 0.001073
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [39][  180/  196]   Loss nan   Top1 9.891493   Top5 49.926215   BatchTime 0.257948   LR 0.001070
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.892    Top5: 49.886    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [39][   20/   40]   Loss 8.200191   Top1 10.078125   Top5 50.058594   BatchTime 0.112979
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
INFO - Validation [39][   40/   40]   Loss 8.216335   Top1 10.000000   Top5 50.000000   BatchTime 0.081403
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 8.216
INFO - ==> Sparsity : 0.485
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0543)
features.15.conv.6 tensor(0.7021)
features.16.conv.0 tensor(0.6845)
features.16.conv.3 tensor(0.0275)
features.16.conv.6 tensor(0.9779)
conv.0 tensor(0.9619)
tensor(1061687.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [40][   20/  196]   Loss nan   Top1 10.097656   Top5 50.039062   BatchTime 0.322624   LR 0.001064
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [40][   40/  196]   Loss nan   Top1 9.833984   Top5 50.166016   BatchTime 0.294730   LR 0.001060
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [40][   60/  196]   Loss nan   Top1 9.876302   Top5 49.856771   BatchTime 0.278994   LR 0.001056
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [40][   80/  196]   Loss nan   Top1 9.907227   Top5 49.931641   BatchTime 0.271099   LR 0.001053
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [40][  100/  196]   Loss nan   Top1 10.164062   Top5 50.105469   BatchTime 0.266759   LR 0.001049
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [40][  120/  196]   Loss nan   Top1 10.143229   Top5 50.048828   BatchTime 0.264023   LR 0.001045
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [40][  140/  196]   Loss nan   Top1 10.066964   Top5 50.086496   BatchTime 0.262034   LR 0.001042
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [40][  160/  196]   Loss nan   Top1 10.036621   Top5 49.941406   BatchTime 0.260424   LR 0.001038
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [40][  180/  196]   Loss nan   Top1 10.015191   Top5 49.963108   BatchTime 0.258870   LR 0.001034
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.022    Top5: 49.968    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 9.101910   Top1 10.078125   Top5 50.058594   BatchTime 0.112172
INFO - Validation [40][   40/   40]   Loss 9.120362   Top1 10.000000   Top5 50.000000   BatchTime 0.082964
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 9.120
INFO - ==> Sparsity : 0.487
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [40][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0543)
features.15.conv.6 tensor(0.7093)
features.16.conv.0 tensor(0.6975)
features.16.conv.3 tensor(0.0270)
features.16.conv.6 tensor(0.9789)
conv.0 tensor(0.9652)
tensor(1066413.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [41][   20/  196]   Loss nan   Top1 10.449219   Top5 51.191406   BatchTime 0.317863   LR 0.001027
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [41][   40/  196]   Loss nan   Top1 10.312500   Top5 50.781250   BatchTime 0.290506   LR 0.001023
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [41][   60/  196]   Loss nan   Top1 10.195312   Top5 50.312500   BatchTime 0.278045   LR 0.001020
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [41][   80/  196]   Loss nan   Top1 10.249023   Top5 50.166016   BatchTime 0.270704   LR 0.001016
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [41][  100/  196]   Loss nan   Top1 10.265625   Top5 50.050781   BatchTime 0.265605   LR 0.001012
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [41][  120/  196]   Loss nan   Top1 10.172526   Top5 49.947917   BatchTime 0.263203   LR 0.001008
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [41][  140/  196]   Loss nan   Top1 10.086496   Top5 49.952567   BatchTime 0.261230   LR 0.001004
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [41][  160/  196]   Loss nan   Top1 10.026855   Top5 49.921875   BatchTime 0.259815   LR 0.001000
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [41][  180/  196]   Loss nan   Top1 10.062934   Top5 49.967448   BatchTime 0.258215   LR 0.000996
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.062    Top5: 50.088    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [41][   20/   40]   Loss 6.002224   Top1 10.078125   Top5 50.058594   BatchTime 0.109592
INFO - Validation [41][   40/   40]   Loss 6.013194   Top1 10.000000   Top5 50.000000   BatchTime 0.082786
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 6.013
INFO - ==> Sparsity : 0.490
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0544)
features.15.conv.6 tensor(0.7133)
features.16.conv.0 tensor(0.7150)
features.16.conv.3 tensor(0.0275)
features.16.conv.6 tensor(0.9818)
conv.0 tensor(0.9675)
tensor(1071578.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [42][   20/  196]   Loss nan   Top1 10.742188   Top5 49.394531   BatchTime 0.320089   LR 0.000988
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [42][   40/  196]   Loss nan   Top1 10.537109   Top5 49.667969   BatchTime 0.283027   LR 0.000984
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [42][   60/  196]   Loss nan   Top1 10.182292   Top5 49.472656   BatchTime 0.274156   LR 0.000980
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [42][   80/  196]   Loss nan   Top1 10.219727   Top5 49.916992   BatchTime 0.269074   LR 0.000976
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [42][  100/  196]   Loss nan   Top1 10.160156   Top5 49.800781   BatchTime 0.268928   LR 0.000972
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [42][  120/  196]   Loss nan   Top1 10.182292   Top5 49.580078   BatchTime 0.266476   LR 0.000968
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [42][  140/  196]   Loss nan   Top1 10.228795   Top5 49.617746   BatchTime 0.263752   LR 0.000964
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [42][  160/  196]   Loss nan   Top1 10.158691   Top5 49.663086   BatchTime 0.261821   LR 0.000959
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [42][  180/  196]   Loss nan   Top1 10.075955   Top5 49.600694   BatchTime 0.260160   LR 0.000955
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - ==> Top1: 10.110    Top5: 49.584    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [42][   20/   40]   Loss 3.825160   Top1 10.078125   Top5 50.058594   BatchTime 0.119021
INFO - Validation [42][   40/   40]   Loss 3.832590   Top1 10.000000   Top5 50.000000   BatchTime 0.088245
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 3.833
INFO - ==> Sparsity : 0.491
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.7172)
features.16.conv.0 tensor(0.7305)
features.16.conv.3 tensor(0.0279)
features.16.conv.6 tensor(0.9834)
conv.0 tensor(0.9682)
tensor(1075360.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [43][   20/  196]   Loss nan   Top1 9.394531   Top5 49.296875   BatchTime 0.318270   LR 0.000947
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [43][   40/  196]   Loss nan   Top1 9.951172   Top5 49.726562   BatchTime 0.288176   LR 0.000943
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [43][   60/  196]   Loss nan   Top1 9.941406   Top5 49.407552   BatchTime 0.275512   LR 0.000939
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [43][   80/  196]   Loss nan   Top1 9.936523   Top5 49.785156   BatchTime 0.268622   LR 0.000934
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [43][  100/  196]   Loss nan   Top1 9.855469   Top5 49.902344   BatchTime 0.264572   LR 0.000930
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [43][  120/  196]   Loss nan   Top1 9.886068   Top5 49.736328   BatchTime 0.262339   LR 0.000926
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [43][  140/  196]   Loss nan   Top1 9.871652   Top5 50.013951   BatchTime 0.260750   LR 0.000921
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [43][  160/  196]   Loss nan   Top1 9.843750   Top5 49.843750   BatchTime 0.259703   LR 0.000917
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [43][  180/  196]   Loss nan   Top1 9.952257   Top5 49.924045   BatchTime 0.258262   LR 0.000912
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - ==> Top1: 9.902    Top5: 49.814    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [43][   20/   40]   Loss 9.351119   Top1 10.078125   Top5 50.058594   BatchTime 0.112732
INFO - Validation [43][   40/   40]   Loss 9.371401   Top1 10.000000   Top5 50.000000   BatchTime 0.083195
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 9.371
INFO - ==> Sparsity : 0.493
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [43][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.7223)
features.16.conv.0 tensor(0.7361)
features.16.conv.3 tensor(0.0272)
features.16.conv.6 tensor(0.9850)
conv.0 tensor(0.9700)
tensor(1078198.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [44][   20/  196]   Loss nan   Top1 10.664062   Top5 49.531250   BatchTime 0.315076   LR 0.000904
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [44][   40/  196]   Loss nan   Top1 10.253906   Top5 49.375000   BatchTime 0.282456   LR 0.000900
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [44][   60/  196]   Loss nan   Top1 10.104167   Top5 49.733073   BatchTime 0.271605   LR 0.000895
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [44][   80/  196]   Loss nan   Top1 10.068359   Top5 49.682617   BatchTime 0.267121   LR 0.000891
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [44][  100/  196]   Loss nan   Top1 9.972656   Top5 49.593750   BatchTime 0.263110   LR 0.000886
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [44][  120/  196]   Loss nan   Top1 9.973958   Top5 49.479167   BatchTime 0.259621   LR 0.000882
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [44][  140/  196]   Loss nan   Top1 9.980469   Top5 49.455915   BatchTime 0.258091   LR 0.000877
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [44][  160/  196]   Loss nan   Top1 10.039062   Top5 49.475098   BatchTime 0.256937   LR 0.000873
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [44][  180/  196]   Loss nan   Top1 9.973958   Top5 49.461806   BatchTime 0.255187   LR 0.000868
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.984    Top5: 49.410    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 9.361306   Top1 10.078125   Top5 50.058594   BatchTime 0.118881
INFO - Validation [44][   40/   40]   Loss 9.381198   Top1 10.000000   Top5 50.000000   BatchTime 0.087424
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0542)
features.15.conv.6 tensor(0.7268)
features.16.conv.0 tensor(0.7417)
features.16.conv.3 tensor(0.0279)
features.16.conv.6 tensor(0.9847)
conv.0 tensor(0.9690)
tensor(1079250.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 9.381
INFO - ==> Sparsity : 0.493
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [45][   20/  196]   Loss nan   Top1 10.136719   Top5 50.117188   BatchTime 0.321891   LR 0.000860
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [45][   40/  196]   Loss nan   Top1 10.175781   Top5 49.746094   BatchTime 0.284237   LR 0.000855
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [45][   60/  196]   Loss nan   Top1 9.915365   Top5 49.928385   BatchTime 0.275121   LR 0.000850
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [45][   80/  196]   Loss nan   Top1 9.838867   Top5 49.760742   BatchTime 0.269026   LR 0.000846
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [45][  100/  196]   Loss nan   Top1 9.812500   Top5 49.921875   BatchTime 0.263881   LR 0.000841
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [45][  120/  196]   Loss nan   Top1 9.778646   Top5 50.065104   BatchTime 0.262703   LR 0.000836
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [45][  140/  196]   Loss nan   Top1 9.771205   Top5 49.980469   BatchTime 0.261415   LR 0.000832
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [45][  160/  196]   Loss nan   Top1 9.814453   Top5 50.090332   BatchTime 0.260588   LR 0.000827
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [45][  180/  196]   Loss nan   Top1 9.843750   Top5 50.036892   BatchTime 0.259282   LR 0.000822
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.846    Top5: 49.966    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 9.508318   Top1 10.078125   Top5 50.058594   BatchTime 0.116621
INFO - Validation [45][   40/   40]   Loss 9.529464   Top1 10.000000   Top5 50.000000   BatchTime 0.083261
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 9.529
INFO - ==> Sparsity : 0.494
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [45][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0542)
features.15.conv.6 tensor(0.7311)
features.16.conv.0 tensor(0.7500)
features.16.conv.3 tensor(0.0281)
features.16.conv.6 tensor(0.9856)
conv.0 tensor(0.9710)
tensor(1082331.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [46][   20/  196]   Loss nan   Top1 10.976562   Top5 50.449219   BatchTime 0.332221   LR 0.000814
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [46][   40/  196]   Loss nan   Top1 10.605469   Top5 50.205078   BatchTime 0.295799   LR 0.000809
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [46][   60/  196]   Loss nan   Top1 10.377604   Top5 50.110677   BatchTime 0.280318   LR 0.000804
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [46][   80/  196]   Loss nan   Top1 10.371094   Top5 49.760742   BatchTime 0.272580   LR 0.000799
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [46][  100/  196]   Loss nan   Top1 10.312500   Top5 49.652344   BatchTime 0.268120   LR 0.000794
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [46][  120/  196]   Loss nan   Top1 10.260417   Top5 49.674479   BatchTime 0.265179   LR 0.000789
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [46][  140/  196]   Loss nan   Top1 10.089286   Top5 49.542411   BatchTime 0.263110   LR 0.000785
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [46][  160/  196]   Loss nan   Top1 10.017090   Top5 49.611816   BatchTime 0.261147   LR 0.000780
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [46][  180/  196]   Loss nan   Top1 10.060764   Top5 49.782986   BatchTime 0.259445   LR 0.000775
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.044    Top5: 49.754    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [46][   20/   40]   Loss 8.825549   Top1 10.078125   Top5 50.058594   BatchTime 0.114682
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0538)
features.15.conv.6 tensor(0.7346)
features.16.conv.0 tensor(0.7612)
features.16.conv.3 tensor(0.0285)
features.16.conv.6 tensor(0.9863)
conv.0 tensor(0.9733)
tensor(1085723.) 2188896.0
INFO - Validation [46][   40/   40]   Loss 8.844259   Top1 10.000000   Top5 50.000000   BatchTime 0.083842
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 8.844
INFO - ==> Sparsity : 0.496
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [47][   20/  196]   Loss nan   Top1 9.980469   Top5 49.980469   BatchTime 0.314744   LR 0.000766
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [47][   40/  196]   Loss nan   Top1 10.048828   Top5 49.863281   BatchTime 0.279666   LR 0.000761
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [47][   60/  196]   Loss nan   Top1 9.869792   Top5 49.687500   BatchTime 0.271337   LR 0.000756
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [47][   80/  196]   Loss nan   Top1 9.785156   Top5 49.638672   BatchTime 0.266544   LR 0.000752
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [47][  100/  196]   Loss nan   Top1 9.789062   Top5 49.820312   BatchTime 0.261688   LR 0.000747
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [47][  120/  196]   Loss nan   Top1 9.746094   Top5 49.684245   BatchTime 0.259959   LR 0.000742
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [47][  140/  196]   Loss nan   Top1 9.732143   Top5 49.732143   BatchTime 0.258452   LR 0.000737
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [47][  160/  196]   Loss nan   Top1 9.870605   Top5 49.758301   BatchTime 0.258003   LR 0.000732
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [47][  180/  196]   Loss nan   Top1 9.832899   Top5 49.722222   BatchTime 0.256477   LR 0.000727
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.868    Top5: 49.788    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [47][   20/   40]   Loss 8.354766   Top1 10.078125   Top5 50.058594   BatchTime 0.116185
INFO - Validation [47][   40/   40]   Loss 8.371239   Top1 10.000000   Top5 50.000000   BatchTime 0.085436
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 8.371
INFO - ==> Sparsity : 0.497
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [47][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.7381)
features.16.conv.0 tensor(0.7683)
features.16.conv.3 tensor(0.0275)
features.16.conv.6 tensor(0.9868)
conv.0 tensor(0.9731)
tensor(1087412.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [48][   20/  196]   Loss nan   Top1 9.667969   Top5 49.824219   BatchTime 0.314545   LR 0.000718
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [48][   40/  196]   Loss nan   Top1 9.511719   Top5 48.955078   BatchTime 0.277364   LR 0.000713
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [48][   60/  196]   Loss nan   Top1 9.778646   Top5 49.270833   BatchTime 0.267994   LR 0.000708
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [48][   80/  196]   Loss nan   Top1 9.873047   Top5 49.604492   BatchTime 0.263731   LR 0.000703
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [48][  100/  196]   Loss nan   Top1 9.839844   Top5 49.585938   BatchTime 0.260763   LR 0.000698
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [48][  120/  196]   Loss nan   Top1 9.820964   Top5 49.625651   BatchTime 0.258961   LR 0.000693
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [48][  140/  196]   Loss nan   Top1 9.866071   Top5 49.662388   BatchTime 0.257548   LR 0.000688
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [48][  160/  196]   Loss nan   Top1 9.843750   Top5 49.763184   BatchTime 0.257084   LR 0.000683
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [48][  180/  196]   Loss nan   Top1 9.884983   Top5 49.802517   BatchTime 0.256174   LR 0.000678
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.796    Top5: 49.734    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [48][   20/   40]   Loss 8.328492   Top1 10.078125   Top5 50.058594   BatchTime 0.111496
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.7408)
features.16.conv.0 tensor(0.7768)
features.16.conv.3 tensor(0.0270)
features.16.conv.6 tensor(0.9872)
conv.0 tensor(0.9743)
tensor(1089742.) 2188896.0
INFO - Validation [48][   40/   40]   Loss 8.345505   Top1 10.000000   Top5 50.000000   BatchTime 0.083838
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 8.346
INFO - ==> Sparsity : 0.498
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [48][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [49][   20/  196]   Loss nan   Top1 9.902344   Top5 50.195312   BatchTime 0.318856   LR 0.000669
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [49][   40/  196]   Loss nan   Top1 10.009766   Top5 50.253906   BatchTime 0.287109   LR 0.000664
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [49][   60/  196]   Loss nan   Top1 10.006510   Top5 50.312500   BatchTime 0.275311   LR 0.000659
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [49][   80/  196]   Loss nan   Top1 9.799805   Top5 50.356445   BatchTime 0.269465   LR 0.000654
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [49][  100/  196]   Loss nan   Top1 9.968750   Top5 50.386719   BatchTime 0.266109   LR 0.000649
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [49][  120/  196]   Loss nan   Top1 10.110677   Top5 50.305990   BatchTime 0.262890   LR 0.000644
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [49][  140/  196]   Loss nan   Top1 9.938616   Top5 50.100446   BatchTime 0.260359   LR 0.000639
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [49][  160/  196]   Loss nan   Top1 9.890137   Top5 49.995117   BatchTime 0.259047   LR 0.000634
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [49][  180/  196]   Loss nan   Top1 9.884983   Top5 49.928385   BatchTime 0.257732   LR 0.000629
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.894    Top5: 49.928    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [49][   20/   40]   Loss 6.815486   Top1 10.078125   Top5 50.058594   BatchTime 0.113012
INFO - Validation [49][   40/   40]   Loss 6.829690   Top1 10.000000   Top5 50.000000   BatchTime 0.084666
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 6.830
INFO - ==> Sparsity : 0.499
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0539)
features.15.conv.6 tensor(0.7431)
features.16.conv.0 tensor(0.7858)
features.16.conv.3 tensor(0.0270)
features.16.conv.6 tensor(0.9884)
conv.0 tensor(0.9734)
tensor(1091492.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [50][   20/  196]   Loss nan   Top1 10.039062   Top5 50.605469   BatchTime 0.311748   LR 0.000620
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [50][   40/  196]   Loss nan   Top1 9.912109   Top5 49.843750   BatchTime 0.283703   LR 0.000615
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [50][   60/  196]   Loss nan   Top1 9.804688   Top5 49.576823   BatchTime 0.273791   LR 0.000610
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [50][   80/  196]   Loss nan   Top1 9.741211   Top5 49.575195   BatchTime 0.266829   LR 0.000605
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [50][  100/  196]   Loss nan   Top1 9.828125   Top5 49.589844   BatchTime 0.264104   LR 0.000600
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [50][  120/  196]   Loss nan   Top1 9.882812   Top5 49.651693   BatchTime 0.263328   LR 0.000595
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [50][  140/  196]   Loss nan   Top1 9.804688   Top5 49.746094   BatchTime 0.261192   LR 0.000590
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [50][  160/  196]   Loss nan   Top1 9.814453   Top5 49.687500   BatchTime 0.259859   LR 0.000585
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [50][  180/  196]   Loss nan   Top1 9.835069   Top5 49.759115   BatchTime 0.258715   LR 0.000580
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - ==> Top1: 9.840    Top5: 49.772    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [50][   20/   40]   Loss 6.356808   Top1 10.078125   Top5 50.058594   BatchTime 0.114949
INFO - Validation [50][   40/   40]   Loss 6.369970   Top1 10.000000   Top5 50.000000   BatchTime 0.087478
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 6.370
INFO - ==> Sparsity : 0.500
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [50][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0542)
features.15.conv.6 tensor(0.7456)
features.16.conv.0 tensor(0.7944)
features.16.conv.3 tensor(0.0272)
features.16.conv.6 tensor(0.9885)
conv.0 tensor(0.9763)
tensor(1094416.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [51][   20/  196]   Loss nan   Top1 10.234375   Top5 50.097656   BatchTime 0.305464   LR 0.000571
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [51][   40/  196]   Loss nan   Top1 10.302734   Top5 49.794922   BatchTime 0.272813   LR 0.000566
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [51][   60/  196]   Loss nan   Top1 10.260417   Top5 49.563802   BatchTime 0.265168   LR 0.000561
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [51][   80/  196]   Loss nan   Top1 10.112305   Top5 49.624023   BatchTime 0.260561   LR 0.000556
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [51][  100/  196]   Loss nan   Top1 10.035156   Top5 49.816406   BatchTime 0.258322   LR 0.000551
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [51][  120/  196]   Loss nan   Top1 9.983724   Top5 49.622396   BatchTime 0.257674   LR 0.000546
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [51][  140/  196]   Loss nan   Top1 9.949777   Top5 49.729353   BatchTime 0.256648   LR 0.000541
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [51][  160/  196]   Loss nan   Top1 9.895020   Top5 49.731445   BatchTime 0.255834   LR 0.000536
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [51][  180/  196]   Loss nan   Top1 9.841580   Top5 49.776476   BatchTime 0.255717   LR 0.000531
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.870    Top5: 49.708    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [51][   20/   40]   Loss 6.856363   Top1 10.078125   Top5 50.058594   BatchTime 0.114254
INFO - Validation [51][   40/   40]   Loss 6.870533   Top1 10.000000   Top5 50.000000   BatchTime 0.083548
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 6.871
INFO - ==> Sparsity : 0.501
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [51][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0542)
features.15.conv.6 tensor(0.7510)
features.16.conv.0 tensor(0.7998)
features.16.conv.3 tensor(0.0279)
features.16.conv.6 tensor(0.9884)
conv.0 tensor(0.9766)
tensor(1096176.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [52][   20/  196]   Loss nan   Top1 10.429688   Top5 51.406250   BatchTime 0.310810   LR 0.000523
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [52][   40/  196]   Loss nan   Top1 10.117188   Top5 50.908203   BatchTime 0.281126   LR 0.000518
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [52][   60/  196]   Loss nan   Top1 10.032552   Top5 50.579427   BatchTime 0.276732   LR 0.000513
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [52][   80/  196]   Loss nan   Top1 10.122070   Top5 50.332031   BatchTime 0.268515   LR 0.000508
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [52][  100/  196]   Loss nan   Top1 10.070312   Top5 50.484375   BatchTime 0.265308   LR 0.000503
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [52][  120/  196]   Loss nan   Top1 10.039062   Top5 50.283203   BatchTime 0.262303   LR 0.000498
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [52][  140/  196]   Loss nan   Top1 10.114397   Top5 50.362723   BatchTime 0.261488   LR 0.000493
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [52][  160/  196]   Loss nan   Top1 10.026855   Top5 50.292969   BatchTime 0.259739   LR 0.000488
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [52][  180/  196]   Loss nan   Top1 9.952257   Top5 50.032552   BatchTime 0.257934   LR 0.000483
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.864    Top5: 49.974    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [52][   20/   40]   Loss 6.555215   Top1 10.078125   Top5 50.058594   BatchTime 0.111078
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.7558)
features.16.conv.0 tensor(0.8034)
features.16.conv.3 tensor(0.0279)
features.16.conv.6 tensor(0.9874)
conv.0 tensor(0.9780)
tensor(1097717.) 2188896.0
INFO - Validation [52][   40/   40]   Loss 6.569484   Top1 10.000000   Top5 50.000000   BatchTime 0.082028
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 6.569
INFO - ==> Sparsity : 0.501
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [52][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [53][   20/  196]   Loss nan   Top1 10.078125   Top5 50.507812   BatchTime 0.319154   LR 0.000474
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [53][   40/  196]   Loss nan   Top1 10.156250   Top5 50.458984   BatchTime 0.288328   LR 0.000470
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [53][   60/  196]   Loss nan   Top1 10.039062   Top5 50.390625   BatchTime 0.276433   LR 0.000465
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [53][   80/  196]   Loss nan   Top1 10.156250   Top5 50.043945   BatchTime 0.268137   LR 0.000460
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [53][  100/  196]   Loss nan   Top1 10.078125   Top5 49.984375   BatchTime 0.264515   LR 0.000455
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [53][  120/  196]   Loss nan   Top1 10.045573   Top5 50.045573   BatchTime 0.262566   LR 0.000450
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [53][  140/  196]   Loss nan   Top1 10.030692   Top5 50.069754   BatchTime 0.261640   LR 0.000445
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [53][  160/  196]   Loss nan   Top1 10.097656   Top5 50.021973   BatchTime 0.261091   LR 0.000441
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [53][  180/  196]   Loss nan   Top1 10.056424   Top5 50.026042   BatchTime 0.259738   LR 0.000436
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.058    Top5: 50.122    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [53][   20/   40]   Loss 7.036533   Top1 10.078125   Top5 50.058594   BatchTime 0.113664
INFO - Validation [53][   40/   40]   Loss 7.051983   Top1 10.000000   Top5 50.000000   BatchTime 0.084292
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 7.052
INFO - ==> Sparsity : 0.502
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [53][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.7595)
features.16.conv.0 tensor(0.8066)
features.16.conv.3 tensor(0.0274)
features.16.conv.6 tensor(0.9859)
conv.0 tensor(0.9789)
tensor(1098676.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [54][   20/  196]   Loss nan   Top1 10.585938   Top5 50.214844   BatchTime 0.319360   LR 0.000427
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [54][   40/  196]   Loss nan   Top1 10.224609   Top5 50.458984   BatchTime 0.285731   LR 0.000423
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [54][   60/  196]   Loss nan   Top1 10.253906   Top5 50.123698   BatchTime 0.276917   LR 0.000418
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [54][   80/  196]   Loss nan   Top1 10.097656   Top5 49.863281   BatchTime 0.269051   LR 0.000413
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [54][  100/  196]   Loss nan   Top1 9.949219   Top5 49.773438   BatchTime 0.266022   LR 0.000408
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [54][  120/  196]   Loss nan   Top1 9.938151   Top5 49.755859   BatchTime 0.263139   LR 0.000404
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [54][  140/  196]   Loss nan   Top1 9.997210   Top5 49.857701   BatchTime 0.261953   LR 0.000399
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [54][  160/  196]   Loss nan   Top1 10.036621   Top5 49.916992   BatchTime 0.261287   LR 0.000394
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [54][  180/  196]   Loss nan   Top1 10.045573   Top5 50.006510   BatchTime 0.259872   LR 0.000390
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.102    Top5: 50.030    Loss: nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [54][   20/   40]   Loss 7.378641   Top1 10.078125   Top5 50.058594   BatchTime 0.114333
INFO - Validation [54][   40/   40]   Loss 7.394665   Top1 10.000000   Top5 50.000000   BatchTime 0.085692
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 7.395
INFO - ==> Sparsity : 0.503
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [54][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0539)
features.15.conv.6 tensor(0.7611)
features.16.conv.0 tensor(0.8107)
features.16.conv.3 tensor(0.0275)
features.16.conv.6 tensor(0.9862)
conv.0 tensor(0.9796)
tensor(1099948.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [55][   20/  196]   Loss nan   Top1 10.527344   Top5 50.761719   BatchTime 0.308152   LR 0.000381
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [55][   40/  196]   Loss nan   Top1 9.804688   Top5 50.390625   BatchTime 0.279006   LR 0.000377
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [55][   60/  196]   Loss nan   Top1 10.000000   Top5 50.221354   BatchTime 0.270483   LR 0.000372
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [55][   80/  196]   Loss nan   Top1 10.078125   Top5 50.039062   BatchTime 0.266025   LR 0.000368
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [55][  100/  196]   Loss nan   Top1 9.976562   Top5 50.019531   BatchTime 0.262208   LR 0.000363
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [55][  120/  196]   Loss nan   Top1 9.941406   Top5 49.915365   BatchTime 0.260083   LR 0.000358
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [55][  140/  196]   Loss nan   Top1 9.843750   Top5 49.804688   BatchTime 0.258608   LR 0.000354
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [55][  160/  196]   Loss nan   Top1 9.838867   Top5 49.838867   BatchTime 0.257469   LR 0.000349
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [55][  180/  196]   Loss nan   Top1 9.865451   Top5 49.806858   BatchTime 0.256444   LR 0.000345
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.898    Top5: 49.834    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [55][   20/   40]   Loss 6.093926   Top1 10.078125   Top5 50.058594   BatchTime 0.116314
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.7639)
features.16.conv.0 tensor(0.8125)
features.16.conv.3 tensor(0.0277)
features.16.conv.6 tensor(0.9857)
conv.0 tensor(0.9791)
tensor(1100289.) 2188896.0
INFO - Validation [55][   40/   40]   Loss 6.107328   Top1 10.000000   Top5 50.000000   BatchTime 0.086077
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 6.107
INFO - ==> Sparsity : 0.503
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [55][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [56][   20/  196]   Loss nan   Top1 10.390625   Top5 51.738281   BatchTime 0.295334   LR 0.000337
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [56][   40/  196]   Loss nan   Top1 10.078125   Top5 50.556641   BatchTime 0.271535   LR 0.000333
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [56][   60/  196]   Loss nan   Top1 10.019531   Top5 50.670573   BatchTime 0.264458   LR 0.000328
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [56][   80/  196]   Loss nan   Top1 10.117188   Top5 50.605469   BatchTime 0.262319   LR 0.000324
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [56][  100/  196]   Loss nan   Top1 10.113281   Top5 50.421875   BatchTime 0.261720   LR 0.000319
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [56][  120/  196]   Loss nan   Top1 10.205078   Top5 50.410156   BatchTime 0.260250   LR 0.000315
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [56][  140/  196]   Loss nan   Top1 10.128348   Top5 50.373884   BatchTime 0.258533   LR 0.000311
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [56][  160/  196]   Loss nan   Top1 10.205078   Top5 50.341797   BatchTime 0.256971   LR 0.000306
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [56][  180/  196]   Loss nan   Top1 10.210503   Top5 50.184462   BatchTime 0.256326   LR 0.000302
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.134    Top5: 50.108    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 6.445062   Top1 10.078125   Top5 50.214844   BatchTime 0.114968
INFO - Validation [56][   40/   40]   Loss 6.460538   Top1 10.000000   Top5 50.000000   BatchTime 0.085797
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 6.461
INFO - ==> Sparsity : 0.503
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [56][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.7659)
features.16.conv.0 tensor(0.8166)
features.16.conv.3 tensor(0.0281)
features.16.conv.6 tensor(0.9831)
conv.0 tensor(0.9799)
tensor(1100790.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [57][   20/  196]   Loss nan   Top1 10.097656   Top5 50.117188   BatchTime 0.326294   LR 0.000294
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [57][   40/  196]   Loss nan   Top1 10.068359   Top5 49.677734   BatchTime 0.300806   LR 0.000290
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [57][   60/  196]   Loss nan   Top1 9.811198   Top5 49.687500   BatchTime 0.283079   LR 0.000286
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [57][   80/  196]   Loss nan   Top1 9.765625   Top5 49.692383   BatchTime 0.274826   LR 0.000282
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [57][  100/  196]   Loss nan   Top1 9.875000   Top5 49.859375   BatchTime 0.270943   LR 0.000277
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [57][  120/  196]   Loss nan   Top1 9.970703   Top5 49.951172   BatchTime 0.267357   LR 0.000273
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [57][  140/  196]   Loss nan   Top1 9.980469   Top5 49.771205   BatchTime 0.264977   LR 0.000269
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [57][  160/  196]   Loss nan   Top1 10.080566   Top5 49.787598   BatchTime 0.263176   LR 0.000265
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [57][  180/  196]   Loss nan   Top1 10.082465   Top5 49.809028   BatchTime 0.259996   LR 0.000261
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.054    Top5: 49.708    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 6.520866   Top1 10.078125   Top5 50.214844   BatchTime 0.112734
INFO - Validation [57][   40/   40]   Loss 6.535842   Top1 10.000000   Top5 50.000000   BatchTime 0.083328
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 6.536
INFO - ==> Sparsity : 0.503
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [57][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0539)
features.15.conv.6 tensor(0.7668)
features.16.conv.0 tensor(0.8211)
features.16.conv.3 tensor(0.0278)
features.16.conv.6 tensor(0.9839)
conv.0 tensor(0.9799)
tensor(1101837.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [58][   20/  196]   Loss nan   Top1 10.136719   Top5 49.003906   BatchTime 0.318124   LR 0.000254
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [58][   40/  196]   Loss nan   Top1 10.117188   Top5 49.394531   BatchTime 0.282710   LR 0.000250
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [58][   60/  196]   Loss nan   Top1 9.947917   Top5 49.778646   BatchTime 0.267216   LR 0.000246
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [58][   80/  196]   Loss nan   Top1 9.794922   Top5 49.848633   BatchTime 0.263526   LR 0.000242
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [58][  100/  196]   Loss nan   Top1 9.847656   Top5 49.667969   BatchTime 0.260955   LR 0.000238
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [58][  120/  196]   Loss nan   Top1 9.915365   Top5 49.886068   BatchTime 0.259063   LR 0.000234
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [58][  140/  196]   Loss nan   Top1 10.019531   Top5 50.086496   BatchTime 0.257394   LR 0.000230
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [58][  160/  196]   Loss nan   Top1 9.992676   Top5 50.073242   BatchTime 0.256733   LR 0.000226
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [58][  180/  196]   Loss nan   Top1 9.956597   Top5 50.000000   BatchTime 0.255921   LR 0.000222
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.902    Top5: 49.922    Loss: nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [58][   20/   40]   Loss 5.985838   Top1 10.078125   Top5 50.214844   BatchTime 0.117923
INFO - Validation [58][   40/   40]   Loss 5.999957   Top1 10.000000   Top5 50.000000   BatchTime 0.087184
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 6.000
INFO - ==> Sparsity : 0.504
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [58][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0542)
features.15.conv.6 tensor(0.7676)
features.16.conv.0 tensor(0.8254)
features.16.conv.3 tensor(0.0270)
features.16.conv.6 tensor(0.9842)
conv.0 tensor(0.9801)
tensor(1102738.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [59][   20/  196]   Loss nan   Top1 10.117188   Top5 50.761719   BatchTime 0.318153   LR 0.000215
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [59][   40/  196]   Loss nan   Top1 9.902344   Top5 50.742188   BatchTime 0.284176   LR 0.000212
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [59][   60/  196]   Loss nan   Top1 10.000000   Top5 50.742188   BatchTime 0.272684   LR 0.000208
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [59][   80/  196]   Loss nan   Top1 9.863281   Top5 50.454102   BatchTime 0.267196   LR 0.000204
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [59][  100/  196]   Loss nan   Top1 9.843750   Top5 50.347656   BatchTime 0.263820   LR 0.000201
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [59][  120/  196]   Loss nan   Top1 9.951172   Top5 50.403646   BatchTime 0.261757   LR 0.000197
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [59][  140/  196]   Loss nan   Top1 10.000000   Top5 50.329241   BatchTime 0.259931   LR 0.000193
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [59][  160/  196]   Loss nan   Top1 9.948730   Top5 50.212402   BatchTime 0.258636   LR 0.000190
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [59][  180/  196]   Loss nan   Top1 9.978299   Top5 50.271267   BatchTime 0.257668   LR 0.000186
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.986    Top5: 50.288    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [59][   20/   40]   Loss 5.790123   Top1 10.078125   Top5 50.214844   BatchTime 0.111352
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
INFO - Validation [59][   40/   40]   Loss 5.803408   Top1 10.000000   Top5 50.000000   BatchTime 0.083134
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 5.803
INFO - ==> Sparsity : 0.504
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [59][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  60
INFO - Training: 50000 samples (256 per mini-batch)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0545)
features.15.conv.6 tensor(0.7687)
features.16.conv.0 tensor(0.8281)
features.16.conv.3 tensor(0.0271)
features.16.conv.6 tensor(0.9846)
conv.0 tensor(0.9809)
tensor(1103855.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [60][   20/  196]   Loss nan   Top1 10.214844   Top5 51.054688   BatchTime 0.320819   LR 0.000180
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [60][   40/  196]   Loss nan   Top1 9.804688   Top5 49.804688   BatchTime 0.283600   LR 0.000176
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [60][   60/  196]   Loss nan   Top1 9.628906   Top5 49.830729   BatchTime 0.272140   LR 0.000173
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [60][   80/  196]   Loss nan   Top1 9.589844   Top5 49.643555   BatchTime 0.266570   LR 0.000169
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [60][  100/  196]   Loss nan   Top1 9.742188   Top5 49.746094   BatchTime 0.263165   LR 0.000166
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [60][  120/  196]   Loss nan   Top1 9.938151   Top5 49.980469   BatchTime 0.268013   LR 0.000162
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [60][  140/  196]   Loss nan   Top1 9.986049   Top5 50.061384   BatchTime 0.269607   LR 0.000159
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [60][  160/  196]   Loss nan   Top1 10.068359   Top5 49.895020   BatchTime 0.270726   LR 0.000156
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [60][  180/  196]   Loss nan   Top1 10.082465   Top5 49.941406   BatchTime 0.270352   LR 0.000152
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 10.046    Top5: 49.874    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [60][   20/   40]   Loss 5.936855   Top1 10.078125   Top5 50.214844   BatchTime 0.115822
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0546)
features.15.conv.6 tensor(0.7701)
features.16.conv.0
INFO - Validation [60][   40/   40]   Loss 5.950592   Top1 10.000000   Top5 50.000000   BatchTime 0.086734
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 5.951
INFO - ==> Sparsity : 0.505
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [60][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  61
features.16.conv.0 tensor(0.8309)
features.16.conv.3 tensor(0.0272)
features.16.conv.6 tensor(0.9844)
conv.0 tensor(0.9810)
tensor(1104433.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [61][   20/  196]   Loss nan   Top1 9.726562   Top5 49.296875   BatchTime 0.315691   LR 0.000147
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [61][   40/  196]   Loss nan   Top1 9.892578   Top5 49.931641   BatchTime 0.293835   LR 0.000143
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [61][   60/  196]   Loss nan   Top1 10.045573   Top5 50.390625   BatchTime 0.288009   LR 0.000140
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [61][   80/  196]   Loss nan   Top1 10.141602   Top5 50.170898   BatchTime 0.285187   LR 0.000137
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [61][  100/  196]   Loss nan   Top1 10.269531   Top5 50.019531   BatchTime 0.284479   LR 0.000134
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [61][  120/  196]   Loss nan   Top1 10.175781   Top5 49.850260   BatchTime 0.286095   LR 0.000131
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [61][  140/  196]   Loss nan   Top1 10.159040   Top5 50.078125   BatchTime 0.287554   LR 0.000128
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [61][  160/  196]   Loss nan   Top1 10.056152   Top5 49.987793   BatchTime 0.284241   LR 0.000125
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [61][  180/  196]   Loss nan   Top1 9.973958   Top5 49.869792   BatchTime 0.283242   LR 0.000122
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - ==> Top1: 9.988    Top5: 49.920    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [61][   20/   40]   Loss 5.816324   Top1 10.078125   Top5 50.214844   BatchTime 0.115766
INFO - Validation [61][   40/   40]   Loss 5.829630   Top1 10.000000   Top5 50.000000   BatchTime 0.084828
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 5.830
INFO - ==> Sparsity : 0.505
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [61][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  62
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0545)
features.15.conv.6 tensor(0.7709)
features.16.conv.0 tensor(0.8330)
features.16.conv.3 tensor(0.0271)
features.16.conv.6 tensor(0.9841)
conv.0 tensor(0.9816)
tensor(1105065.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [62][   20/  196]   Loss nan   Top1 9.101562   Top5 49.589844   BatchTime 0.355218   LR 0.000117
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [62][   40/  196]   Loss nan   Top1 9.707031   Top5 49.755859   BatchTime 0.317314   LR 0.000114
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [62][   60/  196]   Loss nan   Top1 9.986979   Top5 50.182292   BatchTime 0.303477   LR 0.000111
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [62][   80/  196]   Loss nan   Top1 9.892578   Top5 50.395508   BatchTime 0.299379   LR 0.000108
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [62][  100/  196]   Loss nan   Top1 9.988281   Top5 50.367188   BatchTime 0.295930   LR 0.000105
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [62][  120/  196]   Loss nan   Top1 9.882812   Top5 50.260417   BatchTime 0.291031   LR 0.000102
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [62][  140/  196]   Loss nan   Top1 9.888393   Top5 50.209263   BatchTime 0.287563   LR 0.000100
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [62][  160/  196]   Loss nan   Top1 9.924316   Top5 50.246582   BatchTime 0.287594   LR 0.000097
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [62][  180/  196]   Loss nan   Top1 9.852431   Top5 50.232205   BatchTime 0.286353   LR 0.000094
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.846    Top5: 50.192    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [62][   20/   40]   Loss 5.854396   Top1 10.078125   Top5 50.214844   BatchTime 0.111614
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0545)
features.15.conv.6 tensor(0.7717)
features.16.conv.0 tensor(0.8352)
features.16.conv.3 tensor(0.0265)
features.16.conv.6 tensor(0.9840)
conv.0 tensor(0.9818)
tensor(1105547.) 2188896.0
INFO - Validation [62][   40/   40]   Loss 5.867798   Top1 10.000000   Top5 50.000000   BatchTime 0.079396
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 5.868
INFO - ==> Sparsity : 0.505
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [62][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  63
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [63][   20/  196]   Loss nan   Top1 9.824219   Top5 49.863281   BatchTime 0.367574   LR 0.000090
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [63][   40/  196]   Loss nan   Top1 9.882812   Top5 50.253906   BatchTime 0.323503   LR 0.000087
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [63][   60/  196]   Loss nan   Top1 9.856771   Top5 50.332031   BatchTime 0.308712   LR 0.000085
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [63][   80/  196]   Loss nan   Top1 9.829102   Top5 50.244141   BatchTime 0.295260   LR 0.000082
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [63][  100/  196]   Loss nan   Top1 9.847656   Top5 50.156250   BatchTime 0.288540   LR 0.000080
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [63][  120/  196]   Loss nan   Top1 9.765625   Top5 50.195312   BatchTime 0.290199   LR 0.000077
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [63][  140/  196]   Loss nan   Top1 9.818638   Top5 50.212054   BatchTime 0.288695   LR 0.000075
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [63][  160/  196]   Loss nan   Top1 9.782715   Top5 50.048828   BatchTime 0.292056   LR 0.000072
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [63][  180/  196]   Loss nan   Top1 9.741753   Top5 50.060764   BatchTime 0.292627   LR 0.000070
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.784    Top5: 50.094    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [63][   20/   40]   Loss 5.462350   Top1 10.078125   Top5 50.214844   BatchTime 0.108912
INFO - Validation [63][   40/   40]   Loss 5.474957   Top1 10.000000   Top5 50.000000   BatchTime 0.082074
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 5.475
INFO - ==> Sparsity : 0.505
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [63][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  64
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0544)
features.15.conv.6 tensor(0.7722)
features.16.conv.0 tensor(0.8369)
features.16.conv.3 tensor(0.0266)
features.16.conv.6 tensor(0.9840)
conv.0 tensor(0.9820)
tensor(1105988.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [64][   20/  196]   Loss nan   Top1 9.531250   Top5 50.058594   BatchTime 0.342821   LR 0.000066
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [64][   40/  196]   Loss nan   Top1 9.873047   Top5 49.785156   BatchTime 0.307365   LR 0.000064
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [64][   60/  196]   Loss nan   Top1 10.032552   Top5 50.006510   BatchTime 0.288674   LR 0.000062
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [64][   80/  196]   Loss nan   Top1 9.858398   Top5 49.897461   BatchTime 0.285976   LR 0.000059
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [64][  100/  196]   Loss nan   Top1 9.722656   Top5 50.078125   BatchTime 0.280926   LR 0.000057
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [64][  120/  196]   Loss nan   Top1 9.677734   Top5 49.941406   BatchTime 0.279236   LR 0.000055
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [64][  140/  196]   Loss nan   Top1 9.726562   Top5 50.016741   BatchTime 0.277396   LR 0.000053
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [64][  160/  196]   Loss nan   Top1 9.736328   Top5 50.019531   BatchTime 0.275451   LR 0.000051
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [64][  180/  196]   Loss nan   Top1 9.676649   Top5 49.976128   BatchTime 0.276235   LR 0.000049
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.758    Top5: 50.158    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [64][   20/   40]   Loss 5.291993   Top1 10.078125   Top5 50.058594   BatchTime 0.107140
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0546)
features.15.conv.6 tensor(0.7726)
features.16.conv.0 tensor(0.8384)
features.16.conv.3 tensor(0.0266)
features.16.conv.6 tensor(0.9841)
conv.0 tensor(0.9823)
tensor(1106394.) 2188896.0
INFO - Validation [64][   40/   40]   Loss 5.304166   Top1 10.000000   Top5 50.000000   BatchTime 0.078571
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 5.304
INFO - ==> Sparsity : 0.505
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [64][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  65
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [65][   20/  196]   Loss nan   Top1 10.175781   Top5 50.312500   BatchTime 0.319195   LR 0.000046
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [65][   40/  196]   Loss nan   Top1 9.912109   Top5 50.078125   BatchTime 0.290660   LR 0.000044
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [65][   60/  196]   Loss nan   Top1 9.967448   Top5 50.611979   BatchTime 0.288798   LR 0.000042
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [65][   80/  196]   Loss nan   Top1 9.941406   Top5 50.571289   BatchTime 0.282487   LR 0.000040
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [65][  100/  196]   Loss nan   Top1 9.902344   Top5 50.292969   BatchTime 0.275971   LR 0.000039
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [65][  120/  196]   Loss nan   Top1 9.928385   Top5 50.351562   BatchTime 0.273679   LR 0.000037
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [65][  140/  196]   Loss nan   Top1 9.896763   Top5 50.368304   BatchTime 0.272212   LR 0.000035
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [65][  160/  196]   Loss nan   Top1 9.782715   Top5 50.246582   BatchTime 0.271935   LR 0.000033
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [65][  180/  196]   Loss nan   Top1 9.863281   Top5 50.186632   BatchTime 0.271703   LR 0.000032
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.830    Top5: 50.048    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [65][   20/   40]   Loss 5.257781   Top1 10.078125   Top5 50.214844   BatchTime 0.109497
INFO - Validation [65][   40/   40]   Loss 5.270060   Top1 10.000000   Top5 50.000000   BatchTime 0.080255
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0545)
features.15.conv.6 tensor(0.7728)
features.16.conv.0 tensor(0.8398)
features.16.conv.3 tensor(0.0269)
features.16.conv.6 tensor(0.9839)
conv.0 tensor(0.9824)
tensor(1106658.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 5.270
INFO - ==> Sparsity : 0.506
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  66
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [66][   20/  196]   Loss nan   Top1 9.863281   Top5 49.707031   BatchTime 0.322939   LR 0.000029
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [66][   40/  196]   Loss nan   Top1 9.746094   Top5 49.345703   BatchTime 0.312963   LR 0.000028
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [66][   60/  196]   Loss nan   Top1 9.954427   Top5 49.290365   BatchTime 0.306370   LR 0.000026
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [66][   80/  196]   Loss nan   Top1 9.775391   Top5 49.174805   BatchTime 0.300672   LR 0.000025
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [66][  100/  196]   Loss nan   Top1 9.984375   Top5 49.402344   BatchTime 0.299677   LR 0.000023
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [66][  120/  196]   Loss nan   Top1 9.928385   Top5 49.274089   BatchTime 0.296384   LR 0.000022
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [66][  140/  196]   Loss nan   Top1 9.941406   Top5 49.377790   BatchTime 0.292635   LR 0.000021
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [66][  160/  196]   Loss nan   Top1 9.929199   Top5 49.338379   BatchTime 0.291447   LR 0.000019
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [66][  180/  196]   Loss nan   Top1 9.960938   Top5 49.481337   BatchTime 0.287687   LR 0.000018
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - ==> Top1: 9.930    Top5: 49.540    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [66][   20/   40]   Loss 4.994287   Top1 10.078125   Top5 50.058594   BatchTime 0.111289
INFO - Validation [66][   40/   40]   Loss 5.005848   Top1 10.000000   Top5 50.000000   BatchTime 0.082729
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 5.006
INFO - ==> Sparsity : 0.506
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [66][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  67
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0545)
features.15.conv.6 tensor(0.7730)
features.16.conv.0 tensor(0.8403)
features.16.conv.3 tensor(0.0267)
features.16.conv.6 tensor(0.9839)
conv.0 tensor(0.9825)
tensor(1106779.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [67][   20/  196]   Loss nan   Top1 10.175781   Top5 50.683594   BatchTime 0.345054   LR 0.000016
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [67][   40/  196]   Loss nan   Top1 10.146484   Top5 50.791016   BatchTime 0.295381   LR 0.000015
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [67][   60/  196]   Loss nan   Top1 9.973958   Top5 50.481771   BatchTime 0.282881   LR 0.000014
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [67][   80/  196]   Loss nan   Top1 9.921875   Top5 50.590820   BatchTime 0.275739   LR 0.000013
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [67][  100/  196]   Loss nan   Top1 9.957031   Top5 50.570312   BatchTime 0.274759   LR 0.000012
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [67][  120/  196]   Loss nan   Top1 9.902344   Top5 50.458984   BatchTime 0.276809   LR 0.000011
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [67][  140/  196]   Loss nan   Top1 9.891183   Top5 50.337612   BatchTime 0.277718   LR 0.000010
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [67][  160/  196]   Loss nan   Top1 9.934082   Top5 50.473633   BatchTime 0.275695   LR 0.000009
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [67][  180/  196]   Loss nan   Top1 9.943576   Top5 50.501302   BatchTime 0.271060   LR 0.000008
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.922    Top5: 50.420    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
nan
nan
nan
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [67][   20/   40]   Loss 4.913918   Top1 10.078125   Top5 50.214844   BatchTime 0.114182
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0546)
features.15.conv.6 tensor(0.7730)
features.16.conv.0 tensor(0.8405)
features.16.conv.3 tensor(0.0266)
features.16.conv.6 tensor(0.9840)
conv.0 tensor(0.9825)
tensor(1106854.) 2188896.0
INFO - Validation [67][   40/   40]   Loss 4.925227   Top1 10.000000   Top5 50.000000   BatchTime 0.080905
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 4.925
INFO - ==> Sparsity : 0.506
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [67][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  68
INFO - Training: 50000 samples (256 per mini-batch)
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [68][   20/  196]   Loss nan   Top1 10.546875   Top5 50.644531   BatchTime 0.307668   LR 0.000007
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [68][   40/  196]   Loss nan   Top1 10.292969   Top5 50.302734   BatchTime 0.281405   LR 0.000006
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [68][   60/  196]   Loss nan   Top1 9.928385   Top5 50.123698   BatchTime 0.283074   LR 0.000006
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [68][   80/  196]   Loss nan   Top1 9.965820   Top5 50.029297   BatchTime 0.287130   LR 0.000005
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [68][  100/  196]   Loss nan   Top1 9.941406   Top5 50.000000   BatchTime 0.282209   LR 0.000004
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [68][  120/  196]   Loss nan   Top1 9.938151   Top5 49.993490   BatchTime 0.277141   LR 0.000004
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [68][  140/  196]   Loss nan   Top1 9.860491   Top5 50.080915   BatchTime 0.277542   LR 0.000003
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [68][  160/  196]   Loss nan   Top1 9.892578   Top5 50.109863   BatchTime 0.279392   LR 0.000003
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [68][  180/  196]   Loss nan   Top1 9.930556   Top5 50.217014   BatchTime 0.279976   LR 0.000002
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.942    Top5: 50.264    Loss: nan
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
nan
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [68][   20/   40]   Loss 4.921660   Top1 10.078125   Top5 50.214844   BatchTime 0.118761
INFO - Validation [68][   40/   40]   Loss 4.932975   Top1 10.000000   Top5 50.000000   BatchTime 0.083682
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 4.933
INFO - ==> Sparsity : 0.506
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [68][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch  69
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0544)
features.15.conv.6 tensor(0.7730)
features.16.conv.0 tensor(0.8405)
features.16.conv.3 tensor(0.0266)
features.16.conv.6 tensor(0.9840)
conv.0 tensor(0.9825)
tensor(1106869.) 2188896.0
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [69][   20/  196]   Loss nan   Top1 9.160156   Top5 49.550781   BatchTime 0.323881   LR 0.000002
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [69][   40/  196]   Loss nan   Top1 9.472656   Top5 49.316406   BatchTime 0.294102   LR 0.000001
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [69][   60/  196]   Loss nan   Top1 9.648438   Top5 49.661458   BatchTime 0.280779   LR 0.000001
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [69][   80/  196]   Loss nan   Top1 9.755859   Top5 50.014648   BatchTime 0.278778   LR 0.000001
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [69][  100/  196]   Loss nan   Top1 9.660156   Top5 49.796875   BatchTime 0.282232   LR 0.000000
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [69][  120/  196]   Loss nan   Top1 9.824219   Top5 49.853516   BatchTime 0.286516   LR 0.000000
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [69][  140/  196]   Loss nan   Top1 9.891183   Top5 49.946987   BatchTime 0.287537   LR 0.000000
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [69][  160/  196]   Loss nan   Top1 9.897461   Top5 49.873047   BatchTime 0.289331   LR 0.000000
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - Training [69][  180/  196]   Loss nan   Top1 9.932726   Top5 49.854601   BatchTime 0.288608   LR 0.000000
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
nan
INFO - ==> Top1: 9.930    Top5: 49.886    Loss: nan
nan
nan
nan
nan
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [69][   20/   40]   Loss 4.920627   Top1 10.078125   Top5 50.058594   BatchTime 0.108749
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0544)
features.15.conv.6 tensor(0.7730)
features.16.conv.0 tensor(0.8406)
features.16.conv.3 tensor(0.0267)
features.16.conv.6 tensor(0.9840)
conv.0 tensor(0.9825)
tensor(1106876.) 2188896.0
INFO - Validation [69][   40/   40]   Loss 4.931939   Top1 10.000000   Top5 50.000000   BatchTime 0.078147
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 4.932
INFO - ==> Sparsity : 0.506
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
INFO - Scoreboard best 3 ==> Epoch [69][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
INFO - >>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 4.920627   Top1 10.078125   Top5 50.058594   BatchTime 0.113610
INFO - Validation [   40/   40]   Loss 4.931939   Top1 10.000000   Top5 50.000000   BatchTime 0.080688
*************hard_pruning_mode*******************
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 4.932
INFO - ==> Sparsity : 0.000
INFO - Program completed sucessfully ... exiting ...
INFO - >>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [0][   20/  196]   Loss 2.304389   Top1 9.687500   Top5 49.765625   BatchTime 0.323575   LR 0.004999
INFO - Training [0][   40/  196]   Loss 2.304516   Top1 9.902344   Top5 49.511719   BatchTime 0.295062   LR 0.004995
INFO - Training [0][   60/  196]   Loss 2.304449   Top1 10.032552   Top5 49.498698   BatchTime 0.284377   LR 0.004989
INFO - Training [0][   80/  196]   Loss 2.304839   Top1 9.838867   Top5 49.482422   BatchTime 0.272022   LR 0.004980
INFO - Training [0][  100/  196]   Loss 2.304816   Top1 9.925781   Top5 49.585938   BatchTime 0.267142   LR 0.004968
INFO - Training [0][  120/  196]   Loss 2.304689   Top1 9.915365   Top5 49.619141   BatchTime 0.262667   LR 0.004954
INFO - Training [0][  140/  196]   Loss 2.304458   Top1 9.988839   Top5 49.698661   BatchTime 0.257826   LR 0.004938
INFO - Training [0][  160/  196]   Loss 2.304511   Top1 9.978027   Top5 49.614258   BatchTime 0.255326   LR 0.004919
INFO - Training [0][  180/  196]   Loss 2.304524   Top1 9.982639   Top5 49.563802   BatchTime 0.252292   LR 0.004897
INFO - ==> Top1: 9.956    Top5: 49.564    Loss: 2.305
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [0][   20/   40]   Loss 2.687663   Top1 10.078125   Top5 50.058594   BatchTime 0.114524
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0618)
features.15.conv.6 tensor(0.9358)
features.16.conv.0 tensor(0.8718)
features.16.conv.3 tensor(0.0359)
features.16.conv.6 tensor(0.9923)
conv.0 tensor(0.9846)
tensor(1140214.) 2188896.0
INFO - Validation [0][   40/   40]   Loss 2.692103   Top1 10.000000   Top5 50.000000   BatchTime 0.080432
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.692
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [1][   20/  196]   Loss 2.303628   Top1 9.785156   Top5 49.648438   BatchTime 0.307571   LR 0.004853
INFO - Training [1][   40/  196]   Loss 2.303760   Top1 9.716797   Top5 49.687500   BatchTime 0.279079   LR 0.004825
INFO - Training [1][   60/  196]   Loss 2.303579   Top1 9.765625   Top5 50.032552   BatchTime 0.271727   LR 0.004794
INFO - Training [1][   80/  196]   Loss 2.303465   Top1 9.912109   Top5 50.063477   BatchTime 0.262215   LR 0.004761
INFO - Training [1][  100/  196]   Loss 2.303532   Top1 9.746094   Top5 49.906250   BatchTime 0.260052   LR 0.004725
INFO - Training [1][  120/  196]   Loss 2.303488   Top1 9.736328   Top5 49.967448   BatchTime 0.256236   LR 0.004687
INFO - Training [1][  140/  196]   Loss 2.303494   Top1 9.762835   Top5 49.935826   BatchTime 0.255123   LR 0.004647
INFO - Training [1][  160/  196]   Loss 2.303468   Top1 9.702148   Top5 50.007324   BatchTime 0.253569   LR 0.004605
INFO - Training [1][  180/  196]   Loss 2.303507   Top1 9.815538   Top5 50.004340   BatchTime 0.252288   LR 0.004560
INFO - ==> Top1: 9.810    Top5: 49.946    Loss: 2.304
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [1][   20/   40]   Loss 2.825407   Top1 10.078125   Top5 50.195312   BatchTime 0.110605
INFO - Validation [1][   40/   40]   Loss 2.829568   Top1 10.000000   Top5 50.000000   BatchTime 0.082069
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.830
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0609)
features.15.conv.6 tensor(0.9345)
features.16.conv.0 tensor(0.8691)
features.16.conv.3 tensor(0.0375)
features.16.conv.6 tensor(0.9922)
conv.0 tensor(0.9848)
tensor(1139690.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [2][   20/  196]   Loss 2.304554   Top1 8.984375   Top5 50.136719   BatchTime 0.291271   LR 0.004477
INFO - Training [2][   40/  196]   Loss 2.304356   Top1 9.277344   Top5 50.000000   BatchTime 0.263561   LR 0.004426
INFO - Training [2][   60/  196]   Loss 2.303855   Top1 9.381510   Top5 50.247396   BatchTime 0.255377   LR 0.004374
INFO - Training [2][   80/  196]   Loss 2.303803   Top1 9.389648   Top5 50.483398   BatchTime 0.250936   LR 0.004320
INFO - Training [2][  100/  196]   Loss 2.303672   Top1 9.367188   Top5 50.609375   BatchTime 0.250238   LR 0.004264
INFO - Training [2][  120/  196]   Loss 2.303665   Top1 9.401042   Top5 50.458984   BatchTime 0.247364   LR 0.004206
INFO - Training [2][  140/  196]   Loss 2.303615   Top1 9.506138   Top5 50.418527   BatchTime 0.243821   LR 0.004146
INFO - Training [2][  160/  196]   Loss 2.303502   Top1 9.580078   Top5 50.419922   BatchTime 0.242354   LR 0.004085
INFO - Training [2][  180/  196]   Loss 2.303438   Top1 9.680990   Top5 50.481771   BatchTime 0.242959   LR 0.004022
********************pre-trained*****************
INFO - ==> Top1: 9.708    Top5: 50.450    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [2][   20/   40]   Loss 2.868390   Top1 10.078125   Top5 50.195312   BatchTime 0.109567
INFO - Validation [2][   40/   40]   Loss 2.874310   Top1 10.000000   Top5 50.000000   BatchTime 0.081676
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.874
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0608)
features.15.conv.6 tensor(0.9338)
features.16.conv.0 tensor(0.8690)
features.16.conv.3 tensor(0.0378)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9849)
tensor(1139585.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [3][   20/  196]   Loss 2.303479   Top1 10.917969   Top5 49.355469   BatchTime 0.298957   LR 0.003907
INFO - Training [3][   40/  196]   Loss 2.303651   Top1 10.175781   Top5 49.277344   BatchTime 0.278869   LR 0.003840
INFO - Training [3][   60/  196]   Loss 2.303547   Top1 10.013021   Top5 49.127604   BatchTime 0.270558   LR 0.003771
INFO - Training [3][   80/  196]   Loss 2.303338   Top1 10.019531   Top5 49.555664   BatchTime 0.265066   LR 0.003701
INFO - Training [3][  100/  196]   Loss 2.303370   Top1 10.027344   Top5 49.589844   BatchTime 0.259899   LR 0.003630
INFO - Training [3][  120/  196]   Loss 2.303407   Top1 9.951172   Top5 49.547526   BatchTime 0.257940   LR 0.003558
INFO - Training [3][  140/  196]   Loss 2.303386   Top1 9.944196   Top5 49.539621   BatchTime 0.252783   LR 0.003484
INFO - Training [3][  160/  196]   Loss 2.303384   Top1 9.990234   Top5 49.567871   BatchTime 0.251503   LR 0.003410
INFO - Training [3][  180/  196]   Loss 2.303464   Top1 10.000000   Top5 49.600694   BatchTime 0.248874   LR 0.003335
INFO - ==> Top1: 10.018    Top5: 49.676    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 2.747521   Top1 10.078125   Top5 50.195312   BatchTime 0.114026
INFO - Validation [3][   40/   40]   Loss 2.752066   Top1 10.000000   Top5 50.000000   BatchTime 0.084256
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.752
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0609)
features.15.conv.6 tensor(0.9351)
features.16.conv.0 tensor(0.8715)
features.16.conv.3 tensor(0.0389)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9852)
tensor(1140242.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [4][   20/  196]   Loss 2.303261   Top1 9.628906   Top5 50.566406   BatchTime 0.318850   LR 0.003200
INFO - Training [4][   40/  196]   Loss 2.303135   Top1 9.775391   Top5 50.283203   BatchTime 0.284270   LR 0.003122
INFO - Training [4][   60/  196]   Loss 2.303209   Top1 9.863281   Top5 50.292969   BatchTime 0.278505   LR 0.003044
INFO - Training [4][   80/  196]   Loss 2.303196   Top1 9.985352   Top5 50.361328   BatchTime 0.271718   LR 0.002965
INFO - Training [4][  100/  196]   Loss 2.303123   Top1 10.027344   Top5 50.375000   BatchTime 0.265546   LR 0.002886
INFO - Training [4][  120/  196]   Loss 2.303149   Top1 9.951172   Top5 50.253906   BatchTime 0.260714   LR 0.002806
INFO - Training [4][  140/  196]   Loss 2.303098   Top1 10.000000   Top5 50.228795   BatchTime 0.259426   LR 0.002726
INFO - Training [4][  160/  196]   Loss 2.303060   Top1 10.068359   Top5 50.292969   BatchTime 0.256804   LR 0.002646
INFO - Training [4][  180/  196]   Loss 2.303088   Top1 10.125868   Top5 50.199653   BatchTime 0.255593   LR 0.002566
INFO - ==> Top1: 10.096    Top5: 50.178    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [4][   20/   40]   Loss 2.931219   Top1 10.078125   Top5 50.058594   BatchTime 0.116053
INFO - Validation [4][   40/   40]   Loss 2.936154   Top1 10.000000   Top5 50.000000   BatchTime 0.081453
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.936
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0608)
features.15.conv.6 tensor(0.9353)
features.16.conv.0 tensor(0.8710)
features.16.conv.3 tensor(0.0384)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9851)
tensor(1140181.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [5][   20/  196]   Loss 2.303172   Top1 9.433594   Top5 49.941406   BatchTime 0.312656   LR 0.002424
INFO - Training [5][   40/  196]   Loss 2.303705   Top1 9.267578   Top5 48.896484   BatchTime 0.276014   LR 0.002343
INFO - Training [5][   60/  196]   Loss 2.303474   Top1 9.355469   Top5 49.121094   BatchTime 0.266208   LR 0.002263
INFO - Training [5][   80/  196]   Loss 2.303340   Top1 9.433594   Top5 49.638672   BatchTime 0.263287   LR 0.002183
INFO - Training [5][  100/  196]   Loss 2.303246   Top1 9.464844   Top5 49.652344   BatchTime 0.260202   LR 0.002104
INFO - Training [5][  120/  196]   Loss 2.303274   Top1 9.449870   Top5 49.726562   BatchTime 0.256998   LR 0.002024
INFO - Training [5][  140/  196]   Loss 2.303246   Top1 9.522879   Top5 49.726562   BatchTime 0.253591   LR 0.001946
INFO - Training [5][  160/  196]   Loss 2.303208   Top1 9.575195   Top5 49.724121   BatchTime 0.256950   LR 0.001868
INFO - Training [5][  180/  196]   Loss 2.303238   Top1 9.565972   Top5 49.680990   BatchTime 0.257918   LR 0.001790
INFO - ==> Top1: 9.668    Top5: 49.704    Loss: 2.303
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [5][   20/   40]   Loss 2.714660   Top1 10.078125   Top5 50.214844   BatchTime 0.116896
INFO - Validation [5][   40/   40]   Loss 2.718793   Top1 10.000000   Top5 50.000000   BatchTime 0.085341
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.719
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0613)
features.15.conv.6 tensor(0.9337)
features.16.conv.0 tensor(0.8726)
features.16.conv.3 tensor(0.0398)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9853)
tensor(1140285.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [6][   20/  196]   Loss 2.302847   Top1 10.292969   Top5 49.511719   BatchTime 0.316578   LR 0.001655
INFO - Training [6][   40/  196]   Loss 2.302952   Top1 9.960938   Top5 50.029297   BatchTime 0.281441   LR 0.001580
INFO - Training [6][   60/  196]   Loss 2.302808   Top1 10.143229   Top5 50.149740   BatchTime 0.267694   LR 0.001506
INFO - Training [6][   80/  196]   Loss 2.302886   Top1 10.161133   Top5 50.131836   BatchTime 0.259734   LR 0.001432
INFO - Training [6][  100/  196]   Loss 2.302960   Top1 10.058594   Top5 50.132812   BatchTime 0.255607   LR 0.001360
INFO - Training [6][  120/  196]   Loss 2.302951   Top1 10.120443   Top5 49.964193   BatchTime 0.254348   LR 0.001289
INFO - Training [6][  140/  196]   Loss 2.302921   Top1 10.142299   Top5 49.938616   BatchTime 0.252929   LR 0.001220
INFO - Training [6][  160/  196]   Loss 2.302961   Top1 10.085449   Top5 49.902344   BatchTime 0.253466   LR 0.001151
INFO - Training [6][  180/  196]   Loss 2.302936   Top1 10.101997   Top5 49.876302   BatchTime 0.250217   LR 0.001084
INFO - ==> Top1: 10.108    Top5: 49.856    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [6][   20/   40]   Loss 2.749345   Top1 10.078125   Top5 50.214844   BatchTime 0.114006
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0612)
features.15.conv.6 tensor(0.9333)
features.16.conv.0 tensor(0.8727)
features.16.conv.3 tensor(0.0391)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9853)
tensor(1140245.) 2188896.0
INFO - Validation [6][   40/   40]   Loss 2.753932   Top1 10.000000   Top5 50.000000   BatchTime 0.083132
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.754
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [7][   20/  196]   Loss 2.302688   Top1 9.824219   Top5 49.296875   BatchTime 0.304337   LR 0.000969
INFO - Training [7][   40/  196]   Loss 2.302655   Top1 10.048828   Top5 49.824219   BatchTime 0.270300   LR 0.000907
INFO - Training [7][   60/  196]   Loss 2.302618   Top1 9.980469   Top5 49.720052   BatchTime 0.260783   LR 0.000845
INFO - Training [7][   80/  196]   Loss 2.302717   Top1 10.043945   Top5 49.648438   BatchTime 0.258156   LR 0.000786
INFO - Training [7][  100/  196]   Loss 2.302753   Top1 9.988281   Top5 49.582031   BatchTime 0.256950   LR 0.000728
INFO - Training [7][  120/  196]   Loss 2.302685   Top1 10.094401   Top5 49.817708   BatchTime 0.254244   LR 0.000673
INFO - Training [7][  140/  196]   Loss 2.302745   Top1 10.033482   Top5 49.740513   BatchTime 0.254666   LR 0.000619
INFO - Training [7][  160/  196]   Loss 2.302717   Top1 10.019531   Top5 49.787598   BatchTime 0.254993   LR 0.000567
INFO - Training [7][  180/  196]   Loss 2.302752   Top1 10.019531   Top5 49.763455   BatchTime 0.254372   LR 0.000517
INFO - ==> Top1: 10.038    Top5: 49.756    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 2.815656   Top1 10.078125   Top5 50.214844   BatchTime 0.120514
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0609)
features.15.conv.6 tensor(0.9334)
features.16.conv.0 tensor(0.8731)
features.16.conv.3 tensor(0.0392)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9853)
tensor(1140304.) 2188896.0
INFO - Validation [7][   40/   40]   Loss 2.820296   Top1 10.000000   Top5 50.000000   BatchTime 0.084721
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.820
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [8][   20/  196]   Loss 2.302965   Top1 9.609375   Top5 49.882812   BatchTime 0.299313   LR 0.000434
INFO - Training [8][   40/  196]   Loss 2.302933   Top1 9.824219   Top5 49.853516   BatchTime 0.274235   LR 0.000389
INFO - Training [8][   60/  196]   Loss 2.302832   Top1 9.739583   Top5 49.615885   BatchTime 0.276830   LR 0.000347
INFO - Training [8][   80/  196]   Loss 2.302769   Top1 9.921875   Top5 49.804688   BatchTime 0.264148   LR 0.000308
INFO - Training [8][  100/  196]   Loss 2.302712   Top1 9.988281   Top5 49.968750   BatchTime 0.261768   LR 0.000270
INFO - Training [8][  120/  196]   Loss 2.302712   Top1 10.019531   Top5 49.915365   BatchTime 0.256674   LR 0.000235
INFO - Training [8][  140/  196]   Loss 2.302734   Top1 10.066964   Top5 49.966518   BatchTime 0.253691   LR 0.000202
INFO - Training [8][  160/  196]   Loss 2.302766   Top1 9.980469   Top5 50.014648   BatchTime 0.252735   LR 0.000172
INFO - Training [8][  180/  196]   Loss 2.302752   Top1 9.995660   Top5 50.010851   BatchTime 0.248932   LR 0.000143
INFO - ==> Top1: 9.978    Top5: 49.994    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 2.813715   Top1 10.078125   Top5 50.214844   BatchTime 0.116014
INFO - Validation [8][   40/   40]   Loss 2.818641   Top1 10.000000   Top5 50.000000   BatchTime 0.084679
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0609)
features.15.conv.6 tensor(0.9331)
features.16.conv.0 tensor(0.8730)
features.16.conv.3 tensor(0.0391)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9853)
tensor(1140239.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.819
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [9][   20/  196]   Loss 2.302699   Top1 10.605469   Top5 50.312500   BatchTime 0.291415   LR 0.000100
INFO - Training [9][   40/  196]   Loss 2.302577   Top1 10.507812   Top5 50.166016   BatchTime 0.256631   LR 0.000079
INFO - Training [9][   60/  196]   Loss 2.302550   Top1 10.247396   Top5 50.045573   BatchTime 0.254879   LR 0.000060
INFO - Training [9][   80/  196]   Loss 2.302529   Top1 10.224609   Top5 50.307617   BatchTime 0.260095   LR 0.000044
INFO - Training [9][  100/  196]   Loss 2.302541   Top1 10.273438   Top5 50.269531   BatchTime 0.258651   LR 0.000030
INFO - Training [9][  120/  196]   Loss 2.302570   Top1 10.198568   Top5 50.133464   BatchTime 0.258403   LR 0.000019
INFO - Training [9][  140/  196]   Loss 2.302624   Top1 10.117188   Top5 49.991629   BatchTime 0.256721   LR 0.000010
INFO - Training [9][  160/  196]   Loss 2.302619   Top1 10.080566   Top5 50.151367   BatchTime 0.253497   LR 0.000004
INFO - Training [9][  180/  196]   Loss 2.302680   Top1 9.963108   Top5 50.062934   BatchTime 0.254197   LR 0.000001
********************pre-trained*****************
INFO - ==> Top1: 9.992    Top5: 50.088    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [9][   20/   40]   Loss 2.856546   Top1 10.078125   Top5 50.214844   BatchTime 0.120908
INFO - Validation [9][   40/   40]   Loss 2.861621   Top1 10.000000   Top5 50.000000   BatchTime 0.087918
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.862
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0610)
features.15.conv.6 tensor(0.9333)
features.16.conv.0 tensor(0.8730)
features.16.conv.3 tensor(0.0391)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9852)
tensor(1140227.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [10][   20/  196]   Loss 2.302634   Top1 10.468750   Top5 49.199219   BatchTime 0.362996   LR 0.002500
INFO - Training [10][   40/  196]   Loss 2.302719   Top1 10.439453   Top5 49.687500   BatchTime 0.314578   LR 0.002499
INFO - Training [10][   60/  196]   Loss 2.302843   Top1 10.247396   Top5 49.459635   BatchTime 0.293279   LR 0.002499
INFO - Training [10][   80/  196]   Loss 2.302796   Top1 10.249023   Top5 49.677734   BatchTime 0.283259   LR 0.002497
INFO - Training [10][  100/  196]   Loss 2.302769   Top1 10.312500   Top5 49.816406   BatchTime 0.272793   LR 0.002496
INFO - Training [10][  120/  196]   Loss 2.302799   Top1 10.325521   Top5 49.820964   BatchTime 0.266749   LR 0.002494
INFO - Training [10][  140/  196]   Loss 2.302892   Top1 10.267857   Top5 49.587054   BatchTime 0.265145   LR 0.002492
INFO - Training [10][  160/  196]   Loss 2.302899   Top1 10.180664   Top5 49.543457   BatchTime 0.261691   LR 0.002490
INFO - Training [10][  180/  196]   Loss 2.302864   Top1 10.201823   Top5 49.628906   BatchTime 0.261779   LR 0.002487
INFO - ==> Top1: 10.216    Top5: 49.628    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [10][   20/   40]   Loss 2.671312   Top1 10.078125   Top5 50.058594   BatchTime 0.118955
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0624)
features.15.conv.6 tensor(0.9324)
features.16.conv.0 tensor(0.8730)
features.16.conv.3 tensor(0.0391)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9855)
tensor(1140223.) 2188896.0
INFO - Validation [10][   40/   40]   Loss 2.675713   Top1 10.000000   Top5 50.000000   BatchTime 0.084229
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.676
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [11][   20/  196]   Loss 2.302797   Top1 10.078125   Top5 49.589844   BatchTime 0.328318   LR 0.002481
INFO - Training [11][   40/  196]   Loss 2.302776   Top1 10.234375   Top5 49.443359   BatchTime 0.300715   LR 0.002478
INFO - Training [11][   60/  196]   Loss 2.302904   Top1 10.240885   Top5 49.654948   BatchTime 0.289062   LR 0.002474
INFO - Training [11][   80/  196]   Loss 2.302981   Top1 9.931641   Top5 49.697266   BatchTime 0.278880   LR 0.002470
INFO - Training [11][  100/  196]   Loss 2.302925   Top1 9.906250   Top5 49.671875   BatchTime 0.272357   LR 0.002465
INFO - Training [11][  120/  196]   Loss 2.302968   Top1 9.788411   Top5 49.531250   BatchTime 0.268075   LR 0.002460
INFO - Training [11][  140/  196]   Loss 2.302969   Top1 9.849330   Top5 49.536830   BatchTime 0.266151   LR 0.002455
INFO - Training [11][  160/  196]   Loss 2.302946   Top1 9.899902   Top5 49.597168   BatchTime 0.263861   LR 0.002450
INFO - Training [11][  180/  196]   Loss 2.302995   Top1 9.889323   Top5 49.563802   BatchTime 0.262334   LR 0.002444
INFO - ==> Top1: 9.918    Top5: 49.526    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [11][   20/   40]   Loss 2.613989   Top1 10.078125   Top5 50.214844   BatchTime 0.118251
INFO - Validation [11][   40/   40]   Loss 2.617917   Top1 10.000000   Top5 50.000000   BatchTime 0.086233
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.618
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0619)
features.15.conv.6 tensor(0.9362)
features.16.conv.0 tensor(0.8732)
features.16.conv.3 tensor(0.0402)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9855)
tensor(1140848.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [12][   20/  196]   Loss 2.302981   Top1 10.703125   Top5 50.292969   BatchTime 0.355247   LR 0.002433
INFO - Training [12][   40/  196]   Loss 2.302906   Top1 10.390625   Top5 50.312500   BatchTime 0.297108   LR 0.002426
INFO - Training [12][   60/  196]   Loss 2.303071   Top1 10.338542   Top5 50.000000   BatchTime 0.279898   LR 0.002419
INFO - Training [12][   80/  196]   Loss 2.303146   Top1 10.043945   Top5 49.848633   BatchTime 0.271094   LR 0.002412
INFO - Training [12][  100/  196]   Loss 2.303137   Top1 9.949219   Top5 49.734375   BatchTime 0.268439   LR 0.002404
INFO - Training [12][  120/  196]   Loss 2.303155   Top1 9.889323   Top5 49.518229   BatchTime 0.262327   LR 0.002396
INFO - Training [12][  140/  196]   Loss 2.303179   Top1 9.944196   Top5 49.536830   BatchTime 0.260495   LR 0.002388
INFO - Training [12][  160/  196]   Loss 2.303194   Top1 9.851074   Top5 49.455566   BatchTime 0.259417   LR 0.002380
INFO - Training [12][  180/  196]   Loss 2.303174   Top1 9.913194   Top5 49.513889   BatchTime 0.256543   LR 0.002371
********************pre-trained*****************
INFO - ==> Top1: 9.872    Top5: 49.534    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 2.662041   Top1 10.078125   Top5 50.214844   BatchTime 0.136484
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0623)
features.15.conv.6 tensor(0.9356)
features.16.conv.0 tensor(0.8739)
features.16.conv.3 tensor(0.0397)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9855)
tensor(1140854.) 2188896.0
INFO - Validation [12][   40/   40]   Loss 2.666380   Top1 10.000000   Top5 50.000000   BatchTime 0.094072
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.666
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [13][   20/  196]   Loss 2.303118   Top1 9.570312   Top5 49.433594   BatchTime 0.290708   LR 0.002355
INFO - Training [13][   40/  196]   Loss 2.303148   Top1 9.775391   Top5 49.765625   BatchTime 0.267158   LR 0.002345
INFO - Training [13][   60/  196]   Loss 2.303139   Top1 9.837240   Top5 49.615885   BatchTime 0.260678   LR 0.002336
INFO - Training [13][   80/  196]   Loss 2.303111   Top1 9.804688   Top5 49.516602   BatchTime 0.257567   LR 0.002325
INFO - Training [13][  100/  196]   Loss 2.303002   Top1 10.015625   Top5 49.578125   BatchTime 0.254384   LR 0.002315
INFO - Training [13][  120/  196]   Loss 2.302985   Top1 9.996745   Top5 49.560547   BatchTime 0.252169   LR 0.002304
INFO - Training [13][  140/  196]   Loss 2.303001   Top1 9.921875   Top5 49.534040   BatchTime 0.251296   LR 0.002293
INFO - Training [13][  160/  196]   Loss 2.302978   Top1 9.929199   Top5 49.511719   BatchTime 0.250835   LR 0.002282
INFO - Training [13][  180/  196]   Loss 2.302963   Top1 9.887153   Top5 49.592014   BatchTime 0.250223   LR 0.002271
********************pre-trained*****************
INFO - ==> Top1: 9.932    Top5: 49.696    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [13][   20/   40]   Loss 2.777978   Top1 10.078125   Top5 50.214844   BatchTime 0.120895
INFO - Validation [13][   40/   40]   Loss 2.782532   Top1 10.000000   Top5 50.000000   BatchTime 0.085196
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.783
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0619)
features.15.conv.6 tensor(0.9356)
features.16.conv.0 tensor(0.8731)
features.16.conv.3 tensor(0.0389)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9852)
tensor(1140580.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [14][   20/  196]   Loss 2.303220   Top1 9.628906   Top5 49.687500   BatchTime 0.300031   LR 0.002250
INFO - Training [14][   40/  196]   Loss 2.303132   Top1 10.185547   Top5 49.296875   BatchTime 0.269254   LR 0.002238
INFO - Training [14][   60/  196]   Loss 2.303141   Top1 10.045573   Top5 49.401042   BatchTime 0.262593   LR 0.002225
INFO - Training [14][   80/  196]   Loss 2.303099   Top1 9.970703   Top5 49.355469   BatchTime 0.259058   LR 0.002213
INFO - Training [14][  100/  196]   Loss 2.303016   Top1 10.042969   Top5 49.320312   BatchTime 0.254568   LR 0.002200
INFO - Training [14][  120/  196]   Loss 2.303020   Top1 10.120443   Top5 49.417318   BatchTime 0.254935   LR 0.002186
INFO - Training [14][  140/  196]   Loss 2.302993   Top1 10.153460   Top5 49.486607   BatchTime 0.255303   LR 0.002173
INFO - Training [14][  160/  196]   Loss 2.302981   Top1 10.090332   Top5 49.538574   BatchTime 0.255370   LR 0.002159
INFO - Training [14][  180/  196]   Loss 2.303001   Top1 10.071615   Top5 49.474826   BatchTime 0.252904   LR 0.002145
INFO - ==> Top1: 10.118    Top5: 49.512    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 2.578017   Top1 10.078125   Top5 50.058594   BatchTime 0.123042
INFO - Validation [14][   40/   40]   Loss 2.581469   Top1 10.000000   Top5 50.000000   BatchTime 0.088101
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.581
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0600)
features.15.conv.6 tensor(0.9317)
features.16.conv.0 tensor(0.8681)
features.16.conv.3 tensor(0.0399)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9852)
tensor(1139179.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [15][   20/  196]   Loss 2.302806   Top1 9.589844   Top5 49.453125   BatchTime 0.311675   LR 0.002120
INFO - Training [15][   40/  196]   Loss 2.303058   Top1 9.658203   Top5 49.130859   BatchTime 0.269711   LR 0.002106
INFO - Training [15][   60/  196]   Loss 2.303067   Top1 9.986979   Top5 49.427083   BatchTime 0.260042   LR 0.002091
INFO - Training [15][   80/  196]   Loss 2.303005   Top1 10.019531   Top5 49.658203   BatchTime 0.260653   LR 0.002076
INFO - Training [15][  100/  196]   Loss 2.302981   Top1 9.941406   Top5 49.648438   BatchTime 0.255454   LR 0.002061
INFO - Training [15][  120/  196]   Loss 2.303024   Top1 9.830729   Top5 49.534505   BatchTime 0.254725   LR 0.002045
INFO - Training [15][  140/  196]   Loss 2.303002   Top1 9.807478   Top5 49.436384   BatchTime 0.252199   LR 0.002030
INFO - Training [15][  160/  196]   Loss 2.302958   Top1 9.865723   Top5 49.460449   BatchTime 0.250350   LR 0.002014
INFO - Training [15][  180/  196]   Loss 2.302955   Top1 9.848090   Top5 49.429253   BatchTime 0.250004   LR 0.001998
INFO - ==> Top1: 9.808    Top5: 49.352    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [15][   20/   40]   Loss 2.594021   Top1 10.078125   Top5 50.214844   BatchTime 0.129832
INFO - Validation [15][   40/   40]   Loss 2.597991   Top1 10.000000   Top5 50.000000   BatchTime 0.093591
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.598
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0602)
features.15.conv.6 tensor(0.9314)
features.16.conv.0 tensor(0.8672)
features.16.conv.3 tensor(0.0398)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9851)
tensor(1139007.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [16][   20/  196]   Loss 2.302361   Top1 10.097656   Top5 50.605469   BatchTime 0.322773   LR 0.001969
INFO - Training [16][   40/  196]   Loss 2.302720   Top1 10.029297   Top5 50.136719   BatchTime 0.289570   LR 0.001953
INFO - Training [16][   60/  196]   Loss 2.302861   Top1 9.752604   Top5 50.104167   BatchTime 0.275442   LR 0.001936
INFO - Training [16][   80/  196]   Loss 2.302881   Top1 9.565430   Top5 50.146484   BatchTime 0.268909   LR 0.001919
INFO - Training [16][  100/  196]   Loss 2.302910   Top1 9.617188   Top5 50.007812   BatchTime 0.262977   LR 0.001902
INFO - Training [16][  120/  196]   Loss 2.302932   Top1 9.694010   Top5 49.915365   BatchTime 0.260608   LR 0.001885
INFO - Training [16][  140/  196]   Loss 2.302934   Top1 9.673549   Top5 49.760045   BatchTime 0.260986   LR 0.001867
INFO - Training [16][  160/  196]   Loss 2.302972   Top1 9.685059   Top5 49.643555   BatchTime 0.259553   LR 0.001850
INFO - Training [16][  180/  196]   Loss 2.302928   Top1 9.676649   Top5 49.817708   BatchTime 0.255042   LR 0.001832
INFO - ==> Top1: 9.648    Top5: 49.918    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [16][   20/   40]   Loss 2.626808   Top1 10.078125   Top5 50.214844   BatchTime 0.123452
INFO - Validation [16][   40/   40]   Loss 2.630941   Top1 10.000000   Top5 50.000000   BatchTime 0.084319
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.631
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0600)
features.15.conv.6 tensor(0.9310)
features.16.conv.0 tensor(0.8661)
features.16.conv.3 tensor(0.0400)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9852)
tensor(1138797.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [17][   20/  196]   Loss 2.303010   Top1 9.355469   Top5 50.468750   BatchTime 0.308035   LR 0.001800
INFO - Training [17][   40/  196]   Loss 2.302896   Top1 9.824219   Top5 50.224609   BatchTime 0.273071   LR 0.001782
INFO - Training [17][   60/  196]   Loss 2.302871   Top1 9.889323   Top5 50.149740   BatchTime 0.258065   LR 0.001764
INFO - Training [17][   80/  196]   Loss 2.302947   Top1 9.682617   Top5 50.039062   BatchTime 0.255079   LR 0.001746
INFO - Training [17][  100/  196]   Loss 2.302978   Top1 9.726562   Top5 49.878906   BatchTime 0.257769   LR 0.001727
INFO - Training [17][  120/  196]   Loss 2.302973   Top1 9.736328   Top5 49.687500   BatchTime 0.254762   LR 0.001708
INFO - Training [17][  140/  196]   Loss 2.302994   Top1 9.771205   Top5 49.676339   BatchTime 0.253542   LR 0.001690
INFO - Training [17][  160/  196]   Loss 2.302985   Top1 9.819336   Top5 49.567871   BatchTime 0.252772   LR 0.001671
INFO - Training [17][  180/  196]   Loss 2.302912   Top1 9.934896   Top5 49.670139   BatchTime 0.249216   LR 0.001652
INFO - ==> Top1: 9.850    Top5: 49.664    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [17][   20/   40]   Loss 2.594315   Top1 10.078125   Top5 50.214844   BatchTime 0.126709
INFO - Validation [17][   40/   40]   Loss 2.598484   Top1 10.000000   Top5 50.000000   BatchTime 0.091402
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.598
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0602)
features.15.conv.6 tensor(0.9315)
features.16.conv.0 tensor(0.8662)
features.16.conv.3 tensor(0.0396)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9854)
tensor(1138942.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [18][   20/  196]   Loss 2.302340   Top1 10.625000   Top5 51.035156   BatchTime 0.310638   LR 0.001618
INFO - Training [18][   40/  196]   Loss 2.302508   Top1 10.263672   Top5 50.673828   BatchTime 0.276033   LR 0.001599
INFO - Training [18][   60/  196]   Loss 2.302511   Top1 10.091146   Top5 50.846354   BatchTime 0.267855   LR 0.001579
INFO - Training [18][   80/  196]   Loss 2.302571   Top1 10.063477   Top5 50.605469   BatchTime 0.264190   LR 0.001560
INFO - Training [18][  100/  196]   Loss 2.302581   Top1 10.042969   Top5 50.523438   BatchTime 0.262845   LR 0.001540
INFO - Training [18][  120/  196]   Loss 2.302645   Top1 10.065104   Top5 50.445964   BatchTime 0.260759   LR 0.001521
INFO - Training [18][  140/  196]   Loss 2.302666   Top1 10.039062   Top5 50.471540   BatchTime 0.257669   LR 0.001501
INFO - Training [18][  160/  196]   Loss 2.302693   Top1 10.041504   Top5 50.385742   BatchTime 0.255338   LR 0.001482
INFO - Training [18][  180/  196]   Loss 2.302735   Top1 9.934896   Top5 50.312500   BatchTime 0.254362   LR 0.001462
INFO - ==> Top1: 9.916    Top5: 50.216    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [18][   20/   40]   Loss 2.546859   Top1 10.078125   Top5 49.980469   BatchTime 0.123831
INFO - Validation [18][   40/   40]   Loss 2.550109   Top1 10.000000   Top5 50.000000   BatchTime 0.089219
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0602)
features.15.conv.6 tensor(0.9311)
features.16.conv.0 tensor(0.8654)
features.16.conv.3 tensor(0.0396)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9853)
tensor(1138739.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.550
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [19][   20/  196]   Loss 2.302935   Top1 9.609375   Top5 49.726562   BatchTime 0.317582   LR 0.001427
INFO - Training [19][   40/  196]   Loss 2.302770   Top1 10.039062   Top5 49.824219   BatchTime 0.280177   LR 0.001407
INFO - Training [19][   60/  196]   Loss 2.302848   Top1 9.954427   Top5 50.136719   BatchTime 0.269121   LR 0.001387
INFO - Training [19][   80/  196]   Loss 2.302844   Top1 9.760742   Top5 49.941406   BatchTime 0.263434   LR 0.001367
INFO - Training [19][  100/  196]   Loss 2.302756   Top1 9.804688   Top5 50.144531   BatchTime 0.260393   LR 0.001347
INFO - Training [19][  120/  196]   Loss 2.302747   Top1 9.850260   Top5 50.022786   BatchTime 0.255086   LR 0.001327
INFO - Training [19][  140/  196]   Loss 2.302756   Top1 9.849330   Top5 49.963728   BatchTime 0.252956   LR 0.001307
INFO - Training [19][  160/  196]   Loss 2.302773   Top1 9.831543   Top5 49.973145   BatchTime 0.249076   LR 0.001287
INFO - Training [19][  180/  196]   Loss 2.302787   Top1 9.839410   Top5 49.893663   BatchTime 0.249116   LR 0.001266
INFO - ==> Top1: 9.808    Top5: 49.908    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [19][   20/   40]   Loss 2.538703   Top1 10.078125   Top5 50.214844   BatchTime 0.123307
INFO - Validation [19][   40/   40]   Loss 2.542089   Top1 10.000000   Top5 50.000000   BatchTime 0.086439
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.542
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0598)
features.15.conv.6 tensor(0.9316)
features.16.conv.0 tensor(0.8655)
features.16.conv.3 tensor(0.0396)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9854)
tensor(1138861.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [20][   20/  196]   Loss 2.302785   Top1 9.902344   Top5 49.433594   BatchTime 0.300783   LR 0.001231
INFO - Training [20][   40/  196]   Loss 2.302811   Top1 9.921875   Top5 49.482422   BatchTime 0.261495   LR 0.001211
INFO - Training [20][   60/  196]   Loss 2.302742   Top1 10.429688   Top5 49.609375   BatchTime 0.255960   LR 0.001191
INFO - Training [20][   80/  196]   Loss 2.302698   Top1 10.288086   Top5 49.731445   BatchTime 0.254715   LR 0.001171
INFO - Training [20][  100/  196]   Loss 2.302723   Top1 10.253906   Top5 49.605469   BatchTime 0.251622   LR 0.001151
INFO - Training [20][  120/  196]   Loss 2.302708   Top1 10.166016   Top5 49.625651   BatchTime 0.249077   LR 0.001131
INFO - Training [20][  140/  196]   Loss 2.302738   Top1 10.139509   Top5 49.623326   BatchTime 0.250069   LR 0.001111
INFO - Training [20][  160/  196]   Loss 2.302730   Top1 10.222168   Top5 49.602051   BatchTime 0.249578   LR 0.001091
INFO - Training [20][  180/  196]   Loss 2.302719   Top1 10.240885   Top5 49.548611   BatchTime 0.250675   LR 0.001071
INFO - ==> Top1: 10.194    Top5: 49.534    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [20][   20/   40]   Loss 2.591823   Top1 10.078125   Top5 50.214844   BatchTime 0.129141
INFO - Validation [20][   40/   40]   Loss 2.595702   Top1 10.000000   Top5 50.000000   BatchTime 0.088251
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.596
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0602)
features.15.conv.6 tensor(0.9288)
features.16.conv.0 tensor(0.8660)
features.16.conv.3 tensor(0.0404)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9853)
tensor(1138468.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [21][   20/  196]   Loss 2.302928   Top1 9.570312   Top5 49.023438   BatchTime 0.340071   LR 0.001036
INFO - Training [21][   40/  196]   Loss 2.302790   Top1 10.029297   Top5 49.042969   BatchTime 0.293549   LR 0.001016
INFO - Training [21][   60/  196]   Loss 2.302654   Top1 10.227865   Top5 49.746094   BatchTime 0.279865   LR 0.000996
INFO - Training [21][   80/  196]   Loss 2.302682   Top1 10.205078   Top5 49.594727   BatchTime 0.271402   LR 0.000976
INFO - Training [21][  100/  196]   Loss 2.302757   Top1 10.152344   Top5 49.503906   BatchTime 0.268712   LR 0.000957
INFO - Training [21][  120/  196]   Loss 2.302710   Top1 10.087891   Top5 49.583333   BatchTime 0.263508   LR 0.000937
INFO - Training [21][  140/  196]   Loss 2.302740   Top1 10.013951   Top5 49.528460   BatchTime 0.260550   LR 0.000918
INFO - Training [21][  160/  196]   Loss 2.302731   Top1 9.980469   Top5 49.570312   BatchTime 0.259384   LR 0.000899
INFO - Training [21][  180/  196]   Loss 2.302737   Top1 9.939236   Top5 49.476997   BatchTime 0.259094   LR 0.000879
INFO - ==> Top1: 9.920    Top5: 49.468    Loss: 2.303
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [21][   20/   40]   Loss 2.581823   Top1 10.078125   Top5 50.058594   BatchTime 0.125206
INFO - Validation [21][   40/   40]   Loss 2.585696   Top1 10.000000   Top5 50.000000   BatchTime 0.090265
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.586
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0603)
features.15.conv.6 tensor(0.9286)
features.16.conv.0 tensor(0.8663)
features.16.conv.3 tensor(0.0402)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9852)
tensor(1138479.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [22][   20/  196]   Loss 2.302719   Top1 9.863281   Top5 49.921875   BatchTime 0.333317   LR 0.000846
INFO - Training [22][   40/  196]   Loss 2.302845   Top1 9.482422   Top5 49.423828   BatchTime 0.287456   LR 0.000827
INFO - Training [22][   60/  196]   Loss 2.302712   Top1 9.752604   Top5 49.654948   BatchTime 0.271700   LR 0.000808
INFO - Training [22][   80/  196]   Loss 2.302698   Top1 9.750977   Top5 49.648438   BatchTime 0.263244   LR 0.000789
INFO - Training [22][  100/  196]   Loss 2.302674   Top1 9.695312   Top5 49.625000   BatchTime 0.257283   LR 0.000770
INFO - Training [22][  120/  196]   Loss 2.302718   Top1 9.687500   Top5 49.541016   BatchTime 0.253642   LR 0.000752
INFO - Training [22][  140/  196]   Loss 2.302709   Top1 9.681920   Top5 49.581473   BatchTime 0.254070   LR 0.000734
INFO - Training [22][  160/  196]   Loss 2.302723   Top1 9.685059   Top5 49.482422   BatchTime 0.253525   LR 0.000715
INFO - Training [22][  180/  196]   Loss 2.302753   Top1 9.635417   Top5 49.433594   BatchTime 0.250695   LR 0.000697
INFO - ==> Top1: 9.648    Top5: 49.560    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [22][   20/   40]   Loss 2.555123   Top1 10.078125   Top5 50.214844   BatchTime 0.129106
INFO - Validation [22][   40/   40]   Loss 2.558773   Top1 10.000000   Top5 50.000000   BatchTime 0.090234
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.559
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9284)
features.16.conv.0 tensor(0.8658)
features.16.conv.3 tensor(0.0411)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9853)
tensor(1138401.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [23][   20/  196]   Loss 2.302740   Top1 9.824219   Top5 49.628906   BatchTime 0.294717   LR 0.000666
INFO - Training [23][   40/  196]   Loss 2.302582   Top1 10.332031   Top5 49.335938   BatchTime 0.262463   LR 0.000648
INFO - Training [23][   60/  196]   Loss 2.302700   Top1 10.162760   Top5 49.414062   BatchTime 0.251990   LR 0.000630
INFO - Training [23][   80/  196]   Loss 2.302595   Top1 10.175781   Top5 49.707031   BatchTime 0.252080   LR 0.000613
INFO - Training [23][  100/  196]   Loss 2.302629   Top1 10.062500   Top5 49.781250   BatchTime 0.248900   LR 0.000596
INFO - Training [23][  120/  196]   Loss 2.302682   Top1 10.061849   Top5 49.746094   BatchTime 0.248930   LR 0.000579
INFO - Training [23][  140/  196]   Loss 2.302668   Top1 10.136719   Top5 49.799107   BatchTime 0.248894   LR 0.000562
INFO - Training [23][  160/  196]   Loss 2.302691   Top1 10.100098   Top5 49.763184   BatchTime 0.246849   LR 0.000545
INFO - Training [23][  180/  196]   Loss 2.302665   Top1 10.041233   Top5 49.991319   BatchTime 0.244453   LR 0.000529
INFO - ==> Top1: 10.044    Top5: 49.964    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [23][   20/   40]   Loss 2.565373   Top1 10.078125   Top5 50.214844   BatchTime 0.137814
INFO - Validation [23][   40/   40]   Loss 2.569258   Top1 10.000000   Top5 50.000000   BatchTime 0.096234
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.569
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9284)
features.16.conv.0 tensor(0.8682)
features.16.conv.3 tensor(0.0410)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9852)
tensor(1138688.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [24][   20/  196]   Loss 2.302669   Top1 9.785156   Top5 50.175781   BatchTime 0.311671   LR 0.000500
INFO - Training [24][   40/  196]   Loss 2.302694   Top1 9.677734   Top5 49.960938   BatchTime 0.275919   LR 0.000484
INFO - Training [24][   60/  196]   Loss 2.302774   Top1 9.811198   Top5 49.759115   BatchTime 0.263799   LR 0.000468
INFO - Training [24][   80/  196]   Loss 2.302819   Top1 9.843750   Top5 49.511719   BatchTime 0.261363   LR 0.000453
INFO - Training [24][  100/  196]   Loss 2.302796   Top1 9.792969   Top5 49.605469   BatchTime 0.253970   LR 0.000437
INFO - Training [24][  120/  196]   Loss 2.302777   Top1 9.869792   Top5 49.723307   BatchTime 0.253870   LR 0.000422
INFO - Training [24][  140/  196]   Loss 2.302802   Top1 9.907924   Top5 49.547991   BatchTime 0.253341   LR 0.000407
INFO - Training [24][  160/  196]   Loss 2.302813   Top1 9.907227   Top5 49.548340   BatchTime 0.251774   LR 0.000392
INFO - Training [24][  180/  196]   Loss 2.302794   Top1 9.893663   Top5 49.557292   BatchTime 0.249595   LR 0.000378
INFO - ==> Top1: 9.896    Top5: 49.622    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [24][   20/   40]   Loss 2.516159   Top1 10.078125   Top5 50.214844   BatchTime 0.135622
INFO - Validation [24][   40/   40]   Loss 2.519656   Top1 10.000000   Top5 50.000000   BatchTime 0.093949
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.520
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0617)
features.15.conv.6 tensor(0.9288)
features.16.conv.0 tensor(0.8695)
features.16.conv.3 tensor(0.0414)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9852)
tensor(1138962.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [25][   20/  196]   Loss 2.302524   Top1 9.707031   Top5 50.214844   BatchTime 0.322278   LR 0.000353
INFO - Training [25][   40/  196]   Loss 2.302565   Top1 10.273438   Top5 50.166016   BatchTime 0.280200   LR 0.000339
INFO - Training [25][   60/  196]   Loss 2.302607   Top1 10.221354   Top5 49.850260   BatchTime 0.273999   LR 0.000325
INFO - Training [25][   80/  196]   Loss 2.302630   Top1 10.156250   Top5 49.536133   BatchTime 0.264500   LR 0.000312
INFO - Training [25][  100/  196]   Loss 2.302603   Top1 10.164062   Top5 49.796875   BatchTime 0.260063   LR 0.000299
INFO - Training [25][  120/  196]   Loss 2.302590   Top1 10.117188   Top5 49.993490   BatchTime 0.257475   LR 0.000286
INFO - Training [25][  140/  196]   Loss 2.302586   Top1 10.114397   Top5 50.122768   BatchTime 0.253940   LR 0.000273
INFO - Training [25][  160/  196]   Loss 2.302613   Top1 10.009766   Top5 50.073242   BatchTime 0.251321   LR 0.000261
INFO - Training [25][  180/  196]   Loss 2.302600   Top1 10.002170   Top5 50.067274   BatchTime 0.249275   LR 0.000248
INFO - ==> Top1: 9.992    Top5: 50.024    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [25][   20/   40]   Loss 2.521958   Top1 10.078125   Top5 50.214844   BatchTime 0.133857
INFO - Validation [25][   40/   40]   Loss 2.525511   Top1 10.000000   Top5 50.000000   BatchTime 0.093173
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.526
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0615)
features.15.conv.6 tensor(0.9283)
features.16.conv.0 tensor(0.8693)
features.16.conv.3 tensor(0.0422)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9852)
tensor(1138879.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [26][   20/  196]   Loss 2.302720   Top1 9.628906   Top5 50.937500   BatchTime 0.314204   LR 0.000228
INFO - Training [26][   40/  196]   Loss 2.302694   Top1 9.863281   Top5 50.175781   BatchTime 0.285442   LR 0.000216
INFO - Training [26][   60/  196]   Loss 2.302667   Top1 9.902344   Top5 50.188802   BatchTime 0.271057   LR 0.000205
INFO - Training [26][   80/  196]   Loss 2.302700   Top1 9.785156   Top5 50.107422   BatchTime 0.262731   LR 0.000194
INFO - Training [26][  100/  196]   Loss 2.302679   Top1 9.757812   Top5 50.101562   BatchTime 0.255187   LR 0.000183
INFO - Training [26][  120/  196]   Loss 2.302718   Top1 9.781901   Top5 49.983724   BatchTime 0.254065   LR 0.000173
INFO - Training [26][  140/  196]   Loss 2.302719   Top1 9.720982   Top5 49.924665   BatchTime 0.251851   LR 0.000163
INFO - Training [26][  160/  196]   Loss 2.302750   Top1 9.658203   Top5 49.765625   BatchTime 0.247391   LR 0.000153
INFO - Training [26][  180/  196]   Loss 2.302736   Top1 9.717882   Top5 49.774306   BatchTime 0.245858   LR 0.000144
INFO - ==> Top1: 9.788    Top5: 49.678    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [26][   20/   40]   Loss 2.518576   Top1 10.078125   Top5 50.214844   BatchTime 0.129520
INFO - Validation [26][   40/   40]   Loss 2.522061   Top1 10.000000   Top5 50.000000   BatchTime 0.087495
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.522
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0615)
features.15.conv.6 tensor(0.9280)
features.16.conv.0 tensor(0.8692)
features.16.conv.3 tensor(0.0421)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9851)
tensor(1138798.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [27][   20/  196]   Loss 2.302455   Top1 9.960938   Top5 49.921875   BatchTime 0.297368   LR 0.000128
INFO - Training [27][   40/  196]   Loss 2.302630   Top1 9.824219   Top5 49.941406   BatchTime 0.276404   LR 0.000119
INFO - Training [27][   60/  196]   Loss 2.302608   Top1 9.934896   Top5 50.273438   BatchTime 0.266542   LR 0.000111
INFO - Training [27][   80/  196]   Loss 2.302638   Top1 9.765625   Top5 50.053711   BatchTime 0.264676   LR 0.000102
INFO - Training [27][  100/  196]   Loss 2.302627   Top1 9.859375   Top5 50.179688   BatchTime 0.259765   LR 0.000095
INFO - Training [27][  120/  196]   Loss 2.302662   Top1 9.824219   Top5 50.192057   BatchTime 0.256854   LR 0.000087
INFO - Training [27][  140/  196]   Loss 2.302684   Top1 9.799107   Top5 50.114397   BatchTime 0.253374   LR 0.000080
INFO - Training [27][  160/  196]   Loss 2.302677   Top1 9.782715   Top5 50.112305   BatchTime 0.255720   LR 0.000073
INFO - Training [27][  180/  196]   Loss 2.302691   Top1 9.822049   Top5 50.000000   BatchTime 0.255156   LR 0.000066
INFO - ==> Top1: 9.830    Top5: 49.964    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [27][   20/   40]   Loss 2.525293   Top1 10.078125   Top5 50.214844   BatchTime 0.137795
INFO - Validation [27][   40/   40]   Loss 2.528959   Top1 10.000000   Top5 50.000000   BatchTime 0.095618
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.529
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0615)
features.15.conv.6 tensor(0.9283)
features.16.conv.0 tensor(0.8694)
features.16.conv.3 tensor(0.0424)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9852)
tensor(1138857.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [28][   20/  196]   Loss 2.302523   Top1 10.351562   Top5 50.703125   BatchTime 0.344536   LR 0.000055
INFO - Training [28][   40/  196]   Loss 2.302643   Top1 10.195312   Top5 50.146484   BatchTime 0.290214   LR 0.000050
INFO - Training [28][   60/  196]   Loss 2.302640   Top1 9.947917   Top5 50.013021   BatchTime 0.276639   LR 0.000044
INFO - Training [28][   80/  196]   Loss 2.302626   Top1 10.039062   Top5 49.902344   BatchTime 0.270355   LR 0.000039
INFO - Training [28][  100/  196]   Loss 2.302630   Top1 10.046875   Top5 49.792969   BatchTime 0.263557   LR 0.000034
INFO - Training [28][  120/  196]   Loss 2.302608   Top1 10.185547   Top5 49.768880   BatchTime 0.262688   LR 0.000030
INFO - Training [28][  140/  196]   Loss 2.302610   Top1 10.175781   Top5 49.804688   BatchTime 0.259598   LR 0.000026
INFO - Training [28][  160/  196]   Loss 2.302634   Top1 10.192871   Top5 49.763184   BatchTime 0.259626   LR 0.000022
INFO - Training [28][  180/  196]   Loss 2.302643   Top1 10.125868   Top5 49.754774   BatchTime 0.258753   LR 0.000018
INFO - ==> Top1: 10.108    Top5: 49.798    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [28][   20/   40]   Loss 2.516543   Top1 10.078125   Top5 50.214844   BatchTime 0.130507
INFO - Validation [28][   40/   40]   Loss 2.520139   Top1 10.000000   Top5 50.000000   BatchTime 0.089439
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.520
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [28][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9283)
features.16.conv.0 tensor(0.8694)
features.16.conv.3 tensor(0.0421)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9852)
tensor(1138860.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [29][   20/  196]   Loss 2.302537   Top1 10.371094   Top5 50.546875   BatchTime 0.340528   LR 0.000013
INFO - Training [29][   40/  196]   Loss 2.302624   Top1 10.078125   Top5 50.166016   BatchTime 0.291758   LR 0.000010
INFO - Training [29][   60/  196]   Loss 2.302532   Top1 10.039062   Top5 50.364583   BatchTime 0.271963   LR 0.000008
INFO - Training [29][   80/  196]   Loss 2.302515   Top1 10.097656   Top5 50.297852   BatchTime 0.266997   LR 0.000005
INFO - Training [29][  100/  196]   Loss 2.302559   Top1 10.089844   Top5 50.097656   BatchTime 0.260476   LR 0.000004
INFO - Training [29][  120/  196]   Loss 2.302548   Top1 10.247396   Top5 50.221354   BatchTime 0.254227   LR 0.000002
INFO - Training [29][  140/  196]   Loss 2.302572   Top1 10.228795   Top5 50.186942   BatchTime 0.252967   LR 0.000001
INFO - Training [29][  160/  196]   Loss 2.302559   Top1 10.195312   Top5 50.402832   BatchTime 0.251313   LR 0.000001
INFO - Training [29][  180/  196]   Loss 2.302572   Top1 10.236545   Top5 50.347222   BatchTime 0.251162   LR 0.000000
INFO - ==> Top1: 10.238    Top5: 50.438    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [29][   20/   40]   Loss 2.544763   Top1 10.078125   Top5 50.214844   BatchTime 0.136388
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0615)
features.15.conv.6 tensor(0.9283)
features.16.conv.0 tensor(0.8695)
features.16.conv.3 tensor(0.0424)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9851)
tensor(1138867.) 2188896.0
INFO - Validation [29][   40/   40]   Loss 2.548569   Top1 10.000000   Top5 50.000000   BatchTime 0.091393
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.549
INFO - ==> Sparsity : 0.520
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [28][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [30][   20/  196]   Loss 2.302642   Top1 10.761719   Top5 50.292969   BatchTime 0.328254   LR 0.001250
INFO - Training [30][   40/  196]   Loss 2.302748   Top1 10.107422   Top5 49.677734   BatchTime 0.290601   LR 0.001250
INFO - Training [30][   60/  196]   Loss 2.302747   Top1 10.117188   Top5 49.778646   BatchTime 0.279916   LR 0.001250
INFO - Training [30][   80/  196]   Loss 2.302883   Top1 10.009766   Top5 49.511719   BatchTime 0.272335   LR 0.001250
INFO - Training [30][  100/  196]   Loss 2.302816   Top1 9.964844   Top5 49.679688   BatchTime 0.266460   LR 0.001250
INFO - Training [30][  120/  196]   Loss 2.302766   Top1 9.977214   Top5 49.833984   BatchTime 0.263767   LR 0.001249
INFO - Training [30][  140/  196]   Loss 2.302784   Top1 9.966518   Top5 49.712612   BatchTime 0.260252   LR 0.001249
INFO - Training [30][  160/  196]   Loss 2.302803   Top1 9.921875   Top5 49.614258   BatchTime 0.258041   LR 0.001249
INFO - Training [30][  180/  196]   Loss 2.302840   Top1 9.902344   Top5 49.563802   BatchTime 0.254086   LR 0.001248
********************pre-trained*****************
INFO - ==> Top1: 9.944    Top5: 49.528    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 2.483234   Top1 10.078125   Top5 50.214844   BatchTime 0.134048
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0602)
features.15.conv.6 tensor(0.9287)
features.16.conv.0 tensor(0.8741)
features.16.conv.3 tensor(0.0412)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9853)
tensor(1139747.) 2188896.0
INFO - Validation [30][   40/   40]   Loss 2.486508   Top1 10.000000   Top5 50.000000   BatchTime 0.094945
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.487
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [30][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [31][   20/  196]   Loss 2.302760   Top1 9.511719   Top5 49.023438   BatchTime 0.319265   LR 0.001248
INFO - Training [31][   40/  196]   Loss 2.302753   Top1 9.970703   Top5 49.101562   BatchTime 0.270335   LR 0.001247
INFO - Training [31][   60/  196]   Loss 2.302734   Top1 10.058594   Top5 49.622396   BatchTime 0.256412   LR 0.001247
INFO - Training [31][   80/  196]   Loss 2.302730   Top1 9.970703   Top5 49.780273   BatchTime 0.246879   LR 0.001246
INFO - Training [31][  100/  196]   Loss 2.302736   Top1 9.871094   Top5 49.757812   BatchTime 0.245734   LR 0.001246
INFO - Training [31][  120/  196]   Loss 2.302779   Top1 9.794922   Top5 49.628906   BatchTime 0.241564   LR 0.001245
INFO - Training [31][  140/  196]   Loss 2.302757   Top1 9.779576   Top5 49.670759   BatchTime 0.240266   LR 0.001244
INFO - Training [31][  160/  196]   Loss 2.302693   Top1 9.782715   Top5 49.882812   BatchTime 0.238317   LR 0.001244
INFO - Training [31][  180/  196]   Loss 2.302692   Top1 9.848090   Top5 49.924045   BatchTime 0.236100   LR 0.001243
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 9.836    Top5: 49.754    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0604)
features.15.conv.6 tensor(0.9286)
features.16.conv.0 tensor(0.8740)
features.16.conv.3 tensor(0.0412)
features.16.conv.6 tensor(0.9922)
conv.0 tensor(0.9852)
tensor(1139700.) 2188896.0
INFO - Validation [31][   20/   40]   Loss 2.461789   Top1 10.078125   Top5 50.214844   BatchTime 0.139020
INFO - Validation [31][   40/   40]   Loss 2.464751   Top1 10.000000   Top5 50.000000   BatchTime 0.097234
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.465
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [31][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [30][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [29][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [32][   20/  196]   Loss 2.302965   Top1 9.394531   Top5 50.000000   BatchTime 0.306747   LR 0.001242
INFO - Training [32][   40/  196]   Loss 2.302750   Top1 9.736328   Top5 50.136719   BatchTime 0.261928   LR 0.001241
INFO - Training [32][   60/  196]   Loss 2.302717   Top1 9.746094   Top5 50.136719   BatchTime 0.249106   LR 0.001240
INFO - Training [32][   80/  196]   Loss 2.302733   Top1 9.824219   Top5 50.068359   BatchTime 0.242469   LR 0.001239
INFO - Training [32][  100/  196]   Loss 2.302736   Top1 9.894531   Top5 49.875000   BatchTime 0.239359   LR 0.001238
INFO - Training [32][  120/  196]   Loss 2.302763   Top1 9.915365   Top5 49.830729   BatchTime 0.236056   LR 0.001237
INFO - Training [32][  140/  196]   Loss 2.302772   Top1 9.952567   Top5 49.846540   BatchTime 0.233674   LR 0.001236
INFO - Training [32][  160/  196]   Loss 2.302763   Top1 9.924316   Top5 49.760742   BatchTime 0.233297   LR 0.001235
INFO - Training [32][  180/  196]   Loss 2.302762   Top1 9.954427   Top5 49.815538   BatchTime 0.230852   LR 0.001234
********************pre-trained*****************
INFO - ==> Top1: 9.970    Top5: 49.750    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 2.462371   Top1 10.078125   Top5 50.214844   BatchTime 0.139031
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0608)
features.15.conv.6 tensor(0.9281)
features.16.conv.0 tensor(0.8825)
features.16.conv.3 tensor(0.0422)
features.16.conv.6 tensor(0.9922)
conv.0 tensor(0.9853)
tensor(1140989.) 2188896.0
INFO - Validation [32][   40/   40]   Loss 2.465374   Top1 10.000000   Top5 50.000000   BatchTime 0.097912
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.465
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [32][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [31][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [33][   20/  196]   Loss 2.302814   Top1 9.472656   Top5 49.316406   BatchTime 0.313189   LR 0.001232
INFO - Training [33][   40/  196]   Loss 2.302764   Top1 9.794922   Top5 49.716797   BatchTime 0.270371   LR 0.001230
INFO - Training [33][   60/  196]   Loss 2.302776   Top1 9.667969   Top5 49.635417   BatchTime 0.257071   LR 0.001229
INFO - Training [33][   80/  196]   Loss 2.302833   Top1 9.790039   Top5 49.506836   BatchTime 0.246132   LR 0.001228
INFO - Training [33][  100/  196]   Loss 2.302815   Top1 9.902344   Top5 49.382812   BatchTime 0.239615   LR 0.001226
INFO - Training [33][  120/  196]   Loss 2.302841   Top1 9.837240   Top5 49.381510   BatchTime 0.234221   LR 0.001225
INFO - Training [33][  140/  196]   Loss 2.302819   Top1 9.955357   Top5 49.439174   BatchTime 0.230534   LR 0.001224
INFO - Training [33][  160/  196]   Loss 2.302812   Top1 10.004883   Top5 49.541016   BatchTime 0.227287   LR 0.001222
INFO - Training [33][  180/  196]   Loss 2.302809   Top1 9.984809   Top5 49.548611   BatchTime 0.224656   LR 0.001221
********************pre-trained*****************
INFO - ==> Top1: 9.920    Top5: 49.416    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [33][   20/   40]   Loss 2.460385   Top1 10.078125   Top5 50.058594   BatchTime 0.133984
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0596)
features.15.conv.6 tensor(0.9294)
features.16.conv.0 tensor(0.8849)
features.16.conv.3 tensor(0.0425)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9853)
tensor(1141423.) 2188896.0
INFO - Validation [33][   40/   40]   Loss 2.463114   Top1 10.000000   Top5 50.000000   BatchTime 0.093665
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.463
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [33][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [32][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [31][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [34][   20/  196]   Loss 2.302695   Top1 9.589844   Top5 49.570312   BatchTime 0.324945   LR 0.001218
INFO - Training [34][   40/  196]   Loss 2.302720   Top1 9.824219   Top5 49.804688   BatchTime 0.277486   LR 0.001216
INFO - Training [34][   60/  196]   Loss 2.302830   Top1 9.752604   Top5 49.583333   BatchTime 0.259275   LR 0.001215
INFO - Training [34][   80/  196]   Loss 2.302757   Top1 9.970703   Top5 49.829102   BatchTime 0.249433   LR 0.001213
INFO - Training [34][  100/  196]   Loss 2.302760   Top1 9.914062   Top5 49.835938   BatchTime 0.245090   LR 0.001211
INFO - Training [34][  120/  196]   Loss 2.302805   Top1 9.899089   Top5 49.703776   BatchTime 0.242766   LR 0.001209
INFO - Training [34][  140/  196]   Loss 2.302866   Top1 9.807478   Top5 49.522879   BatchTime 0.239479   LR 0.001208
INFO - Training [34][  160/  196]   Loss 2.302851   Top1 9.865723   Top5 49.570312   BatchTime 0.237750   LR 0.001206
INFO - Training [34][  180/  196]   Loss 2.302839   Top1 9.950087   Top5 49.615885   BatchTime 0.237352   LR 0.001204
********************pre-trained*****************
INFO - ==> Top1: 9.906    Top5: 49.530    Loss: 2.303
validation quantized model on cpu
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 2.481671   Top1 10.078125   Top5 50.214844   BatchTime 0.150698
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0601)
features.15.conv.6 tensor(0.9277)
features.16.conv.0 tensor(0.8838)
features.16.conv.3 tensor(0.0420)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9852)
tensor(1140975.) 2188896.0
INFO - Validation [34][   40/   40]   Loss 2.484716   Top1 10.000000   Top5 50.000000   BatchTime 0.101969
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.485
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [34][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [33][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [35][   20/  196]   Loss 2.302712   Top1 10.273438   Top5 50.312500   BatchTime 0.327292   LR 0.001201
INFO - Training [35][   40/  196]   Loss 2.302626   Top1 10.322266   Top5 50.527344   BatchTime 0.277820   LR 0.001199
INFO - Training [35][   60/  196]   Loss 2.302549   Top1 10.403646   Top5 50.462240   BatchTime 0.255003   LR 0.001197
INFO - Training [35][   80/  196]   Loss 2.302611   Top1 10.278320   Top5 50.322266   BatchTime 0.246623   LR 0.001195
INFO - Training [35][  100/  196]   Loss 2.302533   Top1 10.402344   Top5 50.484375   BatchTime 0.241084   LR 0.001192
INFO - Training [35][  120/  196]   Loss 2.302609   Top1 10.263672   Top5 50.263672   BatchTime 0.236539   LR 0.001190
INFO - Training [35][  140/  196]   Loss 2.302690   Top1 10.139509   Top5 50.080915   BatchTime 0.235459   LR 0.001188
INFO - Training [35][  160/  196]   Loss 2.302689   Top1 10.085449   Top5 50.100098   BatchTime 0.233580   LR 0.001186
INFO - Training [35][  180/  196]   Loss 2.302702   Top1 10.071615   Top5 50.054253   BatchTime 0.232789   LR 0.001184
********************pre-trained*****************
INFO - ==> Top1: 10.018    Top5: 49.896    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 2.513241   Top1 10.078125   Top5 49.980469   BatchTime 0.133516
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0591)
features.15.conv.6 tensor(0.9295)
features.16.conv.0 tensor(0.8839)
features.16.conv.3 tensor(0.0428)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9853)
tensor(1141315.) 2188896.0
INFO - Validation [35][   40/   40]   Loss 2.516366   Top1 10.000000   Top5 50.000000   BatchTime 0.090606
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.516
INFO - ==> Sparsity : 0.521
INFO - Scoreboard best 1 ==> Epoch [35][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [34][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [36][   20/  196]   Loss 2.303026   Top1 9.824219   Top5 49.277344   BatchTime 0.320981   LR 0.001180
INFO - Training [36][   40/  196]   Loss 2.302975   Top1 9.697266   Top5 49.316406   BatchTime 0.269238   LR 0.001177
INFO - Training [36][   60/  196]   Loss 2.302885   Top1 9.785156   Top5 49.433594   BatchTime 0.254428   LR 0.001175
INFO - Training [36][   80/  196]   Loss 2.302882   Top1 9.731445   Top5 49.423828   BatchTime 0.247530   LR 0.001173
INFO - Training [36][  100/  196]   Loss 2.302824   Top1 9.828125   Top5 49.730469   BatchTime 0.243812   LR 0.001170
INFO - Training [36][  120/  196]   Loss 2.302864   Top1 9.811198   Top5 49.381510   BatchTime 0.240878   LR 0.001168
INFO - Training [36][  140/  196]   Loss 2.302849   Top1 9.804688   Top5 49.439174   BatchTime 0.238774   LR 0.001165
INFO - Training [36][  160/  196]   Loss 2.302834   Top1 9.782715   Top5 49.423828   BatchTime 0.236491   LR 0.001163
INFO - Training [36][  180/  196]   Loss 2.302839   Top1 9.761285   Top5 49.455295   BatchTime 0.237801   LR 0.001160
INFO - ==> Top1: 9.760    Top5: 49.404    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [36][   20/   40]   Loss 2.486122   Top1 10.078125   Top5 50.214844   BatchTime 0.138691
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0595)
features.15.conv.6 tensor(0.9336)
features.16.conv.0 tensor(0.8873)
features.16.conv.3 tensor(0.0433)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9853)
tensor(1142517.) 2188896.0
INFO - Validation [36][   40/   40]   Loss 2.489295   Top1 10.000000   Top5 50.000000   BatchTime 0.097648
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.489
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [36][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [35][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [37][   20/  196]   Loss 2.302737   Top1 10.546875   Top5 49.609375   BatchTime 0.307914   LR 0.001155
INFO - Training [37][   40/  196]   Loss 2.302844   Top1 9.736328   Top5 49.042969   BatchTime 0.266054   LR 0.001153
INFO - Training [37][   60/  196]   Loss 2.302870   Top1 9.765625   Top5 48.919271   BatchTime 0.250567   LR 0.001150
INFO - Training [37][   80/  196]   Loss 2.302823   Top1 9.897461   Top5 49.213867   BatchTime 0.243396   LR 0.001147
INFO - Training [37][  100/  196]   Loss 2.302828   Top1 9.914062   Top5 49.210938   BatchTime 0.241410   LR 0.001144
INFO - Training [37][  120/  196]   Loss 2.302811   Top1 9.811198   Top5 49.225260   BatchTime 0.238196   LR 0.001142
INFO - Training [37][  140/  196]   Loss 2.302806   Top1 9.860491   Top5 49.363839   BatchTime 0.236739   LR 0.001139
INFO - Training [37][  160/  196]   Loss 2.302771   Top1 9.863281   Top5 49.453125   BatchTime 0.235652   LR 0.001136
INFO - Training [37][  180/  196]   Loss 2.302805   Top1 9.843750   Top5 49.403212   BatchTime 0.233506   LR 0.001133
INFO - ==> Top1: 9.824    Top5: 49.410    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [37][   20/   40]   Loss 2.493626   Top1 10.078125   Top5 50.058594   BatchTime 0.143124
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0596)
features.15.conv.6 tensor(0.9352)
features.16.conv.0 tensor(0.8909)
features.16.conv.3 tensor(0.0426)
features.16.conv.6 tensor(0.9922)
conv.0 tensor(0.9853)
tensor(1143359.) 2188896.0
INFO - Validation [37][   40/   40]   Loss 2.496594   Top1 10.000000   Top5 50.000000   BatchTime 0.099453
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.497
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [37][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [36][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [38][   20/  196]   Loss 2.302648   Top1 10.371094   Top5 49.902344   BatchTime 0.330123   LR 0.001128
INFO - Training [38][   40/  196]   Loss 2.302581   Top1 10.439453   Top5 50.322266   BatchTime 0.280020   LR 0.001125
INFO - Training [38][   60/  196]   Loss 2.302614   Top1 10.312500   Top5 50.455729   BatchTime 0.263107   LR 0.001122
INFO - Training [38][   80/  196]   Loss 2.302650   Top1 10.249023   Top5 50.356445   BatchTime 0.252815   LR 0.001119
INFO - Training [38][  100/  196]   Loss 2.302722   Top1 10.066406   Top5 50.152344   BatchTime 0.247216   LR 0.001116
INFO - Training [38][  120/  196]   Loss 2.302736   Top1 10.042318   Top5 50.113932   BatchTime 0.245154   LR 0.001112
INFO - Training [38][  140/  196]   Loss 2.302735   Top1 10.036272   Top5 50.078125   BatchTime 0.242610   LR 0.001109
INFO - Training [38][  160/  196]   Loss 2.302748   Top1 9.938965   Top5 49.948730   BatchTime 0.241303   LR 0.001106
INFO - Training [38][  180/  196]   Loss 2.302766   Top1 10.045573   Top5 49.780816   BatchTime 0.238807   LR 0.001103
********************pre-trained*****************
INFO - ==> Top1: 10.000    Top5: 49.798    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [38][   20/   40]   Loss 2.511339   Top1 10.078125   Top5 50.058594   BatchTime 0.141624
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0600)
features.15.conv.6 tensor(0.9356)
features.16.conv.0 tensor(0.8926)
features.16.conv.3 tensor(0.0431)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9853)
tensor(1143664.) 2188896.0
INFO - Validation [38][   40/   40]   Loss 2.514624   Top1 10.000000   Top5 50.000000   BatchTime 0.099564
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.515
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [38][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [37][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [39][   20/  196]   Loss 2.302344   Top1 10.957031   Top5 50.781250   BatchTime 0.318389   LR 0.001097
INFO - Training [39][   40/  196]   Loss 2.302663   Top1 10.371094   Top5 50.136719   BatchTime 0.268366   LR 0.001094
INFO - Training [39][   60/  196]   Loss 2.302741   Top1 10.221354   Top5 49.694010   BatchTime 0.255147   LR 0.001090
INFO - Training [39][   80/  196]   Loss 2.302756   Top1 10.219727   Top5 49.692383   BatchTime 0.245526   LR 0.001087
INFO - Training [39][  100/  196]   Loss 2.302758   Top1 10.207031   Top5 49.714844   BatchTime 0.241836   LR 0.001084
INFO - Training [39][  120/  196]   Loss 2.302767   Top1 10.061849   Top5 49.674479   BatchTime 0.237244   LR 0.001080
INFO - Training [39][  140/  196]   Loss 2.302750   Top1 10.089286   Top5 49.720982   BatchTime 0.234196   LR 0.001077
INFO - Training [39][  160/  196]   Loss 2.302772   Top1 10.026855   Top5 49.567871   BatchTime 0.233464   LR 0.001073
INFO - Training [39][  180/  196]   Loss 2.302795   Top1 9.889323   Top5 49.487847   BatchTime 0.231218   LR 0.001070
********************pre-trained*****************
INFO - ==> Top1: 9.886    Top5: 49.470    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 2.469919   Top1 10.078125   Top5 50.058594   BatchTime 0.140365
INFO - Validation [39][   40/   40]   Loss 2.472936   Top1 10.000000   Top5 50.000000   BatchTime 0.098437
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0604)
features.15.conv.6 tensor(0.9355)
features.16.conv.0 tensor(0.8934)
features.16.conv.3 tensor(0.0421)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9853)
tensor(1143757.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.473
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [39][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [38][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [37][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [40][   20/  196]   Loss 2.302663   Top1 9.531250   Top5 50.058594   BatchTime 0.320517   LR 0.001064
INFO - Training [40][   40/  196]   Loss 2.302689   Top1 9.580078   Top5 49.833984   BatchTime 0.276736   LR 0.001060
INFO - Training [40][   60/  196]   Loss 2.302700   Top1 9.863281   Top5 49.986979   BatchTime 0.260443   LR 0.001056
INFO - Training [40][   80/  196]   Loss 2.302730   Top1 9.873047   Top5 49.721680   BatchTime 0.248959   LR 0.001053
INFO - Training [40][  100/  196]   Loss 2.302749   Top1 9.914062   Top5 49.730469   BatchTime 0.244222   LR 0.001049
INFO - Training [40][  120/  196]   Loss 2.302759   Top1 9.886068   Top5 49.677734   BatchTime 0.240142   LR 0.001045
INFO - Training [40][  140/  196]   Loss 2.302738   Top1 9.910714   Top5 49.617746   BatchTime 0.237193   LR 0.001042
INFO - Training [40][  160/  196]   Loss 2.302736   Top1 9.924316   Top5 49.558105   BatchTime 0.236607   LR 0.001038
INFO - Training [40][  180/  196]   Loss 2.302752   Top1 9.813368   Top5 49.518229   BatchTime 0.235050   LR 0.001034
********************pre-trained*****************
INFO - ==> Top1: 9.784    Top5: 49.490    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 2.463646   Top1 10.078125   Top5 50.214844   BatchTime 0.139212
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0602)
features.15.conv.6 tensor(0.9355)
features.16.conv.0 tensor(0.8932)
features.16.conv.3 tensor(0.0426)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9853)
tensor(1143753.) 2188896.0
INFO - Validation [40][   40/   40]   Loss 2.466346   Top1 10.000000   Top5 50.000000   BatchTime 0.095540
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.466
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [40][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [39][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [41][   20/  196]   Loss 2.302615   Top1 9.960938   Top5 50.605469   BatchTime 0.321365   LR 0.001027
INFO - Training [41][   40/  196]   Loss 2.302705   Top1 9.912109   Top5 50.175781   BatchTime 0.270261   LR 0.001023
INFO - Training [41][   60/  196]   Loss 2.302645   Top1 10.143229   Top5 50.572917   BatchTime 0.253875   LR 0.001020
INFO - Training [41][   80/  196]   Loss 2.302692   Top1 9.926758   Top5 50.219727   BatchTime 0.246777   LR 0.001016
INFO - Training [41][  100/  196]   Loss 2.302716   Top1 9.859375   Top5 49.902344   BatchTime 0.244113   LR 0.001012
INFO - Training [41][  120/  196]   Loss 2.302741   Top1 9.895833   Top5 49.710286   BatchTime 0.240148   LR 0.001008
INFO - Training [41][  140/  196]   Loss 2.302767   Top1 9.854911   Top5 49.453125   BatchTime 0.239447   LR 0.001004
INFO - Training [41][  160/  196]   Loss 2.302756   Top1 9.699707   Top5 49.584961   BatchTime 0.238680   LR 0.001000
INFO - Training [41][  180/  196]   Loss 2.302758   Top1 9.698351   Top5 49.592014   BatchTime 0.237622   LR 0.000996
INFO - ==> Top1: 9.686    Top5: 49.534    Loss: 2.303
********************pre-trained*****************
validation quantized model on cpu
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9355)
features.16.conv.0 tensor(0.8930)
features.16.conv.3 tensor(0.0426)
features.16.conv.6 tensor(0.9921)
conv.0 tensor(0.9853)
tensor(1143713.) 2188896.0
INFO - Validation [41][   20/   40]   Loss 2.457378   Top1 10.078125   Top5 50.058594   BatchTime 0.141384
INFO - Validation [41][   40/   40]   Loss 2.460233   Top1 10.000000   Top5 50.000000   BatchTime 0.098094
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.460
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [41][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [40][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [42][   20/  196]   Loss 2.302471   Top1 10.292969   Top5 50.058594   BatchTime 0.328141   LR 0.000988
INFO - Training [42][   40/  196]   Loss 2.302582   Top1 10.068359   Top5 50.126953   BatchTime 0.276539   LR 0.000984
INFO - Training [42][   60/  196]   Loss 2.302657   Top1 9.967448   Top5 49.908854   BatchTime 0.257986   LR 0.000980
INFO - Training [42][   80/  196]   Loss 2.302727   Top1 10.024414   Top5 49.555664   BatchTime 0.248356   LR 0.000976
INFO - Training [42][  100/  196]   Loss 2.302736   Top1 9.906250   Top5 49.539062   BatchTime 0.242742   LR 0.000972
INFO - Training [42][  120/  196]   Loss 2.302715   Top1 9.990234   Top5 49.694010   BatchTime 0.241317   LR 0.000968
INFO - Training [42][  140/  196]   Loss 2.302741   Top1 10.041853   Top5 49.494978   BatchTime 0.238718   LR 0.000964
INFO - Training [42][  160/  196]   Loss 2.302755   Top1 9.916992   Top5 49.516602   BatchTime 0.238058   LR 0.000959
INFO - Training [42][  180/  196]   Loss 2.302763   Top1 9.867622   Top5 49.461806   BatchTime 0.235767   LR 0.000955
********************pre-trained*****************
INFO - ==> Top1: 9.834    Top5: 49.396    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [42][   20/   40]   Loss 2.457730   Top1 10.078125   Top5 50.058594   BatchTime 0.143262
INFO - Validation [42][   40/   40]   Loss 2.460317   Top1 10.000000   Top5 50.000000   BatchTime 0.099204
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0608)
features.15.conv.6 tensor(0.9361)
features.16.conv.0 tensor(0.8933)
features.16.conv.3 tensor(0.0428)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9854)
tensor(1143836.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.460
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [42][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [41][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [40][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [43][   20/  196]   Loss 2.302734   Top1 8.769531   Top5 49.707031   BatchTime 0.319295   LR 0.000947
INFO - Training [43][   40/  196]   Loss 2.302773   Top1 9.179688   Top5 50.019531   BatchTime 0.278584   LR 0.000943
INFO - Training [43][   60/  196]   Loss 2.302675   Top1 9.726562   Top5 50.195312   BatchTime 0.263655   LR 0.000939
INFO - Training [43][   80/  196]   Loss 2.302749   Top1 9.794922   Top5 49.951172   BatchTime 0.257291   LR 0.000934
INFO - Training [43][  100/  196]   Loss 2.302793   Top1 9.656250   Top5 49.765625   BatchTime 0.252364   LR 0.000930
INFO - Training [43][  120/  196]   Loss 2.302777   Top1 9.625651   Top5 49.723307   BatchTime 0.247375   LR 0.000926
INFO - Training [43][  140/  196]   Loss 2.302764   Top1 9.665179   Top5 49.693080   BatchTime 0.245840   LR 0.000921
INFO - Training [43][  160/  196]   Loss 2.302779   Top1 9.675293   Top5 49.636230   BatchTime 0.244126   LR 0.000917
INFO - Training [43][  180/  196]   Loss 2.302766   Top1 9.724392   Top5 49.648438   BatchTime 0.240803   LR 0.000912
********************pre-trained*****************
INFO - ==> Top1: 9.788    Top5: 49.638    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [43][   20/   40]   Loss 2.463955   Top1 10.078125   Top5 50.058594   BatchTime 0.146013
INFO - Validation [43][   40/   40]   Loss 2.466490   Top1 10.000000   Top5 50.000000   BatchTime 0.100782
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0615)
features.15.conv.6 tensor(0.9356)
features.16.conv.0 tensor(0.8916)
features.16.conv.3 tensor(0.0428)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9854)
tensor(1143481.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.466
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [43][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [42][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [44][   20/  196]   Loss 2.302799   Top1 9.492188   Top5 49.218750   BatchTime 0.322628   LR 0.000904
INFO - Training [44][   40/  196]   Loss 2.302764   Top1 9.697266   Top5 49.414062   BatchTime 0.273212   LR 0.000900
INFO - Training [44][   60/  196]   Loss 2.302790   Top1 9.648438   Top5 49.427083   BatchTime 0.258323   LR 0.000895
INFO - Training [44][   80/  196]   Loss 2.302782   Top1 9.653320   Top5 49.335938   BatchTime 0.249123   LR 0.000891
INFO - Training [44][  100/  196]   Loss 2.302761   Top1 9.750000   Top5 49.324219   BatchTime 0.243281   LR 0.000886
INFO - Training [44][  120/  196]   Loss 2.302735   Top1 9.889323   Top5 49.410807   BatchTime 0.240505   LR 0.000882
INFO - Training [44][  140/  196]   Loss 2.302736   Top1 9.891183   Top5 49.369420   BatchTime 0.239477   LR 0.000877
INFO - Training [44][  160/  196]   Loss 2.302740   Top1 9.848633   Top5 49.338379   BatchTime 0.237801   LR 0.000873
INFO - Training [44][  180/  196]   Loss 2.302736   Top1 9.848090   Top5 49.279514   BatchTime 0.235002   LR 0.000868
********************pre-trained*****************
INFO - ==> Top1: 9.852    Top5: 49.276    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 2.460708   Top1 10.078125   Top5 50.214844   BatchTime 0.147123
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9355)
features.16.conv.0 tensor(0.8912)
features.16.conv.3 tensor(0.0427)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9854)
tensor(1143441.) 2188896.0
INFO - Validation [44][   40/   40]   Loss 2.463680   Top1 10.000000   Top5 50.000000   BatchTime 0.101272
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.464
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [44][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [43][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [45][   20/  196]   Loss 2.302752   Top1 10.644531   Top5 48.730469   BatchTime 0.309257   LR 0.000860
INFO - Training [45][   40/  196]   Loss 2.302665   Top1 10.195312   Top5 49.619141   BatchTime 0.263123   LR 0.000855
INFO - Training [45][   60/  196]   Loss 2.302679   Top1 10.104167   Top5 49.361979   BatchTime 0.256065   LR 0.000850
INFO - Training [45][   80/  196]   Loss 2.302684   Top1 10.009766   Top5 49.506836   BatchTime 0.246614   LR 0.000846
INFO - Training [45][  100/  196]   Loss 2.302718   Top1 9.894531   Top5 49.609375   BatchTime 0.243457   LR 0.000841
INFO - Training [45][  120/  196]   Loss 2.302687   Top1 9.925130   Top5 49.723307   BatchTime 0.241311   LR 0.000836
INFO - Training [45][  140/  196]   Loss 2.302695   Top1 9.983259   Top5 49.746094   BatchTime 0.238711   LR 0.000832
INFO - Training [45][  160/  196]   Loss 2.302688   Top1 9.916992   Top5 49.758301   BatchTime 0.237680   LR 0.000827
INFO - Training [45][  180/  196]   Loss 2.302706   Top1 9.841580   Top5 49.654948   BatchTime 0.235601   LR 0.000822
INFO - ==> Top1: 9.838    Top5: 49.500    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0610)
features.15.conv.6 tensor(0.9358)
features.16.conv.0 tensor(0.8922)
features.16.conv.3 tensor(0.0428)
features.16.conv.6 tensor(0.9920)
conv.0 tensor(0.9854)
tensor(1143641.) 2188896.0
INFO - Validation [45][   20/   40]   Loss 2.437522   Top1 10.078125   Top5 50.058594   BatchTime 0.147789
INFO - Validation [45][   40/   40]   Loss 2.440034   Top1 10.000000   Top5 50.000000   BatchTime 0.101080
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.440
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [45][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [44][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [43][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [46][   20/  196]   Loss 2.302640   Top1 9.960938   Top5 49.941406   BatchTime 0.316492   LR 0.000814
INFO - Training [46][   40/  196]   Loss 2.302525   Top1 10.302734   Top5 50.556641   BatchTime 0.269283   LR 0.000809
INFO - Training [46][   60/  196]   Loss 2.302607   Top1 10.234375   Top5 49.869792   BatchTime 0.256349   LR 0.000804
INFO - Training [46][   80/  196]   Loss 2.302636   Top1 10.078125   Top5 50.004883   BatchTime 0.247021   LR 0.000799
INFO - Training [46][  100/  196]   Loss 2.302676   Top1 9.976562   Top5 49.636719   BatchTime 0.243136   LR 0.000794
INFO - Training [46][  120/  196]   Loss 2.302666   Top1 9.986979   Top5 49.739583   BatchTime 0.240863   LR 0.000789
INFO - Training [46][  140/  196]   Loss 2.302679   Top1 9.969308   Top5 49.740513   BatchTime 0.237755   LR 0.000785
INFO - Training [46][  160/  196]   Loss 2.302680   Top1 9.992676   Top5 49.694824   BatchTime 0.235579   LR 0.000780
INFO - Training [46][  180/  196]   Loss 2.302690   Top1 9.939236   Top5 49.585503   BatchTime 0.233415   LR 0.000775
********************pre-trained*****************
INFO - ==> Top1: 9.930    Top5: 49.480    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [46][   20/   40]   Loss 2.442624   Top1 10.078125   Top5 50.058594   BatchTime 0.146375
INFO - Validation [46][   40/   40]   Loss 2.445348   Top1 10.000000   Top5 50.000000   BatchTime 0.100780
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.445
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [46][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [45][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0615)
features.15.conv.6 tensor(0.9358)
features.16.conv.0 tensor(0.8930)
features.16.conv.3 tensor(0.0431)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9854)
tensor(1143750.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [47][   20/  196]   Loss 2.302633   Top1 9.785156   Top5 51.113281   BatchTime 0.328509   LR 0.000766
INFO - Training [47][   40/  196]   Loss 2.302759   Top1 9.638672   Top5 50.380859   BatchTime 0.275009   LR 0.000761
INFO - Training [47][   60/  196]   Loss 2.302714   Top1 9.635417   Top5 50.319010   BatchTime 0.260396   LR 0.000756
INFO - Training [47][   80/  196]   Loss 2.302728   Top1 9.653320   Top5 49.916992   BatchTime 0.250659   LR 0.000752
INFO - Training [47][  100/  196]   Loss 2.302722   Top1 9.679688   Top5 50.039062   BatchTime 0.243974   LR 0.000747
INFO - Training [47][  120/  196]   Loss 2.302709   Top1 9.684245   Top5 49.957682   BatchTime 0.239950   LR 0.000742
INFO - Training [47][  140/  196]   Loss 2.302706   Top1 9.818638   Top5 49.930246   BatchTime 0.238377   LR 0.000737
INFO - Training [47][  160/  196]   Loss 2.302715   Top1 9.753418   Top5 49.904785   BatchTime 0.237305   LR 0.000732
INFO - Training [47][  180/  196]   Loss 2.302716   Top1 9.776476   Top5 49.898003   BatchTime 0.234795   LR 0.000727
********************pre-trained*****************
INFO - ==> Top1: 9.784    Top5: 49.810    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 2.446026   Top1 10.078125   Top5 50.058594   BatchTime 0.150943
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0609)
features.15.conv.6 tensor(0.9359)
features.16.conv.0 tensor(0.8930)
features.16.conv.3 tensor(0.0437)
features.16.conv.6 tensor(0.9918)
conv.0 tensor(0.9855)
tensor(1143765.) 2188896.0
INFO - Validation [47][   40/   40]   Loss 2.448734   Top1 10.000000   Top5 50.000000   BatchTime 0.101426
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.449
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [47][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [46][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [45][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [48][   20/  196]   Loss 2.302807   Top1 9.550781   Top5 49.511719   BatchTime 0.324515   LR 0.000718
INFO - Training [48][   40/  196]   Loss 2.302689   Top1 9.892578   Top5 49.912109   BatchTime 0.272973   LR 0.000713
INFO - Training [48][   60/  196]   Loss 2.302646   Top1 10.149740   Top5 49.596354   BatchTime 0.253760   LR 0.000708
INFO - Training [48][   80/  196]   Loss 2.302635   Top1 10.166016   Top5 49.746094   BatchTime 0.244166   LR 0.000703
INFO - Training [48][  100/  196]   Loss 2.302648   Top1 10.089844   Top5 49.707031   BatchTime 0.236538   LR 0.000698
INFO - Training [48][  120/  196]   Loss 2.302707   Top1 10.029297   Top5 49.423828   BatchTime 0.233123   LR 0.000693
INFO - Training [48][  140/  196]   Loss 2.302706   Top1 10.036272   Top5 49.347098   BatchTime 0.229175   LR 0.000688
INFO - Training [48][  160/  196]   Loss 2.302692   Top1 9.995117   Top5 49.401855   BatchTime 0.226007   LR 0.000683
INFO - Training [48][  180/  196]   Loss 2.302701   Top1 10.062934   Top5 49.348958   BatchTime 0.224331   LR 0.000678
********************pre-trained*****************
INFO - ==> Top1: 10.054    Top5: 49.432    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 2.418745   Top1 10.078125   Top5 50.058594   BatchTime 0.149955
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9359)
features.16.conv.0 tensor(0.8929)
features.16.conv.3 tensor(0.0432)
features.16.conv.6 tensor(0.9918)
conv.0 tensor(0.9854)
tensor(1143735.) 2188896.0
INFO - Validation [48][   40/   40]   Loss 2.420999   Top1 10.000000   Top5 50.000000   BatchTime 0.100307
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.421
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [48][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [47][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [49][   20/  196]   Loss 2.302733   Top1 9.687500   Top5 50.195312   BatchTime 0.325926   LR 0.000669
INFO - Training [49][   40/  196]   Loss 2.302718   Top1 9.794922   Top5 50.185547   BatchTime 0.288862   LR 0.000664
INFO - Training [49][   60/  196]   Loss 2.302740   Top1 9.641927   Top5 49.720052   BatchTime 0.269399   LR 0.000659
INFO - Training [49][   80/  196]   Loss 2.302688   Top1 9.555664   Top5 50.048828   BatchTime 0.258751   LR 0.000654
INFO - Training [49][  100/  196]   Loss 2.302702   Top1 9.519531   Top5 49.835938   BatchTime 0.252132   LR 0.000649
INFO - Training [49][  120/  196]   Loss 2.302676   Top1 9.687500   Top5 49.850260   BatchTime 0.247927   LR 0.000644
INFO - Training [49][  140/  196]   Loss 2.302721   Top1 9.740513   Top5 49.804688   BatchTime 0.244474   LR 0.000639
INFO - Training [49][  160/  196]   Loss 2.302719   Top1 9.760742   Top5 49.873047   BatchTime 0.242108   LR 0.000634
INFO - Training [49][  180/  196]   Loss 2.302697   Top1 9.811198   Top5 49.854601   BatchTime 0.240193   LR 0.000629
********************pre-trained*****************
INFO - ==> Top1: 9.758    Top5: 49.762    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [49][   20/   40]   Loss 2.443406   Top1 10.078125   Top5 50.058594   BatchTime 0.147300
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0616)
features.15.conv.6 tensor(0.9360)
features.16.conv.0 tensor(0.8932)
features.16.conv.3 tensor(0.0434)
features.16.conv.6 tensor(0.9918)
conv.0 tensor(0.9855)
tensor(1143806.) 2188896.0
INFO - Validation [49][   40/   40]   Loss 2.446049   Top1 10.000000   Top5 50.000000   BatchTime 0.101620
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.446
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [49][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [48][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [47][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [50][   20/  196]   Loss 2.302660   Top1 10.429688   Top5 49.746094   BatchTime 0.343116   LR 0.000620
INFO - Training [50][   40/  196]   Loss 2.302671   Top1 10.390625   Top5 49.697266   BatchTime 0.284129   LR 0.000615
INFO - Training [50][   60/  196]   Loss 2.302724   Top1 10.188802   Top5 49.687500   BatchTime 0.262653   LR 0.000610
INFO - Training [50][   80/  196]   Loss 2.302720   Top1 10.083008   Top5 49.682617   BatchTime 0.254997   LR 0.000605
INFO - Training [50][  100/  196]   Loss 2.302682   Top1 9.910156   Top5 49.792969   BatchTime 0.247921   LR 0.000600
INFO - Training [50][  120/  196]   Loss 2.302686   Top1 9.921875   Top5 49.772135   BatchTime 0.246236   LR 0.000595
INFO - Training [50][  140/  196]   Loss 2.302694   Top1 9.827009   Top5 49.642857   BatchTime 0.244955   LR 0.000590
INFO - Training [50][  160/  196]   Loss 2.302685   Top1 9.943848   Top5 49.650879   BatchTime 0.243243   LR 0.000585
INFO - Training [50][  180/  196]   Loss 2.302683   Top1 10.036892   Top5 49.691840   BatchTime 0.241145   LR 0.000580
********************pre-trained*****************
INFO - ==> Top1: 10.044    Top5: 49.718    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [50][   20/   40]   Loss 2.411294   Top1 10.078125   Top5 50.058594   BatchTime 0.149209
INFO - Validation [50][   40/   40]   Loss 2.413544   Top1 10.000000   Top5 50.000000   BatchTime 0.101150
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9362)
features.16.conv.0 tensor(0.8944)
features.16.conv.3 tensor(0.0431)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9855)
tensor(1144042.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.414
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [50][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [49][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [48][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [51][   20/  196]   Loss 2.302618   Top1 9.511719   Top5 49.531250   BatchTime 0.311851   LR 0.000571
INFO - Training [51][   40/  196]   Loss 2.302631   Top1 10.019531   Top5 49.716797   BatchTime 0.265902   LR 0.000566
INFO - Training [51][   60/  196]   Loss 2.302562   Top1 10.000000   Top5 50.000000   BatchTime 0.247157   LR 0.000561
INFO - Training [51][   80/  196]   Loss 2.302638   Top1 10.078125   Top5 49.804688   BatchTime 0.235947   LR 0.000556
INFO - Training [51][  100/  196]   Loss 2.302678   Top1 9.968750   Top5 49.492188   BatchTime 0.229335   LR 0.000551
INFO - Training [51][  120/  196]   Loss 2.302687   Top1 10.022786   Top5 49.563802   BatchTime 0.227031   LR 0.000546
INFO - Training [51][  140/  196]   Loss 2.302671   Top1 9.997210   Top5 49.673549   BatchTime 0.225332   LR 0.000541
INFO - Training [51][  160/  196]   Loss 2.302677   Top1 9.916992   Top5 49.675293   BatchTime 0.223162   LR 0.000536
INFO - Training [51][  180/  196]   Loss 2.302669   Top1 9.984809   Top5 49.613715   BatchTime 0.221752   LR 0.000531
********************pre-trained*****************
INFO - ==> Top1: 10.002    Top5: 49.596    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [51][   20/   40]   Loss 2.461370   Top1 10.078125   Top5 50.058594   BatchTime 0.153337
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9351)
features.16.conv.0 tensor(0.8916)
features.16.conv.3 tensor(0.0429)
features.16.conv.6 tensor(0.9918)
conv.0 tensor(0.9854)
tensor(1143376.) 2188896.0
INFO - Validation [51][   40/   40]   Loss 2.463954   Top1 10.000000   Top5 50.000000   BatchTime 0.106101
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.464
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [51][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [50][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [52][   20/  196]   Loss 2.302548   Top1 10.800781   Top5 50.820312   BatchTime 0.336357   LR 0.000523
INFO - Training [52][   40/  196]   Loss 2.302616   Top1 10.253906   Top5 50.039062   BatchTime 0.286600   LR 0.000518
INFO - Training [52][   60/  196]   Loss 2.302653   Top1 10.110677   Top5 49.654948   BatchTime 0.268713   LR 0.000513
INFO - Training [52][   80/  196]   Loss 2.302634   Top1 10.249023   Top5 49.741211   BatchTime 0.256777   LR 0.000508
INFO - Training [52][  100/  196]   Loss 2.302650   Top1 10.156250   Top5 49.746094   BatchTime 0.250359   LR 0.000503
INFO - Training [52][  120/  196]   Loss 2.302631   Top1 10.211589   Top5 49.830729   BatchTime 0.247590   LR 0.000498
INFO - Training [52][  140/  196]   Loss 2.302657   Top1 10.111607   Top5 49.687500   BatchTime 0.244043   LR 0.000493
INFO - Training [52][  160/  196]   Loss 2.302656   Top1 10.095215   Top5 49.636230   BatchTime 0.241520   LR 0.000488
INFO - Training [52][  180/  196]   Loss 2.302669   Top1 10.034722   Top5 49.672309   BatchTime 0.238148   LR 0.000483
INFO - ==> Top1: 9.974    Top5: 49.640    Loss: 2.303
********************pre-trained*****************
validation quantized model on cpu
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [52][   20/   40]   Loss 2.433830   Top1 10.078125   Top5 50.058594   BatchTime 0.151267
INFO - Validation [52][   40/   40]   Loss 2.436405   Top1 10.000000   Top5 50.000000   BatchTime 0.102301
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.436
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [52][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [51][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [50][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0608)
features.15.conv.6 tensor(0.9349)
features.16.conv.0 tensor(0.8914)
features.16.conv.3 tensor(0.0424)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9854)
tensor(1143349.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [53][   20/  196]   Loss 2.302659   Top1 9.804688   Top5 50.058594   BatchTime 0.335264   LR 0.000474
INFO - Training [53][   40/  196]   Loss 2.302622   Top1 9.843750   Top5 49.726562   BatchTime 0.280540   LR 0.000470
INFO - Training [53][   60/  196]   Loss 2.302599   Top1 9.804688   Top5 50.000000   BatchTime 0.266096   LR 0.000465
INFO - Training [53][   80/  196]   Loss 2.302649   Top1 9.702148   Top5 49.926758   BatchTime 0.257287   LR 0.000460
INFO - Training [53][  100/  196]   Loss 2.302654   Top1 9.710938   Top5 49.824219   BatchTime 0.249983   LR 0.000455
INFO - Training [53][  120/  196]   Loss 2.302679   Top1 9.710286   Top5 49.759115   BatchTime 0.244840   LR 0.000450
INFO - Training [53][  140/  196]   Loss 2.302701   Top1 9.712612   Top5 49.642857   BatchTime 0.243552   LR 0.000445
INFO - Training [53][  160/  196]   Loss 2.302709   Top1 9.687500   Top5 49.584961   BatchTime 0.240528   LR 0.000441
INFO - Training [53][  180/  196]   Loss 2.302720   Top1 9.615885   Top5 49.483507   BatchTime 0.237708   LR 0.000436
********************pre-trained*****************
INFO - ==> Top1: 9.624    Top5: 49.438    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 2.430407   Top1 10.078125   Top5 50.058594   BatchTime 0.152737
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9354)
features.16.conv.0 tensor(0.8923)
features.16.conv.3 tensor(0.0429)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9854)
tensor(1143585.) 2188896.0
INFO - Validation [53][   40/   40]   Loss 2.432766   Top1 10.000000   Top5 50.000000   BatchTime 0.103274
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.433
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [53][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [52][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [51][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [54][   20/  196]   Loss 2.302429   Top1 10.292969   Top5 50.722656   BatchTime 0.329575   LR 0.000427
INFO - Training [54][   40/  196]   Loss 2.302551   Top1 9.853516   Top5 50.478516   BatchTime 0.268598   LR 0.000423
INFO - Training [54][   60/  196]   Loss 2.302525   Top1 9.954427   Top5 50.625000   BatchTime 0.248268   LR 0.000418
INFO - Training [54][   80/  196]   Loss 2.302560   Top1 9.799805   Top5 50.292969   BatchTime 0.241226   LR 0.000413
INFO - Training [54][  100/  196]   Loss 2.302593   Top1 9.703125   Top5 50.078125   BatchTime 0.235781   LR 0.000408
INFO - Training [54][  120/  196]   Loss 2.302608   Top1 9.713542   Top5 49.879557   BatchTime 0.231277   LR 0.000404
INFO - Training [54][  140/  196]   Loss 2.302634   Top1 9.690290   Top5 49.715402   BatchTime 0.227341   LR 0.000399
INFO - Training [54][  160/  196]   Loss 2.302645   Top1 9.626465   Top5 49.550781   BatchTime 0.224638   LR 0.000394
INFO - Training [54][  180/  196]   Loss 2.302633   Top1 9.659288   Top5 49.672309   BatchTime 0.223010   LR 0.000390
INFO - ==> Top1: 9.662    Top5: 49.594    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [54][   20/   40]   Loss 2.422874   Top1 10.078125   Top5 50.058594   BatchTime 0.145456
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0616)
features.15.conv.6 tensor(0.9344)
features.16.conv.0 tensor(0.8932)
features.16.conv.3 tensor(0.0432)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9855)
tensor(1143582.) 2188896.0
INFO - Validation [54][   40/   40]   Loss 2.425112   Top1 10.000000   Top5 50.000000   BatchTime 0.099231
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.425
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [54][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [53][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [52][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [55][   20/  196]   Loss 2.302531   Top1 10.039062   Top5 49.804688   BatchTime 0.334686   LR 0.000381
INFO - Training [55][   40/  196]   Loss 2.302616   Top1 9.511719   Top5 49.384766   BatchTime 0.284134   LR 0.000377
INFO - Training [55][   60/  196]   Loss 2.302591   Top1 9.869792   Top5 49.654948   BatchTime 0.273061   LR 0.000372
INFO - Training [55][   80/  196]   Loss 2.302567   Top1 9.946289   Top5 49.990234   BatchTime 0.258737   LR 0.000368
INFO - Training [55][  100/  196]   Loss 2.302555   Top1 10.089844   Top5 49.863281   BatchTime 0.249980   LR 0.000363
INFO - Training [55][  120/  196]   Loss 2.302597   Top1 9.980469   Top5 49.680990   BatchTime 0.244457   LR 0.000358
INFO - Training [55][  140/  196]   Loss 2.302621   Top1 10.002790   Top5 49.656808   BatchTime 0.241523   LR 0.000354
INFO - Training [55][  160/  196]   Loss 2.302627   Top1 10.002441   Top5 49.599609   BatchTime 0.240063   LR 0.000349
INFO - Training [55][  180/  196]   Loss 2.302646   Top1 9.956597   Top5 49.498698   BatchTime 0.238520   LR 0.000345
********************pre-trained*****************
INFO - ==> Top1: 9.932    Top5: 49.392    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [55][   20/   40]   Loss 2.422560   Top1 10.078125   Top5 50.058594   BatchTime 0.158980
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9343)
features.16.conv.0 tensor(0.8928)
features.16.conv.3 tensor(0.0426)
features.16.conv.6 tensor(0.9918)
conv.0 tensor(0.9855)
tensor(1143488.) 2188896.0
INFO - Validation [55][   40/   40]   Loss 2.424949   Top1 10.000000   Top5 50.000000   BatchTime 0.106491
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.425
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [55][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [54][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [53][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [56][   20/  196]   Loss 2.302654   Top1 10.175781   Top5 48.808594   BatchTime 0.337620   LR 0.000337
INFO - Training [56][   40/  196]   Loss 2.302647   Top1 10.107422   Top5 49.707031   BatchTime 0.279256   LR 0.000333
INFO - Training [56][   60/  196]   Loss 2.302663   Top1 9.856771   Top5 49.778646   BatchTime 0.258241   LR 0.000328
INFO - Training [56][   80/  196]   Loss 2.302655   Top1 9.916992   Top5 49.619141   BatchTime 0.251648   LR 0.000324
INFO - Training [56][  100/  196]   Loss 2.302673   Top1 9.726562   Top5 49.554688   BatchTime 0.247214   LR 0.000319
INFO - Training [56][  120/  196]   Loss 2.302679   Top1 9.674479   Top5 49.625651   BatchTime 0.244595   LR 0.000315
INFO - Training [56][  140/  196]   Loss 2.302669   Top1 9.776786   Top5 49.740513   BatchTime 0.241999   LR 0.000311
INFO - Training [56][  160/  196]   Loss 2.302668   Top1 9.919434   Top5 49.675293   BatchTime 0.238647   LR 0.000306
INFO - Training [56][  180/  196]   Loss 2.302668   Top1 9.884983   Top5 49.609375   BatchTime 0.236410   LR 0.000302
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 9.886    Top5: 49.558    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 2.424283   Top1 10.078125   Top5 50.058594   BatchTime 0.153651
INFO - Validation [56][   40/   40]   Loss 2.426409   Top1 10.000000   Top5 50.000000   BatchTime 0.104283
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.426
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [55][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [54][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0615)
features.15.conv.6 tensor(0.9343)
features.16.conv.0 tensor(0.8936)
features.16.conv.3 tensor(0.0431)
features.16.conv.6 tensor(0.9918)
conv.0 tensor(0.9855)
tensor(1143607.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [57][   20/  196]   Loss 2.302694   Top1 9.394531   Top5 49.335938   BatchTime 0.327923   LR 0.000294
INFO - Training [57][   40/  196]   Loss 2.302667   Top1 9.765625   Top5 49.511719   BatchTime 0.277760   LR 0.000290
INFO - Training [57][   60/  196]   Loss 2.302678   Top1 9.843750   Top5 49.270833   BatchTime 0.259148   LR 0.000286
INFO - Training [57][   80/  196]   Loss 2.302630   Top1 9.838867   Top5 49.614258   BatchTime 0.252273   LR 0.000282
INFO - Training [57][  100/  196]   Loss 2.302602   Top1 9.859375   Top5 49.691406   BatchTime 0.249219   LR 0.000277
INFO - Training [57][  120/  196]   Loss 2.302621   Top1 9.869792   Top5 49.557292   BatchTime 0.245434   LR 0.000273
INFO - Training [57][  140/  196]   Loss 2.302649   Top1 9.790737   Top5 49.324777   BatchTime 0.243139   LR 0.000269
INFO - Training [57][  160/  196]   Loss 2.302646   Top1 9.868164   Top5 49.333496   BatchTime 0.241816   LR 0.000265
INFO - Training [57][  180/  196]   Loss 2.302632   Top1 9.906684   Top5 49.470486   BatchTime 0.239946   LR 0.000261
INFO - ==> Top1: 9.846    Top5: 49.374    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 2.431699   Top1 10.078125   Top5 50.058594   BatchTime 0.152569
INFO - Validation [57][   40/   40]   Loss 2.433909   Top1 10.000000   Top5 50.000000   BatchTime 0.102502
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.434
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [57][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [56][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [55][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0617)
features.15.conv.6 tensor(0.9342)
features.16.conv.0 tensor(0.8943)
features.16.conv.3 tensor(0.0433)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9855)
tensor(1143745.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [58][   20/  196]   Loss 2.302572   Top1 9.726562   Top5 49.707031   BatchTime 0.347967   LR 0.000254
INFO - Training [58][   40/  196]   Loss 2.302548   Top1 10.312500   Top5 49.960938   BatchTime 0.292223   LR 0.000250
INFO - Training [58][   60/  196]   Loss 2.302596   Top1 10.065104   Top5 49.680990   BatchTime 0.273893   LR 0.000246
INFO - Training [58][   80/  196]   Loss 2.302639   Top1 9.882812   Top5 49.682617   BatchTime 0.262530   LR 0.000242
INFO - Training [58][  100/  196]   Loss 2.302634   Top1 9.867188   Top5 49.703125   BatchTime 0.255057   LR 0.000238
INFO - Training [58][  120/  196]   Loss 2.302650   Top1 9.772135   Top5 49.381510   BatchTime 0.249994   LR 0.000234
INFO - Training [58][  140/  196]   Loss 2.302638   Top1 9.804688   Top5 49.525670   BatchTime 0.246581   LR 0.000230
INFO - Training [58][  160/  196]   Loss 2.302633   Top1 9.736328   Top5 49.572754   BatchTime 0.243000   LR 0.000226
INFO - Training [58][  180/  196]   Loss 2.302640   Top1 9.774306   Top5 49.520399   BatchTime 0.241403   LR 0.000222
********************pre-trained*****************
INFO - ==> Top1: 9.794    Top5: 49.604    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [58][   20/   40]   Loss 2.432679   Top1 10.078125   Top5 50.058594   BatchTime 0.157901
INFO - Validation [58][   40/   40]   Loss 2.435056   Top1 10.000000   Top5 50.000000   BatchTime 0.107496
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.435
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [58][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [57][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [56][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0617)
features.15.conv.6 tensor(0.9343)
features.16.conv.0 tensor(0.8946)
features.16.conv.3 tensor(0.0431)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9855)
tensor(1143805.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [59][   20/  196]   Loss 2.302585   Top1 10.644531   Top5 50.000000   BatchTime 0.337892   LR 0.000215
INFO - Training [59][   40/  196]   Loss 2.302565   Top1 10.244141   Top5 50.625000   BatchTime 0.280357   LR 0.000212
INFO - Training [59][   60/  196]   Loss 2.302597   Top1 10.136719   Top5 50.520833   BatchTime 0.263652   LR 0.000208
INFO - Training [59][   80/  196]   Loss 2.302652   Top1 9.877930   Top5 50.053711   BatchTime 0.252856   LR 0.000204
INFO - Training [59][  100/  196]   Loss 2.302647   Top1 9.828125   Top5 49.996094   BatchTime 0.247670   LR 0.000201
INFO - Training [59][  120/  196]   Loss 2.302653   Top1 9.847005   Top5 49.775391   BatchTime 0.242911   LR 0.000197
INFO - Training [59][  140/  196]   Loss 2.302640   Top1 9.888393   Top5 49.829799   BatchTime 0.239507   LR 0.000193
INFO - Training [59][  160/  196]   Loss 2.302631   Top1 9.946289   Top5 49.792480   BatchTime 0.238617   LR 0.000190
INFO - Training [59][  180/  196]   Loss 2.302654   Top1 9.900174   Top5 49.650608   BatchTime 0.237868   LR 0.000186
********************pre-trained*****************
INFO - ==> Top1: 9.854    Top5: 49.624    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [59][   20/   40]   Loss 2.435388   Top1 10.078125   Top5 50.058594   BatchTime 0.154631
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0617)
features.15.conv.6 tensor(0.9344)
features.16.conv.0 tensor(0.8946)
features.16.conv.3 tensor(0.0431)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9855)
tensor(1143826.) 2188896.0
INFO - Validation [59][   40/   40]   Loss 2.437797   Top1 10.000000   Top5 50.000000   BatchTime 0.104063
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.438
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [59][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [58][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [57][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  60
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [60][   20/  196]   Loss 2.302694   Top1 9.980469   Top5 49.062500   BatchTime 0.336181   LR 0.000180
INFO - Training [60][   40/  196]   Loss 2.302664   Top1 10.068359   Top5 49.794922   BatchTime 0.281814   LR 0.000176
INFO - Training [60][   60/  196]   Loss 2.302673   Top1 10.091146   Top5 49.798177   BatchTime 0.265195   LR 0.000173
INFO - Training [60][   80/  196]   Loss 2.302661   Top1 10.092773   Top5 49.975586   BatchTime 0.252469   LR 0.000169
INFO - Training [60][  100/  196]   Loss 2.302641   Top1 10.144531   Top5 50.074219   BatchTime 0.247209   LR 0.000166
INFO - Training [60][  120/  196]   Loss 2.302641   Top1 10.074870   Top5 49.915365   BatchTime 0.241763   LR 0.000162
INFO - Training [60][  140/  196]   Loss 2.302640   Top1 10.022321   Top5 49.796317   BatchTime 0.237919   LR 0.000159
INFO - Training [60][  160/  196]   Loss 2.302651   Top1 9.987793   Top5 49.648438   BatchTime 0.235008   LR 0.000156
INFO - Training [60][  180/  196]   Loss 2.302649   Top1 9.997830   Top5 49.602865   BatchTime 0.233535   LR 0.000152
INFO - ==> Top1: 9.958    Top5: 49.546    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [60][   20/   40]   Loss 2.425404   Top1 10.078125   Top5 50.058594   BatchTime 0.161412
INFO - Validation [60][   40/   40]   Loss 2.427941   Top1 10.000000   Top5 50.000000   BatchTime 0.107794
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.428
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [60][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [59][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [58][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0613)
features.15.conv.6 tensor(0.9345)
features.16.conv.0 tensor(0.8949)
features.16.conv.3 tensor(0.0432)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9856)
tensor(1143883.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  61
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [61][   20/  196]   Loss 2.302581   Top1 10.468750   Top5 49.453125   BatchTime 0.346115   LR 0.000147
INFO - Training [61][   40/  196]   Loss 2.302602   Top1 10.058594   Top5 49.619141   BatchTime 0.287975   LR 0.000143
INFO - Training [61][   60/  196]   Loss 2.302619   Top1 9.902344   Top5 49.589844   BatchTime 0.264512   LR 0.000140
INFO - Training [61][   80/  196]   Loss 2.302614   Top1 9.931641   Top5 49.956055   BatchTime 0.256213   LR 0.000137
INFO - Training [61][  100/  196]   Loss 2.302618   Top1 9.937500   Top5 49.871094   BatchTime 0.252146   LR 0.000134
INFO - Training [61][  120/  196]   Loss 2.302619   Top1 9.951172   Top5 49.882812   BatchTime 0.246475   LR 0.000131
INFO - Training [61][  140/  196]   Loss 2.302621   Top1 10.061384   Top5 50.000000   BatchTime 0.243672   LR 0.000128
INFO - Training [61][  160/  196]   Loss 2.302611   Top1 10.136719   Top5 49.995117   BatchTime 0.240916   LR 0.000125
INFO - Training [61][  180/  196]   Loss 2.302623   Top1 10.043403   Top5 49.986979   BatchTime 0.239961   LR 0.000122
INFO - ==> Top1: 10.080    Top5: 50.028    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [61][   20/   40]   Loss 2.433283   Top1 10.078125   Top5 50.058594   BatchTime 0.158736
INFO - Validation [61][   40/   40]   Loss 2.435719   Top1 10.000000   Top5 50.000000   BatchTime 0.105735
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.436
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [61][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [60][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [59][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0616)
features.15.conv.6 tensor(0.9343)
features.16.conv.0 tensor(0.8949)
features.16.conv.3 tensor(0.0432)
features.16.conv.6 tensor(0.9918)
conv.0 tensor(0.9856)
tensor(1143839.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  62
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [62][   20/  196]   Loss 2.302508   Top1 9.707031   Top5 49.863281   BatchTime 0.330650   LR 0.000117
INFO - Training [62][   40/  196]   Loss 2.302595   Top1 9.658203   Top5 49.599609   BatchTime 0.285872   LR 0.000114
INFO - Training [62][   60/  196]   Loss 2.302646   Top1 9.648438   Top5 49.251302   BatchTime 0.267725   LR 0.000111
INFO - Training [62][   80/  196]   Loss 2.302612   Top1 9.868164   Top5 49.311523   BatchTime 0.255802   LR 0.000108
INFO - Training [62][  100/  196]   Loss 2.302625   Top1 9.808594   Top5 49.281250   BatchTime 0.255741   LR 0.000105
INFO - Training [62][  120/  196]   Loss 2.302618   Top1 9.873047   Top5 49.401042   BatchTime 0.250115   LR 0.000102
INFO - Training [62][  140/  196]   Loss 2.302631   Top1 9.835379   Top5 49.363839   BatchTime 0.246154   LR 0.000100
INFO - Training [62][  160/  196]   Loss 2.302638   Top1 9.846191   Top5 49.355469   BatchTime 0.242787   LR 0.000097
INFO - Training [62][  180/  196]   Loss 2.302644   Top1 9.858941   Top5 49.303385   BatchTime 0.240387   LR 0.000094
INFO - ==> Top1: 9.850    Top5: 49.438    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [62][   20/   40]   Loss 2.427857   Top1 10.078125   Top5 50.058594   BatchTime 0.156937
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0615)
features.15.conv.6 tensor(0.9343)
features.16.conv.0 tensor(0.8948)
features.16.conv.3 tensor(0.0432)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9856)
tensor(1143839.) 2188896.0
INFO - Validation [62][   40/   40]   Loss 2.430283   Top1 10.000000   Top5 50.000000   BatchTime 0.104708
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.430
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [62][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [61][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [60][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  63
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [63][   20/  196]   Loss 2.302781   Top1 9.628906   Top5 48.847656   BatchTime 0.342264   LR 0.000090
INFO - Training [63][   40/  196]   Loss 2.302660   Top1 10.136719   Top5 49.951172   BatchTime 0.293615   LR 0.000087
INFO - Training [63][   60/  196]   Loss 2.302637   Top1 10.039062   Top5 49.960938   BatchTime 0.271130   LR 0.000085
INFO - Training [63][   80/  196]   Loss 2.302647   Top1 9.926758   Top5 49.780273   BatchTime 0.260168   LR 0.000082
INFO - Training [63][  100/  196]   Loss 2.302622   Top1 10.031250   Top5 49.914062   BatchTime 0.254647   LR 0.000080
INFO - Training [63][  120/  196]   Loss 2.302619   Top1 9.980469   Top5 49.925130   BatchTime 0.249180   LR 0.000077
INFO - Training [63][  140/  196]   Loss 2.302609   Top1 10.033482   Top5 50.139509   BatchTime 0.247060   LR 0.000075
INFO - Training [63][  160/  196]   Loss 2.302606   Top1 10.080566   Top5 50.090332   BatchTime 0.245373   LR 0.000072
INFO - Training [63][  180/  196]   Loss 2.302604   Top1 10.101997   Top5 50.088976   BatchTime 0.241955   LR 0.000070
INFO - ==> Top1: 10.112    Top5: 50.174    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [63][   20/   40]   Loss 2.450969   Top1 10.078125   Top5 50.058594   BatchTime 0.158850
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0612)
features.15.conv.6 tensor(0.9342)
features.16.conv.0 tensor(0.8939)
features.16.conv.3 tensor(0.0433)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9855)
tensor(1143652.) 2188896.0
INFO - Validation [63][   40/   40]   Loss 2.453337   Top1 10.000000   Top5 50.000000   BatchTime 0.106542
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.453
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [63][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [62][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [61][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  64
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [64][   20/  196]   Loss 2.302625   Top1 9.726562   Top5 51.230469   BatchTime 0.345497   LR 0.000066
INFO - Training [64][   40/  196]   Loss 2.302618   Top1 9.736328   Top5 50.888672   BatchTime 0.285360   LR 0.000064
INFO - Training [64][   60/  196]   Loss 2.302623   Top1 9.837240   Top5 50.416667   BatchTime 0.264059   LR 0.000062
INFO - Training [64][   80/  196]   Loss 2.302635   Top1 10.019531   Top5 50.190430   BatchTime 0.252829   LR 0.000059
INFO - Training [64][  100/  196]   Loss 2.302678   Top1 9.949219   Top5 49.941406   BatchTime 0.244132   LR 0.000057
INFO - Training [64][  120/  196]   Loss 2.302674   Top1 9.824219   Top5 49.899089   BatchTime 0.239561   LR 0.000055
INFO - Training [64][  140/  196]   Loss 2.302673   Top1 9.843750   Top5 49.773996   BatchTime 0.236125   LR 0.000053
INFO - Training [64][  160/  196]   Loss 2.302669   Top1 9.924316   Top5 49.768066   BatchTime 0.234209   LR 0.000051
INFO - Training [64][  180/  196]   Loss 2.302679   Top1 9.858941   Top5 49.754774   BatchTime 0.232266   LR 0.000049
INFO - ==> Top1: 9.926    Top5: 49.746    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [64][   20/   40]   Loss 2.443854   Top1 10.078125   Top5 50.058594   BatchTime 0.160085
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0617)
features.15.conv.6 tensor(0.9342)
features.16.conv.0 tensor(0.8941)
features.16.conv.3 tensor(0.0432)
features.16.conv.6 tensor(0.9918)
conv.0 tensor(0.9855)
tensor(1143689.) 2188896.0
INFO - Validation [64][   40/   40]   Loss 2.446359   Top1 10.000000   Top5 50.000000   BatchTime 0.104909
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.446
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [64][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [63][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [62][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  65
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [65][   20/  196]   Loss 2.302605   Top1 9.648438   Top5 48.906250   BatchTime 0.326307   LR 0.000046
INFO - Training [65][   40/  196]   Loss 2.302634   Top1 9.960938   Top5 49.355469   BatchTime 0.277695   LR 0.000044
INFO - Training [65][   60/  196]   Loss 2.302557   Top1 10.253906   Top5 49.947917   BatchTime 0.265222   LR 0.000042
INFO - Training [65][   80/  196]   Loss 2.302531   Top1 10.322266   Top5 50.063477   BatchTime 0.256456   LR 0.000040
INFO - Training [65][  100/  196]   Loss 2.302562   Top1 10.257812   Top5 50.023438   BatchTime 0.250075   LR 0.000039
INFO - Training [65][  120/  196]   Loss 2.302569   Top1 10.081380   Top5 49.957682   BatchTime 0.244812   LR 0.000037
INFO - Training [65][  140/  196]   Loss 2.302552   Top1 10.044643   Top5 50.117188   BatchTime 0.241125   LR 0.000035
INFO - Training [65][  160/  196]   Loss 2.302567   Top1 9.990234   Top5 50.117188   BatchTime 0.238655   LR 0.000033
INFO - Training [65][  180/  196]   Loss 2.302567   Top1 10.075955   Top5 50.056424   BatchTime 0.236057   LR 0.000032
********************pre-trained*****************
INFO - ==> Top1: 10.130    Top5: 49.964    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [65][   20/   40]   Loss 2.437347   Top1 10.078125   Top5 50.058594   BatchTime 0.166864
INFO - Validation [65][   40/   40]   Loss 2.439583   Top1 10.000000   Top5 50.000000   BatchTime 0.110706
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0612)
features.15.conv.6 tensor(0.9342)
features.16.conv.0 tensor(0.8941)
features.16.conv.3 tensor(0.0429)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9855)
tensor(1143692.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.440
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [65][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [64][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [63][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  66
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [66][   20/  196]   Loss 2.302664   Top1 10.175781   Top5 50.156250   BatchTime 0.330629   LR 0.000029
INFO - Training [66][   40/  196]   Loss 2.302676   Top1 10.000000   Top5 49.853516   BatchTime 0.281273   LR 0.000028
INFO - Training [66][   60/  196]   Loss 2.302687   Top1 9.863281   Top5 49.498698   BatchTime 0.268505   LR 0.000026
INFO - Training [66][   80/  196]   Loss 2.302666   Top1 9.956055   Top5 49.667969   BatchTime 0.264951   LR 0.000025
INFO - Training [66][  100/  196]   Loss 2.302651   Top1 9.898438   Top5 49.875000   BatchTime 0.258747   LR 0.000023
INFO - Training [66][  120/  196]   Loss 2.302646   Top1 9.843750   Top5 49.752604   BatchTime 0.254063   LR 0.000022
INFO - Training [66][  140/  196]   Loss 2.302629   Top1 9.891183   Top5 49.899554   BatchTime 0.250546   LR 0.000021
INFO - Training [66][  160/  196]   Loss 2.302631   Top1 9.916992   Top5 49.782715   BatchTime 0.249879   LR 0.000019
INFO - Training [66][  180/  196]   Loss 2.302626   Top1 9.937066   Top5 49.871962   BatchTime 0.245933   LR 0.000018
INFO - ==> Top1: 9.922    Top5: 49.824    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [66][   20/   40]   Loss 2.428817   Top1 10.078125   Top5 50.058594   BatchTime 0.160987
INFO - Validation [66][   40/   40]   Loss 2.431189   Top1 10.000000   Top5 50.000000   BatchTime 0.107730
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.431
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [66][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [65][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [64][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0612)
features.15.conv.6 tensor(0.9343)
features.16.conv.0 tensor(0.8940)
features.16.conv.3 tensor(0.0431)
features.16.conv.6 tensor(0.9918)
conv.0 tensor(0.9855)
tensor(1143658.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  67
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [67][   20/  196]   Loss 2.302787   Top1 9.531250   Top5 48.398438   BatchTime 0.344657   LR 0.000016
INFO - Training [67][   40/  196]   Loss 2.302700   Top1 9.892578   Top5 48.886719   BatchTime 0.279416   LR 0.000015
INFO - Training [67][   60/  196]   Loss 2.302668   Top1 10.026042   Top5 49.335938   BatchTime 0.254660   LR 0.000014
INFO - Training [67][   80/  196]   Loss 2.302659   Top1 10.112305   Top5 49.643555   BatchTime 0.241856   LR 0.000013
INFO - Training [67][  100/  196]   Loss 2.302642   Top1 10.085938   Top5 49.835938   BatchTime 0.236748   LR 0.000012
INFO - Training [67][  120/  196]   Loss 2.302640   Top1 10.003255   Top5 49.729818   BatchTime 0.231216   LR 0.000011
INFO - Training [67][  140/  196]   Loss 2.302647   Top1 9.949777   Top5 49.827009   BatchTime 0.228781   LR 0.000010
INFO - Training [67][  160/  196]   Loss 2.302632   Top1 10.004883   Top5 49.772949   BatchTime 0.226927   LR 0.000009
INFO - Training [67][  180/  196]   Loss 2.302625   Top1 9.982639   Top5 49.876302   BatchTime 0.224164   LR 0.000008
********************pre-trained*****************
INFO - ==> Top1: 9.982    Top5: 49.906    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [67][   20/   40]   Loss 2.428981   Top1 10.078125   Top5 50.058594   BatchTime 0.166073
INFO - Validation [67][   40/   40]   Loss 2.431364   Top1 10.000000   Top5 50.000000   BatchTime 0.111655
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0617)
features.15.conv.6 tensor(0.9343)
features.16.conv.0 tensor(0.8940)
features.16.conv.3 tensor(0.0432)
features.16.conv.6 tensor(0.9918)
conv.0 tensor(0.9855)
tensor(1143698.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.431
INFO - ==> Sparsity : 0.522
INFO - Scoreboard best 1 ==> Epoch [67][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  68
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [68][   20/  196]   Loss 2.302630   Top1 10.136719   Top5 49.726562   BatchTime 0.351390   LR 0.000007
INFO - Training [68][   40/  196]   Loss 2.302659   Top1 10.058594   Top5 49.804688   BatchTime 0.293456   LR 0.000006
INFO - Training [68][   60/  196]   Loss 2.302675   Top1 10.123698   Top5 49.804688   BatchTime 0.272885   LR 0.000006
INFO - Training [68][   80/  196]   Loss 2.302660   Top1 9.941406   Top5 49.863281   BatchTime 0.261912   LR 0.000005
INFO - Training [68][  100/  196]   Loss 2.302649   Top1 9.949219   Top5 49.664062   BatchTime 0.253557   LR 0.000004
INFO - Training [68][  120/  196]   Loss 2.302640   Top1 10.035807   Top5 49.619141   BatchTime 0.248147   LR 0.000004
INFO - Training [68][  140/  196]   Loss 2.302631   Top1 10.002790   Top5 49.762835   BatchTime 0.244078   LR 0.000003
INFO - Training [68][  160/  196]   Loss 2.302635   Top1 10.017090   Top5 49.809570   BatchTime 0.240860   LR 0.000003
INFO - Training [68][  180/  196]   Loss 2.302627   Top1 10.004340   Top5 49.748264   BatchTime 0.237593   LR 0.000002
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 9.978    Top5: 49.672    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [68][   20/   40]   Loss 2.428835   Top1 10.078125   Top5 50.058594   BatchTime 0.163882
INFO - Validation [68][   40/   40]   Loss 2.431027   Top1 10.000000   Top5 50.000000   BatchTime 0.109347
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.431
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [68][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [67][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [66][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0613)
features.15.conv.6 tensor(0.9342)
features.16.conv.0 tensor(0.8940)
features.16.conv.3 tensor(0.0431)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9856)
tensor(1143730.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  69
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [69][   20/  196]   Loss 2.302630   Top1 9.882812   Top5 49.785156   BatchTime 0.323169   LR 0.000002
INFO - Training [69][   40/  196]   Loss 2.302623   Top1 9.882812   Top5 49.912109   BatchTime 0.269122   LR 0.000001
INFO - Training [69][   60/  196]   Loss 2.302616   Top1 10.000000   Top5 49.986979   BatchTime 0.251271   LR 0.000001
INFO - Training [69][   80/  196]   Loss 2.302596   Top1 10.078125   Top5 50.244141   BatchTime 0.239479   LR 0.000001
INFO - Training [69][  100/  196]   Loss 2.302597   Top1 10.023438   Top5 50.042969   BatchTime 0.232231   LR 0.000000
INFO - Training [69][  120/  196]   Loss 2.302599   Top1 10.019531   Top5 49.889323   BatchTime 0.229401   LR 0.000000
INFO - Training [69][  140/  196]   Loss 2.302586   Top1 10.016741   Top5 50.058594   BatchTime 0.227264   LR 0.000000
INFO - Training [69][  160/  196]   Loss 2.302588   Top1 10.102539   Top5 50.053711   BatchTime 0.225178   LR 0.000000
INFO - Training [69][  180/  196]   Loss 2.302579   Top1 10.052083   Top5 50.097656   BatchTime 0.222853   LR 0.000000
********************pre-trained*****************
INFO - ==> Top1: 10.006    Top5: 50.034    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [69][   20/   40]   Loss 2.414381   Top1 10.078125   Top5 50.058594   BatchTime 0.196298
INFO - Validation [69][   40/   40]   Loss 2.416656   Top1 10.000000   Top5 50.000000   BatchTime 0.125959
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.417
INFO - ==> Sparsity : 0.523
INFO - Scoreboard best 1 ==> Epoch [69][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 2 ==> Epoch [68][Top1: 10.000   Top5: 50.000]
INFO - Scoreboard best 3 ==> Epoch [67][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(1.)
features.15.conv.3 tensor(0.0616)
features.15.conv.6 tensor(0.9343)
features.16.conv.0 tensor(0.8940)
features.16.conv.3 tensor(0.0432)
features.16.conv.6 tensor(0.9919)
conv.0 tensor(0.9855)
tensor(1143723.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 2.414381   Top1 10.078125   Top5 50.058594   BatchTime 0.161236
INFO - Validation [   40/   40]   Loss 2.416656   Top1 10.000000   Top5 50.000000   BatchTime 0.106907
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 2.417
INFO - ==> Sparsity : 0.000
INFO - Program completed sucessfully ... exiting ...