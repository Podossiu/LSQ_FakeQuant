Files already downloaded and verified
Files already downloaded and verified
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = True
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
  warnings.warn(
INFO - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005
INFO - >>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
*************soft_pruning_mode*******************
0.00000000
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.00000000
0.95438832
0.95022774
0.93792444
0.92494458
0.91841698
0.90955973
0.91534513
0.91676396
INFO - Training [0][   20/  196]   Loss 1.580633   Top1 53.867188   Top5 89.355469   BatchTime 0.374495   LR 0.004999
0.91578811
0.91690201
0.91423291
0.90390593
0.89299172
0.88401157
0.87973469
0.87725425
0.87829125
0.88148242
0.88343281
0.88575107
0.88830489
0.89125681
0.89387739
0.89546853
0.89700598
0.89802891
0.89935482
0.90195006
0.90449643
INFO - Training [0][   40/  196]   Loss 1.492875   Top1 52.988281   Top5 89.707031   BatchTime 0.373664   LR 0.004995
0.90636748
0.90830952
0.91004771
0.90890121
0.91247803
0.91569948
0.91643763
0.91732836
0.91763544
0.91842413
0.91928005
0.91986042
0.92040449
0.92099172
0.92184532
0.92234957
0.92277080
0.92327183
0.92391062
0.92432058
0.92436683
INFO - Training [0][   60/  196]   Loss 1.387285   Top1 55.345052   Top5 90.950521   BatchTime 0.379849   LR 0.004989
0.92441487
0.92419791
0.92438358
0.92424339
0.92464083
0.92454231
0.92438310
0.92436749
0.92443937
0.92450911
0.92408037
0.92408961
0.92416424
0.92404383
0.92377019
0.92378485
0.92377722
0.92342830
0.92326623
0.92342401
INFO - Training [0][   80/  196]   Loss 1.320196   Top1 57.270508   Top5 91.743164   BatchTime 0.383441   LR 0.004980
0.92333221
0.91602445
0.90128821
0.91022992
0.90482372
0.89780402
0.89732778
0.89549327
0.89578205
0.89714587
0.89591366
0.89459765
0.89037120
0.88556653
0.87934601
0.87328047
INFO - Training [0][  100/  196]   Loss 1.259414   Top1 58.894531   Top5 92.488281   BatchTime 0.383419   LR 0.004968
0.87034291
0.86892295
0.87045127
0.87286204
0.87392932
0.87337160
0.87342948
0.87354112
0.87419701
0.87544364
0.87739843
0.87831277
0.87902284
0.87868255
0.87852210
0.87802637
0.87742817
0.87799823
0.87789893
0.87807995
INFO - Training [0][  120/  196]   Loss 1.213198   Top1 60.322266   Top5 93.072917   BatchTime 0.384093   LR 0.004954
0.87836587
0.87892479
0.87952304
0.88059849
0.88234168
0.88338846
0.88551050
0.88752806
0.88836890
0.88968903
0.89041930
0.89102280
0.89204663
0.89282858
0.89383829
0.89511395
0.89687842
0.89778078
0.89930010
0.90038157
0.90126479
INFO - Training [0][  140/  196]   Loss 1.179248   Top1 61.238839   Top5 93.462612   BatchTime 0.385133   LR 0.004938
0.90193576
0.90264654
0.90326840
0.90392250
0.90422368
0.90460867
0.90502596
0.90530765
0.90534669
0.90568393
0.90534240
0.90590084
0.90616602
0.90630704
0.90640599
0.90521824
0.90629095
0.90648258
0.90637386
0.90617055
INFO - Training [0][  160/  196]   Loss 1.153554   Top1 61.958008   Top5 93.708496   BatchTime 0.387638   LR 0.004919
0.90593493
0.90610254
0.90628928
0.90495974
0.90372521
0.90587676
0.90563303
0.90535873
0.90508991
0.90472221
0.90456480
0.90416360
0.90376383
0.90361148
0.90364897
0.90314549
0.90266460
0.90241688
INFO - Training [0][  180/  196]   Loss 1.130509   Top1 62.612847   Top5 93.895399   BatchTime 0.393219   LR 0.004897
0.90173405
0.89862216
0.89288765
0.88465166
0.87969112
0.87619311
0.87426740
0.87694854
0.88125992
0.88542187
0.88930678
0.89093298
0.89413470
0.89630765
0.89779770
0.89859086
0.89823812
0.89801085
0.89769870
INFO - ==> Top1: 63.152    Top5: 94.036    Loss: 1.112
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.89773160
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [0][   20/   40]   Loss 0.865341   Top1 74.296875   Top5 97.812500   BatchTime 0.115533
INFO - Validation [0][   40/   40]   Loss 0.858100   Top1 74.050000   Top5 97.880000   BatchTime 0.089576
INFO - ==> Top1: 74.050    Top5: 97.880    Loss: 0.858
INFO - ==> Sparsity : 0.226
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 74.050   Top5: 97.880]
features.0.conv.0 tensor(0.5833)
features.0.conv.3 tensor(0.2344)
features.1.conv.0 tensor(0.0267)
features.1.conv.3 tensor(0.0995)
features.1.conv.6 tensor(0.0647)
features.2.conv.0 tensor(0.0451)
features.2.conv.3 tensor(0.0664)
features.2.conv.6 tensor(0.0859)
features.3.conv.0 tensor(0.0434)
features.3.conv.3 tensor(0.0586)
features.3.conv.6 tensor(0.0703)
features.4.conv.0 tensor(0.0540)
features.4.conv.3 tensor(0.0909)
features.4.conv.6 tensor(0.1058)
features.5.conv.0 tensor(0.0648)
features.5.conv.3 tensor(0.0596)
features.5.conv.6 tensor(0.1066)
features.6.conv.0 tensor(0.0488)
features.6.conv.3 tensor(0.0469)
features.6.conv.6 tensor(0.0836)
features.7.conv.0 tensor(0.0711)
features.7.conv.3 tensor(0.0992)
features.7.conv.6 tensor(0.1242)
features.8.conv.0 tensor(0.0591)
features.8.conv.3 tensor(0.1204)
features.8.conv.6 tensor(0.1353)
features.9.conv.0 tensor(0.1129)
features.9.conv.3 tensor(0.1071)
features.9.conv.6 tensor(0.1279)
features.10.conv.0 tensor(0.0499)
features.10.conv.3 tensor(0.0932)
features.10.conv.6 tensor(0.1060)
features.11.conv.0 tensor(0.2348)
features.11.conv.3 tensor(0.0924)
features.11.conv.6 tensor(0.1593)
features.12.conv.0 tensor(0.1241)
features.12.conv.3 tensor(0.0912)
features.12.conv.6 tensor(0.4621)
features.13.conv.0 tensor(0.1303)
features.13.conv.3 tensor(0.1231)
features.13.conv.6 tensor(0.1141)
features.14.conv.0 tensor(0.7574)
features.14.conv.3 tensor(0.0914)
features.14.conv.6 tensor(0.3001)
features.15.conv.0 tensor(0.7413)
features.15.conv.3 tensor(0.0669)
features.15.conv.6 tensor(0.2553)
features.16.conv.0 tensor(0.0591)
features.16.conv.3 tensor(0.0756)
features.16.conv.6 tensor(0.1043)
conv.0 tensor(0.0858)
tensor(494764.) 2188896.0
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::TupleConstruct type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)
  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
0.89706570
0.89659739
0.89639598
0.89621741
0.89628178
0.89612973
0.89598119
0.89567387
0.89527678
0.89505875
0.89510822
0.89508092
0.89472020
0.89449006
0.89424473
0.89420027
0.89410365
0.89398390
0.89398015
0.89406264
INFO - Training [1][   20/  196]   Loss 0.925481   Top1 69.101562   Top5 95.156250   BatchTime 0.428135   LR 0.004853
0.88082653
0.89419782
0.89400983
0.89405173
0.89388055
0.89383394
0.89410329
0.89400178
0.89351434
0.89345378
0.89342552
0.89331752
0.89333951
0.89320689
0.89320171
0.89329058
INFO - Training [1][   40/  196]   Loss 0.925225   Top1 69.072266   Top5 95.546875   BatchTime 0.394669   LR 0.004825
0.89329529
0.89320379
0.89338034
0.89354312
0.89346427
0.89329910
0.89314008
0.89308757
0.89310235
0.89292520
0.89275265
0.89273924
0.89277035
0.89221245
0.89095825
0.89278018
0.89281964
0.89295769
0.89259744
0.89248496
0.89249593
0.89226925
INFO - Training [1][   60/  196]   Loss 0.905991   Top1 69.648438   Top5 95.690104   BatchTime 0.389611   LR 0.004794
0.89239359
0.89249212
0.89222479
0.89193124
0.89189577
0.89191955
0.89215034
0.89213812
0.89185822
0.89175326
0.89195734
0.89207929
0.89240801
0.89207464
0.89172131
0.89160943
0.89155877
0.89149141
0.89133847
0.89112657
INFO - Training [1][   80/  196]   Loss 0.896313   Top1 69.921875   Top5 95.898438   BatchTime 0.391039   LR 0.004761
0.89186662
0.89152443
0.89136326
0.89130855
0.89114928
0.89124596
0.89114100
0.89141697
0.89164555
0.89162153
0.89163882
0.89179432
0.89161259
0.89217472
0.89107025
0.89001286
0.89037853
0.89092624
0.89122838
0.89083594
0.89112699
0.89052701
INFO - Training [1][  100/  196]   Loss 0.886429   Top1 70.152344   Top5 96.035156   BatchTime 0.384408   LR 0.004725
0.89096552
0.89126813
0.89141649
0.89147437
0.89142114
0.89148957
0.89163220
0.89183831
0.89125288
0.89003015
0.88486212
0.88097405
0.88785893
0.89214641
0.89212292
0.89190167
INFO - Training [1][  120/  196]   Loss 0.878235   Top1 70.416667   Top5 96.217448   BatchTime 0.382040   LR 0.004687
0.89186537
0.89182293
0.89172429
0.89165932
0.89158744
0.89168841
0.89201027
0.89188719
0.89179015
0.89174843
0.89171898
0.89161950
0.89151102
0.89166987
0.89171600
0.89177358
0.89147496
0.89060539
0.88930219
0.89009053
0.89219213
0.89234018
INFO - Training [1][  140/  196]   Loss 0.865506   Top1 70.884487   Top5 96.358817   BatchTime 0.381699   LR 0.004647
0.89229363
0.89183140
0.89150417
0.89153701
0.89142078
0.89137739
0.89127177
0.89140648
0.89122921
0.89143389
0.89170796
0.89185655
0.89188749
0.89164823
0.89126241
0.88813007
0.88414466
0.88616699
0.88641602
0.88646138
0.88618964
INFO - Training [1][  160/  196]   Loss 0.861341   Top1 71.042480   Top5 96.384277   BatchTime 0.380528   LR 0.004605
0.88563985
0.88431740
0.88109744
0.87620604
0.87553537
0.87209779
0.87277144
0.87771714
0.88054490
0.88365310
0.88856012
0.89128876
0.89106995
0.89112711
0.89114010
0.89123392
INFO - Training [1][  180/  196]   Loss 0.852087   Top1 71.395399   Top5 96.401910   BatchTime 0.378544   LR 0.004560
0.89083529
0.89086848
0.89093834
0.89097148
0.89097422
0.89115369
0.89130247
0.89136124
0.89147913
0.89145809
0.89158034
0.89135128
0.89132053
0.89042932
0.88925666
0.88232088
0.89147455
0.89141387
0.89129978
0.89138460
INFO - ==> Top1: 71.560    Top5: 96.412    Loss: 0.849
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.89136606
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [1][   20/   40]   Loss 0.723361   Top1 76.289062   Top5 97.636719   BatchTime 0.115901
INFO - Validation [1][   40/   40]   Loss 0.715044   Top1 76.170000   Top5 97.740000   BatchTime 0.087490
INFO - ==> Top1: 76.170    Top5: 97.740    Loss: 0.715
INFO - ==> Sparsity : 0.255
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 76.170   Top5: 97.740]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 74.050   Top5: 97.880]
features.0.conv.0 tensor(0.5590)
features.0.conv.3 tensor(0.2188)
features.1.conv.0 tensor(0.0371)
features.1.conv.3 tensor(0.0775)
features.1.conv.6 tensor(0.0716)
features.2.conv.0 tensor(0.0472)
features.2.conv.3 tensor(0.0586)
features.2.conv.6 tensor(0.0961)
features.3.conv.0 tensor(0.0425)
features.3.conv.3 tensor(0.0571)
features.3.conv.6 tensor(0.0705)
features.4.conv.0 tensor(0.0479)
features.4.conv.3 tensor(0.0903)
features.4.conv.6 tensor(0.1021)
features.5.conv.0 tensor(0.0532)
features.5.conv.3 tensor(0.0677)
features.5.conv.6 tensor(0.1012)
features.6.conv.0 tensor(0.0405)
features.6.conv.3 tensor(0.0440)
features.6.conv.6 tensor(0.0870)
features.7.conv.0 tensor(0.0533)
features.7.conv.3 tensor(0.1073)
features.7.conv.6 tensor(0.1304)
features.8.conv.0 tensor(0.0627)
features.8.conv.3 tensor(0.1230)
features.8.conv.6 tensor(0.1410)
features.9.conv.0 tensor(0.0957)
features.9.conv.3 tensor(0.1230)
features.9.conv.6 tensor(0.1453)
features.10.conv.0 tensor(0.0482)
features.10.conv.3 tensor(0.1117)
features.10.conv.6 tensor(0.0996)
features.11.conv.0 tensor(0.2522)
features.11.conv.3 tensor(0.0943)
features.11.conv.6 tensor(0.1968)
features.12.conv.0 tensor(0.1328)
features.12.conv.3 tensor(0.0949)
features.12.conv.6 tensor(0.5368)
features.13.conv.0 tensor(0.1155)
features.13.conv.3 tensor(0.1368)
features.13.conv.6 tensor(0.1172)
features.14.conv.0 tensor(0.8516)
features.14.conv.3 tensor(0.0933)
features.14.conv.6 tensor(0.3516)
features.15.conv.0 tensor(0.8146)
features.15.conv.3 tensor(0.0715)
features.15.conv.6 tensor(0.2134)
features.16.conv.0 tensor(0.0467)
features.16.conv.3 tensor(0.0828)
features.16.conv.6 tensor(0.1604)
conv.0 tensor(0.1178)
tensor(557449.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
0.89143395
0.89146680
0.89141351
0.89163589
0.89155388
0.89144123
0.89159244
0.89154279
0.89149666
0.89162022
0.89139146
0.89116043
0.89127487
0.89132041
0.89139861
0.89137512
INFO - Training [2][   20/  196]   Loss 0.825766   Top1 71.796875   Top5 95.878906   BatchTime 0.413550   LR 0.004477
0.89127821
0.89149326
0.89167792
0.89133251
0.89126068
0.89098305
0.89086789
0.89079672
0.89068413
0.89088666
0.89073080
0.86983645
0.89041036
0.89048833
0.89034182
0.89042789
0.89033687
0.89028907
0.89043182
0.89044774
0.89040315
0.89059412
0.89060074
INFO - Training [2][   40/  196]   Loss 0.829900   Top1 72.285156   Top5 96.152344   BatchTime 0.386099   LR 0.004426
0.89075100
0.89065099
0.89089638
0.89095163
0.89091974
0.89089900
0.89098513
0.89138049
0.89123333
0.89105451
0.89113235
0.89139479
0.89152431
0.89163399
0.89151394
0.89127874
0.89124668
INFO - Training [2][   60/  196]   Loss 0.816762   Top1 72.617188   Top5 96.360677   BatchTime 0.375505   LR 0.004374
0.89132744
0.89136058
0.89095587
0.89084661
0.89062017
0.89048648
0.89081776
0.89069647
0.89078271
0.89071238
0.89086908
0.89057553
0.89070171
0.89061230
0.89060658
0.89063102
0.89051974
0.89040112
0.89007479
0.89007515
0.89010674
0.89040655
INFO - Training [2][   80/  196]   Loss 0.805124   Top1 72.880859   Top5 96.582031   BatchTime 0.373627   LR 0.004320
0.89001501
0.88988006
0.88986957
0.89021075
0.89010978
0.89015323
0.89003146
0.88984251
0.88994777
0.89002472
0.89012188
0.89013278
0.89001518
0.88978153
0.88968545
0.88981032
0.88975978
0.88968235
0.88975233
0.88972539
0.88708407
0.87647080
INFO - Training [2][  100/  196]   Loss 0.790376   Top1 73.343750   Top5 96.609375   BatchTime 0.370916   LR 0.004264
0.86502850
0.86263329
0.86209482
0.86215115
0.86200291
0.86133611
0.86219800
0.86247003
0.86298126
0.86445564
0.86785603
0.87168401
0.86681211
0.85835475
0.88823283
0.88947195
INFO - Training [2][  120/  196]   Loss 0.780425   Top1 73.717448   Top5 96.712240   BatchTime 0.370576   LR 0.004206
0.88964736
0.88962764
0.88937730
0.88939726
0.88959235
0.88933599
0.88931888
0.88906944
0.88888472
0.88874888
0.88873506
0.88886809
0.88888234
0.88873506
0.88867068
0.88861364
0.88820726
0.88806862
0.88807172
0.88797706
0.88756168
INFO - Training [2][  140/  196]   Loss 0.778089   Top1 73.783482   Top5 96.738281   BatchTime 0.371092   LR 0.004146
0.88680756
0.88626128
0.88558310
0.88462150
0.88445675
0.88382804
0.88340652
0.88236314
0.88414401
0.88572210
0.88718617
0.88803339
0.88860673
0.88926762
0.88993466
0.88976985
0.88956183
0.88945335
0.88902014
0.88841558
0.88767314
0.88660800
0.88552415
INFO - Training [2][  160/  196]   Loss 0.779509   Top1 73.830566   Top5 96.760254   BatchTime 0.369478   LR 0.004085
0.87948871
0.86798334
0.87980551
0.88785249
0.88895226
0.88906127
0.88911897
0.88905603
0.88896304
0.88884687
0.88879520
0.88902998
0.88916463
0.88892293
0.88875759
0.88873577
0.88859844
0.88835806
0.88823479
0.88810146
INFO - Training [2][  180/  196]   Loss 0.777639   Top1 73.934462   Top5 96.701389   BatchTime 0.362039   LR 0.004022
0.88790184
0.88742632
0.88722903
0.88719386
0.88695115
0.88701183
0.88691926
0.88683009
0.88667214
0.88650018
0.88645345
0.88525289
0.88425136
INFO - ==> Top1: 74.146    Top5: 96.738    Loss: 0.772
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.88530350
0.88579959
0.88583249
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [2][   20/   40]   Loss 0.635498   Top1 78.886719   Top5 98.378906   BatchTime 0.181586
INFO - Validation [2][   40/   40]   Loss 0.623161   Top1 78.830000   Top5 98.520000   BatchTime 0.116481
INFO - ==> Top1: 78.830    Top5: 98.520    Loss: 0.623
INFO - ==> Sparsity : 0.275
INFO - Scoreboard best 1 ==> Epoch [2][Top1: 78.830   Top5: 98.520]
INFO - Scoreboard best 2 ==> Epoch [1][Top1: 76.170   Top5: 97.740]
INFO - Scoreboard best 3 ==> Epoch [0][Top1: 74.050   Top5: 97.880]
features.0.conv.0 tensor(0.5382)
features.0.conv.3 tensor(0.1914)
features.1.conv.0 tensor(0.0306)
features.1.conv.3 tensor(0.0903)
features.1.conv.6 tensor(0.0634)
features.2.conv.0 tensor(0.0362)
features.2.conv.3 tensor(0.0610)
features.2.conv.6 tensor(0.0952)
features.3.conv.0 tensor(0.0451)
features.3.conv.3 tensor(0.0648)
features.3.conv.6 tensor(0.0675)
features.4.conv.0 tensor(0.0392)
features.4.conv.3 tensor(0.0990)
features.4.conv.6 tensor(0.0993)
features.5.conv.0 tensor(0.0500)
features.5.conv.3 tensor(0.0712)
features.5.conv.6 tensor(0.1045)
features.6.conv.0 tensor(0.0306)
features.6.conv.3 tensor(0.0498)
features.6.conv.6 tensor(0.0915)
features.7.conv.0 tensor(0.0607)
features.7.conv.3 tensor(0.1114)
features.7.conv.6 tensor(0.1274)
features.8.conv.0 tensor(0.0608)
features.8.conv.3 tensor(0.1189)
features.8.conv.6 tensor(0.1464)
features.9.conv.0 tensor(0.0511)
features.9.conv.3 tensor(0.1615)
features.9.conv.6 tensor(0.1391)
features.10.conv.0 tensor(0.0314)
features.10.conv.3 tensor(0.1053)
features.10.conv.6 tensor(0.0902)
features.11.conv.0 tensor(0.2759)
features.11.conv.3 tensor(0.1026)
features.11.conv.6 tensor(0.2187)
features.12.conv.0 tensor(0.1436)
features.12.conv.3 tensor(0.0988)
features.12.conv.6 tensor(0.5835)
features.13.conv.0 tensor(0.1388)
features.13.conv.3 tensor(0.1333)
features.13.conv.6 tensor(0.1241)
features.14.conv.0 tensor(0.8665)
features.14.conv.3 tensor(0.0984)
features.14.conv.6 tensor(0.3126)
features.15.conv.0 tensor(0.8540)
features.15.conv.3 tensor(0.0707)
features.15.conv.6 tensor(0.2270)
features.16.conv.0 tensor(0.0603)
features.16.conv.3 tensor(0.0860)
features.16.conv.6 tensor(0.1884)
conv.0 tensor(0.1777)
tensor(602963.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
0.88542026
0.88485307
0.88422513
0.88401657
0.88369220
0.88306439
0.88098478
0.87824237
0.88034731
0.88560557
0.88495272
0.88431442
0.88438654
0.88425434
0.88404834
0.88317901
0.88126296
0.87707341
0.87001950
INFO - Training [3][   20/  196]   Loss 0.752663   Top1 74.726562   Top5 96.718750   BatchTime 0.417437   LR 0.003907
0.86874282
0.86388928
0.86645925
0.86920434
0.87056231
0.87268931
0.87460923
0.87618268
0.87690681
0.87763220
0.87794441
0.87855780
0.87885338
0.87928963
0.87969965
0.88045293
INFO - Training [3][   40/  196]   Loss 0.742807   Top1 75.195312   Top5 96.845703   BatchTime 0.392859   LR 0.003840
0.88129842
0.88174856
0.88218415
0.88244152
0.88266921
0.88276565
0.88314652
0.88379723
0.88471007
0.88626730
0.88882828
0.89197409
0.89340907
0.89433223
0.89328462
0.89086998
0.88517171
0.87406689
0.87017542
0.87074035
0.87976509
0.88554859
INFO - Training [3][   60/  196]   Loss 0.739871   Top1 75.052083   Top5 96.920573   BatchTime 0.383489   LR 0.003771
0.88409561
0.87650257
0.86902010
0.86654031
0.86632019
0.86617094
0.86668438
0.87324929
0.88725191
0.89323491
0.89388615
0.89365160
0.89350206
0.89333224
0.89289081
0.89247698
0.89200920
0.89203793
0.89235801
0.89211810
0.89197499
0.89162940
0.89124119
INFO - Training [3][   80/  196]   Loss 0.725311   Top1 75.732422   Top5 97.055664   BatchTime 0.375720   LR 0.003701
0.89096373
0.89077884
0.89049977
0.88962775
0.88910842
0.88818496
0.88910168
0.89001518
0.89108622
0.89101958
0.89088815
0.89018714
0.88897240
0.88678390
0.88024396
0.87365812
INFO - Training [3][  100/  196]   Loss 0.711092   Top1 76.316406   Top5 97.167969   BatchTime 0.377328   LR 0.003630
0.89181221
0.89306700
0.89273310
0.89151621
0.89127225
0.89359117
0.89368248
0.89385760
0.89371449
0.89370281
0.89371872
0.89347827
0.89315134
0.89296466
0.89281148
0.89288521
0.89264196
0.89223135
0.89179003
0.89169198
INFO - Training [3][  120/  196]   Loss 0.705416   Top1 76.562500   Top5 97.281901   BatchTime 0.378548   LR 0.003558
0.89151073
0.89108866
0.89097780
0.89069360
0.89052975
0.89060616
0.89075577
0.89101017
0.89104247
0.89102161
0.89133412
0.89140987
0.89157647
0.89169478
0.89161366
0.89184332
0.89162928
0.89142543
0.89149612
0.89140958
0.89085543
INFO - Training [3][  140/  196]   Loss 0.701352   Top1 76.699219   Top5 97.307478   BatchTime 0.376233   LR 0.003484
0.89084518
0.89063013
0.89057362
0.89068824
0.89052421
0.89095479
0.89098698
0.89112335
0.89128172
0.89146656
0.89199191
0.89237082
0.89257401
0.89281005
0.89301336
0.89310682
0.89336234
0.89353698
0.89390248
0.89758819
INFO - Training [3][  160/  196]   Loss 0.701080   Top1 76.701660   Top5 97.341309   BatchTime 0.367275   LR 0.003410
0.90132302
0.90233129
0.90236026
0.90219074
0.90221518
0.90228963
0.90232074
0.90243185
0.90246475
0.90229148
0.90207058
0.90104920
0.90113956
0.90099365
0.90084940
0.90028125
0.90068889
0.89994848
0.89957565
0.89817417
0.89899188
0.89981002
INFO - Training [3][  180/  196]   Loss 0.698114   Top1 76.727431   Top5 97.341580   BatchTime 0.369134   LR 0.003335
0.90255368
0.90237272
0.90214854
0.90190464
0.90124512
0.90066868
0.90020347
0.90026122
0.90051615
0.89904642
0.89771968
0.89473563
0.88419199
0.88959545
0.88878822
0.88343614
INFO - ==> Top1: 76.780    Top5: 97.310    Loss: 0.695
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.87579036
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [3][   20/   40]   Loss 0.590158   Top1 80.117188   Top5 98.085938   BatchTime 0.161559
INFO - Validation [3][   40/   40]   Loss 0.595873   Top1 80.250000   Top5 98.170000   BatchTime 0.107519
INFO - ==> Top1: 80.250    Top5: 98.170    Loss: 0.596
INFO - ==> Sparsity : 0.339
INFO - Scoreboard best 1 ==> Epoch [3][Top1: 80.250   Top5: 98.170]
INFO - Scoreboard best 2 ==> Epoch [2][Top1: 78.830   Top5: 98.520]
INFO - Scoreboard best 3 ==> Epoch [1][Top1: 76.170   Top5: 97.740]
features.0.conv.0 tensor(0.5312)
features.0.conv.3 tensor(0.1855)
features.1.conv.0 tensor(0.0397)
features.1.conv.3 tensor(0.0914)
features.1.conv.6 tensor(0.0668)
features.2.conv.0 tensor(0.0515)
features.2.conv.3 tensor(0.0679)
features.2.conv.6 tensor(0.0969)
features.3.conv.0 tensor(0.0417)
features.3.conv.3 tensor(0.0687)
features.3.conv.6 tensor(0.0668)
features.4.conv.0 tensor(0.0389)
features.4.conv.3 tensor(0.0972)
features.4.conv.6 tensor(0.1048)
features.5.conv.0 tensor(0.0459)
features.5.conv.3 tensor(0.0764)
features.5.conv.6 tensor(0.1048)
features.6.conv.0 tensor(0.0243)
features.6.conv.3 tensor(0.0509)
features.6.conv.6 tensor(0.0884)
features.7.conv.0 tensor(0.0454)
features.7.conv.3 tensor(0.1157)
features.7.conv.6 tensor(0.1302)
features.8.conv.0 tensor(0.0705)
features.8.conv.3 tensor(0.1241)
features.8.conv.6 tensor(0.1396)
features.9.conv.0 tensor(0.0637)
features.9.conv.3 tensor(0.1670)
features.9.conv.6 tensor(0.1322)
features.10.conv.0 tensor(0.0365)
features.10.conv.3 tensor(0.1108)
features.10.conv.6 tensor(0.0849)
features.11.conv.0 tensor(0.3044)
features.11.conv.3 tensor(0.0992)
features.11.conv.6 tensor(0.2072)
features.12.conv.0 tensor(0.1704)
features.12.conv.3 tensor(0.1121)
features.12.conv.6 tensor(0.2327)
features.13.conv.0 tensor(0.1570)
features.13.conv.3 tensor(0.1306)
features.13.conv.6 tensor(0.1211)
features.14.conv.0 tensor(0.8756)
features.14.conv.3 tensor(0.0968)
features.14.conv.6 tensor(0.2558)
features.15.conv.0 tensor(0.8838)
features.15.conv.3 tensor(0.0743)
features.15.conv.6 tensor(0.8889)
features.16.conv.0 tensor(0.4309)
features.16.conv.3 tensor(0.0885)
features.16.conv.6 tensor(0.1711)
conv.0 tensor(0.1901)
tensor(742344.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
0.86917073
0.86193657
0.86016613
0.88307172
0.89795637
0.89796227
0.88888752
0.90061170
0.90198606
0.90172708
0.90135437
0.90122122
0.90236384
0.90259755
0.90249521
0.90246415
0.90248257
INFO - Training [4][   20/  196]   Loss 0.690537   Top1 76.660156   Top5 96.640625   BatchTime 0.431200   LR 0.003200
0.90255260
0.90247500
0.90223718
0.90184438
0.90137148
0.90084141
0.90025568
0.89950371
0.89739996
0.89224201
0.88053328
0.88917875
0.89089364
0.88896424
0.88514692
0.87754989
0.88415968
0.88655460
0.88161570
0.87650615
0.87990659
0.87684071
INFO - Training [4][   40/  196]   Loss 0.671614   Top1 77.656250   Top5 97.187500   BatchTime 0.395981   LR 0.003122
0.87497610
0.88719434
0.90231586
0.90221137
0.90218836
0.90226001
0.90219837
0.90227419
0.90226942
0.90220094
0.90200633
0.90222079
0.90209174
0.90182495
0.90172654
0.90157723
0.90122777
INFO - Training [4][   60/  196]   Loss 0.665749   Top1 77.864583   Top5 97.317708   BatchTime 0.381509   LR 0.003044
0.90105319
0.90088964
0.90082383
0.90061736
0.90037704
0.90016758
0.90010053
0.90006828
0.89987749
0.89980769
0.89970452
0.89967954
0.89959490
0.89989555
0.90030414
0.90052146
0.90034866
0.90059727
0.90045577
0.90052438
0.90034819
0.90031749
0.90024740
INFO - Training [4][   80/  196]   Loss 0.663249   Top1 77.827148   Top5 97.402344   BatchTime 0.374004   LR 0.002965
0.90037793
0.90036291
0.90036464
0.90049618
0.90075421
0.90039885
0.90041506
0.90028375
0.90017027
0.90011805
0.89979780
0.89985901
0.89988571
0.89991808
0.89992434
0.90002424
0.89983964
0.89988458
0.89988309
0.89965588
0.89953220
INFO - Training [4][  100/  196]   Loss 0.656790   Top1 78.089844   Top5 97.453125   BatchTime 0.374127   LR 0.002886
0.89942712
0.89946419
0.89943922
0.89939886
0.89962476
0.89953661
0.89976460
0.89951783
0.89974910
0.89991069
0.89995986
0.90029347
0.90012509
0.89994615
0.90002578
0.90018165
INFO - Training [4][  120/  196]   Loss 0.649980   Top1 78.304036   Top5 97.522786   BatchTime 0.372501   LR 0.002806
0.90019161
0.90018880
0.90018058
0.89977163
0.89980185
0.89996070
0.89995271
0.89991516
0.89981306
0.89980537
0.89955395
0.89934236
0.89910609
0.89898652
0.89846820
0.89829910
0.89780796
0.89753205
INFO - Training [4][  140/  196]   Loss 0.648924   Top1 78.348214   Top5 97.572545   BatchTime 0.366632   LR 0.002726
0.89713722
0.89652264
0.89584339
0.89492279
0.89330792
0.88971138
0.88465983
0.87827337
0.87450266
0.87505263
0.87525392
0.87241626
0.87078822
0.86910301
0.86815006
0.86766398
0.86758572
0.86782801
0.86757332
0.86726600
0.86687452
0.86573935
INFO - Training [4][  160/  196]   Loss 0.649112   Top1 78.315430   Top5 97.609863   BatchTime 0.370685   LR 0.002646
0.86388129
0.86159122
0.86115992
0.85787994
0.85256225
0.86121231
0.86581600
0.86793584
0.86937088
0.86904639
0.86878473
0.86848998
0.86813992
0.86759984
0.86738163
0.86696678
0.86648333
0.86606121
0.86606330
0.86547196
0.86481446
INFO - Training [4][  180/  196]   Loss 0.645870   Top1 78.448351   Top5 97.556424   BatchTime 0.370306   LR 0.002566
0.86364907
0.86267853
0.86048079
0.85686100
0.84841549
0.84239244
0.83812690
0.84402436
0.85665905
0.86409873
0.86572874
0.86651272
0.86629105
0.86612445
0.86598402
0.86598063
0.86560476
INFO - ==> Top1: 78.512    Top5: 97.560    Loss: 0.643
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.86548710
0.86519772
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [4][   20/   40]   Loss 0.493526   Top1 83.085938   Top5 99.277344   BatchTime 0.115687
INFO - Validation [4][   40/   40]   Loss 0.473579   Top1 83.590000   Top5 99.390000   BatchTime 0.085142
INFO - ==> Top1: 83.590    Top5: 99.390    Loss: 0.474
INFO - ==> Sparsity : 0.317
INFO - Scoreboard best 1 ==> Epoch [4][Top1: 83.590   Top5: 99.390]
INFO - Scoreboard best 2 ==> Epoch [3][Top1: 80.250   Top5: 98.170]
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 78.830   Top5: 98.520]
features.0.conv.0 tensor(0.5347)
features.0.conv.3 tensor(0.1836)
features.1.conv.0 tensor(0.0280)
features.1.conv.3 tensor(0.0914)
features.1.conv.6 tensor(0.0690)
features.2.conv.0 tensor(0.0394)
features.2.conv.3 tensor(0.0633)
features.2.conv.6 tensor(0.0987)
features.3.conv.0 tensor(0.0289)
features.3.conv.3 tensor(0.0640)
features.3.conv.6 tensor(0.0668)
features.4.conv.0 tensor(0.0361)
features.4.conv.3 tensor(0.1024)
features.4.conv.6 tensor(0.1042)
features.5.conv.0 tensor(0.0469)
features.5.conv.3 tensor(0.0775)
features.5.conv.6 tensor(0.1045)
features.6.conv.0 tensor(0.0283)
features.6.conv.3 tensor(0.0451)
features.6.conv.6 tensor(0.0857)
features.7.conv.0 tensor(0.0530)
features.7.conv.3 tensor(0.1175)
features.7.conv.6 tensor(0.1242)
features.8.conv.0 tensor(0.0596)
features.8.conv.3 tensor(0.1288)
features.8.conv.6 tensor(0.1420)
features.9.conv.0 tensor(0.0667)
features.9.conv.3 tensor(0.1678)
features.9.conv.6 tensor(0.1789)
features.10.conv.0 tensor(0.0363)
features.10.conv.3 tensor(0.1065)
features.10.conv.6 tensor(0.0843)
features.11.conv.0 tensor(0.3352)
features.11.conv.3 tensor(0.1038)
features.11.conv.6 tensor(0.2399)
features.12.conv.0 tensor(0.1340)
features.12.conv.3 tensor(0.1329)
features.12.conv.6 tensor(0.3142)
features.13.conv.0 tensor(0.1555)
features.13.conv.3 tensor(0.1346)
features.13.conv.6 tensor(0.1174)
features.14.conv.0 tensor(0.8858)
features.14.conv.3 tensor(0.0976)
features.14.conv.6 tensor(0.1848)
features.15.conv.0 tensor(0.9081)
features.15.conv.3 tensor(0.0730)
features.15.conv.6 tensor(0.9898)
features.16.conv.0 tensor(0.0561)
features.16.conv.3 tensor(0.0858)
features.16.conv.6 tensor(0.1606)
conv.0 tensor(0.1802)
tensor(694043.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
0.86500508
0.86477900
0.86502481
0.86572683
0.86589837
0.86566746
0.86548859
0.86556625
0.86567605
0.86569458
0.86548752
0.86549997
0.86499608
0.86478227
0.86414856
0.86395425
0.86396378
0.86349231
0.86347163
0.86319965
INFO - Training [5][   20/  196]   Loss 0.617332   Top1 79.726562   Top5 97.304688   BatchTime 0.448768   LR 0.002424
0.86297470
0.86261421
0.86236423
0.86227369
0.86239797
0.86251354
0.86240220
0.86249053
0.86258405
0.86308861
0.86372179
0.86367297
0.86363894
0.86316365
0.86297619
0.86270809
0.86230642
INFO - Training [5][   40/  196]   Loss 0.632386   Top1 78.710938   Top5 97.509766   BatchTime 0.399442   LR 0.002343
0.86174172
0.86140943
0.86083096
0.85982883
0.85904312
0.85850561
0.85808188
0.85832196
0.85827053
0.85857910
0.85800737
0.85763323
0.85690945
0.85470808
0.85553282
0.85513788
0.85540646
0.85522062
0.85555559
0.85503161
0.85545701
0.85573524
0.85623413
INFO - Training [5][   60/  196]   Loss 0.621105   Top1 79.095052   Top5 97.460938   BatchTime 0.385935   LR 0.002263
0.85652119
0.85684973
0.85747784
0.85785818
0.85859275
0.85959244
0.86014074
0.86074764
0.86098057
0.86135709
0.86141098
0.86113870
0.86130762
0.86163622
0.86188644
0.86181945
INFO - Training [5][   80/  196]   Loss 0.612264   Top1 79.394531   Top5 97.636719   BatchTime 0.382811   LR 0.002183
0.86185127
0.86170250
0.86196005
0.86203307
0.86193973
0.86175483
0.86172062
0.86153984
0.86138970
0.86138737
0.86103249
0.86091089
0.86086369
0.86084896
0.86127150
0.86062223
0.86054164
0.86043513
0.86041242
0.86051303
0.86079508
0.86090034
INFO - Training [5][  100/  196]   Loss 0.603443   Top1 79.632812   Top5 97.675781   BatchTime 0.376862   LR 0.002104
0.86054724
0.86076701
0.86091244
0.86085200
0.86059147
0.86048758
0.85991752
0.86042649
0.85966277
0.85866147
0.85830951
0.85794812
0.85761940
0.85820442
0.85824138
0.85785139
0.85773265
0.85748851
0.85703027
0.85659856
0.85626084
INFO - Training [5][  120/  196]   Loss 0.596468   Top1 79.954427   Top5 97.786458   BatchTime 0.362413   LR 0.002024
0.85578144
0.85569531
0.85543364
0.85538977
0.85479152
0.85278249
0.84925443
0.84560102
0.84167737
0.84291482
0.84219098
0.83924460
0.83626735
0.83343834
0.83235610
0.83135015
0.83070636
INFO - Training [5][  140/  196]   Loss 0.593122   Top1 80.066964   Top5 97.812500   BatchTime 0.361095   LR 0.001946
0.83069134
0.83115000
0.83275145
0.83573854
0.83934295
0.84421676
0.84879500
0.85210854
0.85371870
0.85435754
0.85511816
0.85523921
0.85535914
0.85550040
0.85547954
0.85537732
0.85473597
0.85358405
0.85287708
0.85173351
0.84954107
0.84593368
0.84227169
INFO - Training [5][  160/  196]   Loss 0.595252   Top1 79.997559   Top5 97.790527   BatchTime 0.359315   LR 0.001868
0.83874947
0.83723122
0.83530051
0.83257419
0.82999575
0.82796574
0.82688731
0.82775593
0.82724154
0.82683527
0.82666308
0.82652688
0.82775873
0.82823676
0.82827294
0.82845229
0.82873088
INFO - Training [5][  180/  196]   Loss 0.592759   Top1 80.101997   Top5 97.743056   BatchTime 0.360196   LR 0.001790
0.82960737
0.83296996
0.83842415
0.84485203
0.84997457
0.85262674
0.85499245
0.85493189
0.85474354
0.85538346
0.85461992
0.85455066
0.85484666
0.85497212
0.85408479
0.85362041
INFO - ==> Top1: 80.178    Top5: 97.760    Loss: 0.589
0.85358161
0.85352039
0.85284042
0.85154241
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [5][   20/   40]   Loss 0.429830   Top1 85.429688   Top5 99.335938   BatchTime 0.132001
INFO - Validation [5][   40/   40]   Loss 0.418158   Top1 85.560000   Top5 99.420000   BatchTime 0.091722
INFO - ==> Top1: 85.560    Top5: 99.420    Loss: 0.418
INFO - ==> Sparsity : 0.325
INFO - Scoreboard best 1 ==> Epoch [5][Top1: 85.560   Top5: 99.420]
INFO - Scoreboard best 2 ==> Epoch [4][Top1: 83.590   Top5: 99.390]
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 80.250   Top5: 98.170]
features.0.conv.0 tensor(0.5382)
features.0.conv.3 tensor(0.3242)
features.1.conv.0 tensor(0.0326)
features.1.conv.3 tensor(0.0961)
features.1.conv.6 tensor(0.0668)
features.2.conv.0 tensor(0.0448)
features.2.conv.3 tensor(0.0640)
features.2.conv.6 tensor(0.0992)
features.3.conv.0 tensor(0.0408)
features.3.conv.3 tensor(0.0586)
features.3.conv.6 tensor(0.0679)
features.4.conv.0 tensor(0.0337)
features.4.conv.3 tensor(0.1100)
features.4.conv.6 tensor(0.0962)
features.5.conv.0 tensor(0.0360)
features.5.conv.3 tensor(0.0828)
features.5.conv.6 tensor(0.1030)
features.6.conv.0 tensor(0.0262)
features.6.conv.3 tensor(0.0498)
features.6.conv.6 tensor(0.0813)
features.7.conv.0 tensor(0.0590)
features.7.conv.3 tensor(0.1163)
features.7.conv.6 tensor(0.1287)
features.8.conv.0 tensor(0.0472)
features.8.conv.3 tensor(0.1236)
features.8.conv.6 tensor(0.1578)
features.9.conv.0 tensor(0.0696)
features.9.conv.3 tensor(0.1687)
features.9.conv.6 tensor(0.1344)
features.10.conv.0 tensor(0.0352)
features.10.conv.3 tensor(0.1036)
features.10.conv.6 tensor(0.0893)
features.11.conv.0 tensor(0.3795)
features.11.conv.3 tensor(0.1057)
features.11.conv.6 tensor(0.2772)
features.12.conv.0 tensor(0.1340)
features.12.conv.3 tensor(0.1410)
features.12.conv.6 tensor(0.4327)
features.13.conv.0 tensor(0.1702)
features.13.conv.3 tensor(0.1377)
features.13.conv.6 tensor(0.1171)
features.14.conv.0 tensor(0.8919)
features.14.conv.3 tensor(0.0993)
features.14.conv.6 tensor(0.1797)
features.15.conv.0 tensor(0.9147)
features.15.conv.3 tensor(0.0700)
features.15.conv.6 tensor(0.9818)
features.16.conv.0 tensor(0.0596)
features.16.conv.3 tensor(0.0862)
features.16.conv.6 tensor(0.1757)
conv.0 tensor(0.1828)
tensor(711499.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
0.84917128
0.84917682
0.85023445
0.85045671
0.85123670
0.85163128
0.85161585
0.85171235
0.85212034
0.85488182
0.85851562
0.85868376
0.85871285
0.85867554
0.85883158
0.85890436
0.85895997
0.85952264
0.86138994
INFO - Training [6][   20/  196]   Loss 0.586829   Top1 80.000000   Top5 97.656250   BatchTime 0.434036   LR 0.001655
0.86106914
0.86106271
0.86077780
0.86071819
0.86025351
0.85979980
0.85971659
0.85951865
0.85909933
0.85917360
0.85918182
0.85913998
0.85905486
0.85881525
0.85879415
0.85926354
0.86039138
INFO - Training [6][   40/  196]   Loss 0.582934   Top1 80.136719   Top5 97.626953   BatchTime 0.388271   LR 0.001580
0.86021882
0.86036605
0.86034793
0.86031568
0.86023766
0.86042905
0.86051184
0.86027676
0.86006027
0.86001581
0.85966951
0.85983413
0.85994875
0.85980219
0.85970271
0.85961908
0.85956967
0.85941809
0.85905033
0.85886687
0.85869920
0.85858423
0.85825938
INFO - Training [6][   60/  196]   Loss 0.566034   Top1 80.885417   Top5 97.669271   BatchTime 0.379417   LR 0.001506
0.85820103
0.85795230
0.85781735
0.85767132
0.85740322
0.85706186
0.85692179
0.85668766
0.85657561
0.85646504
0.85616583
0.85591912
0.85571873
0.85556847
0.85518444
INFO - Training [6][   80/  196]   Loss 0.557906   Top1 81.259766   Top5 97.880859   BatchTime 0.375620   LR 0.001432
0.85488224
0.85438281
0.85379547
0.85338658
0.85342342
0.85296345
0.85294068
0.85316688
0.85310513
0.85346276
0.85360271
0.85368675
0.85400087
0.85417682
0.85446882
0.85462689
0.85487092
0.85519117
0.85529196
0.85536122
INFO - Training [6][  100/  196]   Loss 0.548787   Top1 81.535156   Top5 97.921875   BatchTime 0.358236   LR 0.001360
0.85551178
0.85535645
0.85516727
0.85501719
0.85478747
0.85458690
0.85440594
0.85444921
0.85431343
0.85400367
0.85354388
0.85331720
0.85303372
0.85271186
0.85234886
0.85202181
0.85182059
0.85198325
0.85183424
0.85174006
0.85178572
0.85205966
0.85209173
0.85222971
INFO - Training [6][  120/  196]   Loss 0.545918   Top1 81.699219   Top5 97.981771   BatchTime 0.341578   LR 0.001289
0.85231256
0.85241783
0.85267752
0.85298342
0.85320139
0.85317731
0.85331053
0.85359740
0.85373122
0.85388142
0.85384476
0.85339212
0.85324734
0.85307276
0.85283542
0.85276884
0.85268646
INFO - Training [6][  140/  196]   Loss 0.546752   Top1 81.646205   Top5 98.035714   BatchTime 0.343374   LR 0.001220
0.85232037
0.85179967
0.85123199
0.85069388
0.84993196
0.84926301
0.84910637
0.84881806
0.84897423
0.84875005
0.84868813
0.84889126
0.84907377
0.84938836
0.85096687
0.85062057
0.85041541
0.85022610
0.85015929
0.84968919
0.84952265
0.84889686
INFO - Training [6][  160/  196]   Loss 0.547381   Top1 81.550293   Top5 98.017578   BatchTime 0.347103   LR 0.001151
0.84850019
0.84809226
0.84773529
0.84710938
0.84668034
0.84626025
0.84586400
0.84579688
0.84575421
0.84558356
0.84532827
0.84526819
0.84538800
0.84544253
0.84547734
0.84566510
0.84596992
0.84648281
0.84805959
0.84810978
0.84776944
INFO - Training [6][  180/  196]   Loss 0.544693   Top1 81.612413   Top5 97.947049   BatchTime 0.351255   LR 0.001084
0.84723437
0.84689057
0.84661752
0.84620041
0.84583688
0.84538132
0.84505212
0.84483528
0.84460986
0.84441185
0.84576166
0.84621012
0.84600687
0.84564894
0.84525579
0.84473091
INFO - ==> Top1: 81.654    Top5: 97.956    Loss: 0.544
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.84471029
0.84435135
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [6][   20/   40]   Loss 0.386833   Top1 87.207031   Top5 99.355469   BatchTime 0.141670
INFO - Validation [6][   40/   40]   Loss 0.373390   Top1 87.280000   Top5 99.570000   BatchTime 0.149470
INFO - ==> Top1: 87.280    Top5: 99.570    Loss: 0.373
INFO - ==> Sparsity : 0.355
INFO - Scoreboard best 1 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
INFO - Scoreboard best 2 ==> Epoch [5][Top1: 85.560   Top5: 99.420]
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 83.590   Top5: 99.390]
features.0.conv.0 tensor(0.5069)
features.0.conv.3 tensor(0.2637)
features.1.conv.0 tensor(0.0358)
features.1.conv.3 tensor(0.0949)
features.1.conv.6 tensor(0.0681)
features.2.conv.0 tensor(0.0388)
features.2.conv.3 tensor(0.0540)
features.2.conv.6 tensor(0.0952)
features.3.conv.0 tensor(0.0324)
features.3.conv.3 tensor(0.0579)
features.3.conv.6 tensor(0.0618)
features.4.conv.0 tensor(0.0415)
features.4.conv.3 tensor(0.1065)
features.4.conv.6 tensor(0.0960)
features.5.conv.0 tensor(0.0391)
features.5.conv.3 tensor(0.0839)
features.5.conv.6 tensor(0.1064)
features.6.conv.0 tensor(0.0249)
features.6.conv.3 tensor(0.0417)
features.6.conv.6 tensor(0.0797)
features.7.conv.0 tensor(0.0527)
features.7.conv.3 tensor(0.1169)
features.7.conv.6 tensor(0.1257)
features.8.conv.0 tensor(0.0483)
features.8.conv.3 tensor(0.1221)
features.8.conv.6 tensor(0.1420)
features.9.conv.0 tensor(0.0758)
features.9.conv.3 tensor(0.1670)
features.9.conv.6 tensor(0.1332)
features.10.conv.0 tensor(0.0364)
features.10.conv.3 tensor(0.1021)
features.10.conv.6 tensor(0.0946)
features.11.conv.0 tensor(0.4009)
features.11.conv.3 tensor(0.1028)
features.11.conv.6 tensor(0.3163)
features.12.conv.0 tensor(0.1640)
features.12.conv.3 tensor(0.1395)
features.12.conv.6 tensor(0.4422)
features.13.conv.0 tensor(0.1664)
features.13.conv.3 tensor(0.1329)
features.13.conv.6 tensor(0.1159)
features.14.conv.0 tensor(0.8982)
features.14.conv.3 tensor(0.0941)
features.14.conv.6 tensor(0.4217)
features.15.conv.0 tensor(0.9207)
features.15.conv.3 tensor(0.0678)
features.15.conv.6 tensor(0.9821)
features.16.conv.0 tensor(0.0676)
features.16.conv.3 tensor(0.0848)
features.16.conv.6 tensor(0.1801)
conv.0 tensor(0.2303)
tensor(777381.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
0.84395379
0.84304476
0.84224153
0.84117824
0.84012479
0.83904535
0.83806825
0.83741897
0.83669716
0.83566451
0.83482057
0.83369148
0.83197266
0.83031517
0.82910347
0.82732731
0.82587266
INFO - Training [7][   20/  196]   Loss 0.539054   Top1 81.562500   Top5 97.500000   BatchTime 0.435175   LR 0.000969
0.82465130
0.82385349
0.82257640
0.82218289
0.82138175
0.82032984
0.82066828
0.82067490
0.82115424
0.82135707
0.82076174
0.82072085
0.82088310
0.82088798
0.82095701
0.82089210
0.82181889
0.82188869
0.82192713
0.82153755
0.82120991
INFO - Training [7][   40/  196]   Loss 0.529116   Top1 82.207031   Top5 97.978516   BatchTime 0.403002   LR 0.000907
0.82091874
0.82065684
0.82038969
0.81997162
0.81985682
0.81978470
0.81963819
0.81951040
0.81938970
0.81917906
0.81915271
0.81897515
0.81876177
0.81899118
0.81890386
0.81870347
0.81835920
0.81788003
0.81790084
0.81794661
0.81801873
INFO - Training [7][   60/  196]   Loss 0.520880   Top1 82.662760   Top5 98.053385   BatchTime 0.396728   LR 0.000845
0.81797081
0.81806147
0.81786609
0.81769735
0.81766212
0.81747574
0.81743675
0.81700981
0.81723076
0.82095695
0.82193249
0.82410908
0.82343566
0.82326931
0.82304817
0.82318676
0.82281184
0.82240224
0.82222104
INFO - Training [7][   80/  196]   Loss 0.516600   Top1 82.739258   Top5 98.222656   BatchTime 0.376828   LR 0.000786
0.82231230
0.82201791
0.82221121
0.82325619
0.82441193
0.82448161
0.82396811
0.82389194
0.82387942
0.82372183
0.82357383
0.82355917
0.82355028
0.82337815
0.82351226
0.82365900
0.82366747
INFO - Training [7][  100/  196]   Loss 0.507641   Top1 83.074219   Top5 98.265625   BatchTime 0.372870   LR 0.000728
0.82378137
0.82385582
0.82379109
0.82407147
0.82397044
0.82382059
0.82384568
0.82374090
0.82370526
0.82362670
0.82358259
0.82347476
0.82328373
0.82315671
0.82297689
0.82274777
0.82246947
0.82203472
0.82193249
0.82182986
0.82182175
0.82187653
INFO - Training [7][  120/  196]   Loss 0.505611   Top1 83.102214   Top5 98.323568   BatchTime 0.373499   LR 0.000673
0.82203668
0.82226527
0.82230735
0.82229680
0.82231534
0.82213211
0.82229364
0.82238221
0.82218796
0.82194769
0.82164049
0.82166326
0.82212895
0.82247400
0.82255983
0.82241708
0.82214826
0.82211804
0.82208514
0.82202095
0.82171601
0.82154846
INFO - Training [7][  140/  196]   Loss 0.506346   Top1 83.060826   Top5 98.328683   BatchTime 0.373085   LR 0.000619
0.82143879
0.82130647
0.82118493
0.82108027
0.82086521
0.82238096
0.82266879
0.82290572
0.82272452
0.82264787
0.82245278
0.82218236
0.82205766
0.82191938
0.82191503
0.82191801
0.82187098
0.82200646
0.82154936
0.82119352
0.82089001
INFO - Training [7][  160/  196]   Loss 0.509379   Top1 82.902832   Top5 98.298340   BatchTime 0.372178   LR 0.000567
0.82057679
0.82051694
0.82053858
0.82048047
0.82032067
0.82025194
0.82040298
0.82055634
0.82080775
0.82079762
0.82068646
0.82069689
0.82067668
0.82070172
0.82074511
0.82067829
0.82080853
INFO - Training [7][  180/  196]   Loss 0.511151   Top1 82.840712   Top5 98.244358   BatchTime 0.371262   LR 0.000517
0.82090658
0.82078236
0.82082617
0.82082736
0.82066971
0.82080185
0.82086438
0.82074374
0.82078522
0.82090747
0.82101262
0.82101363
0.82088798
0.82088506
0.82097614
INFO - ==> Top1: 82.866    Top5: 98.244    Loss: 0.509
0.82104391
0.82094526
0.82104236
0.82108653
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [7][   20/   40]   Loss 0.394080   Top1 86.523438   Top5 99.453125   BatchTime 0.117357
INFO - Validation [7][   40/   40]   Loss 0.387614   Top1 86.690000   Top5 99.470000   BatchTime 0.084437
INFO - ==> Top1: 86.690    Top5: 99.470    Loss: 0.388
INFO - ==> Sparsity : 0.378
INFO - Scoreboard best 1 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
INFO - Scoreboard best 2 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 85.560   Top5: 99.420]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.5069)
features.0.conv.3 tensor(0.2363)
features.1.conv.0 tensor(0.0378)
features.1.conv.3 tensor(0.0984)
features.1.conv.6 tensor(0.0664)
features.2.conv.0 tensor(0.0399)
features.2.conv.3 tensor(0.0586)
features.2.conv.6 tensor(0.0952)
features.3.conv.0 tensor(0.0347)
features.3.conv.3 tensor(0.0532)
features.3.conv.6 tensor(0.0595)
features.4.conv.0 tensor(0.0482)
features.4.conv.3 tensor(0.1065)
features.4.conv.6 tensor(0.0947)
features.5.conv.0 tensor(0.0365)
features.5.conv.3 tensor(0.0862)
features.5.conv.6 tensor(0.1104)
features.6.conv.0 tensor(0.0285)
features.6.conv.3 tensor(0.0388)
features.6.conv.6 tensor(0.0785)
features.7.conv.0 tensor(0.0524)
features.7.conv.3 tensor(0.1157)
features.7.conv.6 tensor(0.1242)
features.8.conv.0 tensor(0.0499)
features.8.conv.3 tensor(0.1215)
features.8.conv.6 tensor(0.1414)
features.9.conv.0 tensor(0.0769)
features.9.conv.3 tensor(0.1641)
features.9.conv.6 tensor(0.1552)
features.10.conv.0 tensor(0.0361)
features.10.conv.3 tensor(0.0992)
features.10.conv.6 tensor(0.0967)
features.11.conv.0 tensor(0.4329)
features.11.conv.3 tensor(0.1049)
features.11.conv.6 tensor(0.3605)
features.12.conv.0 tensor(0.2029)
features.12.conv.3 tensor(0.1408)
features.12.conv.6 tensor(0.4487)
features.13.conv.0 tensor(0.1708)
features.13.conv.3 tensor(0.1370)
features.13.conv.6 tensor(0.1217)
features.14.conv.0 tensor(0.9017)
features.14.conv.3 tensor(0.0928)
features.14.conv.6 tensor(0.8948)
features.15.conv.0 tensor(0.8878)
features.15.conv.3 tensor(0.0664)
features.15.conv.6 tensor(0.9810)
features.16.conv.0 tensor(0.0748)
features.16.conv.3 tensor(0.0877)
features.16.conv.6 tensor(0.1714)
conv.0 tensor(0.1703)
tensor(827380.) 2188896.0
0.82118571
0.82080019
0.82081074
0.82080317
0.82078665
0.82077569
0.82086051
0.82064456
0.82016236
0.81955898
0.81886637
0.81829119
0.81810683
0.81792271
0.81771964
0.81771046
0.81760752
0.81755447
0.81750834
INFO - Training [8][   20/  196]   Loss 0.504432   Top1 83.066406   Top5 97.792969   BatchTime 0.447218   LR 0.000434
0.81763446
0.81775033
0.81767404
0.81770283
0.81755894
0.81743938
0.81736410
0.81681639
0.81633115
0.81562918
0.81502938
0.81473947
0.81552970
0.81624752
0.81625897
0.81624168
INFO - Training [8][   40/  196]   Loss 0.497548   Top1 83.046875   Top5 97.998047   BatchTime 0.410931   LR 0.000389
0.81594312
0.81567276
0.81556737
0.81524813
0.81509507
0.81479043
0.81435925
0.81404215
0.81381458
0.81350410
0.81297368
0.81294596
0.81272399
0.81263500
0.81236309
0.81206077
0.81192738
0.81154627
0.81132090
0.81119365
0.81126797
0.81106758
0.81080627
0.81065357
0.81062680
INFO - Training [8][   60/  196]   Loss 0.499035   Top1 83.242188   Top5 97.910156   BatchTime 0.413431   LR 0.000347
0.81053102
0.81044501
0.80997950
0.80963260
0.80957031
0.80948573
0.80932003
0.80923760
0.80914968
0.80893463
0.80875403
0.80858648
0.80834007
0.80821717
0.80808097
0.80794907
0.80789357
0.80777729
0.80771190
0.80751836
INFO - Training [8][   80/  196]   Loss 0.498141   Top1 83.212891   Top5 98.056641   BatchTime 0.386141   LR 0.000308
0.80737406
0.80756450
0.80773866
0.80791569
0.80817276
0.80837756
0.80860883
0.80883563
0.80903929
0.80921143
0.80934489
0.80943233
0.80953205
0.80968243
0.80980211
0.80990034
INFO - Training [8][  100/  196]   Loss 0.490663   Top1 83.429688   Top5 98.156250   BatchTime 0.381304   LR 0.000270
0.80992407
0.80998135
0.81004208
0.81013346
0.81021422
0.81035650
0.81057447
0.81130004
0.81241858
0.81241506
0.81240499
0.81230098
0.81220871
0.81211889
0.81201392
0.81192094
0.81186765
0.81173861
0.81167251
0.81156331
0.81152952
INFO - Training [8][  120/  196]   Loss 0.483779   Top1 83.603516   Top5 98.271484   BatchTime 0.380768   LR 0.000235
0.81142473
0.81132126
0.81123912
0.81130731
0.81150192
0.81301421
0.81288946
0.81273246
0.81256348
0.81239128
0.81220400
0.81196880
0.81176430
0.81164807
0.81150681
0.81130791
0.81117558
0.81101316
0.81088930
0.81070161
0.81055772
0.81045812
INFO - Training [8][  140/  196]   Loss 0.476849   Top1 83.861607   Top5 98.339844   BatchTime 0.380045   LR 0.000202
0.81038684
0.81018835
0.80989701
0.80962992
0.80945176
0.80923283
0.80893934
0.80875444
0.80862015
0.80840629
0.80831844
0.80821651
0.80813116
0.80798095
0.80794114
0.80779701
0.80773598
0.80778974
0.80775106
0.80778021
0.80768555
INFO - Training [8][  160/  196]   Loss 0.481357   Top1 83.737793   Top5 98.342285   BatchTime 0.380554   LR 0.000172
0.80760860
0.80753136
0.80751449
0.80744129
0.80735695
0.80733544
0.80728638
0.80735856
0.80735987
0.80730104
0.80729854
0.80725759
0.80724704
0.80724841
0.80713624
0.80720466
INFO - Training [8][  180/  196]   Loss 0.479796   Top1 83.808594   Top5 98.268229   BatchTime 0.378474   LR 0.000143
0.80728066
0.80728573
0.80721140
0.80715710
0.80707002
0.80696589
0.80692077
0.80683702
0.80675507
0.80668342
0.80662733
0.80665356
0.80651790
0.80639458
0.80619293
0.80599606
INFO - ==> Top1: 83.930    Top5: 98.262    Loss: 0.478
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.80575788
0.80563670
0.80541790
0.80529433
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [8][   20/   40]   Loss 0.355714   Top1 87.890625   Top5 99.570312   BatchTime 0.146211
INFO - Validation [8][   40/   40]   Loss 0.343951   Top1 88.150000   Top5 99.650000   BatchTime 0.101196
INFO - ==> Top1: 88.150    Top5: 99.650    Loss: 0.344
INFO - ==> Sparsity : 0.382
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
features.0.conv.0 tensor(0.5174)
features.0.conv.3 tensor(0.2676)
features.1.conv.0 tensor(0.0365)
features.1.conv.3 tensor(0.0914)
features.1.conv.6 tensor(0.0694)
features.2.conv.0 tensor(0.0417)
features.2.conv.3 tensor(0.0579)
features.2.conv.6 tensor(0.0938)
features.3.conv.0 tensor(0.0339)
features.3.conv.3 tensor(0.0532)
features.3.conv.6 tensor(0.0608)
features.4.conv.0 tensor(0.0490)
features.4.conv.3 tensor(0.1024)
features.4.conv.6 tensor(0.0944)
features.5.conv.0 tensor(0.0391)
features.5.conv.3 tensor(0.0856)
features.5.conv.6 tensor(0.1086)
features.6.conv.0 tensor(0.0317)
features.6.conv.3 tensor(0.0376)
features.6.conv.6 tensor(0.0777)
features.7.conv.0 tensor(0.0494)
features.7.conv.3 tensor(0.1157)
features.7.conv.6 tensor(0.1687)
features.8.conv.0 tensor(0.0501)
features.8.conv.3 tensor(0.1227)
features.8.conv.6 tensor(0.1461)
features.9.conv.0 tensor(0.0795)
features.9.conv.3 tensor(0.1635)
features.9.conv.6 tensor(0.1464)
features.10.conv.0 tensor(0.0352)
features.10.conv.3 tensor(0.1007)
features.10.conv.6 tensor(0.0932)
features.11.conv.0 tensor(0.4693)
features.11.conv.3 tensor(0.1020)
features.11.conv.6 tensor(0.3894)
features.12.conv.0 tensor(0.3580)
features.12.conv.3 tensor(0.1385)
features.12.conv.6 tensor(0.4525)
features.13.conv.0 tensor(0.1727)
features.13.conv.3 tensor(0.1360)
features.13.conv.6 tensor(0.1456)
features.14.conv.0 tensor(0.9029)
features.14.conv.3 tensor(0.0918)
features.14.conv.6 tensor(0.9054)
features.15.conv.0 tensor(0.8471)
features.15.conv.3 tensor(0.0654)
features.15.conv.6 tensor(0.9798)
features.16.conv.0 tensor(0.0726)
features.16.conv.3 tensor(0.0860)
features.16.conv.6 tensor(0.1713)
conv.0 tensor(0.1681)
tensor(837014.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
0.80521989
0.80512482
0.80494916
0.80487645
0.80478263
0.80472803
0.80479920
0.80477703
0.80491233
0.80498630
0.80495644
0.80500931
0.80494714
0.80492854
0.80486363
0.80477244
0.80469459
0.80465633
INFO - Training [9][   20/  196]   Loss 0.479152   Top1 83.613281   Top5 97.988281   BatchTime 0.450032   LR 0.000100
0.80465752
0.80468607
0.80465031
0.80461693
0.80464047
0.80464238
0.80452079
0.80446839
0.80437064
0.80434740
0.80408818
0.80404598
0.80396205
0.80377859
0.80376691
0.80365717
0.80354786
0.80350423
0.80340570
INFO - Training [9][   40/  196]   Loss 0.490569   Top1 83.193359   Top5 98.154297   BatchTime 0.414975   LR 0.000079
0.80342281
0.80336750
0.80315083
0.80297470
0.80283093
0.80260623
0.80228192
0.80218667
0.80209982
0.80190504
0.80166382
0.80149674
0.80137020
0.80123037
0.80110788
0.80095327
0.80082691
0.80077821
0.80070317
INFO - Training [9][   60/  196]   Loss 0.484753   Top1 83.483073   Top5 98.164062   BatchTime 0.381231   LR 0.000060
0.80064452
0.80063832
0.80058837
0.80048043
0.80047905
0.80050951
0.80044174
0.80038935
0.80027544
0.80024147
0.80016655
0.80005950
0.79995984
0.79978234
0.79965717
0.79962736
0.79960263
0.79945838
0.79937553
0.79928452
INFO - Training [9][   80/  196]   Loss 0.483711   Top1 83.569336   Top5 98.256836   BatchTime 0.363060   LR 0.000044
0.79922575
0.79917145
0.79915643
0.79912084
0.79911590
0.79910535
0.79908830
0.79905546
0.79904807
0.79905605
0.79905504
0.79902661
0.79903460
0.79898322
0.79895759
0.79893976
0.79891741
0.79892391
0.79888904
0.79887682
0.79887176
0.79883695
INFO - Training [9][  100/  196]   Loss 0.476153   Top1 83.859375   Top5 98.261719   BatchTime 0.363767   LR 0.000030
0.79881561
0.79885358
0.79884750
0.79881752
0.79881477
0.79879087
0.79879719
0.79886466
0.79884899
0.79883397
0.79884404
0.79884320
0.79879338
0.79881555
0.79883909
0.79885739
0.79886168
0.79887986
0.79889691
0.79889959
0.79890937
INFO - Training [9][  120/  196]   Loss 0.471479   Top1 84.059245   Top5 98.323568   BatchTime 0.366872   LR 0.000019
0.79891431
0.79894233
0.79894328
0.79892337
0.79892254
0.79893249
0.79892427
0.79894364
0.79893816
0.79892033
0.79890835
0.79890645
0.79891258
0.79892677
0.79892981
0.79896033
0.79895568
0.79895335
0.79896092
0.79897636
0.79896766
INFO - Training [9][  140/  196]   Loss 0.470606   Top1 84.121094   Top5 98.381696   BatchTime 0.368115   LR 0.000010
0.79894227
0.79898387
0.79897618
0.79896063
0.79896969
0.79895586
0.79895741
0.79894674
0.79895085
0.79894185
0.79892504
0.79891062
0.79892129
0.79890698
0.79889375
0.79889601
0.79892266
INFO - Training [9][  160/  196]   Loss 0.472593   Top1 84.084473   Top5 98.347168   BatchTime 0.366810   LR 0.000004
0.79890251
0.79891104
0.79892647
0.79892284
0.79894060
0.79891384
0.79890209
0.79890454
0.79892260
0.79890567
0.79889107
0.79885852
0.79886204
0.79887348
0.79889542
0.79889548
0.79891253
0.79889196
0.79891336
0.79890138
0.79889303
0.79889995
INFO - Training [9][  180/  196]   Loss 0.472619   Top1 84.086372   Top5 98.287760   BatchTime 0.367023   LR 0.000001
0.79888213
0.79885358
0.79887986
0.79887766
0.79888523
0.79888356
0.79889816
0.79890656
0.79891807
0.79893643
0.79892093
0.79892385
0.79896313
0.79896462
0.79896182
INFO - ==> Top1: 84.154    Top5: 98.306    Loss: 0.470
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.79896390
0.79896671
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [9][   20/   40]   Loss 0.430953   Top1 85.742188   Top5 99.414062   BatchTime 0.116448
INFO - Validation [9][   40/   40]   Loss 0.422394   Top1 85.990000   Top5 99.430000   BatchTime 0.084207
INFO - ==> Top1: 85.990    Top5: 99.430    Loss: 0.422
INFO - ==> Sparsity : 0.385
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.5035)
features.0.conv.3 tensor(0.2637)
features.1.conv.0 tensor(0.0365)
features.1.conv.3 tensor(0.0938)
features.1.conv.6 tensor(0.0681)
features.2.conv.0 tensor(0.0405)
features.2.conv.3 tensor(0.0594)
features.2.conv.6 tensor(0.0952)
features.3.conv.0 tensor(0.0333)
features.3.conv.3 tensor(0.0532)
features.3.conv.6 tensor(0.0608)
features.4.conv.0 tensor(0.0488)
features.4.conv.3 tensor(0.1024)
features.4.conv.6 tensor(0.0955)
features.5.conv.0 tensor(0.0391)
features.5.conv.3 tensor(0.0862)
features.5.conv.6 tensor(0.1126)
features.6.conv.0 tensor(0.0327)
features.6.conv.3 tensor(0.0376)
features.6.conv.6 tensor(0.0771)
features.7.conv.0 tensor(0.0507)
features.7.conv.3 tensor(0.1160)
features.7.conv.6 tensor(0.1747)
features.8.conv.0 tensor(0.0496)
features.8.conv.3 tensor(0.1218)
features.8.conv.6 tensor(0.1525)
features.9.conv.0 tensor(0.0793)
features.9.conv.3 tensor(0.1632)
features.9.conv.6 tensor(0.1434)
features.10.conv.0 tensor(0.0357)
features.10.conv.3 tensor(0.1001)
features.10.conv.6 tensor(0.0953)
features.11.conv.0 tensor(0.4832)
features.11.conv.3 tensor(0.1020)
features.11.conv.6 tensor(0.4040)
features.12.conv.0 tensor(0.3809)
features.12.conv.3 tensor(0.1397)
features.12.conv.6 tensor(0.4584)
features.13.conv.0 tensor(0.1729)
features.13.conv.3 tensor(0.1354)
features.13.conv.6 tensor(0.1789)
features.14.conv.0 tensor(0.9028)
features.14.conv.3 tensor(0.0919)
features.14.conv.6 tensor(0.9091)
features.15.conv.0 tensor(0.8081)
features.15.conv.3 tensor(0.0650)
features.15.conv.6 tensor(0.9793)
features.16.conv.0 tensor(0.0736)
features.16.conv.3 tensor(0.0872)
features.16.conv.6 tensor(0.1836)
conv.0 tensor(0.1687)
tensor(842276.) 2188896.0
0.79897022
0.80376875
0.80503529
0.80661440
0.80767125
0.80743891
0.80867910
0.81052524
0.81252187
0.81567955
0.82173401
0.82533956
0.82836086
0.82995242
0.83052444
0.83017433
0.82992548
INFO - Training [10][   20/  196]   Loss 0.541183   Top1 81.562500   Top5 97.812500   BatchTime 0.432702   LR 0.002500
0.82921761
0.83489347
0.83747327
0.83973563
0.84025794
0.84046948
0.84076554
0.84094679
0.84113145
0.84231627
0.84208870
0.84188884
0.84585756
0.84742206
0.84703737
0.84670252
0.84621584
0.84583539
0.84568846
0.84554589
0.84547782
INFO - Training [10][   40/  196]   Loss 0.547983   Top1 81.201172   Top5 97.968750   BatchTime 0.413071   LR 0.002499
0.84531260
0.84501517
0.84473342
0.84452844
0.84403819
0.84362644
0.84326237
0.84286171
0.84258282
0.84230840
0.84179389
0.84129328
0.84112662
0.84093136
0.84033459
0.83987558
0.83970350
INFO - Training [10][   60/  196]   Loss 0.554575   Top1 81.035156   Top5 98.059896   BatchTime 0.385314   LR 0.002499
0.83920228
0.83864832
0.83815217
0.83812141
0.83728826
0.83644587
0.83610779
0.83486575
0.83158660
0.82835662
0.82605892
0.82493669
0.82571149
0.82647020
0.82760632
0.82860130
0.82959783
0.83036822
0.83001488
0.82979161
0.83010536
INFO - Training [10][   80/  196]   Loss 0.557130   Top1 81.186523   Top5 98.066406   BatchTime 0.358583   LR 0.002497
0.83091807
0.83265281
0.83398932
0.83429497
0.83493334
0.83510035
0.83538359
0.83559936
0.83617318
0.83664566
0.83670616
0.83684283
0.83703279
0.83716691
0.83766490
0.83747435
0.83757180
0.83769709
0.83778459
0.83805764
INFO - Training [10][  100/  196]   Loss 0.553021   Top1 81.359375   Top5 98.062500   BatchTime 0.352545   LR 0.002496
0.83806276
0.83816963
0.83818245
0.83827412
0.83799565
0.83736849
0.83680528
0.83698100
0.83711410
0.83712643
0.83714283
0.83697242
0.83702987
0.83676487
0.83687127
0.83670336
0.83666104
0.83665204
0.83663988
0.83644730
0.83622128
INFO - Training [10][  120/  196]   Loss 0.551728   Top1 81.510417   Top5 98.082682   BatchTime 0.355288   LR 0.002494
0.83596659
0.83452290
0.83642173
0.83641243
0.83649009
0.83697623
0.83833551
0.83844167
0.83777696
0.83676815
0.83769506
0.83608675
0.82854629
0.83606762
0.83795232
0.83768612
0.83747959
0.83752167
0.83704537
0.83630174
0.83599216
0.83566129
INFO - Training [10][  140/  196]   Loss 0.551747   Top1 81.523438   Top5 98.133371   BatchTime 0.357050   LR 0.002492
0.83526951
0.83485502
0.83448219
0.83440554
0.83408993
0.83384717
0.83409691
0.83561492
0.83661067
0.83693540
0.83664256
0.83657253
0.83668602
0.83641535
0.83616215
0.83685446
0.83742571
INFO - Training [10][  160/  196]   Loss 0.554557   Top1 81.379395   Top5 98.110352   BatchTime 0.357360   LR 0.002490
0.83762687
0.83793408
0.83797973
0.83810782
0.83829939
0.83847582
0.83856022
0.83858919
0.83851993
0.83837837
0.83823073
0.83823240
0.83829904
0.83828157
0.83827883
0.83821583
0.83852857
0.83823729
0.83813173
0.83817554
0.83792484
0.83803052
0.83819818
INFO - Training [10][  180/  196]   Loss 0.555874   Top1 81.354167   Top5 98.044705   BatchTime 0.356309   LR 0.002487
0.83841377
0.83868945
0.83853596
0.83871901
0.83893394
0.83881724
0.83823121
0.83905828
0.83897626
0.83924645
0.83942705
0.83945239
0.83950132
0.83950192
0.83951670
0.83946562
INFO - ==> Top1: 81.272    Top5: 98.016    Loss: 0.557
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.83958483
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [10][   20/   40]   Loss 0.470347   Top1 83.964844   Top5 99.160156   BatchTime 0.127666
INFO - Validation [10][   40/   40]   Loss 0.445405   Top1 85.010000   Top5 99.200000   BatchTime 0.089328
INFO - ==> Top1: 85.010    Top5: 99.200    Loss: 0.445
INFO - ==> Sparsity : 0.354
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.5139)
features.0.conv.3 tensor(0.2344)
features.1.conv.0 tensor(0.0345)
features.1.conv.3 tensor(0.0891)
features.1.conv.6 tensor(0.0664)
features.2.conv.0 tensor(0.2378)
features.2.conv.3 tensor(0.0656)
features.2.conv.6 tensor(0.1024)
features.3.conv.0 tensor(0.0324)
features.3.conv.3 tensor(0.0602)
features.3.conv.6 tensor(0.0540)
features.4.conv.0 tensor(0.0374)
features.4.conv.3 tensor(0.0995)
features.4.conv.6 tensor(0.0920)
features.5.conv.0 tensor(0.0441)
features.5.conv.3 tensor(0.0723)
features.5.conv.6 tensor(0.1058)
features.6.conv.0 tensor(0.0285)
features.6.conv.3 tensor(0.0440)
features.6.conv.6 tensor(0.0726)
features.7.conv.0 tensor(0.0380)
features.7.conv.3 tensor(0.1155)
features.7.conv.6 tensor(0.1257)
features.8.conv.0 tensor(0.0523)
features.8.conv.3 tensor(0.1256)
features.8.conv.6 tensor(0.1342)
features.9.conv.0 tensor(0.0703)
features.9.conv.3 tensor(0.1690)
features.9.conv.6 tensor(0.1313)
features.10.conv.0 tensor(0.0357)
features.10.conv.3 tensor(0.1053)
features.10.conv.6 tensor(0.0834)
features.11.conv.0 tensor(0.1258)
features.11.conv.3 tensor(0.1152)
features.11.conv.6 tensor(0.1950)
features.12.conv.0 tensor(0.1560)
features.12.conv.3 tensor(0.1456)
features.12.conv.6 tensor(0.4812)
features.13.conv.0 tensor(0.1428)
features.13.conv.3 tensor(0.1362)
features.13.conv.6 tensor(0.0950)
features.14.conv.0 tensor(0.8382)
features.14.conv.3 tensor(0.0913)
features.14.conv.6 tensor(0.9756)
features.15.conv.0 tensor(0.7608)
features.15.conv.3 tensor(0.0663)
features.15.conv.6 tensor(0.9790)
features.16.conv.0 tensor(0.0626)
features.16.conv.3 tensor(0.0954)
features.16.conv.6 tensor(0.1477)
conv.0 tensor(0.1820)
tensor(773939.) 2188896.0
0.83893889
0.83899736
0.83924788
0.83916724
0.83901817
0.83847141
0.83836091
0.83823103
0.83817047
0.83779830
0.83710212
0.83642524
0.83614004
0.83609098
0.83574617
0.83551830
0.83532482
0.83499920
INFO - Training [11][   20/  196]   Loss 0.576115   Top1 80.058594   Top5 97.460938   BatchTime 0.419053   LR 0.002481
0.83473063
0.83460885
0.83456308
0.83448946
0.83613670
0.83593279
0.83368653
0.82609040
0.82966870
0.83451915
0.83557194
0.83572322
0.83539385
0.83521855
0.83527184
0.83492255
0.83507609
0.83500224
INFO - Training [11][   40/  196]   Loss 0.573980   Top1 80.507812   Top5 97.597656   BatchTime 0.378340   LR 0.002478
0.83478391
0.83451271
0.83387846
0.83362907
0.83338290
0.83286852
0.83235729
0.83188528
0.83140904
0.83136463
0.83104831
0.83069330
0.83055168
0.83073997
0.83065456
0.83056235
0.83091366
0.83105218
0.83059490
0.83043325
0.83057010
INFO - Training [11][   60/  196]   Loss 0.571492   Top1 80.787760   Top5 97.721354   BatchTime 0.381693   LR 0.002474
0.83092725
0.83109719
0.83120525
0.83104670
0.83058631
0.83058870
0.83115655
0.83148235
0.82996005
0.80604875
0.83011204
0.83109373
0.83105296
0.83083320
0.83085954
0.83095753
0.83072764
0.83037406
0.83019847
0.82985693
0.83006567
0.83045352
0.83021468
0.83070934
INFO - Training [11][   80/  196]   Loss 0.569848   Top1 80.888672   Top5 97.788086   BatchTime 0.369189   LR 0.002470
0.83124292
0.83156085
0.83124900
0.83167225
0.83315748
0.83363050
0.83406562
0.83399808
0.83391243
0.83402646
0.83420509
0.83436418
0.83452839
0.83445925
0.83445603
0.83452910
0.83435667
INFO - Training [11][  100/  196]   Loss 0.562898   Top1 81.179688   Top5 97.828125   BatchTime 0.363487   LR 0.002465
0.83425343
0.83378637
0.83364815
0.83383560
0.83418167
0.83430684
0.83460802
0.83526224
0.83661383
0.83658946
0.83681774
0.83672196
0.83634299
0.83626729
0.83617729
0.83613032
0.83578742
0.83567935
0.83562738
0.83555400
0.83553874
0.83547705
INFO - Training [11][  120/  196]   Loss 0.558057   Top1 81.334635   Top5 97.884115   BatchTime 0.363038   LR 0.002460
0.83490229
0.83440858
0.83406335
0.83351755
0.83327985
0.83304167
0.83270413
0.83267170
0.83269846
0.83264077
0.83219385
0.83169305
0.83065569
0.82931477
0.82709748
0.82504946
0.82341397
INFO - Training [11][  140/  196]   Loss 0.560004   Top1 81.269531   Top5 97.901786   BatchTime 0.364626   LR 0.002455
0.81959033
0.81640840
0.81337613
0.81267303
0.81212991
0.81230038
0.81302983
0.81558293
0.81851274
0.82082134
0.82235736
0.82412183
0.82511950
0.82645428
0.82703614
0.82731247
0.82742661
0.82755947
0.82813126
0.82915789
0.83137304
INFO - Training [11][  160/  196]   Loss 0.564088   Top1 81.130371   Top5 97.893066   BatchTime 0.364976   LR 0.002450
0.83047444
0.82999796
0.82960331
0.82966352
0.83057457
0.83124155
0.83087742
0.83051044
0.82989621
0.82777101
0.83021355
0.83191931
0.83308750
0.83370489
0.83562428
0.83574826
0.83547711
0.83569223
0.83514625
0.83480066
0.83486992
INFO - Training [11][  180/  196]   Loss 0.562273   Top1 81.178385   Top5 97.855903   BatchTime 0.367624   LR 0.002444
0.83525693
0.83519226
0.83516169
0.83507544
0.83565748
0.83631694
0.83649498
0.83672714
0.83676362
0.83694965
0.83667517
0.83682156
0.83659184
0.83665913
0.83671838
0.83660597
INFO - ==> Top1: 81.124    Top5: 97.862    Loss: 0.564
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.83648998
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [11][   20/   40]   Loss 0.471629   Top1 84.863281   Top5 99.160156   BatchTime 0.126671
INFO - Validation [11][   40/   40]   Loss 0.463346   Top1 84.820000   Top5 99.330000   BatchTime 0.089238
INFO - ==> Top1: 84.820    Top5: 99.330    Loss: 0.463
INFO - ==> Sparsity : 0.371
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4965)
features.0.conv.3 tensor(0.2422)
features.1.conv.0 tensor(0.0332)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0569)
features.2.conv.0 tensor(0.0365)
features.2.conv.3 tensor(0.0656)
features.2.conv.6 tensor(0.0981)
features.3.conv.0 tensor(0.0315)
features.3.conv.3 tensor(0.0594)
features.3.conv.6 tensor(0.0584)
features.4.conv.0 tensor(0.0308)
features.4.conv.3 tensor(0.1047)
features.4.conv.6 tensor(0.0926)
features.5.conv.0 tensor(0.0343)
features.5.conv.3 tensor(0.0706)
features.5.conv.6 tensor(0.1090)
features.6.conv.0 tensor(0.0270)
features.6.conv.3 tensor(0.0457)
features.6.conv.6 tensor(0.0690)
features.7.conv.0 tensor(0.0365)
features.7.conv.3 tensor(0.1172)
features.7.conv.6 tensor(0.1100)
features.8.conv.0 tensor(0.0507)
features.8.conv.3 tensor(0.1259)
features.8.conv.6 tensor(0.1321)
features.9.conv.0 tensor(0.0752)
features.9.conv.3 tensor(0.1600)
features.9.conv.6 tensor(0.1347)
features.10.conv.0 tensor(0.0382)
features.10.conv.3 tensor(0.1039)
features.10.conv.6 tensor(0.0899)
features.11.conv.0 tensor(0.2454)
features.11.conv.3 tensor(0.1179)
features.11.conv.6 tensor(0.1959)
features.12.conv.0 tensor(0.1790)
features.12.conv.3 tensor(0.1418)
features.12.conv.6 tensor(0.5069)
features.13.conv.0 tensor(0.1006)
features.13.conv.3 tensor(0.1358)
features.13.conv.6 tensor(0.1011)
features.14.conv.0 tensor(0.8394)
features.14.conv.3 tensor(0.0852)
features.14.conv.6 tensor(0.9785)
features.15.conv.0 tensor(0.7962)
features.15.conv.3 tensor(0.0637)
features.15.conv.6 tensor(0.9806)
features.16.conv.0 tensor(0.1553)
features.16.conv.3 tensor(0.0918)
features.16.conv.6 tensor(0.1495)
conv.0 tensor(0.2053)
tensor(811155.) 2188896.0
0.83663660
0.83658612
0.83626330
0.83635455
0.83623385
0.83597404
0.83585191
0.83574694
0.83519667
0.83475953
0.83464003
0.83479357
0.83482605
0.83451462
0.83432347
0.83404893
INFO - Training [12][   20/  196]   Loss 0.582583   Top1 80.957031   Top5 97.402344   BatchTime 0.427575   LR 0.002433
0.83362466
0.83325553
0.83315134
0.83289212
0.83290094
0.83297580
0.83313221
0.83314526
0.83305746
0.83272064
0.83255005
0.83206296
0.83182502
0.83127141
0.83067572
0.83049923
0.82982802
0.82995403
0.83004224
0.82988256
0.82983345
INFO - Training [12][   40/  196]   Loss 0.570571   Top1 81.191406   Top5 97.773438   BatchTime 0.405768   LR 0.002426
0.82940918
0.82980698
0.82968861
0.82961190
0.82691330
0.81960607
0.81074220
0.80901593
0.81270272
0.80863816
0.80757803
0.80913711
0.81311864
0.81962484
0.82631427
0.83111441
0.83391684
0.83586025
0.83670735
0.83656293
0.83673388
INFO - Training [12][   60/  196]   Loss 0.563050   Top1 81.354167   Top5 97.812500   BatchTime 0.398545   LR 0.002419
0.83675790
0.83677524
0.83691102
0.83703041
0.83698809
0.83686548
0.83676046
0.83669382
0.83675784
0.83641773
0.83571762
0.83541310
0.83568865
0.83572733
0.83563983
0.83546793
0.83533567
0.83536845
0.83541566
INFO - Training [12][   80/  196]   Loss 0.554230   Top1 81.503906   Top5 97.861328   BatchTime 0.379875   LR 0.002412
0.83540171
0.83546776
0.83541244
0.83543324
0.83540750
0.83567351
0.83677512
0.83657300
0.83663863
0.83641857
0.83651352
0.83642823
0.83629262
0.83607852
0.83600324
0.83636779
0.83619505
0.83584696
0.83563364
0.83537406
0.83518070
0.83489698
0.83475763
INFO - Training [12][  100/  196]   Loss 0.546425   Top1 81.781250   Top5 97.945312   BatchTime 0.372262   LR 0.002404
0.83470184
0.83485132
0.83450729
0.83424520
0.83356124
0.83228546
0.83066440
0.82981986
0.82801372
0.82219452
0.81347185
0.80850744
0.81220412
0.81634563
0.82053041
0.82362431
INFO - Training [12][  120/  196]   Loss 0.538152   Top1 82.076823   Top5 98.066406   BatchTime 0.371026   LR 0.002396
0.82652837
0.82883233
0.83057201
0.83148170
0.83205581
0.83278704
0.83371300
0.83558667
0.83564818
0.83558029
0.83547860
0.83542383
0.83566910
0.83550644
0.83527893
0.83524716
0.83491021
0.83486229
0.83492011
0.83488327
0.83498341
INFO - Training [12][  140/  196]   Loss 0.537551   Top1 82.059152   Top5 98.097098   BatchTime 0.373963   LR 0.002388
0.83507168
0.83514714
0.83533400
0.83547509
0.83541727
0.83545989
0.83542764
0.83548963
0.83551824
0.83574766
0.83568478
0.83572340
0.83567721
0.83604461
0.83576250
0.83584648
0.83580118
0.83583730
0.83581823
0.83550984
0.83531469
0.83511031
INFO - Training [12][  160/  196]   Loss 0.539040   Top1 81.972656   Top5 98.107910   BatchTime 0.371956   LR 0.002380
0.83481163
0.83437753
0.83404106
0.83370966
0.83353001
0.83352715
0.83327842
0.83318692
0.83303404
0.83289617
0.83256269
0.83209246
0.83208990
0.83224094
0.83224583
0.83168018
0.83091670
0.83019125
0.82941979
0.82861048
0.82798094
INFO - Training [12][  180/  196]   Loss 0.538464   Top1 81.976997   Top5 98.053385   BatchTime 0.372318   LR 0.002371
0.82700610
0.82629895
0.82584178
0.82532394
0.82449913
0.82385600
0.82333022
0.82297528
0.82235295
0.82144928
0.82118303
0.82106549
0.82036066
0.82000989
0.81957191
0.81942666
INFO - ==> Top1: 82.114    Top5: 98.072    Loss: 0.535
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 0.416398   Top1 86.210938   Top5 99.453125   BatchTime 0.125763
INFO - Validation [12][   40/   40]   Loss 0.414525   Top1 86.170000   Top5 99.500000   BatchTime 0.092115
features.0.conv.0 tensor(0.4931)
features.0.conv.3 tensor(0.2461)
features.1.conv.0 tensor(0.0312)
features.1.conv.3 tensor(0.0926)
features.1.conv.6 tensor(0.0595)
features.2.conv.0 tensor(0.0341)
features.2.conv.3 tensor(0.0556)
features.2.conv.6 tensor(0.0880)
features.3.conv.0 tensor(0.0281)
features.3.conv.3 tensor(0.0563)
features.3.conv.6 tensor(0.0566)
features.4.conv.0 tensor(0.0358)
features.4.conv.3 tensor(0.1030)
features.4.conv.6 tensor(0.0947)
features.5.conv.0 tensor(0.0399)
features.5.conv.3 tensor(0.0694)
features.5.conv.6 tensor(0.1167)
features.6.conv.0 tensor(0.0309)
features.6.conv.3 tensor(0.0475)
features.6.conv.6 tensor(0.0728)
features.7.conv.0 tensor(0.0444)
features.7.conv.3 tensor(0.1233)
features.7.conv.6 tensor(0.1252)
features.8.conv.0 tensor(0.0573)
features.8.conv.3 tensor(0.1279)
features.8.conv.6 tensor(0.2028)
features.9.conv.0 tensor(0.0780)
features.9.conv.3 tensor(0.1638)
features.9.conv.6 tensor(0.1318)
features.10.conv.0 tensor(0.0385)
features.10.conv.3 tensor(0.0975)
features.10.conv.6 tensor(0.1086)
features.11.conv.0 tensor(0.1375)
features.11.conv.3 tensor(0.1196)
features.11.conv.6 tensor(0.3549)
features.12.conv.0 tensor(0.1953)
features.12.conv.3 tensor(0.1451)
features.12.conv.6 tensor(0.5637)
features.13.conv.0 tensor(0.1073)
features.13.conv.3 tensor(0.1375)
features.13.conv.6 tensor(0.0975)
features.14.conv.0 tensor(0.8786)
features.14.conv.3 tensor(0.0839)
features.14.conv.6 tensor(0.9786)
features.15.conv.0 tensor(0.8200)
features.15.conv.3 tensor(0.0630)
features.15.conv.6 tensor(0.9801)
features.16.conv.0 tensor(0.2751)
features.16.conv.3 tensor(0.0959)
features.16.conv.6 tensor(0.1736)
conv.0 tensor(0.2005)
tensor(854875.) 2188896.0
INFO - ==> Top1: 86.170    Top5: 99.500    Loss: 0.415
INFO - ==> Sparsity : 0.391
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
0.81958884
0.82005280
0.82065958
0.82132822
0.82239825
0.82431048
0.82549375
0.82575339
0.82632583
0.82607424
0.82591736
0.82610768
0.82660508
0.82690221
0.82708484
0.82711422
0.82706219
0.82703829
0.82691860
INFO - Training [13][   20/  196]   Loss 0.524309   Top1 82.187500   Top5 97.578125   BatchTime 0.411166   LR 0.002355
0.82715487
0.82724011
0.82731974
0.82710892
0.82725364
0.82713419
0.82701015
0.82699668
0.82703030
0.82710606
0.82705534
0.82695246
0.82691973
0.82689220
0.82702893
0.82691550
0.82704008
INFO - Training [13][   40/  196]   Loss 0.540574   Top1 81.562500   Top5 97.753906   BatchTime 0.385702   LR 0.002345
0.82694203
0.82693917
0.82709670
0.82794625
0.82868767
0.82865572
0.82858080
0.82840395
0.82818836
0.82796323
0.82778156
0.82765484
0.82740128
0.82716477
0.82687330
0.82661575
0.82653338
0.82631993
0.82612169
0.82617652
0.82619780
0.82630897
INFO - Training [13][   60/  196]   Loss 0.532666   Top1 81.907552   Top5 97.884115   BatchTime 0.376965   LR 0.002336
0.82643372
0.82654595
0.82660431
0.82679176
0.82677662
0.82672566
0.82672983
0.82690233
0.82689512
0.82682306
0.82683063
0.82707012
0.82727641
0.82724327
0.82736391
0.82715809
0.82698566
0.82679635
0.82687980
0.82681173
INFO - Training [13][   80/  196]   Loss 0.537137   Top1 81.850586   Top5 97.871094   BatchTime 0.360537   LR 0.002325
0.82674384
0.82663345
0.82648158
0.82650220
0.82629931
0.82616466
0.82576102
0.82565904
0.82537830
0.82487780
0.82455635
0.82434011
0.82365912
0.82342213
0.82315964
0.82320011
0.82340938
0.82363147
0.82375479
0.82461840
0.82452244
0.82398951
0.82342827
INFO - Training [13][  100/  196]   Loss 0.530256   Top1 82.136719   Top5 97.914062   BatchTime 0.358972   LR 0.002315
0.82318634
0.82256138
0.82132667
0.82046378
0.82108933
0.82163686
0.82207274
0.82229954
0.82281840
0.82307488
0.82273769
0.82271689
0.82382369
0.82334560
0.82320786
0.82313854
INFO - Training [13][  120/  196]   Loss 0.526935   Top1 82.327474   Top5 97.991536   BatchTime 0.359329   LR 0.002304
0.82309711
0.82293016
0.82305336
0.82288480
0.82266438
0.82248610
0.82241756
0.82231939
0.82200897
0.82193834
0.82197380
0.82154036
0.82063890
0.81968606
0.81833929
0.81786400
0.81675023
0.81458908
0.81380635
0.81313556
0.81243229
0.80917466
INFO - Training [13][  140/  196]   Loss 0.525483   Top1 82.399554   Top5 98.071987   BatchTime 0.359302   LR 0.002293
0.81102407
0.81579185
0.81886703
0.82144153
0.82336348
0.82571906
0.82653981
0.82661414
0.82608652
0.82609606
0.82572228
0.82542574
0.82512933
0.82475525
0.82430202
0.82392359
0.82362682
0.82324284
0.82297873
0.82253379
0.82224214
0.82217139
INFO - Training [13][  160/  196]   Loss 0.527024   Top1 82.343750   Top5 98.093262   BatchTime 0.361177   LR 0.002282
0.82213932
0.82191801
0.82266581
0.82241642
0.82266909
0.82273620
0.82260025
0.82245737
0.82235122
0.82226354
0.82208431
0.82207668
0.82191175
0.82169718
0.82153803
0.82167572
0.82126969
INFO - Training [13][  180/  196]   Loss 0.526706   Top1 82.311198   Top5 98.036024   BatchTime 0.360734   LR 0.002271
0.82137793
0.82115340
0.82103825
0.82115912
0.82091057
0.82091177
0.82094818
0.82084429
0.82065755
0.82069546
0.82060802
0.82068378
0.82107759
0.82137239
0.82132298
INFO - ==> Top1: 82.372    Top5: 98.034    Loss: 0.525
0.82151514
0.82123935
0.82115650
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [13][   20/   40]   Loss 0.431338   Top1 85.625000   Top5 99.218750   BatchTime 0.117203
INFO - Validation [13][   40/   40]   Loss 0.418862   Top1 85.790000   Top5 99.370000   BatchTime 0.086152
INFO - ==> Top1: 85.790    Top5: 99.370    Loss: 0.419
INFO - ==> Sparsity : 0.388
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4688)
features.0.conv.3 tensor(0.2539)
features.1.conv.0 tensor(0.0195)
features.1.conv.3 tensor(0.0903)
features.1.conv.6 tensor(0.0569)
features.2.conv.0 tensor(0.0307)
features.2.conv.3 tensor(0.0540)
features.2.conv.6 tensor(0.0897)
features.3.conv.0 tensor(0.0214)
features.3.conv.3 tensor(0.0602)
features.3.conv.6 tensor(0.0549)
features.4.conv.0 tensor(0.0374)
features.4.conv.3 tensor(0.1059)
features.4.conv.6 tensor(0.0910)
features.5.conv.0 tensor(0.0365)
features.5.conv.3 tensor(0.0712)
features.5.conv.6 tensor(0.1156)
features.6.conv.0 tensor(0.0301)
features.6.conv.3 tensor(0.0457)
features.6.conv.6 tensor(0.0655)
features.7.conv.0 tensor(0.0446)
features.7.conv.3 tensor(0.1215)
features.7.conv.6 tensor(0.1189)
features.8.conv.0 tensor(0.0635)
features.8.conv.3 tensor(0.1285)
features.8.conv.6 tensor(0.1399)
features.9.conv.0 tensor(0.0772)
features.9.conv.3 tensor(0.1580)
features.9.conv.6 tensor(0.1280)
features.10.conv.0 tensor(0.0382)
features.10.conv.3 tensor(0.0981)
features.10.conv.6 tensor(0.0914)
features.11.conv.0 tensor(0.2283)
features.11.conv.3 tensor(0.1204)
features.11.conv.6 tensor(0.3633)
features.12.conv.0 tensor(0.1495)
features.12.conv.3 tensor(0.1543)
features.12.conv.6 tensor(0.5680)
features.13.conv.0 tensor(0.1190)
features.13.conv.3 tensor(0.1416)
features.13.conv.6 tensor(0.1230)
features.14.conv.0 tensor(0.9086)
features.14.conv.3 tensor(0.0854)
features.14.conv.6 tensor(0.9784)
features.15.conv.0 tensor(0.8349)
features.15.conv.3 tensor(0.0611)
features.15.conv.6 tensor(0.9794)
features.16.conv.0 tensor(0.0758)
features.16.conv.3 tensor(0.0951)
features.16.conv.6 tensor(0.2114)
conv.0 tensor(0.2098)
tensor(850173.) 2188896.0
0.82116979
0.82125658
0.82126290
0.82137644
0.82149047
0.82156438
0.82148623
0.82116127
0.82097638
0.82100701
0.82083321
0.82099140
0.82130086
0.82184762
0.82201344
0.82164317
0.82149190
0.82091868
0.82052219
0.82026637
INFO - Training [14][   20/  196]   Loss 0.522021   Top1 82.363281   Top5 97.539062   BatchTime 0.435200   LR 0.002250
0.81939769
0.81871742
0.81853729
0.81866175
0.81901598
0.81872189
0.81854677
0.81873715
0.81859803
0.81806654
0.81748974
0.81705564
0.81674182
0.81712073
0.81781107
0.82007343
INFO - Training [14][   40/  196]   Loss 0.529107   Top1 82.138672   Top5 97.773438   BatchTime 0.402254   LR 0.002238
0.81977934
0.81949538
0.81978565
0.82010162
0.81998914
0.81989247
0.81980807
0.82071179
0.82176483
0.82169420
0.82188064
0.82172394
0.82164675
0.82154673
0.82125556
0.82100511
0.82071471
0.82061750
0.82057303
0.82068783
0.82079262
0.82086039
0.82099760
INFO - Training [14][   60/  196]   Loss 0.519941   Top1 82.539062   Top5 97.962240   BatchTime 0.386012   LR 0.002225
0.82142329
0.82213718
0.82240629
0.82265657
0.82305294
0.82341933
0.82401925
0.82393438
0.82390016
0.82391793
0.82380307
0.82364517
0.82307202
0.82264388
0.82251054
0.82245117
0.82229531
0.82201117
0.82191938
INFO - Training [14][   80/  196]   Loss 0.516161   Top1 82.739258   Top5 98.051758   BatchTime 0.366804   LR 0.002213
0.82193136
0.82189637
0.82161230
0.82127851
0.82098210
0.82111728
0.82124871
0.82133710
0.82119745
0.82098544
0.82050812
0.81991816
0.82011485
0.81957525
0.81947154
0.81945264
0.81935525
0.81928819
0.81891394
INFO - Training [14][  100/  196]   Loss 0.513440   Top1 82.812500   Top5 98.085938   BatchTime 0.359977   LR 0.002200
0.81866270
0.81834090
0.81779915
0.81728733
0.81717235
0.81759876
0.81783706
0.81804204
0.81838977
0.81863302
0.81874382
0.81902224
0.81909877
0.81913084
0.81926614
0.81945437
0.81985664
0.82107085
0.82224548
0.82233804
INFO - Training [14][  120/  196]   Loss 0.507248   Top1 82.958984   Top5 98.183594   BatchTime 0.365258   LR 0.002186
0.82240075
0.82260346
0.82238257
0.82246071
0.82293791
0.82336223
0.82357538
0.82389587
0.82424343
0.82453930
0.82529628
0.83233029
0.83320618
0.83300930
0.83288985
0.83279800
0.83278215
0.83303797
0.83271968
0.83245921
0.83226895
0.83226979
INFO - Training [14][  140/  196]   Loss 0.508391   Top1 83.010603   Top5 98.244978   BatchTime 0.365183   LR 0.002173
0.83220208
0.83219200
0.83223504
0.83230054
0.83222938
0.83230388
0.83218020
0.83216131
0.83232778
0.83234119
0.83207369
0.83196449
0.83208424
0.83210766
0.83201653
0.83195436
0.83182544
INFO - Training [14][  160/  196]   Loss 0.508463   Top1 83.081055   Top5 98.212891   BatchTime 0.364773   LR 0.002159
0.83172095
0.83175045
0.83158332
0.83146018
0.83146971
0.83135390
0.83139318
0.83125365
0.83118814
0.83089674
0.83075029
0.83059835
0.82996273
0.82936525
0.82884967
0.82879651
0.82876015
0.83017099
0.83000571
0.82949334
0.82913923
0.82890326
INFO - Training [14][  180/  196]   Loss 0.509005   Top1 83.116319   Top5 98.140191   BatchTime 0.364679   LR 0.002145
0.82877952
0.82856196
0.82822484
0.82794315
0.82765335
0.82743466
0.82685369
0.82662392
0.82623875
0.82596302
0.82590556
0.82561338
0.82530910
0.82537967
0.82543701
0.82551652
INFO - ==> Top1: 83.166    Top5: 98.130    Loss: 0.507
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.82544798
0.82559335
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [14][   20/   40]   Loss 0.379010   Top1 87.851562   Top5 99.472656   BatchTime 0.130534
INFO - Validation [14][   40/   40]   Loss 0.369061   Top1 87.800000   Top5 99.570000   BatchTime 0.094149
INFO - ==> Top1: 87.800    Top5: 99.570    Loss: 0.369
INFO - ==> Sparsity : 0.384
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.5000)
features.0.conv.3 tensor(0.2500)
features.1.conv.0 tensor(0.0273)
features.1.conv.3 tensor(0.0984)
features.1.conv.6 tensor(0.0616)
features.2.conv.0 tensor(0.0321)
features.2.conv.3 tensor(0.0571)
features.2.conv.6 tensor(0.0883)
features.3.conv.0 tensor(0.0284)
features.3.conv.3 tensor(0.0602)
features.3.conv.6 tensor(0.0525)
features.4.conv.0 tensor(0.0366)
features.4.conv.3 tensor(0.1076)
features.4.conv.6 tensor(0.0939)
features.5.conv.0 tensor(0.0277)
features.5.conv.3 tensor(0.0752)
features.5.conv.6 tensor(0.1125)
features.6.conv.0 tensor(0.0256)
features.6.conv.3 tensor(0.0428)
features.6.conv.6 tensor(0.0663)
features.7.conv.0 tensor(0.0479)
features.7.conv.3 tensor(0.1204)
features.7.conv.6 tensor(0.1173)
features.8.conv.0 tensor(0.0677)
features.8.conv.3 tensor(0.1227)
features.8.conv.6 tensor(0.1384)
features.9.conv.0 tensor(0.0755)
features.9.conv.3 tensor(0.1606)
features.9.conv.6 tensor(0.1890)
features.10.conv.0 tensor(0.0352)
features.10.conv.3 tensor(0.1021)
features.10.conv.6 tensor(0.0805)
features.11.conv.0 tensor(0.1467)
features.11.conv.3 tensor(0.1242)
features.11.conv.6 tensor(0.1965)
features.12.conv.0 tensor(0.2069)
features.12.conv.3 tensor(0.1584)
features.12.conv.6 tensor(0.6079)
features.13.conv.0 tensor(0.1086)
features.13.conv.3 tensor(0.1391)
features.13.conv.6 tensor(0.1183)
features.14.conv.0 tensor(0.8990)
features.14.conv.3 tensor(0.0837)
features.14.conv.6 tensor(0.9770)
features.15.conv.0 tensor(0.8474)
features.15.conv.3 tensor(0.0589)
features.15.conv.6 tensor(0.9785)
features.16.conv.0 tensor(0.0778)
features.16.conv.3 tensor(0.0971)
features.16.conv.6 tensor(0.1833)
conv.0 tensor(0.2249)
tensor(839904.) 2188896.0
0.82596344
0.82622796
0.82687825
0.82709271
0.82704914
0.82713312
0.82704264
0.82726085
0.82760930
0.82938969
0.82955843
0.82951295
0.82952446
0.82913381
0.82907075
0.82917982
0.82921767
INFO - Training [15][   20/  196]   Loss 0.511158   Top1 82.890625   Top5 97.500000   BatchTime 0.416807   LR 0.002120
0.82887805
0.82890797
0.82912582
0.82925439
0.82902336
0.82908255
0.82932258
0.82947397
0.82946748
0.82945746
0.82946604
0.82969028
0.82984710
0.82980382
0.83000654
0.83030725
0.83002979
0.82959259
INFO - Training [15][   40/  196]   Loss 0.514768   Top1 82.783203   Top5 97.851562   BatchTime 0.372740   LR 0.002106
0.82924855
0.82901192
0.82890940
0.82897884
0.82927257
0.82919109
0.82882237
0.82859260
0.82833761
0.82782692
0.82750756
0.82733685
0.82713544
0.82760084
0.82772648
0.82704693
0.82679951
0.82533282
0.82385492
0.82247299
0.82305413
0.82311589
INFO - Training [15][   60/  196]   Loss 0.515495   Top1 82.721354   Top5 97.936198   BatchTime 0.374603   LR 0.002091
0.82379621
0.82418263
0.82399267
0.82347977
0.82273412
0.82146102
0.81836700
0.81524813
0.80959117
0.81373119
0.81669861
0.81605279
0.81721550
0.81339490
0.80929935
0.80254114
0.80258077
0.80103374
0.80489105
INFO - Training [15][   80/  196]   Loss 0.510986   Top1 82.978516   Top5 98.095703   BatchTime 0.360455   LR 0.002076
0.80812871
0.81122732
0.80865878
0.80870068
0.80717325
0.80582350
0.80632079
0.80733287
0.80646265
0.80477244
0.80397123
0.80398351
0.80411083
0.80449331
0.80438280
0.80434012
0.80395788
0.80342698
0.80318505
0.80303830
0.80288237
0.80263668
0.80232531
0.80227590
INFO - Training [15][  100/  196]   Loss 0.500057   Top1 83.277344   Top5 98.136719   BatchTime 0.355094   LR 0.002061
0.80245882
0.80217081
0.80149293
0.80096924
0.80049759
0.79993182
0.79652876
0.79282022
0.79372251
0.79201013
0.79017270
0.79229498
0.80870599
0.81245172
0.81348968
0.81409490
0.81468797
0.81491750
0.81515688
0.81543505
INFO - Training [15][  120/  196]   Loss 0.498954   Top1 83.310547   Top5 98.232422   BatchTime 0.363696   LR 0.002045
0.81585276
0.81625122
0.81680918
0.81719208
0.81720960
0.81720001
0.81734896
0.81721216
0.81652755
0.81587887
0.81551129
0.81534678
0.81610197
0.81716651
0.81794572
0.81784374
INFO - Training [15][  140/  196]   Loss 0.495987   Top1 83.454241   Top5 98.278460   BatchTime 0.363855   LR 0.002030
0.81780273
0.81783408
0.81776237
0.81784058
0.81791949
0.81869459
0.81882924
0.81852216
0.81850147
0.81840152
0.81812966
0.81798744
0.81820965
0.81803894
0.81799561
0.81814688
0.81880003
0.81927735
0.81995106
0.81986082
0.81975192
INFO - Training [15][  160/  196]   Loss 0.498925   Top1 83.317871   Top5 98.244629   BatchTime 0.365079   LR 0.002014
0.81953037
0.81963825
0.81968355
0.81953877
0.81931955
0.81926209
0.81898934
0.81882060
0.81852913
0.81808996
0.81779009
0.81764132
0.81740481
0.81730276
0.81748062
0.81756335
0.81771058
0.81785381
0.81809521
0.81788772
0.81772530
0.81773525
INFO - Training [15][  180/  196]   Loss 0.499712   Top1 83.272569   Top5 98.161892   BatchTime 0.365588   LR 0.001998
0.81767339
0.81778872
0.81796443
0.81789464
0.81785846
0.81787133
0.81777722
0.81774187
0.81766760
0.81761491
0.81750238
0.81729978
0.81724280
0.81732559
0.81730139
0.81728107
INFO - ==> Top1: 83.328    Top5: 98.168    Loss: 0.499
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.81721282
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [15][   20/   40]   Loss 0.476669   Top1 84.179688   Top5 99.277344   BatchTime 0.131785
INFO - Validation [15][   40/   40]   Loss 0.489917   Top1 83.830000   Top5 99.380000   BatchTime 0.092477
INFO - ==> Top1: 83.830    Top5: 99.380    Loss: 0.490
INFO - ==> Sparsity : 0.392
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4688)
features.0.conv.3 tensor(0.2480)
features.1.conv.0 tensor(0.0202)
features.1.conv.3 tensor(0.1019)
features.1.conv.6 tensor(0.0573)
features.2.conv.0 tensor(0.0263)
features.2.conv.3 tensor(0.0563)
features.2.conv.6 tensor(0.0897)
features.3.conv.0 tensor(0.0252)
features.3.conv.3 tensor(0.0532)
features.3.conv.6 tensor(0.0510)
features.4.conv.0 tensor(0.0356)
features.4.conv.3 tensor(0.0914)
features.4.conv.6 tensor(0.0890)
features.5.conv.0 tensor(0.0269)
features.5.conv.3 tensor(0.0770)
features.5.conv.6 tensor(0.1226)
features.6.conv.0 tensor(0.0286)
features.6.conv.3 tensor(0.0451)
features.6.conv.6 tensor(0.0630)
features.7.conv.0 tensor(0.0465)
features.7.conv.3 tensor(0.1250)
features.7.conv.6 tensor(0.1153)
features.8.conv.0 tensor(0.0610)
features.8.conv.3 tensor(0.1253)
features.8.conv.6 tensor(0.1446)
features.9.conv.0 tensor(0.0813)
features.9.conv.3 tensor(0.1641)
features.9.conv.6 tensor(0.1267)
features.10.conv.0 tensor(0.0433)
features.10.conv.3 tensor(0.0964)
features.10.conv.6 tensor(0.0786)
features.11.conv.0 tensor(0.2717)
features.11.conv.3 tensor(0.1229)
features.11.conv.6 tensor(0.3409)
features.12.conv.0 tensor(0.1618)
features.12.conv.3 tensor(0.1559)
features.12.conv.6 tensor(0.6261)
features.13.conv.0 tensor(0.1714)
features.13.conv.3 tensor(0.1426)
features.13.conv.6 tensor(0.0839)
features.14.conv.0 tensor(0.9426)
features.14.conv.3 tensor(0.0816)
features.14.conv.6 tensor(0.9776)
features.15.conv.0 tensor(0.8607)
features.15.conv.3 tensor(0.0576)
features.15.conv.6 tensor(0.9786)
features.16.conv.0 tensor(0.1215)
features.16.conv.3 tensor(0.1035)
features.16.conv.6 tensor(0.1837)
conv.0 tensor(0.1993)
tensor(857376.) 2188896.0
0.81698215
0.81694311
0.81700730
0.81676751
0.81652325
0.81627148
0.81615418
0.81600839
0.81530917
0.81446648
0.81391537
0.81342095
0.81299073
0.81276470
0.81225014
0.81209344
0.81205684
0.81202048
0.81191015
0.81167287
0.81160414
INFO - Training [16][   20/  196]   Loss 0.523776   Top1 82.363281   Top5 97.851562   BatchTime 0.447446   LR 0.001969
0.81133181
0.81106281
0.81084305
0.81097186
0.81086171
0.81022322
0.80996084
0.80946141
0.81086600
0.80950081
0.80947763
0.81003821
0.80944568
0.80839211
0.80765384
0.80668414
INFO - Training [16][   40/  196]   Loss 0.509619   Top1 82.880859   Top5 97.978516   BatchTime 0.408540   LR 0.001953
0.80638778
0.80461973
0.80148405
0.79792476
0.79846948
0.79609680
0.79648930
0.79618084
0.79357225
0.79037440
0.78958863
0.78933299
0.78712040
0.78348279
0.78183693
0.77943712
0.77793151
0.77844679
0.77795219
0.77744734
0.77651256
0.77577496
0.77682388
INFO - Training [16][   60/  196]   Loss 0.498575   Top1 83.196615   Top5 98.098958   BatchTime 0.389582   LR 0.001936
0.77957815
0.78134257
0.78281868
0.78428000
0.78544235
0.78634828
0.78851074
0.78983629
0.79118562
0.79142368
0.79191023
0.79231429
0.79241538
0.79255968
0.79305935
0.79673833
0.80161369
0.80155301
0.80154520
0.80125678
INFO - Training [16][   80/  196]   Loss 0.501346   Top1 83.208008   Top5 98.173828   BatchTime 0.367322   LR 0.001919
0.80112809
0.80100143
0.80087930
0.80086023
0.80110812
0.80138737
0.80147225
0.80178446
0.80219358
0.80237335
0.80269176
0.80280548
0.80279607
0.80273777
0.80272901
0.80293041
INFO - Training [16][  100/  196]   Loss 0.493672   Top1 83.496094   Top5 98.191406   BatchTime 0.365961   LR 0.001902
0.80299199
0.80281657
0.80281806
0.80292523
0.80284935
0.80265099
0.80289072
0.80302328
0.80304497
0.80470270
0.80504048
0.80460125
0.80436450
0.80438489
0.80431187
0.80440807
0.80445558
0.80434293
0.80427319
0.80425590
0.80433631
INFO - Training [16][  120/  196]   Loss 0.486306   Top1 83.805339   Top5 98.268229   BatchTime 0.368619   LR 0.001885
0.80445671
0.80473429
0.80483562
0.80500543
0.80515492
0.80544561
0.80584669
0.80613106
0.80770224
0.80791700
0.80780822
0.80759448
0.80750018
0.80736923
0.80711150
0.80714303
0.80693519
0.80697125
0.80690104
0.80679548
0.80659932
INFO - Training [16][  140/  196]   Loss 0.482897   Top1 83.936942   Top5 98.328683   BatchTime 0.370966   LR 0.001867
0.80656773
0.80675447
0.80669314
0.80684942
0.80707949
0.80690545
0.80674487
0.80670446
0.80674976
0.80676436
0.80686569
0.80694920
0.80707318
0.80704212
0.80720621
0.80717188
0.80713063
0.80689585
0.80674297
0.80670702
0.80660349
0.80629200
0.80631065
INFO - Training [16][  160/  196]   Loss 0.483137   Top1 83.947754   Top5 98.352051   BatchTime 0.367822   LR 0.001850
0.80626470
0.80616212
0.80582762
0.80548501
0.80564231
0.80496281
0.80513346
0.80522394
0.80528319
0.80507219
0.80499059
0.80509597
0.80481112
0.80399138
0.80447936
0.80493486
0.80491751
INFO - Training [16][  180/  196]   Loss 0.481535   Top1 84.025608   Top5 98.307292   BatchTime 0.366686   LR 0.001832
0.80493313
0.80480832
0.80458820
0.80447966
0.80438668
0.80424190
0.80394483
0.80339271
0.80265671
0.80243129
0.80226123
0.80225754
0.80191386
0.80146068
0.80107576
0.80078518
INFO - ==> Top1: 84.044    Top5: 98.290    Loss: 0.481
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.79983228
0.79831696
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [16][   20/   40]   Loss 0.370619   Top1 87.460938   Top5 99.394531   BatchTime 0.123085
INFO - Validation [16][   40/   40]   Loss 0.361248   Top1 87.650000   Top5 99.530000   BatchTime 0.086864
INFO - ==> Top1: 87.650    Top5: 99.530    Loss: 0.361
INFO - ==> Sparsity : 0.404
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 87.650   Top5: 99.530]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4861)
features.0.conv.3 tensor(0.2441)
features.1.conv.0 tensor(0.0260)
features.1.conv.3 tensor(0.0995)
features.1.conv.6 tensor(0.0590)
features.2.conv.0 tensor(0.0330)
features.2.conv.3 tensor(0.0563)
features.2.conv.6 tensor(0.0909)
features.3.conv.0 tensor(0.0191)
features.3.conv.3 tensor(0.0602)
features.3.conv.6 tensor(0.0454)
features.4.conv.0 tensor(0.0496)
features.4.conv.3 tensor(0.0938)
features.4.conv.6 tensor(0.0877)
features.5.conv.0 tensor(0.0327)
features.5.conv.3 tensor(0.0764)
features.5.conv.6 tensor(0.1110)
features.6.conv.0 tensor(0.0312)
features.6.conv.3 tensor(0.0475)
features.6.conv.6 tensor(0.0670)
features.7.conv.0 tensor(0.0446)
features.7.conv.3 tensor(0.1264)
features.7.conv.6 tensor(0.1194)
features.8.conv.0 tensor(0.0603)
features.8.conv.3 tensor(0.1256)
features.8.conv.6 tensor(0.1686)
features.9.conv.0 tensor(0.0907)
features.9.conv.3 tensor(0.1632)
features.9.conv.6 tensor(0.2802)
features.10.conv.0 tensor(0.0417)
features.10.conv.3 tensor(0.1010)
features.10.conv.6 tensor(0.0762)
features.11.conv.0 tensor(0.6912)
features.11.conv.3 tensor(0.1489)
features.11.conv.6 tensor(0.2027)
features.12.conv.0 tensor(0.2091)
features.12.conv.3 tensor(0.1508)
features.12.conv.6 tensor(0.6179)
features.13.conv.0 tensor(0.1219)
features.13.conv.3 tensor(0.1441)
features.13.conv.6 tensor(0.1028)
features.14.conv.0 tensor(0.9571)
features.14.conv.3 tensor(0.0840)
features.14.conv.6 tensor(0.9794)
features.15.conv.0 tensor(0.8706)
features.15.conv.3 tensor(0.0600)
features.15.conv.6 tensor(0.9790)
features.16.conv.0 tensor(0.1274)
features.16.conv.3 tensor(0.1057)
features.16.conv.6 tensor(0.1891)
conv.0 tensor(0.1976)
tensor(884854.) 2188896.0
0.79716188
0.79657412
0.79654485
0.79692888
0.79761595
0.79819119
0.79918772
0.80202830
0.80222476
0.80186605
0.80154461
0.80121851
0.80102462
0.80110574
0.80121487
0.80256206
0.80244064
INFO - Training [17][   20/  196]   Loss 0.506595   Top1 82.695312   Top5 97.773438   BatchTime 0.415131   LR 0.001800
0.80225575
0.80210537
0.80190706
0.80173898
0.80165821
0.80108106
0.80041319
0.79992056
0.79959905
0.79964465
0.80019593
0.80088317
0.80139083
0.80177671
0.80204248
0.80227268
0.80245209
0.80264437
0.80258918
0.80254489
0.80285197
0.80284745
0.80277485
INFO - Training [17][   40/  196]   Loss 0.492261   Top1 83.457031   Top5 98.007812   BatchTime 0.384886   LR 0.001782
0.80292767
0.80327195
0.80303138
0.80294633
0.80305725
0.80311239
0.80305153
0.80285639
0.80211055
0.80238456
0.80232096
0.80219287
0.80208731
0.80200320
0.80183882
0.80159765
0.80134064
INFO - Training [17][   60/  196]   Loss 0.489050   Top1 83.574219   Top5 98.092448   BatchTime 0.372513   LR 0.001764
0.80104500
0.80073631
0.80048513
0.80019265
0.80009520
0.79976320
0.79948831
0.79948133
0.79943383
0.79955673
0.80122364
0.80099237
0.80075562
0.80065113
0.80074292
0.80092907
0.80111969
0.80110627
0.80135375
0.80192906
INFO - Training [17][   80/  196]   Loss 0.489408   Top1 83.676758   Top5 98.183594   BatchTime 0.352762   LR 0.001746
0.80273664
0.80402070
0.80430830
0.80445647
0.80453539
0.80465019
0.80466849
0.80472732
0.80473411
0.80492884
0.80495083
0.80458128
0.80447769
0.80442888
0.80441254
0.80445552
0.80426174
0.80407870
0.80408925
0.80409014
0.80409694
0.80373609
0.80365318
INFO - Training [17][  100/  196]   Loss 0.481978   Top1 83.843750   Top5 98.203125   BatchTime 0.355207   LR 0.001727
0.80357748
0.80365300
0.80369747
0.80346054
0.80318922
0.80305803
0.80318493
0.80293792
0.80287057
0.80264640
0.80267948
0.80266404
0.80249882
0.80250937
0.80252254
0.80229491
0.80205458
0.80195647
0.80203110
0.80398405
INFO - Training [17][  120/  196]   Loss 0.477646   Top1 84.007161   Top5 98.281250   BatchTime 0.361385   LR 0.001708
0.80388582
0.80342215
0.80301124
0.80277395
0.80274737
0.80252981
0.80216455
0.80208218
0.80191445
0.80178434
0.80168581
0.80164123
0.80169147
0.80154318
0.80157942
0.80144233
INFO - Training [17][  140/  196]   Loss 0.472420   Top1 84.160156   Top5 98.342634   BatchTime 0.362448   LR 0.001690
0.80136287
0.80081224
0.80116206
0.80096012
0.80100459
0.80093604
0.80061823
0.79983908
0.79943311
0.79903966
0.79811352
0.79789066
0.79724014
0.79714757
0.79697591
0.79702681
0.79725647
0.79748327
0.79766804
0.79973692
0.79960519
0.79919863
INFO - Training [17][  160/  196]   Loss 0.473107   Top1 84.194336   Top5 98.352051   BatchTime 0.363035   LR 0.001671
0.79892844
0.79890990
0.79870182
0.79788828
0.79706776
0.79586196
0.79537749
0.79544127
0.79527175
0.79391736
0.79365122
0.79239237
0.79179740
0.79129320
0.79113108
0.79153949
0.79229349
0.79391605
0.79571295
0.79851973
0.80045253
0.80044121
0.80025935
INFO - Training [17][  180/  196]   Loss 0.472168   Top1 84.214410   Top5 98.300781   BatchTime 0.362319   LR 0.001652
0.80011201
0.80191207
0.80182451
0.80162770
0.80163878
0.80301368
0.80308807
0.80263609
0.80264938
0.80192131
0.80188566
0.80166322
0.80154800
0.80145264
0.80128324
********************pre-trained*****************
INFO - ==> Top1: 84.238    Top5: 98.302    Loss: 0.471
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [17][   20/   40]   Loss 0.411748   Top1 86.347656   Top5 99.335938   BatchTime 0.124379
INFO - Validation [17][   40/   40]   Loss 0.391512   Top1 86.890000   Top5 99.550000   BatchTime 0.092812
INFO - ==> Top1: 86.890    Top5: 99.550    Loss: 0.392
INFO - ==> Sparsity : 0.406
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 87.650   Top5: 99.530]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4688)
features.0.conv.3 tensor(0.2598)
features.1.conv.0 tensor(0.0280)
features.1.conv.3 tensor(0.0938)
features.1.conv.6 tensor(0.0577)
features.2.conv.0 tensor(0.0263)
features.2.conv.3 tensor(0.0563)
features.2.conv.6 tensor(0.0909)
features.3.conv.0 tensor(0.0182)
features.3.conv.3 tensor(0.0502)
features.3.conv.6 tensor(0.0451)
features.4.conv.0 tensor(0.0397)
features.4.conv.3 tensor(0.0995)
features.4.conv.6 tensor(0.0877)
features.5.conv.0 tensor(0.0366)
features.5.conv.3 tensor(0.0706)
features.5.conv.6 tensor(0.1099)
features.6.conv.0 tensor(0.0233)
features.6.conv.3 tensor(0.0463)
features.6.conv.6 tensor(0.0625)
features.7.conv.0 tensor(0.0486)
features.7.conv.3 tensor(0.1256)
features.7.conv.6 tensor(0.1156)
features.8.conv.0 tensor(0.0607)
features.8.conv.3 tensor(0.1227)
features.8.conv.6 tensor(0.1469)
features.9.conv.0 tensor(0.0872)
features.9.conv.3 tensor(0.1632)
features.9.conv.6 tensor(0.1278)
features.10.conv.0 tensor(0.0389)
features.10.conv.3 tensor(0.1019)
features.10.conv.6 tensor(0.0363)
features.11.conv.0 tensor(0.6313)
features.11.conv.3 tensor(0.1535)
features.11.conv.6 tensor(0.4056)
features.12.conv.0 tensor(0.1834)
features.12.conv.3 tensor(0.1576)
features.12.conv.6 tensor(0.6246)
features.13.conv.0 tensor(0.1247)
features.13.conv.3 tensor(0.1404)
features.13.conv.6 tensor(0.0886)
features.14.conv.0 tensor(0.9590)
features.14.conv.3 tensor(0.0868)
features.14.conv.6 tensor(0.9797)
features.15.conv.0 tensor(0.8766)
features.15.conv.3 tensor(0.0579)
features.15.conv.6 tensor(0.9796)
features.16.conv.0 tensor(0.1277)
features.16.conv.3 tensor(0.1078)
features.16.conv.6 tensor(0.1843)
conv.0 tensor(0.2069)
tensor(888267.) 2188896.0
0.80121356
0.80142379
0.80168366
0.80199933
0.80185938
0.80207622
0.80197090
0.80184692
0.80170482
0.80181527
0.80174398
0.80170429
0.80175167
0.80181849
0.80197388
0.80176634
0.80175591
0.80142885
0.80137277
INFO - Training [18][   20/  196]   Loss 0.468160   Top1 83.984375   Top5 97.558594   BatchTime 0.449992   LR 0.001618
0.80139667
0.80099398
0.80053538
0.80022675
0.80000222
0.79973328
0.79942095
0.79902029
0.79841107
0.79831165
0.79828387
0.79786313
0.79745740
0.79778278
0.79816675
0.79814136
0.79746717
0.79684079
0.79725301
0.79715449
0.79627889
0.79513174
INFO - Training [18][   40/  196]   Loss 0.468505   Top1 84.052734   Top5 97.890625   BatchTime 0.407661   LR 0.001599
0.79529709
0.79612315
0.79561955
0.79477400
0.79402912
0.79110110
0.79013133
0.79236233
0.79350561
0.78881943
0.78245735
0.77907747
0.77630961
0.78564239
0.79618806
0.80025327
0.80014592
0.80045658
INFO - Training [18][   60/  196]   Loss 0.466338   Top1 84.218750   Top5 98.059896   BatchTime 0.382932   LR 0.001579
0.80007499
0.79983377
0.79949838
0.79933316
0.79937863
0.79921353
0.79928595
0.79920262
0.79910433
0.79889065
0.79908556
0.79914463
0.79945660
0.79950333
0.79942387
0.79921675
0.79894871
0.79878402
0.79853195
0.79806036
INFO - Training [18][   80/  196]   Loss 0.469782   Top1 84.121094   Top5 98.129883   BatchTime 0.360385   LR 0.001560
0.79747999
0.79737550
0.79737157
0.79724270
0.79703861
0.79708248
0.79702342
0.79692537
0.79687780
0.79651481
0.79644805
0.79643512
0.79667842
0.79751688
0.79734254
0.79694420
0.79614979
0.79682672
0.79661793
0.79631728
0.79618502
0.79616672
INFO - Training [18][  100/  196]   Loss 0.464696   Top1 84.273438   Top5 98.238281   BatchTime 0.361671   LR 0.001540
0.79629540
0.79616511
0.79610115
0.79624087
0.79641265
0.79655731
0.79671949
0.79671532
0.79653907
0.79628628
0.79646838
0.79662406
0.79652685
0.79631132
0.79602695
0.79584956
0.79572654
0.79575205
0.79581171
0.79629320
INFO - Training [18][  120/  196]   Loss 0.455484   Top1 84.602865   Top5 98.346354   BatchTime 0.368958   LR 0.001521
0.79640770
0.79580837
0.79635859
0.79622227
0.79619473
0.79634649
0.79736376
0.79750764
0.79737830
0.79717809
0.79672825
0.79631424
0.79582292
0.79531032
0.79504335
0.79473937
0.79481059
INFO - Training [18][  140/  196]   Loss 0.454442   Top1 84.723772   Top5 98.356585   BatchTime 0.366009   LR 0.001501
0.79457992
0.79468775
0.79463917
0.79439121
0.79406792
0.79379612
0.79385579
0.79381895
0.79406899
0.79407650
0.79441929
0.79433960
0.79455107
0.79469413
0.79449326
0.79440647
0.79421437
0.79398441
0.79381806
0.79369295
0.79329824
0.79314327
0.79291546
0.79228157
INFO - Training [18][  160/  196]   Loss 0.456488   Top1 84.606934   Top5 98.354492   BatchTime 0.363194   LR 0.001482
0.79181761
0.79158980
0.79162204
0.79218507
0.79239625
0.79232901
0.79258412
0.79295248
0.79320753
0.79328841
0.79326278
0.79317081
0.79333794
0.79352546
0.79387975
0.79399925
INFO - Training [18][  180/  196]   Loss 0.455972   Top1 84.594184   Top5 98.313802   BatchTime 0.362572   LR 0.001462
0.79411477
0.79418600
0.79421908
0.79469353
0.79826236
0.79812467
0.79768008
0.79769087
0.79775834
0.79767752
0.79809326
0.79752308
0.79895639
0.79844368
0.79786336
0.79716831
0.79644716
INFO - ==> Top1: 84.712    Top5: 98.322    Loss: 0.453
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.79480910
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [18][   20/   40]   Loss 0.388944   Top1 87.265625   Top5 99.394531   BatchTime 0.123335
features.0.conv.0 tensor(0.4549)
features.0.conv.3 tensor(0.2578)
features.1.conv.0 tensor(0.0234)
features.1.conv.3 tensor(0.0891)
features.1.conv.6 tensor(0.0547)
features.2.conv.0 tensor(0.0298)
features.2.conv.3 tensor(0.0571)
features.2.conv.6 tensor(0.0856)
features.3.conv.0 tensor(0.0217)
features.3.conv.3 tensor(0.0548)
features.3.conv.6 tensor(0.0391)
features.4.conv.0 tensor(0.2617)
features.4.conv.3 tensor(0.0932)
features.4.conv.6 tensor(0.0854)
features.5.conv.0 tensor(0.0282)
features.5.conv.3 tensor(0.0689)
features.5.conv.6 tensor(0.1055)
features.6.conv.0 tensor(0.0220)
features.6.conv.3 tensor(0.0440)
features.6.conv.6 tensor(0.0599)
features.7.conv.0 tensor(0.0471)
features.7.conv.3 tensor(0.1250)
features.7.conv.6 tensor(0.1158)
features.8.conv.0 tensor(0.0667)
features.8.conv.3 tensor(0.1244)
features.8.conv.6 tensor(0.1197)
features.9.conv.0 tensor(0.0873)
features.9.conv.3 tensor(0.1606)
features.9.conv.6 tensor(0.1314)
features.10.conv.0 tensor(0.0370)
features.10.conv.3 tensor(0.0966)
features.10.conv.6 tensor(0.0703)
features.11.conv.0 tensor(0.5908)
features.11.conv.3 tensor(0.1564)
features.11.conv.6 tensor(0.4293)
features.12.conv.0 tensor(0.2578)
features.12.conv.3 tensor(0.1541)
features.12.conv.6 tensor(0.6308)
features.13.conv.0 tensor(0.1186)
features.13.conv.3 tensor(0.1402)
features.13.conv.6 tensor(0.1039)
features.14.conv.0 tensor(0.9595)
features.14.conv.3 tensor(0.0869)
features.14.conv.6 tensor(0.9801)
features.15.conv.0 tensor(0.8839)
features.15.conv.3 tensor(0.0569)
features.15.conv.6 tensor(0.9799)
features.16.conv.0 tensor(0.1328)
features.16.conv.3 tensor(0.1093)
features.16.conv.6 tensor(0.1851)
conv.0 tensor(0.2122)
tensor(899281.) 2188896.0
INFO - Validation [18][   40/   40]   Loss 0.375382   Top1 87.470000   Top5 99.510000   BatchTime 0.089087
INFO - ==> Top1: 87.470    Top5: 99.510    Loss: 0.375
INFO - ==> Sparsity : 0.411
INFO - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 2 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 87.650   Top5: 99.530]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
0.79564810
0.79593998
0.79652965
0.79669315
0.79647440
0.79597151
0.79573816
0.79556167
0.79555649
0.79547787
0.79484624
0.79452986
0.79460770
0.79457891
0.79451931
0.79427391
0.79387587
0.79319227
INFO - Training [19][   20/  196]   Loss 0.455500   Top1 83.984375   Top5 98.125000   BatchTime 0.435992   LR 0.001427
0.79301721
0.79268414
0.79251820
0.79255414
0.79246956
0.79223961
0.79149216
0.79040945
0.78907454
0.78775960
0.78681713
0.78535157
0.78471619
0.78341293
0.78231084
0.78216445
0.78151405
0.78031826
0.77827805
0.77471948
0.76924181
0.76525140
0.76329476
INFO - Training [19][   40/  196]   Loss 0.456768   Top1 84.375000   Top5 98.164062   BatchTime 0.395819   LR 0.001407
0.76292443
0.76304799
0.76420748
0.76745147
0.77082080
0.77705842
0.78191239
0.78538817
0.78833145
0.79181349
0.79321659
0.79449719
0.79545301
0.79668254
0.79710907
0.79700333
INFO - Training [19][   60/  196]   Loss 0.460026   Top1 84.348958   Top5 98.157552   BatchTime 0.383017   LR 0.001387
0.79694021
0.79700243
0.79733914
0.79794955
0.79829746
0.79841512
0.79850787
0.79859579
0.79874420
0.79897940
0.79886460
0.79878372
0.79867238
0.79873043
0.79851240
0.79845583
0.79845709
0.79844958
0.79831189
0.79827321
0.79832458
0.79829866
INFO - Training [19][   80/  196]   Loss 0.460430   Top1 84.384766   Top5 98.198242   BatchTime 0.356196   LR 0.001367
0.79839641
0.79861730
0.79853976
0.79874158
0.79866499
0.79882395
0.79867339
0.79863453
0.79852045
0.79850030
0.79845387
0.79842585
0.79834861
0.79836041
0.79841602
0.79849279
0.79848403
INFO - Training [19][  100/  196]   Loss 0.450926   Top1 84.777344   Top5 98.242188   BatchTime 0.353835   LR 0.001347
0.79858756
0.79870933
0.79864526
0.79861039
0.79874074
0.79868752
0.79868478
0.79874408
0.79859686
0.79868102
0.79880297
0.79876500
0.79883343
0.79878330
0.79885423
0.80102688
0.80061567
0.80035210
0.80030632
0.80026740
0.80028039
0.80027401
INFO - Training [19][  120/  196]   Loss 0.445460   Top1 84.996745   Top5 98.320312   BatchTime 0.357374   LR 0.001327
0.79999250
0.79968482
0.79940659
0.79893577
0.79890174
0.79893863
0.79907274
0.79910111
0.79909569
0.79917932
0.79917258
0.79932117
0.79931641
0.79927748
0.79934239
0.79944032
0.79934388
0.79906613
0.79882139
0.79830587
INFO - Training [19][  140/  196]   Loss 0.443576   Top1 85.122768   Top5 98.373326   BatchTime 0.363806   LR 0.001307
0.79781008
0.79727328
0.79678380
0.79648513
0.79552513
0.79494804
0.79498947
0.79492843
0.79437703
0.79426426
0.79398704
0.79396284
0.79352033
0.79298681
0.79276139
0.79236346
0.79228479
0.79215932
0.79188764
0.79142529
0.79116994
0.79129368
0.79124171
INFO - Training [19][  160/  196]   Loss 0.448095   Top1 84.982910   Top5 98.388672   BatchTime 0.360416   LR 0.001287
0.79126525
0.79109752
0.79079080
0.79056031
0.79047287
0.79036242
0.79021591
0.79006451
0.78967899
0.78981435
0.78968632
0.79038572
0.79102951
0.79129004
0.79124343
0.79089880
0.79092532
0.79049718
INFO - Training [19][  180/  196]   Loss 0.447575   Top1 84.950087   Top5 98.313802   BatchTime 0.358298   LR 0.001266
0.79103768
0.79095560
0.79043049
0.78982061
0.78929853
0.78901124
0.78859532
0.78834379
0.78802544
0.78747445
0.78713006
0.78714263
0.78770292
0.78797275
0.78783000
0.78747243
0.78729331
INFO - ==> Top1: 85.036    Top5: 98.306    Loss: 0.446
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [19][   20/   40]   Loss 0.365642   Top1 88.222656   Top5 99.375000   BatchTime 0.120959
features.0.conv.0 tensor(0.4757)
features.0.conv.3 tensor(0.2695)
features.1.conv.0 tensor(0.0247)
features.1.conv.3 tensor(0.0903)
features.1.conv.6 tensor(0.0530)
features.2.conv.0 tensor(0.0353)
features.2.conv.3 tensor(0.0571)
features.2.conv.6 tensor(0.0880)
features.3.conv.0 tensor(0.0153)
features.3.conv.3 tensor(0.0548)
features.3.conv.6 tensor(0.0449)
features.4.conv.0 tensor(0.0342)
features.4.conv.3 tensor(0.0926)
features.4.conv.6 tensor(0.0895)
features.5.conv.0 tensor(0.0301)
features.5.conv.3 tensor(0.0660)
features.5.conv.6 tensor(0.1076)
features.6.conv.0 tensor(0.0229)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0566)
features.7.conv.0 tensor(0.0478)
features.7.conv.3 tensor(0.1308)
features.7.conv.6 tensor(0.1506)
features.8.conv.0 tensor(0.0629)
features.8.conv.3 tensor(0.1267)
features.8.conv.6 tensor(0.1240)
features.9.conv.0 tensor(0.0889)
features.9.conv.3 tensor(0.1574)
features.9.conv.6 tensor(0.1914)
features.10.conv.0 tensor(0.0396)
features.10.conv.3 tensor(0.0995)
features.10.conv.6 tensor(0.0895)
features.11.conv.0 tensor(0.5933)
features.11.conv.3 tensor(0.1541)
features.11.conv.6 tensor(0.4334)
features.12.conv.0 tensor(0.1511)
features.12.conv.3 tensor(0.1657)
features.12.conv.6 tensor(0.6515)
features.13.conv.0 tensor(0.1031)
features.13.conv.3 tensor(0.1422)
features.13.conv.6 tensor(0.1257)
features.14.conv.0 tensor(0.9610)
features.14.conv.3 tensor(0.0862)
features.14.conv.6 tensor(0.9801)
features.15.conv.0 tensor(0.8915)
features.15.conv.3 tensor(0.0553)
features.15.conv.6 tensor(0.9812)
features.16.conv.0 tensor(0.1346)
features.16.conv.3 tensor(0.1084)
features.16.conv.6 tensor(0.1882)
conv.0 tensor(0.2055)
tensor(897972.) 2188896.0
INFO - Validation [19][   40/   40]   Loss 0.346461   Top1 88.530000   Top5 99.580000   BatchTime 0.087477
INFO - ==> Top1: 88.530    Top5: 99.580    Loss: 0.346
INFO - ==> Sparsity : 0.410
INFO - Scoreboard best 1 ==> Epoch [19][Top1: 88.530   Top5: 99.580]
INFO - Scoreboard best 2 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Scoreboard best 3 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
0.78742433
0.78732353
0.78707427
0.78664064
0.78661048
0.78658932
0.78625041
0.78586113
0.78597921
0.78594768
0.78699630
0.78813702
0.78815562
0.78837103
0.78876340
0.78878379
0.78875607
0.79041988
0.79047191
0.79048061
INFO - Training [20][   20/  196]   Loss 0.432781   Top1 84.882812   Top5 97.714844   BatchTime 0.454285   LR 0.001231
0.79025209
0.79040194
0.79093605
0.79389739
0.79530627
0.79577839
0.79576069
0.79570299
0.79572284
0.79571915
0.79589158
0.79738730
0.79789466
0.79766500
0.79768866
0.79779077
0.79788309
0.79801130
0.79782385
0.79747719
0.79712433
0.79679829
INFO - Training [20][   40/  196]   Loss 0.445021   Top1 84.951172   Top5 98.066406   BatchTime 0.408618   LR 0.001211
0.79644436
0.79618174
0.79585493
0.79573888
0.79571491
0.79562753
0.79545432
0.79529518
0.79510701
0.79482234
0.79427493
0.79376584
0.79387176
0.79391354
0.79354596
0.79305482
0.79247582
0.79198772
INFO - Training [20][   60/  196]   Loss 0.436701   Top1 85.384115   Top5 98.248698   BatchTime 0.381610   LR 0.001191
0.79151291
0.79117352
0.79120165
0.79170334
0.79268628
0.79358089
0.79609883
0.79878223
0.79914469
0.79878706
0.79866964
0.79849201
0.79818314
0.79818660
0.79845864
0.79853636
0.79835445
0.79847336
INFO - Training [20][   80/  196]   Loss 0.439570   Top1 85.209961   Top5 98.330078   BatchTime 0.369627   LR 0.001171
0.79838127
0.79851979
0.79860824
0.79870373
0.79862934
0.79878819
0.79892439
0.79868811
0.79852140
0.79859120
0.79864144
0.79845726
0.79866153
0.79851681
0.79861307
0.79845911
0.79835361
0.79829079
0.79833221
0.79793459
0.79804331
0.79765141
0.79753262
INFO - Training [20][  100/  196]   Loss 0.431219   Top1 85.527344   Top5 98.394531   BatchTime 0.366979   LR 0.001151
0.79724747
0.79702646
0.79657555
0.79602957
0.79550231
0.79537100
0.79508948
0.79506987
0.79475749
0.79456365
0.79442620
0.79446399
0.79435098
0.79448193
0.79439884
INFO - Training [20][  120/  196]   Loss 0.426459   Top1 85.709635   Top5 98.486328   BatchTime 0.368989   LR 0.001131
0.79404366
0.79405886
0.79408431
0.79417580
0.79433441
0.79430032
0.79432845
0.79437196
0.79466206
0.79489541
0.79492325
0.79501301
0.79518843
0.79511720
0.79496872
0.79491109
0.79495877
0.79497260
0.79488331
0.79457629
0.79465467
0.79491884
INFO - Training [20][  140/  196]   Loss 0.423234   Top1 85.789621   Top5 98.532366   BatchTime 0.369716   LR 0.001111
0.79669428
0.79612988
0.79541749
0.79462206
0.79297572
0.79070961
0.78784144
0.78338999
0.78053963
0.77815539
0.77447218
0.77181464
0.77066267
0.77078772
0.77271992
0.77234226
0.77073616
0.77127916
0.77197063
0.77434212
0.77790296
0.78237706
INFO - Training [20][  160/  196]   Loss 0.427618   Top1 85.668945   Top5 98.520508   BatchTime 0.369041   LR 0.001091
0.78734589
0.79149550
0.79411656
0.79578036
0.79732662
0.79705024
0.79696488
0.79700124
0.79697376
0.79691565
0.79684365
0.79677790
0.79683399
0.79698777
0.79728347
0.79768223
INFO - Training [20][  180/  196]   Loss 0.427501   Top1 85.664062   Top5 98.476562   BatchTime 0.367968   LR 0.001071
0.79753214
0.79745078
0.79728633
0.79712445
0.79701030
0.79683191
0.79691851
0.79692364
0.79701161
0.79656959
0.79596835
0.79585510
0.79590428
0.79557472
0.79500383
0.79394823
0.79406756
0.79434991
0.79395992
0.79348898
********************pre-trained*****************
INFO - ==> Top1: 85.712    Top5: 98.470    Loss: 0.426
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [20][   20/   40]   Loss 0.343728   Top1 88.183594   Top5 99.550781   BatchTime 0.117938
INFO - Validation [20][   40/   40]   Loss 0.332594   Top1 88.460000   Top5 99.650000   BatchTime 0.086626
INFO - ==> Top1: 88.460    Top5: 99.650    Loss: 0.333
INFO - ==> Sparsity : 0.413
INFO - Scoreboard best 1 ==> Epoch [19][Top1: 88.530   Top5: 99.580]
INFO - Scoreboard best 2 ==> Epoch [20][Top1: 88.460   Top5: 99.650]
INFO - Scoreboard best 3 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4549)
features.0.conv.3 tensor(0.2695)
features.1.conv.0 tensor(0.0247)
features.1.conv.3 tensor(0.0868)
features.1.conv.6 tensor(0.0530)
features.2.conv.0 tensor(0.0350)
features.2.conv.3 tensor(0.0602)
features.2.conv.6 tensor(0.0903)
features.3.conv.0 tensor(0.0177)
features.3.conv.3 tensor(0.0563)
features.3.conv.6 tensor(0.0451)
features.4.conv.0 tensor(0.0309)
features.4.conv.3 tensor(0.0920)
features.4.conv.6 tensor(0.0874)
features.5.conv.0 tensor(0.0285)
features.5.conv.3 tensor(0.0700)
features.5.conv.6 tensor(0.1007)
features.6.conv.0 tensor(0.0283)
features.6.conv.3 tensor(0.0446)
features.6.conv.6 tensor(0.0597)
features.7.conv.0 tensor(0.0499)
features.7.conv.3 tensor(0.1288)
features.7.conv.6 tensor(0.1245)
features.8.conv.0 tensor(0.0629)
features.8.conv.3 tensor(0.1186)
features.8.conv.6 tensor(0.1229)
features.9.conv.0 tensor(0.0864)
features.9.conv.3 tensor(0.1580)
features.9.conv.6 tensor(0.1551)
features.10.conv.0 tensor(0.0408)
features.10.conv.3 tensor(0.0998)
features.10.conv.6 tensor(0.0928)
features.11.conv.0 tensor(0.6017)
features.11.conv.3 tensor(0.1549)
features.11.conv.6 tensor(0.4381)
features.12.conv.0 tensor(0.1505)
features.12.conv.3 tensor(0.1680)
features.12.conv.6 tensor(0.6423)
features.13.conv.0 tensor(0.0994)
features.13.conv.3 tensor(0.1424)
features.13.conv.6 tensor(0.1007)
features.14.conv.0 tensor(0.9616)
features.14.conv.3 tensor(0.0881)
features.14.conv.6 tensor(0.9805)
features.15.conv.0 tensor(0.8940)
features.15.conv.3 tensor(0.0557)
features.15.conv.6 tensor(0.9789)
features.16.conv.0 tensor(0.1399)
features.16.conv.3 tensor(0.1071)
features.16.conv.6 tensor(0.2037)
conv.0 tensor(0.2150)
tensor(903896.) 2188896.0
0.79333609
0.79296738
0.79260635
0.79258442
0.79255253
0.79253376
0.79257792
0.79257780
0.79252851
0.79235065
0.79215592
0.79275888
0.79396206
0.79390699
0.79349303
0.79338098
0.79327559
0.79307419
0.79263371
INFO - Training [21][   20/  196]   Loss 0.441926   Top1 84.882812   Top5 97.558594   BatchTime 0.462183   LR 0.001036
0.79227746
0.79169911
0.79140526
0.79135162
0.79128510
0.79123580
0.79084921
0.79039627
0.78996795
0.78958565
0.78950363
0.78934062
0.78879279
0.78844976
0.78778124
0.78699720
0.78592336
0.78510755
0.78478521
0.78448427
0.78414494
0.78389406
0.78373724
INFO - Training [21][   40/  196]   Loss 0.428715   Top1 85.400391   Top5 98.164062   BatchTime 0.408670   LR 0.001016
0.78307265
0.78250480
0.78216654
0.78193080
0.78223139
0.78270811
0.78297216
0.78327614
0.78449118
0.78986180
0.79209059
0.79179865
0.79209805
0.79230183
0.79238373
0.79203314
0.79173017
0.79173517
INFO - Training [21][   60/  196]   Loss 0.423521   Top1 85.664062   Top5 98.203125   BatchTime 0.381863   LR 0.000996
0.79195267
0.79180866
0.79157871
0.79169118
0.79133701
0.79121900
0.79129362
0.79109585
0.79095244
0.79109955
0.79107720
0.79101992
0.79052085
0.79008663
0.78981042
0.78986984
0.79017711
0.78998739
INFO - Training [21][   80/  196]   Loss 0.422834   Top1 85.839844   Top5 98.286133   BatchTime 0.367539   LR 0.000976
0.78980327
0.78985047
0.78976655
0.78957152
0.78950983
0.78948349
0.78952092
0.78986871
0.79017514
0.79128164
0.79244691
0.79215288
0.79192024
0.79141104
0.79117954
0.79113275
0.79121441
0.79102451
0.79064548
0.79019082
0.78994679
0.78956246
INFO - Training [21][  100/  196]   Loss 0.418115   Top1 86.000000   Top5 98.339844   BatchTime 0.367365   LR 0.000957
0.78938681
0.78933561
0.78946131
0.78952056
0.78972077
0.78991145
0.79019672
0.79058880
0.79091161
0.79093927
0.79113233
0.79116756
0.79112434
0.79121476
0.79530442
0.79508460
0.79502624
0.79488546
0.79484737
0.79449809
0.79420537
INFO - Training [21][  120/  196]   Loss 0.412307   Top1 86.106771   Top5 98.440755   BatchTime 0.370719   LR 0.000937
0.79398054
0.79386955
0.79377073
0.79359782
0.79334193
0.79321516
0.79316783
0.79338419
0.79334116
0.79314756
0.79264259
0.79214215
0.79192907
0.79172730
0.79151857
0.79121077
INFO - Training [21][  140/  196]   Loss 0.412041   Top1 86.065848   Top5 98.537946   BatchTime 0.371457   LR 0.000918
0.79077137
0.79062462
0.79031855
0.78982240
0.78949308
0.78903925
0.78872174
0.78857845
0.78873223
0.78900754
0.78944016
0.79002184
0.79048681
0.79069829
0.79100072
0.79116488
0.79137695
0.79141730
0.79143077
0.79351091
0.79388171
0.79397875
0.79423195
INFO - Training [21][  160/  196]   Loss 0.413490   Top1 86.052246   Top5 98.535156   BatchTime 0.368252   LR 0.000899
0.79419082
0.79424477
0.79436427
0.79420519
0.79415423
0.79431635
0.79414082
0.79385871
0.79368061
0.79338461
0.79323328
0.79332578
0.79326051
0.79323536
0.79301149
0.79295933
INFO - Training [21][  180/  196]   Loss 0.413288   Top1 86.056858   Top5 98.478733   BatchTime 0.367625   LR 0.000879
0.79264146
0.79254681
0.79243398
0.79237926
0.79231817
0.79219109
0.79217196
0.79218918
0.79197401
0.79166538
0.79163355
0.79139644
0.79139888
0.79110032
0.79069012
0.79047304
0.79018313
INFO - ==> Top1: 86.102    Top5: 98.476    Loss: 0.412
0.78986341
0.78968745
0.78937489
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [21][   20/   40]   Loss 0.339932   Top1 88.828125   Top5 99.550781   BatchTime 0.125693
INFO - Validation [21][   40/   40]   Loss 0.323474   Top1 89.180000   Top5 99.660000   BatchTime 0.090689
INFO - ==> Top1: 89.180    Top5: 99.660    Loss: 0.323
INFO - ==> Sparsity : 0.418
INFO - Scoreboard best 1 ==> Epoch [21][Top1: 89.180   Top5: 99.660]
INFO - Scoreboard best 2 ==> Epoch [19][Top1: 88.530   Top5: 99.580]
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 88.460   Top5: 99.650]
features.0.conv.0 tensor(0.4653)
features.0.conv.3 tensor(0.2871)
features.1.conv.0 tensor(0.0202)
features.1.conv.3 tensor(0.0868)
features.1.conv.6 tensor(0.0556)
features.2.conv.0 tensor(0.0246)
features.2.conv.3 tensor(0.0594)
features.2.conv.6 tensor(0.0923)
features.3.conv.0 tensor(0.0179)
features.3.conv.3 tensor(0.0532)
features.3.conv.6 tensor(0.0456)
features.4.conv.0 tensor(0.0312)
features.4.conv.3 tensor(0.0926)
features.4.conv.6 tensor(0.0856)
features.5.conv.0 tensor(0.0288)
features.5.conv.3 tensor(0.0683)
features.5.conv.6 tensor(0.1097)
features.6.conv.0 tensor(0.0252)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0598)
features.7.conv.0 tensor(0.0475)
features.7.conv.3 tensor(0.1253)
features.7.conv.6 tensor(0.1338)
features.8.conv.0 tensor(0.0669)
features.8.conv.3 tensor(0.1195)
features.8.conv.6 tensor(0.2125)
features.9.conv.0 tensor(0.0878)
features.9.conv.3 tensor(0.1522)
features.9.conv.6 tensor(0.1559)
features.10.conv.0 tensor(0.0425)
features.10.conv.3 tensor(0.1033)
features.10.conv.6 tensor(0.0943)
features.11.conv.0 tensor(0.6039)
features.11.conv.3 tensor(0.1568)
features.11.conv.6 tensor(0.4727)
features.12.conv.0 tensor(0.1531)
features.12.conv.3 tensor(0.1626)
features.12.conv.6 tensor(0.6529)
features.13.conv.0 tensor(0.1118)
features.13.conv.3 tensor(0.1416)
features.13.conv.6 tensor(0.1092)
features.14.conv.0 tensor(0.9619)
features.14.conv.3 tensor(0.0852)
features.14.conv.6 tensor(0.9806)
features.15.conv.0 tensor(0.8977)
features.15.conv.3 tensor(0.0545)
features.15.conv.6 tensor(0.9772)
features.16.conv.0 tensor(0.1452)
features.16.conv.3 tensor(0.1089)
features.16.conv.6 tensor(0.2045)
conv.0 tensor(0.2202)
tensor(914257.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
0.78899771
0.78860879
0.78833210
0.78840381
0.78858936
0.78863341
0.78849655
0.78819084
0.78813756
0.78802592
0.78765321
0.78716177
0.78643125
0.78586602
0.78505963
0.78446293
0.78377557
0.78294808
INFO - Training [22][   20/  196]   Loss 0.439484   Top1 85.175781   Top5 97.832031   BatchTime 0.431002   LR 0.000846
0.78224510
0.78154325
0.78078103
0.77995366
0.77947122
0.77890700
0.77847582
0.77835238
0.77823979
0.77795219
0.77768689
0.77743554
0.77722859
0.77706921
0.77690387
0.77652425
0.77605951
0.77579373
0.77560258
INFO - Training [22][   40/  196]   Loss 0.436437   Top1 85.449219   Top5 98.095703   BatchTime 0.374682   LR 0.000827
0.77548504
0.77544832
0.77519864
0.77515566
0.77518493
0.77502489
0.77496701
0.77509373
0.77533603
0.77589113
0.77830380
0.78254974
0.78523260
0.78553939
0.78559583
0.78546154
0.78560615
0.78552592
0.78544271
0.78559071
0.78567308
0.78679276
0.78768420
INFO - Training [22][   60/  196]   Loss 0.428545   Top1 85.559896   Top5 98.190104   BatchTime 0.369610   LR 0.000808
0.78777730
0.78785944
0.78804010
0.78854203
0.78874815
0.78848547
0.78866917
0.78870577
0.78879523
0.78900033
0.78911072
0.78915644
0.78914297
0.78920352
0.78927928
0.78933471
0.78962404
0.78943813
0.78952116
0.78957468
0.78934449
0.78918856
INFO - Training [22][   80/  196]   Loss 0.425642   Top1 85.712891   Top5 98.344727   BatchTime 0.369485   LR 0.000789
0.78888559
0.78857559
0.78830963
0.78824407
0.78791374
0.78769386
0.78762954
0.78761882
0.78773510
0.78768188
0.78787738
0.78763795
0.78777242
0.78771740
0.78756279
INFO - Training [22][  100/  196]   Loss 0.415836   Top1 86.093750   Top5 98.402344   BatchTime 0.371860   LR 0.000770
0.78761894
0.78770399
0.78745055
0.78736508
0.78758532
0.78775275
0.78762269
0.78781086
0.78725779
0.78717971
0.78715700
0.78705430
0.78695720
0.78660733
0.78638488
0.78585953
0.78514302
0.78472483
0.78470725
0.78487456
0.78486556
0.78495908
INFO - Training [22][  120/  196]   Loss 0.408445   Top1 86.331380   Top5 98.505859   BatchTime 0.371986   LR 0.000752
0.78499866
0.78506345
0.78514659
0.78508687
0.78500414
0.78512818
0.78471428
0.78454244
0.78438282
0.78415447
0.78404957
0.78403246
0.78391087
0.78378302
0.78382927
0.78377175
0.78356135
0.78367609
0.78583866
0.78536516
0.78591919
0.78574359
INFO - Training [22][  140/  196]   Loss 0.405707   Top1 86.431362   Top5 98.582589   BatchTime 0.369080   LR 0.000734
0.78558308
0.78542137
0.78540921
0.78522694
0.78506643
0.78483003
0.78460717
0.78438526
0.78414482
0.78385174
0.78361005
0.78346300
0.78323257
0.78301734
0.78281510
0.78260583
0.78246266
INFO - Training [22][  160/  196]   Loss 0.405011   Top1 86.408691   Top5 98.632812   BatchTime 0.368569   LR 0.000715
0.78221798
0.78209800
0.78188235
0.78175455
0.78163058
0.78176272
0.78153789
0.78131878
0.78123885
0.78112650
0.78091294
0.78081065
0.78061730
0.78036809
0.78003287
0.77980030
0.77948433
0.77946734
0.77938873
0.77938604
0.77921611
INFO - Training [22][  180/  196]   Loss 0.405812   Top1 86.330295   Top5 98.578559   BatchTime 0.368680   LR 0.000697
0.77905613
0.77888119
0.77886117
0.77869684
0.77829713
0.77791059
0.77779007
0.77765441
0.77754146
0.77747685
0.77722394
0.77708203
0.77683884
0.77654642
0.77637750
0.77616060
0.77594668
INFO - ==> Top1: 86.356    Top5: 98.576    Loss: 0.405
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [22][   20/   40]   Loss 0.325362   Top1 89.199219   Top5 99.648438   BatchTime 0.144136
INFO - Validation [22][   40/   40]   Loss 0.316925   Top1 89.340000   Top5 99.700000   BatchTime 0.098549
features.0.conv.0 tensor(0.4583)
features.0.conv.3 tensor(0.3027)
features.1.conv.0 tensor(0.0189)
features.1.conv.3 tensor(0.0926)
features.1.conv.6 tensor(0.0573)
features.2.conv.0 tensor(0.0284)
features.2.conv.3 tensor(0.0563)
features.2.conv.6 tensor(0.0906)
features.3.conv.0 tensor(0.0217)
features.3.conv.3 tensor(0.0586)
features.3.conv.6 tensor(0.0445)
features.4.conv.0 tensor(0.0361)
features.4.conv.3 tensor(0.0949)
features.4.conv.6 tensor(0.0851)
features.5.conv.0 tensor(0.0285)
features.5.conv.3 tensor(0.0735)
features.5.conv.6 tensor(0.1203)
features.6.conv.0 tensor(0.0199)
features.6.conv.3 tensor(0.0492)
features.6.conv.6 tensor(0.0576)
features.7.conv.0 tensor(0.0452)
features.7.conv.3 tensor(0.1244)
features.7.conv.6 tensor(0.1498)
features.8.conv.0 tensor(0.0661)
features.8.conv.3 tensor(0.1201)
features.8.conv.6 tensor(0.1617)
features.9.conv.0 tensor(0.0907)
features.9.conv.3 tensor(0.1510)
features.9.conv.6 tensor(0.3383)
features.10.conv.0 tensor(0.0388)
features.10.conv.3 tensor(0.1021)
features.10.conv.6 tensor(0.0817)
features.11.conv.0 tensor(0.5700)
features.11.conv.3 tensor(0.1561)
features.11.conv.6 tensor(0.4634)
features.12.conv.0 tensor(0.1555)
features.12.conv.3 tensor(0.1613)
features.12.conv.6 tensor(0.6583)
features.13.conv.0 tensor(0.1189)
features.13.conv.3 tensor(0.1406)
features.13.conv.6 tensor(0.1733)
features.14.conv.0 tensor(0.9628)
features.14.conv.3 tensor(0.0845)
features.14.conv.6 tensor(0.9806)
features.15.conv.0 tensor(0.9015)
features.15.conv.3 tensor(0.0553)
features.15.conv.6 tensor(0.9766)
features.16.conv.0 tensor(0.1482)
features.16.conv.3 tensor(0.1091)
features.16.conv.6 tensor(0.2305)
conv.0 tensor(0.2322)
tensor(935737.) 2188896.0
INFO - ==> Top1: 89.340    Top5: 99.700    Loss: 0.317
INFO - ==> Sparsity : 0.427
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 89.340   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [21][Top1: 89.180   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [19][Top1: 88.530   Top5: 99.580]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
0.77561188
0.77537525
0.77516049
0.77484208
0.77471608
0.77464008
0.77474743
0.77473122
0.77461487
0.77437490
0.77430123
0.77417505
0.77410442
0.77388179
0.77369267
0.77348924
0.77342737
0.77325207
INFO - Training [23][   20/  196]   Loss 0.418118   Top1 85.839844   Top5 98.066406   BatchTime 0.369568   LR 0.000666
0.77328187
0.77323645
0.77328891
0.77319407
0.77309787
0.77286524
0.77267200
0.77243763
0.77246183
0.77276689
0.77313066
0.77324522
0.77368730
0.77389807
0.77424216
0.77487576
0.77521706
0.77696484
0.77931917
0.77938700
0.77936345
INFO - Training [23][   40/  196]   Loss 0.424801   Top1 85.556641   Top5 98.291016   BatchTime 0.329779   LR 0.000648
0.77921879
0.77913892
0.77928656
0.77932912
0.77934915
0.77933097
0.77932930
0.77932775
0.77934891
0.77933002
0.77928722
0.77930462
0.77916169
0.77904880
0.77897263
0.77883160
0.77873451
0.77871549
0.77882946
0.77892113
0.77994907
0.77974659
INFO - Training [23][   60/  196]   Loss 0.408948   Top1 86.256510   Top5 98.385417   BatchTime 0.338801   LR 0.000630
0.77976799
0.77983052
0.77976865
0.77976280
0.77961415
0.77948856
0.77930337
0.77917331
0.77907532
0.77895015
0.77889919
0.77885634
0.77889961
0.77844286
0.77837175
0.77852261
INFO - Training [23][   80/  196]   Loss 0.409742   Top1 86.352539   Top5 98.476562   BatchTime 0.348960   LR 0.000613
0.77873313
0.77891129
0.77886868
0.77888149
0.77872866
0.77855194
0.77817398
0.77798045
0.77790219
0.77773434
0.77752590
0.77734804
0.77694052
0.77680945
0.77691704
0.77672058
0.77656823
0.77643895
0.77659619
0.77670187
0.77652407
INFO - Training [23][  100/  196]   Loss 0.406981   Top1 86.386719   Top5 98.511719   BatchTime 0.354534   LR 0.000596
0.77658802
0.77642697
0.77644742
0.77642268
0.77632797
0.77628738
0.77634996
0.77598101
0.77627027
0.77635103
0.77614337
0.77588040
0.77589470
0.77590036
0.77592576
0.77596980
0.77604389
0.77619910
0.77626848
0.77641439
0.77602232
INFO - Training [23][  120/  196]   Loss 0.398582   Top1 86.722005   Top5 98.613281   BatchTime 0.359338   LR 0.000579
0.77592421
0.77565604
0.77564436
0.77557653
0.77560055
0.77538568
0.77528006
0.77516669
0.77487350
0.77467358
0.77482158
0.77435809
0.77424258
0.77402467
0.77371764
0.77352870
0.77355975
0.77310550
0.77348763
0.77314377
0.77254295
0.77202755
INFO - Training [23][  140/  196]   Loss 0.396367   Top1 86.752232   Top5 98.641183   BatchTime 0.360485   LR 0.000562
0.77173585
0.77153081
0.77151459
0.77148944
0.77142638
0.77138287
0.77119672
0.77116799
0.77122039
0.77128845
0.77127153
0.77117485
0.77114308
0.77101761
0.77101582
0.77110976
INFO - Training [23][  160/  196]   Loss 0.398061   Top1 86.640625   Top5 98.627930   BatchTime 0.362430   LR 0.000545
0.77110738
0.77101558
0.77068508
0.77037776
0.76999521
0.76995248
0.76979500
0.76963234
0.76958811
0.76948130
0.76936811
0.76931912
0.76930708
0.76938146
0.76952529
0.76990408
0.77036941
0.77108282
0.77127308
0.77119792
INFO - Training [23][  180/  196]   Loss 0.398265   Top1 86.612413   Top5 98.561198   BatchTime 0.366470   LR 0.000529
0.77122235
0.77182043
0.77344388
0.77341670
0.77352816
0.77350491
0.77337593
0.77325970
0.77316362
0.77281499
0.77251512
0.77212763
0.77186775
0.77158421
0.77132720
0.77098262
0.77087098
INFO - ==> Top1: 86.656    Top5: 98.548    Loss: 0.397
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.77089208
0.77076924
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [23][   20/   40]   Loss 0.329499   Top1 89.238281   Top5 99.609375   BatchTime 0.125120
INFO - Validation [23][   40/   40]   Loss 0.319621   Top1 89.290000   Top5 99.700000   BatchTime 0.086760
INFO - ==> Top1: 89.290    Top5: 99.700    Loss: 0.320
INFO - ==> Sparsity : 0.426
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 89.340   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 89.290   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [21][Top1: 89.180   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4722)
features.0.conv.3 tensor(0.3242)
features.1.conv.0 tensor(0.0221)
features.1.conv.3 tensor(0.0880)
features.1.conv.6 tensor(0.0595)
features.2.conv.0 tensor(0.0223)
features.2.conv.3 tensor(0.0579)
features.2.conv.6 tensor(0.0929)
features.3.conv.0 tensor(0.0182)
features.3.conv.3 tensor(0.0586)
features.3.conv.6 tensor(0.0432)
features.4.conv.0 tensor(0.0384)
features.4.conv.3 tensor(0.0926)
features.4.conv.6 tensor(0.0871)
features.5.conv.0 tensor(0.0365)
features.5.conv.3 tensor(0.0683)
features.5.conv.6 tensor(0.1092)
features.6.conv.0 tensor(0.0203)
features.6.conv.3 tensor(0.0475)
features.6.conv.6 tensor(0.0560)
features.7.conv.0 tensor(0.0455)
features.7.conv.3 tensor(0.1224)
features.7.conv.6 tensor(0.1478)
features.8.conv.0 tensor(0.0658)
features.8.conv.3 tensor(0.1227)
features.8.conv.6 tensor(0.1474)
features.9.conv.0 tensor(0.0995)
features.9.conv.3 tensor(0.1496)
features.9.conv.6 tensor(0.2250)
features.10.conv.0 tensor(0.0439)
features.10.conv.3 tensor(0.1004)
features.10.conv.6 tensor(0.1093)
features.11.conv.0 tensor(0.5956)
features.11.conv.3 tensor(0.1586)
features.11.conv.6 tensor(0.4639)
features.12.conv.0 tensor(0.1593)
features.12.conv.3 tensor(0.1599)
features.12.conv.6 tensor(0.6642)
features.13.conv.0 tensor(0.1198)
features.13.conv.3 tensor(0.1383)
features.13.conv.6 tensor(0.1842)
features.14.conv.0 tensor(0.9633)
features.14.conv.3 tensor(0.0851)
features.14.conv.6 tensor(0.9807)
features.15.conv.0 tensor(0.9058)
features.15.conv.3 tensor(0.0538)
features.15.conv.6 tensor(0.9793)
features.16.conv.0 tensor(0.1499)
features.16.conv.3 tensor(0.1102)
features.16.conv.6 tensor(0.2112)
conv.0 tensor(0.2349)
tensor(933507.) 2188896.0
0.77056336
0.77040178
0.77047670
0.77042055
0.77028334
0.77023494
0.77014679
0.77009815
0.77005410
0.77063227
0.77111030
0.77157366
0.77176279
0.77409798
0.77825356
INFO - Training [24][   20/  196]   Loss 0.383262   Top1 86.914062   Top5 98.105469   BatchTime 0.347856   LR 0.000500
0.77811062
0.77788037
0.77779239
0.77772623
0.77757275
0.77786988
0.77781075
0.77787304
0.77797598
0.77789581
0.77789003
0.77788001
0.77783799
0.77782845
0.77796149
0.77801883
0.77793789
0.77793282
0.77810705
0.77778155
0.77800614
0.77812374
0.77817243
0.77819967
0.77808195
0.77816576
INFO - Training [24][   40/  196]   Loss 0.379915   Top1 87.128906   Top5 98.349609   BatchTime 0.335661   LR 0.000484
0.77785885
0.77808201
0.77814078
0.77820230
0.77797484
0.77809960
0.77824837
0.77803969
0.77802610
0.77804273
0.77796727
0.77763832
0.77801007
0.77843934
0.78051037
0.78047538
INFO - Training [24][   60/  196]   Loss 0.382975   Top1 86.979167   Top5 98.417969   BatchTime 0.345907   LR 0.000468
0.78038371
0.78045219
0.78048027
0.78055036
0.78049308
0.78041750
0.78042883
0.78033501
0.78031892
0.78030330
0.78040290
0.78034163
0.78037977
0.78048515
0.78058821
0.78034687
0.78029609
0.78029138
0.78015107
0.78004152
0.77987337
0.77965844
INFO - Training [24][   80/  196]   Loss 0.385842   Top1 87.011719   Top5 98.476562   BatchTime 0.352179   LR 0.000453
0.77951205
0.77949351
0.77914268
0.77871472
0.77853757
0.77846694
0.77822185
0.77800125
0.77793396
0.77779239
0.77735192
0.77737564
0.77747810
0.77750432
0.77734601
0.77727562
0.77759266
0.77717555
0.77708489
0.77703625
0.77710104
INFO - Training [24][  100/  196]   Loss 0.381776   Top1 87.113281   Top5 98.496094   BatchTime 0.358081   LR 0.000437
0.77704090
0.77716488
0.77706599
0.77702576
0.77704632
0.77697128
0.77681977
0.77704442
0.77698666
0.77686083
0.77677780
0.77676827
0.77653134
0.77648407
0.77644998
0.77629071
0.77633500
0.77642608
0.77641547
0.77645719
0.77631110
INFO - Training [24][  120/  196]   Loss 0.379768   Top1 87.161458   Top5 98.600260   BatchTime 0.360697   LR 0.000422
0.77640229
0.77629125
0.77634239
0.77634275
0.77638239
0.77657098
0.77652717
0.77654445
0.77658063
0.77663636
0.77630198
0.77646792
0.77660948
0.77653086
0.77643925
0.77633840
0.77616823
0.77613878
INFO - Training [24][  140/  196]   Loss 0.378660   Top1 87.220982   Top5 98.663504   BatchTime 0.357741   LR 0.000407
0.77610701
0.77594823
0.77539444
0.77583659
0.77574074
0.77550739
0.77532905
0.77523279
0.77504927
0.77504140
0.77484280
0.77473503
0.77464730
0.77444094
0.77436876
0.77431124
0.77421242
0.77422649
0.77418596
0.77407849
0.77381665
0.77366537
INFO - Training [24][  160/  196]   Loss 0.380922   Top1 87.175293   Top5 98.664551   BatchTime 0.357811   LR 0.000392
0.77354610
0.77342683
0.77326941
0.77315450
0.77305889
0.77289808
0.77262092
0.77210832
0.77173615
0.77152663
0.77117252
0.77081162
0.77028638
0.76988387
0.76946539
0.76903301
0.76862705
INFO - Training [24][  180/  196]   Loss 0.381318   Top1 87.159288   Top5 98.626302   BatchTime 0.359255   LR 0.000378
0.76801628
0.76762414
0.76755428
0.76750565
0.76745415
0.76710385
0.76684058
0.76665854
0.76661479
0.76652426
0.76646096
0.76625317
0.76604038
0.76575726
0.76553822
0.76540422
INFO - ==> Top1: 87.226    Top5: 98.614    Loss: 0.380
0.76540715
0.76529503
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [24][   20/   40]   Loss 0.512014   Top1 83.984375   Top5 98.945312   BatchTime 0.123859
INFO - Validation [24][   40/   40]   Loss 0.505019   Top1 83.750000   Top5 99.110000   BatchTime 0.086178
features.0.conv.0 tensor(0.4549)
features.0.conv.3 tensor(0.3164)
features.1.conv.0 tensor(0.0267)
features.1.conv.3 tensor(0.0810)
features.1.conv.6 tensor(0.0577)
features.2.conv.0 tensor(0.0246)
features.2.conv.3 tensor(0.0556)
features.2.conv.6 tensor(0.0926)
features.3.conv.0 tensor(0.0200)
features.3.conv.3 tensor(0.0571)
features.3.conv.6 tensor(0.0447)
features.4.conv.0 tensor(0.0371)
features.4.conv.3 tensor(0.0891)
features.4.conv.6 tensor(0.0848)
features.5.conv.0 tensor(0.0301)
features.5.conv.3 tensor(0.0660)
features.5.conv.6 tensor(0.1226)
features.6.conv.0 tensor(0.0199)
features.6.conv.3 tensor(0.0475)
features.6.conv.6 tensor(0.0553)
features.7.conv.0 tensor(0.0479)
features.7.conv.3 tensor(0.1259)
features.7.conv.6 tensor(0.1476)
features.8.conv.0 tensor(0.0664)
features.8.conv.3 tensor(0.1221)
features.8.conv.6 tensor(0.1573)
features.9.conv.0 tensor(0.0983)
features.9.conv.3 tensor(0.1522)
features.9.conv.6 tensor(0.2441)
features.10.conv.0 tensor(0.0378)
features.10.conv.3 tensor(0.1019)
features.10.conv.6 tensor(0.1204)
features.11.conv.0 tensor(0.6007)
features.11.conv.3 tensor(0.1586)
features.11.conv.6 tensor(0.5228)
features.12.conv.0 tensor(0.1793)
features.12.conv.3 tensor(0.1580)
features.12.conv.6 tensor(0.6659)
features.13.conv.0 tensor(0.1198)
features.13.conv.3 tensor(0.1372)
features.13.conv.6 tensor(0.1957)
features.14.conv.0 tensor(0.9634)
features.14.conv.3 tensor(0.0848)
features.14.conv.6 tensor(0.9807)
features.15.conv.0 tensor(0.9081)
features.15.conv.3 tensor(0.0547)
features.15.conv.6 tensor(0.9762)
features.16.conv.0 tensor(0.1523)
features.16.conv.3 tensor(0.1103)
features.16.conv.6 tensor(0.2180)
conv.0 tensor(0.2387)
tensor(944214.) 2188896.0
INFO - ==> Top1: 83.750    Top5: 99.110    Loss: 0.505
INFO - ==> Sparsity : 0.431
INFO - Scoreboard best 1 ==> Epoch [22][Top1: 89.340   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [23][Top1: 89.290   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [21][Top1: 89.180   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
0.76514637
0.76514566
0.76507747
0.76495218
0.76493990
0.76489311
0.76485962
0.76486284
0.76487076
0.76487845
0.76487726
0.76490647
0.76491010
0.76480734
0.76465178
0.76449686
0.76449573
0.76443446
0.76428342
0.76411897
0.76387531
0.76380605
INFO - Training [25][   20/  196]   Loss 0.394906   Top1 86.542969   Top5 98.125000   BatchTime 0.400688   LR 0.000353
0.76385218
0.76391155
0.76380676
0.76378709
0.76378709
0.76373863
0.76375693
0.76377642
0.76374668
0.76377642
0.76377046
0.76370877
0.76370907
0.76372755
0.76373595
0.76375145
0.76383615
0.76398456
INFO - Training [25][   40/  196]   Loss 0.394408   Top1 86.640625   Top5 98.310547   BatchTime 0.365540   LR 0.000339
0.76407206
0.76442504
0.76498008
0.76528770
0.76542550
0.76558906
0.76731747
0.77126276
0.77115649
0.77101725
0.77125627
0.77145195
0.77150077
0.77159530
0.77177674
0.77147567
INFO - Training [25][   60/  196]   Loss 0.389723   Top1 86.751302   Top5 98.470052   BatchTime 0.364528   LR 0.000325
0.77145010
0.77145308
0.77138227
0.77130938
0.77132875
0.77143037
0.77160108
0.77157706
0.77165353
0.77141726
0.77126068
0.77137673
0.77135408
0.77125126
0.77114588
0.77104908
0.77118737
0.77137595
0.77122837
0.77153927
0.77143365
0.77148199
0.77132046
INFO - Training [25][   80/  196]   Loss 0.385309   Top1 86.860352   Top5 98.647461   BatchTime 0.364649   LR 0.000312
0.77123088
0.77117795
0.77116913
0.77118516
0.77114868
0.77133918
0.77131003
0.77107644
0.77116954
0.77111042
0.77105576
0.77106053
0.77098072
0.77097768
0.77106005
0.77107126
0.77112633
0.77074677
0.77104914
INFO - Training [25][  100/  196]   Loss 0.376369   Top1 87.304688   Top5 98.632812   BatchTime 0.372233   LR 0.000299
0.77090275
0.77094191
0.77094382
0.77094340
0.77104324
0.77106416
0.77109188
0.77108860
0.77103299
0.77117729
0.77114922
0.77109021
0.77077538
0.77085161
0.77093935
0.77079058
0.77054250
0.77051985
0.77066761
0.77065152
0.77050269
INFO - Training [25][  120/  196]   Loss 0.370804   Top1 87.539062   Top5 98.730469   BatchTime 0.373922   LR 0.000286
0.77022153
0.77010411
0.77023053
0.77000344
0.76983237
0.77002347
0.77021915
0.77027220
0.77023083
0.77021861
0.77017564
0.77014673
0.77005756
0.76997524
0.76994836
0.76990253
0.76990914
0.77006632
0.77003086
0.76991796
0.77012712
0.77031708
0.77004141
INFO - Training [25][  140/  196]   Loss 0.370195   Top1 87.600446   Top5 98.766741   BatchTime 0.371758   LR 0.000273
0.76990491
0.76969486
0.76972371
0.76982051
0.76906377
0.76939225
0.76953775
0.76912230
0.76829213
0.76783788
0.76760644
0.76755410
0.76742929
0.76734215
0.76718986
0.76698226
INFO - Training [25][  160/  196]   Loss 0.372400   Top1 87.529297   Top5 98.750000   BatchTime 0.370135   LR 0.000261
0.76681858
0.76656193
0.76636690
0.76612294
0.76587206
0.76563603
0.76542878
0.76498199
0.76457077
0.76437402
0.76422220
0.76411605
0.76395494
0.76373863
0.76341587
0.76302832
0.76269466
0.76250744
0.76236129
0.76223868
0.76214987
0.76206064
INFO - Training [25][  180/  196]   Loss 0.372500   Top1 87.519531   Top5 98.719618   BatchTime 0.369528   LR 0.000248
0.76198643
0.76190591
0.76185930
0.76179808
0.76177090
0.76168621
0.76162553
0.76158541
0.76157117
0.76152533
0.76148123
0.76150304
0.76152855
0.76143712
0.76131779
0.76126325
********************pre-trained*****************
INFO - ==> Top1: 87.632    Top5: 98.724    Loss: 0.369
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [25][   20/   40]   Loss 0.320490   Top1 89.531250   Top5 99.628906   BatchTime 0.137703
INFO - Validation [25][   40/   40]   Loss 0.306126   Top1 89.690000   Top5 99.690000   BatchTime 0.095473
INFO - ==> Top1: 89.690    Top5: 99.690    Loss: 0.306
INFO - ==> Sparsity : 0.431
INFO - Scoreboard best 1 ==> Epoch [25][Top1: 89.690   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [22][Top1: 89.340   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [23][Top1: 89.290   Top5: 99.700]
features.0.conv.0 tensor(0.4549)
features.0.conv.3 tensor(0.3184)
features.1.conv.0 tensor(0.0247)
features.1.conv.3 tensor(0.0880)
features.1.conv.6 tensor(0.0564)
features.2.conv.0 tensor(0.0237)
features.2.conv.3 tensor(0.0540)
features.2.conv.6 tensor(0.0903)
features.3.conv.0 tensor(0.0177)
features.3.conv.3 tensor(0.0571)
features.3.conv.6 tensor(0.0441)
features.4.conv.0 tensor(0.0355)
features.4.conv.3 tensor(0.0903)
features.4.conv.6 tensor(0.0845)
features.5.conv.0 tensor(0.0304)
features.5.conv.3 tensor(0.0671)
features.5.conv.6 tensor(0.1296)
features.6.conv.0 tensor(0.0234)
features.6.conv.3 tensor(0.0492)
features.6.conv.6 tensor(0.0561)
features.7.conv.0 tensor(0.0469)
features.7.conv.3 tensor(0.1238)
features.7.conv.6 tensor(0.1819)
features.8.conv.0 tensor(0.0712)
features.8.conv.3 tensor(0.1221)
features.8.conv.6 tensor(0.1725)
features.9.conv.0 tensor(0.0986)
features.9.conv.3 tensor(0.1534)
features.9.conv.6 tensor(0.2259)
features.10.conv.0 tensor(0.0358)
features.10.conv.3 tensor(0.1004)
features.10.conv.6 tensor(0.1189)
features.11.conv.0 tensor(0.6127)
features.11.conv.3 tensor(0.1586)
features.11.conv.6 tensor(0.4877)
features.12.conv.0 tensor(0.1939)
features.12.conv.3 tensor(0.1578)
features.12.conv.6 tensor(0.6689)
features.13.conv.0 tensor(0.1147)
features.13.conv.3 tensor(0.1373)
features.13.conv.6 tensor(0.2050)
features.14.conv.0 tensor(0.9634)
features.14.conv.3 tensor(0.0850)
features.14.conv.6 tensor(0.9810)
features.15.conv.0 tensor(0.9114)
features.15.conv.3 tensor(0.0543)
features.15.conv.6 tensor(0.9758)
features.16.conv.0 tensor(0.1549)
features.16.conv.3 tensor(0.1112)
features.16.conv.6 tensor(0.2104)
conv.0 tensor(0.2370)
tensor(943173.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
0.76115900
0.76108080
0.76091206
0.76065230
0.76059568
0.76050770
0.76038295
0.76024604
0.76014191
0.76004982
0.75991791
0.75982410
0.75974053
0.75961703
0.75941199
0.75930005
0.75912923
0.75900322
0.75886273
0.75871533
0.75855839
INFO - Training [26][   20/  196]   Loss 0.389204   Top1 86.601562   Top5 98.105469   BatchTime 0.369180   LR 0.000228
0.75841916
0.75843477
0.75830978
0.75839770
0.75838917
0.75840843
0.75832641
0.75829405
0.75824481
0.75810945
0.75800860
0.75781214
0.75768167
0.75773102
0.75778055
0.75770605
0.75755799
0.75746357
INFO - Training [26][   40/  196]   Loss 0.373596   Top1 87.080078   Top5 98.378906   BatchTime 0.348704   LR 0.000216
0.75745964
0.75740319
0.75736684
0.75731415
0.75726873
0.75724751
0.75716364
0.75712383
0.75713718
0.75714916
0.75714058
0.75713295
0.75713170
0.75722909
0.75736493
0.75749499
0.75746429
0.75745368
0.75740194
0.75738114
0.75733823
0.75732613
INFO - Training [26][   60/  196]   Loss 0.375026   Top1 87.369792   Top5 98.430990   BatchTime 0.355139   LR 0.000205
0.75731415
0.75730985
0.75728220
0.75722551
0.75717545
0.75727224
0.75721300
0.75725746
0.75725740
0.75715965
0.75708866
0.75696433
0.75688279
0.75688541
0.75684792
0.75683552
INFO - Training [26][   80/  196]   Loss 0.372858   Top1 87.485352   Top5 98.564453   BatchTime 0.359637   LR 0.000194
0.75684321
0.75683647
0.75680631
0.75678372
0.75674486
0.75673252
0.75673270
0.75672644
0.75676084
0.75676763
0.75673240
0.75670850
0.75673026
0.75674415
0.75678730
0.75681496
0.75685322
0.75686502
0.75690818
0.75695699
0.75700212
INFO - Training [26][  100/  196]   Loss 0.369016   Top1 87.511719   Top5 98.605469   BatchTime 0.364236   LR 0.000183
0.75698727
0.75697607
0.75696170
0.75697476
0.75696021
0.75695330
0.75696981
0.75698721
0.75701398
0.75696886
0.75691658
0.75690800
0.75687999
0.75683796
0.75683194
0.75681883
0.75681031
0.75682122
0.75678968
0.75674742
0.75676078
0.75672638
INFO - Training [26][  120/  196]   Loss 0.363409   Top1 87.740885   Top5 98.684896   BatchTime 0.364266   LR 0.000173
0.75671273
0.75672799
0.75670242
0.75665790
0.75662953
0.75662768
0.75658643
0.75653809
0.75649464
0.75647235
0.75646323
0.75644416
0.75640678
0.75637484
0.75633854
0.75632000
0.75628906
INFO - Training [26][  140/  196]   Loss 0.362509   Top1 87.773438   Top5 98.758371   BatchTime 0.364052   LR 0.000163
0.75621045
0.75615883
0.75615031
0.75615728
0.75610447
0.75605446
0.75604987
0.75607753
0.75606787
0.75605136
0.75601697
0.75602216
0.75601870
0.75596476
0.75592703
0.75588024
0.75582111
0.75576562
0.75568742
0.75564283
0.75552678
0.75544298
INFO - Training [26][  160/  196]   Loss 0.366196   Top1 87.670898   Top5 98.715820   BatchTime 0.362910   LR 0.000153
0.75533813
0.75527126
0.75515807
0.75505829
0.75496328
0.75490510
0.75483030
0.75477558
0.75473475
0.75465328
0.75457889
0.75453353
0.75447410
0.75439984
0.75438523
0.75436300
0.75434577
0.75431591
0.75430119
0.75427902
0.75423664
0.75418282
0.75414920
INFO - Training [26][  180/  196]   Loss 0.365851   Top1 87.682292   Top5 98.663194   BatchTime 0.362539   LR 0.000144
0.75411946
0.75409371
0.75405163
0.75397134
0.75391418
0.75382626
0.75383240
0.75374627
0.75369608
0.75366879
0.75363249
0.75365132
0.75363797
0.75364572
********************pre-trained*****************
INFO - ==> Top1: 87.718    Top5: 98.678    Loss: 0.365
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [26][   20/   40]   Loss 0.316284   Top1 89.667969   Top5 99.609375   BatchTime 0.130721
INFO - Validation [26][   40/   40]   Loss 0.300084   Top1 89.850000   Top5 99.680000   BatchTime 0.090955
INFO - ==> Top1: 89.850    Top5: 99.680    Loss: 0.300
INFO - ==> Sparsity : 0.444
INFO - Scoreboard best 1 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Scoreboard best 2 ==> Epoch [25][Top1: 89.690   Top5: 99.690]
INFO - Scoreboard best 3 ==> Epoch [22][Top1: 89.340   Top5: 99.700]
features.0.conv.0 tensor(0.4514)
features.0.conv.3 tensor(0.3281)
features.1.conv.0 tensor(0.0260)
features.1.conv.3 tensor(0.0880)
features.1.conv.6 tensor(0.0577)
features.2.conv.0 tensor(0.0263)
features.2.conv.3 tensor(0.0509)
features.2.conv.6 tensor(0.0897)
features.3.conv.0 tensor(0.0191)
features.3.conv.3 tensor(0.0563)
features.3.conv.6 tensor(0.0451)
features.4.conv.0 tensor(0.0369)
features.4.conv.3 tensor(0.0920)
features.4.conv.6 tensor(0.0846)
features.5.conv.0 tensor(0.0389)
features.5.conv.3 tensor(0.0677)
features.5.conv.6 tensor(0.1138)
features.6.conv.0 tensor(0.0257)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0566)
features.7.conv.0 tensor(0.0491)
features.7.conv.3 tensor(0.1247)
features.7.conv.6 tensor(0.1733)
features.8.conv.0 tensor(0.0701)
features.8.conv.3 tensor(0.1201)
features.8.conv.6 tensor(0.2141)
features.9.conv.0 tensor(0.1017)
features.9.conv.3 tensor(0.1505)
features.9.conv.6 tensor(0.2335)
features.10.conv.0 tensor(0.0362)
features.10.conv.3 tensor(0.1019)
features.10.conv.6 tensor(0.1174)
features.11.conv.0 tensor(0.6203)
features.11.conv.3 tensor(0.1574)
features.11.conv.6 tensor(0.4806)
features.12.conv.0 tensor(0.2024)
features.12.conv.3 tensor(0.1595)
features.12.conv.6 tensor(0.6848)
features.13.conv.0 tensor(0.1184)
features.13.conv.3 tensor(0.1362)
features.13.conv.6 tensor(0.2651)
features.14.conv.0 tensor(0.9636)
features.14.conv.3 tensor(0.0845)
features.14.conv.6 tensor(0.9811)
features.15.conv.0 tensor(0.9132)
features.15.conv.3 tensor(0.0550)
features.15.conv.6 tensor(0.9704)
features.16.conv.0 tensor(0.1562)
features.16.conv.3 tensor(0.1103)
features.16.conv.6 tensor(0.2417)
conv.0 tensor(0.2671)
tensor(972961.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
0.75366348
0.75368512
0.75369143
0.75369304
0.75366288
0.75362438
0.75358874
0.75354505
0.75348461
0.75342882
0.75342602
0.75341022
0.75332326
0.75327009
0.75314701
0.75305420
0.75297600
0.75287545
0.75278395
0.75271875
INFO - Training [27][   20/  196]   Loss 0.391811   Top1 86.816406   Top5 98.183594   BatchTime 0.424774   LR 0.000128
0.75267547
0.75261801
0.75253540
0.75246555
0.75244766
0.75239122
0.75235647
0.75230879
0.75227088
0.75227523
0.75227410
0.75225717
0.75224173
0.75219631
0.75220799
0.75218350
0.75218135
INFO - Training [27][   40/  196]   Loss 0.380734   Top1 87.080078   Top5 98.466797   BatchTime 0.390741   LR 0.000119
0.75219178
0.75218379
0.75221401
0.75224179
0.75230283
0.75233561
0.75233519
0.75234026
0.75236183
0.75237393
0.75235802
0.75237983
0.75242704
0.75247610
0.75244236
0.75252295
0.75256240
0.75258940
0.75264174
0.75268185
0.75268817
0.75273091
INFO - Training [27][   60/  196]   Loss 0.372656   Top1 87.382812   Top5 98.541667   BatchTime 0.386837   LR 0.000111
0.75273883
0.75275755
0.75273043
0.75272012
0.75267178
0.75264055
0.75256240
0.75248325
0.75241232
0.75231445
0.75225037
0.75219017
0.75210726
0.75206363
0.75197816
0.75195771
0.75193912
0.75193256
0.75193506
0.75190216
0.75188506
0.75186968
INFO - Training [27][   80/  196]   Loss 0.371476   Top1 87.451172   Top5 98.642578   BatchTime 0.380699   LR 0.000102
0.75181603
0.75175661
0.75167418
0.75160712
0.75156301
0.75147396
0.75143296
0.75141871
0.75140977
0.75138271
0.75133401
0.75128299
0.75125551
0.75123340
0.75122958
0.75122637
INFO - Training [27][  100/  196]   Loss 0.367359   Top1 87.554688   Top5 98.710938   BatchTime 0.377969   LR 0.000095
0.75120753
0.75118214
0.75115681
0.75114542
0.75112724
0.75109619
0.75104368
0.75099188
0.75091511
0.75085694
0.75079209
0.75075018
0.75070959
0.75064325
0.75061333
0.75059116
0.75053906
0.75049490
0.75041932
0.75033736
0.75026691
0.75018728
INFO - Training [27][  120/  196]   Loss 0.363891   Top1 87.685547   Top5 98.750000   BatchTime 0.375244   LR 0.000087
0.75014073
0.75006980
0.75001174
0.74998105
0.74992353
0.74989241
0.74984246
0.74978393
0.74977595
0.74976659
0.74978906
0.74982208
0.74982154
0.74983418
0.74982482
0.74980468
0.74976254
0.74972659
0.74969673
0.74968225
0.74965912
0.74962097
INFO - Training [27][  140/  196]   Loss 0.361134   Top1 87.834821   Top5 98.816964   BatchTime 0.372987   LR 0.000080
0.74959219
0.74951655
0.74946505
0.74944991
0.74940568
0.74934757
0.74930888
0.74925572
0.74922979
0.74920237
0.74918896
0.74919254
0.74922192
0.74921620
0.74920106
0.74918848
INFO - Training [27][  160/  196]   Loss 0.363728   Top1 87.739258   Top5 98.798828   BatchTime 0.373030   LR 0.000073
0.74915010
0.74912751
0.74912238
0.74911886
0.74911702
0.74912792
0.74910557
0.74909872
0.74910623
0.74910915
0.74912095
0.74913573
0.74911469
0.74913239
0.74913591
0.74909055
0.74904776
0.74902844
0.74902779
0.74904233
0.74906814
INFO - Training [27][  180/  196]   Loss 0.365264   Top1 87.671441   Top5 98.771701   BatchTime 0.374847   LR 0.000066
0.74904364
0.74905133
0.74903536
0.74899215
0.74899924
0.74901706
0.74902153
0.74902153
0.74902469
0.74901789
0.74902117
0.74903393
0.74903792
0.74906003
0.74908733
0.74908906
0.74908566
INFO - ==> Top1: 87.744    Top5: 98.770    Loss: 0.363
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.74907237
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [27][   20/   40]   Loss 0.301977   Top1 89.921875   Top5 99.492188   BatchTime 0.148886
INFO - Validation [27][   40/   40]   Loss 0.288559   Top1 90.230000   Top5 99.660000   BatchTime 0.100061
INFO - ==> Top1: 90.230    Top5: 99.660    Loss: 0.289
INFO - ==> Sparsity : 0.464
INFO - Scoreboard best 1 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Scoreboard best 3 ==> Epoch [25][Top1: 89.690   Top5: 99.690]
features.0.conv.0 tensor(0.4722)
features.0.conv.3 tensor(0.3418)
features.1.conv.0 tensor(0.0234)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0577)
features.2.conv.0 tensor(0.0258)
features.2.conv.3 tensor(0.0532)
features.2.conv.6 tensor(0.0903)
features.3.conv.0 tensor(0.0185)
features.3.conv.3 tensor(0.0563)
features.3.conv.6 tensor(0.0464)
features.4.conv.0 tensor(0.0410)
features.4.conv.3 tensor(0.0920)
features.4.conv.6 tensor(0.0845)
features.5.conv.0 tensor(0.0413)
features.5.conv.3 tensor(0.0700)
features.5.conv.6 tensor(0.1221)
features.6.conv.0 tensor(0.0249)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0566)
features.7.conv.0 tensor(0.0500)
features.7.conv.3 tensor(0.1236)
features.7.conv.6 tensor(0.1737)
features.8.conv.0 tensor(0.0694)
features.8.conv.3 tensor(0.1209)
features.8.conv.6 tensor(0.1976)
features.9.conv.0 tensor(0.1033)
features.9.conv.3 tensor(0.1531)
features.9.conv.6 tensor(0.2345)
features.10.conv.0 tensor(0.0359)
features.10.conv.3 tensor(0.1021)
features.10.conv.6 tensor(0.1240)
features.11.conv.0 tensor(0.6191)
features.11.conv.3 tensor(0.1574)
features.11.conv.6 tensor(0.4975)
features.12.conv.0 tensor(0.2118)
features.12.conv.3 tensor(0.1582)
features.12.conv.6 tensor(0.6977)
features.13.conv.0 tensor(0.1189)
features.13.conv.3 tensor(0.1358)
features.13.conv.6 tensor(0.2835)
features.14.conv.0 tensor(0.9635)
features.14.conv.3 tensor(0.0848)
features.14.conv.6 tensor(0.9810)
features.15.conv.0 tensor(0.9157)
features.15.conv.3 tensor(0.0541)
features.15.conv.6 tensor(0.9696)
features.16.conv.0 tensor(0.1570)
features.16.conv.3 tensor(0.1096)
features.16.conv.6 tensor(0.2916)
conv.0 tensor(0.3214)
tensor(1014722.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
0.74906403
0.74904668
0.74901545
0.74897200
0.74893713
0.74888766
0.74883062
0.74879211
0.74874914
0.74869120
0.74868160
0.74863482
0.74861294
0.74858475
0.74857140
0.74853778
0.74851722
0.74847847
0.74844974
0.74845552
0.74847358
INFO - Training [28][   20/  196]   Loss 0.373753   Top1 87.460938   Top5 98.183594   BatchTime 0.432486   LR 0.000055
0.74844998
0.74843693
0.74841070
0.74835771
0.74832129
0.74830383
0.74824417
0.74820524
0.74818385
0.74815434
0.74814063
0.74811208
0.74806672
0.74806213
0.74801534
0.74795061
INFO - Training [28][   40/  196]   Loss 0.373757   Top1 87.402344   Top5 98.417969   BatchTime 0.396293   LR 0.000050
0.74790949
0.74787349
0.74782449
0.74775934
0.74770600
0.74763316
0.74758607
0.74753523
0.74750566
0.74746144
0.74740946
0.74737287
0.74734974
0.74731958
0.74729282
0.74728841
0.74728382
0.74726093
0.74722940
0.74722064
0.74719262
0.74714774
INFO - Training [28][   60/  196]   Loss 0.363939   Top1 87.662760   Top5 98.574219   BatchTime 0.388234   LR 0.000044
0.74713135
0.74710071
0.74708045
0.74707377
0.74706709
0.74708861
0.74710643
0.74710071
0.74709648
0.74709022
0.74708784
0.74706179
0.74703836
0.74701267
0.74698716
0.74696797
0.74695140
0.74694479
0.74695539
0.74697590
0.74699819
0.74700487
INFO - Training [28][   80/  196]   Loss 0.361991   Top1 87.749023   Top5 98.691406   BatchTime 0.381213   LR 0.000039
0.74702483
0.74703574
0.74702740
0.74702311
0.74701476
0.74702036
0.74701118
0.74700695
0.74701697
0.74700624
0.74699491
0.74700147
0.74698603
0.74695915
0.74695355
0.74696165
0.74693996
INFO - Training [28][  100/  196]   Loss 0.357953   Top1 87.882812   Top5 98.714844   BatchTime 0.377778   LR 0.000034
0.74693066
0.74690706
0.74689883
0.74688703
0.74686384
0.74685502
0.74686068
0.74686062
0.74684739
0.74683040
0.74682754
0.74684048
0.74683297
0.74681312
0.74683416
0.74681777
0.74680465
0.74679935
0.74678040
0.74677205
0.74675524
0.74674839
INFO - Training [28][  120/  196]   Loss 0.351949   Top1 88.085938   Top5 98.772786   BatchTime 0.375938   LR 0.000030
0.74671102
0.74668556
0.74668419
0.74668139
0.74667972
0.74669987
0.74668235
0.74670136
0.74670380
0.74669600
0.74668998
0.74666226
0.74666011
0.74666071
0.74664342
0.74662316
0.74662298
0.74661559
0.74661744
0.74661535
0.74659729
INFO - Training [28][  140/  196]   Loss 0.351854   Top1 88.125000   Top5 98.805804   BatchTime 0.375006   LR 0.000026
0.74659538
0.74658442
0.74658537
0.74659109
0.74658483
0.74658811
0.74659842
0.74660122
0.74658608
0.74657416
0.74656510
0.74656975
0.74656451
0.74656707
0.74656653
0.74655777
0.74655300
0.74653882
INFO - Training [28][  160/  196]   Loss 0.357320   Top1 87.946777   Top5 98.781738   BatchTime 0.372150   LR 0.000022
0.74654317
0.74653435
0.74653453
0.74652594
0.74651909
0.74652487
0.74651366
0.74648368
0.74647868
0.74645376
0.74644113
0.74642539
0.74641228
0.74642485
0.74642217
0.74639899
0.74638832
0.74638176
0.74637371
0.74635363
0.74634588
INFO - Training [28][  180/  196]   Loss 0.358169   Top1 87.903646   Top5 98.713108   BatchTime 0.373294   LR 0.000018
0.74634010
0.74633372
0.74633557
0.74631810
0.74629146
0.74626911
0.74626654
0.74622715
0.74621522
0.74620324
0.74618495
0.74616379
0.74617171
0.74615580
0.74615532
0.74614990
INFO - ==> Top1: 87.972    Top5: 98.734    Loss: 0.356
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [28][   20/   40]   Loss 0.327957   Top1 89.316406   Top5 99.687500   BatchTime 0.123659
features.0.conv.0 tensor(0.4653)
features.0.conv.3 tensor(0.3418)
features.1.conv.0 tensor(0.0221)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0573)
features.2.conv.0 tensor(0.0263)
features.2.conv.3 tensor(0.0540)
features.2.conv.6 tensor(0.0903)
features.3.conv.0 tensor(0.0182)
features.3.conv.3 tensor(0.0556)
features.3.conv.6 tensor(0.0469)
features.4.conv.0 tensor(0.0417)
features.4.conv.3 tensor(0.0938)
features.4.conv.6 tensor(0.0840)
features.5.conv.0 tensor(0.0418)
features.5.conv.3 tensor(0.0700)
features.5.conv.6 tensor(0.1185)
features.6.conv.0 tensor(0.0252)
features.6.conv.3 tensor(0.0503)
features.6.conv.6 tensor(0.0570)
features.7.conv.0 tensor(0.0502)
features.7.conv.3 tensor(0.1247)
features.7.conv.6 tensor(0.1816)
features.8.conv.0 tensor(0.0693)
features.8.conv.3 tensor(0.1198)
features.8.conv.6 tensor(0.2010)
features.9.conv.0 tensor(0.1031)
features.9.conv.3 tensor(0.1528)
features.9.conv.6 tensor(0.2405)
features.10.conv.0 tensor(0.0358)
features.10.conv.3 tensor(0.1030)
features.10.conv.6 tensor(0.1194)
features.11.conv.0 tensor(0.6202)
features.11.conv.3 tensor(0.1572)
features.11.conv.6 tensor(0.5045)
features.12.conv.0 tensor(0.2142)
features.12.conv.3 tensor(0.1590)
features.12.conv.6 tensor(0.6984)
features.13.conv.0 tensor(0.1197)
features.13.conv.3 tensor(0.1368)
features.13.conv.6 tensor(0.3006)
features.14.conv.0 tensor(0.9634)
features.14.conv.3 tensor(0.0846)
features.14.conv.6 tensor(0.9810)
features.15.conv.0 tensor(0.9168)
features.15.conv.3 tensor(0.0538)
features.15.conv.6 tensor(0.9652)
features.16.conv.0 tensor(0.1571)
features.16.conv.3 tensor(0.1094)
features.16.conv.6 tensor(0.3276)
conv.0 tensor(0.3497)
tensor(1039348.) 2188896.0
INFO - Validation [28][   40/   40]   Loss 0.312042   Top1 89.480000   Top5 99.750000   BatchTime 0.090452
INFO - ==> Top1: 89.480    Top5: 99.750    Loss: 0.312
INFO - ==> Sparsity : 0.475
INFO - Scoreboard best 1 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 2 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Scoreboard best 3 ==> Epoch [25][Top1: 89.690   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
0.74614727
0.74611360
0.74611276
0.74611545
0.74609160
0.74608469
0.74607462
0.74606138
0.74603689
0.74601817
0.74603742
0.74602097
0.74601346
0.74600136
0.74600410
0.74598652
0.74597883
0.74597424
INFO - Training [29][   20/  196]   Loss 0.371729   Top1 87.343750   Top5 98.300781   BatchTime 0.448660   LR 0.000013
0.74597859
0.74595439
0.74593180
0.74591023
0.74590045
0.74588442
0.74587673
0.74587280
0.74585968
0.74586654
0.74586523
0.74585319
0.74583918
0.74581677
0.74580204
0.74579746
0.74577665
0.74576414
0.74576187
0.74575865
0.74574226
0.74570888
0.74569708
0.74568528
INFO - Training [29][   40/  196]   Loss 0.368446   Top1 87.275391   Top5 98.417969   BatchTime 0.394479   LR 0.000010
0.74568146
0.74567592
0.74566799
0.74565226
0.74565965
0.74565423
0.74563789
0.74563587
0.74562311
0.74561173
0.74560565
0.74559325
0.74559641
0.74559361
0.74557322
0.74557239
0.74558407
INFO - Training [29][   60/  196]   Loss 0.363390   Top1 87.519531   Top5 98.561198   BatchTime 0.378998   LR 0.000008
0.74558091
0.74556828
0.74556094
0.74554497
0.74553370
0.74552113
0.74553043
0.74551940
0.74551368
0.74550456
0.74549758
0.74548602
0.74548751
0.74548715
0.74547184
0.74548286
0.74547607
0.74548352
0.74547642
0.74546140
0.74545151
0.74545377
0.74546045
0.74545151
INFO - Training [29][   80/  196]   Loss 0.355201   Top1 87.890625   Top5 98.671875   BatchTime 0.368308   LR 0.000005
0.74544036
0.74542928
0.74542719
0.74542493
0.74543065
0.74543786
0.74542505
0.74542171
0.74541360
0.74542797
0.74543661
0.74544513
0.74543595
0.74543649
0.74545681
0.74544489
0.74545640
INFO - Training [29][  100/  196]   Loss 0.350280   Top1 88.089844   Top5 98.750000   BatchTime 0.363341   LR 0.000004
0.74544036
0.74543136
0.74542767
0.74543494
0.74541765
0.74540836
0.74540401
0.74541146
0.74541312
0.74541551
0.74540204
0.74541169
0.74541724
0.74542576
0.74543667
0.74541265
0.74541563
INFO - Training [29][  120/  196]   Loss 0.345654   Top1 88.248698   Top5 98.776042   BatchTime 0.361036   LR 0.000002
0.74541187
0.74539971
0.74540144
0.74539477
0.74542958
0.74541909
0.74541414
0.74540669
0.74540144
0.74540234
0.74540097
0.74540734
0.74541146
0.74541026
0.74540764
0.74541318
0.74539846
0.74539196
0.74538982
0.74539471
0.74539530
0.74539357
0.74538702
INFO - Training [29][  140/  196]   Loss 0.345133   Top1 88.300781   Top5 98.830915   BatchTime 0.359262   LR 0.000001
0.74538052
0.74539429
0.74540454
0.74541146
0.74541193
0.74541968
0.74541754
0.74539793
0.74539423
0.74539262
0.74538136
0.74538815
0.74538243
0.74539500
0.74537891
0.74538004
0.74538219
0.74536490
INFO - Training [29][  160/  196]   Loss 0.349629   Top1 88.093262   Top5 98.803711   BatchTime 0.356530   LR 0.000001
0.74535900
0.74534661
0.74534416
0.74533325
0.74533230
0.74535090
0.74535179
0.74535012
0.74536121
0.74535805
0.74535751
0.74536556
0.74536246
0.74535203
0.74535012
0.74536061
0.74537337
0.74536550
0.74536133
0.74535745
0.74536043
0.74535090
INFO - Training [29][  180/  196]   Loss 0.350950   Top1 88.040365   Top5 98.730469   BatchTime 0.357217   LR 0.000000
0.74533045
0.74532497
0.74530828
0.74531049
0.74531364
0.74531329
0.74532181
0.74532443
0.74531376
0.74530947
0.74530894
0.74530274
0.74530435
0.74530584
0.74531859
0.74532944
INFO - ==> Top1: 88.090    Top5: 98.750    Loss: 0.350
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [29][   20/   40]   Loss 0.314652   Top1 89.921875   Top5 99.667969   BatchTime 0.121054
features.0.conv.0 tensor(0.4757)
features.0.conv.3 tensor(0.3418)
features.1.conv.0 tensor(0.0221)
features.1.conv.3 tensor(0.0891)
features.1.conv.6 tensor(0.0573)
features.2.conv.0 tensor(0.0260)
features.2.conv.3 tensor(0.0540)
features.2.conv.6 tensor(0.0897)
features.3.conv.0 tensor(0.0182)
features.3.conv.3 tensor(0.0556)
features.3.conv.6 tensor(0.0460)
features.4.conv.0 tensor(0.0415)
features.4.conv.3 tensor(0.0926)
features.4.conv.6 tensor(0.0848)
features.5.conv.0 tensor(0.0418)
features.5.conv.3 tensor(0.0700)
features.5.conv.6 tensor(0.1195)
features.6.conv.0 tensor(0.0254)
features.6.conv.3 tensor(0.0492)
features.6.conv.6 tensor(0.0567)
features.7.conv.0 tensor(0.0501)
features.7.conv.3 tensor(0.1238)
features.7.conv.6 tensor(0.1820)
features.8.conv.0 tensor(0.0695)
features.8.conv.3 tensor(0.1198)
features.8.conv.6 tensor(0.2006)
features.9.conv.0 tensor(0.1028)
features.9.conv.3 tensor(0.1516)
features.9.conv.6 tensor(0.2404)
features.10.conv.0 tensor(0.0357)
features.10.conv.3 tensor(0.1030)
features.10.conv.6 tensor(0.1191)
features.11.conv.0 tensor(0.6205)
features.11.conv.3 tensor(0.1576)
features.11.conv.6 tensor(0.5060)
features.12.conv.0 tensor(0.2148)
features.12.conv.3 tensor(0.1593)
features.12.conv.6 tensor(0.6994)
features.13.conv.0 tensor(0.1194)
features.13.conv.3 tensor(0.1366)
features.13.conv.6 tensor(0.3029)
features.14.conv.0 tensor(0.9635)
features.14.conv.3 tensor(0.0845)
features.14.conv.6 tensor(0.9810)
features.15.conv.0 tensor(0.9170)
features.15.conv.3 tensor(0.0539)
features.15.conv.6 tensor(0.9665)
features.16.conv.0 tensor(0.1572)
features.16.conv.3 tensor(0.1100)
features.16.conv.6 tensor(0.3377)
conv.0 tensor(0.3590)
tensor(1046838.) 2188896.0
INFO - Validation [29][   40/   40]   Loss 0.295264   Top1 90.250000   Top5 99.740000   BatchTime 0.090656
INFO - ==> Top1: 90.250    Top5: 99.740    Loss: 0.295
INFO - ==> Sparsity : 0.478
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
0.74530178
0.74647593
0.74463499
0.74362499
0.74135709
0.74125230
0.74235463
0.74194908
0.73989153
0.73917300
0.74415374
0.74396902
0.74592906
0.74598795
0.74498361
0.74500209
0.74421108
INFO - Training [30][   20/  196]   Loss 0.381658   Top1 86.640625   Top5 98.183594   BatchTime 0.465666   LR 0.001250
0.74135423
0.74053878
0.74138659
0.74178386
0.74130052
0.75322330
0.75402081
0.75688875
0.76244104
0.76396853
0.76542348
0.76597810
0.76830447
0.76938981
0.76966894
0.77003324
0.77043766
0.77476001
0.77800018
0.77834767
0.77890933
INFO - Training [30][   40/  196]   Loss 0.396267   Top1 86.298828   Top5 98.339844   BatchTime 0.427506   LR 0.001250
0.77911478
0.77991724
0.78077990
0.78157371
0.78241944
0.78343636
0.78463191
0.78592968
0.79258895
0.79234916
0.79221243
0.79257929
0.79318255
0.79317325
0.79305786
0.79334831
0.79343176
0.79358917
0.79369658
0.79389721
0.79402596
INFO - Training [30][   60/  196]   Loss 0.403857   Top1 86.145833   Top5 98.339844   BatchTime 0.408753   LR 0.001250
0.79795331
0.79780602
0.79789621
0.79788500
0.79792178
0.79801327
0.79815888
0.79841542
0.79851204
0.79832327
0.79801649
0.79803729
0.79808384
0.79811430
0.79800731
0.79795396
0.79788429
0.79787010
0.79770619
0.79752421
0.79736865
0.79737139
INFO - Training [30][   80/  196]   Loss 0.406226   Top1 86.162109   Top5 98.457031   BatchTime 0.396919   LR 0.001250
0.79754680
0.79701203
0.79687101
0.79666597
0.79661334
0.79641956
0.79617500
0.79610431
0.79607403
0.79628241
0.79568988
0.79568821
0.79544324
0.79520249
0.79508680
0.79491490
0.79482996
INFO - Training [30][  100/  196]   Loss 0.403249   Top1 86.250000   Top5 98.507812   BatchTime 0.390984   LR 0.001250
0.79470581
0.79457241
0.79445785
0.79449362
0.79459864
0.79424757
0.79430556
0.79416770
0.79410613
0.79401267
0.79391772
0.79394048
0.79407424
0.79425490
0.79425377
0.79427081
0.79438424
0.79417837
0.79419404
0.79424453
0.79407364
0.79421902
INFO - Training [30][  120/  196]   Loss 0.398007   Top1 86.481120   Top5 98.597005   BatchTime 0.385493   LR 0.001249
0.79383928
0.79345644
0.79347044
0.79348260
0.79348940
0.79351473
0.79340041
0.79334557
0.79314661
0.79310089
0.79279476
0.79254043
0.79232842
0.79239327
0.79252076
0.79283482
0.79270899
0.79292530
INFO - Training [30][  140/  196]   Loss 0.394940   Top1 86.640625   Top5 98.660714   BatchTime 0.379072   LR 0.001249
0.79332519
0.79367369
0.79374927
0.79374003
0.79364371
0.79380882
0.79398358
0.79399931
0.79402393
0.79418409
0.79406965
0.79388124
0.79347610
0.79367089
0.79333353
0.79328734
0.79327983
0.79283196
0.79260445
0.79236770
0.79195672
INFO - Training [30][  160/  196]   Loss 0.397609   Top1 86.564941   Top5 98.652344   BatchTime 0.378918   LR 0.001249
0.79209048
0.79213119
0.79182917
0.79141909
0.79109764
0.79091978
0.79056829
0.79020363
0.78978121
0.78959352
0.78905934
0.78876632
0.78819245
0.78774703
0.78700882
0.78647673
0.78612375
0.78571010
0.78512949
0.78487927
0.78408247
0.78335071
INFO - Training [30][  180/  196]   Loss 0.400381   Top1 86.512587   Top5 98.572049   BatchTime 0.377622   LR 0.001248
0.78177893
0.78059256
0.77901173
0.77753031
0.77569884
0.77551800
0.77540433
0.77399176
0.77454686
0.77797663
0.77913815
0.77818030
0.77545446
0.77427846
0.77307677
INFO - ==> Top1: 86.474    Top5: 98.574    Loss: 0.400
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 0.329872   Top1 88.964844   Top5 99.511719   BatchTime 0.148064
INFO - Validation [30][   40/   40]   Loss 0.316423   Top1 89.200000   Top5 99.640000   BatchTime 0.134237
features.0.conv.0 tensor(0.4757)
features.0.conv.3 tensor(0.3281)
features.1.conv.0 tensor(0.0215)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0582)
features.2.conv.0 tensor(0.0220)
features.2.conv.3 tensor(0.0509)
features.2.conv.6 tensor(0.0903)
features.3.conv.0 tensor(0.0156)
features.3.conv.3 tensor(0.0540)
features.3.conv.6 tensor(0.0414)
features.4.conv.0 tensor(0.0265)
features.4.conv.3 tensor(0.0938)
features.4.conv.6 tensor(0.0856)
features.5.conv.0 tensor(0.0257)
features.5.conv.3 tensor(0.0689)
features.5.conv.6 tensor(0.1774)
features.6.conv.0 tensor(0.0243)
features.6.conv.3 tensor(0.0457)
features.6.conv.6 tensor(0.0558)
features.7.conv.0 tensor(0.0503)
features.7.conv.3 tensor(0.1247)
features.7.conv.6 tensor(0.1578)
features.8.conv.0 tensor(0.0612)
features.8.conv.3 tensor(0.1169)
features.8.conv.6 tensor(0.1160)
features.9.conv.0 tensor(0.0908)
features.9.conv.3 tensor(0.1531)
features.9.conv.6 tensor(0.1125)
features.10.conv.0 tensor(0.0311)
features.10.conv.3 tensor(0.1050)
features.10.conv.6 tensor(0.0782)
features.11.conv.0 tensor(0.5865)
features.11.conv.3 tensor(0.1524)
features.11.conv.6 tensor(0.4319)
features.12.conv.0 tensor(0.2453)
features.12.conv.3 tensor(0.1593)
features.12.conv.6 tensor(0.6589)
features.13.conv.0 tensor(0.1124)
features.13.conv.3 tensor(0.1375)
features.13.conv.6 tensor(0.0771)
features.14.conv.0 tensor(0.9646)
features.14.conv.3 tensor(0.0861)
features.14.conv.6 tensor(0.9812)
features.15.conv.0 tensor(0.9134)
features.15.conv.3 tensor(0.0583)
features.15.conv.6 tensor(0.9809)
features.16.conv.0 tensor(0.1507)
features.16.conv.3 tensor(0.1128)
features.16.conv.6 tensor(0.6693)
conv.0 tensor(0.1129)
tensor(1013330.) 2188896.0
INFO - ==> Top1: 89.200    Top5: 99.640    Loss: 0.316
INFO - ==> Sparsity : 0.463
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
0.77132171
0.76956314
0.76991999
0.77241391
0.77698392
0.78114003
0.78384513
0.78596103
0.78853065
0.78837627
0.78817075
0.78809357
0.78851587
0.78838122
0.78829408
0.78805083
0.78795177
0.78783232
0.78750163
0.78718603
INFO - Training [31][   20/  196]   Loss 0.407890   Top1 85.937500   Top5 98.164062   BatchTime 0.443001   LR 0.001248
0.78691405
0.78645730
0.78626609
0.78617835
0.79044986
0.78990680
0.78938204
0.78863144
0.78808242
0.78767765
0.78715700
0.78656518
0.78602654
0.78541440
0.78496718
0.78419328
0.78372651
0.78313035
0.78251225
0.78196019
0.78118980
0.78038007
INFO - Training [31][   40/  196]   Loss 0.412186   Top1 85.849609   Top5 98.291016   BatchTime 0.396478   LR 0.001247
0.78025246
0.78011096
0.77961022
0.77919143
0.77884591
0.77875805
0.77834600
0.77808470
0.77778548
0.77704579
0.77600718
0.77526385
0.77408677
0.77279180
0.77055758
0.76704830
0.76304728
INFO - Training [31][   60/  196]   Loss 0.414586   Top1 85.735677   Top5 98.385417   BatchTime 0.385949   LR 0.001247
0.76072043
0.75857693
0.75666136
0.75381482
0.75158703
0.74998963
0.74955219
0.75004345
0.75150865
0.75035107
0.75116765
0.75203091
0.75460064
0.75742948
0.75987071
0.76283622
0.76542759
0.76796812
0.77015334
0.77182740
0.77334148
0.77432835
INFO - Training [31][   80/  196]   Loss 0.417337   Top1 85.732422   Top5 98.422852   BatchTime 0.382226   LR 0.001246
0.77526319
0.77632195
0.77672333
0.77678579
0.77660227
0.77809352
0.77988672
0.78184295
0.78196716
0.78183419
0.78176165
0.78167927
0.78157020
0.78170341
0.78157234
0.78161865
0.78153378
0.78074580
0.78018516
0.77964735
0.77942961
INFO - Training [31][  100/  196]   Loss 0.417911   Top1 85.703125   Top5 98.457031   BatchTime 0.379778   LR 0.001246
0.77887529
0.77849734
0.77853203
0.77869779
0.77884787
0.77950388
0.78015482
0.78081608
0.78135771
0.78166801
0.78223485
0.78308338
0.78371239
0.78435987
0.78490794
0.78540188
0.78606272
INFO - Training [31][  120/  196]   Loss 0.410683   Top1 85.983073   Top5 98.509115   BatchTime 0.376902   LR 0.001245
0.79042417
0.79024124
0.79003346
0.78971720
0.78969359
0.78996778
0.78993964
0.78946418
0.78892392
0.78882837
0.78917539
0.78907615
0.78925014
0.78941214
0.78941345
0.78958392
0.78990668
0.79022372
0.79065377
0.79081374
0.79119968
0.79150736
INFO - Training [31][  140/  196]   Loss 0.408807   Top1 86.138393   Top5 98.590960   BatchTime 0.373941   LR 0.001244
0.79217517
0.79234552
0.79231983
0.79254097
0.79281437
0.79289192
0.79288429
0.79315478
0.79319638
0.79313236
0.79622614
0.79576105
0.79550028
0.79488629
0.79456657
0.79557329
0.79504627
0.79460347
0.79451954
0.79387170
0.79330581
INFO - Training [31][  160/  196]   Loss 0.412756   Top1 86.064453   Top5 98.593750   BatchTime 0.374211   LR 0.001244
0.79315150
0.79281455
0.79211938
0.79181546
0.79146039
0.79115307
0.79093796
0.79075867
0.79041499
0.79022866
0.78984225
0.78889531
0.78808969
0.78788978
0.78768337
INFO - Training [31][  180/  196]   Loss 0.413212   Top1 86.072049   Top5 98.552517   BatchTime 0.376733   LR 0.001243
0.78719670
0.78686321
0.78665459
0.78659463
0.78668308
0.78662360
0.78680217
0.78699797
0.78723413
0.78764600
0.78811145
0.78849447
0.79059350
0.79108715
0.79096574
0.79104829
0.79120827
INFO - ==> Top1: 86.056    Top5: 98.568    Loss: 0.414
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.79123724
0.79103887
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [31][   20/   40]   Loss 0.354109   Top1 88.750000   Top5 99.453125   BatchTime 0.197059
INFO - Validation [31][   40/   40]   Loss 0.342340   Top1 88.860000   Top5 99.620000   BatchTime 0.122867
features.0.conv.0 tensor(0.4306)
features.0.conv.3 tensor(0.3203)
features.1.conv.0 tensor(0.0247)
features.1.conv.3 tensor(0.0764)
features.1.conv.6 tensor(0.0612)
features.2.conv.0 tensor(0.0229)
features.2.conv.3 tensor(0.0579)
features.2.conv.6 tensor(0.0906)
features.3.conv.0 tensor(0.0162)
features.3.conv.3 tensor(0.0571)
features.3.conv.6 tensor(0.0432)
features.4.conv.0 tensor(0.0249)
features.4.conv.3 tensor(0.1001)
features.4.conv.6 tensor(0.0835)
features.5.conv.0 tensor(0.0290)
features.5.conv.3 tensor(0.0723)
features.5.conv.6 tensor(0.1152)
features.6.conv.0 tensor(0.0321)
features.6.conv.3 tensor(0.0492)
features.6.conv.6 tensor(0.0547)
features.7.conv.0 tensor(0.0439)
features.7.conv.3 tensor(0.1256)
features.7.conv.6 tensor(0.1328)
features.8.conv.0 tensor(0.0663)
features.8.conv.3 tensor(0.1207)
features.8.conv.6 tensor(0.1182)
features.9.conv.0 tensor(0.0928)
features.9.conv.3 tensor(0.1496)
features.9.conv.6 tensor(0.1333)
features.10.conv.0 tensor(0.0324)
features.10.conv.3 tensor(0.1021)
features.10.conv.6 tensor(0.0915)
features.11.conv.0 tensor(0.4995)
features.11.conv.3 tensor(0.1530)
features.11.conv.6 tensor(0.4838)
features.12.conv.0 tensor(0.2583)
features.12.conv.3 tensor(0.1611)
features.12.conv.6 tensor(0.6530)
features.13.conv.0 tensor(0.0996)
features.13.conv.3 tensor(0.1393)
features.13.conv.6 tensor(0.0823)
features.14.conv.0 tensor(0.9651)
features.14.conv.3 tensor(0.0828)
features.14.conv.6 tensor(0.9815)
features.15.conv.0 tensor(0.9157)
features.15.conv.3 tensor(0.0567)
features.15.conv.6 tensor(0.9812)
features.16.conv.0 tensor(0.1494)
features.16.conv.3 tensor(0.1130)
features.16.conv.6 tensor(0.2909)
conv.0 tensor(0.1144)
tensor(896348.) 2188896.0
INFO - ==> Top1: 88.860    Top5: 99.620    Loss: 0.342
INFO - ==> Sparsity : 0.409
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
0.79073435
0.79057157
0.79026079
0.79002231
0.78975284
0.78975415
0.78981578
0.78999317
0.79108834
0.79184687
0.79170275
0.79154074
0.79119223
0.79074192
0.79043603
0.78994191
0.78919715
0.78853428
0.78837204
0.78779453
INFO - Training [32][   20/  196]   Loss 0.423531   Top1 84.707031   Top5 97.890625   BatchTime 0.438290   LR 0.001242
0.78769797
0.78828871
0.78882575
0.78902853
0.78873378
0.78881747
0.78976607
0.79032272
0.79064673
0.79064721
0.79070282
0.79089803
0.79122788
0.79169756
0.79202664
0.79243904
0.79244715
0.79387432
0.79362845
0.79315895
0.79291457
0.79279494
INFO - Training [32][   40/  196]   Loss 0.431136   Top1 84.990234   Top5 98.134766   BatchTime 0.397754   LR 0.001241
0.79240960
0.79187161
0.79154950
0.79132539
0.79094177
0.79075813
0.79042035
0.79023892
0.78991652
0.78944361
0.78894401
0.78845394
0.78774565
0.78724402
0.78674191
0.78633231
0.78570044
INFO - Training [32][   60/  196]   Loss 0.423660   Top1 85.292969   Top5 98.242188   BatchTime 0.383072   LR 0.001240
0.78507340
0.78370172
0.78270525
0.78140247
0.78092575
0.78063583
0.78082925
0.78087831
0.78074461
0.78081667
0.78070027
0.78119773
0.78192836
0.78228366
0.78239352
0.78239256
0.78219253
0.78222328
0.78214312
0.78218895
0.78225923
0.78228557
INFO - Training [32][   80/  196]   Loss 0.419629   Top1 85.532227   Top5 98.315430   BatchTime 0.379112   LR 0.001239
0.78228223
0.78218436
0.78209841
0.78178132
0.78153127
0.78123754
0.78060877
0.78005254
0.77918911
0.77847534
0.77771783
0.77745271
0.77739096
0.77731919
0.77708983
0.77715135
0.77715498
INFO - Training [32][  100/  196]   Loss 0.409559   Top1 85.906250   Top5 98.382812   BatchTime 0.373085   LR 0.001238
0.77706873
0.77705932
0.77713823
0.77691978
0.77674061
0.77670598
0.77675247
0.77739298
0.77861840
0.77863592
0.77893603
0.77961284
0.78024912
0.78040439
0.78499025
0.78885680
0.78852475
0.78839374
0.78797692
0.78765160
0.78757262
0.78714526
0.78687245
INFO - Training [32][  120/  196]   Loss 0.404863   Top1 86.110026   Top5 98.489583   BatchTime 0.371070   LR 0.001237
0.78663141
0.78651774
0.78616416
0.78570259
0.78546733
0.78502053
0.78464240
0.78443182
0.78431851
0.78421605
0.78428769
0.78410929
0.78542972
0.78831750
0.78838748
0.78951931
0.78902972
INFO - Training [32][  140/  196]   Loss 0.404174   Top1 86.261161   Top5 98.537946   BatchTime 0.368229   LR 0.001236
0.78885078
0.78871310
0.78829437
0.78800464
0.78794682
0.78772998
0.78759104
0.78769827
0.78768975
0.78757542
0.78755438
0.78749198
0.78736657
0.78743440
0.78760958
0.78780133
0.78792459
0.78821152
0.78849870
0.78864938
INFO - Training [32][  160/  196]   Loss 0.404550   Top1 86.218262   Top5 98.518066   BatchTime 0.371047   LR 0.001235
0.78843307
0.78818613
0.78802943
0.78798521
0.78791636
0.78778756
0.78751779
0.78746593
0.78751510
0.78764379
0.78742105
0.78757566
0.78735310
0.78714275
0.78723109
0.78724200
0.78714865
0.78712749
0.78701729
0.78703076
0.78665143
INFO - Training [32][  180/  196]   Loss 0.404119   Top1 86.208767   Top5 98.463542   BatchTime 0.374109   LR 0.001234
0.78679544
0.78656173
0.78639376
0.78636438
0.78641438
0.78630114
0.78619903
0.78616053
0.78618765
0.78612667
0.78655249
0.78635025
0.78636026
0.78620028
0.78593624
INFO - ==> Top1: 86.208    Top5: 98.446    Loss: 0.404
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.78564119
0.78569180
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 0.424541   Top1 86.328125   Top5 99.355469   BatchTime 0.199195
INFO - Validation [32][   40/   40]   Loss 0.419861   Top1 86.410000   Top5 99.420000   BatchTime 0.123965
features.0.conv.0 tensor(0.4444)
features.0.conv.3 tensor(0.3164)
features.1.conv.0 tensor(0.0221)
features.1.conv.3 tensor(0.0810)
features.1.conv.6 tensor(0.0538)
features.2.conv.0 tensor(0.0286)
features.2.conv.3 tensor(0.0540)
features.2.conv.6 tensor(0.0897)
features.3.conv.0 tensor(0.0168)
features.3.conv.3 tensor(0.0502)
features.3.conv.6 tensor(0.0373)
features.4.conv.0 tensor(0.0329)
features.4.conv.3 tensor(0.1024)
features.4.conv.6 tensor(0.0851)
features.5.conv.0 tensor(0.0396)
features.5.conv.3 tensor(0.0654)
features.5.conv.6 tensor(0.1144)
features.6.conv.0 tensor(0.0298)
features.6.conv.3 tensor(0.0463)
features.6.conv.6 tensor(0.0531)
features.7.conv.0 tensor(0.0491)
features.7.conv.3 tensor(0.1250)
features.7.conv.6 tensor(0.1350)
features.8.conv.0 tensor(0.0707)
features.8.conv.3 tensor(0.1183)
features.8.conv.6 tensor(0.1209)
features.9.conv.0 tensor(0.0883)
features.9.conv.3 tensor(0.1525)
features.9.conv.6 tensor(0.1657)
features.10.conv.0 tensor(0.0381)
features.10.conv.3 tensor(0.0969)
features.10.conv.6 tensor(0.0695)
features.11.conv.0 tensor(0.4904)
features.11.conv.3 tensor(0.1557)
features.11.conv.6 tensor(0.5144)
features.12.conv.0 tensor(0.2854)
features.12.conv.3 tensor(0.1630)
features.12.conv.6 tensor(0.6596)
features.13.conv.0 tensor(0.1066)
features.13.conv.3 tensor(0.1387)
features.13.conv.6 tensor(0.0881)
features.14.conv.0 tensor(0.9621)
features.14.conv.3 tensor(0.0851)
features.14.conv.6 tensor(0.9815)
features.15.conv.0 tensor(0.9202)
features.15.conv.3 tensor(0.0575)
features.15.conv.6 tensor(0.9820)
features.16.conv.0 tensor(0.1605)
features.16.conv.3 tensor(0.1157)
features.16.conv.6 tensor(0.2492)
conv.0 tensor(0.1260)
tensor(894827.) 2188896.0
INFO - ==> Top1: 86.410    Top5: 99.420    Loss: 0.420
INFO - ==> Sparsity : 0.409
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
0.78552264
0.78584605
0.78793341
0.78935075
0.78887588
0.78840256
0.78831917
0.78859079
0.78851187
0.78866553
0.78846914
0.78888917
0.79021531
0.78994793
0.78945798
0.78930867
0.78897643
0.78796321
0.78766608
0.78699952
INFO - Training [33][   20/  196]   Loss 0.416247   Top1 86.171875   Top5 98.066406   BatchTime 0.435512   LR 0.001232
0.78711337
0.78675514
0.78649801
0.78573656
0.78506029
0.78402370
0.78267145
0.78113067
0.78205013
0.78549027
0.78774887
0.79002416
0.79201263
0.79455543
0.79471141
0.79465628
0.79455823
0.79428083
0.79424322
0.79410559
0.79399937
INFO - Training [33][   40/  196]   Loss 0.417619   Top1 86.201172   Top5 98.193359   BatchTime 0.400284   LR 0.001230
0.79384339
0.79385883
0.79360175
0.79350013
0.79358429
0.79332674
0.79329115
0.79314816
0.79302090
0.79284072
0.79291582
0.79278481
0.79265666
0.79254383
0.79243904
0.79233944
0.79225016
INFO - Training [33][   60/  196]   Loss 0.416610   Top1 86.223958   Top5 98.339844   BatchTime 0.388909   LR 0.001229
0.79223448
0.79205728
0.79190844
0.79191011
0.79167390
0.79158401
0.79146117
0.79280889
0.79286015
0.79245323
0.79212284
0.79184878
0.79146284
0.79102987
0.79064173
0.79019469
0.79002827
0.78957266
0.78937083
0.78914607
INFO - Training [33][   80/  196]   Loss 0.411676   Top1 86.425781   Top5 98.403320   BatchTime 0.392131   LR 0.001228
0.78876102
0.78832740
0.78803051
0.78789252
0.78761429
0.78732193
0.78707892
0.78686893
0.78657866
0.78615165
0.78583705
0.78551489
0.78502959
0.78474206
0.78419954
0.78378242
0.78343821
0.78303540
0.78279197
0.78251702
0.78263229
INFO - Training [33][  100/  196]   Loss 0.407609   Top1 86.535156   Top5 98.453125   BatchTime 0.389722   LR 0.001226
0.78277642
0.78298610
0.78296489
0.78284210
0.78292042
0.78302020
0.78274268
0.78255427
0.78238130
0.78207928
0.78209776
0.78205299
0.78201085
0.78325808
0.78250211
0.78265345
0.78238767
0.78215557
0.78199434
0.78174305
0.78142542
INFO - Training [33][  120/  196]   Loss 0.402745   Top1 86.702474   Top5 98.554688   BatchTime 0.387990   LR 0.001225
0.78134024
0.78096682
0.78097826
0.78045064
0.77990055
0.77940977
0.77865231
0.77824652
0.77821261
0.77779967
0.77747381
0.77751023
0.77688801
0.77655321
0.77659833
0.77641505
0.77619517
0.77569246
0.77581352
0.77580082
0.77569634
0.77562654
INFO - Training [33][  140/  196]   Loss 0.400023   Top1 86.788504   Top5 98.613281   BatchTime 0.385829   LR 0.001224
0.77531689
0.77486229
0.77436095
0.77382636
0.77342469
0.77318054
0.77294487
0.77260649
0.77202970
0.77148032
0.77127266
0.77098715
0.77056122
0.77015907
0.76954228
0.76884842
0.76817220
0.76748735
0.76705605
INFO - Training [33][  160/  196]   Loss 0.400773   Top1 86.721191   Top5 98.598633   BatchTime 0.388803   LR 0.001222
0.76658183
0.76632202
0.76636595
0.76665354
0.76665139
0.76647937
0.76618576
0.76598042
0.76566756
0.76548684
0.76540893
0.76524872
0.76512909
0.76493222
0.76447946
0.76442963
0.76676947
0.76649702
0.76601130
0.76588923
0.76594812
INFO - Training [33][  180/  196]   Loss 0.401967   Top1 86.592882   Top5 98.556858   BatchTime 0.387287   LR 0.001221
0.76595652
0.76619989
0.76614368
0.76615894
0.76603317
0.76629043
0.76654655
0.76694089
0.76738876
0.76883554
0.76905018
0.76929891
INFO - ==> Top1: 86.584    Top5: 98.578    Loss: 0.402
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.76937985
0.76939458
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [33][   20/   40]   Loss 0.374989   Top1 88.242188   Top5 99.609375   BatchTime 0.155592
features.0.conv.0 tensor(0.4375)
features.0.conv.3 tensor(0.3359)
features.1.conv.0 tensor(0.0176)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0503)
features.2.conv.0 tensor(0.0260)
features.2.conv.3 tensor(0.0525)
features.2.conv.6 tensor(0.0848)
features.3.conv.0 tensor(0.0205)
features.3.conv.3 tensor(0.0502)
features.3.conv.6 tensor(0.0380)
features.4.conv.0 tensor(0.0301)
features.4.conv.3 tensor(0.1024)
features.4.conv.6 tensor(0.0853)
features.5.conv.0 tensor(0.0309)
features.5.conv.3 tensor(0.0666)
features.5.conv.6 tensor(0.1087)
features.6.conv.0 tensor(0.0247)
features.6.conv.3 tensor(0.0492)
features.6.conv.6 tensor(0.0513)
features.7.conv.0 tensor(0.0385)
features.7.conv.3 tensor(0.1279)
features.7.conv.6 tensor(0.1276)
features.8.conv.0 tensor(0.0811)
features.8.conv.3 tensor(0.1152)
features.8.conv.6 tensor(0.1188)
features.9.conv.0 tensor(0.0781)
features.9.conv.3 tensor(0.1545)
features.9.conv.6
INFO - Validation [33][   40/   40]   Loss 0.373584   Top1 88.160000   Top5 99.630000   BatchTime 0.105979
INFO - ==> Top1: 88.160    Top5: 99.630    Loss: 0.374
INFO - ==> Sparsity : 0.423
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  34
features.9.conv.6 tensor(0.1807)
features.10.conv.0 tensor(0.0337)
features.10.conv.3 tensor(0.0987)
features.10.conv.6 tensor(0.0769)
features.11.conv.0 tensor(0.6004)
features.11.conv.3 tensor(0.1534)
features.11.conv.6 tensor(0.4888)
features.12.conv.0 tensor(0.2927)
features.12.conv.3 tensor(0.1586)
features.12.conv.6 tensor(0.6713)
features.13.conv.0 tensor(0.0995)
features.13.conv.3 tensor(0.1368)
features.13.conv.6 tensor(0.2308)
features.14.conv.0 tensor(0.9622)
features.14.conv.3 tensor(0.0841)
features.14.conv.6 tensor(0.9826)
features.15.conv.0 tensor(0.9228)
features.15.conv.3 tensor(0.0604)
features.15.conv.6 tensor(0.9742)
features.16.conv.0 tensor(0.1715)
features.16.conv.3 tensor(0.1135)
features.16.conv.6 tensor(0.2465)
conv.0 tensor(0.1554)
tensor(925401.) 2188896.0
0.76964408
0.77433497
0.77400839
0.77373999
0.77347499
0.77295434
0.77254128
0.77246737
0.77257472
0.77240425
0.77227008
0.77208239
0.77190173
0.77149129
0.77124405
0.77069324
0.77035290
0.77012151
0.76957238
0.76905310
0.76886344
0.76859361
0.76835746
INFO - Training [34][   20/  196]   Loss 0.422904   Top1 85.937500   Top5 98.046875   BatchTime 0.443491   LR 0.001218
0.76819408
0.76620060
0.76556379
0.76552850
0.76465040
0.76321346
0.76079565
0.75764793
0.75692612
0.75608063
0.75516289
0.75318271
0.75360817
0.75582898
0.75771511
INFO - Training [34][   40/  196]   Loss 0.419596   Top1 85.859375   Top5 98.369141   BatchTime 0.411045   LR 0.001216
0.75824088
0.75865847
0.75913012
0.76105285
0.76244187
0.76377612
0.76506281
0.76636928
0.76748329
0.76988560
0.77009183
0.77004409
0.77002281
0.77009207
0.76999557
0.76990044
0.77010185
0.77281153
0.77284271
0.77268583
INFO - Training [34][   60/  196]   Loss 0.416203   Top1 85.768229   Top5 98.470052   BatchTime 0.411609   LR 0.001215
0.77258086
0.77252817
0.77251053
0.77248698
0.77244449
0.77227479
0.77236706
0.77232116
0.77209157
0.77161437
0.77101529
0.77018976
0.76957548
0.76861125
0.76759320
0.76694638
0.76622564
0.76539475
0.76462770
0.76443046
0.76469028
INFO - Training [34][   80/  196]   Loss 0.413759   Top1 86.015625   Top5 98.491211   BatchTime 0.402014   LR 0.001213
0.76479560
0.76508880
0.76515299
0.76546144
0.76590014
0.76635444
0.76697993
0.76751971
0.76790684
0.76831728
0.76875389
0.76913631
0.77109402
0.77119178
0.77120513
0.77101696
0.77074462
0.77045363
0.77001840
0.76993471
0.76997358
0.76984489
INFO - Training [34][  100/  196]   Loss 0.403663   Top1 86.300781   Top5 98.527344   BatchTime 0.396152   LR 0.001211
0.76973343
0.76965827
0.76972222
0.76941383
0.76941097
0.76928073
0.76937228
0.76934606
0.76930898
0.76913190
0.76909852
0.76905602
0.76902092
0.76887476
0.76859421
0.76864570
INFO - Training [34][  120/  196]   Loss 0.400809   Top1 86.438802   Top5 98.577474   BatchTime 0.389901   LR 0.001209
0.76878589
0.76898724
0.76902896
0.76891762
0.76881921
0.76872045
0.76875168
0.76880926
0.76884371
0.76881862
0.76870662
0.76862884
0.76854366
0.76830214
0.76814616
0.76794940
0.76772827
0.76752913
0.76727599
0.76720399
0.76732969
0.76774353
0.76806664
0.76875341
0.77109963
0.77182174
INFO - Training [34][  140/  196]   Loss 0.399670   Top1 86.520647   Top5 98.638393   BatchTime 0.392428   LR 0.001208
0.77292889
0.77326888
0.77362889
0.77405638
0.78474748
0.78497076
0.78480756
0.78472066
0.78495735
0.78506362
0.78514749
0.78483540
0.78497291
0.79271567
0.79246402
0.79233807
0.79178578
INFO - Training [34][  160/  196]   Loss 0.400297   Top1 86.520996   Top5 98.618164   BatchTime 0.387903   LR 0.001206
0.79131466
0.79115558
0.79111010
0.79104018
0.79092699
0.79083151
0.79042298
0.79018235
0.79018503
0.79017973
0.79020256
0.79014921
0.78968698
0.78939772
0.78907353
0.78852272
0.78822094
0.78793937
0.78699088
0.78682798
0.78638577
INFO - Training [34][  180/  196]   Loss 0.401456   Top1 86.469184   Top5 98.561198   BatchTime 0.383403   LR 0.001204
0.78608960
0.78595662
0.78578544
0.78573877
0.78564376
0.78568763
0.78524715
0.78444827
0.78383374
0.78253579
0.78207850
0.78196663
0.78074783
0.77968341
0.77830273
INFO - ==> Top1: 86.492    Top5: 98.534    Loss: 0.401
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 0.350831   Top1 87.812500   Top5 99.550781   BatchTime 0.133834
features.0.conv.0 tensor(0.4271)
features.0.conv.3 tensor(0.3320)
features.1.conv.0 tensor(0.0156)
features.1.conv.3 tensor(0.0833)
features.1.conv.6 tensor(0.0486)
features.2.conv.0 tensor(0.0286)
features.2.conv.3 tensor(0.0579)
features.2.conv.6 tensor(0.0836)
features.3.conv.0 tensor(0.0145)
features.3.conv.3 tensor(0.0525)
features.3.conv.6 tensor(0.0356)
features.4.conv.0 tensor(0.0306)
features.4.conv.3 tensor(0.0949)
features.4.conv.6 tensor(0.0845)
features.5.conv.0 tensor(0.0312)
features.5.conv.3 tensor(0.0671)
features.5.conv.6 tensor(0.1195)
features.6.conv.0 tensor(0.0290)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0491)
features.7.conv.0 tensor(0.0448)
features.7.conv.3 tensor(0.1299)
features.7.conv.6 tensor(0.1294)
features.8.conv.0 tensor(0.0648)
features.8.conv.3 tensor(0.1157)
features.8.conv.6 tensor(0.1297)
features.9.conv.0 tensor(0.0857)
features.9.conv.3 tensor(0.1479)
features.9.conv.6 tensor(0.1713)
features.10.conv.0 tensor(0.0357)
features.10.conv.3 tensor(0.0995)
features.10.conv.6 tensor(0.0734)
features.11.conv.0 tensor(0.5178)
features.11.conv.3 tensor(0.1534)
features.11.conv.6 tensor(0.4960)
features.12.conv.0 tensor(0.3039)
features.12.conv.3 tensor(0.1603)
features.12.conv.6 tensor(0.6649)
features.13.conv.0 tensor(0.1070)
features.13.conv.3 tensor(0.1358)
features.13.conv.6 tensor(0.0946)
features.14.conv.0 tensor(0.9620)
features.14.conv.3 tensor(0.0850)
features.14.conv.6 tensor(0.9820)
features.15.conv.0 tensor(0.9207)
features.15.conv.3 tensor(0.0633)
features.15.conv.6 tensor(0.9740)
features.16.conv.0 tensor(0.1865)
features.16.conv.3 tensor(0.1160)
features.16.conv.6 tensor(0.6118)
conv.0 tensor(0.1629)
tensor(1026531.) 2188896.0
INFO - Validation [34][   40/   40]   Loss 0.342275   Top1 88.380000   Top5 99.610000   BatchTime 0.092064
INFO - ==> Top1: 88.380    Top5: 99.610    Loss: 0.342
INFO - ==> Sparsity : 0.469
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
0.77369261
0.77136624
0.77100980
0.77350932
0.77658528
0.77929509
0.78156811
0.78438693
0.78752238
0.78749871
0.78723258
0.78704762
0.78668964
0.78634822
0.78595787
0.78540456
0.78489369
0.78469592
0.78435498
INFO - Training [35][   20/  196]   Loss 0.424569   Top1 85.117188   Top5 98.300781   BatchTime 0.442039   LR 0.001201
0.78397012
0.78365284
0.78336591
0.78310776
0.78297389
0.78257716
0.78229165
0.78210449
0.78194124
0.78178924
0.78161675
0.78129071
0.78118664
0.78109223
0.78091925
0.78062654
0.78047687
0.78018939
0.78011566
0.77995008
0.77997732
0.77988791
INFO - Training [35][   40/  196]   Loss 0.419970   Top1 85.566406   Top5 98.271484   BatchTime 0.408435   LR 0.001199
0.77996457
0.77979356
0.78016472
0.78124368
0.78103018
0.78090489
0.78056151
0.78037250
0.78010702
0.77979624
0.77958673
0.77964896
0.77955401
0.77957302
0.77953506
0.77932715
0.77929115
0.77957332
0.77958483
0.77982765
0.77985317
INFO - Training [35][   60/  196]   Loss 0.410391   Top1 85.963542   Top5 98.417969   BatchTime 0.394736   LR 0.001197
0.77993721
0.78011763
0.78012121
0.78011978
0.78027713
0.78058058
0.78404385
0.78518993
0.78518134
0.78503925
0.78482938
0.78472346
0.78436351
0.78398222
0.78358126
0.78292137
0.78238487
0.78206891
0.78190279
INFO - Training [35][   80/  196]   Loss 0.407485   Top1 86.083984   Top5 98.540039   BatchTime 0.399126   LR 0.001195
0.78165299
0.78123623
0.78073114
0.78032643
0.78004307
0.77973062
0.77946037
0.77919805
0.77887666
0.77867657
0.77844799
0.77827108
0.77796602
0.77808470
0.77789778
0.77744061
0.77720690
0.77711666
0.77691418
0.77659923
0.77658135
INFO - Training [35][  100/  196]   Loss 0.398365   Top1 86.457031   Top5 98.621094   BatchTime 0.400120   LR 0.001192
0.77647465
0.77656567
0.77648360
0.77621281
0.77587801
0.77537334
0.77512127
0.77500963
0.77493697
0.77663636
0.77809638
0.77782428
0.77770638
0.77714998
0.77697515
0.77696306
0.77684557
0.77612722
0.77545661
INFO - Training [35][  120/  196]   Loss 0.393510   Top1 86.608073   Top5 98.675130   BatchTime 0.399405   LR 0.001190
0.77493590
0.77478570
0.77470928
0.77480364
0.77470964
0.77455193
0.77448821
0.77447206
0.77444482
0.77433527
0.77422118
0.77416027
0.77426946
0.77424788
0.77412671
0.77409387
0.77430987
INFO - Training [35][  140/  196]   Loss 0.392758   Top1 86.618304   Top5 98.708147   BatchTime 0.395839   LR 0.001188
0.77468467
0.77497238
0.77538264
0.77557069
0.77636349
0.77644360
0.77700555
0.77748197
0.78037447
0.78339827
0.78307438
0.78259099
0.78234488
0.78207183
0.78179711
0.78148198
0.78108841
0.78095275
0.78095120
0.78081816
0.78090250
0.78088933
INFO - Training [35][  160/  196]   Loss 0.394433   Top1 86.616211   Top5 98.710938   BatchTime 0.391829   LR 0.001186
0.78083366
0.78067142
0.78055298
0.78045225
0.78018558
0.77997315
0.77979565
0.77955484
0.77942598
0.77915901
0.77823532
0.77774388
0.77725029
0.77665317
0.77609348
0.77621299
0.77602899
0.77574837
INFO - Training [35][  180/  196]   Loss 0.394859   Top1 86.595052   Top5 98.628472   BatchTime 0.384595   LR 0.001184
0.77512532
0.77443135
0.77380329
0.77351838
0.77307349
0.77283221
0.77241337
0.77216089
0.77189982
0.77171057
0.77108639
0.77017987
0.76915109
0.76603633
0.76332539
0.75983006
0.75820518
0.75643885
********************pre-trained*****************
INFO - ==> Top1: 86.682    Top5: 98.640    Loss: 0.393
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [35][   20/   40]   Loss 0.324275   Top1 88.906250   Top5 99.628906   BatchTime 0.123967
features.0.conv.0 tensor(0.4340)
features.0.conv.3 tensor(0.3320)
features.1.conv.0 tensor(0.0124)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0482)
features.2.conv.0 tensor(0.0249)
features.2.conv.3 tensor(0.0502)
features.2.conv.6 tensor(0.0822)
features.3.conv.0 tensor(0.0159)
features.3.conv.3 tensor(0.0548)
features.3.conv.6 tensor(0.0345)
features.4.conv.0 tensor(0.0339)
features.4.conv.3 tensor(0.0949)
features.4.conv.6 tensor(0.0822)
features.5.conv.0 tensor(0.0296)
features.5.conv.3 tensor(0.0666)
features.5.conv.6 tensor(0.1348)
features.6.conv.0 tensor(0.0286)
features.6.conv.3 tensor(0.0486)
features.6.conv.6 tensor(0.0521)
features.7.conv.0 tensor(0.0455)
features.7.conv.3 tensor(0.1302)
features.7.conv.6 tensor(0.1045)
features.8.conv.0 tensor(0.0682)
features.8.conv.3 tensor(0.1163)
features.8.conv.6 tensor(0.1388)
features.9.conv.0 tensor(0.0706)
features.9.conv.3 tensor(0.1539)
features.9.conv.6 tensor(0.2257)
features.10.conv.0 tensor(0.0359)
features.10.conv.3 tensor(0.0938)
features.10.conv.6 tensor(0.0390)
features.11.conv.0 tensor(0.5206)
features.11.conv.3 tensor(0.1503)
features.11.conv.6 tensor(0.5438)
features.12.conv.0 tensor(0.3551)
features.12.conv.3 tensor(0.1622)
features.12.conv.6 tensor(0.6766)
features.13.conv.0 tensor(0.0888)
features.13.conv.3 tensor(0.1348)
features.13.conv.6 tensor(0.1005)
features.14.conv.0 tensor(0.9630)
features.14.conv.3 tensor(0.0861)
features.14.conv.6 tensor(0.9832)
features.15.conv.0 tensor(0.9259)
features.15.conv.3 tensor(0.0644)
features.15.conv.6 tensor(0.9750)
features.16.conv.0 tensor(0.1969)
features.16.conv.3 tensor(0.1169)
features.16.conv.6 tensor(0.6006)
conv.0 tensor(0.1789)
tensor(1037846.) 2188896.0
INFO - Validation [35][   40/   40]   Loss 0.317388   Top1 89.060000   Top5 99.650000   BatchTime 0.087693
INFO - ==> Top1: 89.060    Top5: 99.650    Loss: 0.317
INFO - ==> Sparsity : 0.474
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
0.76088101
0.76519990
0.77020162
0.77379435
0.77744174
0.77784008
0.78110445
0.78177387
0.78146225
0.78180319
0.78192842
0.78193051
0.78183401
0.78177983
0.78173250
0.78181314
0.78184038
0.78187263
0.78209430
INFO - Training [36][   20/  196]   Loss 0.439093   Top1 85.234375   Top5 97.910156   BatchTime 0.436033   LR 0.001180
0.78156984
0.78177738
0.78197694
0.78205591
0.78226161
0.78225988
0.78237778
0.78233385
0.78220838
0.78215790
0.78222919
0.78211212
0.78210092
0.78175920
0.78169203
0.78134644
0.78100246
0.78097951
0.78106874
0.78094125
0.78090721
0.78074700
0.78049201
0.78030372
INFO - Training [36][   40/  196]   Loss 0.415440   Top1 86.132812   Top5 98.271484   BatchTime 0.389604   LR 0.001177
0.77988297
0.77957493
0.77969897
0.77971518
0.77953339
0.77937597
0.77935076
0.77956760
0.77963692
0.77973944
0.77945226
0.77978033
0.77996612
0.78022796
0.78047043
0.78089482
0.78098464
INFO - Training [36][   60/  196]   Loss 0.403984   Top1 86.549479   Top5 98.391927   BatchTime 0.379663   LR 0.001175
0.78140080
0.78182882
0.78201163
0.78186649
0.78211564
0.78189570
0.78177124
0.78145856
0.78111696
0.78109676
0.78107321
0.78125405
0.78154284
0.78232414
0.78401721
0.78397036
0.78379351
0.78329349
0.78326070
0.78306711
INFO - Training [36][   80/  196]   Loss 0.397861   Top1 86.757812   Top5 98.496094   BatchTime 0.381138   LR 0.001173
0.78270173
0.78245008
0.78200948
0.78181648
0.78159231
0.78100944
0.78061754
0.78020120
0.77978951
0.77933550
0.77911818
0.77895415
0.77908796
0.77897900
0.77874148
0.77862728
0.77875662
0.77877456
INFO - Training [36][  100/  196]   Loss 0.389401   Top1 87.101562   Top5 98.550781   BatchTime 0.374481   LR 0.001170
0.77846456
0.77816433
0.77802277
0.77769482
0.77758610
0.77743489
0.77718997
0.77674282
0.77625817
0.77581865
0.77560109
0.77528292
0.77502567
0.77449912
0.77383983
0.77331835
0.77318734
0.77291590
0.77244782
0.77274871
0.77274740
0.77222061
0.77157742
0.77118516
0.77123910
INFO - Training [36][  120/  196]   Loss 0.384463   Top1 87.246094   Top5 98.632812   BatchTime 0.379250   LR 0.001168
0.77097130
0.77100241
0.77071625
0.76893693
0.76839817
0.76846719
0.76806855
0.76813221
0.76784682
0.76791722
0.76754147
0.76716411
0.76695144
0.76740581
0.76803154
0.76838428
INFO - Training [36][  140/  196]   Loss 0.383997   Top1 87.212612   Top5 98.669085   BatchTime 0.378059   LR 0.001165
0.76809746
0.76744497
0.76716220
0.76673406
0.76687288
0.76650178
0.76609749
0.76525086
0.76458675
0.76359975
0.76288497
0.76269275
0.76285678
0.76364434
0.76442337
0.76545280
0.76826721
0.76868105
0.76891947
0.76851428
INFO - Training [36][  160/  196]   Loss 0.384637   Top1 87.165527   Top5 98.649902   BatchTime 0.381663   LR 0.001163
0.76854402
0.76880968
0.76941115
0.77021807
0.77112669
0.77213490
0.77303088
0.77379990
0.77462542
0.77590281
0.77684075
0.77822876
0.78118283
0.78557450
0.78827477
0.78804791
0.78773654
0.78752089
0.78705001
0.78658515
0.78618103
0.78581417
INFO - Training [36][  180/  196]   Loss 0.385869   Top1 87.072483   Top5 98.574219   BatchTime 0.379160   LR 0.001160
0.78543776
0.78485847
0.78423280
0.78371072
0.78299266
0.78270543
0.78258389
0.78233081
0.78207487
0.78158659
0.78188461
0.78189057
0.78167152
0.78148437
INFO - ==> Top1: 87.166    Top5: 98.598    Loss: 0.383
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.78099555
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [36][   20/   40]   Loss 0.348740   Top1 88.535156   Top5 99.453125   BatchTime 0.138392
INFO - Validation [36][   40/   40]   Loss 0.342625   Top1 88.700000   Top5 99.550000   BatchTime 0.094641
INFO - ==> Top1: 88.700    Top5: 99.550    Loss: 0.343
INFO - ==> Sparsity : 0.406
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
features.0.conv.0 tensor(0.4410)
features.0.conv.3 tensor(0.3535)
features.1.conv.0 tensor(0.0163)
features.1.conv.3 tensor(0.0810)
features.1.conv.6 tensor(0.0508)
features.2.conv.0 tensor(0.0307)
features.2.conv.3 tensor(0.0571)
features.2.conv.6 tensor(0.0825)
features.3.conv.0 tensor(0.0197)
features.3.conv.3 tensor(0.0525)
features.3.conv.6 tensor(0.0332)
features.4.conv.0 tensor(0.0285)
features.4.conv.3 tensor(0.0938)
features.4.conv.6 tensor(0.0872)
features.5.conv.0 tensor(0.0272)
features.5.conv.3 tensor(0.0613)
features.5.conv.6 tensor(0.1058)
features.6.conv.0 tensor(0.0249)
features.6.conv.3 tensor(0.0498)
features.6.conv.6 tensor(0.0509)
features.7.conv.0 tensor(0.0483)
features.7.conv.3 tensor(0.1241)
features.7.conv.6 tensor(0.2120)
features.8.conv.0 tensor(0.0706)
features.8.conv.3 tensor(0.1169)
features.8.conv.6 tensor(0.1383)
features.9.conv.0 tensor(0.0758)
features.9.conv.3 tensor(0.1499)
features.9.conv.6 tensor(0.2446)
features.10.conv.0 tensor(0.0354)
features.10.conv.3 tensor(0.0978)
features.10.conv.6 tensor(0.0479)
features.11.conv.0 tensor(0.4953)
features.11.conv.3 tensor(0.1516)
features.11.conv.6 tensor(0.5410)
features.12.conv.0 tensor(0.1423)
features.12.conv.3 tensor(0.1557)
features.12.conv.6 tensor(0.6893)
features.13.conv.0 tensor(0.0921)
features.13.conv.3 tensor(0.1310)
features.13.conv.6 tensor(0.1210)
features.14.conv.0 tensor(0.9426)
features.14.conv.3 tensor(0.0845)
features.14.conv.6 tensor(0.9826)
features.15.conv.0 tensor(0.9290)
features.15.conv.3 tensor(0.0632)
features.15.conv.6 tensor(0.9756)
features.16.conv.0 tensor(0.2011)
features.16.conv.3 tensor(0.1166)
features.16.conv.6 tensor(0.2042)
conv.0 tensor(0.1342)
tensor(888573.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
0.78006554
0.77900022
0.77792883
0.77717566
0.77656776
0.77596104
0.77555132
0.77536464
0.77582753
0.77657443
0.77746248
0.77803630
0.77845764
0.78025305
0.78118402
0.78259635
0.78723168
0.78733379
0.78724724
0.78720611
0.78747022
INFO - Training [37][   20/  196]   Loss 0.395349   Top1 86.542969   Top5 98.125000   BatchTime 0.431874   LR 0.001155
0.78764522
0.78748095
0.78753603
0.78781188
0.78756958
0.78760338
0.78769457
0.78761476
0.78746831
0.78734112
0.78716004
0.78718901
0.78694409
0.78713310
0.79274791
0.79261059
0.79237711
0.79210335
0.79159135
0.79116786
0.79067802
0.79002261
INFO - Training [37][   40/  196]   Loss 0.396739   Top1 86.572266   Top5 98.261719   BatchTime 0.396776   LR 0.001153
0.78945416
0.78852868
0.78822136
0.78823757
0.78803807
0.78801268
0.78798574
0.78778505
0.78772271
0.78772634
0.78769058
0.78746319
0.78727728
0.78710127
0.78691202
0.78664201
0.78689545
INFO - Training [37][   60/  196]   Loss 0.393722   Top1 86.640625   Top5 98.489583   BatchTime 0.384115   LR 0.001150
0.78716815
0.78721333
0.78760082
0.78786635
0.78809786
0.78807938
0.78814763
0.78843486
0.78877330
0.79032606
0.78998309
0.78976172
0.78946483
0.78898388
0.78847885
0.78748780
0.78666925
0.78579098
0.78527689
0.78500688
0.78293431
0.77905101
INFO - Training [37][   80/  196]   Loss 0.390739   Top1 86.835938   Top5 98.569336   BatchTime 0.379187   LR 0.001147
0.77604592
0.77258617
0.77302498
0.77468187
0.77964211
0.78461850
0.78799957
0.79286778
0.79277760
0.79248965
0.79262024
0.79226238
0.79191899
0.79169321
0.79118586
0.79086548
0.79089075
0.79198289
0.79298264
0.79274720
0.79279393
INFO - Training [37][  100/  196]   Loss 0.389298   Top1 86.867188   Top5 98.566406   BatchTime 0.379094   LR 0.001144
0.79306656
0.79323155
0.79323947
0.79316759
0.79313952
0.79314280
0.79300183
0.79275733
0.79260558
0.79254711
0.79281503
0.79289126
0.79304755
0.79281080
0.79274166
0.79253858
0.79236817
INFO - Training [37][  120/  196]   Loss 0.387106   Top1 86.962891   Top5 98.662109   BatchTime 0.375725   LR 0.001142
0.79231614
0.79193711
0.79183447
0.79154879
0.79123110
0.79118824
0.79091805
0.79056501
0.79034096
0.78990513
0.78974116
0.78894883
0.78876966
0.78853202
0.78808486
0.78791261
0.78773063
0.78755224
0.78734589
0.78728867
0.78723240
INFO - Training [37][  140/  196]   Loss 0.385796   Top1 87.025670   Top5 98.716518   BatchTime 0.375482   LR 0.001139
0.78715694
0.78730357
0.78753906
0.78739643
0.78742361
0.78751218
0.78766739
0.78781390
0.78819209
0.78870827
0.78955960
0.79085112
0.79164702
0.79239309
0.79302317
0.79318374
0.79278612
0.79270452
0.79271895
0.79250753
0.79216141
0.79205185
INFO - Training [37][  160/  196]   Loss 0.386619   Top1 86.982422   Top5 98.718262   BatchTime 0.374916   LR 0.001136
0.79136884
0.79085833
0.79078090
0.79037583
0.79000711
0.78994238
0.78952503
0.78897786
0.78843129
0.78787303
0.78758621
0.78707343
0.78670001
0.78612190
0.78552389
0.78506368
0.78472012
0.78448033
INFO - Training [37][  180/  196]   Loss 0.388940   Top1 86.883681   Top5 98.630642   BatchTime 0.370160   LR 0.001133
0.78372788
0.78305382
0.78240067
0.78188336
0.78158301
0.78123230
0.78102279
0.78066498
0.78039891
0.78025752
0.77977216
0.77913994
0.77828354
0.77759713
0.77654850
INFO - ==> Top1: 86.878    Top5: 98.628    Loss: 0.389
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [37][   20/   40]   Loss 0.370275   Top1 87.988281   Top5 99.492188   BatchTime 0.125686
features.0.conv.0 tensor(0.4479)
features.0.conv.3 tensor(0.3359)
features.1.conv.0 tensor(0.0163)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0473)
features.2.conv.0 tensor(0.0289)
features.2.conv.3 tensor(0.0579)
features.2.conv.6 tensor(0.0828)
features.3.conv.0 tensor(0.0234)
features.3.conv.3 tensor(0.0525)
features.3.conv.6 tensor(0.0352)
features.4.conv.0 tensor(0.0352)
features.4.conv.3 tensor(0.0955)
features.4.conv.6 tensor(0.0856)
features.5.conv.0 tensor(0.0316)
features.5.conv.3 tensor(0.0613)
features.5.conv.6 tensor(0.1061)
features.6.conv.0 tensor(0.0251)
features.6.conv.3 tensor(0.0451)
features.6.conv.6 tensor(0.0471)
features.7.conv.0 tensor(0.0417)
features.7.conv.3 tensor(0.1262)
features.7.conv.6 tensor(0.1397)
features.8.conv.0 tensor(0.0699)
features.8.conv.3 tensor(0.1163)
features.8.conv.6 tensor(0.1455)
features.9.conv.0 tensor(0.0802)
features.9.conv.3 tensor(0.1481)
features.9.conv.6 tensor(0.1331)
features.10.conv.0 tensor(0.0330)
features.10.conv.3 tensor(0.0926)
features.10.conv.6 tensor(0.0645)
features.11.conv.0 tensor(0.5119)
features.11.conv.3 tensor(0.1516)
features.11.conv.6 tensor(0.5688)
features.12.conv.0 tensor(0.2361)
features.12.conv.3 tensor(0.1566)
features.12.conv.6 tensor(0.6769)
features.13.conv.0 tensor(0.0972)
features.13.conv.3 tensor(0.1333)
features.13.conv.6 tensor(0.2658)
features.14.conv.0 tensor(0.9351)
features.14.conv.3 tensor(0.0815)
features.14.conv.6 tensor(0.9830)
features.15.conv.0 tensor(0.9302)
features.15.conv.3 tensor(0.0628)
features.15.conv.6 tensor(0.9760)
features.16.conv.0 tensor(0.2079)
features.16.conv.3 tensor(0.1183)
features.16.conv.6 tensor(0.1989)
conv.0 tensor(0.1308)
tensor(902533.) 2188896.0
INFO - Validation [37][   40/   40]   Loss 0.356694   Top1 88.220000   Top5 99.590000   BatchTime 0.101856
INFO - ==> Top1: 88.220    Top5: 99.590    Loss: 0.357
INFO - ==> Sparsity : 0.412
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
0.77528054
0.77374184
0.77214044
0.77067894
0.76912272
0.76758790
0.76601869
0.76482540
0.76345974
0.76265919
0.76173568
0.76085049
0.76014262
0.75941712
0.75838345
0.75761968
0.75722885
0.75689405
0.75606805
INFO - Training [38][   20/  196]   Loss 0.399196   Top1 86.347656   Top5 98.398438   BatchTime 0.431616   LR 0.001128
0.75506121
0.75469935
0.75466686
0.75468659
0.75444496
0.75432545
0.75365931
0.75354707
0.75302720
0.75353611
0.75397748
0.75454837
0.75469828
0.75495684
0.75680286
0.75674891
0.75678575
0.75673163
0.75661910
0.75781059
0.76181275
INFO - Training [38][   40/  196]   Loss 0.395484   Top1 86.582031   Top5 98.496094   BatchTime 0.399143   LR 0.001125
0.76060408
0.75873822
0.75702995
0.75637925
0.75615376
0.75614655
0.75588691
0.75532180
0.75481045
0.75397098
0.75569046
0.76055086
0.76120210
0.76140821
0.75930542
0.75648499
0.75688970
0.75636160
0.75670421
0.75833529
0.76059926
0.76216799
0.76306891
INFO - Training [38][   60/  196]   Loss 0.393245   Top1 86.673177   Top5 98.567708   BatchTime 0.385787   LR 0.001122
0.76203817
0.76094794
0.76065528
0.76115710
0.76206768
0.76362896
0.76591706
0.76767474
0.76838619
0.76952118
0.77072561
0.77178419
0.77236199
0.77272290
0.77303171
0.77325332
0.77306771
INFO - Training [38][   80/  196]   Loss 0.390337   Top1 86.870117   Top5 98.598633   BatchTime 0.378638   LR 0.001119
0.77363688
0.77436686
0.77482504
0.77513629
0.77571040
0.77649206
0.77716035
0.77794391
0.77914900
0.78038698
0.78356129
0.78387803
0.78404349
0.78425252
0.78434098
0.78451180
0.78467035
0.78485644
0.78510183
INFO - Training [38][  100/  196]   Loss 0.383790   Top1 87.105469   Top5 98.656250   BatchTime 0.384734   LR 0.001116
0.78541881
0.78545046
0.78563744
0.78553289
0.78562790
0.78579766
0.78568894
0.78567344
0.78572667
0.78593498
0.78618872
0.78634888
0.78624141
0.78644305
0.78633928
0.78637606
0.78625572
0.78636003
0.78634936
0.78617835
0.78570300
0.78542787
INFO - Training [38][  120/  196]   Loss 0.378133   Top1 87.239583   Top5 98.746745   BatchTime 0.381632   LR 0.001112
0.78511506
0.78512293
0.78502953
0.78479242
0.78475344
0.78488171
0.78495544
0.78499728
0.78469974
0.78458923
0.78472185
0.78455508
0.78455275
0.78447062
0.78437781
0.78418332
0.78407270
0.78390110
0.78356981
0.78345627
0.78342408
INFO - Training [38][  140/  196]   Loss 0.376243   Top1 87.366071   Top5 98.794643   BatchTime 0.382700   LR 0.001109
0.78340697
0.78318685
0.78294408
0.79249841
0.79192853
0.79149228
0.79117268
0.79106218
0.79089141
0.79073268
0.79052722
0.79033011
0.79016972
0.79002827
0.78993297
0.78975308
0.78958505
0.78949887
0.78921252
0.78868788
0.78821349
INFO - Training [38][  160/  196]   Loss 0.379989   Top1 87.280273   Top5 98.769531   BatchTime 0.382740   LR 0.001106
0.78793293
0.78778976
0.78764212
0.78769636
0.78832471
0.78797716
0.78745884
0.78674138
0.78627169
0.78587997
0.78531176
0.78493345
0.78475946
0.78449667
0.78420156
0.78401470
0.78377920
0.78317249
0.78259242
INFO - Training [38][  180/  196]   Loss 0.380253   Top1 87.274306   Top5 98.697917   BatchTime 0.376189   LR 0.001103
0.78205717
0.78161943
0.78143746
0.78111404
0.78124857
0.78137791
0.78119290
0.78104132
0.78068173
0.78060883
0.78046185
0.78023946
INFO - ==> Top1: 87.266    Top5: 98.698    Loss: 0.380
0.77980876
0.77905071
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [38][   20/   40]   Loss 0.317400   Top1 89.277344   Top5 99.707031   BatchTime 0.127309
INFO - Validation [38][   40/   40]   Loss 0.299785   Top1 89.720000   Top5 99.760000   BatchTime 0.090136
INFO - ==> Top1: 89.720    Top5: 99.760    Loss: 0.300
INFO - ==> Sparsity : 0.424
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4375)
features.0.conv.3 tensor(0.3066)
features.1.conv.0 tensor(0.0150)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0473)
features.2.conv.0 tensor(0.0278)
features.2.conv.3 tensor(0.0594)
features.2.conv.6 tensor(0.0813)
features.3.conv.0 tensor(0.0168)
features.3.conv.3 tensor(0.0471)
features.3.conv.6 tensor(0.0347)
features.4.conv.0 tensor(0.0311)
features.4.conv.3 tensor(0.0891)
features.4.conv.6 tensor(0.0868)
features.5.conv.0 tensor(0.0337)
features.5.conv.3 tensor(0.0677)
features.5.conv.6 tensor(0.1260)
features.6.conv.0 tensor(0.0282)
features.6.conv.3 tensor(0.0440)
features.6.conv.6 tensor(0.0456)
features.7.conv.0 tensor(0.0602)
features.7.conv.3 tensor(0.1288)
features.7.conv.6 tensor(0.1006)
features.8.conv.0 tensor(0.0705)
features.8.conv.3 tensor(0.1169)
features.8.conv.6 tensor(0.1665)
features.9.conv.0 tensor(0.0734)
features.9.conv.3 tensor(0.1493)
features.9.conv.6 tensor(0.1274)
features.10.conv.0 tensor(0.0331)
features.10.conv.3 tensor(0.0952)
features.10.conv.6 tensor(0.0671)
features.11.conv.0 tensor(0.5287)
features.11.conv.3 tensor(0.1557)
features.11.conv.6 tensor(0.5352)
features.12.conv.0 tensor(0.2914)
features.12.conv.3 tensor(0.1539)
features.12.conv.6 tensor(0.7234)
features.13.conv.0 tensor(0.1047)
features.13.conv.3 tensor(0.1304)
features.13.conv.6 tensor(0.0985)
features.14.conv.0 tensor(0.9253)
features.14.conv.3 tensor(0.0812)
features.14.conv.6 tensor(0.9833)
features.15.conv.0 tensor(0.9330)
features.15.conv.3 tensor(0.0638)
features.15.conv.6 tensor(0.9755)
features.16.conv.0 tensor(0.2149)
features.16.conv.3 tensor(0.1208)
features.16.conv.6 tensor(0.2674)
conv.0 tensor(0.1665)
tensor(927764.) 2188896.0
0.77811712
0.77751786
0.77675015
0.77632588
0.77577072
0.77709085
0.77654570
0.77537674
0.77410156
0.77157605
0.77019370
0.76932228
0.76818138
0.76825213
0.76919019
0.76881164
0.77001965
0.77130002
0.77264160
0.77441138
0.77423257
0.77337736
INFO - Training [39][   20/  196]   Loss 0.409331   Top1 86.171875   Top5 98.203125   BatchTime 0.424669   LR 0.001097
0.77326900
0.77294147
0.77402824
0.77524942
0.77654022
0.77749115
0.77816808
0.77861559
0.77860510
0.77817953
0.77785760
0.77737361
0.77686727
0.77667135
0.77644539
0.77646655
0.77605450
INFO - Training [39][   40/  196]   Loss 0.404349   Top1 86.513672   Top5 98.417969   BatchTime 0.394403   LR 0.001094
0.77533770
0.77551854
0.77550846
0.77551657
0.77535230
0.77560222
0.77647871
0.77750909
0.77864754
0.77984053
0.78091264
0.78240025
0.78569740
0.78582358
0.78595603
0.78643638
0.78670698
0.78690326
0.78695154
0.78715450
0.78796703
INFO - Training [39][   60/  196]   Loss 0.395379   Top1 86.751302   Top5 98.535156   BatchTime 0.391430   LR 0.001090
0.78914958
0.78928083
0.79237366
0.79268819
0.79257941
0.79260671
0.79259896
0.79240835
0.79233420
0.79234624
0.79228383
0.79231358
0.79244131
0.79277521
0.79296279
0.79295927
0.79260969
0.79212987
0.79162174
0.79138803
INFO - Training [39][   80/  196]   Loss 0.395731   Top1 86.684570   Top5 98.637695   BatchTime 0.392446   LR 0.001087
0.79139954
0.79127735
0.79116857
0.79118437
0.79115158
0.79102641
0.79095823
0.79070896
0.79031372
0.78967643
0.78921562
0.78836137
0.78763926
0.78688991
0.78622210
0.78525132
0.78409106
0.78278238
0.78199351
0.78150225
0.78086865
INFO - Training [39][  100/  196]   Loss 0.385963   Top1 87.046875   Top5 98.667969   BatchTime 0.390408   LR 0.001084
0.78047633
0.78034282
0.78037924
0.77994901
0.77926284
0.77895737
0.77868611
0.77830732
0.77785844
0.77758563
0.77715915
0.77676415
0.77607149
0.77548367
0.77499771
0.77407879
0.77377909
0.77380371
0.77410007
0.77430588
0.77437890
0.77411509
INFO - Training [39][  120/  196]   Loss 0.381541   Top1 87.207031   Top5 98.730469   BatchTime 0.385953   LR 0.001080
0.77377230
0.77356035
0.77360851
0.77360469
0.77355152
0.77350193
0.77341306
0.77345234
0.77378917
0.77425832
0.77502996
0.77571625
0.77619606
0.77670544
0.77713573
0.77707326
INFO - Training [39][  140/  196]   Loss 0.382186   Top1 87.262835   Top5 98.752790   BatchTime 0.385794   LR 0.001077
0.77729052
0.77883065
0.78095859
0.78202748
0.78165692
0.78127187
0.78094769
0.78075320
0.78070629
0.78066510
0.78058362
0.78262156
0.78274727
0.78284091
0.78261834
0.78232914
0.78208649
0.78172189
0.78080535
0.78055471
0.78332007
0.78232801
0.78112763
INFO - Training [39][  160/  196]   Loss 0.382713   Top1 87.209473   Top5 98.735352   BatchTime 0.379888   LR 0.001073
0.78049290
0.78013319
0.78011197
0.77948403
0.77912110
0.77808815
0.77765548
0.77696115
0.77710158
0.77689457
0.77718419
0.77671486
0.77730423
0.77731532
0.77699482
0.77620822
0.77407414
0.77067727
0.76790261
INFO - Training [39][  180/  196]   Loss 0.382468   Top1 87.235243   Top5 98.682726   BatchTime 0.371725   LR 0.001070
0.76337260
0.76659584
0.77083355
0.77579153
0.77970189
0.78257489
0.78845906
0.78855312
0.78852195
0.78867012
0.78891128
0.78913856
0.79010212
0.79386514
0.79409647
********************pre-trained*****************
INFO - ==> Top1: 87.306    Top5: 98.694    Loss: 0.381
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [39][   20/   40]   Loss 0.337063   Top1 89.804688   Top5 99.609375   BatchTime 0.128158
features.0.conv.0 tensor(0.4444)
features.0.conv.3 tensor(0.3066)
features.1.conv.0 tensor(0.0163)
features.1.conv.3 tensor(0.0810)
features.1.conv.6 tensor(0.0503)
features.2.conv.0 tensor(0.0208)
features.2.conv.3 tensor(0.0610)
features.2.conv.6 tensor(0.0909)
features.3.conv.0 tensor(0.0179)
features.3.conv.3 tensor(0.0494)
features.3.conv.6 tensor(0.0360)
features.4.conv.0 tensor(0.0308)
features.4.conv.3 tensor(0.0845)
features.4.conv.6 tensor(0.0833)
features.5.conv.0 tensor(0.0342)
features.5.conv.3 tensor(0.0723)
features.5.conv.6 tensor(0.1086)
features.6.conv.0 tensor(0.0267)
features.6.conv.3 tensor(0.0521)
features.6.conv.6 tensor(0.0455)
features.7.conv.0 tensor(0.0611)
features.7.conv.3 tensor(0.1302)
features.7.conv.6 tensor(0.1112)
features.8.conv.0 tensor(0.0731)
features.8.conv.3 tensor(0.1186)
features.8.conv.6 tensor(0.1168)
features.9.conv.0 tensor(0.0763)
features.9.conv.3 tensor(0.1493)
features.9.conv.6 tensor(0.1541)
features.10.conv.0 tensor(0.0346)
features.10.conv.3 tensor(0.0929)
features.10.conv.6 tensor(0.0656)
features.11.conv.0 tensor(0.5173)
features.11.conv.3 tensor(0.1570)
features.11.conv.6 tensor(0.5470)
features.12.conv.0 tensor(0.1639)
features.12.conv.3 tensor(0.1595)
features.12.conv.6 tensor(0.7004)
features.13.conv.0 tensor(0.1088)
features.13.conv.3 tensor(0.1296)
features.13.conv.6 tensor(0.1050)
features.14.conv.0 tensor(0.8745)
features.14.conv.3 tensor(0.0755)
features.14.conv.6 tensor(0.9844)
features.15.conv.0 tensor(0.9361)
features.15.conv.3 tensor(0.0640)
features.15.conv.6 tensor(0.9764)
features.16.conv.0 tensor(0.2209)
features.16.conv.3 tensor(0.1207)
features.16.conv.6 tensor(0.2107)
conv.0 tensor(0.1550)
tensor(891805.) 2188896.0
INFO - Validation [39][   40/   40]   Loss 0.326441   Top1 90.100000   Top5 99.710000   BatchTime 0.093361
INFO - ==> Top1: 90.100    Top5: 99.710    Loss: 0.326
INFO - ==> Sparsity : 0.407
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
0.79374677
0.79355484
0.79345995
0.79350317
0.79356575
0.79371154
0.79381377
0.79365021
0.79349154
0.79322779
0.79332125
0.79333317
0.79342854
0.79359293
0.79355353
0.79330403
0.79316211
0.79308420
0.79313046
0.79306096
INFO - Training [40][   20/  196]   Loss 0.387706   Top1 86.347656   Top5 98.242188   BatchTime 0.426323   LR 0.001064
0.79312831
0.79309285
0.79284936
0.79289103
0.79272133
0.79254967
0.79229921
0.79161251
0.79101044
0.79083735
0.79058462
0.79014736
0.79005957
0.78997463
0.78982508
0.78975552
0.78959602
0.78925925
INFO - Training [40][   40/  196]   Loss 0.379226   Top1 86.875000   Top5 98.447266   BatchTime 0.381340   LR 0.001060
0.78895855
0.78891510
0.78836310
0.78815532
0.78787899
0.78751320
0.78735924
0.78745341
0.78738368
0.78744745
0.78745407
0.78765732
0.78806436
0.78836375
0.78833872
0.78870177
0.78928256
0.78951126
0.79128349
0.79148358
0.79148620
0.79086864
0.79079360
INFO - Training [40][   60/  196]   Loss 0.379413   Top1 86.822917   Top5 98.561198   BatchTime 0.372774   LR 0.001056
0.79038674
0.79065889
0.79115176
0.79091179
0.79079449
0.79094529
0.79137093
0.79145885
0.79054940
0.79018074
0.78968883
0.78895837
0.78834820
0.78773052
0.78704774
0.78643930
0.78590161
0.78507799
0.78416383
0.78339523
INFO - Training [40][   80/  196]   Loss 0.377242   Top1 87.114258   Top5 98.647461   BatchTime 0.376919   LR 0.001053
0.78222150
0.78159070
0.78118426
0.78073937
0.78025311
0.77984720
0.77960587
0.77946967
0.77935052
0.77956277
0.77982396
0.78017032
0.77996927
0.78015035
0.78032660
0.78073907
0.78160262
INFO - Training [40][  100/  196]   Loss 0.372641   Top1 87.300781   Top5 98.683594   BatchTime 0.375210   LR 0.001049
0.78329962
0.78551358
0.78932661
0.78893715
0.78844780
0.78793287
0.78719807
0.78725326
0.78673732
0.78630286
0.78597897
0.78628868
0.78735602
0.78686190
0.78618270
0.78547817
0.78478742
0.78429985
0.78336024
0.78207475
0.78099942
0.78010726
INFO - Training [40][  120/  196]   Loss 0.365200   Top1 87.565104   Top5 98.779297   BatchTime 0.374333   LR 0.001045
0.77886838
0.77780837
0.77708590
0.77618593
0.77593589
0.77565056
0.77533907
0.77502483
0.77476549
0.77443600
0.77394843
0.77303702
0.77199960
0.77103072
0.76982272
0.76919532
0.76883101
0.76778257
0.76672775
0.76599234
0.76586366
0.76540619
0.76295656
INFO - Training [40][  140/  196]   Loss 0.363594   Top1 87.656250   Top5 98.816964   BatchTime 0.369816   LR 0.001042
0.75912434
0.75548142
0.75402504
0.75228435
0.75343257
0.75572902
0.75744092
0.75868529
0.76013231
0.75976157
0.75990826
0.75914812
0.75850403
0.75740623
0.75637901
0.75574231
0.75480306
0.75402737
INFO - Training [40][  160/  196]   Loss 0.367266   Top1 87.551270   Top5 98.774414   BatchTime 0.365445   LR 0.001038
0.75304437
0.75239116
0.75232720
0.75001943
0.74847674
0.74781173
0.74664915
0.74530101
0.74497086
0.74504542
0.74442798
0.74406648
0.74422741
0.74487001
0.74459827
0.74809796
0.75047022
0.75405753
0.75733703
0.75916636
0.76045239
INFO - Training [40][  180/  196]   Loss 0.369455   Top1 87.545573   Top5 98.715278   BatchTime 0.355929   LR 0.001034
0.76687908
0.76805395
0.77391803
0.77520329
0.77570808
0.77620465
0.77616769
0.77635294
0.77645433
0.77602917
0.77577418
0.77586484
0.77652889
0.77648854
********************pre-trained*****************
INFO - ==> Top1: 87.542    Top5: 98.700    Loss: 0.370
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [40][   20/   40]   Loss 0.423851   Top1 87.832031   Top5 99.511719   BatchTime 0.128252
features.0.conv.0 tensor(0.4479)
features.0.conv.3 tensor(0.3066)
features.1.conv.0 tensor(0.0130)
features.1.conv.3 tensor(0.0799)
features.1.conv.6 tensor(0.0464)
features.2.conv.0 tensor(0.0298)
features.2.conv.3 tensor(0.0633)
features.2.conv.6 tensor(0.0828)
features.3.conv.0 tensor(0.0171)
features.3.conv.3 tensor(0.0478)
features.3.conv.6 tensor(0.0328)
features.4.conv.0 tensor(0.0317)
features.4.conv.3 tensor(0.0932)
features.4.conv.6 tensor(0.0850)
features.5.conv.0 tensor(0.0290)
features.5.conv.3 tensor(0.0723)
features.5.conv.6 tensor(0.1104)
features.6.conv.0 tensor(0.0286)
features.6.conv.3 tensor(0.0480)
features.6.conv.6 tensor(0.0474)
features.7.conv.0 tensor(0.0599)
features.7.conv.3 tensor(0.1264)
features.7.conv.6 tensor(0.1051)
features.8.conv.0 tensor(0.0779)
features.8.conv.3 tensor(0.1163)
features.8.conv.6 tensor(0.1189)
features.9.conv.0 tensor(0.0752)
features.9.conv.3 tensor(0.1424)
features.9.conv.6 tensor(0.1684)
features.10.conv.0 tensor(0.0327)
features.10.conv.3 tensor(0.0897)
features.10.conv.6 tensor(0.1501)
features.11.conv.0 tensor(0.5289)
features.11.conv.3 tensor(0.1551)
features.11.conv.6 tensor(0.5530)
features.12.conv.0 tensor(0.4426)
features.12.conv.3 tensor(0.1549)
features.12.conv.6 tensor(0.7095)
features.13.conv.0 tensor(0.1293)
features.13.conv.3 tensor(0.1291)
features.13.conv.6 tensor(0.1381)
features.14.conv.0 tensor(0.8793)
features.14.conv.3 tensor(0.0748)
features.14.conv.6 tensor(0.9843)
features.15.conv.0 tensor(0.9372)
features.15.conv.3 tensor(0.0622)
features.15.conv.6 tensor(0.9770)
features.16.conv.0 tensor(0.2253)
features.16.conv.3 tensor(0.1205)
features.16.conv.6 tensor(0.2695)
conv.0 tensor(0.1536)
tensor(935249.) 2188896.0
INFO - Validation [40][   40/   40]   Loss 0.406807   Top1 88.200000   Top5 99.640000   BatchTime 0.091851
INFO - ==> Top1: 88.200    Top5: 99.640    Loss: 0.407
INFO - ==> Sparsity : 0.427
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
0.77669400
0.77754694
0.77897871
0.78228253
0.78359503
0.78324813
0.78330040
0.78343403
0.78337061
0.78332376
0.78373224
0.78351039
0.78329355
0.78342301
0.78362614
0.78387105
0.78408599
0.78473890
INFO - Training [41][   20/  196]   Loss 0.387743   Top1 86.621094   Top5 98.261719   BatchTime 0.448203   LR 0.001027
0.78529370
0.78557944
0.78605384
0.78652292
0.78658581
0.78678477
0.78682774
0.78700119
0.78668547
0.78663784
0.78657717
0.78647202
0.78569841
0.78484732
0.78421265
0.78369504
0.78314918
0.78241020
0.78187358
0.78126627
0.78082758
0.78016448
INFO - Training [41][   40/  196]   Loss 0.395443   Top1 86.562500   Top5 98.378906   BatchTime 0.408489   LR 0.001023
0.77937776
0.77871448
0.77813202
0.77795678
0.77769917
0.77719182
0.77688575
0.77642745
0.77574164
0.77527648
0.77457160
0.77406985
0.77339602
0.77292901
0.77281243
0.77272934
0.77258837
0.77255124
0.77248555
0.77256089
0.77273011
0.77245969
INFO - Training [41][   60/  196]   Loss 0.382967   Top1 87.070312   Top5 98.541667   BatchTime 0.392025   LR 0.001020
0.77252907
0.77266109
0.77261382
0.77277958
0.77308106
0.77317077
0.77308446
0.77317768
0.77335864
0.77313662
0.77307850
0.77280366
0.77264613
0.77285916
0.77295178
0.77308685
INFO - Training [41][   80/  196]   Loss 0.377721   Top1 87.192383   Top5 98.710938   BatchTime 0.387104   LR 0.001016
0.77332342
0.77352881
0.77351046
0.77356607
0.77340293
0.77339411
0.77348667
0.77364928
0.77366167
0.77386850
0.77358353
0.77347183
0.77349424
0.77354449
0.77354640
0.77374953
0.77562714
0.77629572
0.77631158
0.77601814
0.77563524
0.77547491
INFO - Training [41][  100/  196]   Loss 0.371115   Top1 87.394531   Top5 98.726562   BatchTime 0.383565   LR 0.001012
0.77525240
0.77476937
0.77472979
0.77407360
0.77333403
0.77317697
0.77295357
0.77300453
0.77292347
0.77300149
0.77282816
0.77288842
0.77280426
0.77262133
0.77263957
0.77273524
0.77248061
0.77187681
0.77127576
0.77034396
0.76988828
0.76927185
INFO - Training [41][  120/  196]   Loss 0.364147   Top1 87.623698   Top5 98.795573   BatchTime 0.380050   LR 0.001008
0.76887608
0.76850080
0.76772231
0.76688707
0.76631373
0.76577264
0.76578367
0.76594770
0.76642424
0.76703161
0.76749688
0.76752579
0.76733327
0.76729190
0.76737595
0.76983005
0.77067220
INFO - Training [41][  140/  196]   Loss 0.364735   Top1 87.603237   Top5 98.819754   BatchTime 0.378942   LR 0.001004
0.77024364
0.76978743
0.76959401
0.76928604
0.76849884
0.76761729
0.76681256
0.76624495
0.76597220
0.76557171
0.76541126
0.76514965
0.76511258
0.76515490
0.76515806
0.76473415
0.76449436
0.76441556
0.76429862
0.76459879
0.76457620
0.76456457
0.76439232
0.76468825
INFO - Training [41][  160/  196]   Loss 0.365639   Top1 87.636719   Top5 98.798828   BatchTime 0.372431   LR 0.001000
0.76572508
0.76676065
0.76776761
0.76908022
0.76907617
0.76927227
0.76973206
0.77006656
0.77030140
0.77034432
0.77022898
0.77271271
0.77222896
0.77163988
0.77100289
INFO - Training [41][  180/  196]   Loss 0.368533   Top1 87.545573   Top5 98.745660   BatchTime 0.360876   LR 0.000996
0.77061599
0.77021122
0.77974546
0.77922493
0.77905744
0.77896285
0.77872884
0.77853405
0.77823639
0.77788347
0.77739626
0.77688664
0.77639729
0.77599543
0.77567643
0.77540690
0.77467680
0.77426732
********************pre-trained*****************
INFO - ==> Top1: 87.586    Top5: 98.740    Loss: 0.367
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [41][   20/   40]   Loss 0.351634   Top1 89.160156   Top5 99.609375   BatchTime 0.127697
features.0.conv.0 tensor(0.4688)
features.0.conv.3 tensor(0.3516)
features.1.conv.0 tensor(0.0156)
features.1.conv.3 tensor(0.0775)
features.1.conv.6 tensor(0.0503)
features.2.conv.0 tensor(0.0214)
features.2.conv.3 tensor(0.0571)
features.2.conv.6 tensor(0.0830)
features.3.conv.0 tensor(0.0208)
features.3.conv.3 tensor(0.0455)
features.3.conv.6 tensor(0.0306)
features.4.conv.0 tensor(0.0319)
features.4.conv.3 tensor(0.0932)
features.4.conv.6 tensor(0.0850)
features.5.conv.0 tensor(0.0303)
features.5.conv.3 tensor(0.0671)
features.5.conv.6 tensor(0.0653)
features.6.conv.0 tensor(0.0303)
features.6.conv.3 tensor(0.0509)
features.6.conv.6 tensor(0.0465)
features.7.conv.0 tensor(0.0662)
features.7.conv.3 tensor(0.1256)
features.7.conv.6 tensor(0.1183)
features.8.conv.0 tensor(0.0669)
features.8.conv.3 tensor(0.1152)
features.8.conv.6 tensor(0.0857)
features.9.conv.0 tensor(0.0712)
features.9.conv.3 tensor(0.1467)
features.9.conv.6 tensor(0.2327)
features.10.conv.0 tensor(0.0350)
features.10.conv.3 tensor(0.0920)
features.10.conv.6 tensor(0.0788)
features.11.conv.0 tensor(0.5357)
features.11.conv.3 tensor(0.1586)
features.11.conv.6 tensor(0.5663)
features.12.conv.0 tensor(0.2606)
features.12.conv.3 tensor(0.1584)
features.12.conv.6 tensor(0.6858)
features.13.conv.0 tensor(0.1092)
features.13.conv.3 tensor(0.1289)
features.13.conv.6 tensor(0.1407)
features.14.conv.0 tensor(0.8829)
features.14.conv.3 tensor(0.0729)
features.14.conv.6 tensor(0.9852)
features.15.conv.0 tensor(0.9387)
features.15.conv.3 tensor(0.0626)
features.15.conv.6 tensor(0.9772)
features.16.conv.0 tensor(0.2300)
features.16.conv.3 tensor(0.1221)
features.16.conv.6 tensor(0.1976)
conv.0 tensor(0.1817)
tensor(913341.) 2188896.0
INFO - Validation [41][   40/   40]   Loss 0.332117   Top1 89.480000   Top5 99.680000   BatchTime 0.091876
INFO - ==> Top1: 89.480    Top5: 99.680    Loss: 0.332
INFO - ==> Sparsity : 0.417
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
0.77418327
0.77405560
0.77361286
0.77294505
0.77255368
0.77271336
0.77296013
0.77315813
0.77314806
0.77308559
0.77295613
0.77274185
0.77227551
0.77161968
0.77108550
0.77102238
0.77104414
0.77136421
0.77187073
0.77229488
INFO - Training [42][   20/  196]   Loss 0.379094   Top1 87.050781   Top5 98.203125   BatchTime 0.432268   LR 0.000988
0.77243203
0.77263629
0.77286148
0.77480316
0.77967042
0.77879113
0.77814633
0.77760673
0.77760619
0.77779144
0.77740258
0.77750701
0.77743763
0.77752662
0.77736050
0.77722514
0.77703440
0.77725476
0.77735752
0.77749652
0.77725476
0.77730608
0.77763915
INFO - Training [42][   40/  196]   Loss 0.388167   Top1 86.865234   Top5 98.281250   BatchTime 0.394520   LR 0.000984
0.77764553
0.77771783
0.77785963
0.77771425
0.77743465
0.77684486
0.77640331
0.77573109
0.77484941
0.77415401
0.77910513
0.77815527
0.77758914
0.77722830
0.77689016
0.77719152
INFO - Training [42][   60/  196]   Loss 0.377504   Top1 87.265625   Top5 98.424479   BatchTime 0.387524   LR 0.000980
0.77723080
0.77691054
0.77698344
0.77732766
0.77735496
0.77689260
0.77639419
0.77623320
0.77629417
0.77567059
0.77488375
0.77465999
0.77402472
0.77365720
0.77336210
0.77314866
0.77370238
0.77465725
0.77593052
0.77927071
0.78051329
INFO - Training [42][   80/  196]   Loss 0.375064   Top1 87.441406   Top5 98.574219   BatchTime 0.386311   LR 0.000976
0.78123134
0.78244650
0.78363991
0.78581554
0.78795874
0.78791595
0.78807354
0.78806430
0.78816569
0.78793705
0.78768909
0.78746086
0.78753126
0.78738910
0.78725356
0.78710634
0.78691328
0.78684187
0.78671414
0.78622139
0.78577006
0.78530461
INFO - Training [42][  100/  196]   Loss 0.369318   Top1 87.589844   Top5 98.636719   BatchTime 0.381562   LR 0.000972
0.78465801
0.78429949
0.78421623
0.78400254
0.78375739
0.78332764
0.78299379
0.78197366
0.78136021
0.78040737
0.77997905
0.77937049
0.77892452
0.77822477
0.77823180
0.78013027
0.78003758
0.77931654
0.77859724
0.77829415
INFO - Training [42][  120/  196]   Loss 0.366286   Top1 87.613932   Top5 98.723958   BatchTime 0.382406   LR 0.000968
0.77804506
0.77789587
0.77772367
0.77758062
0.77711648
0.77674502
0.77634859
0.77629268
0.77604276
0.77568752
0.77517170
0.77479488
0.77471554
0.77437586
0.77418828
0.77395427
0.77381289
0.77376264
0.77292508
0.77292180
INFO - Training [42][  140/  196]   Loss 0.367340   Top1 87.594866   Top5 98.791853   BatchTime 0.386486   LR 0.000964
0.77311563
0.77275735
0.77256596
0.77241278
0.77250046
0.77280605
0.77309465
0.77333647
0.77336627
0.77338940
0.77312177
0.77269965
0.77247608
0.77253771
0.77254546
0.77234030
0.77220398
INFO - Training [42][  160/  196]   Loss 0.369009   Top1 87.536621   Top5 98.791504   BatchTime 0.383333   LR 0.000959
0.77207333
0.77194864
0.77178895
0.77170765
0.77174878
0.77157319
0.77147734
0.77149194
0.77123922
0.77118891
0.77091426
0.77059472
0.77005678
0.76962781
0.76944989
0.76898527
0.76881468
0.76844746
0.76834863
0.76823109
0.76811892
INFO - Training [42][  180/  196]   Loss 0.369152   Top1 87.565104   Top5 98.730469   BatchTime 0.372008   LR 0.000955
0.76789349
0.76763344
0.76741159
0.76725501
0.76727891
0.76719034
0.76717526
0.76706332
0.76691687
0.76800269
0.77025121
0.77224398
0.77186114
0.77096850
0.76982141
0.76892263
********************pre-trained*****************
INFO - ==> Top1: 87.688    Top5: 98.732    Loss: 0.366
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [42][   20/   40]   Loss 0.323709   Top1 89.433594   Top5 99.667969   BatchTime 0.125810
INFO - Validation [42][   40/   40]   Loss 0.312252   Top1 89.410000   Top5 99.690000   BatchTime 0.088309
features.0.conv.0 tensor(0.4722)
features.0.conv.3 tensor(0.3145)
features.1.conv.0 tensor(0.0150)
features.1.conv.3 tensor(0.0845)
features.1.conv.6 tensor(0.0460)
features.2.conv.0 tensor(0.0229)
features.2.conv.3 tensor(0.0556)
features.2.conv.6 tensor(0.0825)
features.3.conv.0 tensor(0.0194)
features.3.conv.3 tensor(0.0502)
features.3.conv.6 tensor(0.0267)
features.4.conv.0 tensor(0.0337)
features.4.conv.3 tensor(0.0932)
features.4.conv.6 tensor(0.0815)
features.5.conv.0 tensor(0.0290)
features.5.conv.3 tensor(0.0642)
features.5.conv.6 tensor(0.0615)
features.6.conv.0 tensor(0.0280)
features.6.conv.3 tensor(0.0457)
features.6.conv.6 tensor(0.0472)
features.7.conv.0 tensor(0.0588)
features.7.conv.3 tensor(0.1233)
features.7.conv.6 tensor(0.1231)
features.8.conv.0 tensor(0.0772)
features.8.conv.3 tensor(0.1178)
features.8.conv.6 tensor(0.1128)
features.9.conv.0 tensor(0.0717)
features.9.conv.3 tensor(0.1470)
features.9.conv.6 tensor(0.1689)
features.10.conv.0 tensor(0.0312)
features.10.conv.3 tensor(0.0917)
features.10.conv.6 tensor(0.0689)
features.11.conv.0 tensor(0.5337)
features.11.conv.3 tensor(0.1553)
features.11.conv.6 tensor(0.5542)
features.12.conv.0 tensor(0.2753)
features.12.conv.3 tensor(0.1605)
features.12.conv.6 tensor(0.7219)
features.13.conv.0 tensor(0.1101)
features.13.conv.3 tensor(0.1281)
features.13.conv.6 tensor(0.3052)
features.14.conv.0 tensor(0.8859)
features.14.conv.3 tensor(0.0713)
features.14.conv.6 tensor(0.9829)
features.15.conv.0 tensor(0.9403)
features.15.conv.3 tensor(0.0639)
features.15.conv.6 tensor(0.9779)
features.16.conv.0 tensor(0.2375)
features.16.conv.3 tensor(0.1221)
features.16.conv.6 tensor(0.3787)
conv.0 tensor(0.1459)
tensor(971867.) 2188896.0
INFO - ==> Top1: 89.410    Top5: 99.690    Loss: 0.312
INFO - ==> Sparsity : 0.444
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
0.77022511
0.76979703
0.76949465
0.76895136
0.76895416
0.76920754
0.76905531
0.76928854
0.76940495
0.76959449
0.76977021
0.77007455
0.77034181
0.77063531
0.77073145
0.77072603
0.77084720
0.77071023
0.77067047
0.77061868
INFO - Training [43][   20/  196]   Loss 0.383858   Top1 87.441406   Top5 98.339844   BatchTime 0.437784   LR 0.000947
0.77050710
0.77050644
0.76990432
0.76944882
0.76905352
0.76854587
0.76831931
0.76780188
0.76753837
0.76753306
0.76711482
0.76651996
0.76607877
0.76567042
0.76556134
0.76487803
0.76459116
0.76418060
0.76362216
0.76309806
0.76297283
INFO - Training [43][   40/  196]   Loss 0.374310   Top1 87.509766   Top5 98.466797   BatchTime 0.408490   LR 0.000943
0.76268601
0.76215971
0.76153362
0.76086998
0.76078063
0.76018983
0.75948220
0.75828880
0.75692052
0.75680190
0.75722843
0.75789094
0.75904322
0.76029652
0.76149422
0.76262891
0.76664066
0.76633728
0.76582175
0.76551509
0.76536673
INFO - Training [43][   60/  196]   Loss 0.370028   Top1 87.688802   Top5 98.522135   BatchTime 0.404594   LR 0.000939
0.76517725
0.76436818
0.76374233
0.76324129
0.76261657
0.76159805
0.76120579
0.76080406
0.76043695
0.76001406
0.75937051
0.75877625
0.75886464
0.75886428
0.75864482
0.75847775
INFO - Training [43][   80/  196]   Loss 0.361220   Top1 87.978516   Top5 98.671875   BatchTime 0.394385   LR 0.000934
0.75854164
0.75833333
0.75822937
0.75803208
0.75788665
0.75795984
0.75797081
0.75727916
0.76131588
0.75948727
0.75522852
0.75047272
0.74738109
0.75542790
0.75511396
0.75534517
0.75458235
0.75559205
0.75584245
0.75821304
0.76088572
0.76200038
INFO - Training [43][  100/  196]   Loss 0.355867   Top1 88.164062   Top5 98.722656   BatchTime 0.388523   LR 0.000930
0.76305854
0.76473629
0.76890224
0.77037853
0.77117270
0.77220589
0.77241135
0.77304327
0.77418053
0.77515763
0.77606130
0.77596641
0.77605480
0.77628452
0.77616930
0.77619588
0.77641028
0.77652550
0.77655959
0.77623451
INFO - Training [43][  120/  196]   Loss 0.352738   Top1 88.297526   Top5 98.753255   BatchTime 0.386052   LR 0.000926
0.77636713
0.77636153
0.77632707
0.77617270
0.77623791
0.77657968
0.77694893
0.77705967
0.77742541
0.78034681
0.78004491
0.78028160
0.78074521
0.78096157
0.78073961
0.77973968
0.77960587
0.77976346
0.77992684
0.78037298
0.78090692
INFO - Training [43][  140/  196]   Loss 0.354718   Top1 88.247768   Top5 98.833705   BatchTime 0.387760   LR 0.000921
0.78276914
0.78306997
0.78318238
0.78337854
0.78338534
0.78381741
0.78382891
0.78386003
0.78371239
0.78348309
0.78333336
0.78309619
0.78307277
0.78291893
0.78253222
0.78250366
INFO - Training [43][  160/  196]   Loss 0.355504   Top1 88.171387   Top5 98.840332   BatchTime 0.383561   LR 0.000917
0.78213269
0.78178978
0.78156263
0.78103507
0.78042829
0.78014028
0.77978349
0.77937418
0.77878422
0.77812475
0.77807283
0.77740121
0.77656782
0.77598727
0.77563477
0.77493322
0.77417105
0.77376711
0.77316731
0.77290940
0.77332538
0.77240425
0.77150369
0.77099866
0.77031171
0.76926082
INFO - Training [43][  180/  196]   Loss 0.357182   Top1 88.101128   Top5 98.773872   BatchTime 0.376250   LR 0.000912
0.76890498
0.76887709
0.76920408
0.76936340
0.76895881
0.76881325
0.76800245
0.76559371
0.76314026
0.76088560
0.75847524
0.75612319
INFO - ==> Top1: 88.066    Top5: 98.758    Loss: 0.357
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.75410998
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [43][   20/   40]   Loss 1.030390   Top1 80.527344   Top5 98.339844   BatchTime 0.127357
INFO - Validation [43][   40/   40]   Loss 1.034757   Top1 80.110000   Top5 98.300000   BatchTime 0.092859
INFO - ==> Top1: 80.110    Top5: 98.300    Loss: 1.035
INFO - ==> Sparsity : 0.514
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4757)
features.0.conv.3 tensor(0.3184)
features.1.conv.0 tensor(0.0130)
features.1.conv.3 tensor(0.0787)
features.1.conv.6 tensor(0.0425)
features.2.conv.0 tensor(0.0243)
features.2.conv.3 tensor(0.0563)
features.2.conv.6 tensor(0.0816)
features.3.conv.0 tensor(0.0205)
features.3.conv.3 tensor(0.0478)
features.3.conv.6 tensor(0.0243)
features.4.conv.0 tensor(0.0304)
features.4.conv.3 tensor(0.0926)
features.4.conv.6 tensor(0.0846)
features.5.conv.0 tensor(0.0332)
features.5.conv.3 tensor(0.0654)
features.5.conv.6 tensor(0.0666)
features.6.conv.0 tensor(0.0247)
features.6.conv.3 tensor(0.0463)
features.6.conv.6 tensor(0.0456)
features.7.conv.0 tensor(0.0616)
features.7.conv.3 tensor(0.1253)
features.7.conv.6 tensor(0.0967)
features.8.conv.0 tensor(0.0763)
features.8.conv.3 tensor(0.1134)
features.8.conv.6 tensor(0.2316)
features.9.conv.0 tensor(0.0667)
features.9.conv.3 tensor(0.1481)
features.9.conv.6 tensor(0.1332)
features.10.conv.0 tensor(0.0304)
features.10.conv.3 tensor(0.0894)
features.10.conv.6 tensor(0.0873)
features.11.conv.0 tensor(0.5360)
features.11.conv.3 tensor(0.1547)
features.11.conv.6 tensor(0.5447)
features.12.conv.0 tensor(0.3264)
features.12.conv.3 tensor(0.1559)
features.12.conv.6 tensor(0.7206)
features.13.conv.0 tensor(0.1066)
features.13.conv.3 tensor(0.1285)
features.13.conv.6 tensor(0.0992)
features.14.conv.0 tensor(0.8880)
features.14.conv.3 tensor(0.0719)
features.14.conv.6 tensor(0.9840)
features.15.conv.0 tensor(0.9414)
features.15.conv.3 tensor(0.0632)
features.15.conv.6 tensor(0.9755)
features.16.conv.0 tensor(0.2385)
features.16.conv.3 tensor(0.1205)
features.16.conv.6 tensor(0.9603)
conv.0 tensor(0.1190)
tensor(1125053.) 2188896.0
0.75345480
0.75322968
0.75346297
0.75323701
0.75354016
0.75380516
0.75405729
0.75448704
0.75558424
0.75708759
0.75803012
0.75785381
0.75852472
0.75817007
0.75679553
0.75565624
0.75525904
INFO - Training [44][   20/  196]   Loss 0.376418   Top1 86.914062   Top5 98.183594   BatchTime 0.410827   LR 0.000904
0.75458008
0.75385392
0.75312078
0.75313848
0.75313187
0.75314969
0.75404638
0.75560266
0.75733542
0.76172191
0.76247126
0.76227129
0.76206964
0.76156384
0.76039100
0.75910634
0.76080239
0.76135743
0.76018578
0.75994831
0.76008934
0.76070082
INFO - Training [44][   40/  196]   Loss 0.379299   Top1 87.275391   Top5 98.408203   BatchTime 0.388713   LR 0.000900
0.76006758
0.75959074
0.75933826
0.75956118
0.76039904
0.76052690
0.76045376
0.76049018
0.76270163
0.76337028
0.76454633
0.76530927
0.76581496
0.76634645
0.76661378
0.76735198
0.76911479
0.77261257
0.77259076
0.77280241
0.77273488
INFO - Training [44][   60/  196]   Loss 0.369977   Top1 87.447917   Top5 98.554688   BatchTime 0.388742   LR 0.000895
0.77276599
0.77288270
0.77304852
0.77315134
0.77282894
0.77281541
0.77275908
0.77242357
0.77263033
0.77238244
0.77204895
0.77192855
0.77188885
0.77178437
0.77177262
0.77141970
0.77181202
0.77162123
0.77164567
0.77185619
0.77178836
0.77183938
INFO - Training [44][   80/  196]   Loss 0.370922   Top1 87.441406   Top5 98.701172   BatchTime 0.381709   LR 0.000891
0.77162206
0.77151728
0.77134424
0.77125442
0.77102166
0.77112776
0.77130663
0.77139509
0.77226400
0.77322376
0.77451003
0.77545762
0.77742767
0.78218830
0.78230619
0.78232759
0.78188628
INFO - Training [44][  100/  196]   Loss 0.364726   Top1 87.648438   Top5 98.750000   BatchTime 0.378190   LR 0.000886
0.78194016
0.78181398
0.78158492
0.78154230
0.78153074
0.78147000
0.78126043
0.78138351
0.78124374
0.78134245
0.78152412
0.78135353
0.78133607
0.78141505
0.78158778
0.78156114
0.78143197
0.78146470
0.78166479
0.78129500
0.78086364
0.78072202
INFO - Training [44][  120/  196]   Loss 0.360201   Top1 87.796224   Top5 98.818359   BatchTime 0.374706   LR 0.000882
0.78050023
0.78047943
0.78071851
0.78046864
0.78025031
0.78036940
0.78060490
0.78048933
0.78068757
0.78091782
0.78126532
0.78162062
0.78149974
0.78170943
0.78170723
0.78114194
0.78120512
0.78129512
0.78128523
0.78141636
0.78144646
INFO - Training [44][  140/  196]   Loss 0.358996   Top1 87.854353   Top5 98.881138   BatchTime 0.376330   LR 0.000877
0.78139812
0.78160423
0.78288132
0.78267658
0.78255969
0.78259474
0.78213680
0.78188890
0.78207904
0.78159046
0.78120649
0.78087336
0.78063661
0.78045386
0.78040057
0.78005832
0.77981836
INFO - Training [44][  160/  196]   Loss 0.359862   Top1 87.827148   Top5 98.852539   BatchTime 0.372827   LR 0.000873
0.77968252
0.77950042
0.77906567
0.77873760
0.77849883
0.77830684
0.77814686
0.77792776
0.77800709
0.77779800
0.77753961
0.77727091
0.77693594
0.77677232
0.77666014
0.77664632
0.77650833
0.77625322
0.77585489
INFO - Training [44][  180/  196]   Loss 0.361471   Top1 87.773438   Top5 98.789062   BatchTime 0.367833   LR 0.000868
0.77531207
0.77448940
0.77320570
0.77281386
0.77208501
0.77161473
0.77095556
0.77026606
0.76958054
0.76880121
0.76796532
0.76722044
0.76655608
0.76588398
0.76534081
0.76468712
INFO - ==> Top1: 87.862    Top5: 98.786    Loss: 0.359
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.76398033
0.76340818
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [44][   20/   40]   Loss 0.303748   Top1 90.156250   Top5 99.667969   BatchTime 0.131039
INFO - Validation [44][   40/   40]   Loss 0.300591   Top1 90.050000   Top5 99.750000   BatchTime 0.095060
INFO - ==> Top1: 90.050    Top5: 99.750    Loss: 0.301
INFO - ==> Sparsity : 0.419
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4688)
features.0.conv.3 tensor(0.3359)
features.1.conv.0 tensor(0.0169)
features.1.conv.3 tensor(0.0822)
features.1.conv.6 tensor(0.0399)
features.2.conv.0 tensor(0.0255)
features.2.conv.3 tensor(0.0525)
features.2.conv.6 tensor(0.0787)
features.3.conv.0 tensor(0.0174)
features.3.conv.3 tensor(0.0494)
features.3.conv.6 tensor(0.0239)
features.4.conv.0 tensor(0.0347)
features.4.conv.3 tensor(0.0880)
features.4.conv.6 tensor(0.0856)
features.5.conv.0 tensor(0.0337)
features.5.conv.3 tensor(0.0642)
features.5.conv.6 tensor(0.0638)
features.6.conv.0 tensor(0.0231)
features.6.conv.3 tensor(0.0446)
features.6.conv.6 tensor(0.0464)
features.7.conv.0 tensor(0.0597)
features.7.conv.3 tensor(0.1233)
features.7.conv.6 tensor(0.1655)
features.8.conv.0 tensor(0.0793)
features.8.conv.3 tensor(0.1108)
features.8.conv.6 tensor(0.2215)
features.9.conv.0 tensor(0.0643)
features.9.conv.3 tensor(0.1470)
features.9.conv.6 tensor(0.2167)
features.10.conv.0 tensor(0.0326)
features.10.conv.3 tensor(0.0877)
features.10.conv.6 tensor(0.1035)
features.11.conv.0 tensor(0.5427)
features.11.conv.3 tensor(0.1499)
features.11.conv.6 tensor(0.6074)
features.12.conv.0 tensor(0.3339)
features.12.conv.3 tensor(0.1557)
features.12.conv.6 tensor(0.7083)
features.13.conv.0 tensor(0.1120)
features.13.conv.3 tensor(0.1285)
features.13.conv.6 tensor(0.1077)
features.14.conv.0 tensor(0.8902)
features.14.conv.3 tensor(0.0708)
features.14.conv.6 tensor(0.9836)
features.15.conv.0 tensor(0.9421)
features.15.conv.3 tensor(0.0620)
features.15.conv.6 tensor(0.9760)
features.16.conv.0 tensor(0.2401)
features.16.conv.3 tensor(0.1203)
features.16.conv.6 tensor(0.1953)
conv.0 tensor(0.1629)
tensor(917424.) 2188896.0
0.76270258
0.76219630
0.76166028
0.76068950
0.75913727
0.75811273
0.75769567
0.75747871
0.75722408
0.75690722
0.75648129
0.75612581
0.75579977
0.75519097
0.75471598
0.75415784
0.75363874
INFO - Training [45][   20/  196]   Loss 0.363210   Top1 87.617188   Top5 98.437500   BatchTime 0.423156   LR 0.000860
0.75335395
0.75307727
0.75291628
0.75234061
0.75155395
0.75120318
0.75062239
0.74966455
0.74838752
0.74746829
0.74663913
0.74599481
0.74565238
0.74539995
0.74507064
0.74473298
0.74416471
0.74374908
0.74355048
0.74331713
0.74316293
INFO - Training [45][   40/  196]   Loss 0.368103   Top1 87.500000   Top5 98.632812   BatchTime 0.401835   LR 0.000855
0.74315888
0.74339449
0.74363953
0.74488795
0.74619317
0.74617344
0.74646723
0.74648416
0.74634492
0.74657667
0.74616838
0.74578393
0.74533159
0.74482191
0.74396050
0.74388933
0.74365419
0.74348569
0.74353087
0.74354160
0.74343890
0.74343258
INFO - Training [45][   60/  196]   Loss 0.365043   Top1 87.617188   Top5 98.658854   BatchTime 0.393179   LR 0.000850
0.74365741
0.74388629
0.74452025
0.74548870
0.74662030
0.75226402
0.75325596
0.75249124
0.75222617
0.75226158
0.75229794
0.75252753
0.75261265
0.75262910
0.75279617
0.75276995
0.75268668
INFO - Training [45][   80/  196]   Loss 0.360616   Top1 87.812500   Top5 98.828125   BatchTime 0.382949   LR 0.000846
0.75364238
0.75545985
0.75533080
0.75524127
0.75506681
0.75495392
0.75489455
0.75490940
0.75472522
0.75468874
0.75464308
0.75460219
0.75461841
0.75442153
0.75434858
0.75429690
0.75406885
0.75384355
0.75348485
0.75335342
0.75314510
0.75308502
0.75308257
0.75306743
0.75301373
0.75271517
0.75256872
0.75241071
0.75234586
0.75224537
0.75219876
0.75195783
0.75166482
0.75154763
0.75146061
0.75129056
0.75125986
0.75117403
0.75104141
0.75091976
0.75075036
0.75078428
0.75077093
0.75093383
0.75515836
INFO - Training [45][  100/  196]   Loss 0.353302   Top1 88.054688   Top5 98.890625   BatchTime 0.378482   LR 0.000841
INFO - Training [45][  120/  196]   Loss 0.351978   Top1 88.108724   Top5 98.938802   BatchTime 0.375211   LR 0.000836
0.75481236
0.75421244
0.75383675
0.75363880
0.75324744
0.75287861
0.75252110
0.75236368
0.75212353
0.75193459
0.75196558
0.75198615
0.75228536
0.75242066
0.75268817
INFO - Training [45][  140/  196]   Loss 0.351688   Top1 88.191964   Top5 98.995536   BatchTime 0.375720   LR 0.000832
0.75285262
0.75306177
0.75295299
0.75281972
0.75281042
0.75299090
0.75285298
0.75264245
0.75243014
0.75218850
0.75201100
0.75203949
0.75213820
0.75232989
0.75251782
0.75270396
0.75288188
0.75309384
0.75329053
0.75358737
0.75379747
0.75403267
0.75413322
0.75426060
INFO - Training [45][  160/  196]   Loss 0.351355   Top1 88.176270   Top5 98.972168   BatchTime 0.370724   LR 0.000827
0.75445569
0.75450885
0.75439185
0.75442308
0.75429112
0.75416452
0.75423688
0.75424600
0.75386387
0.75395828
0.75378811
0.75386977
0.75395650
0.75375861
0.75363600
0.75329548
0.75283211
INFO - Training [45][  180/  196]   Loss 0.351322   Top1 88.168403   Top5 98.927951   BatchTime 0.368759   LR 0.000822
0.75247079
0.75224000
0.75229007
0.75260025
0.75296146
0.75330758
0.75315744
0.75287396
0.75252974
0.75215667
0.75207859
0.75191903
0.75168079
0.75143379
0.75114948
0.75072080
INFO - ==> Top1: 88.210    Top5: 98.916    Loss: 0.351
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.75016975
0.74947923
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [45][   20/   40]   Loss 0.424574   Top1 86.718750   Top5 99.257812   BatchTime 0.129349
INFO - Validation [45][   40/   40]   Loss 0.422344   Top1 86.590000   Top5 99.250000   BatchTime 0.092184
INFO - ==> Top1: 86.590    Top5: 99.250    Loss: 0.422
INFO - ==> Sparsity : 0.460
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4444)
features.0.conv.3 tensor(0.3555)
features.1.conv.0 tensor(0.0176)
features.1.conv.3 tensor(0.0868)
features.1.conv.6 tensor(0.0430)
features.2.conv.0 tensor(0.0269)
features.2.conv.3 tensor(0.0556)
features.2.conv.6 tensor(0.0802)
features.3.conv.0 tensor(0.0203)
features.3.conv.3 tensor(0.0494)
features.3.conv.6 tensor(0.0265)
features.4.conv.0 tensor(0.0379)
features.4.conv.3 tensor(0.0868)
features.4.conv.6 tensor(0.0819)
features.5.conv.0 tensor(0.0415)
features.5.conv.3 tensor(0.0654)
features.5.conv.6 tensor(0.0713)
features.6.conv.0 tensor(0.0239)
features.6.conv.3 tensor(0.0463)
features.6.conv.6 tensor(0.0478)
features.7.conv.0 tensor(0.0511)
features.7.conv.3 tensor(0.1221)
features.7.conv.6 tensor(0.1033)
features.8.conv.0 tensor(0.0810)
features.8.conv.3 tensor(0.1117)
features.8.conv.6 tensor(0.1693)
features.9.conv.0 tensor(0.0729)
features.9.conv.3 tensor(0.1453)
features.9.conv.6 tensor(0.2550)
features.10.conv.0 tensor(0.0363)
features.10.conv.3 tensor(0.0926)
features.10.conv.6 tensor(0.0924)
features.11.conv.0 tensor(0.5805)
features.11.conv.3 tensor(0.1487)
features.11.conv.6 tensor(0.5718)
features.12.conv.0 tensor(0.3294)
features.12.conv.3 tensor(0.1539)
features.12.conv.6 tensor(0.7027)
features.13.conv.0 tensor(0.1187)
features.13.conv.3 tensor(0.1316)
features.13.conv.6 tensor(0.1916)
features.14.conv.0 tensor(0.8924)
features.14.conv.3 tensor(0.0705)
features.14.conv.6 tensor(0.9848)
features.15.conv.0 tensor(0.9442)
features.15.conv.3 tensor(0.0627)
features.15.conv.6 tensor(0.9785)
features.16.conv.0 tensor(0.2461)
features.16.conv.3 tensor(0.1199)
features.16.conv.6 tensor(0.3372)
conv.0 tensor(0.2582)
tensor(1007879.) 2188896.0
0.74935192
0.74914622
0.74884987
0.74857318
0.74826527
0.74792379
0.74746335
0.74710649
0.75792795
0.75738025
0.75682318
0.75616354
0.75574446
0.75515586
0.75486010
0.75481409
0.75473171
0.75446945
0.75444055
0.75412953
0.75400990
INFO - Training [46][   20/  196]   Loss 0.343886   Top1 88.476562   Top5 98.261719   BatchTime 0.446358   LR 0.000814
0.75398505
0.75394237
0.75388765
0.75392371
0.75381660
0.75359380
0.75359994
0.75410390
0.75414401
0.75352097
0.75315666
0.75304180
0.75268114
0.75180489
0.75134093
0.75092018
INFO - Training [46][   40/  196]   Loss 0.350436   Top1 88.349609   Top5 98.496094   BatchTime 0.414093   LR 0.000809
0.75094086
0.75028354
0.74804497
0.74509722
0.74193335
0.73996443
0.73859060
0.73780304
0.73678172
0.73584735
0.73485672
0.73229784
0.73184663
0.73000377
0.72893673
0.72864544
0.72995085
0.72979563
0.72945976
0.72992867
0.73023450
0.73155493
INFO - Training [46][   60/  196]   Loss 0.350339   Top1 88.326823   Top5 98.541667   BatchTime 0.398133   LR 0.000804
0.73326272
0.73516893
0.73694021
0.73792064
0.74017107
0.74161506
0.74220663
0.74278688
0.74343717
0.74353600
0.74341559
0.74357903
0.74524939
0.74909186
0.75159329
0.75151378
0.75146276
0.75158399
0.75181240
0.75191677
0.75187296
0.75157684
0.75156081
INFO - Training [46][   80/  196]   Loss 0.349701   Top1 88.447266   Top5 98.657227   BatchTime 0.387946   LR 0.000799
0.75196254
0.75245261
0.75395507
0.75435638
0.75473553
0.75688887
0.75718063
0.75748163
0.75768971
0.75818616
0.75808853
0.75833553
0.75856745
0.75864500
0.75872982
0.75880802
INFO - Training [46][  100/  196]   Loss 0.343427   Top1 88.613281   Top5 98.730469   BatchTime 0.384608   LR 0.000794
0.75892621
0.75912535
0.75928092
0.75958186
0.75997645
0.76022464
0.76034951
0.76063985
0.76084405
0.76083124
0.76088768
0.76118726
0.76150614
0.76190960
0.76243025
0.76374823
0.76669717
0.76675785
0.76684976
0.76691866
0.76703393
INFO - Training [46][  120/  196]   Loss 0.342669   Top1 88.590495   Top5 98.785807   BatchTime 0.382176   LR 0.000789
0.76721686
0.76751930
0.76721090
0.76714146
0.76723492
0.76738191
0.76749390
0.76760095
0.76774836
0.76798189
0.76791692
0.76845670
0.76843280
0.76851338
0.76872963
0.76877248
0.76872963
0.76835477
0.76772374
INFO - Training [46][  140/  196]   Loss 0.341659   Top1 88.596540   Top5 98.864397   BatchTime 0.372104   LR 0.000785
0.76736885
0.76731145
0.76727223
0.76722270
0.76707888
0.76673752
0.76643938
0.76613712
0.76587230
0.76568550
0.76554084
0.76531672
0.76498872
0.76479173
0.76461744
0.76440334
0.76413113
0.76379550
0.76332867
0.76241368
INFO - Training [46][  160/  196]   Loss 0.345835   Top1 88.432617   Top5 98.867188   BatchTime 0.365300   LR 0.000780
0.76214612
0.76189572
0.76178521
0.76179838
0.76173037
0.76164299
0.76161051
0.76157731
0.76147252
0.76139909
0.76136404
0.76127410
0.76113141
0.76109535
0.76166135
0.76214546
0.76210767
0.76217854
0.76213723
0.76210046
0.76187998
0.76135534
INFO - Training [46][  180/  196]   Loss 0.346898   Top1 88.363715   Top5 98.823785   BatchTime 0.365458   LR 0.000775
0.76107240
0.76083308
0.76099283
0.76136208
0.76142311
0.76139057
0.76149833
0.76124555
0.76115483
0.76072389
0.76107901
0.76091701
0.76057428
0.76042682
0.75965756
0.75928646
********************pre-trained*****************
INFO - ==> Top1: 88.400    Top5: 98.840    Loss: 0.347
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 0.484382   Top1 84.960938   Top5 99.335938   BatchTime 0.124912
INFO - Validation [46][   40/   40]   Loss 0.471844   Top1 85.310000   Top5 99.350000   BatchTime 0.090351
features.0.conv.0 tensor(0.4271)
features.0.conv.3 tensor(0.3320)
features.1.conv.0 tensor(0.0156)
features.1.conv.3 tensor(0.0880)
features.1.conv.6 tensor(0.0460)
features.2.conv.0 tensor(0.0240)
features.2.conv.3 tensor(0.0563)
features.2.conv.6 tensor(0.0784)
features.3.conv.0 tensor(0.0208)
features.3.conv.3 tensor(0.0502)
features.3.conv.6 tensor(0.0252)
features.4.conv.0 tensor(0.0369)
features.4.conv.3 tensor(0.0868)
features.4.conv.6 tensor(0.0812)
features.5.conv.0 tensor(0.0400)
features.5.conv.3 tensor(0.0648)
features.5.conv.6 tensor(0.0799)
features.6.conv.0 tensor(0.0195)
features.6.conv.3 tensor(0.0503)
features.6.conv.6 tensor(0.0482)
features.7.conv.0 tensor(0.0589)
features.7.conv.3 tensor(0.1230)
features.7.conv.6 tensor(0.0994)
features.8.conv.0 tensor(0.0895)
features.8.conv.3 tensor(0.1123)
features.8.conv.6 tensor(0.1365)
features.9.conv.0 tensor(0.0719)
features.9.conv.3 tensor(0.1484)
features.9.conv.6 tensor(0.2550)
features.10.conv.0 tensor(0.0360)
features.10.conv.3 tensor(0.0920)
features.10.conv.6 tensor(0.0839)
features.11.conv.0 tensor(0.5438)
features.11.conv.3 tensor(0.1510)
features.11.conv.6 tensor(0.5866)
features.12.conv.0 tensor(0.3649)
features.12.conv.3 tensor(0.1541)
features.12.conv.6 tensor(0.6952)
features.13.conv.0 tensor(0.1094)
features.13.conv.3 tensor(0.1306)
features.13.conv.6 tensor(0.2141)
features.14.conv.0 tensor(0.8949)
features.14.conv.3 tensor(0.0721)
features.14.conv.6 tensor(0.9847)
features.15.conv.0 tensor(0.9453)
features.15.conv.3 tensor(0.0609)
features.15.conv.6 tensor(0.9772)
features.16.conv.0 tensor(0.2494)
features.16.conv.3 tensor(0.1208)
features.16.conv.6 tensor(0.3610)
conv.0 tensor(0.1735)
tensor(982422.) 2188896.0
INFO - ==> Top1: 85.310    Top5: 99.350    Loss: 0.472
INFO - ==> Sparsity : 0.449
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
0.75877917
0.75832814
0.75762612
0.75748420
0.75683838
0.75686401
0.75654948
0.75618976
0.75612253
0.75577575
0.75537145
0.75479198
0.75416505
0.75377518
0.75311369
0.75263810
0.75211883
0.75165796
0.75129652
0.75115877
INFO - Training [47][   20/  196]   Loss 0.366254   Top1 87.675781   Top5 98.320312   BatchTime 0.424234   LR 0.000766
0.75078601
0.75042617
0.75004250
0.74961293
0.74930942
0.74897516
0.74846798
0.74777162
0.74702471
0.74653834
0.74610406
0.74570882
0.74530184
0.74513847
0.74539733
0.74540353
0.74542391
0.74537313
0.74602848
0.74652779
INFO - Training [47][   40/  196]   Loss 0.363098   Top1 87.802734   Top5 98.486328   BatchTime 0.407464   LR 0.000761
0.74704516
0.74778062
0.74818188
0.74868470
0.74895656
0.74907655
0.75051934
0.75401491
0.75382483
0.75355619
0.75360310
0.75368154
0.75361347
0.75311190
0.75255620
0.75249821
0.75240177
0.75213486
INFO - Training [47][   60/  196]   Loss 0.352139   Top1 88.151042   Top5 98.613281   BatchTime 0.387974   LR 0.000756
0.75224560
0.75206459
0.75209844
0.75210416
0.75202817
0.75360262
0.75379759
0.75376326
0.75331002
0.75292891
0.75275749
0.75223750
0.75202751
0.75173032
0.75128704
0.75107014
0.75110626
0.75150234
0.75195235
0.75182849
0.75172639
0.75146091
INFO - Training [47][   80/  196]   Loss 0.349395   Top1 88.251953   Top5 98.784180   BatchTime 0.382250   LR 0.000752
0.75122017
0.75135881
0.75154382
0.75165164
0.75181836
0.75191969
0.75201344
0.75187254
0.75156403
0.75145173
0.75137836
0.75129294
0.75126445
0.75118333
0.75115162
0.75116748
0.75131333
0.75135088
0.75145489
0.75131148
0.75128824
INFO - Training [47][  100/  196]   Loss 0.344505   Top1 88.500000   Top5 98.851562   BatchTime 0.379855   LR 0.000747
0.75118661
0.75131774
0.75143820
0.75154507
0.75151825
0.75123060
0.75111783
0.75124103
0.75127590
0.75127375
0.75103217
0.75093526
0.75093663
0.75082177
0.75069642
0.75080466
0.75060135
INFO - Training [47][  120/  196]   Loss 0.341113   Top1 88.668620   Top5 98.929036   BatchTime 0.374942   LR 0.000742
0.75054169
0.75055331
0.75045991
0.75071555
0.75077033
0.75083750
0.75048292
0.75068349
0.75269771
0.75228512
0.75203478
0.75210720
0.75226676
0.75236487
0.75240159
0.75228924
0.75249302
0.75254899
0.75214875
0.75187576
INFO - Training [47][  140/  196]   Loss 0.339875   Top1 88.763951   Top5 98.976004   BatchTime 0.363112   LR 0.000737
0.75172031
0.75161821
0.75145566
0.75131661
0.75104445
0.75061011
0.75021034
0.74993080
0.74977529
0.74948364
0.74934399
0.74908412
0.74917144
0.74899244
0.74877316
0.74868929
0.74873310
0.74885297
0.74893665
INFO - Training [47][  160/  196]   Loss 0.343610   Top1 88.645020   Top5 98.959961   BatchTime 0.359139   LR 0.000732
0.74899584
0.74898261
0.74897146
0.74820381
0.74794525
0.74763948
0.74748969
0.74722630
0.74676257
0.74613965
0.74615043
0.74619251
0.74623096
0.74588966
0.74511385
0.74426895
0.74327153
0.74272096
0.74280459
0.74283630
0.74286908
INFO - Training [47][  180/  196]   Loss 0.344252   Top1 88.602431   Top5 98.938802   BatchTime 0.361814   LR 0.000727
0.74305212
0.74317718
0.74336523
0.74341822
0.74348950
0.74364185
0.74373895
0.74364328
0.74366784
0.74405122
0.75415194
0.75411755
0.75523019
0.75633013
0.75628448
0.75666481
0.75660008
0.75646031
INFO - ==> Top1: 88.602    Top5: 98.916    Loss: 0.344
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 0.330795   Top1 89.648438   Top5 99.648438   BatchTime 0.123937
features.0.conv.0 tensor(0.4132)
features.0.conv.3 tensor(0.3262)
features.1.conv.0 tensor(0.0124)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0417)
features.2.conv.0 tensor(0.0295)
features.2.conv.3 tensor(0.0579)
features.2.conv.6 tensor(0.0775)
features.3.conv.0 tensor(0.0237)
features.3.conv.3 tensor(0.0455)
features.3.conv.6 tensor(0.0224)
features.4.conv.0 tensor(0.0373)
features.4.conv.3 tensor(0.0880)
features.4.conv.6 tensor(0.0806)
features.5.conv.0 tensor(0.0332)
features.5.conv.3 tensor(0.0619)
features.5.conv.6 tensor(0.0879)
features.6.conv.0 tensor(0.0221)
features.6.conv.3 tensor(0.0509)
features.6.conv.6 tensor(0.0479)
features.7.conv.0 tensor(0.0549)
features.7.conv.3 tensor(0.1224)
features.7.conv.6 tensor(0.1136)
features.8.conv.0 tensor(0.0928)
features.8.conv.3 tensor(0.1100)
features.8.conv.6 tensor(0.3486)
features.9.conv.0 tensor(0.0739)
features.9.conv.3 tensor(0.1484)
features.9.conv.6 tensor(0.2572)
features.10.conv.0 tensor(0.0350)
features.10.conv.3 tensor(0.0943)
features.10.conv.6 tensor(0.1181)
features.11.conv.0 tensor(0.5195)
features.11.conv.3 tensor(0.1535)
features.11.conv.6 tensor(0.5829)
features.12.conv.0 tensor(0.3251)
features.12.conv.3 tensor(0.1530)
features.12.conv.6 tensor(0.7091)
features.13.conv.0 tensor(0.1092)
features.13.conv.3 tensor(0.1279)
features.13.conv.6 tensor(0.1124)
features.14.conv.0 tensor(0.8963)
features.14.conv.3 tensor(0.0703)
features.14.conv.6 tensor(0.9856)
features.15.conv.0 tensor(0.9471)
features.15.conv.3 tensor(0.0604)
features.15.conv.6 tensor(0.9789)
features.16.conv.0 tensor(0.2507)
features.16.conv.3 tensor(0.1186)
features.16.conv.6 tensor(0.3498)
conv.0 tensor(0.1843)
tensor(978957.) 2188896.0
INFO - Validation [47][   40/   40]   Loss 0.320128   Top1 89.850000   Top5 99.670000   BatchTime 0.087613
INFO - ==> Top1: 89.850    Top5: 99.670    Loss: 0.320
INFO - ==> Sparsity : 0.447
INFO - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
0.75650191
0.75624168
0.75597864
0.75583225
0.75575840
0.75579542
0.75599301
0.75618184
0.75647342
0.75676644
0.75705069
0.75739521
0.75763935
0.75786304
0.75807214
0.76206487
0.76130283
0.76047844
0.76001507
0.75977015
INFO - Training [48][   20/  196]   Loss 0.371477   Top1 87.226562   Top5 98.222656   BatchTime 0.419561   LR 0.000718
0.75949079
0.75928158
0.75906610
0.76143712
0.76105076
0.76072299
0.76028633
0.75993562
0.75985301
0.75998664
0.75959826
0.75921875
0.75767285
0.75679100
0.75543851
0.75421351
0.75398815
0.75385690
0.75379223
0.75347769
0.75275600
INFO - Training [48][   40/  196]   Loss 0.364847   Top1 87.695312   Top5 98.476562   BatchTime 0.397026   LR 0.000713
0.75251436
0.75245661
0.75243717
0.75251627
0.75244826
0.75240022
0.75238401
0.75231498
0.75215495
0.75180775
0.75209892
0.75442386
0.75617981
0.75752366
0.75890797
0.76351517
INFO - Training [48][   60/  196]   Loss 0.357053   Top1 88.105469   Top5 98.580729   BatchTime 0.388438   LR 0.000708
0.76493442
0.76470298
0.76467985
0.76471782
0.76455462
0.76481384
0.76451570
0.76452208
0.76428008
0.76419902
0.76422060
0.76424491
0.76434565
0.76411551
0.76420552
0.76430500
0.76403821
0.76389933
0.76397628
0.76352632
0.76340789
0.76332814
0.76353568
INFO - Training [48][   80/  196]   Loss 0.351805   Top1 88.256836   Top5 98.715820   BatchTime 0.380851   LR 0.000703
0.76319557
0.76297885
0.76276600
0.76248938
0.76229435
0.76218349
0.76221699
0.76203489
0.76174521
0.76155996
0.76137310
0.76147825
0.76171327
0.76165360
0.76155597
0.76171935
0.76182842
0.76197290
0.76199365
0.76171219
0.76147407
0.76149273
INFO - Training [48][  100/  196]   Loss 0.340413   Top1 88.589844   Top5 98.812500   BatchTime 0.377007   LR 0.000698
0.76144409
0.76102215
0.76067609
0.76036870
0.76028073
0.76035458
0.76034200
0.76055282
0.76025313
0.76003951
0.75994062
0.76008445
0.76008964
0.76017123
0.76029271
0.76065946
0.76220828
0.76319849
0.76351422
INFO - Training [48][  120/  196]   Loss 0.334444   Top1 88.753255   Top5 98.870443   BatchTime 0.368037   LR 0.000693
0.76328951
0.76343173
0.76349616
0.76350617
0.76367784
0.76391977
0.76414895
0.76443690
0.76443779
0.76444191
0.76460898
0.76489717
0.76476371
0.76479870
0.76482445
0.76461244
0.76403672
INFO - Training [48][  140/  196]   Loss 0.333946   Top1 88.805804   Top5 98.920201   BatchTime 0.364315   LR 0.000688
0.76356941
0.76316756
0.76278651
0.76239735
0.76189476
0.76124775
0.76086211
0.76057613
0.76034981
0.75996935
0.75995469
0.75990140
0.75944799
0.75903684
0.75848877
0.75826842
0.75769114
0.75705481
0.75659537
0.75613630
0.75580770
0.75555742
INFO - Training [48][  160/  196]   Loss 0.335014   Top1 88.781738   Top5 98.920898   BatchTime 0.364279   LR 0.000683
0.75552952
0.75521094
0.75482279
0.75445038
0.75507128
0.75705898
0.75649124
0.75579160
0.75554806
0.75532901
0.75523692
0.75508308
0.75488198
0.75469083
0.75458288
0.75430411
0.75412631
0.75400060
0.75391513
0.75413388
0.75390053
0.75376737
INFO - Training [48][  180/  196]   Loss 0.335991   Top1 88.745660   Top5 98.901910   BatchTime 0.365600   LR 0.000678
0.75370073
0.75331914
0.75300324
0.75278276
0.75265771
0.75236237
0.75249338
0.75210500
0.75216347
0.75172818
0.75123352
0.75068271
0.75005585
0.74956608
********************pre-trained*****************
INFO - ==> Top1: 88.820    Top5: 98.898    Loss: 0.335
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [48][   20/   40]   Loss 0.319295   Top1 90.214844   Top5 99.648438   BatchTime 0.117202
INFO - Validation [48][   40/   40]   Loss 0.306920   Top1 90.550000   Top5 99.710000   BatchTime 0.084613
INFO - ==> Top1: 90.550    Top5: 99.710    Loss: 0.307
INFO - ==> Sparsity : 0.450
INFO - Scoreboard best 1 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
features.0.conv.0 tensor(0.4653)
features.0.conv.3 tensor(0.3281)
features.1.conv.0 tensor(0.0124)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0399)
features.2.conv.0 tensor(0.0240)
features.2.conv.3 tensor(0.0594)
features.2.conv.6 tensor(0.0775)
features.3.conv.0 tensor(0.0211)
features.3.conv.3 tensor(0.0409)
features.3.conv.6 tensor(0.0202)
features.4.conv.0 tensor(0.0368)
features.4.conv.3 tensor(0.0891)
features.4.conv.6 tensor(0.1431)
features.5.conv.0 tensor(0.0386)
features.5.conv.3 tensor(0.0631)
features.5.conv.6 tensor(0.0926)
features.6.conv.0 tensor(0.0272)
features.6.conv.3 tensor(0.0451)
features.6.conv.6 tensor(0.0469)
features.7.conv.0 tensor(0.0542)
features.7.conv.3 tensor(0.1230)
features.7.conv.6 tensor(0.1041)
features.8.conv.0 tensor(0.0925)
features.8.conv.3 tensor(0.1114)
features.8.conv.6 tensor(0.1216)
features.9.conv.0 tensor(0.0741)
features.9.conv.3 tensor(0.1502)
features.9.conv.6 tensor(0.2647)
features.10.conv.0 tensor(0.0442)
features.10.conv.3 tensor(0.0955)
features.10.conv.6 tensor(0.1246)
features.11.conv.0 tensor(0.5470)
features.11.conv.3 tensor(0.1512)
features.11.conv.6 tensor(0.5959)
features.12.conv.0 tensor(0.4526)
features.12.conv.3 tensor(0.1518)
features.12.conv.6 tensor(0.7132)
features.13.conv.0 tensor(0.1130)
features.13.conv.3 tensor(0.1281)
features.13.conv.6 tensor(0.2886)
features.14.conv.0 tensor(0.8979)
features.14.conv.3 tensor(0.0714)
features.14.conv.6 tensor(0.9857)
features.15.conv.0 tensor(0.9471)
features.15.conv.3 tensor(0.0602)
features.15.conv.6 tensor(0.9768)
features.16.conv.0 tensor(0.1156)
features.16.conv.3 tensor(0.1222)
features.16.conv.6 tensor(0.3677)
conv.0 tensor(0.1851)
tensor(985221.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  49
INFO - Training: 50000 samples (256 per mini-batch)
0.74870402
0.74805290
0.74779361
0.74762118
0.74741989
0.74698943
0.74641377
0.74601704
0.74552035
0.74495059
0.74767834
0.74779189
0.74806631
0.74788332
0.74764955
0.74747974
0.74799973
0.74735075
0.74675918
0.74624413
0.74584204
0.74566036
INFO - Training [49][   20/  196]   Loss 0.342123   Top1 88.105469   Top5 98.359375   BatchTime 0.462734   LR 0.000669
0.74558020
0.74568063
0.74572206
0.74599248
0.74679315
0.74797076
0.74866813
0.74921507
0.74948001
0.74972433
0.75249791
0.75504422
0.75404382
0.75397354
0.75400925
0.75407940
INFO - Training [49][   40/  196]   Loss 0.340190   Top1 88.291016   Top5 98.613281   BatchTime 0.425393   LR 0.000664
0.75409943
0.75466132
0.75522780
0.75571305
0.75624591
0.75651246
0.75682193
0.75696492
0.75677508
0.75636363
0.75598866
0.75606459
0.75580472
0.75575286
0.75570232
0.75577819
0.75573194
0.75536042
0.75537658
0.75585890
0.75569373
0.75571734
INFO - Training [49][   60/  196]   Loss 0.339492   Top1 88.359375   Top5 98.665365   BatchTime 0.405611   LR 0.000659
0.75577885
0.75598329
0.75597394
0.75600791
0.75585198
0.75574982
0.75555325
0.75533336
0.75530523
0.75509298
0.75498217
0.75453824
0.75447446
0.75441587
0.75407141
0.75405622
0.75394791
0.75359809
0.75324500
0.75299287
0.75274801
0.75256157
0.75232595
INFO - Training [49][   80/  196]   Loss 0.335798   Top1 88.461914   Top5 98.847656   BatchTime 0.394459   LR 0.000654
0.75222009
0.75208133
0.75196356
0.75169796
0.75145656
0.75142890
0.75123566
0.75126392
0.75121891
0.75118726
0.75110763
0.75096816
0.75086653
0.75067323
0.75034052
0.75029325
0.75000763
0.74983406
0.74968630
0.74957353
INFO - Training [49][  100/  196]   Loss 0.334076   Top1 88.542969   Top5 98.855469   BatchTime 0.375791   LR 0.000649
0.74956757
0.74952126
0.74941504
0.74921238
0.74893349
0.74865878
0.74815714
0.74753308
0.74695086
0.74641395
0.74596554
0.74561983
0.74492222
0.74445766
0.74407035
0.74360830
0.74337083
0.74316651
INFO - Training [49][  120/  196]   Loss 0.328016   Top1 88.854167   Top5 98.912760   BatchTime 0.365997   LR 0.000644
0.74252462
0.74196041
0.74172091
0.74140555
0.74191487
0.74218315
0.74211413
0.74237293
0.74241716
0.74232107
0.74215275
0.74163997
0.74088979
0.73985338
0.73861772
0.73783541
0.74640346
0.74386460
0.74206126
0.74115753
0.73916161
INFO - Training [49][  140/  196]   Loss 0.327552   Top1 88.881138   Top5 98.959263   BatchTime 0.366957   LR 0.000639
0.73823661
0.73745781
0.73663789
0.73745900
0.73864120
0.73948216
0.73969257
0.73914301
0.73905635
0.73957551
0.74071932
0.74079001
0.74157310
0.74242747
0.74347168
0.74462825
INFO - Training [49][  160/  196]   Loss 0.332922   Top1 88.737793   Top5 98.918457   BatchTime 0.368427   LR 0.000634
0.74550027
0.74628055
0.74692726
0.74736840
0.74783897
0.74735814
0.74719632
0.74679655
0.74650574
0.74618554
0.74586511
0.74568343
0.74576634
0.74600047
0.74622369
0.74608624
0.74592018
0.74578691
0.74539119
0.74507099
0.74479043
0.74423707
INFO - Training [49][  180/  196]   Loss 0.335474   Top1 88.650174   Top5 98.893229   BatchTime 0.368257   LR 0.000629
0.74373561
0.74388665
0.74393487
0.74394637
0.74402618
0.74411994
0.74403912
0.74382788
0.74403393
0.74401397
0.74395448
0.74380845
0.74376982
0.74353945
0.74329430
0.74329555
INFO - ==> Top1: 88.632    Top5: 98.896    Loss: 0.335
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [49][   20/   40]   Loss 0.334885   Top1 89.570312   Top5 99.570312   BatchTime 0.156278
INFO - Validation [49][   40/   40]   Loss 0.326140   Top1 89.580000   Top5 99.670000   BatchTime 0.109812
INFO - ==> Top1: 89.580    Top5: 99.670    Loss: 0.326
INFO - ==> Sparsity : 0.460
INFO - Scoreboard best 1 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4306)
features.0.conv.3 tensor(0.3203)
features.1.conv.0 tensor(0.0137)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0412)
features.2.conv.0 tensor(0.0272)
features.2.conv.3 tensor(0.0548)
features.2.conv.6 tensor(0.0784)
features.3.conv.0 tensor(0.0203)
features.3.conv.3 tensor(0.0463)
features.3.conv.6 tensor(0.0200)
features.4.conv.0 tensor(0.0387)
features.4.conv.3 tensor(0.0914)
features.4.conv.6 tensor(0.0907)
features.5.conv.0 tensor(0.0368)
features.5.conv.3 tensor(0.0619)
features.5.conv.6 tensor(0.0934)
features.6.conv.0 tensor(0.0270)
features.6.conv.3 tensor(0.0475)
features.6.conv.6 tensor(0.0466)
features.7.conv.0 tensor(0.0494)
features.7.conv.3 tensor(0.1224)
features.7.conv.6 tensor(0.2706)
features.8.conv.0 tensor(0.0718)
features.8.conv.3 tensor(0.1114)
features.8.conv.6 tensor(0.1977)
features.9.conv.0 tensor(0.0802)
features.9.conv.3 tensor(0.1481)
features.9.conv.6 tensor(0.2903)
features.10.conv.0 tensor(0.0371)
features.10.conv.3 tensor(0.0978)
features.10.conv.6 tensor(0.0933)
features.11.conv.0 tensor(0.5394)
features.11.conv.3 tensor(0.1518)
features.11.conv.6 tensor(0.5877)
features.12.conv.0 tensor(0.3810)
features.12.conv.3 tensor(0.1508)
features.12.conv.6 tensor(0.7289)
features.13.conv.0 tensor(0.1144)
features.13.conv.3 tensor(0.1279)
features.13.conv.6 tensor(0.2496)
features.14.conv.0 tensor(0.8988)
features.14.conv.3 tensor(0.0696)
features.14.conv.6 tensor(0.9870)
features.15.conv.0 tensor(0.9467)
features.15.conv.3 tensor(0.0594)
features.15.conv.6 tensor(0.9777)
features.16.conv.0 tensor(0.2274)
features.16.conv.3 tensor(0.1207)
features.16.conv.6 tensor(0.3690)
conv.0 tensor(0.2000)
tensor(1006295.) 2188896.0
0.74358964
0.74375212
0.74338484
0.74342686
0.74340665
0.74497986
0.74536091
0.74535179
0.74528188
0.74527603
0.74522948
0.74517798
0.74509239
0.74504358
0.74482828
0.74479222
0.74480206
0.74460757
0.74482763
0.74486214
INFO - Training [50][   20/  196]   Loss 0.359157   Top1 87.988281   Top5 98.398438   BatchTime 0.456563   LR 0.000620
0.74501967
0.74504209
0.74494821
0.74472672
0.74461895
0.74470955
0.74480110
0.74479347
0.74490446
0.74505502
0.74511003
0.74497592
0.74493778
0.74489188
0.74633372
0.74602318
0.74576592
0.74523574
0.74473792
0.74427897
0.74384576
0.74339676
INFO - Training [50][   40/  196]   Loss 0.356036   Top1 87.890625   Top5 98.535156   BatchTime 0.410595   LR 0.000615
0.74306911
0.74270165
0.74238992
0.74184042
0.74156147
0.74142671
0.74103439
0.74059463
0.74011415
0.73973471
0.73929667
0.73942411
0.73923850
0.73913956
0.73880506
0.73864031
0.73826998
INFO - Training [50][   60/  196]   Loss 0.352565   Top1 88.014323   Top5 98.652344   BatchTime 0.394765   LR 0.000610
0.73829204
0.73842454
0.73859501
0.73888737
0.73889768
0.73901761
0.73924023
0.73937505
0.73946220
0.73949772
0.73963404
0.73958260
0.73970044
0.73974967
0.73957199
0.73942798
0.73929989
0.74053246
INFO - Training [50][   80/  196]   Loss 0.347449   Top1 88.291016   Top5 98.754883   BatchTime 0.377287   LR 0.000605
0.74039418
0.74015975
0.73970324
0.73931241
0.73901570
0.73888361
0.73870111
0.73853809
0.73858321
0.73856342
0.73844123
0.73846507
0.73845911
0.73825175
0.73801076
0.73788029
0.73784178
0.73784947
0.73780453
0.73779374
0.73780227
0.73757225
0.73740476
0.73716342
0.73702669
INFO - Training [50][  100/  196]   Loss 0.338136   Top1 88.691406   Top5 98.839844   BatchTime 0.367470   LR 0.000600
0.73680073
0.73667723
0.73662883
0.73654503
0.73647571
0.73643237
0.73625350
0.73633128
0.73628527
0.73621476
0.73598492
0.73565876
0.73539168
0.73485768
0.73466140
0.73458833
INFO - Training [50][  120/  196]   Loss 0.330664   Top1 89.036458   Top5 98.912760   BatchTime 0.366424   LR 0.000595
0.73489738
0.73731750
0.73751986
0.73764890
0.73776191
0.73765147
0.73756355
0.73734450
0.73730451
0.73716950
0.73694909
0.73680490
0.73693228
0.74219054
0.74202520
0.74151242
0.74067521
0.74056709
0.74074513
0.74079943
0.74091858
0.74125874
INFO - Training [50][  140/  196]   Loss 0.328715   Top1 89.098772   Top5 98.989955   BatchTime 0.365833   LR 0.000590
0.74148607
0.74181139
0.74212766
0.74236536
0.74209458
0.74229294
0.74239188
0.74265128
0.74243903
0.74243760
0.74246037
0.74264252
0.74246269
0.74238676
0.74205995
0.74207562
0.74217528
0.74242210
0.74233907
0.74252611
0.74225050
0.74217999
0.74225897
INFO - Training [50][  160/  196]   Loss 0.330702   Top1 89.023438   Top5 98.962402   BatchTime 0.364936   LR 0.000585
0.74231619
0.74250650
0.74254507
0.74273169
0.74273086
0.74231923
0.74231637
0.74243599
0.74264854
0.74287450
0.74301833
0.74320298
0.74352568
0.74350852
0.74361980
0.74387676
INFO - Training [50][  180/  196]   Loss 0.331823   Top1 88.973524   Top5 98.936632   BatchTime 0.365208   LR 0.000580
0.74357754
0.74344218
0.74377686
0.74380118
0.74417710
0.74425721
0.74434614
0.74429375
0.74410874
0.74411070
0.74425024
0.74416018
0.74430370
0.74428445
0.74434131
0.74450290
INFO - ==> Top1: 89.046    Top5: 98.956    Loss: 0.330
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
0.74476302
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [50][   20/   40]   Loss 0.316384   Top1 90.273438   Top5 99.648438   BatchTime 0.132025
INFO - Validation [50][   40/   40]   Loss 0.307324   Top1 90.180000   Top5 99.680000   BatchTime 0.110642
INFO - ==> Top1: 90.180    Top5: 99.680    Loss: 0.307
INFO - ==> Sparsity : 0.467
INFO - Scoreboard best 1 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
INFO - Scoreboard best 2 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
features.0.conv.0 tensor(0.4375)
features.0.conv.3 tensor(0.3223)
features.1.conv.0 tensor(0.0130)
features.1.conv.3 tensor(0.0880)
features.1.conv.6 tensor(0.0425)
features.2.conv.0 tensor(0.0295)
features.2.conv.3 tensor(0.0502)
features.2.conv.6 tensor(0.0775)
features.3.conv.0 tensor(0.0182)
features.3.conv.3 tensor(0.0471)
features.3.conv.6 tensor(0.0224)
features.4.conv.0 tensor(0.0314)
features.4.conv.3 tensor(0.0845)
features.4.conv.6 tensor(0.0846)
features.5.conv.0 tensor(0.0474)
features.5.conv.3 tensor(0.0671)
features.5.conv.6 tensor(0.0965)
features.6.conv.0 tensor(0.0285)
features.6.conv.3 tensor(0.0463)
features.6.conv.6 tensor(0.0466)
features.7.conv.0 tensor(0.0542)
features.7.conv.3 tensor(0.1241)
features.7.conv.6 tensor(0.1348)
features.8.conv.0 tensor(0.0879)
features.8.conv.3 tensor(0.1108)
features.8.conv.6 tensor(0.2402)
features.9.conv.0 tensor(0.0866)
features.9.conv.3 tensor(0.1470)
features.9.conv.6 tensor(0.3056)
features.10.conv.0 tensor(0.0315)
features.10.conv.3 tensor(0.0969)
features.10.conv.6 tensor(0.0732)
features.11.conv.0 tensor(0.5465)
features.11.conv.3 tensor(0.1508)
features.11.conv.6 tensor(0.5949)
features.12.conv.0 tensor(0.3371)
features.12.conv.3 tensor(0.1491)
features.12.conv.6 tensor(0.7116)
features.13.conv.0 tensor(0.1172)
features.13.conv.3 tensor(0.1279)
features.13.conv.6 tensor(0.3305)
features.14.conv.0 tensor(0.8997)
features.14.conv.3 tensor(0.0712)
features.14.conv.6 tensor(0.9868)
features.15.conv.0 tensor(0.9475)
features.15.conv.3 tensor(0.0602)
features.15.conv.6 tensor(0.9773)
features.16.conv.0 tensor(0.2594)
features.16.conv.3 tensor(0.1189)
features.16.conv.6 tensor(0.3720)
conv.0 tensor(0.2183)
tensor(1022698.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
0.74482495
0.74481809
0.74459916
0.74453622
0.74444872
0.74443054
0.74430221
0.74383974
0.74357045
0.74342269
0.74371618
0.74360198
0.74348563
0.74337310
0.74337757
0.74338704
0.74329793
0.74303335
0.74304265
INFO - Training [51][   20/  196]   Loss 0.353735   Top1 88.046875   Top5 98.437500   BatchTime 0.462230   LR 0.000571
0.74330097
0.74338061
0.74297678
0.74278057
0.74245691
0.74225962
0.74211055
0.74222362
0.74204499
0.74223822
0.74200404
0.74158973
0.74088758
0.74018472
0.73994941
0.73987401
0.73963475
0.73930955
0.73909849
0.73892617
INFO - Training [51][   40/  196]   Loss 0.348420   Top1 88.388672   Top5 98.535156   BatchTime 0.429053   LR 0.000566
0.73868942
0.73848748
0.73834670
0.73818898
0.73805642
0.73778832
0.73745871
0.73706108
0.73674649
0.73636955
0.73606718
0.73573685
0.73524755
0.73459297
0.73374635
0.73280966
0.73226714
0.73173255
0.73124552
0.73090595
0.73088264
0.73080611
0.73072946
0.73040807
INFO - Training [51][   60/  196]   Loss 0.343995   Top1 88.450521   Top5 98.613281   BatchTime 0.397191   LR 0.000561
0.73023438
0.73026329
0.73208898
0.73233730
0.73243308
0.73252279
0.73229384
0.73181838
0.73141402
0.73100340
0.73073226
0.73069572
0.73074901
0.73065376
0.73031169
0.72993505
0.72970307
0.72941160
INFO - Training [51][   80/  196]   Loss 0.338131   Top1 88.803711   Top5 98.740234   BatchTime 0.379880   LR 0.000556
0.72901684
0.72870922
0.72817546
0.72803271
0.72789854
0.72788495
0.72802937
0.72806841
0.72784501
0.72801477
0.72796047
0.72782248
0.72777575
0.72783685
0.72814518
0.72904104
0.72952324
INFO - Training [51][  100/  196]   Loss 0.330272   Top1 89.042969   Top5 98.835938   BatchTime 0.377634   LR 0.000551
0.73005092
0.73027533
0.73053843
0.73084056
0.73156852
0.73217583
0.73313838
0.73553884
0.73942846
0.73987490
0.73945469
0.73968995
0.74005407
0.74157155
0.74145269
0.74113262
0.74127060
0.74142241
0.74141282
0.74106753
0.74119645
0.74074459
INFO - Training [51][  120/  196]   Loss 0.325010   Top1 89.192708   Top5 98.916016   BatchTime 0.374372   LR 0.000546
0.74083632
0.74063009
0.74067175
0.74063069
0.74075687
0.74055558
0.74059731
0.74042737
0.74037701
0.74041373
0.74049228
0.74025559
0.74031496
0.74050558
0.74063599
0.74064142
0.74066681
0.74064428
0.74060977
0.74064511
0.74041420
0.74052668
0.74234778
INFO - Training [51][  140/  196]   Loss 0.324934   Top1 89.168527   Top5 98.964844   BatchTime 0.371171   LR 0.000541
0.74267441
0.74241990
0.74218905
0.74208248
0.74199253
0.74184382
0.74186921
0.74196678
0.74203175
0.74227649
0.74196184
0.74211049
0.74255842
0.74265164
0.74236846
0.74243784
INFO - Training [51][  160/  196]   Loss 0.329154   Top1 89.008789   Top5 98.923340   BatchTime 0.370820   LR 0.000536
0.74198174
0.74199551
0.74212152
0.74206036
0.74183053
0.74152589
0.74138826
0.74125719
0.74122834
0.74093765
0.74071312
0.74072891
0.74074703
0.74064732
0.74064189
0.74045980
0.74056333
0.74043566
0.74013948
0.73972988
0.73928314
INFO - Training [51][  180/  196]   Loss 0.330130   Top1 88.975694   Top5 98.862847   BatchTime 0.371432   LR 0.000531
0.73937911
0.73943585
0.73937911
0.73908383
0.73918831
0.73930484
0.73954898
0.73965663
0.73962843
0.73931348
0.73922569
0.73941535
0.73960817
0.73954129
0.73924178
0.73920768
INFO - ==> Top1: 89.044    Top5: 98.892    Loss: 0.329
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [51][   20/   40]   Loss 0.311347   Top1 90.722656   Top5 99.648438   BatchTime 0.131677
INFO - Validation [51][   40/   40]   Loss 0.298658   Top1 90.790000   Top5 99.690000   BatchTime 0.093398
INFO - ==> Top1: 90.790    Top5: 99.690    Loss: 0.299
INFO - ==> Sparsity : 0.471
INFO - Scoreboard best 1 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
INFO - Scoreboard best 3 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
features.0.conv.0 tensor(0.4097)
features.0.conv.3 tensor(0.3242)
features.1.conv.0 tensor(0.0189)
features.1.conv.3 tensor(0.0833)
features.1.conv.6 tensor(0.0430)
features.2.conv.0 tensor(0.0310)
features.2.conv.3 tensor(0.0502)
features.2.conv.6 tensor(0.0778)
features.3.conv.0 tensor(0.0182)
features.3.conv.3 tensor(0.0494)
features.3.conv.6 tensor(0.0221)
features.4.conv.0 tensor(0.0348)
features.4.conv.3 tensor(0.0885)
features.4.conv.6 tensor(0.0856)
features.5.conv.0 tensor(0.0396)
features.5.conv.3 tensor(0.0631)
features.5.conv.6 tensor(0.1090)
features.6.conv.0 tensor(0.0295)
features.6.conv.3 tensor(0.0469)
features.6.conv.6 tensor(0.0466)
features.7.conv.0 tensor(0.0601)
features.7.conv.3 tensor(0.1253)
features.7.conv.6 tensor(0.1659)
features.8.conv.0 tensor(0.0830)
features.8.conv.3 tensor(0.1091)
features.8.conv.6 tensor(0.2684)
features.9.conv.0 tensor(0.0888)
features.9.conv.3 tensor(0.1455)
features.9.conv.6 tensor(0.3032)
features.10.conv.0 tensor(0.0322)
features.10.conv.3 tensor(0.0949)
features.10.conv.6 tensor(0.0796)
features.11.conv.0 tensor(0.5583)
features.11.conv.3 tensor(0.1551)
features.11.conv.6 tensor(0.5994)
features.12.conv.0 tensor(0.3812)
features.12.conv.3 tensor(0.1478)
features.12.conv.6 tensor(0.7257)
features.13.conv.0 tensor(0.1225)
features.13.conv.3 tensor(0.1273)
features.13.conv.6 tensor(0.3208)
features.14.conv.0 tensor(0.9008)
features.14.conv.3 tensor(0.0706)
features.14.conv.6 tensor(0.9864)
features.15.conv.0 tensor(0.9476)
features.15.conv.3 tensor(0.0612)
features.15.conv.6 tensor(0.9772)
features.16.conv.0 tensor(0.2075)
features.16.conv.3 tensor(0.1200)
features.16.conv.6 tensor(0.4015)
conv.0 tensor(0.2239)
tensor(1031512.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
0.73917145
0.73891336
0.73847508
0.73804617
0.73770052
0.73762459
0.73726428
0.73679537
0.73594511
0.73529154
0.73489761
0.73481262
0.73466074
0.73461658
0.73426729
0.73428547
0.73418248
0.73406279
INFO - Training [52][   20/  196]   Loss 0.333925   Top1 88.710938   Top5 98.632812   BatchTime 0.422076   LR 0.000523
0.73379666
0.73374099
0.73291153
0.73251772
0.73232675
0.73216975
0.73207891
0.73189569
0.73154658
0.73113680
0.73072660
0.73008311
0.72947961
0.72881263
0.72809255
0.72747278
0.72643650
0.72611040
0.72593778
0.72557360
0.72520494
INFO - Training [52][   40/  196]   Loss 0.340318   Top1 88.623047   Top5 98.642578   BatchTime 0.356565   LR 0.000518
0.72672737
0.72635752
0.72590595
0.72548729
0.72525984
0.72492456
0.72482401
0.72467494
0.72443163
0.72404319
0.72373617
0.72330314
0.72293204
0.72256953
0.72239387
0.72228289
0.72227150
0.72192198
0.72179198
0.72136766
0.72110140
0.72117370
0.72117299
INFO - Training [52][   60/  196]   Loss 0.339971   Top1 88.587240   Top5 98.652344   BatchTime 0.352988   LR 0.000513
0.72108257
0.72044790
0.71997148
0.71959019
0.71960747
0.72003704
0.72023046
0.72036350
0.72043955
0.72050565
0.72050077
0.72039568
0.72034895
0.72033936
0.72033894
0.72030878
INFO - Training [52][   80/  196]   Loss 0.331955   Top1 88.867188   Top5 98.833008   BatchTime 0.358688   LR 0.000508
0.72032368
0.72032577
0.72036117
0.72054994
0.72070658
0.72099566
0.72142959
0.72218376
0.72248131
0.72264677
0.72290486
0.72311360
0.72309846
0.72302037
0.72297043
0.72292149
0.72276545
0.72272521
0.72263294
0.72261399
INFO - Training [52][  100/  196]   Loss 0.324093   Top1 89.117188   Top5 98.890625   BatchTime 0.367297   LR 0.000503
0.72266936
0.72254246
0.72244680
0.72236520
0.72243243
0.72256505
0.72247452
0.72249866
0.72237724
0.72211254
0.72185516
0.72159904
0.72141391
0.72131222
0.72113252
0.72107911
0.72104394
0.72092521
0.72091597
0.72096491
0.72088104
INFO - Training [52][  120/  196]   Loss 0.320597   Top1 89.300130   Top5 98.916016   BatchTime 0.368662   LR 0.000498
0.72080994
0.72082257
0.72087759
0.72081584
0.72083330
0.72083181
0.72074467
0.72064042
0.72041142
0.72023183
0.72009075
0.71988666
0.71970659
0.71944284
0.71908432
0.71854568
0.71772528
0.71752423
0.71752042
0.71716654
0.71679240
0.71655804
INFO - Training [52][  140/  196]   Loss 0.315960   Top1 89.481027   Top5 98.978795   BatchTime 0.368168   LR 0.000493
0.71632612
0.71615934
0.71570611
0.71528685
0.71511853
0.71488434
0.71476620
0.71430522
0.71401584
0.71393698
0.71396923
0.71409237
0.71407431
0.71411377
0.71442431
0.71434134
0.71429801
0.71417129
0.71383178
0.71352881
0.71328658
INFO - Training [52][  160/  196]   Loss 0.320983   Top1 89.262695   Top5 98.979492   BatchTime 0.369527   LR 0.000488
0.71307874
0.71275854
0.71207774
0.71139866
0.71145016
0.71114022
0.71106082
0.71107370
0.71108443
0.71134239
0.71095222
0.71029216
0.70984077
0.70795107
0.70628059
0.70472342
0.70304847
0.70278782
0.70254374
INFO - Training [52][  180/  196]   Loss 0.321169   Top1 89.307726   Top5 98.951823   BatchTime 0.374357   LR 0.000483
0.70204949
0.70240819
0.70240569
0.70233786
0.70248693
0.70260030
0.70252699
0.70252568
0.70275611
0.70295602
0.70318681
0.70731312
0.70763355
0.70799762
0.70831025
********************pre-trained*****************
INFO - ==> Top1: 89.366    Top5: 98.956    Loss: 0.319
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [52][   20/   40]   Loss 0.352371   Top1 89.511719   Top5 99.394531   BatchTime 0.123250
INFO - Validation [52][   40/   40]   Loss 0.342738   Top1 89.490000   Top5 99.520000   BatchTime 0.088576
features.0.conv.0 tensor(0.4271)
features.0.conv.3 tensor(0.3438)
features.1.conv.0 tensor(0.0150)
features.1.conv.3 tensor(0.0903)
features.1.conv.6 tensor(0.0447)
features.2.conv.0 tensor(0.0315)
features.2.conv.3 tensor(0.0548)
features.2.conv.6 tensor(0.0775)
features.3.conv.0 tensor(0.0237)
features.3.conv.3 tensor(0.0455)
features.3.conv.6 tensor(0.0224)
features.4.conv.0 tensor(0.0337)
features.4.conv.3 tensor(0.0897)
features.4.conv.6 tensor(0.1156)
features.5.conv.0 tensor(0.0373)
features.5.conv.3 tensor(0.0625)
features.5.conv.6 tensor(0.1079)
features.6.conv.0 tensor(0.0304)
features.6.conv.3 tensor(0.0428)
features.6.conv.6 tensor(0.0470)
features.7.conv.0 tensor(0.0666)
features.7.conv.3 tensor(0.1250)
features.7.conv.6 tensor(0.2008)
features.8.conv.0 tensor(0.0837)
features.8.conv.3 tensor(0.1108)
features.8.conv.6 tensor(0.2340)
features.9.conv.0 tensor(0.0859)
features.9.conv.3 tensor(0.1487)
features.9.conv.6 tensor(0.3128)
features.10.conv.0 tensor(0.0382)
features.10.conv.3 tensor(0.0940)
features.10.conv.6 tensor(0.1089)
features.11.conv.0 tensor(0.5673)
features.11.conv.3 tensor(0.1534)
features.11.conv.6 tensor(0.6112)
features.12.conv.0 tensor(0.3561)
features.12.conv.3 tensor(0.1499)
features.12.conv.6 tensor(0.7194)
features.13.conv.0 tensor(0.1188)
features.13.conv.3 tensor(0.1277)
features.13.conv.6 tensor(0.3129)
features.14.conv.0 tensor(0.9015)
features.14.conv.3 tensor(0.0707)
features.14.conv.6 tensor(0.9870)
features.15.conv.0 tensor(0.9479)
features.15.conv.3 tensor(0.0595)
features.15.conv.6 tensor(0.9763)
features.16.conv.0 tensor(0.2498)
features.16.conv.3 tensor(0.1171)
features.16.conv.6 tensor(0.4191)
conv.0 tensor(0.6254)
tensor(1208196.) 2188896.0
INFO - ==> Top1: 89.490    Top5: 99.520    Loss: 0.343
INFO - ==> Sparsity : 0.552
INFO - Scoreboard best 1 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
INFO - Scoreboard best 3 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
0.70727122
0.70733565
0.70743525
0.70696789
0.70688295
0.70621264
0.70549452
0.70482355
0.70438868
0.70401508
0.70357352
0.71389461
0.71391118
0.71392161
0.71372569
0.71338516
0.71327245
INFO - Training [53][   20/  196]   Loss 0.333321   Top1 88.574219   Top5 98.554688   BatchTime 0.384125   LR 0.000474
0.71284688
0.71288210
0.71304142
0.71245819
0.71215761
0.71192586
0.71226263
0.71265042
0.71270347
0.71261811
0.71242100
0.71244591
0.71236098
0.71230996
0.71226466
0.71252567
0.71267557
0.71260059
0.71248013
0.71222574
0.71234488
0.71227688
INFO - Training [53][   40/  196]   Loss 0.346658   Top1 88.203125   Top5 98.623047   BatchTime 0.381579   LR 0.000470
0.71223152
0.71196604
0.71195883
0.71208578
0.71211392
0.71206051
0.71191901
0.71173495
0.71163172
0.71192539
0.71225995
0.71244538
0.71242863
0.71248382
0.71276981
0.71327931
0.71375769
0.71402168
0.71448815
0.71518379
0.71542627
0.71569490
INFO - Training [53][   60/  196]   Loss 0.337591   Top1 88.658854   Top5 98.691406   BatchTime 0.376193   LR 0.000465
0.71581942
0.71618301
0.71652895
0.71698236
0.71743304
0.71794242
0.71851069
0.71883172
0.71965027
0.72041208
0.72099352
0.72104776
0.72093749
0.72091746
0.72068363
0.72031999
0.72019362
0.72022754
0.72024101
0.72019154
0.72042489
INFO - Training [53][   80/  196]   Loss 0.335122   Top1 88.715820   Top5 98.818359   BatchTime 0.375486   LR 0.000460
0.72062260
0.72089916
0.72101837
0.72116274
0.72132164
0.72149754
0.72195166
0.72201711
0.72231561
0.72256064
0.72280371
0.72309458
0.72292566
0.72335124
0.72301078
0.72301179
INFO - Training [53][  100/  196]   Loss 0.328255   Top1 88.988281   Top5 98.867188   BatchTime 0.375177   LR 0.000455
0.72326356
0.72333997
0.72336948
0.72352755
0.72358233
0.72359443
0.72375703
0.72379631
0.72365522
0.72362798
0.72383338
0.72382319
0.72378737
0.72398210
0.72361439
0.72334349
0.72335720
0.72329712
0.72319669
0.72294986
0.72257477
INFO - Training [53][  120/  196]   Loss 0.319173   Top1 89.287109   Top5 98.932292   BatchTime 0.376529   LR 0.000450
0.72219366
0.72222364
0.72189778
0.72144449
0.72112614
0.72081578
0.72050273
0.72008330
0.71972919
0.71925431
0.71876866
0.71815193
0.71752131
0.71678185
0.71616536
0.71568739
0.71552885
0.71535146
0.71526873
0.71512616
INFO - Training [53][  140/  196]   Loss 0.314195   Top1 89.461496   Top5 99.020647   BatchTime 0.380061   LR 0.000445
0.71510440
0.71495301
0.71470630
0.71436703
0.71402270
0.71362752
0.71321744
0.71295941
0.71273094
0.71233296
0.71201921
0.71179187
0.71147257
0.71076643
0.71029663
0.71005148
0.70987314
0.70964825
0.70952952
0.70939839
0.70916724
0.70887834
INFO - Training [53][  160/  196]   Loss 0.315963   Top1 89.331055   Top5 99.006348   BatchTime 0.379121   LR 0.000441
0.70848054
0.70813948
0.70781910
0.70742142
0.70719314
0.70716149
0.70704073
0.70688283
0.70692176
0.70693451
0.70707756
0.70719641
0.70737404
0.70755655
0.70766586
0.70766193
0.70769858
0.70783532
0.70797855
0.70803249
0.70811105
INFO - Training [53][  180/  196]   Loss 0.317651   Top1 89.279514   Top5 98.962674   BatchTime 0.379305   LR 0.000436
0.70821685
0.70828402
0.70832419
0.70863289
0.70859694
0.70858812
0.70859843
0.70873326
0.70883787
0.70894748
0.70888025
0.70884055
0.70874804
0.70862186
********************pre-trained*****************
INFO - ==> Top1: 89.338    Top5: 98.972    Loss: 0.315
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [53][   20/   40]   Loss 0.339709   Top1 89.707031   Top5 99.589844   BatchTime 0.210497
INFO - Validation [53][   40/   40]   Loss 0.330008   Top1 89.850000   Top5 99.650000   BatchTime 0.131022
features.0.conv.0 tensor(0.4514)
features.0.conv.3 tensor(0.3320)
features.1.conv.0 tensor(0.0169)
features.1.conv.3 tensor(0.0880)
features.1.conv.6 tensor(0.0404)
features.2.conv.0 tensor(0.0298)
features.2.conv.3 tensor(0.0478)
features.2.conv.6 tensor(0.0752)
features.3.conv.0 tensor(0.0231)
features.3.conv.3 tensor(0.0432)
features.3.conv.6 tensor(0.0221)
features.4.conv.0 tensor(0.0368)
features.4.conv.3 tensor(0.0816)
features.4.conv.6 tensor(0.0882)
features.5.conv.0 tensor(0.0381)
features.5.conv.3 tensor(0.0648)
features.5.conv.6 tensor(0.1099)
features.6.conv.0 tensor(0.0275)
features.6.conv.3 tensor(0.0440)
features.6.conv.6 tensor(0.0482)
features.7.conv.0 tensor(0.0586)
features.7.conv.3 tensor(0.1227)
features.7.conv.6 tensor(0.2011)
features.8.conv.0 tensor(0.0735)
features.8.conv.3 tensor(0.1079)
features.8.conv.6 tensor(0.2634)
features.9.conv.0 tensor(0.0857)
features.9.conv.3 tensor(0.1476)
features.9.conv.6 tensor(0.3086)
features.10.conv.0 tensor(0.0378)
features.10.conv.3 tensor(0.0966)
features.10.conv.6 tensor(0.1211)
features.11.conv.0 tensor(0.5595)
features.11.conv.3 tensor(0.1537)
features.11.conv.6 tensor(0.6151)
features.12.conv.0 tensor(0.3692)
features.12.conv.3 tensor(0.1487)
features.12.conv.6 tensor(0.7194)
features.13.conv.0 tensor(0.1257)
features.13.conv.3 tensor(0.1262)
features.13.conv.6 tensor(0.3772)
features.14.conv.0 tensor(0.9022)
features.14.conv.3 tensor(0.0703)
features.14.conv.6 tensor(0.9876)
features.15.conv.0 tensor(0.9490)
features.15.conv.3 tensor(0.0596)
features.15.conv.6 tensor(0.9768)
features.16.conv.0 tensor(0.2574)
features.16.conv.3 tensor(0.1171)
features.16.conv.6 tensor(0.4064)
conv.0 tensor(0.5065)
tensor(1164424.) 2188896.0
INFO - ==> Top1: 89.850    Top5: 99.650    Loss: 0.330
INFO - ==> Sparsity : 0.532
INFO - Scoreboard best 1 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
INFO - Scoreboard best 3 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
0.70848233
0.70853573
0.70838141
0.70816672
0.70798886
0.70795667
0.70812964
0.70806444
0.70793480
0.70762688
0.70736498
0.70711952
0.70691925
0.70675588
0.70657605
0.70660055
0.70642203
0.70622236
0.70622319
0.70639050
0.70737416
0.70907390
INFO - Training [54][   20/  196]   Loss 0.328013   Top1 88.886719   Top5 98.496094   BatchTime 0.319397   LR 0.000427
0.70906740
0.70899773
0.70906317
0.70898300
0.70878029
0.70858705
0.70842582
0.70823693
0.70799839
0.70781773
0.70762038
0.70743906
0.70731217
0.70712560
0.70691580
0.70677906
INFO - Training [54][   40/  196]   Loss 0.320768   Top1 89.003906   Top5 98.828125   BatchTime 0.335540   LR 0.000423
0.70674819
0.70670867
0.70674998
0.70658821
0.70643961
0.70641965
0.70641941
0.70645916
0.70656687
0.70659024
0.70656830
0.70656043
0.70651054
0.70645559
0.70639116
0.70625687
0.70613587
0.70605940
0.70599186
0.70589304
0.70585454
0.70577961
INFO - Training [54][   60/  196]   Loss 0.326405   Top1 88.821615   Top5 98.925781   BatchTime 0.344482   LR 0.000418
0.70571315
0.70572656
0.70572102
0.70577073
0.70579636
0.70590812
0.70599037
0.70615244
0.70642072
0.70659482
0.70679533
0.70696986
0.70713842
0.70722961
0.70728046
0.70721829
0.70725352
0.70731300
0.70746678
0.70756853
INFO - Training [54][   80/  196]   Loss 0.323603   Top1 89.077148   Top5 98.989258   BatchTime 0.358074   LR 0.000413
0.70763981
0.70770937
0.70771205
0.70778388
0.71255302
0.71233857
0.71216738
0.71208614
0.71196961
0.71187222
0.71173817
0.71156019
0.71147472
0.71143430
0.71133828
0.71122897
0.71122867
0.71117496
0.71118671
0.71116042
0.71106577
0.71094143
INFO - Training [54][  100/  196]   Loss 0.316566   Top1 89.425781   Top5 99.039062   BatchTime 0.362143   LR 0.000408
0.71089703
0.71076238
0.71063858
0.71059048
0.71054155
0.71042418
0.71027905
0.71014178
0.71000880
0.70989239
0.70978636
0.70971018
0.70975006
0.70971602
0.70963657
0.70945066
0.72062165
INFO - Training [54][  120/  196]   Loss 0.309471   Top1 89.703776   Top5 99.098307   BatchTime 0.360353   LR 0.000404
0.72066563
0.72047651
0.72055751
0.72060448
0.72054559
0.72069424
0.72073579
0.72073579
0.72045654
0.72040451
0.72038800
0.72054839
0.72051656
0.72024786
0.72034544
0.72026724
0.72006261
0.72026211
0.72030741
0.72011042
0.72004992
0.72027165
INFO - Training [54][  140/  196]   Loss 0.307655   Top1 89.799107   Top5 99.123884   BatchTime 0.359607   LR 0.000399
0.72049290
0.72056735
0.72041875
0.72038811
0.72045773
0.72063875
0.72047246
0.72065842
0.72067016
0.72059530
0.72063500
0.72261977
0.72246063
0.72217917
0.72212434
0.72203547
0.72174811
0.72184545
0.72193271
0.72181386
0.72175431
INFO - Training [54][  160/  196]   Loss 0.310755   Top1 89.680176   Top5 99.106445   BatchTime 0.363364   LR 0.000394
0.72170293
0.72147483
0.72161412
0.72156036
0.72140104
0.72146660
0.72144252
0.72146523
0.72138202
0.72142649
0.72112739
0.72127843
0.72099179
0.72094780
0.72072387
0.72066903
INFO - Training [54][  180/  196]   Loss 0.309386   Top1 89.726562   Top5 99.062500   BatchTime 0.363751   LR 0.000390
0.72068775
0.72070169
0.72000450
0.71993506
0.71994096
0.72005105
0.72021168
0.72039175
0.72004479
0.71996915
0.71964508
0.71964914
0.71977156
0.71965641
0.71991783
0.71981865
INFO - ==> Top1: 89.758    Top5: 99.054    Loss: 0.308
0.71950185
0.71944791
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [54][   20/   40]   Loss 0.383767   Top1 88.613281   Top5 99.355469   BatchTime 0.138814
INFO - Validation [54][   40/   40]   Loss 0.372804   Top1 88.770000   Top5 99.490000   BatchTime 0.097585
features.0.conv.0 tensor(0.4167)
features.0.conv.3 tensor(0.3184)
features.1.conv.0 tensor(0.0124)
features.1.conv.3 tensor(0.0868)
features.1.conv.6 tensor(0.0408)
features.2.conv.0 tensor(0.0289)
features.2.conv.3 tensor(0.0478)
features.2.conv.6 tensor(0.0787)
features.3.conv.0 tensor(0.0272)
features.3.conv.3 tensor(0.0448)
features.3.conv.6 tensor(0.0228)
features.4.conv.0 tensor(0.0348)
features.4.conv.3 tensor(0.0874)
features.4.conv.6 tensor(0.0885)
features.5.conv.0 tensor(0.0391)
features.5.conv.3 tensor(0.0625)
features.5.conv.6 tensor(0.1131)
features.6.conv.0 tensor(0.0312)
features.6.conv.3 tensor(0.0480)
features.6.conv.6 tensor(0.0487)
features.7.conv.0 tensor(0.0656)
features.7.conv.3 tensor(0.1227)
features.7.conv.6 tensor(0.1597)
features.8.conv.0 tensor(0.0786)
features.8.conv.3 tensor(0.1102)
features.8.conv.6 tensor(0.2367)
features.9.conv.0 tensor(0.0780)
features.9.conv.3 tensor(0.1435)
features.9.conv.6 tensor(0.3067)
features.10.conv.0 tensor(0.0354)
features.10.conv.3 tensor(0.0940)
features.10.conv.6 tensor(0.1173)
features.11.conv.0 tensor(0.5819)
features.11.conv.3 tensor(0.1549)
features.11.conv.6 tensor(0.6371)
features.12.conv.0 tensor(0.3959)
features.12.conv.3 tensor(0.1493)
features.12.conv.6 tensor(0.7401)
features.13.conv.0 tensor(0.1275)
features.13.conv.3 tensor(0.1246)
features.13.conv.6 tensor(0.3709)
features.14.conv.0 tensor(0.9028)
features.14.conv.3 tensor(0.0685)
features.14.conv.6 tensor(0.9876)
features.15.conv.0 tensor(0.9496)
features.15.conv.3 tensor(0.0593)
features.15.conv.6 tensor(0.9788)
features.16.conv.0 tensor(0.2588)
features.16.conv.3 tensor(0.1184)
features.16.conv.6 tensor(0.4378)
conv.0 tensor(0.5493)
tensor(1195140.) 2188896.0
INFO - ==> Top1: 88.770    Top5: 99.490    Loss: 0.373
INFO - ==> Sparsity : 0.546
INFO - Scoreboard best 1 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
INFO - Scoreboard best 3 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
0.71945202
0.71942580
0.71953404
0.71949452
0.71971315
0.71939862
0.71935630
0.71952492
0.71974045
0.71981597
0.71978086
0.71982229
0.71993613
0.72013563
0.72019076
0.72046095
0.72072530
0.72103816
0.72091925
0.72083050
INFO - Training [55][   20/  196]   Loss 0.316280   Top1 88.964844   Top5 98.710938   BatchTime 0.423312   LR 0.000381
0.72085255
0.72068632
0.72049278
0.72041160
0.72046250
0.72052532
0.72050554
0.72056288
0.72041911
0.71998888
0.72000611
0.71993303
0.71979791
0.71948212
0.71933901
0.71889722
0.71865749
0.71858078
0.71843296
0.71845031
0.71816975
0.71821851
INFO - Training [55][   40/  196]   Loss 0.307795   Top1 89.628906   Top5 98.710938   BatchTime 0.394938   LR 0.000377
0.71833843
0.71800208
0.71780574
0.71760285
0.71743315
0.71705085
0.71654183
0.71648353
0.71631759
0.71606433
0.71602994
0.71600610
0.71600974
0.71600509
0.71581596
0.71568894
0.71569264
INFO - Training [55][   60/  196]   Loss 0.309214   Top1 89.531250   Top5 98.808594   BatchTime 0.385556   LR 0.000372
0.71559489
0.71543324
0.71527058
0.71503419
0.71473867
0.71450627
0.71432561
0.71412665
0.71400583
0.71396703
0.71392399
0.71386993
0.71371371
0.71331543
0.71292305
0.71242291
0.71189255
0.71134245
0.71071923
0.70979935
0.70891029
0.70786041
INFO - Training [55][   80/  196]   Loss 0.308615   Top1 89.536133   Top5 98.979492   BatchTime 0.380312   LR 0.000368
0.70593858
0.70540375
0.70522344
0.70504111
0.70500243
0.70501906
0.70506769
0.70509553
0.70513684
0.70521849
0.70513666
0.70516396
0.70518351
0.70521122
0.70531136
0.70535272
0.70534623
0.70532519
0.70527995
0.70516872
0.70510113
INFO - Training [55][  100/  196]   Loss 0.307286   Top1 89.628906   Top5 98.945312   BatchTime 0.378284   LR 0.000363
0.70506465
0.70503724
0.70503277
0.70499647
0.70498645
0.70500124
0.70496356
0.70486617
0.70482051
0.70477587
0.70473886
0.70472646
0.70475030
0.70480436
0.70488346
0.70488560
0.70493990
INFO - Training [55][  120/  196]   Loss 0.301082   Top1 89.833984   Top5 99.016927   BatchTime 0.374216   LR 0.000358
0.70502371
0.70508724
0.70514536
0.70518315
0.70523727
0.70528072
0.70525998
0.70521802
0.70518750
0.70516443
0.70509809
0.70504445
0.70499188
0.70489079
0.70477331
0.70471716
0.70475143
0.70474678
0.70472169
0.70463079
INFO - Training [55][  140/  196]   Loss 0.302381   Top1 89.863281   Top5 99.065290   BatchTime 0.378688   LR 0.000354
0.70452809
0.70443523
0.70430052
0.70418024
0.70400321
0.70381433
0.70377511
0.70378268
0.70382333
0.70380682
0.70375383
0.70373958
0.70370263
0.70366716
0.70359689
0.70353514
0.70345098
0.70337975
0.70327753
0.70322150
0.70315838
0.70308107
INFO - Training [55][  160/  196]   Loss 0.303213   Top1 89.833984   Top5 99.082031   BatchTime 0.376941   LR 0.000349
0.70298392
0.70298457
0.70290047
0.70281279
0.70283282
0.70278794
0.70278335
0.70279461
0.70280039
0.70283103
0.70284551
0.70286041
0.70286095
0.70286995
0.70291734
0.70301998
0.70309436
0.70316035
0.70320106
0.70319134
0.70319533
0.70316279
INFO - Training [55][  180/  196]   Loss 0.304037   Top1 89.774306   Top5 99.053819   BatchTime 0.375864   LR 0.000345
0.70315242
0.70317942
0.70315707
0.70310050
0.70295459
0.70279306
0.70266491
0.70252085
0.70239955
0.70223910
0.70209849
0.70189196
0.70178181
INFO - ==> Top1: 89.812    Top5: 99.050    Loss: 0.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [55][   20/   40]   Loss 0.323436   Top1 90.078125   Top5 99.609375   BatchTime 0.138208
features.0.conv.0 tensor(0.4271)
features.0.conv.3 tensor(0.3730)
features.1.conv.0 tensor(0.0111)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0404)
features.2.conv.0 tensor(0.0272)
features.2.conv.3 tensor(0.0509)
features.2.conv.6 tensor(0.0775)
features.3.conv.0 tensor(0.0205)
features.3.conv.3 tensor(0.0440)
features.3.conv.6 tensor(0.0221)
features.4.conv.0 tensor(0.0350)
features.4.conv.3 tensor(0.0851)
features.4.conv.6 tensor(0.1061)
features.5.conv.0 tensor(0.0361)
features.5.conv.3 tensor(0.0608)
features.5.conv.6 tensor(0.1102)
features.6.conv.0 tensor(0.0298)
features.6.conv.3 tensor(0.0463)
features.6.conv.6 tensor(0.0479)
features.7.conv.0 tensor(0.0682)
features.7.conv.3 tensor(0.1204)
features.7.conv.6 tensor(0.2166)
features.8.conv.0 tensor(0.0821)
features.8.conv.3 tensor(0.1123)
features.8.conv.6 tensor(0.2506)
features.9.conv.0 tensor(0.0812)
features.9.conv.3 tensor(0.1467)
features.9.conv.6 tensor(0.3232)
features.10.conv.0 tensor(0.0358)
features.10.conv.3 tensor(0.0955)
features.10.conv.6 tensor(0.1115)
features.11.conv.0 tensor(0.5652)
features.11.conv.3 tensor(0.1539)
features.11.conv.6 tensor(0.6182)
features.12.conv.0 tensor(0.4186)
features.12.conv.3 tensor(0.1508)
features.12.conv.6 tensor(0.7292)
features.13.conv.0 tensor(0.1262)
features.13.conv.3 tensor(0.1223)
features.13.conv.6 tensor(0.3707)
features.14.conv.0 tensor(0.9032)
features.14.conv.3 tensor(0.0698)
features.14.conv.6 tensor(0.9872)
features.15.conv.0 tensor(0.9507)
features.15.conv.3 tensor(0.0590)
features.15.conv.6 tensor(0.9782)
features.16.conv.0 tensor(0.3272)
features.16.conv.3 tensor(0.1181)
features.16.conv.6 tensor(0.4240)
conv.0 tensor(0.5222)
tensor(1191215.) 2188896.0
INFO - Validation [55][   40/   40]   Loss 0.309215   Top1 90.300000   Top5 99.710000   BatchTime 0.106582
INFO - ==> Top1: 90.300    Top5: 99.710    Loss: 0.309
INFO - ==> Sparsity : 0.544
INFO - Scoreboard best 1 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
INFO - Scoreboard best 2 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
INFO - Scoreboard best 3 ==> Epoch [55][Top1: 90.300   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
0.70163220
0.70148534
0.70135713
0.70117718
0.70096207
0.70074475
0.70051408
0.70040005
0.70028424
0.70022070
0.70017672
0.70010108
0.70013028
0.70009857
0.70013505
0.70026273
0.70036370
0.70046180
0.70056301
INFO - Training [56][   20/  196]   Loss 0.325557   Top1 88.886719   Top5 98.671875   BatchTime 0.440375   LR 0.000337
0.70061511
0.70071203
0.70087433
0.70097125
0.70105875
0.70117557
0.70121855
0.70124108
0.70128655
0.70131391
0.70136094
0.70139211
0.70139682
0.70129615
0.70121974
0.70115155
0.70099986
0.70088589
0.70076525
0.70064050
INFO - Training [56][   40/  196]   Loss 0.320336   Top1 89.218750   Top5 98.798828   BatchTime 0.415615   LR 0.000333
0.70057112
0.70049191
0.70044577
0.70033437
0.70025611
0.70067966
0.70242208
0.70414084
0.70632416
0.71299917
0.71280622
0.71287078
0.71320981
0.71341771
0.71311295
0.71346039
0.71356112
0.71332496
0.71345866
0.71361655
0.71361512
INFO - Training [56][   60/  196]   Loss 0.313664   Top1 89.544271   Top5 98.873698   BatchTime 0.406432   LR 0.000328
0.71369666
0.71363401
0.71367323
0.71378863
0.71367973
0.71409744
0.71642548
0.71677613
0.71643555
0.71650189
0.71644348
0.71652544
0.71616161
0.71613538
0.71612895
0.71613717
0.71630120
0.71613377
0.71638471
0.71634996
0.71636850
0.71643054
INFO - Training [56][   80/  196]   Loss 0.313113   Top1 89.599609   Top5 98.979492   BatchTime 0.397124   LR 0.000324
0.71629840
0.71659762
0.71656317
0.71642178
0.71660048
0.71664906
0.71660191
0.71681571
0.71684748
0.71707618
0.71703416
0.71703619
0.71683747
0.71691018
0.71687943
0.71695340
0.71722180
INFO - Training [56][  100/  196]   Loss 0.306452   Top1 89.742188   Top5 99.039062   BatchTime 0.389294   LR 0.000319
0.71695530
0.71709979
0.71701902
0.71684813
0.71674293
0.71661788
0.71654624
0.71658480
0.71659523
0.71662796
0.71670157
0.71688306
0.71687597
0.71654266
0.71647936
0.71646154
0.71645725
0.71623176
0.71624368
0.71597719
INFO - Training [56][  120/  196]   Loss 0.301949   Top1 89.850260   Top5 99.108073   BatchTime 0.390722   LR 0.000315
0.71603900
0.71578366
0.71553040
0.71570420
0.71580744
0.71578103
0.71553504
0.71558237
0.71537071
0.71544814
0.71521318
0.71534383
0.71547168
0.71532756
0.71525747
0.71524739
0.71504015
0.71507299
0.71511257
0.71494120
0.71498090
0.71490592
INFO - Training [56][  140/  196]   Loss 0.300277   Top1 89.969308   Top5 99.140625   BatchTime 0.387647   LR 0.000311
0.71473449
0.71468657
0.71479881
0.71486980
0.71464992
0.71479696
0.71494514
0.71513093
0.71514142
0.71509451
0.71533853
0.71547520
0.71578038
0.71592915
0.71601254
0.71612412
0.71640027
0.71668506
0.71689481
0.71695113
0.71683717
INFO - Training [56][  160/  196]   Loss 0.303570   Top1 89.887695   Top5 99.118652   BatchTime 0.386429   LR 0.000306
0.71682626
0.71702439
0.71734887
0.71707815
0.71715885
0.71727931
0.71702719
0.71716392
0.71714568
0.71706277
0.71706724
0.71714771
0.71714568
0.71703887
0.71671742
0.71679598
0.71626675
INFO - Training [56][  180/  196]   Loss 0.303195   Top1 89.895833   Top5 99.069010   BatchTime 0.382592   LR 0.000302
0.71647584
0.71617502
0.71618491
0.71622884
0.71604306
0.71597046
0.71580899
0.71553278
0.71485239
0.71405768
0.71359682
0.71317732
0.71286416
0.71252376
0.71212536
0.71175158
0.71140343
INFO - ==> Top1: 89.944    Top5: 99.064    Loss: 0.302
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 0.294323   Top1 90.859375   Top5 99.609375   BatchTime 0.126243
features.0.conv.0 tensor(0.4236)
features.0.conv.3 tensor(0.3242)
features.1.conv.0 tensor(0.0124)
features.1.conv.3 tensor(0.0833)
features.1.conv.6 tensor(0.0434)
features.2.conv.0 tensor(0.0286)
features.2.conv.3 tensor(0.0525)
features.2.conv.6 tensor(0.0755)
features.3.conv.0 tensor(0.0200)
features.3.conv.3 tensor(0.0424)
features.3.conv.6 tensor(0.0219)
features.4.conv.0 tensor(0.0379)
features.4.conv.3 tensor(0.0816)
features.4.conv.6 tensor(0.0929)
features.5.conv.0 tensor(0.0371)
features.5.conv.3 tensor(0.0642)
features.5.conv.6 tensor(0.1045)
features.6.conv.0 tensor(0.0267)
features.6.conv.3 tensor(0.0451)
features.6.conv.6 tensor(0.0461)
features.7.conv.0 tensor(0.0684)
features.7.conv.3 tensor(0.1198)
features.7.conv.6 tensor(0.1948)
features.8.conv.0 tensor(0.0865)
features.8.conv.3 tensor(0.1079)
features.8.conv.6 tensor(0.2450)
features.9.conv.0 tensor(0.0849)
features.9.conv.3 tensor(0.1455)
features.9.conv.6 tensor(0.3070)
features.10.conv.0 tensor(0.0340)
features.10.conv.3 tensor(0.0940)
features.10.conv.6 tensor(0.1169)
features.11.conv.0 tensor(0.5795)
features.11.conv.3 tensor(0.1549)
features.11.conv.6 tensor(0.6206)
features.12.conv.0 tensor(0.4099)
features.12.conv.3 tensor(0.1516)
features.12.conv.6 tensor(0.7280)
features.13.conv.0 tensor(0.1404)
features.13.conv.3 tensor(0.1227)
features.13.conv.6 tensor(0.3721)
features.14.conv.0 tensor(0.9037)
features.14.conv.3 tensor(0.0692)
features.14.conv.6 tensor(0.9871)
features.15.conv.0 tensor(0.9502)
features.15.conv.3 tensor(0.0596)
features.15.conv.6 tensor(0.9784)
features.16.conv.0 tensor(0.2613)
features.16.conv.3 tensor(0.1155)
features.16.conv.6 tensor(0.4394)
conv.0 tensor(0.5453)
tensor(1195697.) 2188896.0
INFO - Validation [56][   40/   40]   Loss 0.277298   Top1 91.220000   Top5 99.700000   BatchTime 0.091416
INFO - ==> Top1: 91.220    Top5: 99.700    Loss: 0.277
INFO - ==> Sparsity : 0.546
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
INFO - Scoreboard best 3 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
0.71087992
0.71033353
0.70976996
0.70918900
0.70864171
0.70812505
0.70765269
0.70716208
0.70668656
0.70605731
0.70524520
0.70464528
0.70407599
0.70357299
0.70308191
0.70265561
0.70221251
0.70190161
0.70181423
INFO - Training [57][   20/  196]   Loss 0.308413   Top1 89.414062   Top5 98.300781   BatchTime 0.447812   LR 0.000294
0.70180422
0.70168638
0.70157790
0.70164025
0.70154238
0.70140618
0.70127195
0.70108455
0.70096982
0.70065814
0.70039904
0.70000976
0.69987476
0.69975698
0.69976258
0.69958860
0.69955850
0.69958317
0.69952571
0.69935614
0.69923329
0.69908714
0.69890392
INFO - Training [57][   40/  196]   Loss 0.308863   Top1 89.511719   Top5 98.525391   BatchTime 0.403388   LR 0.000290
0.69884694
0.69882649
0.69870526
0.69865203
0.69856405
0.69849825
0.69845045
0.69841546
0.69836956
0.69831657
0.69833380
0.69832766
0.69830883
0.69824964
0.69820869
0.69812191
0.69802547
INFO - Training [57][   60/  196]   Loss 0.310563   Top1 89.505208   Top5 98.626302   BatchTime 0.386624   LR 0.000286
0.69800228
0.69800061
0.69793153
0.69780880
0.69771731
0.69769442
0.69760221
0.69746500
0.69728166
0.69717509
0.69710916
0.69708806
0.69705570
0.69701999
0.69699758
0.69699937
0.69701231
0.69705611
0.69706500
0.69714952
0.69720757
0.69727159
INFO - Training [57][   80/  196]   Loss 0.313083   Top1 89.506836   Top5 98.764648   BatchTime 0.380001   LR 0.000282
0.69726539
0.69723499
0.69725746
0.69728214
0.69733673
0.69731861
0.69728321
0.69727069
0.69734848
0.69747549
0.69764966
0.69776762
0.69789630
0.69805104
0.69819903
0.69844484
0.69865966
0.69891381
0.69923359
0.69956958
0.69975346
INFO - Training [57][  100/  196]   Loss 0.305562   Top1 89.738281   Top5 98.875000   BatchTime 0.380825   LR 0.000277
0.69988495
0.70001423
0.70004237
0.70012051
0.70021361
0.70030540
0.70036381
0.70041221
0.70048255
0.70058471
0.70067799
0.70076376
0.70084697
0.70093310
0.70102853
0.70106226
0.70109069
INFO - Training [57][  120/  196]   Loss 0.300081   Top1 89.957682   Top5 98.984375   BatchTime 0.378096   LR 0.000273
0.70104146
0.70102322
0.70096195
0.70085925
0.70073104
0.70059305
0.70043659
0.70025188
0.70013458
0.70002419
0.69989336
0.69987518
0.69979405
0.69964367
0.69953501
0.69937283
0.69925320
0.69916523
0.69906068
0.69902736
0.69896990
0.69887620
0.69879723
0.69872361
INFO - Training [57][  140/  196]   Loss 0.299749   Top1 89.988839   Top5 99.034598   BatchTime 0.371431   LR 0.000269
0.69867110
0.69863880
0.69867450
0.69868326
0.69868219
0.69862711
0.69855750
0.69851518
0.69846207
0.69839442
0.69834191
0.69830370
0.69827282
0.69827414
0.69825602
0.69819301
0.69810355
0.69803214
INFO - Training [57][  160/  196]   Loss 0.302261   Top1 89.960938   Top5 99.020996   BatchTime 0.365391   LR 0.000265
0.69798893
0.69788057
0.69779676
0.69772279
0.69763285
0.69750059
0.69740403
0.69729000
0.69721770
0.69716913
0.69713932
0.69713920
0.69714689
0.69714761
0.69716120
0.69719315
0.69721502
0.69721943
0.69726890
0.69736820
INFO - Training [57][  180/  196]   Loss 0.301102   Top1 89.995660   Top5 98.977865   BatchTime 0.358553   LR 0.000261
0.69739878
0.69747162
0.69759327
0.69766742
0.69773936
0.69773316
0.69769704
0.69763160
0.69754702
0.69744289
0.69738007
0.69734055
0.69723749
0.69721794
0.69716650
********************pre-trained*****************
INFO - ==> Top1: 90.042    Top5: 98.982    Loss: 0.300
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [57][   20/   40]   Loss 0.326764   Top1 90.078125   Top5 99.628906   BatchTime 0.128657
features.0.conv.0 tensor(0.4514)
features.0.conv.3 tensor(0.3379)
features.1.conv.0 tensor(0.0137)
features.1.conv.3 tensor(0.0868)
features.1.conv.6 tensor(0.0425)
features.2.conv.0 tensor(0.0275)
features.2.conv.3 tensor(0.0517)
features.2.conv.6 tensor(0.0775)
features.3.conv.0 tensor(0.0203)
features.3.conv.3 tensor(0.0424)
features.3.conv.6 tensor(0.0191)
features.4.conv.0 tensor(0.0399)
features.4.conv.3 tensor(0.0833)
features.4.conv.6 tensor(0.0872)
features.5.conv.0 tensor(0.0384)
features.5.conv.3 tensor(0.0631)
features.5.conv.6 tensor(0.1159)
features.6.conv.0 tensor(0.0291)
features.6.conv.3 tensor(0.0475)
features.6.conv.6 tensor(0.0471)
features.7.conv.0 tensor(0.0695)
features.7.conv.3 tensor(0.1204)
features.7.conv.6 tensor(0.1824)
features.8.conv.0 tensor(0.0917)
features.8.conv.3 tensor(0.1097)
features.8.conv.6 tensor(0.2434)
features.9.conv.0 tensor(0.0839)
features.9.conv.3 tensor(0.1427)
features.9.conv.6 tensor(0.3231)
features.10.conv.0 tensor(0.0326)
features.10.conv.3 tensor(0.0946)
features.10.conv.6 tensor(0.1140)
features.11.conv.0 tensor(0.5702)
features.11.conv.3 tensor(0.1534)
features.11.conv.6 tensor(0.6235)
features.12.conv.0 tensor(0.4663)
features.12.conv.3 tensor(0.1516)
features.12.conv.6 tensor(0.7314)
features.13.conv.0 tensor(0.1390)
features.13.conv.3 tensor(0.1248)
features.13.conv.6 tensor(0.3579)
features.14.conv.0 tensor(0.9045)
features.14.conv.3 tensor(0.0684)
features.14.conv.6 tensor(0.9872)
features.15.conv.0 tensor(0.9515)
features.15.conv.3 tensor(0.0587)
features.15.conv.6 tensor(0.9773)
features.16.conv.0 tensor(0.3025)
features.16.conv.3 tensor(0.1168)
features.16.conv.6 tensor(0.4932)
conv.0 tensor(0.5480)
tensor(1221473.) 2188896.0
INFO - Validation [57][   40/   40]   Loss 0.309208   Top1 90.200000   Top5 99.660000   BatchTime 0.091091
INFO - ==> Top1: 90.200    Top5: 99.660    Loss: 0.309
INFO - ==> Sparsity : 0.558
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
INFO - Scoreboard best 3 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
0.69712937
0.69715029
0.69721860
0.69732755
0.69733566
0.69736558
0.69743001
0.69745445
0.69751406
0.69759691
0.69763142
0.69769329
0.69769973
0.69764674
0.69761723
0.69756711
0.69757217
0.69756812
0.69751000
INFO - Training [58][   20/  196]   Loss 0.317639   Top1 89.101562   Top5 98.769531   BatchTime 0.444108   LR 0.000254
0.69738680
0.69725668
0.69715714
0.69708979
0.69699043
0.69703907
0.69703543
0.69705123
0.69706017
0.69702029
0.69696748
0.69688654
0.69675982
0.69664890
0.69667447
0.69673717
0.69677442
0.69676071
0.69666851
0.69658560
0.69648349
0.69645637
INFO - Training [58][   40/  196]   Loss 0.321050   Top1 89.160156   Top5 98.779297   BatchTime 0.402206   LR 0.000250
0.69640511
0.69628066
0.69619572
0.69617909
0.69620514
0.69623715
0.69628841
0.69630063
0.69634295
0.69629747
0.69628501
0.69635797
0.69637835
0.69642162
0.69643730
0.69644725
0.69648606
INFO - Training [58][   60/  196]   Loss 0.314707   Top1 89.440104   Top5 98.795573   BatchTime 0.383471   LR 0.000246
0.69653296
0.69657952
0.69658351
0.69660234
0.69661516
0.69659865
0.69661528
0.69660801
0.69660324
0.69657326
0.69656116
0.69651526
0.69650954
0.69647050
0.69649863
0.69650519
0.69646221
0.69646174
0.69647515
0.69646603
0.69647789
INFO - Training [58][   80/  196]   Loss 0.309106   Top1 89.682617   Top5 98.920898   BatchTime 0.385327   LR 0.000242
0.69645089
0.69639313
0.69631541
0.69626880
0.69620830
0.69611788
0.69602913
0.69590873
0.69588464
0.69582373
0.69581920
0.69585466
0.69588470
0.69595134
0.69607973
0.69615960
0.69620675
0.69617307
0.69617707
0.69617289
0.69618642
0.69616175
INFO - Training [58][  100/  196]   Loss 0.302832   Top1 89.886719   Top5 98.949219   BatchTime 0.381132   LR 0.000238
0.69614810
0.69614714
0.69614804
0.69613922
0.69608814
0.69604844
0.69605970
0.69607335
0.69607401
0.69605201
0.69603270
0.69597900
0.69595212
0.69598633
0.69599980
0.69603097
0.69607025
0.69617188
0.69627875
0.69638032
0.69641393
0.69643217
INFO - Training [58][  120/  196]   Loss 0.297103   Top1 90.097656   Top5 99.016927   BatchTime 0.376658   LR 0.000234
0.69649124
0.69653642
0.69655609
0.69658506
0.69662094
0.69669092
0.69677889
0.69687045
0.69695348
0.69705606
0.69713032
0.69726425
0.69740838
0.69752592
0.69761324
0.69771463
0.69779259
0.69784009
INFO - Training [58][  140/  196]   Loss 0.295612   Top1 90.200893   Top5 99.056920   BatchTime 0.373366   LR 0.000230
0.69789541
0.69800079
0.69804198
0.69808042
0.69812065
0.69818765
0.69828618
0.69839197
0.69849360
0.69854051
0.69857150
0.69856834
0.69853091
0.69849604
0.69846189
0.69841552
0.69835430
0.69826150
0.69815898
0.69805765
INFO - Training [58][  160/  196]   Loss 0.298161   Top1 90.139160   Top5 99.040527   BatchTime 0.362838   LR 0.000226
0.69798809
0.69789845
0.69784516
0.69781572
0.69782132
0.69780999
0.69775838
0.69770771
0.69769502
0.69768775
0.69767147
0.69765753
0.69766259
0.69767368
0.69764531
0.69763124
0.69764686
0.69766462
INFO - Training [58][  180/  196]   Loss 0.298823   Top1 90.130208   Top5 98.995226   BatchTime 0.361091   LR 0.000222
0.69771749
0.69776064
0.69783139
0.69792241
0.69802004
0.69813216
0.69823420
0.69830793
0.69835907
0.69841743
0.69845366
0.69852835
0.69858181
0.69857216
0.69857854
0.69855154
0.69854021
********************pre-trained*****************
INFO - ==> Top1: 90.132    Top5: 98.990    Loss: 0.298
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [58][   20/   40]   Loss 0.299072   Top1 90.917969   Top5 99.589844   BatchTime 0.125923
INFO - Validation [58][   40/   40]   Loss 0.284580   Top1 91.130000   Top5 99.700000   BatchTime 0.090486
INFO - ==> Top1: 91.130    Top5: 99.700    Loss: 0.285
INFO - ==> Sparsity : 0.552
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4618)
features.0.conv.3 tensor(0.3477)
features.1.conv.0 tensor(0.0150)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0417)
features.2.conv.0 tensor(0.0286)
features.2.conv.3 tensor(0.0540)
features.2.conv.6 tensor(0.0770)
features.3.conv.0 tensor(0.0203)
features.3.conv.3 tensor(0.0455)
features.3.conv.6 tensor(0.0211)
features.4.conv.0 tensor(0.0363)
features.4.conv.3 tensor(0.0839)
features.4.conv.6 tensor(0.0928)
features.5.conv.0 tensor(0.0425)
features.5.conv.3 tensor(0.0642)
features.5.conv.6 tensor(0.1162)
features.6.conv.0 tensor(0.0282)
features.6.conv.3 tensor(0.0451)
features.6.conv.6 tensor(0.0479)
features.7.conv.0 tensor(0.0703)
features.7.conv.3 tensor(0.1215)
features.7.conv.6 tensor(0.1872)
features.8.conv.0 tensor(0.0954)
features.8.conv.3 tensor(0.1102)
features.8.conv.6 tensor(0.2458)
features.9.conv.0 tensor(0.0867)
features.9.conv.3 tensor(0.1461)
features.9.conv.6 tensor(0.3262)
features.10.conv.0 tensor(0.0327)
features.10.conv.3 tensor(0.0940)
features.10.conv.6 tensor(0.1171)
features.11.conv.0 tensor(0.5638)
features.11.conv.3 tensor(0.1510)
features.11.conv.6 tensor(0.6300)
features.12.conv.0 tensor(0.4247)
features.12.conv.3 tensor(0.1493)
features.12.conv.6 tensor(0.7339)
features.13.conv.0 tensor(0.1375)
features.13.conv.3 tensor(0.1233)
features.13.conv.6 tensor(0.3987)
features.14.conv.0 tensor(0.9046)
features.14.conv.3 tensor(0.0682)
features.14.conv.6 tensor(0.9872)
features.15.conv.0 tensor(0.9520)
features.15.conv.3 tensor(0.0581)
features.15.conv.6 tensor(0.9778)
features.16.conv.0 tensor(0.2747)
features.16.conv.3 tensor(0.1159)
features.16.conv.6 tensor(0.4397)
conv.0 tensor(0.5599)
tensor(1207949.) 2188896.0
0.69854182
0.69853359
0.69848150
0.69843727
0.69844586
0.69841194
0.69837427
0.69830143
0.69822347
0.69815403
0.69805020
0.69797665
0.69788247
0.69772023
0.69753599
0.69736350
0.69724607
0.69708467
0.69696921
0.69686216
0.69682348
INFO - Training [59][   20/  196]   Loss 0.311720   Top1 89.511719   Top5 98.515625   BatchTime 0.443442   LR 0.000215
0.69672644
0.69665122
0.69659269
0.69648939
0.69640654
0.69632316
0.69623655
0.69619089
0.69612604
0.69605976
0.69594729
0.69585878
0.69591647
0.69594908
0.69599456
0.69602162
0.69604439
INFO - Training [59][   40/  196]   Loss 0.314301   Top1 89.765625   Top5 98.818359   BatchTime 0.401719   LR 0.000212
0.69615108
0.69623369
0.69638973
0.69650781
0.69659233
0.69664997
0.69670975
0.69673705
0.69678068
0.69680279
0.69678575
0.69673032
0.69667816
0.69664967
0.69657975
0.69656998
0.69644916
0.69632339
0.69620943
0.69611210
0.69605267
0.69597775
INFO - Training [59][   60/  196]   Loss 0.308641   Top1 89.824219   Top5 98.932292   BatchTime 0.386496   LR 0.000208
0.69588536
0.69580716
0.69579935
0.69577342
0.69573539
0.69567257
0.69561678
0.69556397
0.69550472
0.69540554
0.69536084
0.69531733
0.69522172
0.69509572
0.69498366
0.69489986
0.69480139
0.69475681
0.69474334
0.69471192
0.69469345
INFO - Training [59][   80/  196]   Loss 0.306313   Top1 89.804688   Top5 99.028320   BatchTime 0.386517   LR 0.000204
0.69468027
0.69463420
0.69454914
0.69454551
0.69455701
0.69458210
0.69457984
0.69455659
0.69450837
0.69444138
0.69439292
0.69436210
0.69431663
0.69431496
0.69431955
0.69433933
0.69432598
0.69429487
0.69429553
0.69424808
0.69417799
INFO - Training [59][  100/  196]   Loss 0.301484   Top1 89.972656   Top5 99.046875   BatchTime 0.384945   LR 0.000201
0.69411647
0.69403422
0.69397712
0.69387555
0.69381887
0.69376218
0.69365788
0.69349360
0.69335771
0.69326109
0.69323081
0.69315976
0.69306141
0.69296801
0.69297767
0.69300348
0.69300038
INFO - Training [59][  120/  196]   Loss 0.298112   Top1 90.074870   Top5 99.121094   BatchTime 0.381510   LR 0.000197
0.69299489
0.69296259
0.69291866
0.69289297
0.69292980
0.69295627
0.69299036
0.69306272
0.69309580
0.69315612
0.69321316
0.69325268
0.69326174
0.69326705
0.69325304
0.69325829
0.69336712
0.69343030
0.69348741
INFO - Training [59][  140/  196]   Loss 0.296761   Top1 90.159040   Top5 99.143415   BatchTime 0.370351   LR 0.000193
0.69357938
0.69361633
0.69364536
0.69372267
0.69379884
0.69381803
0.69383037
0.69393587
0.69403130
0.69413936
0.69425339
0.69437206
0.69445395
0.69460386
0.69471449
0.69481581
0.69487727
0.69495064
0.69499207
0.69503045
0.69511509
0.69514042
INFO - Training [59][  160/  196]   Loss 0.299391   Top1 90.039062   Top5 99.123535   BatchTime 0.359649   LR 0.000190
0.69519675
0.69520760
0.69522148
0.69518572
0.69510335
0.69506335
0.69501543
0.69495964
0.69497114
0.69496131
0.69495088
0.69496250
0.69491845
0.69488484
0.69482613
0.69478172
0.69475895
0.69473225
0.69469839
0.69466501
0.69461489
0.69457799
0.69459969
INFO - Training [59][  180/  196]   Loss 0.298045   Top1 90.080295   Top5 99.066840   BatchTime 0.357109   LR 0.000186
0.69457817
0.69455594
0.69454151
0.69448024
0.69442916
0.69437289
0.69433749
0.69428229
0.69420993
0.69415933
0.69410741
INFO - ==> Top1: 90.130    Top5: 99.070    Loss: 0.297
0.69405311
0.69405746
********************pre-trained*****************
validation quantized model on cpu
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [59][   20/   40]   Loss 0.316612   Top1 90.351562   Top5 99.648438   BatchTime 0.135537
INFO - Validation [59][   40/   40]   Loss 0.301409   Top1 90.600000   Top5 99.730000   BatchTime 0.094958
INFO - ==> Top1: 90.600    Top5: 99.730    Loss: 0.301
INFO - ==> Sparsity : 0.565
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  60
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4444)
features.0.conv.3 tensor(0.3340)
features.1.conv.0 tensor(0.0163)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0412)
features.2.conv.0 tensor(0.0333)
features.2.conv.3 tensor(0.0517)
features.2.conv.6 tensor(0.0761)
features.3.conv.0 tensor(0.0217)
features.3.conv.3 tensor(0.0440)
features.3.conv.6 tensor(0.0213)
features.4.conv.0 tensor(0.0347)
features.4.conv.3 tensor(0.0839)
features.4.conv.6 tensor(0.0993)
features.5.conv.0 tensor(0.0402)
features.5.conv.3 tensor(0.0666)
features.5.conv.6 tensor(0.1257)
features.6.conv.0 tensor(0.0298)
features.6.conv.3 tensor(0.0434)
features.6.conv.6 tensor(0.0473)
features.7.conv.0 tensor(0.0728)
features.7.conv.3 tensor(0.1224)
features.7.conv.6 tensor(0.1895)
features.8.conv.0 tensor(0.0909)
features.8.conv.3 tensor(0.1076)
features.8.conv.6 tensor(0.2560)
features.9.conv.0 tensor(0.0896)
features.9.conv.3 tensor(0.1441)
features.9.conv.6 tensor(0.3215)
features.10.conv.0 tensor(0.0367)
features.10.conv.3 tensor(0.0955)
features.10.conv.6 tensor(0.1208)
features.11.conv.0 tensor(0.5708)
features.11.conv.3 tensor(0.1508)
features.11.conv.6 tensor(0.6431)
features.12.conv.0 tensor(0.4406)
features.12.conv.3 tensor(0.1491)
features.12.conv.6 tensor(0.7358)
features.13.conv.0 tensor(0.1421)
features.13.conv.3 tensor(0.1229)
features.13.conv.6 tensor(0.3940)
features.14.conv.0 tensor(0.9054)
features.14.conv.3 tensor(0.0697)
features.14.conv.6 tensor(0.9874)
features.15.conv.0 tensor(0.9526)
features.15.conv.3 tensor(0.0598)
features.15.conv.6 tensor(0.9766)
features.16.conv.0 tensor(0.3065)
features.16.conv.3 tensor(0.1152)
features.16.conv.6 tensor(0.4955)
conv.0 tensor(0.5683)
tensor(1235930.) 2188896.0
0.69407022
0.69409055
0.69414902
0.69416744
0.69418794
0.69416636
0.69411010
0.69408166
0.69403583
0.69397837
0.69388574
0.69388950
0.69389915
0.69386107
0.69383073
0.69381618
0.69375187
0.69372469
0.69376522
0.69378906
0.69379145
0.69375300
0.69369012
INFO - Training [60][   20/  196]   Loss 0.296749   Top1 89.433594   Top5 98.769531   BatchTime 0.426704   LR 0.000180
0.69357926
0.69347721
0.69342297
0.69332176
0.69321400
0.69314808
0.69307005
0.69300526
0.69292516
0.69285965
0.69282115
0.69275308
0.69269651
0.69260001
0.69250220
INFO - Training [60][   40/  196]   Loss 0.298724   Top1 89.492188   Top5 98.935547   BatchTime 0.406464   LR 0.000176
0.69234341
0.69219232
0.69203240
0.69200158
0.69193584
0.69194549
0.69192719
0.69192266
0.69189298
0.69191092
0.69195032
0.69201577
0.69203848
0.69207847
0.69210613
0.69213510
0.69211686
0.69205981
0.69202030
0.69200057
0.69203091
0.69209099
INFO - Training [60][   60/  196]   Loss 0.297419   Top1 89.778646   Top5 98.945312   BatchTime 0.390507   LR 0.000173
0.69213921
0.69216639
0.69213229
0.69211936
0.69211942
0.69208264
0.69203454
0.69195569
0.69184357
0.69173032
0.69159913
0.69150519
0.69143707
0.69138557
0.69135028
0.69130570
0.69125986
0.69120121
0.69119352
0.69120860
INFO - Training [60][   80/  196]   Loss 0.296108   Top1 89.882812   Top5 99.013672   BatchTime 0.392531   LR 0.000169
0.69122463
0.69127297
0.69132155
0.69136482
0.69138193
0.69136822
0.69136769
0.69142008
0.69142264
0.69144529
0.69150019
0.69152743
0.69155121
0.69159651
0.69172114
0.69176877
0.69179934
0.69181544
0.69179553
0.69178873
0.69185865
0.69193685
0.69196224
INFO - Training [60][  100/  196]   Loss 0.292687   Top1 90.070312   Top5 99.003906   BatchTime 0.385550   LR 0.000166
0.69204718
0.69215065
0.69221812
0.69228142
0.69232202
0.69227046
0.69223750
0.69218600
0.69215131
0.69209629
0.69205052
0.69202524
0.69192988
0.69182789
0.69178361
0.69175261
0.69173080
INFO - Training [60][  120/  196]   Loss 0.289469   Top1 90.231120   Top5 99.046224   BatchTime 0.380160   LR 0.000162
0.69170451
0.69166017
0.69164616
0.69162416
0.69167674
0.69174242
0.69181174
0.69186646
0.69190317
0.69190174
0.69191450
0.69196159
0.69198126
0.69204569
0.69207156
0.69213784
0.69217747
0.69218981
INFO - Training [60][  140/  196]   Loss 0.286940   Top1 90.318080   Top5 99.104353   BatchTime 0.372960   LR 0.000159
0.69220263
0.69216591
0.69209093
0.69201905
0.69195884
0.69190925
0.69178808
0.69160688
0.69143206
0.69126362
0.69108999
0.69097096
0.69089329
0.69087613
0.69084960
0.69078434
0.69075614
0.69068551
0.69064933
0.69059372
0.69056368
0.69051248
0.69046903
0.69038403
0.69032419
0.69026083
INFO - Training [60][  160/  196]   Loss 0.289574   Top1 90.236816   Top5 99.072266   BatchTime 0.364890   LR 0.000156
0.69018483
0.69014603
0.69006270
0.68997979
0.68992019
0.68985975
0.68978846
0.68967998
0.68953586
0.68942571
0.68932271
0.68923849
0.68912768
0.68905711
INFO - Training [60][  180/  196]   Loss 0.288965   Top1 90.221354   Top5 99.066840   BatchTime 0.356652   LR 0.000152
0.68896818
0.68892694
0.68894160
0.68894476
0.68897778
0.68898892
0.68897361
0.68894261
0.68897122
0.68898576
0.68898761
0.68899322
0.68903589
0.68911701
0.68923110
0.68933958
0.68946481
0.68958205
********************pre-trained*****************
INFO - ==> Top1: 90.324    Top5: 99.080    Loss: 0.287
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [60][   20/   40]   Loss 0.320069   Top1 90.429688   Top5 99.648438   BatchTime 0.162987
INFO - Validation [60][   40/   40]   Loss 0.307432   Top1 90.650000   Top5 99.690000   BatchTime 0.108699
INFO - ==> Top1: 90.650    Top5: 99.690    Loss: 0.307
INFO - ==> Sparsity : 0.575
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  61
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4514)
features.0.conv.3 tensor(0.3457)
features.1.conv.0 tensor(0.0130)
features.1.conv.3 tensor(0.0880)
features.1.conv.6 tensor(0.0425)
features.2.conv.0 tensor(0.0359)
features.2.conv.3 tensor(0.0502)
features.2.conv.6 tensor(0.0752)
features.3.conv.0 tensor(0.0234)
features.3.conv.3 tensor(0.0440)
features.3.conv.6 tensor(0.0228)
features.4.conv.0 tensor(0.0345)
features.4.conv.3 tensor(0.0822)
features.4.conv.6 tensor(0.0985)
features.5.conv.0 tensor(0.0443)
features.5.conv.3 tensor(0.0637)
features.5.conv.6 tensor(0.1302)
features.6.conv.0 tensor(0.0304)
features.6.conv.3 tensor(0.0451)
features.6.conv.6 tensor(0.0467)
features.7.conv.0 tensor(0.0885)
features.7.conv.3 tensor(0.1195)
features.7.conv.6 tensor(0.1863)
features.8.conv.0 tensor(0.0895)
features.8.conv.3 tensor(0.1100)
features.8.conv.6 tensor(0.2740)
features.9.conv.0 tensor(0.0872)
features.9.conv.3 tensor(0.1455)
features.9.conv.6 tensor(0.3268)
features.10.conv.0 tensor(0.0385)
features.10.conv.3 tensor(0.0981)
features.10.conv.6 tensor(0.1278)
features.11.conv.0 tensor(0.5801)
features.11.conv.3 tensor(0.1512)
features.11.conv.6 tensor(0.6529)
features.12.conv.0 tensor(0.4382)
features.12.conv.3 tensor(0.1466)
features.12.conv.6 tensor(0.7358)
features.13.conv.0 tensor(0.1425)
features.13.conv.3 tensor(0.1246)
features.13.conv.6 tensor(0.4190)
features.14.conv.0 tensor(0.9059)
features.14.conv.3 tensor(0.0694)
features.14.conv.6 tensor(0.9876)
features.15.conv.0 tensor(0.9534)
features.15.conv.3 tensor(0.0589)
features.15.conv.6 tensor(0.9774)
features.16.conv.0 tensor(0.3288)
features.16.conv.3 tensor(0.1150)
features.16.conv.6 tensor(0.5142)
conv.0 tensor(0.5888)
tensor(1258264.) 2188896.0
0.68983132
0.68998843
0.69013065
0.69025624
0.69036621
0.69041270
0.69044751
0.69051641
0.69060242
0.69064671
0.69068450
0.69072849
0.69076818
0.69077384
0.69077629
0.69075179
0.69074571
0.69074631
0.69069314
0.69070393
0.69070947
0.69068676
INFO - Training [61][   20/  196]   Loss 0.325200   Top1 88.964844   Top5 98.593750   BatchTime 0.433706   LR 0.000147
0.69067132
0.69066781
0.69066560
0.69062036
0.69059128
0.69061786
0.69066876
0.69071680
0.69077617
0.69081771
0.69086903
0.69091529
0.69095868
0.69101447
0.69105005
0.69109780
INFO - Training [61][   40/  196]   Loss 0.311689   Top1 89.648438   Top5 98.642578   BatchTime 0.404296   LR 0.000143
0.69117278
0.69118345
0.69121295
0.69124150
0.69127816
0.69135612
0.69143409
0.69149292
0.69154888
0.69155931
0.69156629
0.69157469
0.69156903
0.69156784
0.69152707
0.69150513
0.69150823
0.69151783
0.69152153
0.69148040
INFO - Training [61][   60/  196]   Loss 0.304644   Top1 89.837240   Top5 98.789062   BatchTime 0.402164   LR 0.000140
0.69141728
0.69133943
0.69126022
0.69117558
0.69107807
0.69097072
0.69084698
0.69077587
0.69070506
0.69061190
0.69052839
0.69046199
0.69034004
0.69021034
0.69010395
0.69003451
0.68996876
0.68991333
0.68986613
0.68983704
0.68979603
0.68981969
0.68989879
INFO - Training [61][   80/  196]   Loss 0.301886   Top1 89.960938   Top5 98.920898   BatchTime 0.389570   LR 0.000137
0.68996835
0.69008380
0.69017577
0.69024384
0.69032907
0.69036305
0.69042206
0.69047803
0.69052237
0.69050843
0.69049102
0.69040644
0.69031960
0.69027263
0.69021273
0.69016325
0.69011080
0.69009161
0.69004089
0.68997616
0.68988597
0.68979937
INFO - Training [61][  100/  196]   Loss 0.295653   Top1 90.167969   Top5 98.964844   BatchTime 0.383892   LR 0.000134
0.68972450
0.68974060
0.68972498
0.68976063
0.68979621
0.68983144
0.68987131
0.68994009
0.69005305
0.69015366
0.69023860
0.69031870
0.69032139
0.69031751
0.69032663
0.69028598
0.69024378
INFO - Training [61][  120/  196]   Loss 0.288732   Top1 90.452474   Top5 99.026693   BatchTime 0.379358   LR 0.000131
0.69020325
0.69014454
0.69008720
0.69008392
0.69009334
0.69010407
0.69006628
0.69002742
0.68995011
0.68990654
0.68987525
0.68985343
0.68982494
0.68979794
0.68976659
0.68973786
0.68972081
0.68972087
0.68969733
0.68968284
0.68969887
0.68974197
0.68979108
0.68985707
INFO - Training [61][  140/  196]   Loss 0.288989   Top1 90.396205   Top5 99.079241   BatchTime 0.374178   LR 0.000128
0.68989730
0.68997079
0.68999827
0.69002008
0.68999243
0.68995589
0.68992215
0.68986815
0.68984050
0.68979663
0.68972307
0.68966228
0.68961400
0.68957734
0.68952274
0.68941939
0.68933862
0.68925631
INFO - Training [61][  160/  196]   Loss 0.291400   Top1 90.268555   Top5 99.074707   BatchTime 0.367981   LR 0.000125
0.68916124
0.68907207
0.68900377
0.68895316
0.68887287
0.68872589
0.68856889
0.68842471
0.68826729
0.68812460
0.68798280
0.68787420
0.68779999
0.68768096
0.68759972
0.68752682
0.68745869
0.68735921
0.68728942
INFO - Training [61][  180/  196]   Loss 0.289968   Top1 90.303819   Top5 99.042969   BatchTime 0.372842   LR 0.000122
0.68722421
0.68717128
0.68713999
0.68710202
0.68703341
0.68701595
0.68700290
0.68698889
0.68704647
0.68708849
0.68713689
0.68719059
0.68725508
0.68733937
0.68740487
********************pre-trained*****************
INFO - ==> Top1: 90.348    Top5: 99.062    Loss: 0.289
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [61][   20/   40]   Loss 0.312395   Top1 90.644531   Top5 99.589844   BatchTime 0.125013
features.0.conv.0 tensor(0.4514)
features.0.conv.3 tensor(0.3477)
features.1.conv.0 tensor(0.0117)
features.1.conv.3 tensor(0.0810)
features.1.conv.6 tensor(0.0417)
features.2.conv.0 tensor(0.0379)
features.2.conv.3 tensor(0.0509)
features.2.conv.6 tensor(0.0747)
features.3.conv.0 tensor(0.0214)
features.3.conv.3 tensor(0.0432)
features.3.conv.6 tensor(0.0211)
features.4.conv.0 tensor(0.0371)
features.4.conv.3 tensor(0.0845)
features.4.conv.6 tensor(0.0942)
features.5.conv.0 tensor(0.0428)
features.5.conv.3 tensor(0.0654)
features.5.conv.6 tensor(0.1405)
features.6.conv.0 tensor(0.0304)
features.6.conv.3 tensor(0.0428)
features.6.conv.6 tensor(0.0472)
features.7.conv.0 tensor(0.0754)
features.7.conv.3 tensor(0.1241)
features.7.conv.6 tensor(0.1918)
features.8.conv.0 tensor(0.0902)
features.8.conv.3 tensor(0.1082)
features.8.conv.6 tensor(0.2581)
features.9.conv.0 tensor(0.0912)
features.9.conv.3 tensor(0.1458)
features.9.conv.6 tensor(0.3352)
features.10.conv.0 tensor(0.0382)
features.10.conv.3 tensor(0.0966)
features.10.conv.6 tensor(0.1418)
features.11.conv.0 tensor(0.5925)
features.11.conv.3 tensor(0.1495)
features.11.conv.6 tensor(0.6464)
features.12.conv.0 tensor(0.4817)
features.12.conv.3 tensor(0.1480)
features.12.conv.6 tensor(0.7443)
features.13.conv.0 tensor(0.1454)
features.13.conv.3 tensor(0.1252)
features.13.conv.6 tensor(0.4339)
features.14.conv.0 tensor(0.9064)
features.14.conv.3 tensor(0.0696)
features.14.conv.6 tensor(0.9877)
features.15.conv.0 tensor(0.9542)
features.15.conv.3 tensor(0.0581)
features.15.conv.6 tensor(0.9773)
features.16.conv.0 tensor(0.3467)
features.16.conv.3 tensor(0.1153)
features.16.conv.6 tensor(0.5122)
conv.0 tensor(0.5700)
tensor(1257912.) 2188896.0
INFO - Validation [61][   40/   40]   Loss 0.294642   Top1 90.950000   Top5 99.690000   BatchTime 0.091214
INFO - ==> Top1: 90.950    Top5: 99.690    Loss: 0.295
INFO - ==> Sparsity : 0.575
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [61][Top1: 90.950   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  62
INFO - Training: 50000 samples (256 per mini-batch)
0.68739748
0.68740696
0.68742347
0.68744612
0.68747801
0.68752211
0.68754160
0.68754399
0.68755519
0.68758065
0.68760586
0.68765056
0.68770176
0.68776095
0.68782008
0.68789470
0.68794894
0.68799549
0.68804538
0.68810129
0.68811452
0.68813765
0.68817276
INFO - Training [62][   20/  196]   Loss 0.285834   Top1 90.566406   Top5 98.613281   BatchTime 0.454341   LR 0.000117
0.68819094
0.68822056
0.68826765
0.68829572
0.68830538
0.68829298
0.68829280
0.68832970
0.68835503
0.68838298
0.68836975
0.68838131
0.68837845
0.68835789
0.68834841
INFO - Training [62][   40/  196]   Loss 0.296421   Top1 90.097656   Top5 98.837891   BatchTime 0.420492   LR 0.000114
0.68837535
0.68838573
0.68836117
0.68831903
0.68827629
0.68824929
0.68823659
0.68823159
0.68823421
0.68823129
0.68819457
0.68816555
0.68809170
0.68805182
0.68801546
0.68800402
0.68802696
0.68804598
0.68806624
0.68810886
0.68817806
0.68820417
0.68821400
INFO - Training [62][   60/  196]   Loss 0.295352   Top1 90.110677   Top5 98.932292   BatchTime 0.400600   LR 0.000111
0.68820024
0.68817431
0.68814242
0.68811089
0.68810183
0.68805671
0.68800175
0.68799776
0.68795633
0.68791056
0.68789428
0.68786293
0.68782115
0.68782008
0.68778950
0.68774575
0.68770063
0.68763125
0.68756729
0.68754864
0.68757081
0.68760645
INFO - Training [62][   80/  196]   Loss 0.295104   Top1 90.244141   Top5 99.008789   BatchTime 0.389752   LR 0.000108
0.68755090
0.68751550
0.68744320
0.68740642
0.68739957
0.68737787
0.68733102
0.68732005
0.68733251
0.68733263
0.68734461
0.68736094
0.68743098
0.68749672
0.68761593
0.68775296
INFO - Training [62][  100/  196]   Loss 0.291087   Top1 90.394531   Top5 99.050781   BatchTime 0.384162   LR 0.000105
0.68786341
0.68794155
0.68800300
0.68805176
0.68806607
0.68808526
0.68809408
0.68807739
0.68807006
0.68805718
0.68803608
0.68806785
0.68808210
0.68811488
0.68811035
0.68812495
0.68814838
0.68819416
0.68823767
0.68825930
0.68828815
0.68832099
0.68836302
0.68842554
0.68849289
INFO - Training [62][  120/  196]   Loss 0.284770   Top1 90.673828   Top5 99.098307   BatchTime 0.377260   LR 0.000102
0.68854117
0.68855911
0.68855608
0.68853533
0.68852210
0.68856609
0.68858331
0.68859088
0.68856937
0.68858469
0.68858027
0.68861216
0.68861735
0.68861824
0.68862003
0.68865103
0.68865609
0.68868423
INFO - Training [62][  140/  196]   Loss 0.286078   Top1 90.602679   Top5 99.157366   BatchTime 0.368112   LR 0.000100
0.68869108
0.68871403
0.68871540
0.68873858
0.68875033
0.68878865
0.68882078
0.68883818
0.68883902
0.68882990
0.68882269
0.68881357
0.68882465
0.68885946
0.68887055
0.68888199
0.68890214
INFO - Training [62][  160/  196]   Loss 0.288053   Top1 90.498047   Top5 99.155273   BatchTime 0.365854   LR 0.000097
0.68892175
0.68893260
0.68890208
0.68887734
0.68887353
0.68886328
0.68884605
0.68884629
0.68883830
0.68886757
0.68887126
0.68889958
0.68892896
0.68895173
0.68894726
0.68898320
0.68902612
0.68906456
0.68910545
0.68913245
0.68916357
0.68919092
0.68920571
INFO - Training [62][  180/  196]   Loss 0.289134   Top1 90.431858   Top5 99.138455   BatchTime 0.364310   LR 0.000094
0.68921715
0.68921584
0.68919045
0.68914837
0.68913740
0.68910396
0.68909538
0.68906862
0.68905425
0.68903697
0.68904054
0.68903780
0.68901491
0.68898320
********************pre-trained*****************
INFO - ==> Top1: 90.442    Top5: 99.108    Loss: 0.288
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [62][   20/   40]   Loss 0.309510   Top1 90.546875   Top5 99.609375   BatchTime 0.125957
features.0.conv.0 tensor(0.4167)
features.0.conv.3 tensor(0.3516)
features.1.conv.0 tensor(0.0130)
features.1.conv.3 tensor(0.0822)
features.1.conv.6 tensor(0.0408)
features.2.conv.0 tensor(0.0367)
features.2.conv.3 tensor(0.0478)
features.2.conv.6 tensor(0.0758)
features.3.conv.0 tensor(0.0234)
features.3.conv.3 tensor(0.0417)
features.3.conv.6 tensor(0.0219)
features.4.conv.0 tensor(0.0366)
features.4.conv.3 tensor(0.0828)
features.4.conv.6 tensor(0.0968)
features.5.conv.0 tensor(0.0435)
features.5.conv.3 tensor(0.0660)
features.5.conv.6 tensor(0.1348)
features.6.conv.0 tensor(0.0304)
features.6.conv.3 tensor(0.0428)
features.6.conv.6 tensor(0.0468)
features.7.conv.0 tensor(0.0753)
features.7.conv.3 tensor(0.1241)
features.7.conv.6 tensor(0.2001)
features.8.conv.0 tensor(0.0894)
features.8.conv.3 tensor(0.1097)
features.8.conv.6 tensor(0.2633)
features.9.conv.0 tensor(0.0920)
features.9.conv.3 tensor(0.1432)
features.9.conv.6 tensor(0.3317)
features.10.conv.0 tensor(0.0376)
features.10.conv.3 tensor(0.0981)
features.10.conv.6 tensor(0.1299)
features.11.conv.0 tensor(0.5884)
features.11.conv.3 tensor(0.1505)
features.11.conv.6 tensor(0.6473)
features.12.conv.0 tensor(0.4716)
features.12.conv.3 tensor(0.1474)
features.12.conv.6 tensor(0.7449)
features.13.conv.0 tensor(0.1475)
features.13.conv.3 tensor(0.1244)
features.13.conv.6 tensor(0.4287)
features.14.conv.0 tensor(0.9067)
features.14.conv.3 tensor(0.0701)
features.14.conv.6 tensor(0.9878)
features.15.conv.0 tensor(0.9542)
features.15.conv.3 tensor(0.0579)
features.15.conv.6 tensor(0.9769)
features.16.conv.0 tensor(0.3146)
features.16.conv.3 tensor(0.1155)
features.16.conv.6 tensor(0.4897)
conv.0 tensor(0.5807)
tensor(1249166.) 2188896.0
INFO - Validation [62][   40/   40]   Loss 0.293375   Top1 90.790000   Top5 99.760000   BatchTime 0.089457
INFO - ==> Top1: 90.790    Top5: 99.760    Loss: 0.293
INFO - ==> Sparsity : 0.571
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [61][Top1: 90.950   Top5: 99.690]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  63
INFO - Training: 50000 samples (256 per mini-batch)
0.68895406
0.68891132
0.68886894
0.68881440
0.68877524
0.68871754
0.68865949
0.68862474
0.68861109
0.68859625
0.68860614
0.68862420
0.68862408
0.68862045
0.68861580
0.68864667
0.68866289
0.68870097
0.68873543
INFO - Training [63][   20/  196]   Loss 0.321829   Top1 88.945312   Top5 98.476562   BatchTime 0.461113   LR 0.000090
0.68878514
0.68882674
0.68884873
0.68886656
0.68885422
0.68884575
0.68883282
0.68883026
0.68879002
0.68873578
0.68867499
0.68862110
0.68857563
0.68855178
0.68854064
0.68853623
0.68848765
0.68841809
0.68833673
0.68831390
0.68825185
INFO - Training [63][   40/  196]   Loss 0.316896   Top1 89.062500   Top5 98.740234   BatchTime 0.426428   LR 0.000087
0.68822515
0.68825281
0.68823105
0.68821460
0.68819231
0.68820119
0.68819714
0.68816614
0.68809354
0.68804336
0.68803126
0.68801785
0.68799806
0.68798482
0.68796778
0.68791825
0.68787867
0.68780977
0.68777376
0.68769133
0.68759060
0.68749952
INFO - Training [63][   60/  196]   Loss 0.316437   Top1 89.205729   Top5 98.789062   BatchTime 0.403541   LR 0.000085
0.68745190
0.68738490
0.68730849
0.68725544
0.68720472
0.68714309
0.68710083
0.68703508
0.68700236
0.68698668
0.68697357
0.68695545
0.68695378
0.68695951
0.68695420
0.68696034
0.68697381
0.68702370
0.68708074
0.68712944
0.68719888
0.68725711
INFO - Training [63][   80/  196]   Loss 0.313652   Top1 89.375000   Top5 98.901367   BatchTime 0.395744   LR 0.000082
0.68727773
0.68732399
0.68738061
0.68743426
0.68746948
0.68746746
0.68749261
0.68747860
0.68742406
0.68741035
0.68736750
0.68733239
0.68728691
0.68724507
0.68723416
0.68722016
0.68719012
INFO - Training [63][  100/  196]   Loss 0.306584   Top1 89.679688   Top5 98.957031   BatchTime 0.387177   LR 0.000080
0.68717152
0.68714780
0.68714041
0.68713146
0.68713570
0.68713021
0.68712896
0.68714017
0.68713838
0.68713695
0.68715292
0.68715066
0.68717766
0.68720871
0.68721968
0.68721223
0.68717813
0.68716443
0.68718445
INFO - Training [63][  120/  196]   Loss 0.299959   Top1 89.918620   Top5 99.049479   BatchTime 0.373492   LR 0.000077
0.68722391
0.68725395
0.68729264
0.68730992
0.68731439
0.68735057
0.68741888
0.68744034
0.68745011
0.68746465
0.68749154
0.68749058
0.68749195
0.68749839
0.68750447
0.68752313
0.68751854
0.68752527
0.68750304
0.68748385
INFO - Training [63][  140/  196]   Loss 0.297102   Top1 90.033482   Top5 99.101562   BatchTime 0.365103   LR 0.000075
0.68743312
0.68741679
0.68741447
0.68742329
0.68742102
0.68743938
0.68744117
0.68743962
0.68739563
0.68734968
0.68733561
0.68729919
0.68727833
0.68728566
0.68729848
0.68727547
0.68725991
0.68724531
0.68723178
0.68721968
0.68716937
INFO - Training [63][  160/  196]   Loss 0.298241   Top1 89.992676   Top5 99.106445   BatchTime 0.365436   LR 0.000072
0.68713146
0.68707222
0.68702406
0.68701029
0.68700880
0.68700731
0.68700886
0.68699372
0.68701333
0.68702775
0.68703282
0.68702179
0.68700755
0.68702340
0.68703526
0.68703276
0.68703896
0.68705356
0.68705237
0.68703502
0.68702614
0.68702573
INFO - Training [63][  180/  196]   Loss 0.299625   Top1 89.865451   Top5 99.079861   BatchTime 0.365932   LR 0.000070
0.68701398
0.68700725
0.68700975
0.68700564
0.68699062
0.68695188
0.68692523
0.68689626
0.68687475
0.68687671
0.68688047
0.68689114
0.68689686
********************pre-trained*****************
INFO - ==> Top1: 89.908    Top5: 99.080    Loss: 0.299
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [63][   20/   40]   Loss 0.294874   Top1 90.996094   Top5 99.687500   BatchTime 0.131402
INFO - Validation [63][   40/   40]   Loss 0.284052   Top1 91.040000   Top5 99.790000   BatchTime 0.092408
features.0.conv.0 tensor(0.4062)
features.0.conv.3 tensor(0.3457)
features.1.conv.0 tensor(0.0137)
features.1.conv.3 tensor(0.0822)
features.1.conv.6 tensor(0.0425)
features.2.conv.0 tensor(0.0362)
features.2.conv.3 tensor(0.0486)
features.2.conv.6 tensor(0.0758)
features.3.conv.0 tensor(0.0231)
features.3.conv.3 tensor(0.0394)
features.3.conv.6 tensor(0.0202)
features.4.conv.0 tensor(0.0374)
features.4.conv.3 tensor(0.0833)
features.4.conv.6 tensor(0.0921)
features.5.conv.0 tensor(0.0459)
features.5.conv.3 tensor(0.0654)
features.5.conv.6 tensor(0.1287)
features.6.conv.0 tensor(0.0295)
features.6.conv.3 tensor(0.0446)
features.6.conv.6 tensor(0.0469)
features.7.conv.0 tensor(0.0762)
features.7.conv.3 tensor(0.1236)
features.7.conv.6 tensor(0.2075)
features.8.conv.0 tensor(0.0901)
features.8.conv.3 tensor(0.1102)
features.8.conv.6 tensor(0.2675)
features.9.conv.0 tensor(0.0949)
features.9.conv.3 tensor(0.1432)
features.9.conv.6 tensor(0.3323)
features.10.conv.0 tensor(0.0363)
features.10.conv.3 tensor(0.0972)
features.10.conv.6 tensor(0.1340)
features.11.conv.0 tensor(0.5861)
features.11.conv.3 tensor(0.1512)
features.11.conv.6 tensor(0.6542)
features.12.conv.0 tensor(0.4681)
features.12.conv.3 tensor(0.1462)
features.12.conv.6 tensor(0.7444)
features.13.conv.0 tensor(0.1517)
features.13.conv.3 tensor(0.1267)
features.13.conv.6 tensor(0.4482)
features.14.conv.0 tensor(0.9067)
features.14.conv.3 tensor(0.0703)
features.14.conv.6 tensor(0.9877)
features.15.conv.0 tensor(0.9546)
features.15.conv.3 tensor(0.0582)
features.15.conv.6 tensor(0.9760)
features.16.conv.0 tensor(0.3309)
features.16.conv.3 tensor(0.1156)
features.16.conv.6 tensor(0.5164)
conv.0 tensor(0.5801)
tensor(1262083.) 2188896.0
INFO - ==> Top1: 91.040    Top5: 99.790    Loss: 0.284
INFO - ==> Sparsity : 0.577
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [63][Top1: 91.040   Top5: 99.790]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  64
INFO - Training: 50000 samples (256 per mini-batch)
0.68691641
0.68695056
0.68697292
0.68696314
0.68695003
0.68697381
0.68699014
0.68701208
0.68699378
0.68696398
0.68695617
0.68693340
0.68690121
0.68687183
0.68686414
0.68682164
0.68682218
0.68683308
0.68682957
0.68685871
INFO - Training [64][   20/  196]   Loss 0.305485   Top1 89.062500   Top5 98.652344   BatchTime 0.454828   LR 0.000066
0.68685585
0.68684715
0.68684143
0.68683457
0.68686247
0.68688035
0.68687820
0.68687582
0.68688852
0.68689424
0.68691474
0.68692917
0.68693811
0.68692791
0.68691117
0.68691200
0.68691760
0.68693036
0.68693179
0.68693590
0.68694800
INFO - Training [64][   40/  196]   Loss 0.307806   Top1 89.257812   Top5 98.818359   BatchTime 0.417260   LR 0.000064
0.68694931
0.68694979
0.68693507
0.68690133
0.68688482
0.68686748
0.68684816
0.68680656
0.68679625
0.68679196
0.68680149
0.68680215
0.68680531
0.68679672
0.68676341
0.68673724
0.68670470
0.68669844
0.68670213
0.68670899
0.68673527
0.68673754
INFO - Training [64][   60/  196]   Loss 0.305065   Top1 89.609375   Top5 98.834635   BatchTime 0.396988   LR 0.000062
0.68672746
0.68673092
0.68670642
0.68674618
0.68675834
0.68680459
0.68681848
0.68682557
0.68682349
0.68680650
0.68681079
0.68678498
0.68675214
0.68674105
0.68673289
0.68672985
0.68672693
0.68671262
INFO - Training [64][   80/  196]   Loss 0.300882   Top1 89.799805   Top5 98.969727   BatchTime 0.384789   LR 0.000059
0.68670213
0.68670499
0.68670171
0.68670666
0.68669075
0.68668824
0.68669623
0.68668461
0.68667251
0.68667477
0.68667084
0.68664181
0.68663895
0.68661511
0.68660021
0.68659729
0.68656057
0.68655986
INFO - Training [64][  100/  196]   Loss 0.295931   Top1 90.031250   Top5 98.988281   BatchTime 0.373629   LR 0.000057
0.68651456
0.68646073
0.68639237
0.68632454
0.68627405
0.68622845
0.68620604
0.68617439
0.68615454
0.68614352
0.68610960
0.68611234
0.68610066
0.68608260
0.68605632
0.68603736
0.68601620
0.68599486
0.68596649
0.68595845
0.68594337
0.68591917
0.68585902
0.68580180
INFO - Training [64][  120/  196]   Loss 0.292597   Top1 90.185547   Top5 99.059245   BatchTime 0.367299   LR 0.000055
0.68575341
0.68571180
0.68565142
0.68558002
0.68549967
0.68545276
0.68537605
0.68525660
0.68515581
0.68506634
0.68498939
0.68495327
0.68493772
0.68491632
0.68491161
0.68488830
INFO - Training [64][  140/  196]   Loss 0.291510   Top1 90.298549   Top5 99.109933   BatchTime 0.366164   LR 0.000053
0.68489814
0.68487942
0.68486160
0.68483281
0.68478042
0.68476439
0.68474644
0.68473369
0.68478477
0.68476158
0.68474811
0.68476444
0.68486196
0.68488508
0.68489933
0.68490380
0.68494111
0.68496650
0.68500465
0.68502283
0.68498075
0.68491644
INFO - Training [64][  160/  196]   Loss 0.294013   Top1 90.273438   Top5 99.108887   BatchTime 0.365459   LR 0.000051
0.68483037
0.68477947
0.68472350
0.68467140
0.68466491
0.68462247
0.68459451
0.68458545
0.68456125
0.68453062
0.68453103
0.68454164
0.68452489
0.68452352
0.68452209
0.68450516
0.68449950
0.68450683
0.68453127
0.68459088
0.68464088
0.68469441
0.68474472
INFO - Training [64][  180/  196]   Loss 0.294089   Top1 90.264757   Top5 99.088542   BatchTime 0.365737   LR 0.000049
0.68474841
0.68471104
0.68470651
0.68466514
0.68463516
0.68461281
0.68459713
0.68455082
0.68454438
0.68454373
0.68456209
INFO - ==> Top1: 90.296    Top5: 99.068    Loss: 0.293
0.68459159
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [64][   20/   40]   Loss 0.340049   Top1 89.453125   Top5 99.589844   BatchTime 0.125973
INFO - Validation [64][   40/   40]   Loss 0.327733   Top1 89.820000   Top5 99.710000   BatchTime 0.089929
INFO - ==> Top1: 89.820    Top5: 99.710    Loss: 0.328
INFO - ==> Sparsity : 0.586
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [63][Top1: 91.040   Top5: 99.790]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  65
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4132)
features.0.conv.3 tensor(0.3418)
features.1.conv.0 tensor(0.0104)
features.1.conv.3 tensor(0.0856)
features.1.conv.6 tensor(0.0421)
features.2.conv.0 tensor(0.0356)
features.2.conv.3 tensor(0.0509)
features.2.conv.6 tensor(0.0767)
features.3.conv.0 tensor(0.0214)
features.3.conv.3 tensor(0.0417)
features.3.conv.6 tensor(0.0206)
features.4.conv.0 tensor(0.0386)
features.4.conv.3 tensor(0.0828)
features.4.conv.6 tensor(0.0947)
features.5.conv.0 tensor(0.0461)
features.5.conv.3 tensor(0.0642)
features.5.conv.6 tensor(0.1302)
features.6.conv.0 tensor(0.0317)
features.6.conv.3 tensor(0.0428)
features.6.conv.6 tensor(0.0471)
features.7.conv.0 tensor(0.0768)
features.7.conv.3 tensor(0.1230)
features.7.conv.6 tensor(0.2109)
features.8.conv.0 tensor(0.0925)
features.8.conv.3 tensor(0.1102)
features.8.conv.6 tensor(0.2658)
features.9.conv.0 tensor(0.0977)
features.9.conv.3 tensor(0.1427)
features.9.conv.6 tensor(0.3290)
features.10.conv.0 tensor(0.0369)
features.10.conv.3 tensor(0.0987)
features.10.conv.6 tensor(0.1360)
features.11.conv.0 tensor(0.5903)
features.11.conv.3 tensor(0.1501)
features.11.conv.6 tensor(0.6497)
features.12.conv.0 tensor(0.4659)
features.12.conv.3 tensor(0.1464)
features.12.conv.6 tensor(0.7435)
features.13.conv.0 tensor(0.1516)
features.13.conv.3 tensor(0.1258)
features.13.conv.6 tensor(0.4569)
features.14.conv.0 tensor(0.9068)
features.14.conv.3 tensor(0.0700)
features.14.conv.6 tensor(0.9879)
features.15.conv.0 tensor(0.9551)
features.15.conv.3 tensor(0.0588)
features.15.conv.6 tensor(0.9766)
features.16.conv.0 tensor(0.3403)
features.16.conv.3 tensor(0.1159)
features.16.conv.6 tensor(0.5732)
conv.0 tensor(0.5843)
tensor(1283741.) 2188896.0
0.68465972
0.68473333
0.68477523
0.68479931
0.68479306
0.68479890
0.68478286
0.68475533
0.68470818
0.68472165
0.68470097
0.68467867
0.68468612
0.68467879
0.68467522
0.68468934
0.68469322
0.68466830
0.68467444
0.68464726
0.68463671
0.68461215
INFO - Training [65][   20/  196]   Loss 0.317738   Top1 89.257812   Top5 98.613281   BatchTime 0.436780   LR 0.000046
0.68460417
0.68461329
0.68459505
0.68457913
0.68454951
0.68450230
0.68444431
0.68440837
0.68438339
0.68434012
0.68428969
0.68426222
0.68422776
0.68419087
0.68418032
0.68414652
0.68412727
0.68406641
0.68406242
0.68407565
0.68409592
INFO - Training [65][   40/  196]   Loss 0.312731   Top1 89.326172   Top5 98.720703   BatchTime 0.415281   LR 0.000044
0.68406880
0.68404925
0.68405217
0.68406004
0.68409091
0.68412435
0.68412876
0.68415439
0.68419504
0.68418401
0.68419296
0.68420941
0.68425727
0.68429911
0.68434602
0.68435967
0.68435377
INFO - Training [65][   60/  196]   Loss 0.312275   Top1 89.283854   Top5 98.834635   BatchTime 0.396257   LR 0.000042
0.68439054
0.68440855
0.68439251
0.68437582
0.68438858
0.68440276
0.68441164
0.68443543
0.68439859
0.68437284
0.68436027
0.68434745
0.68433076
0.68432146
0.68428391
0.68424034
0.68418801
0.68412167
0.68405533
0.68396252
0.68387437
INFO - Training [65][   80/  196]   Loss 0.304291   Top1 89.667969   Top5 99.057617   BatchTime 0.391313   LR 0.000040
0.68381542
0.68377048
0.68371612
0.68367296
0.68364251
0.68367821
0.68368757
0.68367082
0.68367654
0.68365401
0.68366057
0.68366235
0.68368614
0.68370825
0.68370968
0.68369812
0.68369722
0.68368876
INFO - Training [65][  100/  196]   Loss 0.295080   Top1 90.007812   Top5 99.113281   BatchTime 0.380343   LR 0.000039
0.68368238
0.68366140
0.68363816
0.68363297
0.68363726
0.68363976
0.68364561
0.68364483
0.68363291
0.68360227
0.68359923
0.68359679
0.68357950
0.68355733
0.68352634
0.68349129
0.68345928
0.68341851
0.68339276
0.68338412
0.68336624
INFO - Training [65][  120/  196]   Loss 0.289507   Top1 90.266927   Top5 99.169922   BatchTime 0.379841   LR 0.000037
0.68334466
0.68329585
0.68325990
0.68322784
0.68318516
0.68315607
0.68312621
0.68310308
0.68305665
0.68301243
0.68300593
0.68302208
0.68305409
0.68305081
0.68306488
0.68308437
0.68312591
0.68314826
0.68317348
0.68321651
0.68328404
0.68333334
0.68336582
INFO - Training [65][  140/  196]   Loss 0.289075   Top1 90.304129   Top5 99.207589   BatchTime 0.377226   LR 0.000035
0.68340659
0.68343371
0.68344063
0.68345660
0.68347168
0.68348795
0.68352741
0.68354923
0.68357211
0.68356830
0.68356627
0.68356419
0.68356001
0.68356693
0.68354565
0.68355340
0.68356913
INFO - Training [65][  160/  196]   Loss 0.289418   Top1 90.273438   Top5 99.184570   BatchTime 0.373800   LR 0.000033
0.68355155
0.68352234
0.68349725
0.68348712
0.68345928
0.68344456
0.68342245
0.68340564
0.68337363
0.68335128
0.68331826
0.68329823
0.68328041
0.68327361
0.68323511
0.68321651
0.68319285
0.68317741
0.68313658
0.68311840
0.68308902
INFO - Training [65][  180/  196]   Loss 0.288354   Top1 90.308160   Top5 99.127604   BatchTime 0.374618   LR 0.000032
0.68303055
0.68301487
0.68297583
0.68293923
0.68293566
0.68292481
0.68289429
0.68288225
0.68288386
0.68285793
0.68282235
0.68277842
0.68277335
0.68275648
0.68274701
********************pre-trained*****************
INFO - ==> Top1: 90.316    Top5: 99.128    Loss: 0.287
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [65][   20/   40]   Loss 0.340163   Top1 89.667969   Top5 99.667969   BatchTime 0.124811
features.0.conv.0 tensor(0.4097)
features.0.conv.3 tensor(0.3398)
features.1.conv.0 tensor(0.0098)
features.1.conv.3 tensor(0.0845)
features.1.conv.6 tensor(0.0421)
features.2.conv.0 tensor(0.0353)
features.2.conv.3 tensor(0.0525)
features.2.conv.6 tensor(0.0761)
features.3.conv.0 tensor(0.0223)
features.3.conv.3 tensor(0.0409)
features.3.conv.6 tensor(0.0204)
features.4.conv.0 tensor(0.0391)
features.4.conv.3 tensor(0.0828)
features.4.conv.6 tensor(0.0959)
features.5.conv.0 tensor(0.0465)
features.5.conv.3 tensor(0.0648)
features.5.conv.6 tensor(0.1271)
features.6.conv.0 tensor(0.0321)
features.6.conv.3 tensor(0.0422)
features.6.conv.6 tensor(0.0476)
features.7.conv.0 tensor(0.0766)
features.7.conv.3 tensor(0.1230)
features.7.conv.6 tensor(0.2115)
features.8.conv.0 tensor(0.0922)
features.8.conv.3 tensor(0.1097)
features.8.conv.6 tensor(0.2657)
features.9.conv.0 tensor(0.0993)
features.9.conv.3 tensor(0.1432)
features.9.conv.6 tensor(0.3286)
features.10.conv.0 tensor(0.0363)
features.10.conv.3 tensor(0.0984)
features.10.conv.6 tensor(0.1368)
features.11.conv.0 tensor(0.5938)
features.11.conv.3 tensor(0.1495)
features.11.conv.6 tensor(0.6481)
features.12.conv.0 tensor(0.4786)
features.12.conv.3 tensor(0.1472)
features.12.conv.6 tensor(0.7442)
features.13.conv.0 tensor(0.1534)
features.13.conv.3 tensor(0.1252)
features.13.conv.6 tensor(0.4417)
features.14.conv.0 tensor(0.9070)
features.14.conv.3 tensor(0.0698)
features.14.conv.6 tensor(0.9878)
features.15.conv.0 tensor(0.9556)
features.15.conv.3 tensor(0.0584)
features.15.conv.6 tensor(0.9769)
features.16.conv.0 tensor(0.3670)
features.16.conv.3 tensor(0.1159)
features.16.conv.6 tensor(0.6028)
conv.0 tensor(0.5847)
tensor(1296801.) 2188896.0
INFO - Validation [65][   40/   40]   Loss 0.328158   Top1 89.930000   Top5 99.720000   BatchTime 0.089561
INFO - ==> Top1: 89.930    Top5: 99.720    Loss: 0.328
INFO - ==> Sparsity : 0.592
INFO - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [63][Top1: 91.040   Top5: 99.790]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  66
INFO - Training: 50000 samples (256 per mini-batch)
0.68268305
0.68265992
0.68263662
0.68260485
0.68257976
0.68260068
0.68259144
0.68258184
0.68257129
0.68258530
0.68259513
0.68260533
0.68260562
0.68263888
0.68264145
0.68264329
0.68264675
0.68264049
0.68261141
0.68259746
0.68260092
0.68261904
INFO - Training [66][   20/  196]   Loss 0.306862   Top1 89.687500   Top5 98.769531   BatchTime 0.483019   LR 0.000029
0.68265802
0.68265682
0.68267745
0.68267608
0.68267906
0.68266046
0.68264723
0.68263090
0.68260568
0.68258727
0.68255371
0.68252462
0.68247539
0.68244129
0.68240523
0.68239021
0.68234551
0.68234015
0.68233353
0.68234527
0.68234491
INFO - Training [66][   40/  196]   Loss 0.305251   Top1 89.804688   Top5 98.896484   BatchTime 0.436765   LR 0.000028
0.68234646
0.68235028
0.68233997
0.68230528
0.68228239
0.68228817
0.68228292
0.68228495
0.68227082
0.68223697
0.68220758
0.68218780
0.68217140
0.68216515
0.68214732
0.68214774
INFO - Training [66][   60/  196]   Loss 0.307611   Top1 89.713542   Top5 98.938802   BatchTime 0.413202   LR 0.000026
0.68213069
0.68212461
0.68213075
0.68213630
0.68213236
0.68212265
0.68208778
0.68208462
0.68206847
0.68204081
0.68200952
0.68199259
0.68196732
0.68195206
0.68193626
0.68191326
0.68185979
0.68180609
0.68177807
0.68172848
INFO - Training [66][   80/  196]   Loss 0.304260   Top1 89.799805   Top5 99.028320   BatchTime 0.386570   LR 0.000025
0.68167394
0.68162471
0.68159634
0.68157792
0.68153775
0.68151706
0.68146908
0.68142784
0.68140048
0.68138063
0.68133467
0.68127477
0.68123347
0.68120193
0.68118232
0.68120486
0.68121713
0.68121082
0.68121719
0.68123883
0.68124819
0.68126100
0.68127114
INFO - Training [66][  100/  196]   Loss 0.293660   Top1 90.183594   Top5 99.093750   BatchTime 0.378412   LR 0.000023
0.68127823
0.68126255
0.68125564
0.68125290
0.68124115
0.68123639
0.68123209
0.68124944
0.68125957
0.68128550
0.68131757
0.68135023
0.68138182
0.68141818
0.68144518
0.68145919
0.68146056
INFO - Training [66][  120/  196]   Loss 0.289604   Top1 90.445964   Top5 99.127604   BatchTime 0.374252   LR 0.000022
0.68148434
0.68148106
0.68149209
0.68151999
0.68153721
0.68157053
0.68159330
0.68158531
0.68159348
0.68160754
0.68161583
0.68163288
0.68165952
0.68170112
0.68171364
0.68173653
0.68176067
0.68180996
0.68182766
0.68185526
0.68186164
0.68186814
INFO - Training [66][  140/  196]   Loss 0.288947   Top1 90.407366   Top5 99.157366   BatchTime 0.371086   LR 0.000021
0.68187118
0.68189144
0.68190068
0.68192148
0.68193394
0.68192875
0.68193853
0.68194062
0.68195015
0.68198287
0.68201840
0.68203235
0.68203956
0.68204141
0.68205410
0.68207777
0.68210065
0.68210369
0.68211544
0.68212289
0.68211043
0.68211061
0.68209940
INFO - Training [66][  160/  196]   Loss 0.290611   Top1 90.356445   Top5 99.140625   BatchTime 0.369560   LR 0.000019
0.68210006
0.68209130
0.68211502
0.68212736
0.68212944
0.68214047
0.68214941
0.68216759
0.68218917
0.68219095
0.68222415
0.68225271
0.68225646
0.68226320
0.68222737
0.68221909
INFO - Training [66][  180/  196]   Loss 0.289284   Top1 90.401476   Top5 99.136285   BatchTime 0.368928   LR 0.000018
0.68220466
0.68219298
0.68217903
0.68218559
0.68218142
0.68220556
0.68222064
0.68222964
0.68224955
0.68225461
0.68225861
0.68225020
0.68224943
0.68225247
0.68224281
0.68222618
INFO - ==> Top1: 90.450    Top5: 99.128    Loss: 0.287
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4097)
features.0.conv.3 tensor(0.3418)
features.1.conv.0 tensor(0.0104)
features.1.conv.3 tensor(0.0845)
features.1.conv.6 tensor(0.0425)
features.2.conv.0 tensor(0.0356)
features.2.conv.3 tensor(0.0509)
features.2.conv.6 tensor(0.0764)
features.3.conv.0 tensor(0.0220)
features.3.conv.3 tensor(0.0409)
features.3.conv.6 tensor(0.0206)
features.4.conv.0 tensor(0.0386)
features.4.conv.3 tensor(0.0828)
features.4.conv.6 tensor(0.0951)
features.5.conv.0 tensor(0.0465)
features.5.conv.3 tensor(0.0654)
features.5.conv.6 tensor(0.1268)
features.6.conv.0 tensor(0.0322)
features.6.conv.3 tensor(0.0422)
features.6.conv.6 tensor(0.0476)
features.7.conv.0 tensor(0.0779)
features.7.conv.3 tensor(0.1221)
features.7.conv.6 tensor(0.2078)
features.8.conv.0 tensor(0.0929)
features.8.conv.3 tensor(0.1117)
features.8.conv.6 tensor(0.2675)
features.9.conv.0 tensor(0.0993)
features.9.conv.3 tensor(0.1441)
features.9.conv.6 tensor(0.3310)
features.10.conv.0 tensor(0.0365)
features.10.conv.3 tensor(0.0987)
features.10.conv.6 tensor(0.1345)
features.11.conv.0 tensor(0.5943)
features.11.conv.3 tensor(0.1495)
features.11.conv.6 tensor(0.6469)
features.12.conv.0 tensor(0.4828)
features.12.conv.3 tensor(0.1476)
features.12.conv.6 tensor(0.7446)
features.13.conv.0 tensor(0.1545)
features.13.conv.3 tensor(0.1246)
features.13.conv.6 tensor(0.4403)
features.14.conv.0 tensor(0.9070)
features.14.conv.3 tensor(0.0700)
features.14.conv.6 tensor(0.9880)
features.15.conv.0 tensor(0.9558)
features.15.conv.3 tensor(0.0586)
features.15.conv.6 tensor(0.9775)
features.16.conv.0 tensor(0.3690)
features.16.conv.3 tensor(0.1163)
features.16.conv.6 tensor(0.6100)
conv.0 tensor(0.5850)
tensor(1299743.) 2188896.0
INFO - Validation [66][   20/   40]   Loss 0.299063   Top1 91.015625   Top5 99.589844   BatchTime 0.122797
INFO - Validation [66][   40/   40]   Loss 0.281293   Top1 91.240000   Top5 99.730000   BatchTime 0.086891
INFO - ==> Top1: 91.240    Top5: 99.730    Loss: 0.281
INFO - ==> Sparsity : 0.594
INFO - Scoreboard best 1 ==> Epoch [66][Top1: 91.240   Top5: 99.730]
INFO - Scoreboard best 2 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Scoreboard best 3 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  67
INFO - Training: 50000 samples (256 per mini-batch)
0.68221968
0.68220395
0.68219340
0.68218088
0.68216014
0.68214023
0.68212450
0.68212771
0.68213594
0.68211240
0.68210083
0.68208992
0.68206519
0.68207455
0.68209147
0.68210578
0.68210053
0.68210089
0.68208736
0.68206853
0.68204612
INFO - Training [67][   20/  196]   Loss 0.302820   Top1 90.097656   Top5 98.554688   BatchTime 0.479701   LR 0.000016
0.68203229
0.68201625
0.68201834
0.68200368
0.68196630
0.68192381
0.68190497
0.68190950
0.68190724
0.68189156
0.68188202
0.68188488
0.68189502
0.68189228
0.68188214
0.68187582
0.68191051
0.68193215
0.68196368
INFO - Training [67][   40/  196]   Loss 0.301325   Top1 89.882812   Top5 98.828125   BatchTime 0.393826   LR 0.000015
0.68197948
0.68198562
0.68200165
0.68199921
0.68201613
0.68200928
0.68202949
0.68203735
0.68204433
0.68204927
0.68206275
0.68205816
0.68205446
0.68205804
0.68204296
0.68201494
0.68200547
0.68197900
0.68197203
0.68198192
INFO - Training [67][   60/  196]   Loss 0.303058   Top1 90.091146   Top5 98.873698   BatchTime 0.364309   LR 0.000014
0.68197048
0.68195325
0.68193978
0.68194747
0.68195534
0.68193752
0.68191606
0.68193370
0.68193501
0.68194211
0.68195277
0.68195689
0.68197018
0.68197030
0.68197685
0.68197924
0.68198407
0.68197739
0.68198037
INFO - Training [67][   80/  196]   Loss 0.301003   Top1 90.136719   Top5 98.974609   BatchTime 0.375673   LR 0.000013
0.68196303
0.68197519
0.68197155
0.68196231
0.68197393
0.68197042
0.68197012
0.68195164
0.68193275
0.68193811
0.68194848
0.68194765
0.68193895
0.68192822
0.68193012
0.68192506
0.68190557
0.68189114
0.68187797
0.68186742
0.68186891
INFO - Training [67][  100/  196]   Loss 0.295092   Top1 90.265625   Top5 99.023438   BatchTime 0.378774   LR 0.000012
0.68186444
0.68186134
0.68186033
0.68187660
0.68188477
0.68186593
0.68185902
0.68185860
0.68183351
0.68181068
0.68180519
0.68179542
0.68180394
0.68178904
0.68179017
0.68179196
0.68178171
0.68176472
0.68174565
0.68173599
0.68172246
0.68171513
0.68169457
INFO - Training [67][  120/  196]   Loss 0.289432   Top1 90.455729   Top5 99.069010   BatchTime 0.374833   LR 0.000011
0.68166786
0.68166757
0.68166631
0.68166745
0.68164408
0.68163490
0.68161350
0.68160015
0.68157434
0.68155748
0.68155527
0.68152642
0.68152344
0.68151706
0.68150491
0.68149716
INFO - Training [67][  140/  196]   Loss 0.285541   Top1 90.546875   Top5 99.157366   BatchTime 0.373913   LR 0.000010
0.68150276
0.68150085
0.68149942
0.68148166
0.68149388
0.68151218
0.68151331
0.68150687
0.68151516
0.68152463
0.68152928
0.68154353
0.68155646
0.68156809
0.68156815
0.68159610
0.68160504
0.68159497
0.68159550
0.68160468
0.68160594
0.68160242
INFO - Training [67][  160/  196]   Loss 0.287375   Top1 90.419922   Top5 99.150391   BatchTime 0.372258   LR 0.000009
0.68160462
0.68157786
0.68158454
0.68157160
0.68156344
0.68155009
0.68155128
0.68154043
0.68154204
0.68153507
0.68152237
0.68153208
0.68153363
0.68151730
0.68150389
0.68150955
0.68150496
0.68150765
INFO - Training [67][  180/  196]   Loss 0.288552   Top1 90.336372   Top5 99.118924   BatchTime 0.368687   LR 0.000008
0.68150097
0.68148780
0.68148285
0.68148726
0.68148297
0.68149996
0.68150324
0.68150795
0.68150812
0.68150133
0.68151432
0.68152547
0.68151015
0.68151337
0.68150824
0.68149340
0.68150383
INFO - ==> Top1: 90.318    Top5: 99.102    Loss: 0.289
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [67][   20/   40]   Loss 0.306936   Top1 91.054688   Top5 99.648438   BatchTime 0.198593
features.0.conv.0 tensor(0.4097)
features.0.conv.3 tensor(0.3398)
features.1.conv.0 tensor(0.0104)
features.1.conv.3 tensor(0.0833)
features.1.conv.6 tensor(0.0434)
features.2.conv.0 tensor(0.0353)
features.2.conv.3 tensor(0.0502)
features.2.conv.6 tensor(0.0764)
features.3.conv.0 tensor(0.0226)
features.3.conv.3 tensor(0.0417)
features.3.conv.6 tensor(0.0202)
features.4.conv.0 tensor(0.0396)
features.4.conv.3 tensor(0.0804)
features.4.conv.6 tensor(0.0967)
features.5.conv.0 tensor(0.0457)
features.5.conv.3 tensor(0.0642)
features.5.conv.6 tensor(0.1276)
features.6.conv.0 tensor(0.0316)
features.6.conv.3 tensor(0.0417)
features.6.conv.6 tensor(0.0476)
features.7.conv.0 tensor(0.0773)
features.7.conv.3 tensor(0.1227)
features.7.conv.6 tensor(0.2087)
features.8.conv.0 tensor(0.0928)
features.8.conv.3 tensor(0.1114)
features.8.conv.6 tensor(0.2671)
features.9.conv.0 tensor(0.0997)
features.9.conv.3 tensor(0.1444)
features.9.conv.6 tensor(0.3322)
features.10.conv.0 tensor(0.0365)
features.10.conv.3 tensor(0.0978)
features.10.conv.6 tensor(0.1335)
features.11.conv.0 tensor(0.5958)
features.11.conv.3 tensor(0.1512)
features.11.conv.6 tensor(0.6463)
features.12.conv.0 tensor(0.4842)
features.12.conv.3 tensor(0.1462)
features.12.conv.6 tensor(0.7454)
features.13.conv.0 tensor(0.1554)
features.13.conv.3 tensor(0.1256)
features.13.conv.6 tensor(0.4404)
features.14.conv.0 tensor(0.9071)
features.14.conv.3 tensor(0.0696)
features.14.conv.6 tensor(0.9879)
features.15.conv.0 tensor(0.9559)
features.15.conv.3 tensor(0.0586)
features.15.conv.6 tensor(0.9774)
features.16.conv.0 tensor(0.3749)
features.16.conv.3 tensor(0.1160)
features.16.conv.6 tensor(0.6172)
conv.0 tensor(0.5871)
tensor(1303964.) 2188896.0
INFO - Validation [67][   40/   40]   Loss 0.287882   Top1 91.330000   Top5 99.750000   BatchTime 0.132311
INFO - ==> Top1: 91.330    Top5: 99.750    Loss: 0.288
INFO - ==> Sparsity : 0.596
INFO - Scoreboard best 1 ==> Epoch [67][Top1: 91.330   Top5: 99.750]
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 91.240   Top5: 99.730]
INFO - Scoreboard best 3 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch  68
INFO - Training: 50000 samples (256 per mini-batch)
0.68150938
0.68149561
0.68148577
0.68148524
0.68147421
0.68146771
0.68147457
0.68146861
0.68146390
0.68146783
0.68146604
0.68147963
0.68147701
0.68147320
0.68147200
0.68147683
0.68148720
0.68147558
0.68147099
0.68147534
INFO - Training [68][   20/  196]   Loss 0.305331   Top1 90.078125   Top5 98.613281   BatchTime 0.401429   LR 0.000007
0.68148476
0.68149990
0.68149376
0.68150765
0.68152034
0.68151462
0.68152285
0.68151587
0.68149942
0.68150908
0.68151635
0.68151349
0.68151742
0.68150204
0.68150288
0.68149185
0.68147939
0.68147880
0.68148029
0.68147433
0.68145090
0.68145573
INFO - Training [68][   40/  196]   Loss 0.310695   Top1 89.726562   Top5 98.789062   BatchTime 0.384081   LR 0.000006
0.68143338
0.68143833
0.68142241
0.68142819
0.68143594
0.68143308
0.68143094
0.68143898
0.68143159
0.68142962
0.68140566
0.68140906
0.68140566
0.68139690
0.68140459
0.68139762
0.68141824
0.68142086
0.68140841
0.68141127
0.68141806
INFO - Training [68][   60/  196]   Loss 0.303450   Top1 89.882812   Top5 98.867188   BatchTime 0.381302   LR 0.000006
0.68143553
0.68142992
0.68142295
0.68142664
0.68141460
0.68143106
0.68141592
0.68141133
0.68141121
0.68140936
0.68140358
0.68140638
0.68140757
0.68140173
0.68139207
0.68139225
0.68138701
INFO - Training [68][   80/  196]   Loss 0.297784   Top1 90.039062   Top5 98.955078   BatchTime 0.375346   LR 0.000005
0.68137485
0.68136942
0.68136346
0.68136370
0.68135661
0.68134612
0.68134809
0.68135107
0.68135756
0.68135262
0.68135649
0.68136632
0.68135607
0.68135035
0.68135512
0.68133175
0.68131030
0.68131709
0.68131995
0.68130988
0.68131012
0.68131000
INFO - Training [68][  100/  196]   Loss 0.291528   Top1 90.281250   Top5 98.996094   BatchTime 0.374696   LR 0.000004
0.68129295
0.68129098
0.68128449
0.68128449
0.68129015
0.68128318
0.68126374
0.68125403
0.68125468
0.68125027
0.68123317
0.68124247
0.68125826
0.68125713
0.68127346
0.68125665
0.68126345
INFO - Training [68][  120/  196]   Loss 0.285249   Top1 90.481771   Top5 99.049479   BatchTime 0.370556   LR 0.000004
0.68125778
0.68125319
0.68125850
0.68125772
0.68125099
0.68125314
0.68125844
0.68127388
0.68126541
0.68127000
0.68127072
0.68125808
0.68125772
0.68126804
0.68126637
0.68126208
0.68126202
0.68125898
0.68125808
0.68125343
0.68125892
0.68126369
0.68127102
INFO - Training [68][  140/  196]   Loss 0.283992   Top1 90.611049   Top5 99.118304   BatchTime 0.368456   LR 0.000003
0.68126827
0.68125904
0.68124688
0.68126053
0.68124861
0.68124646
0.68124825
0.68123966
0.68125474
0.68125302
0.68126750
0.68124783
0.68125355
0.68125480
0.68125218
0.68124437
0.68124276
0.68125218
0.68124813
0.68123221
0.68123490
0.68123317
INFO - Training [68][  160/  196]   Loss 0.288532   Top1 90.458984   Top5 99.116211   BatchTime 0.366955   LR 0.000003
0.68123662
0.68124062
0.68124115
0.68124318
0.68124664
0.68123966
0.68125981
0.68125355
0.68125206
0.68124884
0.68123955
0.68123567
0.68124020
0.68125397
0.68125117
0.68125439
0.68126637
INFO - Training [68][  180/  196]   Loss 0.288555   Top1 90.423177   Top5 99.084201   BatchTime 0.365868   LR 0.000002
0.68127185
0.68128407
0.68128502
0.68128413
0.68127054
0.68127048
0.68127036
0.68126529
0.68125516
0.68125552
0.68126160
0.68127930
0.68127811
0.68129879
0.68129027
********************pre-trained*****************
INFO - ==> Top1: 90.370    Top5: 99.068    Loss: 0.290
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [68][   20/   40]   Loss 0.316135   Top1 90.312500   Top5 99.667969   BatchTime 0.144182
features.0.conv.0 tensor(0.4271)
features.0.conv.3 tensor(0.3418)
features.1.conv.0 tensor(0.0104)
features.1.conv.3 tensor(0.0833)
features.1.conv.6 tensor(0.0438)
features.2.conv.0 tensor(0.0353)
features.2.conv.3 tensor(0.0509)
features.2.conv.6 tensor(0.0764)
features.3.conv.0 tensor(0.0223)
features.3.conv.3 tensor(0.0417)
features.3.conv.6 tensor(0.0200)
features.4.conv.0 tensor(0.0391)
features.4.conv.3 tensor(0.0816)
features.4.conv.6 tensor(0.0970)
features.5.conv.0 tensor(0.0459)
features.5.conv.3 tensor(0.0642)
features.5.conv.6 tensor(0.1276)
features.6.conv.0 tensor(0.0317)
features.6.conv.3 tensor(0.0405)
features.6.conv.6 tensor(0.0475)
features.7.conv.0 tensor(0.0772)
features.7.conv.3 tensor(0.1221)
features.7.conv.6 tensor(0.2098)
features.8.conv.0 tensor(0.0927)
features.8.conv.3 tensor(0.1111)
features.8.conv.6 tensor(0.2675)
features.9.conv.0 tensor(0.0999)
features.9.conv.3 tensor(0.1427)
features.9.conv.6 tensor(0.3320)
features.10.conv.0 tensor(0.0365)
features.10.conv.3 tensor(0.0992)
features.10.conv.6 tensor(0.1340)
features.11.conv.0 tensor(0.5959)
features.11.conv.3 tensor(0.1505)
features.11.conv.6 tensor(0.6464)
features.12.conv.0 tensor(0.4839)
features.12.conv.3 tensor(0.1468)
features.12.conv.6 tensor(0.7452)
features.13.conv.0 tensor(0.1555)
features.13.conv.3 tensor(0.1256)
features.13.conv.6 tensor(0.4409)
features.14.conv.0 tensor(0.9071)
features.14.conv.3 tensor(0.0694)
features.14.conv.6 tensor(0.9879)
features.15.conv.0 tensor(0.9560)
features.15.conv.3 tensor(0.0584)
features.15.conv.6 tensor(0.9777)
features.16.conv.0 tensor(0.3795)
features.16.conv.3 tensor(0.1160)
features.16.conv.6 tensor(0.6171)
conv.0 tensor(0.5886)
tensor(1305396.) 2188896.0
INFO - Validation [68][   40/   40]   Loss 0.308233   Top1 90.390000   Top5 99.710000   BatchTime 0.107222
INFO - ==> Top1: 90.390    Top5: 99.710    Loss: 0.308
INFO - ==> Sparsity : 0.596
INFO - Scoreboard best 1 ==> Epoch [67][Top1: 91.330   Top5: 99.750]
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 91.240   Top5: 99.730]
INFO - Scoreboard best 3 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch  69
INFO - Training: 50000 samples (256 per mini-batch)
0.68128067
0.68128461
0.68127304
0.68126762
0.68128550
0.68128288
0.68127704
0.68128407
0.68127555
0.68128043
0.68126804
0.68127799
0.68128169
0.68128419
0.68128073
0.68127859
0.68128699
0.68127960
0.68128049
0.68128002
0.68128610
0.68128222
INFO - Training [69][   20/  196]   Loss 0.306898   Top1 89.960938   Top5 98.496094   BatchTime 0.460267   LR 0.000002
0.68128830
0.68129575
0.68132007
0.68132567
0.68132681
0.68132740
0.68132979
0.68132710
0.68132997
0.68133700
0.68133599
0.68132716
0.68133330
0.68132693
0.68131310
0.68132740
0.68132162
0.68133646
0.68133211
0.68132693
INFO - Training [69][   40/  196]   Loss 0.305178   Top1 89.775391   Top5 98.759766   BatchTime 0.431863   LR 0.000001
0.68131751
0.68131202
0.68132704
0.68133926
0.68134010
0.68132591
0.68133211
0.68133855
0.68132854
0.68133205
0.68133557
0.68132693
0.68132699
0.68132740
0.68132085
0.68133253
0.68133253
0.68133843
0.68132412
0.68132669
0.68132389
0.68132091
INFO - Training [69][   60/  196]   Loss 0.304314   Top1 89.804688   Top5 98.867188   BatchTime 0.408648   LR 0.000001
0.68132204
0.68133736
0.68134880
0.68134880
0.68133467
0.68133187
0.68134016
0.68135005
0.68134552
0.68133503
0.68133599
0.68133372
0.68134260
0.68133825
0.68133557
0.68133622
0.68134224
INFO - Training [69][   80/  196]   Loss 0.299852   Top1 90.058594   Top5 98.964844   BatchTime 0.395279   LR 0.000001
0.68134141
0.68134898
0.68134397
0.68134743
0.68132740
0.68131256
0.68130839
0.68129778
0.68129224
0.68127531
0.68128860
0.68129003
0.68128085
0.68127441
0.68128181
0.68128675
0.68127316
0.68129116
0.68128723
0.68128049
0.68126172
0.68125671
INFO - Training [69][  100/  196]   Loss 0.293912   Top1 90.308594   Top5 99.031250   BatchTime 0.388508   LR 0.000000
0.68126220
0.68127871
0.68127972
0.68129712
0.68128943
0.68127596
0.68128043
0.68127918
0.68127698
0.68126029
0.68124366
0.68124634
0.68124592
0.68122363
0.68123132
0.68125629
0.68125242
0.68126959
0.68128550
0.68126553
INFO - Training [69][  120/  196]   Loss 0.290584   Top1 90.419922   Top5 99.101562   BatchTime 0.388924   LR 0.000000
0.68127757
0.68126750
0.68126571
0.68125379
0.68127173
0.68126804
0.68127584
0.68127465
0.68128091
0.68128484
0.68128282
0.68129653
0.68128794
0.68129104
0.68129504
0.68128502
0.68129259
0.68128586
0.68127257
0.68126386
INFO - Training [69][  140/  196]   Loss 0.289488   Top1 90.418527   Top5 99.162946   BatchTime 0.392387   LR 0.000000
0.68127298
0.68128216
0.68128699
0.68128753
0.68129766
0.68130082
0.68130213
0.68130898
0.68129307
0.68129796
0.68129897
0.68130463
0.68130916
0.68129629
0.68130231
0.68129593
0.68129486
0.68129736
0.68128800
0.68129003
0.68128258
INFO - Training [69][  160/  196]   Loss 0.292282   Top1 90.366211   Top5 99.128418   BatchTime 0.392125   LR 0.000000
0.68128836
0.68128800
0.68128067
0.68128443
0.68127066
0.68126893
0.68128204
0.68126869
0.68127877
0.68127376
0.68127578
0.68126690
0.68124586
0.68124652
0.68124723
0.68124181
0.68124855
INFO - Training [69][  180/  196]   Loss 0.293335   Top1 90.266927   Top5 99.095052   BatchTime 0.387379   LR 0.000000
0.68125546
0.68126589
0.68125552
0.68125927
0.68126208
0.68125838
0.68125361
0.68124938
0.68125308
0.68125784
0.68124318
0.68125814
0.68126750
0.68127435
0.68127275
********************pre-trained*****************
INFO - ==> Top1: 90.292    Top5: 99.092    Loss: 0.293
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.4097)
features.0.conv.3 tensor(0.3398)
features.1.conv.0 tensor(0.0104)
features.1.conv.3 tensor(0.0833)
features.1.conv.6 tensor(0.0438)
features.2.conv.0 tensor(0.0350)
features.2.conv.3 tensor(0.0502)
features.2.conv.6 tensor(0.0764)
features.3.conv.0 tensor(0.0223)
features.3.conv.3 tensor(0.0417)
features.3.conv.6 tensor(0.0200)
features.4.conv.0 tensor(0.0389)
features.4.conv.3 tensor(0.0804)
features.4.conv.6 tensor(0.0970)
features.5.conv.0 tensor(0.0456)
features.5.conv.3 tensor(0.0642)
features.5.conv.6 tensor(0.1274)
features.6.conv.0 tensor(0.0317)
features.6.conv.3 tensor(0.0422)
features.6.conv.6 tensor(0.0476)
features.7.conv.0 tensor(0.0773)
features.7.conv.3 tensor(0.1233)
features.7.conv.6 tensor(0.2097)
features.8.conv.0 tensor(0.0926)
features.8.conv.3 tensor(0.1108)
features.8.conv.6 tensor(0.2679)
features.9.conv.0 tensor(0.1000)
features.9.conv.3 tensor(0.1415)
features.9.conv.6 tensor(0.3320)
features.10.conv.0 tensor(0.0363)
features.10.conv.3 tensor(0.0984)
features.10.conv.6 tensor(0.1340)
features.11.conv.0 tensor(0.5960)
features.11.conv.3 tensor(0.1505)
features.11.conv.6 tensor(0.6464)
features.12.conv.0 tensor(0.4837)
features.12.conv.3 tensor(0.1472)
features.12.conv.6 tensor(0.7454)
features.13.conv.0 tensor(0.1557)
features.13.conv.3 tensor(0.1250)
features.13.conv.6 tensor(0.4409)
features.14.conv.0 tensor(0.9070)
features.14.conv.3 tensor(0.0696)
features.14.conv.6 tensor(0.9879)
features.15.conv.0 tensor(0.9559)
features.15.conv.3 tensor(0.0584)
features.15.conv.6 tensor(0.9775)
features.16.conv.0 tensor(0.3799)
features.16.conv.3 tensor(0.1161)
features.16.conv.6 tensor(0.6165)
conv.0 tensor(0.5882)
tensor(1305084.) 2188896.0
INFO - Validation [69][   20/   40]   Loss 0.295919   Top1 90.917969   Top5 99.667969   BatchTime 0.150437
INFO - Validation [69][   40/   40]   Loss 0.282769   Top1 91.040000   Top5 99.760000   BatchTime 0.103067
INFO - ==> Top1: 91.040    Top5: 99.760    Loss: 0.283
INFO - ==> Sparsity : 0.596
INFO - Scoreboard best 1 ==> Epoch [67][Top1: 91.330   Top5: 99.750]
INFO - Scoreboard best 2 ==> Epoch [66][Top1: 91.240   Top5: 99.730]
INFO - Scoreboard best 3 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
INFO - >>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.295919   Top1 90.917969   Top5 99.667969   BatchTime 0.154070
*************hard_pruning_mode*******************
INFO - Validation [   40/   40]   Loss 0.282769   Top1 91.040000   Top5 99.760000   BatchTime 0.116969
INFO - ==> Top1: 91.040    Top5: 99.760    Loss: 0.283
INFO - ==> Sparsity : 0.000
INFO - Program completed sucessfully ... exiting ...
INFO - >>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [0][   20/  196]   Loss 0.516422   Top1 82.500000   Top5 97.910156   BatchTime 0.427111   LR 0.004999
INFO - Training [0][   40/  196]   Loss 0.533692   Top1 81.699219   Top5 98.046875   BatchTime 0.401305   LR 0.004995
INFO - Training [0][   60/  196]   Loss 0.526782   Top1 81.796875   Top5 98.125000   BatchTime 0.385677   LR 0.004989
INFO - Training [0][   80/  196]   Loss 0.525310   Top1 81.889648   Top5 98.134766   BatchTime 0.373907   LR 0.004980
INFO - Training [0][  100/  196]   Loss 0.520647   Top1 81.980469   Top5 98.195312   BatchTime 0.366332   LR 0.004968
INFO - Training [0][  120/  196]   Loss 0.514339   Top1 82.268880   Top5 98.255208   BatchTime 0.363109   LR 0.004954
INFO - Training [0][  140/  196]   Loss 0.514726   Top1 82.260045   Top5 98.278460   BatchTime 0.363211   LR 0.004938
INFO - Training [0][  160/  196]   Loss 0.521801   Top1 82.028809   Top5 98.229980   BatchTime 0.359222   LR 0.004919
INFO - Training [0][  180/  196]   Loss 0.521345   Top1 81.948785   Top5 98.177083   BatchTime 0.350996   LR 0.004897
********************pre-trained*****************
INFO - ==> Top1: 82.076    Top5: 98.210    Loss: 0.518
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [0][   20/   40]   Loss 0.495652   Top1 84.394531   Top5 98.828125   BatchTime 0.127971
features.0.conv.0 tensor(0.4583)
features.0.conv.3 tensor(0.3418)
features.1.conv.0 tensor(0.0124)
features.1.conv.3 tensor(0.0694)
features.1.conv.6 tensor(0.0417)
features.2.conv.0 tensor(0.0367)
features.2.conv.3 tensor(0.0594)
features.2.conv.6 tensor(0.0741)
features.3.conv.0 tensor(0.0258)
features.3.conv.3 tensor(0.0440)
features.3.conv.6 tensor(0.0269)
features.4.conv.0 tensor(0.0345)
features.4.conv.3 tensor(0.0856)
features.4.conv.6 tensor(0.1486)
features.5.conv.0 tensor(0.0492)
features.5.conv.3 tensor(0.0718)
features.5.conv.6 tensor(0.1883)
features.6.conv.0 tensor(0.0304)
features.6.conv.3 tensor(0.0399)
features.6.conv.6 tensor(0.0472)
features.7.conv.0 tensor(0.0926)
features.7.conv.3 tensor(0.1262)
features.7.conv.6 tensor(0.3052)
features.8.conv.0 tensor(0.1071)
features.8.conv.3 tensor(0.1047)
features.8.conv.6 tensor(0.3556)
features.9.conv.0 tensor(0.1079)
features.9.conv.3 tensor(0.1372)
features.9.conv.6 tensor(0.4094)
features.10.conv.0 tensor(0.0454)
features.10.conv.3 tensor(0.1004)
features.10.conv.6 tensor(0.2201)
features.11.conv.0 tensor(0.6464)
features.11.conv.3 tensor(0.1672)
features.11.conv.6 tensor(0.7049)
features.12.conv.0 tensor(0.5641)
features.12.conv.3 tensor(0.1655)
features.12.conv.6 tensor(0.7943)
features.13.conv.0 tensor(0.1753)
features.13.conv.3 tensor(0.1346)
features.13.conv.6 tensor(0.5400)
features.14.conv.0 tensor(0.9286)
features.14.conv.3 tensor(0.0785)
features.14.conv.6 tensor(0.9898)
features.15.conv.0 tensor(0.9653)
features.15.conv.3 tensor(0.0684)
features.15.conv.6 tensor(0.9849)
features.16.conv.0 tensor(0.5040)
features.16.conv.3 tensor(0.1572)
features.16.conv.6 tensor(0.7090)
conv.0 tensor(0.7630)
tensor(1465908.) 2188896.0
INFO - Validation [0][   40/   40]   Loss 0.491205   Top1 84.110000   Top5 99.030000   BatchTime 0.090284
INFO - ==> Top1: 84.110    Top5: 99.030    Loss: 0.491
INFO - ==> Sparsity : 0.670
INFO - Scoreboard best 1 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   1
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [1][   20/  196]   Loss 0.561665   Top1 80.898438   Top5 97.519531   BatchTime 0.423026   LR 0.004853
INFO - Training [1][   40/  196]   Loss 0.555339   Top1 80.810547   Top5 97.705078   BatchTime 0.383121   LR 0.004825
INFO - Training [1][   60/  196]   Loss 0.538476   Top1 81.282552   Top5 97.981771   BatchTime 0.369611   LR 0.004794
INFO - Training [1][   80/  196]   Loss 0.528715   Top1 81.630859   Top5 98.095703   BatchTime 0.361315   LR 0.004761
INFO - Training [1][  100/  196]   Loss 0.514553   Top1 82.132812   Top5 98.183594   BatchTime 0.355331   LR 0.004725
INFO - Training [1][  120/  196]   Loss 0.502326   Top1 82.539062   Top5 98.271484   BatchTime 0.353307   LR 0.004687
INFO - Training [1][  140/  196]   Loss 0.493925   Top1 82.787388   Top5 98.356585   BatchTime 0.350278   LR 0.004647
INFO - Training [1][  160/  196]   Loss 0.496752   Top1 82.719727   Top5 98.330078   BatchTime 0.342970   LR 0.004605
INFO - Training [1][  180/  196]   Loss 0.499843   Top1 82.556424   Top5 98.224826   BatchTime 0.338292   LR 0.004560
********************pre-trained*****************
INFO - ==> Top1: 82.576    Top5: 98.204    Loss: 0.499
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [1][   20/   40]   Loss 0.396840   Top1 87.480469   Top5 99.472656   BatchTime 0.146941
features.0.conv.0 tensor(0.4479)
features.0.conv.3 tensor(0.3516)
features.1.conv.0 tensor(0.0143)
features.1.conv.3 tensor(0.0799)
features.1.conv.6 tensor(0.0308)
features.2.conv.0 tensor(0.0344)
features.2.conv.3 tensor(0.0486)
features.2.conv.6 tensor(0.0718)
features.3.conv.0 tensor(0.0205)
features.3.conv.3 tensor(0.0471)
features.3.conv.6 tensor(0.0226)
features.4.conv.0 tensor(0.0378)
features.4.conv.3 tensor(0.0856)
features.4.conv.6 tensor(0.1776)
features.5.conv.0 tensor(0.0488)
features.5.conv.3 tensor(0.0602)
features.5.conv.6 tensor(0.2194)
features.6.conv.0 tensor(0.0361)
features.6.conv.3 tensor(0.0411)
features.6.conv.6 tensor(0.0457)
features.7.conv.0 tensor(0.0901)
features.7.conv.3 tensor(0.1308)
features.7.conv.6 tensor(0.3378)
features.8.conv.0 tensor(0.1152)
features.8.conv.3 tensor(0.1152)
features.8.conv.6 tensor(0.3864)
features.9.conv.0 tensor(0.1121)
features.9.conv.3 tensor(0.1479)
features.9.conv.6 tensor(0.4366)
features.10.conv.0 tensor(0.0408)
features.10.conv.3 tensor(0.1033)
features.10.conv.6 tensor(0.2566)
features.11.conv.0 tensor(0.6644)
features.11.conv.3 tensor(0.1752)
features.11.conv.6 tensor(0.7261)
features.12.conv.0 tensor(0.5860)
features.12.conv.3 tensor(0.1698)
features.12.conv.6 tensor(0.8051)
features.13.conv.0 tensor(0.1863)
features.13.conv.3 tensor(0.1312)
features.13.conv.6 tensor(0.5667)
features.14.conv.0 tensor(0.9187)
features.14.conv.3 tensor(0.0838)
features.14.conv.6 tensor(0.9885)
features.15.conv.0 tensor(0.9579)
features.15.conv.3 tensor(0.0696)
features.15.conv.6 tensor(0.9853)
INFO - Validation [1][   40/   40]   Loss 0.388780   Top1 87.230000   Top5 99.520000   BatchTime 0.118794
INFO - ==> Top1: 87.230    Top5: 99.520    Loss: 0.389
INFO - ==> Sparsity : 0.684
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
features.16.conv.0 tensor(0.5296)
features.16.conv.3 tensor(0.1633)
features.16.conv.6 tensor(0.7264)
conv.0 tensor(0.7972)
tensor(1497702.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_best.pth.tar
save quantized models...
INFO - >>>>>> Epoch   2
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [2][   20/  196]   Loss 0.508608   Top1 81.738281   Top5 97.636719   BatchTime 0.427887   LR 0.004477
INFO - Training [2][   40/  196]   Loss 0.508021   Top1 82.226562   Top5 97.949219   BatchTime 0.385603   LR 0.004426
INFO - Training [2][   60/  196]   Loss 0.539377   Top1 81.067708   Top5 97.356771   BatchTime 0.372688   LR 0.004374
INFO - Training [2][   80/  196]   Loss 0.536415   Top1 81.230469   Top5 97.597656   BatchTime 0.364382   LR 0.004320
INFO - Training [2][  100/  196]   Loss 0.528031   Top1 81.558594   Top5 97.695312   BatchTime 0.357198   LR 0.004264
INFO - Training [2][  120/  196]   Loss 0.802920   Top1 70.777995   Top5 90.677083   BatchTime 0.347431   LR 0.004206
INFO - Training [2][  140/  196]   Loss 1.022893   Top1 62.034040   Top5 84.754464   BatchTime 0.340251   LR 0.004146
INFO - Training [2][  160/  196]   Loss 1.187122   Top1 55.517578   Top5 80.251465   BatchTime 0.336715   LR 0.004085
INFO - Training [2][  180/  196]   Loss 1.313738   Top1 50.390625   Top5 76.759983   BatchTime 0.335406   LR 0.004022
********************pre-trained*****************
INFO - ==> Top1: 47.214    Top5: 74.666    Loss: 1.393
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [2][   20/   40]   Loss 116.099051   Top1 10.253906   Top5 50.214844   BatchTime 0.142592
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.1029)
features.16.conv.3 tensor(0.0587)
INFO - Validation [2][   40/   40]   Loss 116.525622   Top1 10.000000   Top5 50.000000   BatchTime 0.104729
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 116.526
INFO - ==> Sparsity : 0.258
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
features.16.conv.6 tensor(0.6752)
conv.0 tensor(0.8322)
tensor(564613.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch   3
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [3][   20/  196]   Loss 2.327054   Top1 9.824219   Top5 49.472656   BatchTime 0.411092   LR 0.003907
INFO - Training [3][   40/  196]   Loss 2.323355   Top1 10.039062   Top5 50.097656   BatchTime 0.375546   LR 0.003840
INFO - Training [3][   60/  196]   Loss 2.322061   Top1 9.960938   Top5 50.240885   BatchTime 0.364236   LR 0.003771
INFO - Training [3][   80/  196]   Loss 2.319563   Top1 10.053711   Top5 50.410156   BatchTime 0.361700   LR 0.003701
INFO - Training [3][  100/  196]   Loss 2.318637   Top1 10.000000   Top5 50.347656   BatchTime 0.364258   LR 0.003630
INFO - Training [3][  120/  196]   Loss 2.317855   Top1 9.941406   Top5 50.162760   BatchTime 0.364585   LR 0.003558
INFO - Training [3][  140/  196]   Loss 2.316902   Top1 10.002790   Top5 50.301339   BatchTime 0.352530   LR 0.003484
INFO - Training [3][  160/  196]   Loss 2.316340   Top1 9.924316   Top5 50.251465   BatchTime 0.353537   LR 0.003410
INFO - Training [3][  180/  196]   Loss 2.315677   Top1 9.913194   Top5 50.227865   BatchTime 0.351540   LR 0.003335
********************pre-trained*****************
INFO - ==> Top1: 9.948    Top5: 50.232    Loss: 2.315
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [3][   20/   40]   Loss 103.742659   Top1 10.253906   Top5 50.214844   BatchTime 0.138360
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0587)
features.16.conv.6 tensor(0.6915)
conv.0 tensor(0.8515)
tensor(576867.) 2188896.0
INFO - Validation [3][   40/   40]   Loss 104.088432   Top1 10.000000   Top5 50.000000   BatchTime 0.102288
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 104.088
INFO - ==> Sparsity : 0.264
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch   4
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [4][   20/  196]   Loss 2.306656   Top1 9.863281   Top5 50.742188   BatchTime 0.423040   LR 0.003200
INFO - Training [4][   40/  196]   Loss 2.307224   Top1 9.960938   Top5 50.458984   BatchTime 0.379058   LR 0.003122
INFO - Training [4][   60/  196]   Loss 2.307761   Top1 10.000000   Top5 49.928385   BatchTime 0.369258   LR 0.003044
INFO - Training [4][   80/  196]   Loss 2.307957   Top1 9.863281   Top5 49.824219   BatchTime 0.361012   LR 0.002965
INFO - Training [4][  100/  196]   Loss 2.307858   Top1 9.890625   Top5 49.859375   BatchTime 0.357334   LR 0.002886
INFO - Training [4][  120/  196]   Loss 2.307439   Top1 9.892578   Top5 50.071615   BatchTime 0.346444   LR 0.002806
INFO - Training [4][  140/  196]   Loss 2.307251   Top1 9.857701   Top5 50.097656   BatchTime 0.341456   LR 0.002726
INFO - Training [4][  160/  196]   Loss 2.307415   Top1 9.929199   Top5 50.146484   BatchTime 0.343575   LR 0.002646
INFO - Training [4][  180/  196]   Loss 2.307233   Top1 9.945747   Top5 50.225694   BatchTime 0.343619   LR 0.002566
********************pre-trained*****************
INFO - ==> Top1: 9.992    Top5: 50.216    Loss: 2.307
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [4][   20/   40]   Loss 89.339193   Top1 10.253906   Top5 50.214844   BatchTime 0.137353
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0587)
features.16.conv.6 tensor(0.6945)
conv.0 tensor(0.8566)
tensor(579873.) 2188896.0
INFO - Validation [4][   40/   40]   Loss 89.656615   Top1 10.000000   Top5 50.000000   BatchTime 0.096452
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 89.657
INFO - ==> Sparsity : 0.265
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch   5
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [5][   20/  196]   Loss 2.304920   Top1 10.214844   Top5 50.273438   BatchTime 0.423000   LR 0.002424
INFO - Training [5][   40/  196]   Loss 2.305294   Top1 9.853516   Top5 49.736328   BatchTime 0.395474   LR 0.002343
INFO - Training [5][   60/  196]   Loss 2.305535   Top1 9.863281   Top5 49.661458   BatchTime 0.378444   LR 0.002263
INFO - Training [5][   80/  196]   Loss 2.305024   Top1 9.965820   Top5 49.877930   BatchTime 0.368834   LR 0.002183
INFO - Training [5][  100/  196]   Loss 2.304900   Top1 9.906250   Top5 49.906250   BatchTime 0.361337   LR 0.002104
INFO - Training [5][  120/  196]   Loss 2.304944   Top1 9.977214   Top5 49.879557   BatchTime 0.346482   LR 0.002024
INFO - Training [5][  140/  196]   Loss 2.304929   Top1 9.952567   Top5 49.882812   BatchTime 0.340511   LR 0.001946
INFO - Training [5][  160/  196]   Loss 2.304884   Top1 9.941406   Top5 49.934082   BatchTime 0.341992   LR 0.001868
INFO - Training [5][  180/  196]   Loss 2.304912   Top1 9.878472   Top5 49.848090   BatchTime 0.341361   LR 0.001790
INFO - ==> Top1: 9.942    Top5: 49.992    Loss: 2.305
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [5][   20/   40]   Loss 91.364597   Top1 10.253906   Top5 50.214844   BatchTime 0.126418
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0588)
features.16.conv.6 tensor(0.6955)
conv.0 tensor(0.8586)
tensor(580995.) 2188896.0
INFO - Validation [5][   40/   40]   Loss 91.681230   Top1 10.000000   Top5 50.000000   BatchTime 0.090501
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 91.681
INFO - ==> Sparsity : 0.265
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch   6
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [6][   20/  196]   Loss 2.303533   Top1 10.703125   Top5 50.937500   BatchTime 0.425471   LR 0.001655
INFO - Training [6][   40/  196]   Loss 2.304858   Top1 10.234375   Top5 50.048828   BatchTime 0.382199   LR 0.001580
INFO - Training [6][   60/  196]   Loss 2.304987   Top1 10.175781   Top5 49.850260   BatchTime 0.375258   LR 0.001506
INFO - Training [6][   80/  196]   Loss 2.304773   Top1 10.112305   Top5 49.829102   BatchTime 0.366165   LR 0.001432
INFO - Training [6][  100/  196]   Loss 2.304760   Top1 10.089844   Top5 49.750000   BatchTime 0.359158   LR 0.001360
INFO - Training [6][  120/  196]   Loss 2.304729   Top1 10.019531   Top5 49.778646   BatchTime 0.349898   LR 0.001289
INFO - Training [6][  140/  196]   Loss 2.304695   Top1 9.972098   Top5 49.715402   BatchTime 0.345033   LR 0.001220
INFO - Training [6][  160/  196]   Loss 2.304645   Top1 9.926758   Top5 49.638672   BatchTime 0.344501   LR 0.001151
INFO - Training [6][  180/  196]   Loss 2.304575   Top1 9.893663   Top5 49.713542   BatchTime 0.343764   LR 0.001084
********************pre-trained*****************
INFO - ==> Top1: 9.900    Top5: 49.646    Loss: 2.305
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [6][   20/   40]   Loss 91.440081   Top1 10.253906   Top5 50.214844   BatchTime 0.125665
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0590)
features.16.conv.6 tensor(0.6961)
conv.0 tensor(0.8592)
tensor(581449.) 2188896.0
INFO - Validation [6][   40/   40]   Loss 91.761538   Top1 10.000000   Top5 50.000000   BatchTime 0.088305
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 91.762
INFO - ==> Sparsity : 0.266
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch   7
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [7][   20/  196]   Loss 2.303742   Top1 10.273438   Top5 49.511719   BatchTime 0.439373   LR 0.000969
INFO - Training [7][   40/  196]   Loss 2.303727   Top1 10.253906   Top5 49.375000   BatchTime 0.390303   LR 0.000907
INFO - Training [7][   60/  196]   Loss 2.303915   Top1 10.182292   Top5 49.375000   BatchTime 0.380577   LR 0.000845
INFO - Training [7][   80/  196]   Loss 2.303755   Top1 10.166016   Top5 49.345703   BatchTime 0.373696   LR 0.000786
INFO - Training [7][  100/  196]   Loss 2.303706   Top1 10.164062   Top5 49.449219   BatchTime 0.366629   LR 0.000728
INFO - Training [7][  120/  196]   Loss 2.303584   Top1 10.133464   Top5 49.589844   BatchTime 0.349231   LR 0.000673
INFO - Training [7][  140/  196]   Loss 2.303664   Top1 10.041853   Top5 49.592634   BatchTime 0.347055   LR 0.000619
INFO - Training [7][  160/  196]   Loss 2.303610   Top1 10.046387   Top5 49.770508   BatchTime 0.348341   LR 0.000567
INFO - Training [7][  180/  196]   Loss 2.303574   Top1 10.065104   Top5 49.733073   BatchTime 0.346919   LR 0.000517
********************pre-trained*****************
INFO - ==> Top1: 10.116    Top5: 49.882    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [7][   20/   40]   Loss 89.458520   Top1 10.253906   Top5 50.214844   BatchTime 0.126813
INFO - Validation [7][   40/   40]   Loss 89.772284   Top1 10.000000   Top5 50.000000   BatchTime 0.090068
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0590)
features.16.conv.6 tensor(0.6965)
conv.0 tensor(0.8590)
tensor(581498.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 89.772
INFO - ==> Sparsity : 0.266
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch   8
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [8][   20/  196]   Loss 2.303927   Top1 9.746094   Top5 50.234375   BatchTime 0.421162   LR 0.000434
INFO - Training [8][   40/  196]   Loss 2.303904   Top1 9.609375   Top5 49.531250   BatchTime 0.380647   LR 0.000389
INFO - Training [8][   60/  196]   Loss 2.303463   Top1 9.648438   Top5 50.136719   BatchTime 0.365320   LR 0.000347
INFO - Training [8][   80/  196]   Loss 2.303351   Top1 9.707031   Top5 50.209961   BatchTime 0.366436   LR 0.000308
INFO - Training [8][  100/  196]   Loss 2.303443   Top1 9.761719   Top5 50.050781   BatchTime 0.361012   LR 0.000270
INFO - Training [8][  120/  196]   Loss 2.303389   Top1 9.772135   Top5 50.078125   BatchTime 0.344706   LR 0.000235
INFO - Training [8][  140/  196]   Loss 2.303464   Top1 9.679129   Top5 49.949777   BatchTime 0.340081   LR 0.000202
INFO - Training [8][  160/  196]   Loss 2.303483   Top1 9.719238   Top5 49.748535   BatchTime 0.342982   LR 0.000172
INFO - Training [8][  180/  196]   Loss 2.303461   Top1 9.754774   Top5 49.776476   BatchTime 0.344720   LR 0.000143
INFO - ==> Top1: 9.762    Top5: 49.792    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [8][   20/   40]   Loss 89.791621   Top1 10.253906   Top5 50.214844   BatchTime 0.131417
INFO - Validation [8][   40/   40]   Loss 90.104291   Top1 10.000000   Top5 50.000000   BatchTime 0.092059
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0590)
features.16.conv.6 tensor(0.6965)
conv.0 tensor(0.8592)
tensor(581548.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 90.104
INFO - ==> Sparsity : 0.266
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch   9
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [9][   20/  196]   Loss 2.303374   Top1 9.394531   Top5 49.960938   BatchTime 0.422268   LR 0.000100
INFO - Training [9][   40/  196]   Loss 2.303266   Top1 9.833984   Top5 50.029297   BatchTime 0.380677   LR 0.000079
INFO - Training [9][   60/  196]   Loss 2.303219   Top1 10.039062   Top5 49.837240   BatchTime 0.365456   LR 0.000060
INFO - Training [9][   80/  196]   Loss 2.303228   Top1 10.048828   Top5 49.697266   BatchTime 0.358104   LR 0.000044
INFO - Training [9][  100/  196]   Loss 2.303224   Top1 10.019531   Top5 49.847656   BatchTime 0.357023   LR 0.000030
INFO - Training [9][  120/  196]   Loss 2.303219   Top1 10.068359   Top5 49.749349   BatchTime 0.347684   LR 0.000019
INFO - Training [9][  140/  196]   Loss 2.303089   Top1 10.094866   Top5 49.924665   BatchTime 0.343662   LR 0.000010
INFO - Training [9][  160/  196]   Loss 2.303029   Top1 10.078125   Top5 50.029297   BatchTime 0.345503   LR 0.000004
INFO - Training [9][  180/  196]   Loss 2.302966   Top1 10.119358   Top5 50.169271   BatchTime 0.343934   LR 0.000001
INFO - ==> Top1: 10.142    Top5: 50.152    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [9][   20/   40]   Loss 89.515043   Top1 10.253906   Top5 50.214844   BatchTime 0.134059
INFO - Validation [9][   40/   40]   Loss 89.829018   Top1 10.000000   Top5 50.000000   BatchTime 0.094902
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0596)
features.16.conv.6 tensor(0.6965)
conv.0 tensor(0.8593)
tensor(581604.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 89.829
INFO - ==> Sparsity : 0.266
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  10
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [10][   20/  196]   Loss 2.303830   Top1 9.746094   Top5 50.195312   BatchTime 0.392584   LR 0.002500
INFO - Training [10][   40/  196]   Loss 2.303867   Top1 9.990234   Top5 50.078125   BatchTime 0.363894   LR 0.002499
INFO - Training [10][   60/  196]   Loss 2.304228   Top1 10.097656   Top5 49.882812   BatchTime 0.353669   LR 0.002499
INFO - Training [10][   80/  196]   Loss 2.304718   Top1 9.848633   Top5 49.497070   BatchTime 0.348783   LR 0.002497
INFO - Training [10][  100/  196]   Loss 2.304897   Top1 9.742188   Top5 49.218750   BatchTime 0.349907   LR 0.002496
INFO - Training [10][  120/  196]   Loss 2.304772   Top1 9.690755   Top5 49.417318   BatchTime 0.337680   LR 0.002494
INFO - Training [10][  140/  196]   Loss 2.304747   Top1 9.673549   Top5 49.472656   BatchTime 0.335689   LR 0.002492
INFO - Training [10][  160/  196]   Loss 2.304561   Top1 9.699707   Top5 49.560547   BatchTime 0.337164   LR 0.002490
INFO - Training [10][  180/  196]   Loss 2.304543   Top1 9.715712   Top5 49.605035   BatchTime 0.339212   LR 0.002487
********************pre-trained*****************
INFO - ==> Top1: 9.746    Top5: 49.574    Loss: 2.304
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [10][   20/   40]   Loss 87.283808   Top1 10.253906   Top5 50.214844   BatchTime 0.135226
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0588)
features.16.conv.6 tensor(0.6976)
conv.0 tensor(0.8620)
tensor(583039.) 2188896.0
INFO - Validation [10][   40/   40]   Loss 87.587315   Top1 10.000000   Top5 50.000000   BatchTime 0.097444
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 87.587
INFO - ==> Sparsity : 0.266
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  11
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [11][   20/  196]   Loss 2.304356   Top1 9.199219   Top5 49.511719   BatchTime 0.425964   LR 0.002481
INFO - Training [11][   40/  196]   Loss 2.304007   Top1 9.677734   Top5 49.365234   BatchTime 0.385490   LR 0.002478
INFO - Training [11][   60/  196]   Loss 2.303780   Top1 10.032552   Top5 49.921875   BatchTime 0.372457   LR 0.002474
INFO - Training [11][   80/  196]   Loss 2.303997   Top1 9.907227   Top5 49.809570   BatchTime 0.363920   LR 0.002470
INFO - Training [11][  100/  196]   Loss 2.303882   Top1 10.050781   Top5 50.007812   BatchTime 0.362678   LR 0.002465
INFO - Training [11][  120/  196]   Loss 2.303825   Top1 10.071615   Top5 50.097656   BatchTime 0.347522   LR 0.002460
INFO - Training [11][  140/  196]   Loss 2.304020   Top1 9.991629   Top5 49.974888   BatchTime 0.334854   LR 0.002455
INFO - Training [11][  160/  196]   Loss 2.304024   Top1 10.073242   Top5 49.958496   BatchTime 0.328446   LR 0.002450
INFO - Training [11][  180/  196]   Loss 2.304100   Top1 10.026042   Top5 49.802517   BatchTime 0.331162   LR 0.002444
INFO - ==> Top1: 10.084    Top5: 49.800    Loss: 2.304
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [11][   20/   40]   Loss 81.235638   Top1 10.253906   Top5 50.214844   BatchTime 0.134263
INFO - Validation [11][   40/   40]   Loss 81.513869   Top1 10.000000   Top5 50.000000   BatchTime 0.096981
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0597)
features.16.conv.6 tensor(0.6998)
conv.0 tensor(0.8631)
tensor(584151.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 81.514
INFO - ==> Sparsity : 0.267
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  12
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [12][   20/  196]   Loss 2.303231   Top1 9.804688   Top5 50.781250   BatchTime 0.430003   LR 0.002433
INFO - Training [12][   40/  196]   Loss 2.303552   Top1 9.785156   Top5 50.351562   BatchTime 0.380962   LR 0.002426
INFO - Training [12][   60/  196]   Loss 2.304031   Top1 9.843750   Top5 49.824219   BatchTime 0.366924   LR 0.002419
INFO - Training [12][   80/  196]   Loss 2.303885   Top1 9.848633   Top5 49.687500   BatchTime 0.358625   LR 0.002412
INFO - Training [12][  100/  196]   Loss 2.303787   Top1 9.820312   Top5 49.601562   BatchTime 0.355311   LR 0.002404
INFO - Training [12][  120/  196]   Loss 2.303836   Top1 9.781901   Top5 49.580078   BatchTime 0.354847   LR 0.002396
INFO - Training [12][  140/  196]   Loss 2.303793   Top1 9.924665   Top5 49.500558   BatchTime 0.346078   LR 0.002388
INFO - Training [12][  160/  196]   Loss 2.303793   Top1 9.863281   Top5 49.562988   BatchTime 0.337110   LR 0.002380
INFO - Training [12][  180/  196]   Loss 2.303809   Top1 9.878472   Top5 49.587674   BatchTime 0.337999   LR 0.002371
INFO - ==> Top1: 9.850    Top5: 49.552    Loss: 2.304
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [12][   20/   40]   Loss 78.924787   Top1 10.253906   Top5 50.214844   BatchTime 0.133428
INFO - Validation [12][   40/   40]   Loss 79.192577   Top1 10.000000   Top5 50.000000   BatchTime 0.093559
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 79.193
INFO - ==> Sparsity : 0.267
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  13
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0587)
features.16.conv.6 tensor(0.7006)
conv.0 tensor(0.8644)
tensor(584980.) 2188896.0
INFO - Training [13][   20/  196]   Loss 2.303229   Top1 10.078125   Top5 50.019531   BatchTime 0.417671   LR 0.002355
INFO - Training [13][   40/  196]   Loss 2.303204   Top1 10.253906   Top5 50.234375   BatchTime 0.394157   LR 0.002345
INFO - Training [13][   60/  196]   Loss 2.303539   Top1 10.182292   Top5 50.169271   BatchTime 0.390707   LR 0.002336
INFO - Training [13][   80/  196]   Loss 2.303741   Top1 10.000000   Top5 49.975586   BatchTime 0.381306   LR 0.002325
INFO - Training [13][  100/  196]   Loss 2.303761   Top1 10.015625   Top5 49.859375   BatchTime 0.373627   LR 0.002315
INFO - Training [13][  120/  196]   Loss 2.303739   Top1 10.055339   Top5 49.609375   BatchTime 0.368575   LR 0.002304
INFO - Training [13][  140/  196]   Loss 2.303741   Top1 9.994420   Top5 49.695871   BatchTime 0.358879   LR 0.002293
INFO - Training [13][  160/  196]   Loss 2.303582   Top1 10.073242   Top5 49.873047   BatchTime 0.351061   LR 0.002282
INFO - Training [13][  180/  196]   Loss 2.303713   Top1 10.028212   Top5 49.798177   BatchTime 0.350735   LR 0.002271
INFO - ==> Top1: 10.016    Top5: 49.776    Loss: 2.304
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [13][   20/   40]   Loss 73.909235   Top1 10.253906   Top5 50.214844   BatchTime 0.133951
INFO - Validation [13][   40/   40]   Loss 74.152412   Top1 10.000000   Top5 50.000000   BatchTime 0.095298
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 74.152
INFO - ==> Sparsity : 0.268
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  14
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0582)
features.16.conv.6 tensor(0.7013)
conv.0 tensor(0.8657)
tensor(585712.) 2188896.0
INFO - Training [14][   20/  196]   Loss 2.303434   Top1 9.707031   Top5 50.722656   BatchTime 0.427128   LR 0.002250
INFO - Training [14][   40/  196]   Loss 2.303515   Top1 9.892578   Top5 50.585938   BatchTime 0.378018   LR 0.002238
INFO - Training [14][   60/  196]   Loss 2.303635   Top1 9.941406   Top5 50.345052   BatchTime 0.367740   LR 0.002225
INFO - Training [14][   80/  196]   Loss 2.303527   Top1 9.980469   Top5 50.166016   BatchTime 0.369628   LR 0.002213
INFO - Training [14][  100/  196]   Loss 2.303318   Top1 10.074219   Top5 50.351562   BatchTime 0.365126   LR 0.002200
INFO - Training [14][  120/  196]   Loss 2.303252   Top1 10.091146   Top5 50.345052   BatchTime 0.357366   LR 0.002186
INFO - Training [14][  140/  196]   Loss 2.303379   Top1 9.974888   Top5 50.147879   BatchTime 0.344203   LR 0.002173
INFO - Training [14][  160/  196]   Loss 2.303443   Top1 9.960938   Top5 50.144043   BatchTime 0.339614   LR 0.002159
INFO - Training [14][  180/  196]   Loss 2.303531   Top1 9.984809   Top5 50.039062   BatchTime 0.338764   LR 0.002145
INFO - ==> Top1: 9.990    Top5: 50.040    Loss: 2.304
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [14][   20/   40]   Loss 72.002252   Top1 10.253906   Top5 50.214844   BatchTime 0.135511
INFO - Validation [14][   40/   40]   Loss 72.244024   Top1 10.000000   Top5 50.000000   BatchTime 0.096355
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 72.244
INFO - ==> Sparsity : 0.268
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  15
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0582)
features.16.conv.6 tensor(0.7022)
conv.0 tensor(0.8666)
tensor(586345.) 2188896.0
INFO - Training [15][   20/  196]   Loss 2.302939   Top1 9.882812   Top5 50.742188   BatchTime 0.429409   LR 0.002120
INFO - Training [15][   40/  196]   Loss 2.302961   Top1 10.078125   Top5 50.527344   BatchTime 0.379363   LR 0.002106
INFO - Training [15][   60/  196]   Loss 2.303472   Top1 9.824219   Top5 49.746094   BatchTime 0.367850   LR 0.002091
INFO - Training [15][   80/  196]   Loss 2.303436   Top1 9.824219   Top5 49.770508   BatchTime 0.367211   LR 0.002076
INFO - Training [15][  100/  196]   Loss 2.303518   Top1 9.820312   Top5 49.582031   BatchTime 0.363392   LR 0.002061
INFO - Training [15][  120/  196]   Loss 2.303424   Top1 9.951172   Top5 49.625651   BatchTime 0.356773   LR 0.002045
INFO - Training [15][  140/  196]   Loss 2.303421   Top1 9.958147   Top5 49.520089   BatchTime 0.346425   LR 0.002030
INFO - Training [15][  160/  196]   Loss 2.303384   Top1 9.978027   Top5 49.572754   BatchTime 0.341752   LR 0.002014
INFO - Training [15][  180/  196]   Loss 2.303314   Top1 10.030382   Top5 49.639757   BatchTime 0.341228   LR 0.001998
INFO - ==> Top1: 10.008    Top5: 49.566    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [15][   20/   40]   Loss 69.047340   Top1 10.253906   Top5 50.214844   BatchTime 0.130012
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0584)
features.16.conv.6 tensor(0.7028)
conv.0 tensor(0.8670)
tensor(586674.) 2188896.0
INFO - Validation [15][   40/   40]   Loss 69.280744   Top1 10.000000   Top5 50.000000   BatchTime 0.091847
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 69.281
INFO - ==> Sparsity : 0.268
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  16
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [16][   20/  196]   Loss 2.303654   Top1 9.980469   Top5 50.019531   BatchTime 0.427409   LR 0.001969
INFO - Training [16][   40/  196]   Loss 2.303312   Top1 10.039062   Top5 50.351562   BatchTime 0.378418   LR 0.001953
INFO - Training [16][   60/  196]   Loss 2.303755   Top1 9.811198   Top5 50.221354   BatchTime 0.365362   LR 0.001936
INFO - Training [16][   80/  196]   Loss 2.303661   Top1 9.609375   Top5 50.234375   BatchTime 0.360213   LR 0.001919
INFO - Training [16][  100/  196]   Loss 2.303558   Top1 9.648438   Top5 50.246094   BatchTime 0.358248   LR 0.001902
INFO - Training [16][  120/  196]   Loss 2.303668   Top1 9.658203   Top5 49.951172   BatchTime 0.357115   LR 0.001885
INFO - Training [16][  140/  196]   Loss 2.303622   Top1 9.715402   Top5 49.785156   BatchTime 0.347075   LR 0.001867
INFO - Training [16][  160/  196]   Loss 2.303567   Top1 9.702148   Top5 49.755859   BatchTime 0.342753   LR 0.001850
INFO - Training [16][  180/  196]   Loss 2.303513   Top1 9.667969   Top5 49.798177   BatchTime 0.343706   LR 0.001832
********************pre-trained*****************
INFO - ==> Top1: 9.636    Top5: 49.824    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [16][   20/   40]   Loss 70.096271   Top1 10.253906   Top5 50.214844   BatchTime 0.138271
INFO - Validation [16][   40/   40]   Loss 70.330852   Top1 10.000000   Top5 50.000000   BatchTime 0.097075
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0579)
features.16.conv.6 tensor(0.7040)
conv.0 tensor(0.8671)
tensor(587105.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 70.331
INFO - ==> Sparsity : 0.268
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  17
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [17][   20/  196]   Loss 2.303421   Top1 9.843750   Top5 50.234375   BatchTime 0.448866   LR 0.001800
INFO - Training [17][   40/  196]   Loss 2.303755   Top1 9.941406   Top5 50.078125   BatchTime 0.394872   LR 0.001782
INFO - Training [17][   60/  196]   Loss 2.303471   Top1 9.843750   Top5 50.305990   BatchTime 0.373963   LR 0.001764
INFO - Training [17][   80/  196]   Loss 2.303497   Top1 9.824219   Top5 50.092773   BatchTime 0.365980   LR 0.001746
INFO - Training [17][  100/  196]   Loss 2.303538   Top1 9.824219   Top5 50.039062   BatchTime 0.359872   LR 0.001727
INFO - Training [17][  120/  196]   Loss 2.303479   Top1 9.863281   Top5 49.990234   BatchTime 0.355420   LR 0.001708
INFO - Training [17][  140/  196]   Loss 2.303481   Top1 9.905134   Top5 50.050223   BatchTime 0.344195   LR 0.001690
INFO - Training [17][  160/  196]   Loss 2.303428   Top1 9.936523   Top5 49.941406   BatchTime 0.333435   LR 0.001671
INFO - Training [17][  180/  196]   Loss 2.303467   Top1 9.906684   Top5 49.973958   BatchTime 0.332182   LR 0.001652
INFO - ==> Top1: 9.886    Top5: 49.994    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [17][   20/   40]   Loss 70.810470   Top1 10.253906   Top5 50.214844   BatchTime 0.129121
INFO - Validation [17][   40/   40]   Loss 71.052481   Top1 10.000000   Top5 50.000000   BatchTime 0.091042
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 71.052
INFO - ==> Sparsity : 0.268
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  18
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0587)
features.16.conv.6 tensor(0.7047)
conv.0 tensor(0.8672)
tensor(587375.) 2188896.0
INFO - Training [18][   20/  196]   Loss 2.303742   Top1 9.589844   Top5 49.062500   BatchTime 0.413929   LR 0.001618
INFO - Training [18][   40/  196]   Loss 2.303793   Top1 9.804688   Top5 48.945312   BatchTime 0.375406   LR 0.001599
INFO - Training [18][   60/  196]   Loss 2.303603   Top1 9.628906   Top5 49.186198   BatchTime 0.366527   LR 0.001579
INFO - Training [18][   80/  196]   Loss 2.303653   Top1 9.702148   Top5 49.233398   BatchTime 0.357263   LR 0.001560
INFO - Training [18][  100/  196]   Loss 2.303530   Top1 9.710938   Top5 49.257812   BatchTime 0.352909   LR 0.001540
INFO - Training [18][  120/  196]   Loss 2.303466   Top1 9.667969   Top5 49.355469   BatchTime 0.350282   LR 0.001521
INFO - Training [18][  140/  196]   Loss 2.303435   Top1 9.723772   Top5 49.316406   BatchTime 0.344969   LR 0.001501
INFO - Training [18][  160/  196]   Loss 2.303428   Top1 9.707031   Top5 49.375000   BatchTime 0.335226   LR 0.001482
INFO - Training [18][  180/  196]   Loss 2.303436   Top1 9.735243   Top5 49.283854   BatchTime 0.325312   LR 0.001462
INFO - ==> Top1: 9.730    Top5: 49.268    Loss: 2.303
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [18][   20/   40]   Loss 68.407526   Top1 10.253906   Top5 50.214844   BatchTime 0.124707
INFO - Validation [18][   40/   40]   Loss 68.641652   Top1 10.000000   Top5 50.000000   BatchTime 0.088121
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 68.642
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0580)
features.16.conv.6 tensor(0.7055)
conv.0 tensor(0.8677)
tensor(587813.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  19
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [19][   20/  196]   Loss 2.303428   Top1 9.667969   Top5 49.414062   BatchTime 0.422747   LR 0.001427
INFO - Training [19][   40/  196]   Loss 2.303584   Top1 9.560547   Top5 49.238281   BatchTime 0.384432   LR 0.001407
INFO - Training [19][   60/  196]   Loss 2.303518   Top1 9.654948   Top5 49.414062   BatchTime 0.367310   LR 0.001387
INFO - Training [19][   80/  196]   Loss 2.303475   Top1 9.863281   Top5 49.418945   BatchTime 0.361027   LR 0.001367
INFO - Training [19][  100/  196]   Loss 2.303402   Top1 9.710938   Top5 49.390625   BatchTime 0.355854   LR 0.001347
INFO - Training [19][  120/  196]   Loss 2.303296   Top1 9.736328   Top5 49.677734   BatchTime 0.351864   LR 0.001327
INFO - Training [19][  140/  196]   Loss 2.303284   Top1 9.796317   Top5 49.681920   BatchTime 0.351708   LR 0.001307
INFO - Training [19][  160/  196]   Loss 2.303342   Top1 9.873047   Top5 49.614258   BatchTime 0.349670   LR 0.001287
INFO - Training [19][  180/  196]   Loss 2.303355   Top1 9.874132   Top5 49.542101   BatchTime 0.346604   LR 0.001266
INFO - ==> Top1: 9.888    Top5: 49.538    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [19][   20/   40]   Loss 67.944423   Top1 10.253906   Top5 50.214844   BatchTime 0.129592
INFO - Validation [19][   40/   40]   Loss 68.175355   Top1 10.000000   Top5 50.000000   BatchTime 0.091177
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 68.175
INFO - ==> Sparsity : 0.268
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  20
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0584)
features.16.conv.6 tensor(0.7046)
conv.0 tensor(0.8676)
tensor(587486.) 2188896.0
INFO - Training [20][   20/  196]   Loss 2.303407   Top1 9.921875   Top5 50.156250   BatchTime 0.421674   LR 0.001231
INFO - Training [20][   40/  196]   Loss 2.303551   Top1 9.667969   Top5 49.697266   BatchTime 0.381858   LR 0.001211
INFO - Training [20][   60/  196]   Loss 2.303449   Top1 9.609375   Top5 49.817708   BatchTime 0.364846   LR 0.001191
INFO - Training [20][   80/  196]   Loss 2.303355   Top1 9.721680   Top5 49.794922   BatchTime 0.356890   LR 0.001171
INFO - Training [20][  100/  196]   Loss 2.303361   Top1 9.800781   Top5 49.621094   BatchTime 0.352279   LR 0.001151
INFO - Training [20][  120/  196]   Loss 2.303353   Top1 9.798177   Top5 49.602865   BatchTime 0.353090   LR 0.001131
INFO - Training [20][  140/  196]   Loss 2.303330   Top1 9.801897   Top5 49.559152   BatchTime 0.356160   LR 0.001111
INFO - Training [20][  160/  196]   Loss 2.303257   Top1 9.875488   Top5 49.672852   BatchTime 0.353272   LR 0.001091
INFO - Training [20][  180/  196]   Loss 2.303217   Top1 9.891493   Top5 49.741753   BatchTime 0.346984   LR 0.001071
INFO - ==> Top1: 9.918    Top5: 49.760    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [20][   20/   40]   Loss 67.518963   Top1 10.253906   Top5 50.214844   BatchTime 0.128364
INFO - Validation [20][   40/   40]   Loss 67.751711   Top1 10.000000   Top5 50.000000   BatchTime 0.089840
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 67.752
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  21
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0591)
features.16.conv.6 tensor(0.7055)
conv.0 tensor(0.8679)
tensor(587865.) 2188896.0
INFO - Training [21][   20/  196]   Loss 2.303271   Top1 8.906250   Top5 50.312500   BatchTime 0.395056   LR 0.001036
INFO - Training [21][   40/  196]   Loss 2.303147   Top1 9.394531   Top5 50.175781   BatchTime 0.363275   LR 0.001016
INFO - Training [21][   60/  196]   Loss 2.303082   Top1 9.824219   Top5 50.188802   BatchTime 0.355837   LR 0.000996
INFO - Training [21][   80/  196]   Loss 2.303106   Top1 9.799805   Top5 49.965820   BatchTime 0.352498   LR 0.000976
INFO - Training [21][  100/  196]   Loss 2.303153   Top1 9.585938   Top5 49.988281   BatchTime 0.349495   LR 0.000957
INFO - Training [21][  120/  196]   Loss 2.303065   Top1 9.794922   Top5 50.152995   BatchTime 0.349811   LR 0.000937
INFO - Training [21][  140/  196]   Loss 2.303114   Top1 9.785156   Top5 50.139509   BatchTime 0.348170   LR 0.000918
INFO - Training [21][  160/  196]   Loss 2.303137   Top1 9.736328   Top5 50.051270   BatchTime 0.347618   LR 0.000899
INFO - Training [21][  180/  196]   Loss 2.303108   Top1 9.793837   Top5 50.015191   BatchTime 0.344311   LR 0.000879
INFO - ==> Top1: 9.768    Top5: 49.984    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [21][   20/   40]   Loss 69.883735   Top1 10.253906   Top5 50.214844   BatchTime 0.161182
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0589)
features.16.conv.6 tensor(0.7053)
conv.0 tensor(0.8676)
tensor(587678.) 2188896.0
INFO - Validation [21][   40/   40]   Loss 70.121540   Top1 10.000000   Top5 50.000000   BatchTime 0.106816
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 70.122
INFO - ==> Sparsity : 0.268
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  22
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [22][   20/  196]   Loss 2.303218   Top1 9.765625   Top5 50.175781   BatchTime 0.405077   LR 0.000846
INFO - Training [22][   40/  196]   Loss 2.303269   Top1 9.609375   Top5 50.205078   BatchTime 0.373319   LR 0.000827
INFO - Training [22][   60/  196]   Loss 2.303142   Top1 9.752604   Top5 49.934896   BatchTime 0.360081   LR 0.000808
INFO - Training [22][   80/  196]   Loss 2.303131   Top1 9.819336   Top5 49.853516   BatchTime 0.359903   LR 0.000789
INFO - Training [22][  100/  196]   Loss 2.303100   Top1 9.703125   Top5 50.035156   BatchTime 0.354020   LR 0.000770
INFO - Training [22][  120/  196]   Loss 2.303042   Top1 9.791667   Top5 49.947917   BatchTime 0.352671   LR 0.000752
INFO - Training [22][  140/  196]   Loss 2.303121   Top1 9.838170   Top5 49.852121   BatchTime 0.352213   LR 0.000734
INFO - Training [22][  160/  196]   Loss 2.303102   Top1 9.755859   Top5 49.821777   BatchTime 0.350601   LR 0.000715
INFO - Training [22][  180/  196]   Loss 2.303109   Top1 9.691840   Top5 49.726562   BatchTime 0.349627   LR 0.000697
INFO - ==> Top1: 9.690    Top5: 49.752    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [22][   20/   40]   Loss 71.212675   Top1 10.253906   Top5 50.214844   BatchTime 0.145145
INFO - Validation [22][   40/   40]   Loss 71.454346   Top1 10.000000   Top5 50.000000   BatchTime 0.097428
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 71.454
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  23
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0583)
features.16.conv.6 tensor(0.7073)
conv.0 tensor(0.8680)
tensor(588468.) 2188896.0
INFO - Training [23][   20/  196]   Loss 2.303472   Top1 9.335938   Top5 49.277344   BatchTime 0.416416   LR 0.000666
INFO - Training [23][   40/  196]   Loss 2.303101   Top1 9.619141   Top5 49.453125   BatchTime 0.375091   LR 0.000648
INFO - Training [23][   60/  196]   Loss 2.303078   Top1 9.785156   Top5 49.720052   BatchTime 0.362789   LR 0.000630
INFO - Training [23][   80/  196]   Loss 2.303039   Top1 9.902344   Top5 49.628906   BatchTime 0.355528   LR 0.000613
INFO - Training [23][  100/  196]   Loss 2.302872   Top1 10.085938   Top5 49.761719   BatchTime 0.352187   LR 0.000596
INFO - Training [23][  120/  196]   Loss 2.302911   Top1 10.074870   Top5 49.707031   BatchTime 0.350150   LR 0.000579
INFO - Training [23][  140/  196]   Loss 2.302888   Top1 10.092076   Top5 49.807478   BatchTime 0.348169   LR 0.000562
INFO - Training [23][  160/  196]   Loss 2.302945   Top1 10.031738   Top5 49.675293   BatchTime 0.347164   LR 0.000545
INFO - Training [23][  180/  196]   Loss 2.302921   Top1 10.039062   Top5 49.711372   BatchTime 0.346162   LR 0.000529
INFO - ==> Top1: 10.078    Top5: 49.826    Loss: 2.303
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [23][   20/   40]   Loss 71.951925   Top1 10.253906   Top5 50.214844   BatchTime 0.145744
INFO - Validation [23][   40/   40]   Loss 72.195528   Top1 10.000000   Top5 50.000000   BatchTime 0.097286
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 72.196
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  24
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0584)
features.16.conv.6 tensor(0.7071)
conv.0 tensor(0.8677)
tensor(588292.) 2188896.0
INFO - Training [24][   20/  196]   Loss 2.303030   Top1 9.687500   Top5 49.609375   BatchTime 0.407068   LR 0.000500
INFO - Training [24][   40/  196]   Loss 2.302656   Top1 10.273438   Top5 49.990234   BatchTime 0.376769   LR 0.000484
INFO - Training [24][   60/  196]   Loss 2.302744   Top1 10.045573   Top5 49.700521   BatchTime 0.364732   LR 0.000468
INFO - Training [24][   80/  196]   Loss 2.302883   Top1 10.014648   Top5 49.697266   BatchTime 0.355217   LR 0.000453
INFO - Training [24][  100/  196]   Loss 2.302855   Top1 9.988281   Top5 49.800781   BatchTime 0.353454   LR 0.000437
INFO - Training [24][  120/  196]   Loss 2.302904   Top1 9.886068   Top5 49.684245   BatchTime 0.349230   LR 0.000422
INFO - Training [24][  140/  196]   Loss 2.302915   Top1 9.919085   Top5 49.757254   BatchTime 0.347064   LR 0.000407
INFO - Training [24][  160/  196]   Loss 2.303003   Top1 9.843750   Top5 49.560547   BatchTime 0.347209   LR 0.000392
INFO - Training [24][  180/  196]   Loss 2.303072   Top1 9.861111   Top5 49.487847   BatchTime 0.345988   LR 0.000378
INFO - ==> Top1: 9.856    Top5: 49.608    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [24][   20/   40]   Loss 72.275293   Top1 10.253906   Top5 50.214844   BatchTime 0.148282
INFO - Validation [24][   40/   40]   Loss 72.522234   Top1 10.000000   Top5 50.000000   BatchTime 0.100591
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 72.522
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  25
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0581)
features.16.conv.6 tensor(0.7074)
conv.0 tensor(0.8677)
tensor(588390.) 2188896.0
INFO - Training [25][   20/  196]   Loss 2.302570   Top1 10.117188   Top5 50.097656   BatchTime 0.442142   LR 0.000353
INFO - Training [25][   40/  196]   Loss 2.302632   Top1 10.019531   Top5 49.726562   BatchTime 0.392867   LR 0.000339
INFO - Training [25][   60/  196]   Loss 2.302732   Top1 9.960938   Top5 49.726562   BatchTime 0.373723   LR 0.000325
INFO - Training [25][   80/  196]   Loss 2.302677   Top1 9.995117   Top5 49.887695   BatchTime 0.365028   LR 0.000312
INFO - Training [25][  100/  196]   Loss 2.302635   Top1 9.984375   Top5 50.039062   BatchTime 0.360333   LR 0.000299
INFO - Training [25][  120/  196]   Loss 2.302617   Top1 10.074870   Top5 50.065104   BatchTime 0.359379   LR 0.000286
INFO - Training [25][  140/  196]   Loss 2.302658   Top1 10.016741   Top5 49.916295   BatchTime 0.361867   LR 0.000273
INFO - Training [25][  160/  196]   Loss 2.302744   Top1 9.948730   Top5 49.780273   BatchTime 0.360964   LR 0.000261
INFO - Training [25][  180/  196]   Loss 2.302756   Top1 10.030382   Top5 49.778646   BatchTime 0.357392   LR 0.000248
INFO - ==> Top1: 10.028    Top5: 49.734    Loss: 2.303
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [25][   20/   40]   Loss 72.273362   Top1 10.253906   Top5 50.214844   BatchTime 0.150692
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0584)
features.16.conv.6 tensor(0.7073)
conv.0 tensor(0.8678)
tensor(588403.) 2188896.0
INFO - Validation [25][   40/   40]   Loss 72.519174   Top1 10.000000   Top5 50.000000   BatchTime 0.104780
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 72.519
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  26
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [26][   20/  196]   Loss 2.302313   Top1 10.585938   Top5 52.109375   BatchTime 0.407013   LR 0.000228
INFO - Training [26][   40/  196]   Loss 2.302520   Top1 10.273438   Top5 50.751953   BatchTime 0.373022   LR 0.000216
INFO - Training [26][   60/  196]   Loss 2.302500   Top1 10.227865   Top5 50.820312   BatchTime 0.365048   LR 0.000205
INFO - Training [26][   80/  196]   Loss 2.302513   Top1 10.278320   Top5 50.844727   BatchTime 0.366095   LR 0.000194
INFO - Training [26][  100/  196]   Loss 2.302624   Top1 10.261719   Top5 50.605469   BatchTime 0.358902   LR 0.000183
INFO - Training [26][  120/  196]   Loss 2.302719   Top1 10.123698   Top5 50.384115   BatchTime 0.356404   LR 0.000173
INFO - Training [26][  140/  196]   Loss 2.302832   Top1 10.044643   Top5 50.223214   BatchTime 0.353544   LR 0.000163
INFO - Training [26][  160/  196]   Loss 2.302817   Top1 10.097656   Top5 50.104980   BatchTime 0.351467   LR 0.000153
INFO - Training [26][  180/  196]   Loss 2.302794   Top1 10.130208   Top5 50.052083   BatchTime 0.350042   LR 0.000144
INFO - ==> Top1: 10.110    Top5: 50.064    Loss: 2.303
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [26][   20/   40]   Loss 72.029857   Top1 10.253906   Top5 50.214844   BatchTime 0.147555
INFO - Validation [26][   40/   40]   Loss 72.275830   Top1 10.000000   Top5 50.000000   BatchTime 0.099317
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 72.276
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  27
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0586)
features.16.conv.6 tensor(0.7074)
conv.0 tensor(0.8679)
tensor(588472.) 2188896.0
INFO - Training [27][   20/  196]   Loss 2.303177   Top1 9.472656   Top5 49.667969   BatchTime 0.412424   LR 0.000128
INFO - Training [27][   40/  196]   Loss 2.302951   Top1 9.882812   Top5 50.126953   BatchTime 0.375122   LR 0.000119
INFO - Training [27][   60/  196]   Loss 2.302867   Top1 10.130208   Top5 50.019531   BatchTime 0.357620   LR 0.000111
INFO - Training [27][   80/  196]   Loss 2.302885   Top1 10.083008   Top5 50.000000   BatchTime 0.351549   LR 0.000102
INFO - Training [27][  100/  196]   Loss 2.302943   Top1 9.953125   Top5 49.933594   BatchTime 0.348516   LR 0.000095
INFO - Training [27][  120/  196]   Loss 2.302920   Top1 9.993490   Top5 50.003255   BatchTime 0.345555   LR 0.000087
INFO - Training [27][  140/  196]   Loss 2.302926   Top1 10.041853   Top5 49.927455   BatchTime 0.343825   LR 0.000080
INFO - Training [27][  160/  196]   Loss 2.302967   Top1 9.916992   Top5 49.804688   BatchTime 0.342241   LR 0.000073
INFO - Training [27][  180/  196]   Loss 2.302973   Top1 9.982639   Top5 49.748264   BatchTime 0.342267   LR 0.000066
********************pre-trained*****************
INFO - ==> Top1: 9.994    Top5: 49.782    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [27][   20/   40]   Loss 72.597249   Top1 10.253906   Top5 50.214844   BatchTime 0.162478
INFO - Validation [27][   40/   40]   Loss 72.843558   Top1 10.000000   Top5 50.000000   BatchTime 0.118910
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 72.844
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  28
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0587)
features.16.conv.6 tensor(0.7074)
conv.0 tensor(0.8678)
tensor(588415.) 2188896.0
INFO - Training [28][   20/  196]   Loss 2.303255   Top1 9.453125   Top5 49.121094   BatchTime 0.411594   LR 0.000055
INFO - Training [28][   40/  196]   Loss 2.302827   Top1 10.175781   Top5 49.921875   BatchTime 0.376775   LR 0.000050
INFO - Training [28][   60/  196]   Loss 2.303141   Top1 9.889323   Top5 49.433594   BatchTime 0.362180   LR 0.000044
INFO - Training [28][   80/  196]   Loss 2.302903   Top1 10.009766   Top5 49.926758   BatchTime 0.354939   LR 0.000039
INFO - Training [28][  100/  196]   Loss 2.302852   Top1 10.035156   Top5 49.906250   BatchTime 0.350555   LR 0.000034
INFO - Training [28][  120/  196]   Loss 2.302909   Top1 9.938151   Top5 49.798177   BatchTime 0.346008   LR 0.000030
INFO - Training [28][  140/  196]   Loss 2.302876   Top1 9.991629   Top5 49.762835   BatchTime 0.343666   LR 0.000026
INFO - Training [28][  160/  196]   Loss 2.302814   Top1 10.034180   Top5 49.841309   BatchTime 0.345147   LR 0.000022
INFO - Training [28][  180/  196]   Loss 2.302878   Top1 9.965278   Top5 49.796007   BatchTime 0.343997   LR 0.000018
INFO - ==> Top1: 9.940    Top5: 49.832    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [28][   20/   40]   Loss 72.538111   Top1 10.253906   Top5 50.214844   BatchTime 0.149261
INFO - Validation [28][   40/   40]   Loss 72.785309   Top1 10.000000   Top5 50.000000   BatchTime 0.131198
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0581)
features.16.conv.6 tensor(0.7073)
conv.0 tensor(0.8680)
tensor(588472.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 72.785
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [28][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  29
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [29][   20/  196]   Loss 2.302629   Top1 10.097656   Top5 50.214844   BatchTime 0.379811   LR 0.000013
INFO - Training [29][   40/  196]   Loss 2.302701   Top1 10.000000   Top5 50.292969   BatchTime 0.357742   LR 0.000010
INFO - Training [29][   60/  196]   Loss 2.302761   Top1 9.967448   Top5 50.013021   BatchTime 0.348363   LR 0.000008
INFO - Training [29][   80/  196]   Loss 2.302809   Top1 9.907227   Top5 49.995117   BatchTime 0.343145   LR 0.000005
INFO - Training [29][  100/  196]   Loss 2.302803   Top1 9.957031   Top5 50.089844   BatchTime 0.349628   LR 0.000004
INFO - Training [29][  120/  196]   Loss 2.302818   Top1 9.928385   Top5 50.006510   BatchTime 0.346780   LR 0.000002
INFO - Training [29][  140/  196]   Loss 2.302803   Top1 9.938616   Top5 49.983259   BatchTime 0.345000   LR 0.000001
INFO - Training [29][  160/  196]   Loss 2.302840   Top1 9.941406   Top5 49.897461   BatchTime 0.343314   LR 0.000001
INFO - Training [29][  180/  196]   Loss 2.302824   Top1 9.993490   Top5 49.898003   BatchTime 0.343059   LR 0.000000
INFO - ==> Top1: 10.012    Top5: 50.000    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [29][   20/   40]   Loss 72.414732   Top1 10.253906   Top5 50.214844   BatchTime 0.135046
INFO - Validation [29][   40/   40]   Loss 72.660979   Top1 10.000000   Top5 50.000000   BatchTime 0.098782
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0586)
features.16.conv.6 tensor(0.7073)
conv.0 tensor(0.8678)
tensor(588413.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 72.661
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [29][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  30
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [30][   20/  196]   Loss 2.302748   Top1 9.218750   Top5 50.449219   BatchTime 0.364177   LR 0.001250
INFO - Training [30][   40/  196]   Loss 2.302894   Top1 9.589844   Top5 50.263672   BatchTime 0.348803   LR 0.001250
INFO - Training [30][   60/  196]   Loss 2.302899   Top1 9.811198   Top5 50.390625   BatchTime 0.346276   LR 0.001250
INFO - Training [30][   80/  196]   Loss 2.303003   Top1 9.721680   Top5 50.043945   BatchTime 0.345212   LR 0.001250
INFO - Training [30][  100/  196]   Loss 2.303070   Top1 9.753906   Top5 49.714844   BatchTime 0.342582   LR 0.001250
INFO - Training [30][  120/  196]   Loss 2.303141   Top1 9.752604   Top5 49.625651   BatchTime 0.341171   LR 0.001249
INFO - Training [30][  140/  196]   Loss 2.303135   Top1 9.782366   Top5 49.628906   BatchTime 0.339737   LR 0.001249
INFO - Training [30][  160/  196]   Loss 2.303185   Top1 9.809570   Top5 49.587402   BatchTime 0.339176   LR 0.001249
INFO - Training [30][  180/  196]   Loss 2.303154   Top1 9.815538   Top5 49.696181   BatchTime 0.338740   LR 0.001248
INFO - ==> Top1: 9.832    Top5: 49.676    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [30][   20/   40]   Loss 63.828444   Top1 10.253906   Top5 50.214844   BatchTime 0.131964
INFO - Validation [30][   40/   40]   Loss 64.047161   Top1 10.000000   Top5 50.000000   BatchTime 0.094237
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 64.047
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [30][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  31
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0586)
features.16.conv.6 tensor(0.7081)
conv.0 tensor(0.8682)
tensor(588797.) 2188896.0
INFO - Training [31][   20/  196]   Loss 2.302972   Top1 9.726562   Top5 50.214844   BatchTime 0.376860   LR 0.001248
INFO - Training [31][   40/  196]   Loss 2.303417   Top1 10.039062   Top5 49.453125   BatchTime 0.358105   LR 0.001247
INFO - Training [31][   60/  196]   Loss 2.303417   Top1 10.097656   Top5 49.394531   BatchTime 0.350869   LR 0.001247
INFO - Training [31][   80/  196]   Loss 2.303293   Top1 10.102539   Top5 49.624023   BatchTime 0.352607   LR 0.001246
INFO - Training [31][  100/  196]   Loss 2.303217   Top1 10.210938   Top5 49.859375   BatchTime 0.358069   LR 0.001246
INFO - Training [31][  120/  196]   Loss 2.303279   Top1 10.061849   Top5 49.830729   BatchTime 0.353748   LR 0.001245
INFO - Training [31][  140/  196]   Loss 2.303311   Top1 9.966518   Top5 49.877232   BatchTime 0.351622   LR 0.001244
INFO - Training [31][  160/  196]   Loss 2.303279   Top1 9.956055   Top5 49.970703   BatchTime 0.349560   LR 0.001244
INFO - Training [31][  180/  196]   Loss 2.303195   Top1 10.008681   Top5 50.104167   BatchTime 0.347779   LR 0.001243
INFO - ==> Top1: 10.010    Top5: 50.042    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [31][   20/   40]   Loss 63.445699   Top1 10.253906   Top5 50.214844   BatchTime 0.124959
INFO - Validation [31][   40/   40]   Loss 63.656669   Top1 10.000000   Top5 50.000000   BatchTime 0.088031
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0581)
features.16.conv.6 tensor(0.7092)
conv.0 tensor(0.8692)
tensor(589542.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 63.657
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [31][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  32
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [32][   20/  196]   Loss 2.302914   Top1 10.859375   Top5 50.253906   BatchTime 0.340304   LR 0.001242
INFO - Training [32][   40/  196]   Loss 2.303262   Top1 10.390625   Top5 49.882812   BatchTime 0.321722   LR 0.001241
INFO - Training [32][   60/  196]   Loss 2.303224   Top1 10.000000   Top5 49.550781   BatchTime 0.326398   LR 0.001240
INFO - Training [32][   80/  196]   Loss 2.303154   Top1 10.224609   Top5 49.687500   BatchTime 0.326853   LR 0.001239
INFO - Training [32][  100/  196]   Loss 2.303168   Top1 10.082031   Top5 49.562500   BatchTime 0.330095   LR 0.001238
INFO - Training [32][  120/  196]   Loss 2.303260   Top1 10.022786   Top5 49.560547   BatchTime 0.330749   LR 0.001237
INFO - Training [32][  140/  196]   Loss 2.303264   Top1 9.910714   Top5 49.542411   BatchTime 0.333740   LR 0.001236
INFO - Training [32][  160/  196]   Loss 2.303210   Top1 9.929199   Top5 49.638672   BatchTime 0.338381   LR 0.001235
INFO - Training [32][  180/  196]   Loss 2.303206   Top1 9.986979   Top5 49.526910   BatchTime 0.338592   LR 0.001234
INFO - ==> Top1: 9.988    Top5: 49.552    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [32][   20/   40]   Loss 59.931615   Top1 10.253906   Top5 50.214844   BatchTime 0.127460
INFO - Validation [32][   40/   40]   Loss 60.136036   Top1 10.000000   Top5 50.000000   BatchTime 0.089912
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 60.136
INFO - ==> Sparsity : 0.269
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [32][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  33
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0574)
features.16.conv.6 tensor(0.7105)
conv.0 tensor(0.8691)
tensor(589894.) 2188896.0
INFO - Training [33][   20/  196]   Loss 2.302972   Top1 10.292969   Top5 50.019531   BatchTime 0.343424   LR 0.001232
INFO - Training [33][   40/  196]   Loss 2.302832   Top1 10.224609   Top5 49.589844   BatchTime 0.324423   LR 0.001230
INFO - Training [33][   60/  196]   Loss 2.302958   Top1 10.104167   Top5 49.707031   BatchTime 0.326441   LR 0.001229
INFO - Training [33][   80/  196]   Loss 2.302918   Top1 10.029297   Top5 49.814453   BatchTime 0.328461   LR 0.001228
INFO - Training [33][  100/  196]   Loss 2.302958   Top1 9.894531   Top5 49.843750   BatchTime 0.334063   LR 0.001226
INFO - Training [33][  120/  196]   Loss 2.302860   Top1 9.925130   Top5 49.964193   BatchTime 0.335861   LR 0.001225
INFO - Training [33][  140/  196]   Loss 2.302973   Top1 9.885603   Top5 49.891183   BatchTime 0.335431   LR 0.001224
INFO - Training [33][  160/  196]   Loss 2.302955   Top1 9.968262   Top5 49.892578   BatchTime 0.334516   LR 0.001222
INFO - Training [33][  180/  196]   Loss 2.303018   Top1 9.904514   Top5 49.843750   BatchTime 0.333711   LR 0.001221
********************pre-trained*****************
INFO - ==> Top1: 9.912    Top5: 49.806    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [33][   20/   40]   Loss 55.188247   Top1 10.253906   Top5 50.214844   BatchTime 0.134858
INFO - Validation [33][   40/   40]   Loss 55.374905   Top1 10.000000   Top5 50.000000   BatchTime 0.095814
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0583)
features.16.conv.6 tensor(0.7119)
conv.0 tensor(0.8696)
tensor(590553.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 55.375
INFO - ==> Sparsity : 0.270
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [33][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  34
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [34][   20/  196]   Loss 2.302650   Top1 9.941406   Top5 50.117188   BatchTime 0.359965   LR 0.001218
INFO - Training [34][   40/  196]   Loss 2.302850   Top1 10.068359   Top5 49.619141   BatchTime 0.321926   LR 0.001216
INFO - Training [34][   60/  196]   Loss 2.302867   Top1 10.000000   Top5 49.739583   BatchTime 0.326333   LR 0.001215
INFO - Training [34][   80/  196]   Loss 2.303008   Top1 9.887695   Top5 49.990234   BatchTime 0.333742   LR 0.001213
INFO - Training [34][  100/  196]   Loss 2.303067   Top1 9.925781   Top5 49.937500   BatchTime 0.333452   LR 0.001211
INFO - Training [34][  120/  196]   Loss 2.303037   Top1 9.941406   Top5 49.918620   BatchTime 0.337011   LR 0.001209
INFO - Training [34][  140/  196]   Loss 2.303136   Top1 9.776786   Top5 49.938616   BatchTime 0.337483   LR 0.001208
INFO - Training [34][  160/  196]   Loss 2.303087   Top1 9.814453   Top5 50.039062   BatchTime 0.338173   LR 0.001206
INFO - Training [34][  180/  196]   Loss 2.303115   Top1 9.848090   Top5 50.000000   BatchTime 0.338409   LR 0.001204
INFO - ==> Top1: 9.902    Top5: 49.980    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [34][   20/   40]   Loss 54.358937   Top1 10.253906   Top5 50.214844   BatchTime 0.128889
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0575)
features.16.conv.6 tensor(0.7134)
conv.0 tensor(0.8701)
tensor(591196.) 2188896.0
INFO - Validation [34][   40/   40]   Loss 54.543002   Top1 10.000000   Top5 50.000000   BatchTime 0.091174
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 54.543
INFO - ==> Sparsity : 0.270
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [34][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  35
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [35][   20/  196]   Loss 2.303189   Top1 10.703125   Top5 48.964844   BatchTime 0.367730   LR 0.001201
INFO - Training [35][   40/  196]   Loss 2.302850   Top1 10.527344   Top5 49.619141   BatchTime 0.340326   LR 0.001199
INFO - Training [35][   60/  196]   Loss 2.303139   Top1 10.364583   Top5 49.511719   BatchTime 0.314501   LR 0.001197
INFO - Training [35][   80/  196]   Loss 2.303115   Top1 10.424805   Top5 49.516602   BatchTime 0.295987   LR 0.001195
INFO - Training [35][  100/  196]   Loss 2.303025   Top1 10.390625   Top5 49.484375   BatchTime 0.286926   LR 0.001192
INFO - Training [35][  120/  196]   Loss 2.303064   Top1 10.292969   Top5 49.580078   BatchTime 0.280548   LR 0.001190
INFO - Training [35][  140/  196]   Loss 2.303021   Top1 10.301339   Top5 49.606585   BatchTime 0.276221   LR 0.001188
INFO - Training [35][  160/  196]   Loss 2.302959   Top1 10.249023   Top5 49.675293   BatchTime 0.272736   LR 0.001186
INFO - Training [35][  180/  196]   Loss 2.303011   Top1 10.121528   Top5 49.626736   BatchTime 0.267684   LR 0.001184
INFO - ==> Top1: 10.080    Top5: 49.620    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [35][   20/   40]   Loss 53.290930   Top1 10.253906   Top5 50.214844   BatchTime 0.125362
INFO - Validation [35][   40/   40]   Loss 53.470376   Top1 10.000000   Top5 50.000000   BatchTime 0.089482
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 53.470
INFO - ==> Sparsity : 0.270
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [35][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  36
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0566)
features.16.conv.6 tensor(0.7143)
conv.0 tensor(0.8701)
tensor(591482.) 2188896.0
INFO - Training [36][   20/  196]   Loss 2.302856   Top1 10.390625   Top5 50.468750   BatchTime 0.314040   LR 0.001180
INFO - Training [36][   40/  196]   Loss 2.303336   Top1 9.638672   Top5 49.638672   BatchTime 0.291868   LR 0.001177
INFO - Training [36][   60/  196]   Loss 2.303318   Top1 9.544271   Top5 49.596354   BatchTime 0.277047   LR 0.001175
INFO - Training [36][   80/  196]   Loss 2.303273   Top1 9.296875   Top5 49.594727   BatchTime 0.263077   LR 0.001173
INFO - Training [36][  100/  196]   Loss 2.303275   Top1 9.406250   Top5 49.441406   BatchTime 0.256232   LR 0.001170
INFO - Training [36][  120/  196]   Loss 2.303152   Top1 9.482422   Top5 49.619141   BatchTime 0.253972   LR 0.001168
INFO - Training [36][  140/  196]   Loss 2.303211   Top1 9.547991   Top5 49.606585   BatchTime 0.249817   LR 0.001165
INFO - Training [36][  160/  196]   Loss 2.303240   Top1 9.504395   Top5 49.543457   BatchTime 0.247014   LR 0.001163
INFO - Training [36][  180/  196]   Loss 2.303172   Top1 9.611545   Top5 49.631076   BatchTime 0.244649   LR 0.001160
INFO - ==> Top1: 9.692    Top5: 49.702    Loss: 2.303
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [36][   20/   40]   Loss 53.301538   Top1 10.253906   Top5 50.214844   BatchTime 0.131916
INFO - Validation [36][   40/   40]   Loss 53.484531   Top1 10.000000   Top5 50.000000   BatchTime 0.093373
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 53.485
INFO - ==> Sparsity : 0.270
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [36][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  37
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0581)
features.16.conv.6 tensor(0.7147)
conv.0 tensor(0.8707)
tensor(591833.) 2188896.0
INFO - Training [37][   20/  196]   Loss 2.302806   Top1 9.863281   Top5 50.136719   BatchTime 0.316462   LR 0.001155
INFO - Training [37][   40/  196]   Loss 2.302865   Top1 10.009766   Top5 50.009766   BatchTime 0.286211   LR 0.001153
INFO - Training [37][   60/  196]   Loss 2.303084   Top1 9.778646   Top5 49.544271   BatchTime 0.278646   LR 0.001150
INFO - Training [37][   80/  196]   Loss 2.302951   Top1 10.068359   Top5 49.565430   BatchTime 0.273058   LR 0.001147
INFO - Training [37][  100/  196]   Loss 2.302976   Top1 10.011719   Top5 49.742188   BatchTime 0.268442   LR 0.001144
INFO - Training [37][  120/  196]   Loss 2.303340   Top1 9.980469   Top5 49.599609   BatchTime 0.264898   LR 0.001142
INFO - Training [37][  140/  196]   Loss 2.303321   Top1 9.930246   Top5 49.550781   BatchTime 0.262940   LR 0.001139
INFO - Training [37][  160/  196]   Loss 2.303252   Top1 9.965820   Top5 49.575195   BatchTime 0.261296   LR 0.001136
INFO - Training [37][  180/  196]   Loss 2.303253   Top1 9.941406   Top5 49.433594   BatchTime 0.260232   LR 0.001133
********************pre-trained*****************
INFO - ==> Top1: 9.954    Top5: 49.572    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [37][   20/   40]   Loss 47.170946   Top1 10.253906   Top5 50.214844   BatchTime 0.130610
INFO - Validation [37][   40/   40]   Loss 47.333457   Top1 10.000000   Top5 50.000000   BatchTime 0.091294
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.333
INFO - ==> Sparsity : 0.271
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [37][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  38
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0573)
features.16.conv.6 tensor(0.7158)
conv.0 tensor(0.8711)
tensor(592375.) 2188896.0
INFO - Training [38][   20/  196]   Loss 2.303025   Top1 9.238281   Top5 49.785156   BatchTime 0.298277   LR 0.001128
INFO - Training [38][   40/  196]   Loss 2.302843   Top1 9.941406   Top5 50.361328   BatchTime 0.275183   LR 0.001125
INFO - Training [38][   60/  196]   Loss 2.302942   Top1 9.947917   Top5 49.986979   BatchTime 0.267879   LR 0.001122
INFO - Training [38][   80/  196]   Loss 2.302954   Top1 10.083008   Top5 50.024414   BatchTime 0.265065   LR 0.001119
INFO - Training [38][  100/  196]   Loss 2.303019   Top1 10.117188   Top5 49.890625   BatchTime 0.261655   LR 0.001116
INFO - Training [38][  120/  196]   Loss 2.303132   Top1 10.013021   Top5 49.739583   BatchTime 0.255804   LR 0.001112
INFO - Training [38][  140/  196]   Loss 2.303075   Top1 9.974888   Top5 49.891183   BatchTime 0.250399   LR 0.001109
INFO - Training [38][  160/  196]   Loss 2.303060   Top1 9.958496   Top5 49.848633   BatchTime 0.250832   LR 0.001106
INFO - Training [38][  180/  196]   Loss 2.303088   Top1 9.947917   Top5 49.748264   BatchTime 0.257442   LR 0.001103
INFO - ==> Top1: 9.960    Top5: 49.792    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [38][   20/   40]   Loss 45.631766   Top1 10.253906   Top5 50.214844   BatchTime 0.136186
INFO - Validation [38][   40/   40]   Loss 45.788757   Top1 10.000000   Top5 50.000000   BatchTime 0.095808
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 45.789
INFO - ==> Sparsity : 0.271
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [38][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  39
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0576)
features.16.conv.6 tensor(0.7165)
conv.0 tensor(0.8717)
tensor(592810.) 2188896.0
INFO - Training [39][   20/  196]   Loss 2.303596   Top1 9.238281   Top5 49.980469   BatchTime 0.326698   LR 0.001097
INFO - Training [39][   40/  196]   Loss 2.303182   Top1 9.931641   Top5 50.205078   BatchTime 0.277107   LR 0.001094
INFO - Training [39][   60/  196]   Loss 2.303204   Top1 9.928385   Top5 50.006510   BatchTime 0.267405   LR 0.001090
INFO - Training [39][   80/  196]   Loss 2.303064   Top1 9.799805   Top5 50.195312   BatchTime 0.268123   LR 0.001087
INFO - Training [39][  100/  196]   Loss 2.303020   Top1 9.835938   Top5 50.246094   BatchTime 0.271731   LR 0.001084
INFO - Training [39][  120/  196]   Loss 2.303107   Top1 9.785156   Top5 49.964193   BatchTime 0.275241   LR 0.001080
INFO - Training [39][  140/  196]   Loss 2.303121   Top1 9.704241   Top5 49.860491   BatchTime 0.279708   LR 0.001077
INFO - Training [39][  160/  196]   Loss 2.303056   Top1 9.819336   Top5 49.936523   BatchTime 0.278365   LR 0.001073
INFO - Training [39][  180/  196]   Loss 2.303043   Top1 9.880642   Top5 49.921875   BatchTime 0.273806   LR 0.001070
********************pre-trained*****************
INFO - ==> Top1: 9.868    Top5: 49.774    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [39][   20/   40]   Loss 43.501040   Top1 10.253906   Top5 50.214844   BatchTime 0.136497
INFO - Validation [39][   40/   40]   Loss 43.648147   Top1 10.000000   Top5 50.000000   BatchTime 0.095555
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 43.648
INFO - ==> Sparsity : 0.271
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [39][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  40
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0566)
features.16.conv.6 tensor(0.7153)
conv.0 tensor(0.8709)
tensor(592108.) 2188896.0
INFO - Training [40][   20/  196]   Loss 2.302855   Top1 10.097656   Top5 50.507812   BatchTime 0.295544   LR 0.001064
INFO - Training [40][   40/  196]   Loss 2.303158   Top1 9.990234   Top5 50.292969   BatchTime 0.263637   LR 0.001060
INFO - Training [40][   60/  196]   Loss 2.303119   Top1 9.785156   Top5 50.123698   BatchTime 0.252718   LR 0.001056
INFO - Training [40][   80/  196]   Loss 2.303028   Top1 9.863281   Top5 50.043945   BatchTime 0.253336   LR 0.001053
INFO - Training [40][  100/  196]   Loss 2.303042   Top1 9.804688   Top5 50.050781   BatchTime 0.246852   LR 0.001049
INFO - Training [40][  120/  196]   Loss 2.303099   Top1 9.833984   Top5 49.873047   BatchTime 0.241024   LR 0.001045
INFO - Training [40][  140/  196]   Loss 2.303059   Top1 9.882812   Top5 49.866071   BatchTime 0.239217   LR 0.001042
INFO - Training [40][  160/  196]   Loss 2.303045   Top1 9.948730   Top5 49.846191   BatchTime 0.237758   LR 0.001038
INFO - Training [40][  180/  196]   Loss 2.303007   Top1 9.906684   Top5 49.796007   BatchTime 0.236572   LR 0.001034
********************pre-trained*****************
INFO - ==> Top1: 9.890    Top5: 49.928    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [40][   20/   40]   Loss 42.986398   Top1 10.253906   Top5 50.214844   BatchTime 0.129266
INFO - Validation [40][   40/   40]   Loss 43.132325   Top1 10.000000   Top5 50.000000   BatchTime 0.091837
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 43.132
INFO - ==> Sparsity : 0.271
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [40][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  41
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0562)
features.16.conv.6 tensor(0.7151)
conv.0 tensor(0.8714)
tensor(592222.) 2188896.0
INFO - Training [41][   20/  196]   Loss 2.302877   Top1 9.824219   Top5 50.859375   BatchTime 0.362402   LR 0.001027
INFO - Training [41][   40/  196]   Loss 2.303077   Top1 9.414062   Top5 50.107422   BatchTime 0.319665   LR 0.001023
INFO - Training [41][   60/  196]   Loss 2.303039   Top1 9.550781   Top5 49.895833   BatchTime 0.300841   LR 0.001020
INFO - Training [41][   80/  196]   Loss 2.302980   Top1 9.687500   Top5 50.014648   BatchTime 0.289805   LR 0.001016
INFO - Training [41][  100/  196]   Loss 2.302967   Top1 9.796875   Top5 50.085938   BatchTime 0.284349   LR 0.001012
INFO - Training [41][  120/  196]   Loss 2.303011   Top1 9.889323   Top5 49.957682   BatchTime 0.278199   LR 0.001008
INFO - Training [41][  140/  196]   Loss 2.302947   Top1 9.969308   Top5 50.136719   BatchTime 0.274278   LR 0.001004
INFO - Training [41][  160/  196]   Loss 2.302903   Top1 10.034180   Top5 50.258789   BatchTime 0.271216   LR 0.001000
INFO - Training [41][  180/  196]   Loss 2.302895   Top1 10.045573   Top5 50.164931   BatchTime 0.269034   LR 0.000996
INFO - ==> Top1: 10.066    Top5: 50.178    Loss: 2.303
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [41][   20/   40]   Loss 36.980595   Top1 10.253906   Top5 50.214844   BatchTime 0.122154
INFO - Validation [41][   40/   40]   Loss 37.104587   Top1 10.000000   Top5 50.000000   BatchTime 0.086138
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 37.105
INFO - ==> Sparsity : 0.271
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [41][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  42
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0569)
features.16.conv.6 tensor(0.7172)
conv.0 tensor(0.8718)
tensor(593083.) 2188896.0
INFO - Training [42][   20/  196]   Loss 2.302629   Top1 10.390625   Top5 50.175781   BatchTime 0.310965   LR 0.000988
INFO - Training [42][   40/  196]   Loss 2.302867   Top1 10.292969   Top5 49.912109   BatchTime 0.270394   LR 0.000984
INFO - Training [42][   60/  196]   Loss 2.302867   Top1 10.319010   Top5 50.071615   BatchTime 0.262896   LR 0.000980
INFO - Training [42][   80/  196]   Loss 2.302857   Top1 10.166016   Top5 50.043945   BatchTime 0.260256   LR 0.000976
INFO - Training [42][  100/  196]   Loss 2.302963   Top1 10.007812   Top5 49.730469   BatchTime 0.267606   LR 0.000972
INFO - Training [42][  120/  196]   Loss 2.302918   Top1 10.061849   Top5 49.905599   BatchTime 0.262951   LR 0.000968
INFO - Training [42][  140/  196]   Loss 2.302960   Top1 9.980469   Top5 49.910714   BatchTime 0.259153   LR 0.000964
INFO - Training [42][  160/  196]   Loss 2.302950   Top1 9.973145   Top5 49.899902   BatchTime 0.258238   LR 0.000959
INFO - Training [42][  180/  196]   Loss 2.303007   Top1 9.963108   Top5 49.913194   BatchTime 0.257404   LR 0.000955
INFO - ==> Top1: 9.976    Top5: 49.942    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [42][   20/   40]   Loss 37.126526   Top1 10.253906   Top5 50.214844   BatchTime 0.133099
INFO - Validation [42][   40/   40]   Loss 37.253994   Top1 10.000000   Top5 50.000000   BatchTime 0.095561
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 37.254
INFO - ==> Sparsity : 0.271
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [42][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  43
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0561)
features.16.conv.6 tensor(0.7183)
conv.0 tensor(0.8719)
tensor(593457.) 2188896.0
INFO - Training [43][   20/  196]   Loss 2.302339   Top1 10.312500   Top5 50.722656   BatchTime 0.311961   LR 0.000947
INFO - Training [43][   40/  196]   Loss 2.302456   Top1 10.107422   Top5 50.117188   BatchTime 0.276149   LR 0.000943
INFO - Training [43][   60/  196]   Loss 2.302754   Top1 9.863281   Top5 49.811198   BatchTime 0.267405   LR 0.000939
INFO - Training [43][   80/  196]   Loss 2.302952   Top1 9.819336   Top5 49.394531   BatchTime 0.260353   LR 0.000934
INFO - Training [43][  100/  196]   Loss 2.302993   Top1 9.746094   Top5 49.273438   BatchTime 0.261999   LR 0.000930
INFO - Training [43][  120/  196]   Loss 2.303007   Top1 9.817708   Top5 49.195964   BatchTime 0.257748   LR 0.000926
INFO - Training [43][  140/  196]   Loss 2.302995   Top1 9.796317   Top5 49.282924   BatchTime 0.255193   LR 0.000921
INFO - Training [43][  160/  196]   Loss 2.302985   Top1 9.841309   Top5 49.270020   BatchTime 0.252832   LR 0.000917
INFO - Training [43][  180/  196]   Loss 2.302963   Top1 9.891493   Top5 49.379340   BatchTime 0.249440   LR 0.000912
********************pre-trained*****************
INFO - ==> Top1: 9.884    Top5: 49.346    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [43][   20/   40]   Loss 36.026351   Top1 10.253906   Top5 50.214844   BatchTime 0.123397
INFO - Validation [43][   40/   40]   Loss 36.149903   Top1 10.000000   Top5 50.000000   BatchTime 0.087401
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 36.150
INFO - ==> Sparsity : 0.271
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [43][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  44
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0564)
features.16.conv.6 tensor(0.7182)
conv.0 tensor(0.8719)
tensor(593414.) 2188896.0
INFO - Training [44][   20/  196]   Loss 2.302984   Top1 9.902344   Top5 49.863281   BatchTime 0.315286   LR 0.000904
INFO - Training [44][   40/  196]   Loss 2.303178   Top1 9.912109   Top5 49.423828   BatchTime 0.282432   LR 0.000900
INFO - Training [44][   60/  196]   Loss 2.303188   Top1 9.830729   Top5 49.218750   BatchTime 0.270616   LR 0.000895
INFO - Training [44][   80/  196]   Loss 2.303215   Top1 9.833984   Top5 49.135742   BatchTime 0.265724   LR 0.000891
INFO - Training [44][  100/  196]   Loss 2.303134   Top1 9.867188   Top5 49.523438   BatchTime 0.262558   LR 0.000886
INFO - Training [44][  120/  196]   Loss 2.303034   Top1 9.905599   Top5 49.641927   BatchTime 0.261296   LR 0.000882
INFO - Training [44][  140/  196]   Loss 2.302954   Top1 9.896763   Top5 49.707031   BatchTime 0.258947   LR 0.000877
INFO - Training [44][  160/  196]   Loss 2.302912   Top1 9.909668   Top5 49.790039   BatchTime 0.259358   LR 0.000873
INFO - Training [44][  180/  196]   Loss 2.302935   Top1 9.809028   Top5 49.787326   BatchTime 0.259183   LR 0.000868
INFO - ==> Top1: 9.790    Top5: 49.824    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [44][   20/   40]   Loss 36.499133   Top1 10.253906   Top5 50.214844   BatchTime 0.125555
INFO - Validation [44][   40/   40]   Loss 36.624191   Top1 10.000000   Top5 50.000000   BatchTime 0.088366
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0558)
features.16.conv.6 tensor(0.7187)
conv.0 tensor(0.8720)
tensor(593603.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 36.624
INFO - ==> Sparsity : 0.271
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [44][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  45
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [45][   20/  196]   Loss 2.302981   Top1 10.585938   Top5 49.140625   BatchTime 0.298994   LR 0.000860
INFO - Training [45][   40/  196]   Loss 2.302804   Top1 10.253906   Top5 49.765625   BatchTime 0.258279   LR 0.000855
INFO - Training [45][   60/  196]   Loss 2.302942   Top1 10.182292   Top5 49.602865   BatchTime 0.245843   LR 0.000850
INFO - Training [45][   80/  196]   Loss 2.302869   Top1 10.244141   Top5 49.716797   BatchTime 0.239862   LR 0.000846
INFO - Training [45][  100/  196]   Loss 2.302928   Top1 10.187500   Top5 49.640625   BatchTime 0.237816   LR 0.000841
INFO - Training [45][  120/  196]   Loss 2.302895   Top1 10.152995   Top5 49.674479   BatchTime 0.238667   LR 0.000836
INFO - Training [45][  140/  196]   Loss 2.302820   Top1 10.189732   Top5 49.829799   BatchTime 0.248370   LR 0.000832
INFO - Training [45][  160/  196]   Loss 2.302857   Top1 10.202637   Top5 49.863281   BatchTime 0.255666   LR 0.000827
INFO - Training [45][  180/  196]   Loss 2.302878   Top1 10.186632   Top5 49.871962   BatchTime 0.261372   LR 0.000822
********************pre-trained*****************
INFO - ==> Top1: 10.196    Top5: 49.830    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [45][   20/   40]   Loss 29.772500   Top1 10.253906   Top5 50.214844   BatchTime 0.124379
INFO - Validation [45][   40/   40]   Loss 29.873142   Top1 10.000000   Top5 50.000000   BatchTime 0.090887
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 29.873
INFO - ==> Sparsity : 0.271
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [45][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  46
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0558)
features.16.conv.6 tensor(0.7193)
conv.0 tensor(0.8724)
tensor(593939.) 2188896.0
INFO - Training [46][   20/  196]   Loss 2.302825   Top1 9.648438   Top5 50.175781   BatchTime 0.376041   LR 0.000814
INFO - Training [46][   40/  196]   Loss 2.302910   Top1 9.853516   Top5 50.224609   BatchTime 0.341033   LR 0.000809
INFO - Training [46][   60/  196]   Loss 2.302831   Top1 9.882812   Top5 50.403646   BatchTime 0.328803   LR 0.000804
INFO - Training [46][   80/  196]   Loss 2.302817   Top1 9.863281   Top5 50.292969   BatchTime 0.323237   LR 0.000799
INFO - Training [46][  100/  196]   Loss 2.302808   Top1 9.925781   Top5 50.066406   BatchTime 0.312118   LR 0.000794
INFO - Training [46][  120/  196]   Loss 2.302816   Top1 9.938151   Top5 50.094401   BatchTime 0.297742   LR 0.000789
INFO - Training [46][  140/  196]   Loss 2.302867   Top1 9.988839   Top5 50.013951   BatchTime 0.288686   LR 0.000785
INFO - Training [46][  160/  196]   Loss 2.302887   Top1 9.934082   Top5 49.919434   BatchTime 0.282609   LR 0.000780
INFO - Training [46][  180/  196]   Loss 2.302921   Top1 9.902344   Top5 49.724392   BatchTime 0.276100   LR 0.000775
INFO - ==> Top1: 9.850    Top5: 49.536    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [46][   20/   40]   Loss 48.901380   Top1 10.253906   Top5 50.214844   BatchTime 0.129047
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0547)
features.16.conv.6 tensor(0.7198)
conv.0 tensor(0.8724)
tensor(594114.) 2188896.0
INFO - Validation [46][   40/   40]   Loss 49.069843   Top1 10.000000   Top5 50.000000   BatchTime 0.092994
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 49.070
INFO - ==> Sparsity : 0.271
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [46][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  47
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [47][   20/  196]   Loss 2.302904   Top1 9.550781   Top5 49.511719   BatchTime 0.313680   LR 0.000766
INFO - Training [47][   40/  196]   Loss 2.302770   Top1 9.833984   Top5 50.273438   BatchTime 0.281920   LR 0.000761
INFO - Training [47][   60/  196]   Loss 2.302952   Top1 9.895833   Top5 50.045573   BatchTime 0.269532   LR 0.000756
INFO - Training [47][   80/  196]   Loss 2.302926   Top1 9.946289   Top5 50.004883   BatchTime 0.259956   LR 0.000752
INFO - Training [47][  100/  196]   Loss 2.302869   Top1 10.046875   Top5 49.964844   BatchTime 0.259195   LR 0.000747
INFO - Training [47][  120/  196]   Loss 2.302848   Top1 10.065104   Top5 50.042318   BatchTime 0.261156   LR 0.000742
INFO - Training [47][  140/  196]   Loss 2.302942   Top1 9.966518   Top5 49.921875   BatchTime 0.259390   LR 0.000737
INFO - Training [47][  160/  196]   Loss 2.302858   Top1 9.980469   Top5 50.021973   BatchTime 0.258126   LR 0.000732
INFO - Training [47][  180/  196]   Loss 2.302913   Top1 9.895833   Top5 49.898003   BatchTime 0.257837   LR 0.000727
INFO - ==> Top1: 9.870    Top5: 49.868    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [47][   20/   40]   Loss 45.660366   Top1 10.253906   Top5 50.214844   BatchTime 0.124409
INFO - Validation [47][   40/   40]   Loss 45.819242   Top1 10.000000   Top5 50.000000   BatchTime 0.088753
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 45.819
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [47][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0560)
features.16.conv.6 tensor(0.7207)
conv.0 tensor(0.8725)
tensor(594406.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  48
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [48][   20/  196]   Loss 2.303063   Top1 9.492188   Top5 49.980469   BatchTime 0.311001   LR 0.000718
INFO - Training [48][   40/  196]   Loss 2.303067   Top1 9.863281   Top5 49.570312   BatchTime 0.272121   LR 0.000713
INFO - Training [48][   60/  196]   Loss 2.302875   Top1 9.993490   Top5 49.980469   BatchTime 0.266711   LR 0.000708
INFO - Training [48][   80/  196]   Loss 2.302853   Top1 10.078125   Top5 49.902344   BatchTime 0.262709   LR 0.000703
INFO - Training [48][  100/  196]   Loss 2.302880   Top1 10.105469   Top5 49.757812   BatchTime 0.260498   LR 0.000698
INFO - Training [48][  120/  196]   Loss 2.302888   Top1 10.130208   Top5 49.788411   BatchTime 0.259687   LR 0.000693
INFO - Training [48][  140/  196]   Loss 2.302982   Top1 9.910714   Top5 49.695871   BatchTime 0.256309   LR 0.000688
INFO - Training [48][  160/  196]   Loss 2.302984   Top1 9.943848   Top5 49.729004   BatchTime 0.253511   LR 0.000683
INFO - Training [48][  180/  196]   Loss 2.302959   Top1 9.928385   Top5 49.785156   BatchTime 0.252348   LR 0.000678
INFO - ==> Top1: 9.952    Top5: 49.848    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [48][   20/   40]   Loss 44.203104   Top1 10.253906   Top5 50.214844   BatchTime 0.127507
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3
INFO - Validation [48][   40/   40]   Loss 44.356135   Top1 10.000000   Top5 50.000000   BatchTime 0.090864
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 44.356
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [48][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  49
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0566)
features.16.conv.6 tensor(0.7212)
conv.0 tensor(0.8728)
tensor(594698.) 2188896.0
INFO - Training [49][   20/  196]   Loss 2.303170   Top1 9.628906   Top5 48.437500   BatchTime 0.309663   LR 0.000669
INFO - Training [49][   40/  196]   Loss 2.303081   Top1 10.058594   Top5 49.130859   BatchTime 0.267547   LR 0.000664
INFO - Training [49][   60/  196]   Loss 2.303066   Top1 10.019531   Top5 49.277344   BatchTime 0.260409   LR 0.000659
INFO - Training [49][   80/  196]   Loss 2.302955   Top1 9.902344   Top5 49.594727   BatchTime 0.257845   LR 0.000654
INFO - Training [49][  100/  196]   Loss 2.302968   Top1 9.937500   Top5 49.718750   BatchTime 0.256437   LR 0.000649
INFO - Training [49][  120/  196]   Loss 2.302957   Top1 9.866536   Top5 49.843750   BatchTime 0.253284   LR 0.000644
INFO - Training [49][  140/  196]   Loss 2.302907   Top1 9.815848   Top5 49.846540   BatchTime 0.253170   LR 0.000639
INFO - Training [49][  160/  196]   Loss 2.302886   Top1 9.836426   Top5 49.848633   BatchTime 0.256057   LR 0.000634
INFO - Training [49][  180/  196]   Loss 2.302867   Top1 9.878472   Top5 49.815538   BatchTime 0.261855   LR 0.000629
INFO - ==> Top1: 9.902    Top5: 49.748    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [49][   20/   40]   Loss 42.515286   Top1 10.253906   Top5 50.214844   BatchTime 0.123705
INFO - Validation [49][   40/   40]   Loss 42.662280   Top1 10.000000   Top5 50.000000   BatchTime 0.086545
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 42.662
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [49][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  50
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0567)
features.16.conv.6 tensor(0.7214)
conv.0 tensor(0.8728)
tensor(594773.) 2188896.0
INFO - Training [50][   20/  196]   Loss 2.302890   Top1 9.863281   Top5 49.941406   BatchTime 0.289862   LR 0.000620
INFO - Training [50][   40/  196]   Loss 2.303021   Top1 9.873047   Top5 49.550781   BatchTime 0.257426   LR 0.000615
INFO - Training [50][   60/  196]   Loss 2.302974   Top1 9.837240   Top5 49.830729   BatchTime 0.242357   LR 0.000610
INFO - Training [50][   80/  196]   Loss 2.302924   Top1 9.931641   Top5 49.765625   BatchTime 0.237505   LR 0.000605
INFO - Training [50][  100/  196]   Loss 2.302974   Top1 9.875000   Top5 49.761719   BatchTime 0.237433   LR 0.000600
INFO - Training [50][  120/  196]   Loss 2.303028   Top1 9.768880   Top5 49.677734   BatchTime 0.235850   LR 0.000595
INFO - Training [50][  140/  196]   Loss 2.302996   Top1 9.824219   Top5 49.709821   BatchTime 0.237247   LR 0.000590
INFO - Training [50][  160/  196]   Loss 2.303011   Top1 9.711914   Top5 49.560547   BatchTime 0.241445   LR 0.000585
INFO - Training [50][  180/  196]   Loss 2.303000   Top1 9.704861   Top5 49.613715   BatchTime 0.243895   LR 0.000580
INFO - ==> Top1: 9.712    Top5: 49.554    Loss: 2.303
********************pre-trained*****************
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [50][   20/   40]   Loss 41.038318   Top1 10.253906   Top5 50.214844   BatchTime 0.130631
INFO - Validation [50][   40/   40]   Loss 41.182097   Top1 10.000000   Top5 50.000000   BatchTime 0.092343
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 41.182
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [50][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  51
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0558)
features.16.conv.6 tensor(0.7223)
conv.0 tensor(0.8740)
tensor(595530.) 2188896.0
INFO - Training [51][   20/  196]   Loss 2.302922   Top1 9.726562   Top5 49.062500   BatchTime 0.336660   LR 0.000571
INFO - Training [51][   40/  196]   Loss 2.302939   Top1 9.912109   Top5 49.433594   BatchTime 0.290897   LR 0.000566
INFO - Training [51][   60/  196]   Loss 2.302844   Top1 9.941406   Top5 49.713542   BatchTime 0.277609   LR 0.000561
INFO - Training [51][   80/  196]   Loss 2.302863   Top1 9.931641   Top5 49.672852   BatchTime 0.267085   LR 0.000556
INFO - Training [51][  100/  196]   Loss 2.302869   Top1 9.859375   Top5 49.656250   BatchTime 0.263148   LR 0.000551
INFO - Training [51][  120/  196]   Loss 2.302897   Top1 9.833984   Top5 49.573568   BatchTime 0.261100   LR 0.000546
INFO - Training [51][  140/  196]   Loss 2.302917   Top1 9.860491   Top5 49.564732   BatchTime 0.260227   LR 0.000541
INFO - Training [51][  160/  196]   Loss 2.302912   Top1 9.851074   Top5 49.655762   BatchTime 0.265544   LR 0.000536
INFO - Training [51][  180/  196]   Loss 2.302894   Top1 9.865451   Top5 49.628906   BatchTime 0.263905   LR 0.000531
INFO - ==> Top1: 9.868    Top5: 49.714    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [51][   20/   40]   Loss 46.212422   Top1 10.253906   Top5 50.214844   BatchTime 0.127681
INFO - Validation [51][   40/   40]   Loss 46.372534   Top1 10.000000   Top5 50.000000   BatchTime 0.090606
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 46.373
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [51][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  52
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0562)
features.16.conv.6 tensor(0.7226)
conv.0 tensor(0.8736)
tensor(595446.) 2188896.0
INFO - Training [52][   20/  196]   Loss 2.302667   Top1 10.039062   Top5 49.160156   BatchTime 0.297827   LR 0.000523
INFO - Training [52][   40/  196]   Loss 2.302663   Top1 10.058594   Top5 49.619141   BatchTime 0.263238   LR 0.000518
INFO - Training [52][   60/  196]   Loss 2.302714   Top1 10.078125   Top5 49.335938   BatchTime 0.251877   LR 0.000513
INFO - Training [52][   80/  196]   Loss 2.302748   Top1 10.136719   Top5 49.580078   BatchTime 0.251121   LR 0.000508
INFO - Training [52][  100/  196]   Loss 2.302757   Top1 10.121094   Top5 49.632812   BatchTime 0.250665   LR 0.000503
INFO - Training [52][  120/  196]   Loss 2.302781   Top1 10.029297   Top5 49.622396   BatchTime 0.250508   LR 0.000498
INFO - Training [52][  140/  196]   Loss 2.302740   Top1 10.131138   Top5 49.726562   BatchTime 0.252817   LR 0.000493
INFO - Training [52][  160/  196]   Loss 2.302758   Top1 10.144043   Top5 49.785156   BatchTime 0.252766   LR 0.000488
INFO - Training [52][  180/  196]   Loss 2.302750   Top1 10.117188   Top5 49.765625   BatchTime 0.249077   LR 0.000483
INFO - ==> Top1: 10.048    Top5: 49.650    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [52][   20/   40]   Loss 47.399948   Top1 10.253906   Top5 50.214844   BatchTime 0.132096
INFO - Validation [52][   40/   40]   Loss 47.564392   Top1 10.000000   Top5 50.000000   BatchTime 0.092970
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.564
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [52][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  53
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0571)
features.16.conv.6 tensor(0.7226)
conv.0 tensor(0.8738)
tensor(595571.) 2188896.0
INFO - Training [53][   20/  196]   Loss 2.302714   Top1 10.371094   Top5 49.667969   BatchTime 0.308060   LR 0.000474
INFO - Training [53][   40/  196]   Loss 2.302742   Top1 10.224609   Top5 50.175781   BatchTime 0.266444   LR 0.000470
INFO - Training [53][   60/  196]   Loss 2.302688   Top1 10.130208   Top5 50.468750   BatchTime 0.259008   LR 0.000465
INFO - Training [53][   80/  196]   Loss 2.302722   Top1 10.073242   Top5 50.083008   BatchTime 0.255177   LR 0.000460
INFO - Training [53][  100/  196]   Loss 2.302896   Top1 9.949219   Top5 49.636719   BatchTime 0.252728   LR 0.000455
INFO - Training [53][  120/  196]   Loss 2.302884   Top1 9.899089   Top5 49.713542   BatchTime 0.251776   LR 0.000450
INFO - Training [53][  140/  196]   Loss 2.302951   Top1 9.801897   Top5 49.573103   BatchTime 0.251616   LR 0.000445
INFO - Training [53][  160/  196]   Loss 2.302944   Top1 9.807129   Top5 49.704590   BatchTime 0.250126   LR 0.000441
INFO - Training [53][  180/  196]   Loss 2.302928   Top1 9.819878   Top5 49.756944   BatchTime 0.250853   LR 0.000436
INFO - ==> Top1: 9.806    Top5: 49.722    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [53][   20/   40]   Loss 44.664213   Top1 10.253906   Top5 50.214844   BatchTime 0.123414
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0549)
features.16.conv.6 tensor(0.7231)
conv.0 tensor(0.8737)
tensor(595641.) 2188896.0
INFO - Validation [53][   40/   40]   Loss 44.820480   Top1 10.000000   Top5 50.000000   BatchTime 0.088491
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 44.820
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [53][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  54
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [54][   20/  196]   Loss 2.302581   Top1 10.156250   Top5 50.722656   BatchTime 0.299199   LR 0.000427
INFO - Training [54][   40/  196]   Loss 2.302521   Top1 9.824219   Top5 50.449219   BatchTime 0.268863   LR 0.000423
INFO - Training [54][   60/  196]   Loss 2.302589   Top1 9.785156   Top5 50.553385   BatchTime 0.259234   LR 0.000418
INFO - Training [54][   80/  196]   Loss 2.302659   Top1 9.750977   Top5 50.405273   BatchTime 0.252431   LR 0.000413
INFO - Training [54][  100/  196]   Loss 2.302731   Top1 9.691406   Top5 50.175781   BatchTime 0.250692   LR 0.000408
INFO - Training [54][  120/  196]   Loss 2.302762   Top1 9.674479   Top5 49.934896   BatchTime 0.248607   LR 0.000404
INFO - Training [54][  140/  196]   Loss 2.302777   Top1 9.673549   Top5 49.824219   BatchTime 0.245746   LR 0.000399
INFO - Training [54][  160/  196]   Loss 2.302814   Top1 9.670410   Top5 49.807129   BatchTime 0.242972   LR 0.000394
INFO - Training [54][  180/  196]   Loss 2.302788   Top1 9.832899   Top5 49.796007   BatchTime 0.241522   LR 0.000390
********************pre-trained*****************
INFO - ==> Top1: 9.858    Top5: 49.720    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [54][   20/   40]   Loss 44.495374   Top1 10.253906   Top5 50.214844   BatchTime 0.131567
INFO - Validation [54][   40/   40]   Loss 44.652284   Top1 10.000000   Top5 50.000000   BatchTime 0.093965
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 44.652
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [54][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  55
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0551)
features.16.conv.6 tensor(0.7236)
conv.0 tensor(0.8736)
tensor(595753.) 2188896.0
INFO - Training [55][   20/  196]   Loss 2.302702   Top1 10.312500   Top5 49.980469   BatchTime 0.295841   LR 0.000381
INFO - Training [55][   40/  196]   Loss 2.302606   Top1 10.048828   Top5 50.361328   BatchTime 0.263214   LR 0.000377
INFO - Training [55][   60/  196]   Loss 2.302764   Top1 9.934896   Top5 49.837240   BatchTime 0.255476   LR 0.000372
INFO - Training [55][   80/  196]   Loss 2.302775   Top1 9.960938   Top5 49.682617   BatchTime 0.253785   LR 0.000368
INFO - Training [55][  100/  196]   Loss 2.302812   Top1 9.921875   Top5 49.496094   BatchTime 0.250126   LR 0.000363
INFO - Training [55][  120/  196]   Loss 2.302839   Top1 9.889323   Top5 49.661458   BatchTime 0.246425   LR 0.000358
INFO - Training [55][  140/  196]   Loss 2.302839   Top1 9.919085   Top5 49.690290   BatchTime 0.244026   LR 0.000354
INFO - Training [55][  160/  196]   Loss 2.302907   Top1 9.863281   Top5 49.504395   BatchTime 0.244595   LR 0.000349
INFO - Training [55][  180/  196]   Loss 2.302950   Top1 9.756944   Top5 49.440104   BatchTime 0.245216   LR 0.000345
INFO - ==> Top1: 9.820    Top5: 49.470    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [55][   20/   40]   Loss 35.337687   Top1 10.253906   Top5 50.214844   BatchTime 0.130397
INFO - Validation [55][   40/   40]   Loss 35.458949   Top1 10.000000   Top5 50.000000   BatchTime 0.094244
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 35.459
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [55][Top1: 10.000   Top5: 50.000]
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0564)
features.16.conv.6 tensor(0.7237)
conv.0 tensor(0.8735)
tensor(595748.) 2188896.0
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  56
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [56][   20/  196]   Loss 2.302870   Top1 10.273438   Top5 49.394531   BatchTime 0.334462   LR 0.000337
INFO - Training [56][   40/  196]   Loss 2.302792   Top1 10.185547   Top5 49.570312   BatchTime 0.280773   LR 0.000333
INFO - Training [56][   60/  196]   Loss 2.302798   Top1 10.032552   Top5 49.733073   BatchTime 0.263841   LR 0.000328
INFO - Training [56][   80/  196]   Loss 2.302843   Top1 9.887695   Top5 49.790039   BatchTime 0.256976   LR 0.000324
INFO - Training [56][  100/  196]   Loss 2.302858   Top1 9.953125   Top5 49.765625   BatchTime 0.255393   LR 0.000319
INFO - Training [56][  120/  196]   Loss 2.302886   Top1 10.042318   Top5 49.648438   BatchTime 0.254463   LR 0.000315
INFO - Training [56][  140/  196]   Loss 2.302873   Top1 10.106027   Top5 49.561942   BatchTime 0.251418   LR 0.000311
INFO - Training [56][  160/  196]   Loss 2.302888   Top1 10.039062   Top5 49.626465   BatchTime 0.248666   LR 0.000306
INFO - Training [56][  180/  196]   Loss 2.302882   Top1 9.991319   Top5 49.620226   BatchTime 0.246329   LR 0.000302
********************pre-trained*****************
INFO - ==> Top1: 10.000    Top5: 49.682    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [56][   20/   40]   Loss 38.531119   Top1 10.253906   Top5 50.214844   BatchTime 0.140653
INFO - Validation [56][   40/   40]   Loss 38.663107   Top1 10.000000   Top5 50.000000   BatchTime 0.096795
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0559)
features.16.conv.6 tensor(0.7238)
conv.0 tensor(0.8737)
tensor(595856.) 2188896.0
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 38.663
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [56][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  57
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [57][   20/  196]   Loss 2.302885   Top1 9.863281   Top5 49.570312   BatchTime 0.331350   LR 0.000294
INFO - Training [57][   40/  196]   Loss 2.302752   Top1 9.765625   Top5 49.628906   BatchTime 0.291020   LR 0.000290
INFO - Training [57][   60/  196]   Loss 2.302840   Top1 9.576823   Top5 49.479167   BatchTime 0.279548   LR 0.000286
INFO - Training [57][   80/  196]   Loss 2.302690   Top1 9.858398   Top5 49.921875   BatchTime 0.272163   LR 0.000282
INFO - Training [57][  100/  196]   Loss 2.302686   Top1 9.937500   Top5 49.812500   BatchTime 0.267523   LR 0.000277
INFO - Training [57][  120/  196]   Loss 2.302646   Top1 9.983724   Top5 50.117188   BatchTime 0.264073   LR 0.000273
INFO - Training [57][  140/  196]   Loss 2.302669   Top1 9.986049   Top5 50.142299   BatchTime 0.262447   LR 0.000269
INFO - Training [57][  160/  196]   Loss 2.302688   Top1 9.968262   Top5 50.109863   BatchTime 0.262651   LR 0.000265
INFO - Training [57][  180/  196]   Loss 2.302705   Top1 9.932726   Top5 50.043403   BatchTime 0.261272   LR 0.000261
INFO - ==> Top1: 9.930    Top5: 50.092    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [57][   20/   40]   Loss 38.249504   Top1 10.253906   Top5 50.214844   BatchTime 0.128078
INFO - Validation [57][   40/   40]   Loss 38.381375   Top1 10.000000   Top5 50.000000   BatchTime 0.097463
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 38.381
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [57][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  58
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0550)
features.16.conv.6 tensor(0.7243)
conv.0 tensor(0.8735)
tensor(595953.) 2188896.0
INFO - Training [58][   20/  196]   Loss 2.302621   Top1 9.902344   Top5 49.824219   BatchTime 0.295866   LR 0.000254
INFO - Training [58][   40/  196]   Loss 2.302874   Top1 10.175781   Top5 49.667969   BatchTime 0.263267   LR 0.000250
INFO - Training [58][   60/  196]   Loss 2.302746   Top1 10.123698   Top5 49.817708   BatchTime 0.257980   LR 0.000246
INFO - Training [58][   80/  196]   Loss 2.302776   Top1 10.004883   Top5 49.794922   BatchTime 0.262818   LR 0.000242
INFO - Training [58][  100/  196]   Loss 2.302744   Top1 10.218750   Top5 49.730469   BatchTime 0.258961   LR 0.000238
INFO - Training [58][  120/  196]   Loss 2.302749   Top1 10.081380   Top5 49.671224   BatchTime 0.256176   LR 0.000234
INFO - Training [58][  140/  196]   Loss 2.302741   Top1 10.106027   Top5 49.684710   BatchTime 0.254257   LR 0.000230
INFO - Training [58][  160/  196]   Loss 2.302770   Top1 10.112305   Top5 49.685059   BatchTime 0.253495   LR 0.000226
INFO - Training [58][  180/  196]   Loss 2.302787   Top1 10.045573   Top5 49.680990   BatchTime 0.253341   LR 0.000222
INFO - ==> Top1: 9.970    Top5: 49.652    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [58][   20/   40]   Loss 36.612827   Top1 10.253906   Top5 50.214844   BatchTime 0.133885
INFO - Validation [58][   40/   40]   Loss 36.738423   Top1 10.000000   Top5 50.000000   BatchTime 0.091256
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 36.738
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [58][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  59
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0551)
features.16.conv.6 tensor(0.7245)
conv.0 tensor(0.8738)
tensor(596085.) 2188896.0
INFO - Training [59][   20/  196]   Loss 2.303158   Top1 9.375000   Top5 49.765625   BatchTime 0.318302   LR 0.000215
INFO - Training [59][   40/  196]   Loss 2.303101   Top1 9.580078   Top5 49.765625   BatchTime 0.268099   LR 0.000212
INFO - Training [59][   60/  196]   Loss 2.302915   Top1 9.667969   Top5 50.227865   BatchTime 0.255746   LR 0.000208
INFO - Training [59][   80/  196]   Loss 2.302875   Top1 9.692383   Top5 50.195312   BatchTime 0.245422   LR 0.000204
INFO - Training [59][  100/  196]   Loss 2.302802   Top1 9.718750   Top5 50.335938   BatchTime 0.239319   LR 0.000201
INFO - Training [59][  120/  196]   Loss 2.302845   Top1 9.749349   Top5 50.074870   BatchTime 0.236692   LR 0.000197
INFO - Training [59][  140/  196]   Loss 2.302839   Top1 9.704241   Top5 49.972098   BatchTime 0.234445   LR 0.000193
INFO - Training [59][  160/  196]   Loss 2.302823   Top1 9.780273   Top5 49.982910   BatchTime 0.231576   LR 0.000190
INFO - Training [59][  180/  196]   Loss 2.302811   Top1 9.796007   Top5 49.965278   BatchTime 0.228897   LR 0.000186
INFO - ==> Top1: 9.808    Top5: 49.852    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [59][   20/   40]   Loss 40.837832   Top1 10.253906   Top5 50.214844   BatchTime 0.127016
INFO - Validation [59][   40/   40]   Loss 40.979012   Top1 10.000000   Top5 50.000000   BatchTime 0.090837
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 40.979
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [59][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  60
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0551)
features.16.conv.6 tensor(0.7246)
conv.0 tensor(0.8737)
tensor(596113.) 2188896.0
INFO - Training [60][   20/  196]   Loss 2.302997   Top1 10.332031   Top5 48.769531   BatchTime 0.346766   LR 0.000180
INFO - Training [60][   40/  196]   Loss 2.302954   Top1 9.990234   Top5 49.433594   BatchTime 0.308070   LR 0.000176
INFO - Training [60][   60/  196]   Loss 2.302804   Top1 10.058594   Top5 49.661458   BatchTime 0.288013   LR 0.000173
INFO - Training [60][   80/  196]   Loss 2.302851   Top1 9.907227   Top5 49.453125   BatchTime 0.274742   LR 0.000169
INFO - Training [60][  100/  196]   Loss 2.302823   Top1 9.921875   Top5 49.554688   BatchTime 0.264779   LR 0.000166
INFO - Training [60][  120/  196]   Loss 2.302869   Top1 9.840495   Top5 49.534505   BatchTime 0.257836   LR 0.000162
INFO - Training [60][  140/  196]   Loss 2.302830   Top1 9.852121   Top5 49.720982   BatchTime 0.253454   LR 0.000159
INFO - Training [60][  160/  196]   Loss 2.302779   Top1 9.848633   Top5 49.721680   BatchTime 0.250012   LR 0.000156
INFO - Training [60][  180/  196]   Loss 2.302787   Top1 9.887153   Top5 49.720052   BatchTime 0.246798   LR 0.000152
INFO - ==> Top1: 9.902    Top5: 49.660    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [60][   20/   40]   Loss 44.705653   Top1 10.253906   Top5 50.214844   BatchTime 0.128576
INFO - Validation [60][   40/   40]   Loss 44.859769   Top1 10.000000   Top5 50.000000   BatchTime 0.091739
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 44.860
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [60][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  61
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0544)
features.16.conv.6 tensor(0.7244)
conv.0 tensor(0.8740)
tensor(596145.) 2188896.0
INFO - Training [61][   20/  196]   Loss 2.302898   Top1 10.000000   Top5 49.511719   BatchTime 0.384845   LR 0.000147
INFO - Training [61][   40/  196]   Loss 2.302929   Top1 9.375000   Top5 49.257812   BatchTime 0.326685   LR 0.000143
INFO - Training [61][   60/  196]   Loss 2.302867   Top1 9.667969   Top5 49.687500   BatchTime 0.288979   LR 0.000140
INFO - Training [61][   80/  196]   Loss 2.302835   Top1 9.873047   Top5 49.750977   BatchTime 0.270351   LR 0.000137
INFO - Training [61][  100/  196]   Loss 2.302854   Top1 9.886719   Top5 49.738281   BatchTime 0.258701   LR 0.000134
INFO - Training [61][  120/  196]   Loss 2.302825   Top1 9.931641   Top5 49.749349   BatchTime 0.250374   LR 0.000131
INFO - Training [61][  140/  196]   Loss 2.302838   Top1 9.913504   Top5 49.707031   BatchTime 0.244177   LR 0.000128
INFO - Training [61][  160/  196]   Loss 2.302866   Top1 9.914551   Top5 49.799805   BatchTime 0.241704   LR 0.000125
INFO - Training [61][  180/  196]   Loss 2.302904   Top1 9.858941   Top5 49.735243   BatchTime 0.238457   LR 0.000122
INFO - ==> Top1: 9.884    Top5: 49.768    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [61][   20/   40]   Loss 47.742422   Top1 10.253906   Top5 50.214844   BatchTime 0.126579
INFO - Validation [61][   40/   40]   Loss 47.906875   Top1 10.000000   Top5 50.000000   BatchTime 0.090644
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.907
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [61][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  62
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0539)
features.16.conv.6 tensor(0.7246)
conv.0 tensor(0.8739)
tensor(596174.) 2188896.0
INFO - Training [62][   20/  196]   Loss 2.302888   Top1 10.566406   Top5 49.257812   BatchTime 0.334831   LR 0.000117
INFO - Training [62][   40/  196]   Loss 2.302844   Top1 10.185547   Top5 49.335938   BatchTime 0.285065   LR 0.000114
INFO - Training [62][   60/  196]   Loss 2.302853   Top1 10.006510   Top5 49.511719   BatchTime 0.268781   LR 0.000111
INFO - Training [62][   80/  196]   Loss 2.302803   Top1 10.039062   Top5 49.877930   BatchTime 0.271133   LR 0.000108
INFO - Training [62][  100/  196]   Loss 2.302759   Top1 10.062500   Top5 49.941406   BatchTime 0.264032   LR 0.000105
INFO - Training [62][  120/  196]   Loss 2.302715   Top1 10.065104   Top5 49.957682   BatchTime 0.260061   LR 0.000102
INFO - Training [62][  140/  196]   Loss 2.302702   Top1 10.119978   Top5 49.946987   BatchTime 0.258536   LR 0.000100
INFO - Training [62][  160/  196]   Loss 2.302706   Top1 10.063477   Top5 49.895020   BatchTime 0.257292   LR 0.000097
INFO - Training [62][  180/  196]   Loss 2.302711   Top1 9.963108   Top5 49.822049   BatchTime 0.256486   LR 0.000094
INFO - ==> Top1: 9.920    Top5: 49.828    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [62][   20/   40]   Loss 48.772469   Top1 10.253906   Top5 50.214844   BatchTime 0.127589
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0545)
features.16.conv.6 tensor(0.7245)
conv.0 tensor(0.8735)
tensor(595992.) 2188896.0
INFO - Validation [62][   40/   40]   Loss 48.942976   Top1 10.000000   Top5 50.000000   BatchTime 0.089912
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 48.943
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [62][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  63
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [63][   20/  196]   Loss 2.302628   Top1 9.648438   Top5 49.882812   BatchTime 0.323690   LR 0.000090
INFO - Training [63][   40/  196]   Loss 2.302645   Top1 10.009766   Top5 49.726562   BatchTime 0.287544   LR 0.000087
INFO - Training [63][   60/  196]   Loss 2.302632   Top1 9.895833   Top5 50.006510   BatchTime 0.273841   LR 0.000085
INFO - Training [63][   80/  196]   Loss 2.302631   Top1 10.009766   Top5 50.073242   BatchTime 0.272139   LR 0.000082
INFO - Training [63][  100/  196]   Loss 2.302687   Top1 9.925781   Top5 49.941406   BatchTime 0.262953   LR 0.000080
INFO - Training [63][  120/  196]   Loss 2.302708   Top1 9.863281   Top5 49.820964   BatchTime 0.256502   LR 0.000077
INFO - Training [63][  140/  196]   Loss 2.302747   Top1 9.829799   Top5 49.726562   BatchTime 0.254799   LR 0.000075
INFO - Training [63][  160/  196]   Loss 2.302727   Top1 9.853516   Top5 49.765625   BatchTime 0.251508   LR 0.000072
INFO - Training [63][  180/  196]   Loss 2.302700   Top1 9.932726   Top5 49.793837   BatchTime 0.249568   LR 0.000070
INFO - ==> Top1: 9.926    Top5: 49.808    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [63][   20/   40]   Loss 47.247188   Top1 10.253906   Top5 50.214844   BatchTime 0.125017
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0549)
features.16.conv.6 tensor(0.7247)
conv.0 tensor(0.8736)
tensor(596111.) 2188896.0
INFO - Validation [63][   40/   40]   Loss 47.411246   Top1 10.000000   Top5 50.000000   BatchTime 0.088856
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.411
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [63][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  64
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [64][   20/  196]   Loss 2.302757   Top1 10.449219   Top5 50.039062   BatchTime 0.313318   LR 0.000066
INFO - Training [64][   40/  196]   Loss 2.302832   Top1 10.146484   Top5 49.960938   BatchTime 0.280414   LR 0.000064
INFO - Training [64][   60/  196]   Loss 2.302693   Top1 9.908854   Top5 50.208333   BatchTime 0.271518   LR 0.000062
INFO - Training [64][   80/  196]   Loss 2.302550   Top1 10.185547   Top5 50.410156   BatchTime 0.262421   LR 0.000059
INFO - Training [64][  100/  196]   Loss 2.302541   Top1 10.187500   Top5 50.484375   BatchTime 0.265129   LR 0.000057
INFO - Training [64][  120/  196]   Loss 2.302609   Top1 10.045573   Top5 50.312500   BatchTime 0.261043   LR 0.000055
INFO - Training [64][  140/  196]   Loss 2.302611   Top1 10.086496   Top5 50.295759   BatchTime 0.259401   LR 0.000053
INFO - Training [64][  160/  196]   Loss 2.302617   Top1 10.183105   Top5 50.300293   BatchTime 0.256247   LR 0.000051
INFO - Training [64][  180/  196]   Loss 2.302637   Top1 10.147569   Top5 50.275608   BatchTime 0.255099   LR 0.000049
INFO - ==> Top1: 10.208    Top5: 50.330    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
********************pre-trained*****************
validation quantized model on cpu
INFO - Validation [64][   20/   40]   Loss 47.445906   Top1 10.253906   Top5 50.214844   BatchTime 0.128649
INFO - Validation [64][   40/   40]   Loss 47.610502   Top1 10.000000   Top5 50.000000   BatchTime 0.091107
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.611
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [64][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  65
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0546)
features.16.conv.6 tensor(0.7246)
conv.0 tensor(0.8737)
tensor(596106.) 2188896.0
INFO - Training [65][   20/  196]   Loss 2.303259   Top1 9.707031   Top5 48.457031   BatchTime 0.318483   LR 0.000046
INFO - Training [65][   40/  196]   Loss 2.303031   Top1 9.726562   Top5 49.472656   BatchTime 0.287366   LR 0.000044
INFO - Training [65][   60/  196]   Loss 2.302941   Top1 9.837240   Top5 49.570312   BatchTime 0.287898   LR 0.000042
INFO - Training [65][   80/  196]   Loss 2.302808   Top1 9.877930   Top5 49.765625   BatchTime 0.291834   LR 0.000040
INFO - Training [65][  100/  196]   Loss 2.302880   Top1 9.738281   Top5 49.675781   BatchTime 0.291954   LR 0.000039
INFO - Training [65][  120/  196]   Loss 2.302865   Top1 9.807943   Top5 49.752604   BatchTime 0.279776   LR 0.000037
INFO - Training [65][  140/  196]   Loss 2.302861   Top1 9.874442   Top5 49.592634   BatchTime 0.279518   LR 0.000035
INFO - Training [65][  160/  196]   Loss 2.302865   Top1 9.841309   Top5 49.672852   BatchTime 0.276528   LR 0.000033
INFO - Training [65][  180/  196]   Loss 2.302828   Top1 9.928385   Top5 49.832899   BatchTime 0.268748   LR 0.000032
INFO - ==> Top1: 9.950    Top5: 49.858    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
********************pre-trained*****************
INFO - Validation: 10000 samples (256 per mini-batch)
validation quantized model on cpu
INFO - Validation [65][   20/   40]   Loss 46.992323   Top1 10.253906   Top5 50.214844   BatchTime 0.130641
INFO - Validation [65][   40/   40]   Loss 47.155453   Top1 10.000000   Top5 50.000000   BatchTime 0.093098
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.155
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [65][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  66
INFO - Training: 50000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0551)
features.16.conv.6 tensor(0.7246)
conv.0 tensor(0.8737)
tensor(596081.) 2188896.0
INFO - Training [66][   20/  196]   Loss 2.302428   Top1 10.097656   Top5 50.664062   BatchTime 0.308215   LR 0.000029
INFO - Training [66][   40/  196]   Loss 2.302594   Top1 9.960938   Top5 50.253906   BatchTime 0.270545   LR 0.000028
INFO - Training [66][   60/  196]   Loss 2.302587   Top1 10.084635   Top5 50.058594   BatchTime 0.261197   LR 0.000026
INFO - Training [66][   80/  196]   Loss 2.302664   Top1 10.048828   Top5 50.078125   BatchTime 0.258404   LR 0.000025
INFO - Training [66][  100/  196]   Loss 2.302657   Top1 10.062500   Top5 49.941406   BatchTime 0.262001   LR 0.000023
INFO - Training [66][  120/  196]   Loss 2.302696   Top1 10.084635   Top5 49.886068   BatchTime 0.258312   LR 0.000022
INFO - Training [66][  140/  196]   Loss 2.302662   Top1 10.097656   Top5 49.969308   BatchTime 0.258705   LR 0.000021
INFO - Training [66][  160/  196]   Loss 2.302704   Top1 10.046387   Top5 49.885254   BatchTime 0.256967   LR 0.000019
INFO - Training [66][  180/  196]   Loss 2.302686   Top1 10.019531   Top5 49.906684   BatchTime 0.256656   LR 0.000018
********************pre-trained*****************
INFO - ==> Top1: 10.050    Top5: 50.032    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [66][   20/   40]   Loss 47.421818   Top1 10.253906   Top5 50.214844   BatchTime 0.127725
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0545)
features.16.conv.6 tensor(0.7246)
conv.0 tensor(0.8738)
tensor(596113.) 2188896.0
INFO - Validation [66][   40/   40]   Loss 47.586262   Top1 10.000000   Top5 50.000000   BatchTime 0.090900
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.586
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [66][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  67
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [67][   20/  196]   Loss 2.302887   Top1 10.312500   Top5 50.078125   BatchTime 0.342601   LR 0.000016
INFO - Training [67][   40/  196]   Loss 2.302731   Top1 10.263672   Top5 49.736328   BatchTime 0.315975   LR 0.000015
INFO - Training [67][   60/  196]   Loss 2.302775   Top1 10.045573   Top5 49.680990   BatchTime 0.287680   LR 0.000014
INFO - Training [67][   80/  196]   Loss 2.302726   Top1 10.078125   Top5 49.663086   BatchTime 0.275397   LR 0.000013
INFO - Training [67][  100/  196]   Loss 2.302682   Top1 10.074219   Top5 49.867188   BatchTime 0.267153   LR 0.000012
INFO - Training [67][  120/  196]   Loss 2.302689   Top1 10.039062   Top5 49.843750   BatchTime 0.260252   LR 0.000011
INFO - Training [67][  140/  196]   Loss 2.302693   Top1 10.053013   Top5 49.933036   BatchTime 0.254734   LR 0.000010
INFO - Training [67][  160/  196]   Loss 2.302709   Top1 10.058594   Top5 49.943848   BatchTime 0.253858   LR 0.000009
INFO - Training [67][  180/  196]   Loss 2.302761   Top1 10.101997   Top5 49.767795   BatchTime 0.254003   LR 0.000008
********************pre-trained*****************
INFO - ==> Top1: 10.070    Top5: 49.734    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
validation quantized model on cpu
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [67][   20/   40]   Loss 47.013233   Top1 10.253906   Top5 50.214844   BatchTime 0.132537
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0552)
features.16.conv.6 tensor(0.7245)
conv.0 tensor(0.8738)
tensor(596118.) 2188896.0
INFO - Validation [67][   40/   40]   Loss 47.176510   Top1 10.000000   Top5 50.000000   BatchTime 0.090053
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.177
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [67][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  68
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [68][   20/  196]   Loss 2.302673   Top1 10.390625   Top5 49.785156   BatchTime 0.327902   LR 0.000007
INFO - Training [68][   40/  196]   Loss 2.302522   Top1 10.322266   Top5 50.107422   BatchTime 0.288120   LR 0.000006
INFO - Training [68][   60/  196]   Loss 2.302516   Top1 10.299479   Top5 50.058594   BatchTime 0.276058   LR 0.000006
INFO - Training [68][   80/  196]   Loss 2.302516   Top1 10.161133   Top5 50.209961   BatchTime 0.264342   LR 0.000005
INFO - Training [68][  100/  196]   Loss 2.302636   Top1 10.085938   Top5 50.199219   BatchTime 0.259154   LR 0.000004
INFO - Training [68][  120/  196]   Loss 2.302668   Top1 10.045573   Top5 50.110677   BatchTime 0.257849   LR 0.000004
INFO - Training [68][  140/  196]   Loss 2.302626   Top1 10.209263   Top5 50.279018   BatchTime 0.255356   LR 0.000003
INFO - Training [68][  160/  196]   Loss 2.302596   Top1 10.219727   Top5 50.336914   BatchTime 0.254108   LR 0.000003
INFO - Training [68][  180/  196]   Loss 2.302623   Top1 10.199653   Top5 50.227865   BatchTime 0.253816   LR 0.000002
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 10.158    Top5: 50.148    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0551)
features.16.conv.6 tensor(0.7246)
conv.0 tensor(0.8737)
tensor(596106.) 2188896.0
INFO - Validation [68][   20/   40]   Loss 47.307878   Top1 10.253906   Top5 50.214844   BatchTime 0.131549
INFO - Validation [68][   40/   40]   Loss 47.472448   Top1 10.000000   Top5 50.000000   BatchTime 0.090576
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.472
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [68][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch  69
INFO - Training: 50000 samples (256 per mini-batch)
INFO - Training [69][   20/  196]   Loss 2.302662   Top1 9.570312   Top5 50.156250   BatchTime 0.284293   LR 0.000002
INFO - Training [69][   40/  196]   Loss 2.302766   Top1 9.990234   Top5 50.107422   BatchTime 0.244938   LR 0.000001
INFO - Training [69][   60/  196]   Loss 2.302754   Top1 10.039062   Top5 49.869792   BatchTime 0.233516   LR 0.000001
INFO - Training [69][   80/  196]   Loss 2.302705   Top1 10.034180   Top5 50.053711   BatchTime 0.237076   LR 0.000001
INFO - Training [69][  100/  196]   Loss 2.302734   Top1 9.996094   Top5 49.906250   BatchTime 0.239028   LR 0.000000
INFO - Training [69][  120/  196]   Loss 2.302728   Top1 9.925130   Top5 50.104167   BatchTime 0.238041   LR 0.000000
INFO - Training [69][  140/  196]   Loss 2.302711   Top1 10.030692   Top5 50.086496   BatchTime 0.237861   LR 0.000000
INFO - Training [69][  160/  196]   Loss 2.302705   Top1 10.056152   Top5 49.990234   BatchTime 0.238132   LR 0.000000
INFO - Training [69][  180/  196]   Loss 2.302726   Top1 10.028212   Top5 49.884983   BatchTime 0.237551   LR 0.000000
********************pre-trained*****************
validation quantized model on cpu
INFO - ==> Top1: 10.054    Top5: 49.926    Loss: 2.303
INFO - Created `MobileNetv2` model
          Use pre-trained model = False
INFO - Validation: 10000 samples (256 per mini-batch)
features.0.conv.0 tensor(0.)
features.0.conv.3 tensor(0.)
features.1.conv.0 tensor(0.)
features.1.conv.3 tensor(0.)
features.1.conv.6 tensor(0.)
features.2.conv.0 tensor(0.)
features.2.conv.3 tensor(0.)
features.2.conv.6 tensor(0.)
features.3.conv.0 tensor(0.)
features.3.conv.3 tensor(0.)
features.3.conv.6 tensor(0.)
features.4.conv.0 tensor(0.)
features.4.conv.3 tensor(0.)
features.4.conv.6 tensor(0.)
features.5.conv.0 tensor(0.)
features.5.conv.3 tensor(0.)
features.5.conv.6 tensor(0.)
features.6.conv.0 tensor(0.)
features.6.conv.3 tensor(0.)
features.6.conv.6 tensor(0.)
features.7.conv.0 tensor(0.)
features.7.conv.3 tensor(0.)
features.7.conv.6 tensor(0.)
features.8.conv.0 tensor(0.)
features.8.conv.3 tensor(0.)
features.8.conv.6 tensor(0.)
features.9.conv.0 tensor(0.)
features.9.conv.3 tensor(0.)
features.9.conv.6 tensor(0.)
features.10.conv.0 tensor(0.)
features.10.conv.3 tensor(0.)
features.10.conv.6 tensor(0.)
features.11.conv.0 tensor(0.)
features.11.conv.3 tensor(0.)
features.11.conv.6 tensor(0.)
features.12.conv.0 tensor(0.)
features.12.conv.3 tensor(0.)
features.12.conv.6 tensor(0.)
features.13.conv.0 tensor(0.)
features.13.conv.3 tensor(0.)
features.13.conv.6 tensor(0.)
features.14.conv.0 tensor(0.)
features.14.conv.3 tensor(0.)
features.14.conv.6 tensor(0.)
features.15.conv.0 tensor(0.)
features.15.conv.3 tensor(0.)
features.15.conv.6 tensor(0.)
features.16.conv.0 tensor(0.0987)
features.16.conv.3 tensor(0.0547)
features.16.conv.6 tensor(0.7246)
conv.0 tensor(0.8737)
tensor(596103.) 2188896.0
INFO - Validation [69][   20/   40]   Loss 46.923034   Top1 10.253906   Top5 50.214844   BatchTime 0.131123
INFO - Validation [69][   40/   40]   Loss 47.085261   Top1 10.000000   Top5 50.000000   BatchTime 0.091525
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.085
INFO - ==> Sparsity : 0.272
INFO - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
INFO - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
INFO - Scoreboard best 3 ==> Epoch [69][Top1: 10.000   Top5: 50.000]
INFO - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
INFO - >>>>>> Epoch -1 (final model evaluation)
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 46.923034   Top1 10.253906   Top5 50.214844   BatchTime 0.127658
INFO - Validation [   40/   40]   Loss 47.085261   Top1 10.000000   Top5 50.000000   BatchTime 0.089269
INFO - ==> Top1: 10.000    Top5: 50.000    Loss: 47.085
INFO - ==> Sparsity : 0.000
INFO - Program completed sucessfully ... exiting ...