
Files already downloaded and verified
Files already downloaded and verified
********************pre-trained*****************
INFO - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
INFO - Created `MobileNetv2` model
          Use pre-trained model = True
/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
  warnings.warn(
INFO - Validation: 10000 samples (256 per mini-batch)
INFO - Validation [   20/   40]   Loss 0.453618   Top1 91.464844   Top5 99.492188   BatchTime 0.181509
INFO - Validation [   40/   40]   Loss 0.456191   Top1 91.370000   Top5 99.570000   BatchTime 0.099158
INFO - ==> Top1: 91.370    Top5: 99.570    Loss: 0.456
INFO - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.0005
               maximize: False
               weight_decay: 4e-05
           )
INFO - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.0005
INFO - >>>>>> Epoch   0
INFO - Training: 50000 samples (256 per mini-batch)
*************soft_pruning_mode*******************
0.00000000
Traceback (most recent call last):
  File "main_slsq.py", line 94, in <module>
    main()
  File "main_slsq.py", line 80, in main
    trainer.train_qat_slsq(train_loader, val_loader, test_loader,qat_model, teacher_model,criterion,
  File "/home/ilena7440/LSQ_FakeQuant/trainer/process.py", line 50, in train_qat_slsq
    t_top1, t_top5, t_loss = train_one_epoch_slsq_with_distillation(train_loader, qat_model, teacher_model,
  File "/home/ilena7440/LSQ_FakeQuant/trainer/process.py", line 269, in train_one_epoch_slsq_with_distillation
    loss.backward()
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/ilena7440/qilbertenv/lib/python3.8/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt