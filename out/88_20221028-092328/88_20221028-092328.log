2022-10-28 09:23:28,672 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-092328/88_20221028-092328.log
2022-10-28 09:23:30,406 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 09:23:30,442 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-28 09:23:30,606 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 09:23:30,606 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 09:23:31,861 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 09:23:31,861 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 09:23:34,757 - INFO  - Validation [   20/   40]   Loss 2.337042   Top1 9.882812   Top5 49.296875   BatchTime 0.144769   
2022-10-28 09:23:36,371 - INFO  - Validation [   40/   40]   Loss 2.335632   Top1 10.000000   Top5 49.510000   BatchTime 0.112728   
2022-10-28 09:23:36,437 - INFO  - ==> Top1: 10.000    Top5: 49.510    Loss: 2.336

2022-10-28 09:23:36,437 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 49.510]
2022-10-28 09:23:36,438 - INFO  - >>>>>> Epoch   0
2022-10-28 09:23:36,438 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 09:23:39,095 - INFO  - Training [0][   20/  196]   Loss 2.270953   Top1 12.148438   Top5 51.210938   BatchTime 0.132809   LR 0.001000   
2022-10-28 09:23:41,219 - INFO  - Training [0][   40/  196]   Loss 2.286769   Top1 10.996094   Top5 50.830078   BatchTime 0.119509   LR 0.001000   
2022-10-28 09:23:43,345 - INFO  - Training [0][   60/  196]   Loss 2.292041   Top1 10.690104   Top5 50.462240   BatchTime 0.115107   LR 0.001000   
2022-10-28 09:23:45,472 - INFO  - Training [0][   80/  196]   Loss 2.294677   Top1 10.375977   Top5 50.458984   BatchTime 0.112922   LR 0.001000   
2022-10-28 09:23:47,600 - INFO  - Training [0][  100/  196]   Loss 2.296259   Top1 10.199219   Top5 50.386719   BatchTime 0.111619   LR 0.001000   
2022-10-28 09:23:49,728 - INFO  - Training [0][  120/  196]   Loss 2.297313   Top1 10.146484   Top5 50.192057   BatchTime 0.110748   LR 0.001000   
2022-10-28 09:23:51,861 - INFO  - Training [0][  140/  196]   Loss 2.298066   Top1 10.253906   Top5 50.239955   BatchTime 0.110162   LR 0.001000   
2022-10-28 09:23:54,007 - INFO  - Training [0][  160/  196]   Loss 2.298631   Top1 10.227051   Top5 50.356445   BatchTime 0.109801   LR 0.001000   
2022-10-28 09:23:56,122 - INFO  - Training [0][  180/  196]   Loss 2.299070   Top1 10.249566   Top5 50.249566   BatchTime 0.109354   LR 0.001000   
2022-10-28 09:23:57,845 - INFO  - ==> Top1: 10.258    Top5: 50.236    Loss: 2.299

2022-10-28 09:23:57,969 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 09:23:59,592 - INFO  - Validation [0][   20/   40]   Loss 2.302585   Top1 10.078125   Top5 50.019531   BatchTime 0.081127   
2022-10-28 09:24:00,671 - INFO  - Validation [0][   40/   40]   Loss 2.302585   Top1 10.000000   Top5 50.000000   BatchTime 0.067529   
2022-10-28 09:24:00,745 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-10-28 09:24:00,745 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 09:24:02,439 - INFO  - Validation [0][   20/   40]   Loss 2.621898   Top1 9.941406   Top5 51.132812   BatchTime 0.084669   
2022-10-28 09:24:03,419 - INFO  - Validation [0][   40/   40]   Loss 2.618112   Top1 9.960000   Top5 51.220000   BatchTime 0.066831   
2022-10-28 09:24:03,505 - INFO  - ==> Top1: 9.960    Top5: 51.220    Loss: 2.618

2022-10-28 09:24:03,505 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 49.510]
2022-10-28 09:24:03,505 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 9.960   Top5: 51.220]
2022-10-28 09:24:03,541 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221028-092328/88_checkpoint.pth.tar

2022-10-28 09:24:03,541 - INFO  - >>>>>> Epoch   1
2022-10-28 09:24:03,541 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 09:24:06,276 - INFO  - Training [1][   20/  196]   Loss 2.302585   Top1 9.804688   Top5 50.781250   BatchTime 0.136704   LR 0.001000   
2022-10-28 09:24:08,412 - INFO  - Training [1][   40/  196]   Loss 2.302585   Top1 9.736328   Top5 50.390625   BatchTime 0.121750   LR 0.001000   
2022-10-28 09:24:10,548 - INFO  - Training [1][   60/  196]   Loss 2.302585   Top1 9.863281   Top5 50.364583   BatchTime 0.116767   LR 0.001000   
2022-10-28 09:24:12,686 - INFO  - Training [1][   80/  196]   Loss 2.302585   Top1 10.043945   Top5 50.371094   BatchTime 0.114295   LR 0.001000   
2022-10-28 09:24:14,825 - INFO  - Training [1][  100/  196]   Loss 2.302585   Top1 10.000000   Top5 50.078125   BatchTime 0.112826   LR 0.001000   
2022-10-28 09:24:16,965 - INFO  - Training [1][  120/  196]   Loss 2.302585   Top1 10.035807   Top5 49.980469   BatchTime 0.111856   LR 0.001000   
2022-10-28 09:24:19,109 - INFO  - Training [1][  140/  196]   Loss 2.302585   Top1 9.896763   Top5 49.983259   BatchTime 0.111191   LR 0.001000   
2022-10-28 09:24:21,248 - INFO  - Training [1][  160/  196]   Loss 2.302585   Top1 9.948730   Top5 50.019531   BatchTime 0.110661   LR 0.001000   
2022-10-28 09:24:23,364 - INFO  - Training [1][  180/  196]   Loss 2.302585   Top1 9.976128   Top5 49.986979   BatchTime 0.110121   LR 0.001000   
2022-10-28 09:24:25,082 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-10-28 09:24:25,208 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 09:24:26,850 - INFO  - Validation [1][   20/   40]   Loss 2.302585   Top1 10.078125   Top5 50.019531   BatchTime 0.082058   
2022-10-28 09:24:27,937 - INFO  - Validation [1][   40/   40]   Loss 2.302585   Top1 10.000000   Top5 50.000000   BatchTime 0.068194   
2022-10-28 09:24:28,010 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-10-28 09:24:28,010 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 09:24:29,711 - INFO  - Validation [1][   20/   40]   Loss 2.619281   Top1 9.570312   Top5 50.917969   BatchTime 0.085025   
2022-10-28 09:24:30,648 - INFO  - Validation [1][   40/   40]   Loss 2.612227   Top1 9.110000   Top5 50.980000   BatchTime 0.065937   
2022-10-28 09:24:30,735 - INFO  - ==> Top1: 9.110    Top5: 50.980    Loss: 2.612

2022-10-28 09:24:30,735 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 49.510]
2022-10-28 09:24:30,736 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 9.960   Top5: 51.220]
2022-10-28 09:24:30,736 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 9.110   Top5: 50.980]
2022-10-28 09:24:30,799 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221028-092328/88_checkpoint.pth.tar

2022-10-28 09:24:30,800 - INFO  - >>>>>> Epoch   2
2022-10-28 09:24:30,800 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 09:24:33,547 - INFO  - Training [2][   20/  196]   Loss 2.302585   Top1 9.843750   Top5 49.804688   BatchTime 0.137323   LR 0.001000   
2022-10-28 09:24:35,690 - INFO  - Training [2][   40/  196]   Loss 2.302585   Top1 9.814453   Top5 49.726562   BatchTime 0.122242   LR 0.001000   
2022-10-28 09:24:37,832 - INFO  - Training [2][   60/  196]   Loss 2.302585   Top1 9.785156   Top5 49.850260   BatchTime 0.117198   LR 0.001000   
2022-10-28 09:24:39,977 - INFO  - Training [2][   80/  196]   Loss 2.302585   Top1 9.746094   Top5 49.936523   BatchTime 0.114702   LR 0.001000   
2022-10-28 09:24:42,120 - INFO  - Training [2][  100/  196]   Loss 2.302585   Top1 9.859375   Top5 50.035156   BatchTime 0.113195   LR 0.001000   
2022-10-28 09:24:44,262 - INFO  - Training [2][  120/  196]   Loss 2.302585   Top1 9.980469   Top5 50.065104   BatchTime 0.112176   LR 0.001000   
2022-10-28 09:24:46,404 - INFO  - Training [2][  140/  196]   Loss 2.302585   Top1 9.980469   Top5 49.927455   BatchTime 0.111450   LR 0.001000   
2022-10-28 09:24:48,546 - INFO  - Training [2][  160/  196]   Loss 2.302585   Top1 10.041504   Top5 50.051270   BatchTime 0.110911   LR 0.001000   
2022-10-28 09:24:50,670 - INFO  - Training [2][  180/  196]   Loss 2.302585   Top1 9.995660   Top5 50.026042   BatchTime 0.110385   LR 0.001000   
2022-10-28 09:24:52,396 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-10-28 09:24:52,512 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 09:24:54,153 - INFO  - Validation [2][   20/   40]   Loss 2.302585   Top1 10.078125   Top5 50.019531   BatchTime 0.082035   
2022-10-28 09:24:55,230 - INFO  - Validation [2][   40/   40]   Loss 2.302585   Top1 10.000000   Top5 50.000000   BatchTime 0.067929   
2022-10-28 09:24:55,313 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-10-28 09:24:55,313 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 09:24:57,059 - INFO  - Validation [2][   20/   40]   Loss 2.617718   Top1 10.000000   Top5 50.488281   BatchTime 0.087263   
2022-10-28 09:24:57,998 - INFO  - Validation [2][   40/   40]   Loss 2.613501   Top1 9.800000   Top5 50.580000   BatchTime 0.067104   
2022-10-28 09:24:58,068 - INFO  - ==> Top1: 9.800    Top5: 50.580    Loss: 2.614

2022-10-28 09:24:58,068 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 49.510]
2022-10-28 09:24:58,068 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 9.960   Top5: 51.220]
2022-10-28 09:24:58,069 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 9.800   Top5: 50.580]
2022-10-28 09:24:58,146 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221028-092328/88_checkpoint.pth.tar

2022-10-28 09:24:58,146 - INFO  - >>>>>> Epoch   3
2022-10-28 09:24:58,146 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 09:25:00,902 - INFO  - Training [3][   20/  196]   Loss 2.302585   Top1 10.644531   Top5 51.503906   BatchTime 0.137741   LR 0.001000   
2022-10-28 09:25:03,040 - INFO  - Training [3][   40/  196]   Loss 2.302585   Top1 10.146484   Top5 50.605469   BatchTime 0.122316   LR 0.001000   
2022-10-28 09:25:05,176 - INFO  - Training [3][   60/  196]   Loss 2.302585   Top1 10.358073   Top5 50.553385   BatchTime 0.117152   LR 0.001000   
2022-10-28 09:25:07,314 - INFO  - Training [3][   80/  196]   Loss 2.302585   Top1 10.205078   Top5 50.175781   BatchTime 0.114589   LR 0.001000   
2022-10-28 09:25:09,452 - INFO  - Training [3][  100/  196]   Loss 2.302585   Top1 10.226562   Top5 50.089844   BatchTime 0.113042   LR 0.001000   
2022-10-28 09:25:11,589 - INFO  - Training [3][  120/  196]   Loss 2.302585   Top1 10.175781   Top5 49.928385   BatchTime 0.112010   LR 0.001000   
2022-10-28 09:25:13,727 - INFO  - Training [3][  140/  196]   Loss 2.302585   Top1 10.203683   Top5 50.041853   BatchTime 0.111284   LR 0.001000   
2022-10-28 09:25:15,865 - INFO  - Training [3][  160/  196]   Loss 2.302585   Top1 10.107422   Top5 50.107422   BatchTime 0.110737   LR 0.001000   
2022-10-28 09:25:17,992 - INFO  - Training [3][  180/  196]   Loss 2.302585   Top1 10.065104   Top5 50.030382   BatchTime 0.110247   LR 0.001000   
2022-10-28 09:25:19,718 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-10-28 09:25:19,842 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 09:25:21,585 - INFO  - Validation [3][   20/   40]   Loss 2.302585   Top1 10.078125   Top5 50.019531   BatchTime 0.087148   
