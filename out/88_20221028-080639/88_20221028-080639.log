2022-10-28 08:06:39,589 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-080639/88_20221028-080639.log
2022-10-28 08:06:41,250 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 08:06:41,286 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-28 08:06:41,450 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 08:06:41,450 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 08:06:42,699 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 08:06:42,699 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:06:45,652 - INFO  - Validation [   20/   40]   Loss 3047.717822   Top1 12.753906   Top5 57.070312   BatchTime 0.145693   
2022-10-28 08:06:47,304 - INFO  - Validation [   40/   40]   Loss 3031.409704   Top1 12.670000   Top5 56.460000   BatchTime 0.114142   
2022-10-28 08:06:47,377 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-28 08:06:47,377 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 08:06:47,377 - INFO  - >>>>>> Epoch   0
2022-10-28 08:06:47,377 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 08:06:49,622 - INFO  - Training [0][   20/  196]   Loss 1.101479   Top1 70.742188   Top5 97.246094   BatchTime 0.112222   LR 0.001000   
2022-10-28 08:06:51,323 - INFO  - Training [0][   40/  196]   Loss 0.831563   Top1 77.041016   Top5 98.134766   BatchTime 0.098628   LR 0.001000   
2022-10-28 08:06:53,025 - INFO  - Training [0][   60/  196]   Loss 0.731994   Top1 79.114583   Top5 98.430990   BatchTime 0.094120   LR 0.001000   
2022-10-28 08:06:54,729 - INFO  - Training [0][   80/  196]   Loss 0.652505   Top1 80.942383   Top5 98.676758   BatchTime 0.091887   LR 0.001000   
2022-10-28 08:06:56,433 - INFO  - Training [0][  100/  196]   Loss 0.599569   Top1 82.234375   Top5 98.835938   BatchTime 0.090550   LR 0.001000   
2022-10-28 08:06:58,137 - INFO  - Training [0][  120/  196]   Loss 0.565807   Top1 83.001302   Top5 98.925781   BatchTime 0.089660   LR 0.001000   
2022-10-28 08:06:59,841 - INFO  - Training [0][  140/  196]   Loss 0.536288   Top1 83.694196   Top5 99.023438   BatchTime 0.089025   LR 0.001000   
2022-10-28 08:07:01,546 - INFO  - Training [0][  160/  196]   Loss 0.511956   Top1 84.267578   Top5 99.113770   BatchTime 0.088551   LR 0.001000   
2022-10-28 08:07:03,232 - INFO  - Training [0][  180/  196]   Loss 0.492217   Top1 84.754774   Top5 99.175347   BatchTime 0.088078   LR 0.001000   
2022-10-28 08:07:04,618 - INFO  - ==> Top1: 85.088    Top5: 99.218    Loss: 0.479

