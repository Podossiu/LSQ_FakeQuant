2022-11-01 00:52:42,561 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221101-005242/88_20221101-005242.log
2022-11-01 00:52:43,779 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-01 00:52:43,866 - INFO  - Created `mobilenetv2` model
          Use pre-trained model = True
2022-11-01 00:52:44,536 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-11-01 00:52:44,536 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-11-01 00:52:45,612 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-01 00:52:45,613 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-01 00:52:49,217 - INFO  - Validation [   20/   40]   Loss nan   Top1 10.078125   Top5 50.019531   BatchTime 0.180110   
2022-11-01 00:52:50,595 - INFO  - Validation [   40/   40]   Loss nan   Top1 10.000000   Top5 50.000000   BatchTime 0.124524   
2022-11-01 00:52:50,694 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: nan

2022-11-01 00:52:50,694 - INFO  - ==> Sparsity : 0.059

2022-11-01 00:52:50,694 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 50.000]
2022-11-01 00:52:50,695 - INFO  - >>>>>> Epoch   0
2022-11-01 00:52:50,696 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-01 00:52:54,586 - INFO  - Training [0][   20/  196]   Loss 20.449349   Top1 0.156250   Top5 0.976562   BatchTime 0.194392   LR 0.001000   
2022-11-01 00:52:57,620 - INFO  - Training [0][   40/  196]   Loss 18.887268   Top1 0.615234   Top5 2.978516   BatchTime 0.173047   LR 0.001000   
2022-11-01 00:53:00,577 - INFO  - Training [0][   60/  196]   Loss 18.047051   Top1 1.412760   Top5 6.236979   BatchTime 0.164641   LR 0.001000   
2022-11-01 00:53:03,539 - INFO  - Training [0][   80/  196]   Loss 17.466594   Top1 2.358398   Top5 10.732422   BatchTime 0.160509   LR 0.001000   
2022-11-01 00:53:06,504 - INFO  - Training [0][  100/  196]   Loss 17.008442   Top1 3.429688   Top5 15.578125   BatchTime 0.158053   LR 0.001000   
2022-11-01 00:53:09,452 - INFO  - Training [0][  120/  196]   Loss 16.623189   Top1 4.677734   Top5 20.169271   BatchTime 0.156277   LR 0.001000   
2022-11-01 00:53:12,402 - INFO  - Training [0][  140/  196]   Loss 16.286743   Top1 5.842634   Top5 24.511719   BatchTime 0.155027   LR 0.001000   
2022-11-01 00:53:15,346 - INFO  - Training [0][  160/  196]   Loss 15.984646   Top1 6.923828   Top5 28.508301   BatchTime 0.154045   LR 0.001000   
2022-11-01 00:53:18,208 - INFO  - Training [0][  180/  196]   Loss 15.714608   Top1 7.921007   Top5 32.089844   BatchTime 0.152829   LR 0.001000   
2022-11-01 00:53:20,579 - INFO  - ==> Top1: 8.684    Top5: 34.630    Loss: 15.525

