2022-11-25 11:18:02,519 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88_20221125-111802.log
2022-11-25 11:18:06,844 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-25 11:18:08,839 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-25 11:18:09,702 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
2022-11-25 11:18:09,702 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005

2022-11-25 11:18:09,926 - INFO  - >>>>>> Epoch   0
2022-11-25 11:18:09,928 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:18:18,973 - INFO  - Training [0][   20/  196]   Loss 1.571111   Top1 53.398438   Top5 89.101562   BatchTime 0.452160   LR 0.004999   
2022-11-25 11:18:27,334 - INFO  - Training [0][   40/  196]   Loss 1.487792   Top1 52.285156   Top5 89.384766   BatchTime 0.435084   LR 0.004995   
2022-11-25 11:18:35,488 - INFO  - Training [0][   60/  196]   Loss 1.384029   Top1 54.459635   Top5 90.644531   BatchTime 0.425966   LR 0.004989   
2022-11-25 11:18:44,221 - INFO  - Training [0][   80/  196]   Loss 1.314619   Top1 56.499023   Top5 91.586914   BatchTime 0.428628   LR 0.004980   
2022-11-25 11:18:52,868 - INFO  - Training [0][  100/  196]   Loss 1.253574   Top1 58.363281   Top5 92.371094   BatchTime 0.429371   LR 0.004968   
2022-11-25 11:19:01,043 - INFO  - Training [0][  120/  196]   Loss 1.205866   Top1 59.889323   Top5 92.858073   BatchTime 0.425933   LR 0.004954   
2022-11-25 11:19:09,434 - INFO  - Training [0][  140/  196]   Loss 1.191195   Top1 60.424107   Top5 92.938058   BatchTime 0.425025   LR 0.004938   
2022-11-25 11:19:17,248 - INFO  - Training [0][  160/  196]   Loss 1.170753   Top1 61.083984   Top5 93.112793   BatchTime 0.420730   LR 0.004919   
2022-11-25 11:19:23,513 - INFO  - Training [0][  180/  196]   Loss 1.147664   Top1 61.773003   Top5 93.337674   BatchTime 0.408791   LR 0.004897   
2022-11-25 11:19:28,532 - INFO  - ==> Top1: 62.382    Top5: 93.476    Loss: 1.128

2022-11-25 11:19:28,771 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:19:30,082 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:19:32,282 - INFO  - Validation [0][   20/   40]   Loss 0.705497   Top1 76.328125   Top5 98.554688   BatchTime 0.109939   
2022-11-25 11:19:33,361 - INFO  - Validation [0][   40/   40]   Loss 0.698075   Top1 76.410000   Top5 98.560000   BatchTime 0.081944   
2022-11-25 11:19:33,550 - INFO  - ==> Top1: 76.410    Top5: 98.560    Loss: 0.698

2022-11-25 11:19:33,550 - INFO  - ==> Sparsity : 0.152

2022-11-25 11:19:33,551 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 76.410   Top5: 98.560]
2022-11-25 11:19:39,315 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:19:39,318 - INFO  - >>>>>> Epoch   1
2022-11-25 11:19:39,320 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:19:48,665 - INFO  - Training [1][   20/  196]   Loss 0.930762   Top1 68.046875   Top5 95.703125   BatchTime 0.467105   LR 0.004853   
2022-11-25 11:19:56,150 - INFO  - Training [1][   40/  196]   Loss 0.949319   Top1 67.724609   Top5 95.673828   BatchTime 0.420673   LR 0.004825   
2022-11-25 11:20:03,600 - INFO  - Training [1][   60/  196]   Loss 0.954075   Top1 67.356771   Top5 95.416667   BatchTime 0.404604   LR 0.004794   
2022-11-25 11:20:11,051 - INFO  - Training [1][   80/  196]   Loss 0.938361   Top1 67.880859   Top5 95.654297   BatchTime 0.396599   LR 0.004761   
2022-11-25 11:20:18,707 - INFO  - Training [1][  100/  196]   Loss 0.919990   Top1 68.632812   Top5 95.769531   BatchTime 0.393839   LR 0.004725   
2022-11-25 11:20:26,149 - INFO  - Training [1][  120/  196]   Loss 0.906355   Top1 69.169922   Top5 95.979818   BatchTime 0.390213   LR 0.004687   
2022-11-25 11:20:33,648 - INFO  - Training [1][  140/  196]   Loss 0.892732   Top1 69.592634   Top5 96.110491   BatchTime 0.388033   LR 0.004647   
2022-11-25 11:20:40,126 - INFO  - Training [1][  160/  196]   Loss 0.884936   Top1 69.836426   Top5 96.113281   BatchTime 0.380013   LR 0.004605   
2022-11-25 11:20:46,627 - INFO  - Training [1][  180/  196]   Loss 0.870368   Top1 70.301649   Top5 96.178385   BatchTime 0.373906   LR 0.004560   
2022-11-25 11:20:52,553 - INFO  - ==> Top1: 70.542    Top5: 96.206    Loss: 0.864

2022-11-25 11:20:52,780 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:20:54,095 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:20:56,376 - INFO  - Validation [1][   20/   40]   Loss 0.628708   Top1 78.886719   Top5 98.574219   BatchTime 0.113983   
2022-11-25 11:20:57,492 - INFO  - Validation [1][   40/   40]   Loss 0.634339   Top1 78.610000   Top5 98.600000   BatchTime 0.084898   
2022-11-25 11:20:57,813 - INFO  - ==> Top1: 78.610    Top5: 98.600    Loss: 0.634

2022-11-25 11:20:57,813 - INFO  - ==> Sparsity : 0.150

2022-11-25 11:20:57,814 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 78.610   Top5: 98.600]
2022-11-25 11:20:57,814 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 76.410   Top5: 98.560]
2022-11-25 11:21:06,226 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:21:06,229 - INFO  - >>>>>> Epoch   2
2022-11-25 11:21:06,233 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:21:15,012 - INFO  - Training [2][   20/  196]   Loss 0.825666   Top1 71.445312   Top5 96.015625   BatchTime 0.438727   LR 0.004477   
2022-11-25 11:21:22,349 - INFO  - Training [2][   40/  196]   Loss 0.807187   Top1 72.392578   Top5 96.386719   BatchTime 0.402768   LR 0.004426   
2022-11-25 11:21:29,787 - INFO  - Training [2][   60/  196]   Loss 0.792815   Top1 72.701823   Top5 96.595052   BatchTime 0.392487   LR 0.004374   
2022-11-25 11:21:36,941 - INFO  - Training [2][   80/  196]   Loss 0.780326   Top1 73.168945   Top5 96.679688   BatchTime 0.383784   LR 0.004320   
2022-11-25 11:21:44,086 - INFO  - Training [2][  100/  196]   Loss 0.769531   Top1 73.550781   Top5 96.683594   BatchTime 0.378485   LR 0.004264   
2022-11-25 11:21:51,378 - INFO  - Training [2][  120/  196]   Loss 0.760677   Top1 73.811849   Top5 96.777344   BatchTime 0.376165   LR 0.004206   
2022-11-25 11:21:58,176 - INFO  - Training [2][  140/  196]   Loss 0.761168   Top1 73.761161   Top5 96.830357   BatchTime 0.370984   LR 0.004146   
2022-11-25 11:22:04,271 - INFO  - Training [2][  160/  196]   Loss 0.764036   Top1 73.698730   Top5 96.831055   BatchTime 0.362705   LR 0.004085   
2022-11-25 11:22:11,692 - INFO  - Training [2][  180/  196]   Loss 0.759822   Top1 73.891059   Top5 96.783854   BatchTime 0.363634   LR 0.004022   
2022-11-25 11:22:17,578 - INFO  - ==> Top1: 74.052    Top5: 96.800    Loss: 0.755

2022-11-25 11:22:17,891 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:22:19,128 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:22:23,294 - INFO  - Validation [2][   20/   40]   Loss 0.585192   Top1 81.230469   Top5 98.867188   BatchTime 0.208207   
2022-11-25 11:22:24,589 - INFO  - Validation [2][   40/   40]   Loss 0.579532   Top1 80.980000   Top5 98.980000   BatchTime 0.136489   
2022-11-25 11:22:24,802 - INFO  - ==> Top1: 80.980    Top5: 98.980    Loss: 0.580

2022-11-25 11:22:24,802 - INFO  - ==> Sparsity : 0.168

2022-11-25 11:22:24,803 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 80.980   Top5: 98.980]
2022-11-25 11:22:24,803 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 78.610   Top5: 98.600]
2022-11-25 11:22:24,803 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 76.410   Top5: 98.560]
2022-11-25 11:22:31,631 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:22:31,634 - INFO  - >>>>>> Epoch   3
2022-11-25 11:22:31,637 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:22:40,409 - INFO  - Training [3][   20/  196]   Loss 0.747987   Top1 75.000000   Top5 96.406250   BatchTime 0.438523   LR 0.003907   
2022-11-25 11:22:47,924 - INFO  - Training [3][   40/  196]   Loss 0.737081   Top1 75.009766   Top5 96.650391   BatchTime 0.407136   LR 0.003840   
2022-11-25 11:22:55,466 - INFO  - Training [3][   60/  196]   Loss 0.728883   Top1 75.104167   Top5 96.842448   BatchTime 0.397124   LR 0.003771   
2022-11-25 11:23:02,867 - INFO  - Training [3][   80/  196]   Loss 0.718088   Top1 75.537109   Top5 97.045898   BatchTime 0.390349   LR 0.003701   
2022-11-25 11:23:10,101 - INFO  - Training [3][  100/  196]   Loss 0.704388   Top1 76.093750   Top5 97.039062   BatchTime 0.384614   LR 0.003630   
2022-11-25 11:23:16,588 - INFO  - Training [3][  120/  196]   Loss 0.697632   Top1 76.279297   Top5 97.135417   BatchTime 0.374574   LR 0.003558   
2022-11-25 11:23:23,028 - INFO  - Training [3][  140/  196]   Loss 0.692705   Top1 76.409040   Top5 97.195871   BatchTime 0.367060   LR 0.003484   
2022-11-25 11:23:30,188 - INFO  - Training [3][  160/  196]   Loss 0.692183   Top1 76.469727   Top5 97.207031   BatchTime 0.365929   LR 0.003410   
2022-11-25 11:23:37,658 - INFO  - Training [3][  180/  196]   Loss 0.690635   Top1 76.425781   Top5 97.170139   BatchTime 0.366766   LR 0.003335   
2022-11-25 11:23:43,775 - INFO  - ==> Top1: 76.556    Top5: 97.170    Loss: 0.687

2022-11-25 11:23:44,001 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:23:45,415 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:23:47,764 - INFO  - Validation [3][   20/   40]   Loss 0.508516   Top1 82.949219   Top5 99.082031   BatchTime 0.117351   
2022-11-25 11:23:49,092 - INFO  - Validation [3][   40/   40]   Loss 0.505483   Top1 82.810000   Top5 99.300000   BatchTime 0.091874   
2022-11-25 11:23:49,679 - INFO  - ==> Top1: 82.810    Top5: 99.300    Loss: 0.505

2022-11-25 11:23:49,679 - INFO  - ==> Sparsity : 0.172

2022-11-25 11:23:49,680 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 82.810   Top5: 99.300]
2022-11-25 11:23:49,680 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 80.980   Top5: 98.980]
2022-11-25 11:23:49,680 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 78.610   Top5: 98.600]
2022-11-25 11:23:55,590 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:23:55,595 - INFO  - >>>>>> Epoch   4
2022-11-25 11:23:55,597 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:24:04,521 - INFO  - Training [4][   20/  196]   Loss 0.669720   Top1 76.992188   Top5 96.718750   BatchTime 0.446066   LR 0.003200   
2022-11-25 11:24:11,927 - INFO  - Training [4][   40/  196]   Loss 0.652614   Top1 77.656250   Top5 97.050781   BatchTime 0.408171   LR 0.003122   
2022-11-25 11:24:19,095 - INFO  - Training [4][   60/  196]   Loss 0.650810   Top1 77.701823   Top5 97.259115   BatchTime 0.391582   LR 0.003044   
2022-11-25 11:24:26,666 - INFO  - Training [4][   80/  196]   Loss 0.652861   Top1 77.685547   Top5 97.338867   BatchTime 0.388322   LR 0.002965   
2022-11-25 11:24:33,552 - INFO  - Training [4][  100/  196]   Loss 0.646316   Top1 77.910156   Top5 97.402344   BatchTime 0.379518   LR 0.002886   
2022-11-25 11:24:39,917 - INFO  - Training [4][  120/  196]   Loss 0.636955   Top1 78.229167   Top5 97.500000   BatchTime 0.369305   LR 0.002806   
2022-11-25 11:24:47,079 - INFO  - Training [4][  140/  196]   Loss 0.635842   Top1 78.250558   Top5 97.544643   BatchTime 0.367702   LR 0.002726   
2022-11-25 11:24:54,969 - INFO  - Training [4][  160/  196]   Loss 0.636823   Top1 78.234863   Top5 97.565918   BatchTime 0.371052   LR 0.002646   
2022-11-25 11:25:02,445 - INFO  - Training [4][  180/  196]   Loss 0.632375   Top1 78.387587   Top5 97.526042   BatchTime 0.371356   LR 0.002566   
2022-11-25 11:25:08,295 - INFO  - ==> Top1: 78.444    Top5: 97.530    Loss: 0.630

2022-11-25 11:25:08,532 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:25:09,821 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:25:12,564 - INFO  - Validation [4][   20/   40]   Loss 0.473075   Top1 84.707031   Top5 99.199219   BatchTime 0.137057   
2022-11-25 11:25:14,099 - INFO  - Validation [4][   40/   40]   Loss 0.463924   Top1 84.500000   Top5 99.260000   BatchTime 0.106911   
2022-11-25 11:25:14,707 - INFO  - ==> Top1: 84.500    Top5: 99.260    Loss: 0.464

2022-11-25 11:25:14,707 - INFO  - ==> Sparsity : 0.178

2022-11-25 11:25:14,708 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 84.500   Top5: 99.260]
2022-11-25 11:25:14,708 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 82.810   Top5: 99.300]
2022-11-25 11:25:14,708 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 80.980   Top5: 98.980]
2022-11-25 11:25:20,690 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:25:20,692 - INFO  - >>>>>> Epoch   5
2022-11-25 11:25:20,694 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:25:29,255 - INFO  - Training [5][   20/  196]   Loss 0.622209   Top1 78.710938   Top5 97.031250   BatchTime 0.427934   LR 0.002424   
2022-11-25 11:25:36,534 - INFO  - Training [5][   40/  196]   Loss 0.637261   Top1 78.154297   Top5 97.167969   BatchTime 0.395935   LR 0.002343   
2022-11-25 11:25:43,806 - INFO  - Training [5][   60/  196]   Loss 0.621658   Top1 78.860677   Top5 97.239583   BatchTime 0.385154   LR 0.002263   
2022-11-25 11:25:50,909 - INFO  - Training [5][   80/  196]   Loss 0.607964   Top1 79.296875   Top5 97.421875   BatchTime 0.377656   LR 0.002183   
2022-11-25 11:25:57,048 - INFO  - Training [5][  100/  196]   Loss 0.595441   Top1 79.695312   Top5 97.589844   BatchTime 0.363506   LR 0.002104   
2022-11-25 11:26:02,686 - INFO  - Training [5][  120/  196]   Loss 0.588734   Top1 80.006510   Top5 97.643229   BatchTime 0.349905   LR 0.002024   
2022-11-25 11:26:10,277 - INFO  - Training [5][  140/  196]   Loss 0.584039   Top1 80.094866   Top5 97.695312   BatchTime 0.354141   LR 0.001946   
2022-11-25 11:26:17,479 - INFO  - Training [5][  160/  196]   Loss 0.587042   Top1 79.960938   Top5 97.707520   BatchTime 0.354884   LR 0.001868   
2022-11-25 11:26:24,851 - INFO  - Training [5][  180/  196]   Loss 0.586003   Top1 80.008681   Top5 97.693142   BatchTime 0.356406   LR 0.001790   
2022-11-25 11:26:30,496 - INFO  - ==> Top1: 80.130    Top5: 97.692    Loss: 0.583

2022-11-25 11:26:30,885 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:26:32,618 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:26:35,015 - INFO  - Validation [5][   20/   40]   Loss 0.458791   Top1 84.531250   Top5 99.257812   BatchTime 0.119751   
2022-11-25 11:26:36,121 - INFO  - Validation [5][   40/   40]   Loss 0.454969   Top1 84.550000   Top5 99.320000   BatchTime 0.087532   
2022-11-25 11:26:36,476 - INFO  - ==> Top1: 84.550    Top5: 99.320    Loss: 0.455

2022-11-25 11:26:36,476 - INFO  - ==> Sparsity : 0.177

2022-11-25 11:26:36,477 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 84.550   Top5: 99.320]
2022-11-25 11:26:36,477 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 84.500   Top5: 99.260]
2022-11-25 11:26:36,477 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 82.810   Top5: 99.300]
2022-11-25 11:26:42,790 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:26:42,795 - INFO  - >>>>>> Epoch   6
2022-11-25 11:26:42,797 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:26:51,542 - INFO  - Training [6][   20/  196]   Loss 0.588356   Top1 79.765625   Top5 97.558594   BatchTime 0.437094   LR 0.001655   
2022-11-25 11:26:58,751 - INFO  - Training [6][   40/  196]   Loss 0.580159   Top1 79.941406   Top5 97.539062   BatchTime 0.398785   LR 0.001580   
2022-11-25 11:27:06,252 - INFO  - Training [6][   60/  196]   Loss 0.563744   Top1 80.625000   Top5 97.636719   BatchTime 0.390875   LR 0.001506   
2022-11-25 11:27:13,352 - INFO  - Training [6][   80/  196]   Loss 0.553489   Top1 80.805664   Top5 97.768555   BatchTime 0.381903   LR 0.001432   
2022-11-25 11:27:19,350 - INFO  - Training [6][  100/  196]   Loss 0.542126   Top1 81.218750   Top5 97.851562   BatchTime 0.365499   LR 0.001360   
2022-11-25 11:27:27,190 - INFO  - Training [6][  120/  196]   Loss 0.537309   Top1 81.455078   Top5 97.952474   BatchTime 0.369915   LR 0.001289   
2022-11-25 11:27:34,515 - INFO  - Training [6][  140/  196]   Loss 0.537946   Top1 81.473214   Top5 97.996652   BatchTime 0.369389   LR 0.001220   
2022-11-25 11:27:42,117 - INFO  - Training [6][  160/  196]   Loss 0.537774   Top1 81.464844   Top5 97.971191   BatchTime 0.370727   LR 0.001151   
2022-11-25 11:27:49,408 - INFO  - Training [6][  180/  196]   Loss 0.535772   Top1 81.486545   Top5 97.881944   BatchTime 0.370043   LR 0.001084   
2022-11-25 11:27:55,364 - INFO  - ==> Top1: 81.500    Top5: 97.894    Loss: 0.536

2022-11-25 11:27:55,617 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:27:57,030 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:27:59,482 - INFO  - Validation [6][   20/   40]   Loss 0.412898   Top1 86.582031   Top5 99.296875   BatchTime 0.122505   
2022-11-25 11:28:00,744 - INFO  - Validation [6][   40/   40]   Loss 0.401779   Top1 86.590000   Top5 99.500000   BatchTime 0.092804   
2022-11-25 11:28:01,340 - INFO  - ==> Top1: 86.590    Top5: 99.500    Loss: 0.402

2022-11-25 11:28:01,340 - INFO  - ==> Sparsity : 0.176

2022-11-25 11:28:01,340 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 86.590   Top5: 99.500]
2022-11-25 11:28:01,341 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 84.550   Top5: 99.320]
2022-11-25 11:28:01,341 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 84.500   Top5: 99.260]
2022-11-25 11:28:07,220 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:28:07,225 - INFO  - >>>>>> Epoch   7
2022-11-25 11:28:07,229 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:28:16,245 - INFO  - Training [7][   20/  196]   Loss 0.522886   Top1 81.503906   Top5 97.636719   BatchTime 0.450552   LR 0.000969   
2022-11-25 11:28:23,554 - INFO  - Training [7][   40/  196]   Loss 0.519403   Top1 81.865234   Top5 97.968750   BatchTime 0.407998   LR 0.000907   
2022-11-25 11:28:30,413 - INFO  - Training [7][   60/  196]   Loss 0.511440   Top1 82.298177   Top5 97.955729   BatchTime 0.386318   LR 0.000845   
2022-11-25 11:28:36,237 - INFO  - Training [7][   80/  196]   Loss 0.508347   Top1 82.280273   Top5 98.085938   BatchTime 0.362541   LR 0.000786   
2022-11-25 11:28:44,024 - INFO  - Training [7][  100/  196]   Loss 0.501622   Top1 82.402344   Top5 98.125000   BatchTime 0.367897   LR 0.000728   
2022-11-25 11:28:51,525 - INFO  - Training [7][  120/  196]   Loss 0.498359   Top1 82.591146   Top5 98.212891   BatchTime 0.369087   LR 0.000673   
2022-11-25 11:28:58,787 - INFO  - Training [7][  140/  196]   Loss 0.498819   Top1 82.566964   Top5 98.250558   BatchTime 0.368231   LR 0.000619   
2022-11-25 11:29:06,327 - INFO  - Training [7][  160/  196]   Loss 0.499913   Top1 82.551270   Top5 98.234863   BatchTime 0.369327   LR 0.000567   
2022-11-25 11:29:13,518 - INFO  - Training [7][  180/  196]   Loss 0.501711   Top1 82.539062   Top5 98.185764   BatchTime 0.368240   LR 0.000517   
2022-11-25 11:29:19,324 - INFO  - ==> Top1: 82.642    Top5: 98.204    Loss: 0.499

2022-11-25 11:29:19,589 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:29:21,123 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:29:24,498 - INFO  - Validation [7][   20/   40]   Loss 0.499425   Top1 83.710938   Top5 98.886719   BatchTime 0.168645   
2022-11-25 11:29:25,623 - INFO  - Validation [7][   40/   40]   Loss 0.492437   Top1 83.750000   Top5 99.030000   BatchTime 0.112458   
2022-11-25 11:29:26,236 - INFO  - ==> Top1: 83.750    Top5: 99.030    Loss: 0.492

2022-11-25 11:29:26,236 - INFO  - ==> Sparsity : 0.176

2022-11-25 11:29:26,237 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 86.590   Top5: 99.500]
2022-11-25 11:29:26,237 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 84.550   Top5: 99.320]
2022-11-25 11:29:26,237 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 84.500   Top5: 99.260]
2022-11-25 11:29:26,400 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:29:26,401 - INFO  - >>>>>> Epoch   8
2022-11-25 11:29:26,403 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:29:35,381 - INFO  - Training [8][   20/  196]   Loss 0.501600   Top1 82.539062   Top5 97.910156   BatchTime 0.448752   LR 0.000434   
2022-11-25 11:29:42,949 - INFO  - Training [8][   40/  196]   Loss 0.495571   Top1 82.812500   Top5 98.056641   BatchTime 0.413577   LR 0.000389   
2022-11-25 11:29:49,906 - INFO  - Training [8][   60/  196]   Loss 0.495668   Top1 82.825521   Top5 98.033854   BatchTime 0.391660   LR 0.000347   
2022-11-25 11:29:55,560 - INFO  - Training [8][   80/  196]   Loss 0.494184   Top1 82.729492   Top5 98.154297   BatchTime 0.364419   LR 0.000308   
2022-11-25 11:30:02,987 - INFO  - Training [8][  100/  196]   Loss 0.485922   Top1 83.011719   Top5 98.203125   BatchTime 0.365807   LR 0.000270   
2022-11-25 11:30:10,683 - INFO  - Training [8][  120/  196]   Loss 0.478787   Top1 83.238932   Top5 98.307292   BatchTime 0.368971   LR 0.000235   
2022-11-25 11:30:18,191 - INFO  - Training [8][  140/  196]   Loss 0.472439   Top1 83.526786   Top5 98.367746   BatchTime 0.369888   LR 0.000202   
2022-11-25 11:30:25,586 - INFO  - Training [8][  160/  196]   Loss 0.476108   Top1 83.356934   Top5 98.356934   BatchTime 0.369873   LR 0.000172   
2022-11-25 11:30:32,818 - INFO  - Training [8][  180/  196]   Loss 0.474571   Top1 83.348524   Top5 98.281250   BatchTime 0.368955   LR 0.000143   
2022-11-25 11:30:38,832 - INFO  - ==> Top1: 83.420    Top5: 98.304    Loss: 0.474

2022-11-25 11:30:39,058 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:30:40,448 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:30:42,875 - INFO  - Validation [8][   20/   40]   Loss 0.774238   Top1 74.667969   Top5 98.183594   BatchTime 0.121249   
2022-11-25 11:30:43,953 - INFO  - Validation [8][   40/   40]   Loss 0.777028   Top1 74.440000   Top5 98.300000   BatchTime 0.087580   
2022-11-25 11:30:44,160 - INFO  - ==> Top1: 74.440    Top5: 98.300    Loss: 0.777

2022-11-25 11:30:44,160 - INFO  - ==> Sparsity : 0.177

2022-11-25 11:30:44,161 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 86.590   Top5: 99.500]
2022-11-25 11:30:44,161 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 84.550   Top5: 99.320]
2022-11-25 11:30:44,161 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 84.500   Top5: 99.260]
2022-11-25 11:30:44,277 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:30:44,279 - INFO  - >>>>>> Epoch   9
2022-11-25 11:30:44,280 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:30:53,135 - INFO  - Training [9][   20/  196]   Loss 0.490995   Top1 82.773438   Top5 97.519531   BatchTime 0.442594   LR 0.000100   
2022-11-25 11:31:00,596 - INFO  - Training [9][   40/  196]   Loss 0.491700   Top1 82.529297   Top5 97.792969   BatchTime 0.407834   LR 0.000079   
2022-11-25 11:31:07,967 - INFO  - Training [9][   60/  196]   Loss 0.484203   Top1 82.812500   Top5 98.020833   BatchTime 0.394727   LR 0.000060   
2022-11-25 11:31:14,025 - INFO  - Training [9][   80/  196]   Loss 0.482824   Top1 82.983398   Top5 98.095703   BatchTime 0.371776   LR 0.000044   
2022-11-25 11:31:21,899 - INFO  - Training [9][  100/  196]   Loss 0.475672   Top1 83.308594   Top5 98.199219   BatchTime 0.376161   LR 0.000030   
2022-11-25 11:31:29,390 - INFO  - Training [9][  120/  196]   Loss 0.468628   Top1 83.499349   Top5 98.297526   BatchTime 0.375887   LR 0.000019   
2022-11-25 11:31:36,913 - INFO  - Training [9][  140/  196]   Loss 0.466614   Top1 83.549107   Top5 98.351004   BatchTime 0.375923   LR 0.000010   
2022-11-25 11:31:44,344 - INFO  - Training [9][  160/  196]   Loss 0.468050   Top1 83.493652   Top5 98.347168   BatchTime 0.375377   LR 0.000004   
2022-11-25 11:31:51,654 - INFO  - Training [9][  180/  196]   Loss 0.467216   Top1 83.565538   Top5 98.289931   BatchTime 0.374281   LR 0.000001   
2022-11-25 11:31:57,578 - INFO  - ==> Top1: 83.578    Top5: 98.280    Loss: 0.468

2022-11-25 11:31:57,824 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:31:59,298 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:32:01,678 - INFO  - Validation [9][   20/   40]   Loss 0.386020   Top1 87.519531   Top5 99.355469   BatchTime 0.118915   
2022-11-25 11:32:02,731 - INFO  - Validation [9][   40/   40]   Loss 0.376680   Top1 87.580000   Top5 99.450000   BatchTime 0.085786   
2022-11-25 11:32:02,973 - INFO  - ==> Top1: 87.580    Top5: 99.450    Loss: 0.377

2022-11-25 11:32:02,973 - INFO  - ==> Sparsity : 0.178

2022-11-25 11:32:02,974 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.580   Top5: 99.450]
2022-11-25 11:32:02,974 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 86.590   Top5: 99.500]
2022-11-25 11:32:02,974 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 84.550   Top5: 99.320]
2022-11-25 11:32:08,434 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:32:08,437 - INFO  - >>>>>> Epoch  10
2022-11-25 11:32:08,440 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:32:17,475 - INFO  - Training [10][   20/  196]   Loss 0.517963   Top1 81.894531   Top5 97.714844   BatchTime 0.451520   LR 0.002500   
2022-11-25 11:32:24,742 - INFO  - Training [10][   40/  196]   Loss 0.533947   Top1 81.308594   Top5 97.812500   BatchTime 0.407435   LR 0.002499   
2022-11-25 11:32:30,730 - INFO  - Training [10][   60/  196]   Loss 0.546993   Top1 81.035156   Top5 97.825521   BatchTime 0.371411   LR 0.002499   
2022-11-25 11:32:38,615 - INFO  - Training [10][   80/  196]   Loss 0.573931   Top1 80.214844   Top5 97.226562   BatchTime 0.377123   LR 0.002497   
2022-11-25 11:32:46,219 - INFO  - Training [10][  100/  196]   Loss 0.566310   Top1 80.488281   Top5 97.398438   BatchTime 0.377738   LR 0.002496   
2022-11-25 11:32:53,793 - INFO  - Training [10][  120/  196]   Loss 0.563703   Top1 80.634766   Top5 97.522786   BatchTime 0.377894   LR 0.002494   
2022-11-25 11:33:01,138 - INFO  - Training [10][  140/  196]   Loss 0.561949   Top1 80.683594   Top5 97.653460   BatchTime 0.376375   LR 0.002492   
2022-11-25 11:33:08,579 - INFO  - Training [10][  160/  196]   Loss 0.562308   Top1 80.720215   Top5 97.663574   BatchTime 0.375833   LR 0.002490   
2022-11-25 11:33:15,850 - INFO  - Training [10][  180/  196]   Loss 0.562681   Top1 80.640191   Top5 97.615017   BatchTime 0.374466   LR 0.002487   
2022-11-25 11:33:21,769 - INFO  - ==> Top1: 80.610    Top5: 97.622    Loss: 0.563

2022-11-25 11:33:22,060 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:33:23,864 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:33:26,268 - INFO  - Validation [10][   20/   40]   Loss 0.572363   Top1 81.152344   Top5 98.671875   BatchTime 0.120091   
2022-11-25 11:33:27,405 - INFO  - Validation [10][   40/   40]   Loss 0.571272   Top1 80.930000   Top5 98.740000   BatchTime 0.088472   
2022-11-25 11:33:27,638 - INFO  - ==> Top1: 80.930    Top5: 98.740    Loss: 0.571

2022-11-25 11:33:27,639 - INFO  - ==> Sparsity : 0.181

2022-11-25 11:33:27,639 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.580   Top5: 99.450]
2022-11-25 11:33:27,639 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 86.590   Top5: 99.500]
2022-11-25 11:33:27,639 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 84.550   Top5: 99.320]
2022-11-25 11:33:27,763 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:33:27,765 - INFO  - >>>>>> Epoch  11
2022-11-25 11:33:27,767 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:33:36,935 - INFO  - Training [11][   20/  196]   Loss 0.564188   Top1 80.820312   Top5 97.031250   BatchTime 0.458285   LR 0.002481   
2022-11-25 11:33:44,162 - INFO  - Training [11][   40/  196]   Loss 0.564672   Top1 80.634766   Top5 97.431641   BatchTime 0.409809   LR 0.002478   
2022-11-25 11:33:49,896 - INFO  - Training [11][   60/  196]   Loss 0.563780   Top1 80.520833   Top5 97.643229   BatchTime 0.368773   LR 0.002474   
2022-11-25 11:33:57,143 - INFO  - Training [11][   80/  196]   Loss 0.565260   Top1 80.507812   Top5 97.719727   BatchTime 0.367164   LR 0.002470   
2022-11-25 11:34:04,590 - INFO  - Training [11][  100/  196]   Loss 0.556834   Top1 80.839844   Top5 97.750000   BatchTime 0.368200   LR 0.002465   
2022-11-25 11:34:12,098 - INFO  - Training [11][  120/  196]   Loss 0.551547   Top1 81.031901   Top5 97.858073   BatchTime 0.369399   LR 0.002460   
2022-11-25 11:34:19,435 - INFO  - Training [11][  140/  196]   Loss 0.555537   Top1 80.965402   Top5 97.890625   BatchTime 0.369035   LR 0.002455   
2022-11-25 11:34:26,916 - INFO  - Training [11][  160/  196]   Loss 0.558978   Top1 80.761719   Top5 97.907715   BatchTime 0.369660   LR 0.002450   
2022-11-25 11:34:34,308 - INFO  - Training [11][  180/  196]   Loss 0.557656   Top1 80.839844   Top5 97.849392   BatchTime 0.369657   LR 0.002444   
2022-11-25 11:34:40,123 - INFO  - ==> Top1: 80.830    Top5: 97.852    Loss: 0.557

2022-11-25 11:34:40,379 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:34:41,801 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:34:44,239 - INFO  - Validation [11][   20/   40]   Loss 0.449047   Top1 85.292969   Top5 99.121094   BatchTime 0.121785   
2022-11-25 11:34:45,416 - INFO  - Validation [11][   40/   40]   Loss 0.445876   Top1 85.410000   Top5 99.250000   BatchTime 0.090332   
2022-11-25 11:34:45,673 - INFO  - ==> Top1: 85.410    Top5: 99.250    Loss: 0.446

2022-11-25 11:34:45,674 - INFO  - ==> Sparsity : 0.182

2022-11-25 11:34:45,674 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.580   Top5: 99.450]
2022-11-25 11:34:45,674 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 86.590   Top5: 99.500]
2022-11-25 11:34:45,674 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 85.410   Top5: 99.250]
2022-11-25 11:34:45,807 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:34:45,809 - INFO  - >>>>>> Epoch  12
2022-11-25 11:34:45,811 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:34:55,354 - INFO  - Training [12][   20/  196]   Loss 0.556617   Top1 80.332031   Top5 97.304688   BatchTime 0.477032   LR 0.002433   
2022-11-25 11:35:03,024 - INFO  - Training [12][   40/  196]   Loss 0.556030   Top1 80.634766   Top5 97.607422   BatchTime 0.430270   LR 0.002426   
2022-11-25 11:35:09,343 - INFO  - Training [12][   60/  196]   Loss 0.552248   Top1 80.852865   Top5 97.688802   BatchTime 0.392158   LR 0.002419   
2022-11-25 11:35:15,916 - INFO  - Training [12][   80/  196]   Loss 0.550545   Top1 80.976562   Top5 97.783203   BatchTime 0.376279   LR 0.002412   
2022-11-25 11:35:24,178 - INFO  - Training [12][  100/  196]   Loss 0.542433   Top1 81.347656   Top5 97.855469   BatchTime 0.383647   LR 0.002404   
2022-11-25 11:35:31,704 - INFO  - Training [12][  120/  196]   Loss 0.538308   Top1 81.497396   Top5 97.958984   BatchTime 0.382419   LR 0.002396   
2022-11-25 11:35:38,955 - INFO  - Training [12][  140/  196]   Loss 0.538150   Top1 81.478795   Top5 98.013393   BatchTime 0.379579   LR 0.002388   
2022-11-25 11:35:46,391 - INFO  - Training [12][  160/  196]   Loss 0.539351   Top1 81.508789   Top5 97.990723   BatchTime 0.378610   LR 0.002380   
2022-11-25 11:35:53,747 - INFO  - Training [12][  180/  196]   Loss 0.540192   Top1 81.438802   Top5 97.929688   BatchTime 0.377407   LR 0.002371   
2022-11-25 11:35:59,188 - INFO  - ==> Top1: 81.538    Top5: 97.952    Loss: 0.538

2022-11-25 11:35:59,419 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:36:00,832 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:36:03,390 - INFO  - Validation [12][   20/   40]   Loss 0.515171   Top1 82.734375   Top5 99.121094   BatchTime 0.127792   
2022-11-25 11:36:04,636 - INFO  - Validation [12][   40/   40]   Loss 0.523212   Top1 82.690000   Top5 99.160000   BatchTime 0.095055   
2022-11-25 11:36:04,985 - INFO  - ==> Top1: 82.690    Top5: 99.160    Loss: 0.523

2022-11-25 11:36:04,985 - INFO  - ==> Sparsity : 0.240

2022-11-25 11:36:04,986 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.580   Top5: 99.450]
2022-11-25 11:36:04,986 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 86.590   Top5: 99.500]
2022-11-25 11:36:04,986 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 85.410   Top5: 99.250]
2022-11-25 11:36:05,110 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:36:05,112 - INFO  - >>>>>> Epoch  13
2022-11-25 11:36:05,113 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:36:14,192 - INFO  - Training [13][   20/  196]   Loss 0.536611   Top1 81.738281   Top5 97.480469   BatchTime 0.453824   LR 0.002355   
2022-11-25 11:36:21,655 - INFO  - Training [13][   40/  196]   Loss 0.547074   Top1 81.269531   Top5 97.656250   BatchTime 0.413492   LR 0.002345   
2022-11-25 11:36:28,307 - INFO  - Training [13][   60/  196]   Loss 0.531500   Top1 81.731771   Top5 97.792969   BatchTime 0.386525   LR 0.002336   
2022-11-25 11:36:34,164 - INFO  - Training [13][   80/  196]   Loss 0.533389   Top1 81.582031   Top5 97.875977   BatchTime 0.363100   LR 0.002325   
2022-11-25 11:36:40,561 - INFO  - Training [13][  100/  196]   Loss 0.528688   Top1 81.667969   Top5 97.914062   BatchTime 0.354452   LR 0.002315   
2022-11-25 11:36:48,014 - INFO  - Training [13][  120/  196]   Loss 0.528830   Top1 81.663411   Top5 97.975260   BatchTime 0.357479   LR 0.002304   
2022-11-25 11:36:55,246 - INFO  - Training [13][  140/  196]   Loss 0.529205   Top1 81.623884   Top5 98.046875   BatchTime 0.358072   LR 0.002293   
2022-11-25 11:37:02,796 - INFO  - Training [13][  160/  196]   Loss 0.530151   Top1 81.596680   Top5 98.076172   BatchTime 0.360497   LR 0.002282   
2022-11-25 11:37:10,224 - INFO  - Training [13][  180/  196]   Loss 0.529692   Top1 81.612413   Top5 98.020833   BatchTime 0.361710   LR 0.002271   
2022-11-25 11:37:16,218 - INFO  - ==> Top1: 81.724    Top5: 98.002    Loss: 0.528

2022-11-25 11:37:16,459 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:37:18,097 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:37:20,537 - INFO  - Validation [13][   20/   40]   Loss 0.407291   Top1 86.796875   Top5 99.375000   BatchTime 0.121900   
2022-11-25 11:37:21,672 - INFO  - Validation [13][   40/   40]   Loss 0.395959   Top1 86.630000   Top5 99.450000   BatchTime 0.089319   
2022-11-25 11:37:21,880 - INFO  - ==> Top1: 86.630    Top5: 99.450    Loss: 0.396

2022-11-25 11:37:21,881 - INFO  - ==> Sparsity : 0.223

2022-11-25 11:37:21,881 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.580   Top5: 99.450]
2022-11-25 11:37:21,881 - INFO  - Scoreboard best 2 ==> Epoch [13][Top1: 86.630   Top5: 99.450]
2022-11-25 11:37:21,881 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 86.590   Top5: 99.500]
2022-11-25 11:37:22,005 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:37:22,006 - INFO  - >>>>>> Epoch  14
2022-11-25 11:37:22,008 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:37:31,241 - INFO  - Training [14][   20/  196]   Loss 0.512762   Top1 81.796875   Top5 97.617188   BatchTime 0.461522   LR 0.002250   
2022-11-25 11:37:38,596 - INFO  - Training [14][   40/  196]   Loss 0.523407   Top1 81.523438   Top5 97.822266   BatchTime 0.414627   LR 0.002238   
2022-11-25 11:37:46,017 - INFO  - Training [14][   60/  196]   Loss 0.517091   Top1 81.842448   Top5 97.988281   BatchTime 0.400102   LR 0.002225   
2022-11-25 11:37:53,295 - INFO  - Training [14][   80/  196]   Loss 0.514132   Top1 82.021484   Top5 98.076172   BatchTime 0.391048   LR 0.002213   
2022-11-25 11:38:00,479 - INFO  - Training [14][  100/  196]   Loss 0.508854   Top1 82.289062   Top5 98.121094   BatchTime 0.384675   LR 0.002200   
2022-11-25 11:38:06,043 - INFO  - Training [14][  120/  196]   Loss 0.503825   Top1 82.454427   Top5 98.206380   BatchTime 0.366930   LR 0.002186   
2022-11-25 11:38:13,399 - INFO  - Training [14][  140/  196]   Loss 0.504416   Top1 82.488839   Top5 98.261719   BatchTime 0.367059   LR 0.002173   
2022-11-25 11:38:20,798 - INFO  - Training [14][  160/  196]   Loss 0.506122   Top1 82.426758   Top5 98.215332   BatchTime 0.367416   LR 0.002159   
2022-11-25 11:38:28,106 - INFO  - Training [14][  180/  196]   Loss 0.507927   Top1 82.348090   Top5 98.142361   BatchTime 0.367193   LR 0.002145   
2022-11-25 11:38:34,036 - INFO  - ==> Top1: 82.416    Top5: 98.120    Loss: 0.506

2022-11-25 11:38:34,260 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:38:35,612 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:38:38,202 - INFO  - Validation [14][   20/   40]   Loss 0.450185   Top1 84.921875   Top5 99.257812   BatchTime 0.129363   
2022-11-25 11:38:39,276 - INFO  - Validation [14][   40/   40]   Loss 0.450278   Top1 85.040000   Top5 99.310000   BatchTime 0.091536   
2022-11-25 11:38:39,508 - INFO  - ==> Top1: 85.040    Top5: 99.310    Loss: 0.450

2022-11-25 11:38:39,508 - INFO  - ==> Sparsity : 0.230

2022-11-25 11:38:39,508 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.580   Top5: 99.450]
2022-11-25 11:38:39,508 - INFO  - Scoreboard best 2 ==> Epoch [13][Top1: 86.630   Top5: 99.450]
2022-11-25 11:38:39,509 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 86.590   Top5: 99.500]
2022-11-25 11:38:39,705 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:38:39,708 - INFO  - >>>>>> Epoch  15
2022-11-25 11:38:39,711 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:38:49,425 - INFO  - Training [15][   20/  196]   Loss 0.522956   Top1 81.855469   Top5 97.675781   BatchTime 0.485490   LR 0.002120   
2022-11-25 11:38:56,774 - INFO  - Training [15][   40/  196]   Loss 0.563451   Top1 80.087891   Top5 96.748047   BatchTime 0.426464   LR 0.002106   
2022-11-25 11:39:04,186 - INFO  - Training [15][   60/  196]   Loss 0.548002   Top1 80.781250   Top5 97.180990   BatchTime 0.407845   LR 0.002091   
2022-11-25 11:39:11,687 - INFO  - Training [15][   80/  196]   Loss 0.537687   Top1 81.191406   Top5 97.524414   BatchTime 0.399645   LR 0.002076   
2022-11-25 11:39:19,548 - INFO  - Training [15][  100/  196]   Loss 0.519075   Top1 81.753906   Top5 97.699219   BatchTime 0.398325   LR 0.002061   
2022-11-25 11:39:25,320 - INFO  - Training [15][  120/  196]   Loss 0.513213   Top1 82.021484   Top5 97.858073   BatchTime 0.380038   LR 0.002045   
2022-11-25 11:39:31,973 - INFO  - Training [15][  140/  196]   Loss 0.509251   Top1 82.142857   Top5 97.968750   BatchTime 0.373266   LR 0.002030   
2022-11-25 11:39:39,257 - INFO  - Training [15][  160/  196]   Loss 0.508816   Top1 82.158203   Top5 97.956543   BatchTime 0.372132   LR 0.002014   
2022-11-25 11:39:46,404 - INFO  - Training [15][  180/  196]   Loss 0.506452   Top1 82.287326   Top5 97.903646   BatchTime 0.370491   LR 0.001998   
2022-11-25 11:39:52,377 - INFO  - ==> Top1: 82.386    Top5: 97.948    Loss: 0.504

2022-11-25 11:39:52,641 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:39:54,220 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:39:56,753 - INFO  - Validation [15][   20/   40]   Loss 0.410619   Top1 86.289062   Top5 99.335938   BatchTime 0.126526   
2022-11-25 11:39:57,955 - INFO  - Validation [15][   40/   40]   Loss 0.400925   Top1 86.320000   Top5 99.530000   BatchTime 0.093336   
2022-11-25 11:39:58,178 - INFO  - ==> Top1: 86.320    Top5: 99.530    Loss: 0.401

2022-11-25 11:39:58,178 - INFO  - ==> Sparsity : 0.235

2022-11-25 11:39:58,178 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.580   Top5: 99.450]
2022-11-25 11:39:58,178 - INFO  - Scoreboard best 2 ==> Epoch [13][Top1: 86.630   Top5: 99.450]
2022-11-25 11:39:58,178 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 86.590   Top5: 99.500]
2022-11-25 11:39:58,302 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:39:58,304 - INFO  - >>>>>> Epoch  16
2022-11-25 11:39:58,306 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:40:07,220 - INFO  - Training [16][   20/  196]   Loss 0.489181   Top1 83.261719   Top5 97.949219   BatchTime 0.445562   LR 0.001969   
2022-11-25 11:40:14,749 - INFO  - Training [16][   40/  196]   Loss 0.486889   Top1 83.203125   Top5 98.115234   BatchTime 0.411014   LR 0.001953   
2022-11-25 11:40:22,193 - INFO  - Training [16][   60/  196]   Loss 0.480535   Top1 83.229167   Top5 98.216146   BatchTime 0.398080   LR 0.001936   
2022-11-25 11:40:29,794 - INFO  - Training [16][   80/  196]   Loss 0.483181   Top1 83.300781   Top5 98.247070   BatchTime 0.393561   LR 0.001919   
2022-11-25 11:40:37,483 - INFO  - Training [16][  100/  196]   Loss 0.476425   Top1 83.515625   Top5 98.269531   BatchTime 0.391748   LR 0.001902   
2022-11-25 11:40:43,938 - INFO  - Training [16][  120/  196]   Loss 0.469690   Top1 83.785807   Top5 98.349609   BatchTime 0.380242   LR 0.001885   
2022-11-25 11:40:50,723 - INFO  - Training [16][  140/  196]   Loss 0.467008   Top1 83.842076   Top5 98.370536   BatchTime 0.374390   LR 0.001867   
2022-11-25 11:40:58,039 - INFO  - Training [16][  160/  196]   Loss 0.468821   Top1 83.842773   Top5 98.354492   BatchTime 0.373315   LR 0.001850   
2022-11-25 11:41:05,427 - INFO  - Training [16][  180/  196]   Loss 0.468975   Top1 83.843316   Top5 98.281250   BatchTime 0.372875   LR 0.001832   
2022-11-25 11:41:11,446 - INFO  - ==> Top1: 83.872    Top5: 98.292    Loss: 0.469

2022-11-25 11:41:11,673 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:41:13,189 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:41:15,773 - INFO  - Validation [16][   20/   40]   Loss 0.391671   Top1 87.128906   Top5 99.570312   BatchTime 0.129019   
2022-11-25 11:41:16,903 - INFO  - Validation [16][   40/   40]   Loss 0.385998   Top1 86.890000   Top5 99.660000   BatchTime 0.092817   
2022-11-25 11:41:17,260 - INFO  - ==> Top1: 86.890    Top5: 99.660    Loss: 0.386

2022-11-25 11:41:17,260 - INFO  - ==> Sparsity : 0.238

2022-11-25 11:41:17,261 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.580   Top5: 99.450]
2022-11-25 11:41:17,261 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 86.890   Top5: 99.660]
2022-11-25 11:41:17,261 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 86.630   Top5: 99.450]
2022-11-25 11:41:17,424 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:41:17,425 - INFO  - >>>>>> Epoch  17
2022-11-25 11:41:17,427 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:41:26,467 - INFO  - Training [17][   20/  196]   Loss 0.500389   Top1 82.246094   Top5 97.714844   BatchTime 0.451877   LR 0.001800   
2022-11-25 11:41:33,895 - INFO  - Training [17][   40/  196]   Loss 0.488721   Top1 82.910156   Top5 97.910156   BatchTime 0.411632   LR 0.001782   
2022-11-25 11:41:41,277 - INFO  - Training [17][   60/  196]   Loss 0.484718   Top1 83.118490   Top5 97.988281   BatchTime 0.397442   LR 0.001764   
2022-11-25 11:41:48,845 - INFO  - Training [17][   80/  196]   Loss 0.479648   Top1 83.295898   Top5 98.100586   BatchTime 0.392687   LR 0.001746   
2022-11-25 11:41:56,088 - INFO  - Training [17][  100/  196]   Loss 0.472954   Top1 83.550781   Top5 98.117188   BatchTime 0.386579   LR 0.001727   
2022-11-25 11:42:02,543 - INFO  - Training [17][  120/  196]   Loss 0.467143   Top1 83.779297   Top5 98.216146   BatchTime 0.375942   LR 0.001708   
2022-11-25 11:42:09,095 - INFO  - Training [17][  140/  196]   Loss 0.462165   Top1 83.981585   Top5 98.311942   BatchTime 0.369030   LR 0.001690   
2022-11-25 11:42:16,376 - INFO  - Training [17][  160/  196]   Loss 0.464014   Top1 83.930664   Top5 98.337402   BatchTime 0.368411   LR 0.001671   
2022-11-25 11:42:23,476 - INFO  - Training [17][  180/  196]   Loss 0.463011   Top1 83.936632   Top5 98.289931   BatchTime 0.366921   LR 0.001652   
2022-11-25 11:42:29,398 - INFO  - ==> Top1: 83.974    Top5: 98.290    Loss: 0.461

2022-11-25 11:42:29,642 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:42:31,308 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:42:33,823 - INFO  - Validation [17][   20/   40]   Loss 0.350459   Top1 88.828125   Top5 99.589844   BatchTime 0.125686   
2022-11-25 11:42:34,854 - INFO  - Validation [17][   40/   40]   Loss 0.342301   Top1 88.680000   Top5 99.700000   BatchTime 0.088627   
2022-11-25 11:42:35,064 - INFO  - ==> Top1: 88.680    Top5: 99.700    Loss: 0.342

2022-11-25 11:42:35,065 - INFO  - ==> Sparsity : 0.271

2022-11-25 11:42:35,065 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 88.680   Top5: 99.700]
2022-11-25 11:42:35,065 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 87.580   Top5: 99.450]
2022-11-25 11:42:35,065 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 86.890   Top5: 99.660]
2022-11-25 11:42:41,714 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:42:41,716 - INFO  - >>>>>> Epoch  18
2022-11-25 11:42:41,719 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:42:50,094 - INFO  - Training [18][   20/  196]   Loss 0.435858   Top1 84.355469   Top5 98.007812   BatchTime 0.418628   LR 0.001618   
2022-11-25 11:42:57,493 - INFO  - Training [18][   40/  196]   Loss 0.453117   Top1 83.925781   Top5 98.183594   BatchTime 0.394299   LR 0.001599   
2022-11-25 11:43:05,024 - INFO  - Training [18][   60/  196]   Loss 0.451213   Top1 84.192708   Top5 98.300781   BatchTime 0.388365   LR 0.001579   
2022-11-25 11:43:12,803 - INFO  - Training [18][   80/  196]   Loss 0.449178   Top1 84.238281   Top5 98.413086   BatchTime 0.388515   LR 0.001560   
2022-11-25 11:43:19,494 - INFO  - Training [18][  100/  196]   Loss 0.447833   Top1 84.320312   Top5 98.421875   BatchTime 0.377724   LR 0.001540   
2022-11-25 11:43:26,295 - INFO  - Training [18][  120/  196]   Loss 0.443207   Top1 84.479167   Top5 98.473307   BatchTime 0.371444   LR 0.001521   
2022-11-25 11:43:33,737 - INFO  - Training [18][  140/  196]   Loss 0.439506   Top1 84.628906   Top5 98.546317   BatchTime 0.371532   LR 0.001501   
2022-11-25 11:43:41,023 - INFO  - Training [18][  160/  196]   Loss 0.444701   Top1 84.477539   Top5 98.508301   BatchTime 0.370629   LR 0.001482   
2022-11-25 11:43:48,503 - INFO  - Training [18][  180/  196]   Loss 0.445179   Top1 84.450955   Top5 98.424479   BatchTime 0.371007   LR 0.001462   
2022-11-25 11:43:54,497 - INFO  - ==> Top1: 84.506    Top5: 98.420    Loss: 0.445

2022-11-25 11:43:54,753 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:43:56,698 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:43:59,300 - INFO  - Validation [18][   20/   40]   Loss 0.350026   Top1 88.203125   Top5 99.453125   BatchTime 0.130054   
2022-11-25 11:44:00,398 - INFO  - Validation [18][   40/   40]   Loss 0.342978   Top1 88.590000   Top5 99.550000   BatchTime 0.092467   
2022-11-25 11:44:00,634 - INFO  - ==> Top1: 88.590    Top5: 99.550    Loss: 0.343

2022-11-25 11:44:00,635 - INFO  - ==> Sparsity : 0.270

2022-11-25 11:44:00,635 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 88.680   Top5: 99.700]
2022-11-25 11:44:00,635 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 88.590   Top5: 99.550]
2022-11-25 11:44:00,635 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 87.580   Top5: 99.450]
2022-11-25 11:44:00,756 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:44:00,758 - INFO  - >>>>>> Epoch  19
2022-11-25 11:44:00,760 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:44:09,675 - INFO  - Training [19][   20/  196]   Loss 0.448960   Top1 84.062500   Top5 97.792969   BatchTime 0.445630   LR 0.001427   
2022-11-25 11:44:17,051 - INFO  - Training [19][   40/  196]   Loss 0.440002   Top1 84.423828   Top5 98.027344   BatchTime 0.407232   LR 0.001407   
2022-11-25 11:44:24,695 - INFO  - Training [19][   60/  196]   Loss 0.436829   Top1 84.667969   Top5 98.131510   BatchTime 0.398870   LR 0.001387   
2022-11-25 11:44:32,122 - INFO  - Training [19][   80/  196]   Loss 0.433709   Top1 84.941406   Top5 98.242188   BatchTime 0.391998   LR 0.001367   
2022-11-25 11:44:38,708 - INFO  - Training [19][  100/  196]   Loss 0.426942   Top1 85.242188   Top5 98.277344   BatchTime 0.379450   LR 0.001347   
2022-11-25 11:44:45,170 - INFO  - Training [19][  120/  196]   Loss 0.423125   Top1 85.292969   Top5 98.398438   BatchTime 0.370065   LR 0.001327   
2022-11-25 11:44:52,601 - INFO  - Training [19][  140/  196]   Loss 0.422605   Top1 85.320871   Top5 98.457031   BatchTime 0.370270   LR 0.001307   
2022-11-25 11:44:59,803 - INFO  - Training [19][  160/  196]   Loss 0.427759   Top1 85.163574   Top5 98.432617   BatchTime 0.369000   LR 0.001287   
2022-11-25 11:45:07,120 - INFO  - Training [19][  180/  196]   Loss 0.426509   Top1 85.210503   Top5 98.411458   BatchTime 0.368648   LR 0.001266   
2022-11-25 11:45:13,483 - INFO  - ==> Top1: 85.250    Top5: 98.416    Loss: 0.424

2022-11-25 11:45:13,753 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:45:15,333 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:45:17,685 - INFO  - Validation [19][   20/   40]   Loss 0.347589   Top1 88.984375   Top5 99.355469   BatchTime 0.117534   
2022-11-25 11:45:18,791 - INFO  - Validation [19][   40/   40]   Loss 0.334810   Top1 88.830000   Top5 99.570000   BatchTime 0.086397   
2022-11-25 11:45:18,990 - INFO  - ==> Top1: 88.830    Top5: 99.570    Loss: 0.335

2022-11-25 11:45:18,990 - INFO  - ==> Sparsity : 0.274

2022-11-25 11:45:18,990 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 88.830   Top5: 99.570]
2022-11-25 11:45:18,991 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 88.680   Top5: 99.700]
2022-11-25 11:45:18,991 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 88.590   Top5: 99.550]
2022-11-25 11:45:24,105 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:45:24,110 - INFO  - >>>>>> Epoch  20
2022-11-25 11:45:24,113 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:45:32,539 - INFO  - Training [20][   20/  196]   Loss 0.423713   Top1 85.292969   Top5 97.988281   BatchTime 0.421182   LR 0.001231   
2022-11-25 11:45:40,598 - INFO  - Training [20][   40/  196]   Loss 0.424622   Top1 85.244141   Top5 98.300781   BatchTime 0.412064   LR 0.001211   
2022-11-25 11:45:48,151 - INFO  - Training [20][   60/  196]   Loss 0.428108   Top1 84.986979   Top5 98.346354   BatchTime 0.400591   LR 0.001191   
2022-11-25 11:45:54,918 - INFO  - Training [20][   80/  196]   Loss 0.423461   Top1 85.170898   Top5 98.491211   BatchTime 0.385030   LR 0.001171   
2022-11-25 11:46:01,091 - INFO  - Training [20][  100/  196]   Loss 0.419144   Top1 85.292969   Top5 98.496094   BatchTime 0.369754   LR 0.001151   
2022-11-25 11:46:08,085 - INFO  - Training [20][  120/  196]   Loss 0.414065   Top1 85.465495   Top5 98.551432   BatchTime 0.366412   LR 0.001131   
2022-11-25 11:46:15,741 - INFO  - Training [20][  140/  196]   Loss 0.413471   Top1 85.521763   Top5 98.610491   BatchTime 0.368750   LR 0.001111   
2022-11-25 11:46:22,931 - INFO  - Training [20][  160/  196]   Loss 0.412492   Top1 85.593262   Top5 98.620605   BatchTime 0.367595   LR 0.001091   
2022-11-25 11:46:30,510 - INFO  - Training [20][  180/  196]   Loss 0.412976   Top1 85.557726   Top5 98.580729   BatchTime 0.368853   LR 0.001071   
2022-11-25 11:46:36,368 - INFO  - ==> Top1: 85.680    Top5: 98.600    Loss: 0.410

2022-11-25 11:46:36,621 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:46:38,107 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:46:40,520 - INFO  - Validation [20][   20/   40]   Loss 0.345906   Top1 88.535156   Top5 99.570312   BatchTime 0.120563   
2022-11-25 11:46:41,640 - INFO  - Validation [20][   40/   40]   Loss 0.337411   Top1 88.500000   Top5 99.620000   BatchTime 0.088286   
2022-11-25 11:46:41,888 - INFO  - ==> Top1: 88.500    Top5: 99.620    Loss: 0.337

2022-11-25 11:46:41,889 - INFO  - ==> Sparsity : 0.273

2022-11-25 11:46:41,889 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 88.830   Top5: 99.570]
2022-11-25 11:46:41,889 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 88.680   Top5: 99.700]
2022-11-25 11:46:41,889 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 88.590   Top5: 99.550]
2022-11-25 11:46:42,012 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:46:42,013 - INFO  - >>>>>> Epoch  21
2022-11-25 11:46:42,015 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:46:50,657 - INFO  - Training [21][   20/  196]   Loss 0.417183   Top1 84.902344   Top5 98.183594   BatchTime 0.431960   LR 0.001036   
2022-11-25 11:46:58,319 - INFO  - Training [21][   40/  196]   Loss 0.424433   Top1 85.224609   Top5 98.369141   BatchTime 0.407523   LR 0.001016   
2022-11-25 11:47:05,973 - INFO  - Training [21][   60/  196]   Loss 0.414145   Top1 85.442708   Top5 98.430990   BatchTime 0.399250   LR 0.000996   
2022-11-25 11:47:12,775 - INFO  - Training [21][   80/  196]   Loss 0.412483   Top1 85.566406   Top5 98.520508   BatchTime 0.384455   LR 0.000976   
2022-11-25 11:47:18,729 - INFO  - Training [21][  100/  196]   Loss 0.406650   Top1 85.746094   Top5 98.554688   BatchTime 0.367108   LR 0.000957   
2022-11-25 11:47:25,342 - INFO  - Training [21][  120/  196]   Loss 0.400720   Top1 85.979818   Top5 98.636068   BatchTime 0.361035   LR 0.000937   
2022-11-25 11:47:32,756 - INFO  - Training [21][  140/  196]   Loss 0.398220   Top1 86.085379   Top5 98.696987   BatchTime 0.362409   LR 0.000918   
2022-11-25 11:47:39,877 - INFO  - Training [21][  160/  196]   Loss 0.401855   Top1 85.922852   Top5 98.696289   BatchTime 0.361617   LR 0.000899   
2022-11-25 11:47:47,459 - INFO  - Training [21][  180/  196]   Loss 0.399460   Top1 86.004774   Top5 98.656684   BatchTime 0.363558   LR 0.000879   
2022-11-25 11:47:53,865 - INFO  - ==> Top1: 86.024    Top5: 98.644    Loss: 0.397

2022-11-25 11:47:54,195 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:47:55,604 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:47:58,909 - INFO  - Validation [21][   20/   40]   Loss 0.389234   Top1 87.343750   Top5 99.238281   BatchTime 0.165126   
2022-11-25 11:47:59,934 - INFO  - Validation [21][   40/   40]   Loss 0.387840   Top1 87.130000   Top5 99.430000   BatchTime 0.108189   
2022-11-25 11:48:00,177 - INFO  - ==> Top1: 87.130    Top5: 99.430    Loss: 0.388

2022-11-25 11:48:00,177 - INFO  - ==> Sparsity : 0.282

2022-11-25 11:48:00,177 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 88.830   Top5: 99.570]
2022-11-25 11:48:00,178 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 88.680   Top5: 99.700]
2022-11-25 11:48:00,178 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 88.590   Top5: 99.550]
2022-11-25 11:48:00,324 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:48:00,326 - INFO  - >>>>>> Epoch  22
2022-11-25 11:48:00,328 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:48:08,828 - INFO  - Training [22][   20/  196]   Loss 0.431418   Top1 85.214844   Top5 97.832031   BatchTime 0.424831   LR 0.000846   
2022-11-25 11:48:16,534 - INFO  - Training [22][   40/  196]   Loss 0.438579   Top1 85.068359   Top5 98.242188   BatchTime 0.405096   LR 0.000827   
2022-11-25 11:48:24,298 - INFO  - Training [22][   60/  196]   Loss 0.433268   Top1 85.253906   Top5 98.320312   BatchTime 0.399455   LR 0.000808   
2022-11-25 11:48:30,950 - INFO  - Training [22][   80/  196]   Loss 0.427742   Top1 85.307617   Top5 98.481445   BatchTime 0.382742   LR 0.000789   
2022-11-25 11:48:36,742 - INFO  - Training [22][  100/  196]   Loss 0.416202   Top1 85.593750   Top5 98.531250   BatchTime 0.364109   LR 0.000770   
2022-11-25 11:48:42,903 - INFO  - Training [22][  120/  196]   Loss 0.408707   Top1 85.764974   Top5 98.603516   BatchTime 0.354770   LR 0.000752   
2022-11-25 11:48:50,168 - INFO  - Training [22][  140/  196]   Loss 0.406001   Top1 85.856585   Top5 98.655134   BatchTime 0.355976   LR 0.000734   
2022-11-25 11:48:57,457 - INFO  - Training [22][  160/  196]   Loss 0.403733   Top1 85.898438   Top5 98.691406   BatchTime 0.357038   LR 0.000715   
2022-11-25 11:49:04,873 - INFO  - Training [22][  180/  196]   Loss 0.402635   Top1 85.930990   Top5 98.648003   BatchTime 0.358564   LR 0.000697   
2022-11-25 11:49:11,093 - INFO  - ==> Top1: 86.072    Top5: 98.632    Loss: 0.399

2022-11-25 11:49:11,350 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:49:12,690 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:49:15,297 - INFO  - Validation [22][   20/   40]   Loss 0.361764   Top1 88.437500   Top5 99.472656   BatchTime 0.130258   
2022-11-25 11:49:16,347 - INFO  - Validation [22][   40/   40]   Loss 0.349713   Top1 88.570000   Top5 99.610000   BatchTime 0.091375   
2022-11-25 11:49:16,563 - INFO  - ==> Top1: 88.570    Top5: 99.610    Loss: 0.350

2022-11-25 11:49:16,564 - INFO  - ==> Sparsity : 0.276

2022-11-25 11:49:16,564 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 88.830   Top5: 99.570]
2022-11-25 11:49:16,564 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 88.680   Top5: 99.700]
2022-11-25 11:49:16,564 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 88.590   Top5: 99.550]
2022-11-25 11:49:16,703 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:49:16,705 - INFO  - >>>>>> Epoch  23
2022-11-25 11:49:16,707 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:49:25,371 - INFO  - Training [23][   20/  196]   Loss 0.405433   Top1 85.839844   Top5 98.105469   BatchTime 0.433053   LR 0.000666   
2022-11-25 11:49:33,416 - INFO  - Training [23][   40/  196]   Loss 0.396814   Top1 86.201172   Top5 98.388672   BatchTime 0.417662   LR 0.000648   
2022-11-25 11:49:40,823 - INFO  - Training [23][   60/  196]   Loss 0.395245   Top1 86.230469   Top5 98.496094   BatchTime 0.401890   LR 0.000630   
2022-11-25 11:49:48,103 - INFO  - Training [23][   80/  196]   Loss 0.392717   Top1 86.347656   Top5 98.627930   BatchTime 0.392411   LR 0.000613   
2022-11-25 11:49:53,821 - INFO  - Training [23][  100/  196]   Loss 0.383977   Top1 86.636719   Top5 98.667969   BatchTime 0.371114   LR 0.000596   
2022-11-25 11:49:59,588 - INFO  - Training [23][  120/  196]   Loss 0.379518   Top1 86.780599   Top5 98.730469   BatchTime 0.357320   LR 0.000579   
2022-11-25 11:50:06,976 - INFO  - Training [23][  140/  196]   Loss 0.375014   Top1 86.972656   Top5 98.814174   BatchTime 0.359044   LR 0.000562   
2022-11-25 11:50:14,437 - INFO  - Training [23][  160/  196]   Loss 0.377461   Top1 86.943359   Top5 98.813477   BatchTime 0.360796   LR 0.000545   
2022-11-25 11:50:21,614 - INFO  - Training [23][  180/  196]   Loss 0.378125   Top1 86.872830   Top5 98.778212   BatchTime 0.360578   LR 0.000529   
2022-11-25 11:50:27,563 - INFO  - ==> Top1: 86.876    Top5: 98.764    Loss: 0.377

2022-11-25 11:50:27,825 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:50:29,318 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:50:31,988 - INFO  - Validation [23][   20/   40]   Loss 0.350628   Top1 88.515625   Top5 99.472656   BatchTime 0.133416   
2022-11-25 11:50:33,221 - INFO  - Validation [23][   40/   40]   Loss 0.343191   Top1 88.550000   Top5 99.600000   BatchTime 0.097517   
2022-11-25 11:50:33,427 - INFO  - ==> Top1: 88.550    Top5: 99.600    Loss: 0.343

2022-11-25 11:50:33,427 - INFO  - ==> Sparsity : 0.281

2022-11-25 11:50:33,427 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 88.830   Top5: 99.570]
2022-11-25 11:50:33,427 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 88.680   Top5: 99.700]
2022-11-25 11:50:33,427 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 88.590   Top5: 99.550]
2022-11-25 11:50:33,552 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:50:33,554 - INFO  - >>>>>> Epoch  24
2022-11-25 11:50:33,555 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:50:42,566 - INFO  - Training [24][   20/  196]   Loss 0.398007   Top1 86.113281   Top5 98.007812   BatchTime 0.450251   LR 0.000500   
2022-11-25 11:50:50,499 - INFO  - Training [24][   40/  196]   Loss 0.392696   Top1 86.386719   Top5 98.369141   BatchTime 0.423427   LR 0.000484   
2022-11-25 11:50:57,852 - INFO  - Training [24][   60/  196]   Loss 0.384339   Top1 86.510417   Top5 98.457031   BatchTime 0.404846   LR 0.000468   
2022-11-25 11:51:05,312 - INFO  - Training [24][   80/  196]   Loss 0.383355   Top1 86.445312   Top5 98.540039   BatchTime 0.396877   LR 0.000453   
2022-11-25 11:51:11,460 - INFO  - Training [24][  100/  196]   Loss 0.374235   Top1 86.851562   Top5 98.621094   BatchTime 0.378979   LR 0.000437   
2022-11-25 11:51:16,963 - INFO  - Training [24][  120/  196]   Loss 0.368319   Top1 87.119141   Top5 98.707682   BatchTime 0.361679   LR 0.000422   
2022-11-25 11:51:23,607 - INFO  - Training [24][  140/  196]   Loss 0.367162   Top1 87.126116   Top5 98.775112   BatchTime 0.357467   LR 0.000407   
2022-11-25 11:51:31,129 - INFO  - Training [24][  160/  196]   Loss 0.367895   Top1 87.121582   Top5 98.754883   BatchTime 0.359791   LR 0.000392   
2022-11-25 11:51:38,487 - INFO  - Training [24][  180/  196]   Loss 0.368346   Top1 87.113715   Top5 98.730469   BatchTime 0.360696   LR 0.000378   
2022-11-25 11:51:44,457 - INFO  - ==> Top1: 87.090    Top5: 98.714    Loss: 0.369

2022-11-25 11:51:44,702 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:51:46,189 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:51:48,700 - INFO  - Validation [24][   20/   40]   Loss 0.300338   Top1 90.117188   Top5 99.531250   BatchTime 0.125406   
2022-11-25 11:51:49,761 - INFO  - Validation [24][   40/   40]   Loss 0.294660   Top1 90.230000   Top5 99.680000   BatchTime 0.089238   
2022-11-25 11:51:50,019 - INFO  - ==> Top1: 90.230    Top5: 99.680    Loss: 0.295

2022-11-25 11:51:50,019 - INFO  - ==> Sparsity : 0.308

2022-11-25 11:51:50,020 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 11:51:50,020 - INFO  - Scoreboard best 2 ==> Epoch [19][Top1: 88.830   Top5: 99.570]
2022-11-25 11:51:50,020 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 88.680   Top5: 99.700]
2022-11-25 11:51:56,088 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:51:56,094 - INFO  - >>>>>> Epoch  25
2022-11-25 11:51:56,097 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:52:04,893 - INFO  - Training [25][   20/  196]   Loss 0.380148   Top1 85.976562   Top5 98.437500   BatchTime 0.439670   LR 0.000353   
2022-11-25 11:52:12,829 - INFO  - Training [25][   40/  196]   Loss 0.382920   Top1 86.357422   Top5 98.525391   BatchTime 0.418254   LR 0.000339   
2022-11-25 11:52:20,298 - INFO  - Training [25][   60/  196]   Loss 0.377134   Top1 86.569010   Top5 98.626302   BatchTime 0.403316   LR 0.000325   
2022-11-25 11:52:27,011 - INFO  - Training [25][   80/  196]   Loss 0.371502   Top1 86.811523   Top5 98.715820   BatchTime 0.386395   LR 0.000312   
2022-11-25 11:52:33,015 - INFO  - Training [25][  100/  196]   Loss 0.363710   Top1 87.148438   Top5 98.734375   BatchTime 0.369158   LR 0.000299   
2022-11-25 11:52:39,108 - INFO  - Training [25][  120/  196]   Loss 0.358412   Top1 87.304688   Top5 98.792318   BatchTime 0.358400   LR 0.000286   
2022-11-25 11:52:46,655 - INFO  - Training [25][  140/  196]   Loss 0.356718   Top1 87.433036   Top5 98.833705   BatchTime 0.361109   LR 0.000273   
2022-11-25 11:52:54,212 - INFO  - Training [25][  160/  196]   Loss 0.357010   Top1 87.500000   Top5 98.793945   BatchTime 0.363201   LR 0.000261   
2022-11-25 11:53:01,599 - INFO  - Training [25][  180/  196]   Loss 0.357298   Top1 87.532552   Top5 98.806424   BatchTime 0.363882   LR 0.000248   
2022-11-25 11:53:07,609 - INFO  - ==> Top1: 87.628    Top5: 98.808    Loss: 0.355

2022-11-25 11:53:07,851 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:53:09,171 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:53:11,740 - INFO  - Validation [25][   20/   40]   Loss 0.314922   Top1 89.902344   Top5 99.609375   BatchTime 0.128375   
2022-11-25 11:53:12,892 - INFO  - Validation [25][   40/   40]   Loss 0.302855   Top1 90.050000   Top5 99.690000   BatchTime 0.092989   
2022-11-25 11:53:13,274 - INFO  - ==> Top1: 90.050    Top5: 99.690    Loss: 0.303

2022-11-25 11:53:13,274 - INFO  - ==> Sparsity : 0.308

2022-11-25 11:53:13,274 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 11:53:13,275 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.050   Top5: 99.690]
2022-11-25 11:53:13,275 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 88.830   Top5: 99.570]
2022-11-25 11:53:13,400 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:53:13,402 - INFO  - >>>>>> Epoch  26
2022-11-25 11:53:13,404 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:53:22,274 - INFO  - Training [26][   20/  196]   Loss 0.361853   Top1 86.972656   Top5 98.398438   BatchTime 0.443384   LR 0.000228   
2022-11-25 11:53:30,323 - INFO  - Training [26][   40/  196]   Loss 0.356325   Top1 87.324219   Top5 98.476562   BatchTime 0.422914   LR 0.000216   
2022-11-25 11:53:38,082 - INFO  - Training [26][   60/  196]   Loss 0.349969   Top1 87.643229   Top5 98.580729   BatchTime 0.411256   LR 0.000205   
2022-11-25 11:53:45,599 - INFO  - Training [26][   80/  196]   Loss 0.349557   Top1 87.739258   Top5 98.715820   BatchTime 0.402411   LR 0.000194   
2022-11-25 11:53:51,602 - INFO  - Training [26][  100/  196]   Loss 0.345801   Top1 87.847656   Top5 98.738281   BatchTime 0.381954   LR 0.000183   
2022-11-25 11:53:57,368 - INFO  - Training [26][  120/  196]   Loss 0.340274   Top1 88.020833   Top5 98.798828   BatchTime 0.366340   LR 0.000173   
2022-11-25 11:54:05,056 - INFO  - Training [26][  140/  196]   Loss 0.339477   Top1 88.077567   Top5 98.850446   BatchTime 0.368922   LR 0.000163   
2022-11-25 11:54:12,602 - INFO  - Training [26][  160/  196]   Loss 0.341855   Top1 88.039551   Top5 98.830566   BatchTime 0.369967   LR 0.000153   
2022-11-25 11:54:20,247 - INFO  - Training [26][  180/  196]   Loss 0.342392   Top1 88.027344   Top5 98.799913   BatchTime 0.371334   LR 0.000144   
2022-11-25 11:54:26,400 - INFO  - ==> Top1: 88.038    Top5: 98.806    Loss: 0.343

2022-11-25 11:54:26,670 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:54:28,149 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:54:30,639 - INFO  - Validation [26][   20/   40]   Loss 0.300569   Top1 90.664062   Top5 99.531250   BatchTime 0.124396   
2022-11-25 11:54:31,723 - INFO  - Validation [26][   40/   40]   Loss 0.293244   Top1 90.420000   Top5 99.690000   BatchTime 0.089301   
2022-11-25 11:54:32,081 - INFO  - ==> Top1: 90.420    Top5: 99.690    Loss: 0.293

2022-11-25 11:54:32,081 - INFO  - ==> Sparsity : 0.313

2022-11-25 11:54:32,081 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 11:54:32,081 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 11:54:32,082 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.050   Top5: 99.690]
2022-11-25 11:54:38,665 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:54:38,669 - INFO  - >>>>>> Epoch  27
2022-11-25 11:54:38,671 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:54:47,784 - INFO  - Training [27][   20/  196]   Loss 0.381619   Top1 86.953125   Top5 98.496094   BatchTime 0.455533   LR 0.000128   
2022-11-25 11:54:55,279 - INFO  - Training [27][   40/  196]   Loss 0.369554   Top1 87.148438   Top5 98.574219   BatchTime 0.415129   LR 0.000119   
2022-11-25 11:55:02,824 - INFO  - Training [27][   60/  196]   Loss 0.359126   Top1 87.259115   Top5 98.710938   BatchTime 0.402511   LR 0.000111   
2022-11-25 11:55:08,613 - INFO  - Training [27][   80/  196]   Loss 0.351470   Top1 87.646484   Top5 98.789062   BatchTime 0.374247   LR 0.000102   
2022-11-25 11:55:14,524 - INFO  - Training [27][  100/  196]   Loss 0.346001   Top1 87.824219   Top5 98.832031   BatchTime 0.358506   LR 0.000095   
2022-11-25 11:55:22,071 - INFO  - Training [27][  120/  196]   Loss 0.340646   Top1 88.040365   Top5 98.886719   BatchTime 0.361645   LR 0.000087   
2022-11-25 11:55:29,511 - INFO  - Training [27][  140/  196]   Loss 0.339588   Top1 88.108259   Top5 98.939732   BatchTime 0.363124   LR 0.000080   
2022-11-25 11:55:36,868 - INFO  - Training [27][  160/  196]   Loss 0.340131   Top1 88.117676   Top5 98.920898   BatchTime 0.363711   LR 0.000073   
2022-11-25 11:55:44,178 - INFO  - Training [27][  180/  196]   Loss 0.341687   Top1 88.064236   Top5 98.884549   BatchTime 0.363912   LR 0.000066   
2022-11-25 11:55:50,202 - INFO  - ==> Top1: 88.100    Top5: 98.882    Loss: 0.341

2022-11-25 11:55:50,454 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:55:51,965 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:55:54,609 - INFO  - Validation [27][   20/   40]   Loss 0.317384   Top1 89.941406   Top5 99.511719   BatchTime 0.132130   
2022-11-25 11:55:55,709 - INFO  - Validation [27][   40/   40]   Loss 0.311145   Top1 89.920000   Top5 99.630000   BatchTime 0.093559   
2022-11-25 11:55:56,111 - INFO  - ==> Top1: 89.920    Top5: 99.630    Loss: 0.311

2022-11-25 11:55:56,112 - INFO  - ==> Sparsity : 0.317

2022-11-25 11:55:56,112 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 11:55:56,112 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 11:55:56,113 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.050   Top5: 99.690]
2022-11-25 11:55:56,235 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:55:56,237 - INFO  - >>>>>> Epoch  28
2022-11-25 11:55:56,240 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:56:05,092 - INFO  - Training [28][   20/  196]   Loss 0.352678   Top1 87.109375   Top5 98.593750   BatchTime 0.442463   LR 0.000055   
2022-11-25 11:56:13,275 - INFO  - Training [28][   40/  196]   Loss 0.350223   Top1 87.294922   Top5 98.681641   BatchTime 0.425807   LR 0.000050   
2022-11-25 11:56:20,707 - INFO  - Training [28][   60/  196]   Loss 0.346677   Top1 87.643229   Top5 98.678385   BatchTime 0.407737   LR 0.000044   
2022-11-25 11:56:26,832 - INFO  - Training [28][   80/  196]   Loss 0.344476   Top1 87.836914   Top5 98.759766   BatchTime 0.382364   LR 0.000039   
2022-11-25 11:56:33,914 - INFO  - Training [28][  100/  196]   Loss 0.341457   Top1 87.917969   Top5 98.816406   BatchTime 0.376711   LR 0.000034   
2022-11-25 11:56:41,215 - INFO  - Training [28][  120/  196]   Loss 0.336224   Top1 88.144531   Top5 98.889974   BatchTime 0.374764   LR 0.000030   
2022-11-25 11:56:48,741 - INFO  - Training [28][  140/  196]   Loss 0.333111   Top1 88.306362   Top5 98.945312   BatchTime 0.374987   LR 0.000026   
2022-11-25 11:56:56,207 - INFO  - Training [28][  160/  196]   Loss 0.338621   Top1 88.105469   Top5 98.950195   BatchTime 0.374772   LR 0.000022   
2022-11-25 11:57:03,427 - INFO  - Training [28][  180/  196]   Loss 0.340463   Top1 88.046875   Top5 98.882378   BatchTime 0.373245   LR 0.000018   
2022-11-25 11:57:09,516 - INFO  - ==> Top1: 88.180    Top5: 98.886    Loss: 0.338

2022-11-25 11:57:09,762 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:57:11,224 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:57:14,118 - INFO  - Validation [28][   20/   40]   Loss 0.305847   Top1 90.253906   Top5 99.609375   BatchTime 0.144640   
2022-11-25 11:57:15,102 - INFO  - Validation [28][   40/   40]   Loss 0.294123   Top1 90.450000   Top5 99.730000   BatchTime 0.096932   
2022-11-25 11:57:15,356 - INFO  - ==> Top1: 90.450    Top5: 99.730    Loss: 0.294

2022-11-25 11:57:15,356 - INFO  - ==> Sparsity : 0.317

2022-11-25 11:57:15,357 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 11:57:15,357 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 11:57:15,357 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 11:57:20,886 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 11:57:20,897 - INFO  - >>>>>> Epoch  29
2022-11-25 11:57:20,900 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:57:30,413 - INFO  - Training [29][   20/  196]   Loss 0.354711   Top1 87.343750   Top5 98.574219   BatchTime 0.475524   LR 0.000013   
2022-11-25 11:57:37,350 - INFO  - Training [29][   40/  196]   Loss 0.354919   Top1 87.382812   Top5 98.681641   BatchTime 0.411197   LR 0.000010   
2022-11-25 11:57:43,194 - INFO  - Training [29][   60/  196]   Loss 0.360857   Top1 87.180990   Top5 98.743490   BatchTime 0.371521   LR 0.000008   
2022-11-25 11:57:49,821 - INFO  - Training [29][   80/  196]   Loss 0.358517   Top1 87.353516   Top5 98.862305   BatchTime 0.361480   LR 0.000005   
2022-11-25 11:57:57,118 - INFO  - Training [29][  100/  196]   Loss 0.348958   Top1 87.832031   Top5 98.914062   BatchTime 0.362155   LR 0.000004   
2022-11-25 11:58:04,619 - INFO  - Training [29][  120/  196]   Loss 0.344342   Top1 87.998047   Top5 98.932292   BatchTime 0.364305   LR 0.000002   
2022-11-25 11:58:11,938 - INFO  - Training [29][  140/  196]   Loss 0.343746   Top1 88.035714   Top5 98.959263   BatchTime 0.364538   LR 0.000001   
2022-11-25 11:58:19,220 - INFO  - Training [29][  160/  196]   Loss 0.345787   Top1 87.924805   Top5 98.947754   BatchTime 0.364486   LR 0.000001   
2022-11-25 11:58:26,735 - INFO  - Training [29][  180/  196]   Loss 0.345840   Top1 87.936198   Top5 98.871528   BatchTime 0.365734   LR 0.000000   
2022-11-25 11:58:32,709 - INFO  - ==> Top1: 87.960    Top5: 98.852    Loss: 0.345

2022-11-25 11:58:32,976 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:58:34,413 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:58:36,860 - INFO  - Validation [29][   20/   40]   Loss 0.311966   Top1 89.863281   Top5 99.453125   BatchTime 0.122293   
2022-11-25 11:58:37,999 - INFO  - Validation [29][   40/   40]   Loss 0.305643   Top1 90.010000   Top5 99.610000   BatchTime 0.089609   
2022-11-25 11:58:38,211 - INFO  - ==> Top1: 90.010    Top5: 99.610    Loss: 0.306

2022-11-25 11:58:38,212 - INFO  - ==> Sparsity : 0.318

2022-11-25 11:58:38,212 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 11:58:38,212 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 11:58:38,212 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 11:58:38,591 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:58:38,593 - INFO  - >>>>>> Epoch  30
2022-11-25 11:58:38,594 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:58:46,737 - INFO  - Training [30][   20/  196]   Loss 0.374096   Top1 87.070312   Top5 98.164062   BatchTime 0.406990   LR 0.001250   
2022-11-25 11:58:54,541 - INFO  - Training [30][   40/  196]   Loss 0.380244   Top1 86.816406   Top5 98.476562   BatchTime 0.398596   LR 0.001250   
2022-11-25 11:59:00,793 - INFO  - Training [30][   60/  196]   Loss 0.383836   Top1 86.660156   Top5 98.522135   BatchTime 0.369919   LR 0.001250   
2022-11-25 11:59:08,370 - INFO  - Training [30][   80/  196]   Loss 0.387005   Top1 86.689453   Top5 98.662109   BatchTime 0.372157   LR 0.001250   
2022-11-25 11:59:15,811 - INFO  - Training [30][  100/  196]   Loss 0.384448   Top1 86.757812   Top5 98.679688   BatchTime 0.372134   LR 0.001250   
2022-11-25 11:59:23,436 - INFO  - Training [30][  120/  196]   Loss 0.382455   Top1 86.842448   Top5 98.756510   BatchTime 0.373650   LR 0.001249   
2022-11-25 11:59:30,571 - INFO  - Training [30][  140/  196]   Loss 0.382134   Top1 86.880580   Top5 98.797433   BatchTime 0.371235   LR 0.001249   
2022-11-25 11:59:37,817 - INFO  - Training [30][  160/  196]   Loss 0.386555   Top1 86.687012   Top5 98.784180   BatchTime 0.370120   LR 0.001249   
2022-11-25 11:59:45,301 - INFO  - Training [30][  180/  196]   Loss 0.388489   Top1 86.540799   Top5 98.747830   BatchTime 0.370572   LR 0.001248   
2022-11-25 11:59:51,216 - INFO  - ==> Top1: 86.496    Top5: 98.710    Loss: 0.390

2022-11-25 11:59:51,459 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:59:52,881 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:59:55,296 - INFO  - Validation [30][   20/   40]   Loss 0.390860   Top1 87.871094   Top5 99.550781   BatchTime 0.120659   
2022-11-25 11:59:56,423 - INFO  - Validation [30][   40/   40]   Loss 0.377415   Top1 87.790000   Top5 99.570000   BatchTime 0.088511   
2022-11-25 11:59:56,661 - INFO  - ==> Top1: 87.790    Top5: 99.570    Loss: 0.377

2022-11-25 11:59:56,662 - INFO  - ==> Sparsity : 0.275

2022-11-25 11:59:56,662 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 11:59:56,662 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 11:59:56,662 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 11:59:56,783 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 11:59:56,784 - INFO  - >>>>>> Epoch  31
2022-11-25 11:59:56,786 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:00:05,811 - INFO  - Training [31][   20/  196]   Loss 0.420186   Top1 84.960938   Top5 98.320312   BatchTime 0.451096   LR 0.001248   
2022-11-25 12:00:12,188 - INFO  - Training [31][   40/  196]   Loss 0.418933   Top1 85.380859   Top5 98.466797   BatchTime 0.384989   LR 0.001247   
2022-11-25 12:00:20,119 - INFO  - Training [31][   60/  196]   Loss 0.408934   Top1 85.677083   Top5 98.580729   BatchTime 0.388840   LR 0.001247   
2022-11-25 12:00:27,842 - INFO  - Training [31][   80/  196]   Loss 0.403531   Top1 85.937500   Top5 98.657227   BatchTime 0.388155   LR 0.001246   
2022-11-25 12:00:35,167 - INFO  - Training [31][  100/  196]   Loss 0.395764   Top1 86.101562   Top5 98.683594   BatchTime 0.383782   LR 0.001246   
2022-11-25 12:00:42,391 - INFO  - Training [31][  120/  196]   Loss 0.390820   Top1 86.269531   Top5 98.727214   BatchTime 0.380018   LR 0.001245   
2022-11-25 12:00:49,768 - INFO  - Training [31][  140/  196]   Loss 0.389034   Top1 86.336496   Top5 98.775112   BatchTime 0.378421   LR 0.001244   
2022-11-25 12:00:56,978 - INFO  - Training [31][  160/  196]   Loss 0.392096   Top1 86.279297   Top5 98.762207   BatchTime 0.376181   LR 0.001244   
2022-11-25 12:01:04,343 - INFO  - Training [31][  180/  196]   Loss 0.392710   Top1 86.215278   Top5 98.721788   BatchTime 0.375298   LR 0.001243   
2022-11-25 12:01:10,321 - INFO  - ==> Top1: 86.218    Top5: 98.730    Loss: 0.393

2022-11-25 12:01:10,588 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:01:12,272 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:01:15,053 - INFO  - Validation [31][   20/   40]   Loss 0.354286   Top1 88.476562   Top5 99.433594   BatchTime 0.138976   
2022-11-25 12:01:16,202 - INFO  - Validation [31][   40/   40]   Loss 0.349807   Top1 88.420000   Top5 99.530000   BatchTime 0.098215   
2022-11-25 12:01:16,435 - INFO  - ==> Top1: 88.420    Top5: 99.530    Loss: 0.350

2022-11-25 12:01:16,435 - INFO  - ==> Sparsity : 0.299

2022-11-25 12:01:16,435 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:01:16,435 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:01:16,436 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:01:16,573 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:01:16,575 - INFO  - >>>>>> Epoch  32
2022-11-25 12:01:16,576 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:01:24,581 - INFO  - Training [32][   20/  196]   Loss 0.416367   Top1 85.878906   Top5 97.968750   BatchTime 0.400085   LR 0.001242   
2022-11-25 12:01:31,248 - INFO  - Training [32][   40/  196]   Loss 0.403604   Top1 86.113281   Top5 98.378906   BatchTime 0.366712   LR 0.001241   
2022-11-25 12:01:39,462 - INFO  - Training [32][   60/  196]   Loss 0.409419   Top1 85.859375   Top5 98.430990   BatchTime 0.381375   LR 0.001240   
2022-11-25 12:01:46,856 - INFO  - Training [32][   80/  196]   Loss 0.408052   Top1 85.820312   Top5 98.530273   BatchTime 0.378453   LR 0.001239   
2022-11-25 12:01:54,263 - INFO  - Training [32][  100/  196]   Loss 0.400917   Top1 85.945312   Top5 98.636719   BatchTime 0.376833   LR 0.001238   
2022-11-25 12:02:01,994 - INFO  - Training [32][  120/  196]   Loss 0.396198   Top1 86.116536   Top5 98.704427   BatchTime 0.378451   LR 0.001237   
2022-11-25 12:02:09,625 - INFO  - Training [32][  140/  196]   Loss 0.391509   Top1 86.291853   Top5 98.775112   BatchTime 0.378892   LR 0.001236   
2022-11-25 12:02:17,099 - INFO  - Training [32][  160/  196]   Loss 0.393831   Top1 86.225586   Top5 98.752441   BatchTime 0.378248   LR 0.001235   
2022-11-25 12:02:24,507 - INFO  - Training [32][  180/  196]   Loss 0.394217   Top1 86.219618   Top5 98.704427   BatchTime 0.377373   LR 0.001234   
2022-11-25 12:02:30,587 - INFO  - ==> Top1: 86.182    Top5: 98.692    Loss: 0.394

2022-11-25 12:02:30,825 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:02:32,424 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:02:35,023 - INFO  - Validation [32][   20/   40]   Loss 0.345877   Top1 88.496094   Top5 99.492188   BatchTime 0.129828   
2022-11-25 12:02:36,136 - INFO  - Validation [32][   40/   40]   Loss 0.338766   Top1 88.310000   Top5 99.570000   BatchTime 0.092758   
2022-11-25 12:02:36,424 - INFO  - ==> Top1: 88.310    Top5: 99.570    Loss: 0.339

2022-11-25 12:02:36,424 - INFO  - ==> Sparsity : 0.299

2022-11-25 12:02:36,425 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:02:36,425 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:02:36,425 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:02:36,547 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:02:36,549 - INFO  - >>>>>> Epoch  33
2022-11-25 12:02:36,551 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:02:43,729 - INFO  - Training [33][   20/  196]   Loss 0.415006   Top1 85.546875   Top5 98.339844   BatchTime 0.358763   LR 0.001232   
2022-11-25 12:02:51,049 - INFO  - Training [33][   40/  196]   Loss 0.410317   Top1 85.527344   Top5 98.378906   BatchTime 0.362390   LR 0.001230   
2022-11-25 12:02:59,227 - INFO  - Training [33][   60/  196]   Loss 0.404388   Top1 85.820312   Top5 98.509115   BatchTime 0.377899   LR 0.001229   
2022-11-25 12:03:06,509 - INFO  - Training [33][   80/  196]   Loss 0.404855   Top1 85.917969   Top5 98.579102   BatchTime 0.374439   LR 0.001228   
2022-11-25 12:03:13,848 - INFO  - Training [33][  100/  196]   Loss 0.400162   Top1 86.050781   Top5 98.625000   BatchTime 0.372948   LR 0.001226   
2022-11-25 12:03:21,476 - INFO  - Training [33][  120/  196]   Loss 0.395840   Top1 86.266276   Top5 98.697917   BatchTime 0.374352   LR 0.001225   
2022-11-25 12:03:29,112 - INFO  - Training [33][  140/  196]   Loss 0.395179   Top1 86.314174   Top5 98.730469   BatchTime 0.375417   LR 0.001224   
2022-11-25 12:03:36,503 - INFO  - Training [33][  160/  196]   Loss 0.395463   Top1 86.325684   Top5 98.757324   BatchTime 0.374682   LR 0.001222   
2022-11-25 12:03:43,825 - INFO  - Training [33][  180/  196]   Loss 0.398062   Top1 86.226128   Top5 98.695747   BatchTime 0.373726   LR 0.001221   
2022-11-25 12:03:49,735 - INFO  - ==> Top1: 86.210    Top5: 98.684    Loss: 0.397

2022-11-25 12:03:50,004 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:03:51,424 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:03:53,891 - INFO  - Validation [33][   20/   40]   Loss 0.333697   Top1 89.648438   Top5 99.550781   BatchTime 0.123267   
2022-11-25 12:03:55,127 - INFO  - Validation [33][   40/   40]   Loss 0.319785   Top1 89.600000   Top5 99.720000   BatchTime 0.092539   
2022-11-25 12:03:55,372 - INFO  - ==> Top1: 89.600    Top5: 99.720    Loss: 0.320

2022-11-25 12:03:55,372 - INFO  - ==> Sparsity : 0.291

2022-11-25 12:03:55,372 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:03:55,373 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:03:55,373 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:03:55,503 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:03:55,505 - INFO  - >>>>>> Epoch  34
2022-11-25 12:03:55,507 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:04:03,645 - INFO  - Training [34][   20/  196]   Loss 0.390714   Top1 86.562500   Top5 97.988281   BatchTime 0.406774   LR 0.001218   
2022-11-25 12:04:10,925 - INFO  - Training [34][   40/  196]   Loss 0.394000   Top1 86.201172   Top5 98.242188   BatchTime 0.385376   LR 0.001216   
2022-11-25 12:04:19,110 - INFO  - Training [34][   60/  196]   Loss 0.390526   Top1 86.269531   Top5 98.378906   BatchTime 0.393327   LR 0.001215   
2022-11-25 12:04:26,723 - INFO  - Training [34][   80/  196]   Loss 0.390811   Top1 86.318359   Top5 98.525391   BatchTime 0.390166   LR 0.001213   
2022-11-25 12:04:34,234 - INFO  - Training [34][  100/  196]   Loss 0.383641   Top1 86.558594   Top5 98.589844   BatchTime 0.387237   LR 0.001211   
2022-11-25 12:04:41,778 - INFO  - Training [34][  120/  196]   Loss 0.376850   Top1 86.793620   Top5 98.704427   BatchTime 0.385568   LR 0.001209   
2022-11-25 12:04:49,153 - INFO  - Training [34][  140/  196]   Loss 0.375706   Top1 86.883371   Top5 98.738839   BatchTime 0.383164   LR 0.001208   
2022-11-25 12:04:56,640 - INFO  - Training [34][  160/  196]   Loss 0.381995   Top1 86.701660   Top5 98.715820   BatchTime 0.382061   LR 0.001206   
2022-11-25 12:05:04,190 - INFO  - Training [34][  180/  196]   Loss 0.381852   Top1 86.710069   Top5 98.667535   BatchTime 0.381553   LR 0.001204   
2022-11-25 12:05:09,896 - INFO  - ==> Top1: 86.698    Top5: 98.656    Loss: 0.382

2022-11-25 12:05:10,108 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:05:11,253 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:05:14,640 - INFO  - Validation [34][   20/   40]   Loss 0.363096   Top1 88.750000   Top5 99.453125   BatchTime 0.169272   
2022-11-25 12:05:16,224 - INFO  - Validation [34][   40/   40]   Loss 0.355020   Top1 88.690000   Top5 99.560000   BatchTime 0.124230   
2022-11-25 12:05:16,446 - INFO  - ==> Top1: 88.690    Top5: 99.560    Loss: 0.355

2022-11-25 12:05:16,446 - INFO  - ==> Sparsity : 0.271

2022-11-25 12:05:16,447 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:05:16,447 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:05:16,447 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:05:16,766 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:05:16,767 - INFO  - >>>>>> Epoch  35
2022-11-25 12:05:16,769 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:05:25,260 - INFO  - Training [35][   20/  196]   Loss 0.385291   Top1 86.777344   Top5 98.417969   BatchTime 0.424419   LR 0.001201   
2022-11-25 12:05:32,854 - INFO  - Training [35][   40/  196]   Loss 0.394820   Top1 86.230469   Top5 98.398438   BatchTime 0.402067   LR 0.001199   
2022-11-25 12:05:41,228 - INFO  - Training [35][   60/  196]   Loss 0.395083   Top1 86.276042   Top5 98.457031   BatchTime 0.407607   LR 0.001197   
2022-11-25 12:05:48,343 - INFO  - Training [35][   80/  196]   Loss 0.391563   Top1 86.538086   Top5 98.554688   BatchTime 0.394644   LR 0.001195   
2022-11-25 12:05:55,836 - INFO  - Training [35][  100/  196]   Loss 0.383093   Top1 86.847656   Top5 98.632812   BatchTime 0.390640   LR 0.001192   
2022-11-25 12:06:03,100 - INFO  - Training [35][  120/  196]   Loss 0.378060   Top1 86.988932   Top5 98.694661   BatchTime 0.386065   LR 0.001190   
2022-11-25 12:06:10,456 - INFO  - Training [35][  140/  196]   Loss 0.376868   Top1 87.047991   Top5 98.758371   BatchTime 0.383457   LR 0.001188   
2022-11-25 12:06:17,939 - INFO  - Training [35][  160/  196]   Loss 0.380277   Top1 86.914062   Top5 98.757324   BatchTime 0.382295   LR 0.001186   
2022-11-25 12:06:25,336 - INFO  - Training [35][  180/  196]   Loss 0.381185   Top1 86.931424   Top5 98.691406   BatchTime 0.380910   LR 0.001184   
2022-11-25 12:06:30,470 - INFO  - ==> Top1: 86.964    Top5: 98.676    Loss: 0.380

2022-11-25 12:06:30,678 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:06:31,894 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:06:34,806 - INFO  - Validation [35][   20/   40]   Loss 0.328358   Top1 89.257812   Top5 99.531250   BatchTime 0.145478   
2022-11-25 12:06:35,873 - INFO  - Validation [35][   40/   40]   Loss 0.324260   Top1 89.320000   Top5 99.630000   BatchTime 0.099444   
2022-11-25 12:06:36,093 - INFO  - ==> Top1: 89.320    Top5: 99.630    Loss: 0.324

2022-11-25 12:06:36,093 - INFO  - ==> Sparsity : 0.308

2022-11-25 12:06:36,093 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:06:36,094 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:06:36,094 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:06:36,229 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:06:36,230 - INFO  - >>>>>> Epoch  36
2022-11-25 12:06:36,232 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:06:45,338 - INFO  - Training [36][   20/  196]   Loss 0.397306   Top1 85.742188   Top5 98.339844   BatchTime 0.455159   LR 0.001180   
2022-11-25 12:06:53,130 - INFO  - Training [36][   40/  196]   Loss 0.404043   Top1 85.898438   Top5 98.417969   BatchTime 0.422389   LR 0.001177   
2022-11-25 12:07:00,663 - INFO  - Training [36][   60/  196]   Loss 0.397824   Top1 85.957031   Top5 98.606771   BatchTime 0.407140   LR 0.001175   
2022-11-25 12:07:08,059 - INFO  - Training [36][   80/  196]   Loss 0.397894   Top1 85.898438   Top5 98.681641   BatchTime 0.397802   LR 0.001173   
2022-11-25 12:07:15,585 - INFO  - Training [36][  100/  196]   Loss 0.386453   Top1 86.394531   Top5 98.730469   BatchTime 0.393501   LR 0.001170   
2022-11-25 12:07:23,252 - INFO  - Training [36][  120/  196]   Loss 0.380343   Top1 86.588542   Top5 98.792318   BatchTime 0.391802   LR 0.001168   
2022-11-25 12:07:30,605 - INFO  - Training [36][  140/  196]   Loss 0.378163   Top1 86.682478   Top5 98.864397   BatchTime 0.388354   LR 0.001165   
2022-11-25 12:07:37,893 - INFO  - Training [36][  160/  196]   Loss 0.381428   Top1 86.582031   Top5 98.823242   BatchTime 0.385359   LR 0.001163   
2022-11-25 12:07:43,948 - INFO  - Training [36][  180/  196]   Loss 0.380305   Top1 86.627604   Top5 98.789062   BatchTime 0.376178   LR 0.001160   
2022-11-25 12:07:48,615 - INFO  - ==> Top1: 86.682    Top5: 98.800    Loss: 0.378

2022-11-25 12:07:48,895 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:07:50,687 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:07:53,212 - INFO  - Validation [36][   20/   40]   Loss 0.690736   Top1 78.632812   Top5 98.593750   BatchTime 0.126154   
2022-11-25 12:07:54,285 - INFO  - Validation [36][   40/   40]   Loss 0.684880   Top1 78.790000   Top5 98.700000   BatchTime 0.089924   
2022-11-25 12:07:54,570 - INFO  - ==> Top1: 78.790    Top5: 98.700    Loss: 0.685

2022-11-25 12:07:54,571 - INFO  - ==> Sparsity : 0.290

2022-11-25 12:07:54,571 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:07:54,571 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:07:54,571 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:07:54,691 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:07:54,693 - INFO  - >>>>>> Epoch  37
2022-11-25 12:07:54,695 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:08:03,328 - INFO  - Training [37][   20/  196]   Loss 0.373928   Top1 86.660156   Top5 98.203125   BatchTime 0.431506   LR 0.001155   
2022-11-25 12:08:10,646 - INFO  - Training [37][   40/  196]   Loss 0.386980   Top1 86.328125   Top5 98.466797   BatchTime 0.398718   LR 0.001153   
2022-11-25 12:08:18,692 - INFO  - Training [37][   60/  196]   Loss 0.382098   Top1 86.608073   Top5 98.541667   BatchTime 0.399898   LR 0.001150   
2022-11-25 12:08:26,219 - INFO  - Training [37][   80/  196]   Loss 0.382769   Top1 86.679688   Top5 98.715820   BatchTime 0.394014   LR 0.001147   
2022-11-25 12:08:33,527 - INFO  - Training [37][  100/  196]   Loss 0.377446   Top1 86.855469   Top5 98.750000   BatchTime 0.388294   LR 0.001144   
2022-11-25 12:08:40,889 - INFO  - Training [37][  120/  196]   Loss 0.373448   Top1 86.917318   Top5 98.837891   BatchTime 0.384926   LR 0.001142   
2022-11-25 12:08:48,289 - INFO  - Training [37][  140/  196]   Loss 0.372505   Top1 86.944754   Top5 98.883929   BatchTime 0.382794   LR 0.001139   
2022-11-25 12:08:55,380 - INFO  - Training [37][  160/  196]   Loss 0.374759   Top1 86.928711   Top5 98.845215   BatchTime 0.379262   LR 0.001136   
2022-11-25 12:09:01,259 - INFO  - Training [37][  180/  196]   Loss 0.375870   Top1 86.907552   Top5 98.773872   BatchTime 0.369785   LR 0.001133   
2022-11-25 12:09:07,152 - INFO  - ==> Top1: 86.918    Top5: 98.768    Loss: 0.375

2022-11-25 12:09:07,432 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:09:08,866 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:09:11,615 - INFO  - Validation [37][   20/   40]   Loss 0.348761   Top1 88.886719   Top5 99.589844   BatchTime 0.137375   
2022-11-25 12:09:12,760 - INFO  - Validation [37][   40/   40]   Loss 0.336401   Top1 89.040000   Top5 99.660000   BatchTime 0.097307   
2022-11-25 12:09:13,009 - INFO  - ==> Top1: 89.040    Top5: 99.660    Loss: 0.336

2022-11-25 12:09:13,010 - INFO  - ==> Sparsity : 0.306

2022-11-25 12:09:13,010 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:09:13,011 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:09:13,011 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:09:13,149 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:09:13,151 - INFO  - >>>>>> Epoch  38
2022-11-25 12:09:13,153 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:09:21,822 - INFO  - Training [38][   20/  196]   Loss 0.390799   Top1 86.347656   Top5 98.320312   BatchTime 0.433324   LR 0.001128   
2022-11-25 12:09:29,540 - INFO  - Training [38][   40/  196]   Loss 0.395379   Top1 86.318359   Top5 98.388672   BatchTime 0.409630   LR 0.001125   
2022-11-25 12:09:37,763 - INFO  - Training [38][   60/  196]   Loss 0.383668   Top1 86.595052   Top5 98.561198   BatchTime 0.410133   LR 0.001122   
2022-11-25 12:09:45,165 - INFO  - Training [38][   80/  196]   Loss 0.380314   Top1 86.801758   Top5 98.627930   BatchTime 0.400117   LR 0.001119   
2022-11-25 12:09:52,490 - INFO  - Training [38][  100/  196]   Loss 0.376625   Top1 86.980469   Top5 98.683594   BatchTime 0.393341   LR 0.001116   
2022-11-25 12:09:59,686 - INFO  - Training [38][  120/  196]   Loss 0.370082   Top1 87.259115   Top5 98.746745   BatchTime 0.387756   LR 0.001112   
2022-11-25 12:10:06,928 - INFO  - Training [38][  140/  196]   Loss 0.368699   Top1 87.248884   Top5 98.803013   BatchTime 0.384085   LR 0.001109   
2022-11-25 12:10:13,498 - INFO  - Training [38][  160/  196]   Loss 0.371290   Top1 87.172852   Top5 98.818359   BatchTime 0.377139   LR 0.001106   
2022-11-25 12:10:19,603 - INFO  - Training [38][  180/  196]   Loss 0.371978   Top1 87.118056   Top5 98.793403   BatchTime 0.369148   LR 0.001103   
2022-11-25 12:10:25,841 - INFO  - ==> Top1: 87.196    Top5: 98.782    Loss: 0.369

2022-11-25 12:10:26,099 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:10:27,598 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:10:30,017 - INFO  - Validation [38][   20/   40]   Loss 0.366080   Top1 88.261719   Top5 99.472656   BatchTime 0.120862   
2022-11-25 12:10:31,218 - INFO  - Validation [38][   40/   40]   Loss 0.364134   Top1 88.160000   Top5 99.540000   BatchTime 0.090459   
2022-11-25 12:10:31,433 - INFO  - ==> Top1: 88.160    Top5: 99.540    Loss: 0.364

2022-11-25 12:10:31,434 - INFO  - ==> Sparsity : 0.316

2022-11-25 12:10:31,434 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:10:31,434 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:10:31,434 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:10:31,556 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:10:31,557 - INFO  - >>>>>> Epoch  39
2022-11-25 12:10:31,559 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:10:40,340 - INFO  - Training [39][   20/  196]   Loss 0.377316   Top1 86.640625   Top5 98.457031   BatchTime 0.438919   LR 0.001097   
2022-11-25 12:10:48,245 - INFO  - Training [39][   40/  196]   Loss 0.374212   Top1 86.953125   Top5 98.564453   BatchTime 0.417084   LR 0.001094   
2022-11-25 12:10:56,023 - INFO  - Training [39][   60/  196]   Loss 0.379316   Top1 86.816406   Top5 98.593750   BatchTime 0.407681   LR 0.001090   
2022-11-25 12:11:03,484 - INFO  - Training [39][   80/  196]   Loss 0.380287   Top1 86.870117   Top5 98.691406   BatchTime 0.399029   LR 0.001087   
2022-11-25 12:11:11,096 - INFO  - Training [39][  100/  196]   Loss 0.375913   Top1 87.000000   Top5 98.757812   BatchTime 0.395335   LR 0.001084   
2022-11-25 12:11:18,792 - INFO  - Training [39][  120/  196]   Loss 0.371519   Top1 87.190755   Top5 98.808594   BatchTime 0.393584   LR 0.001080   
2022-11-25 12:11:26,004 - INFO  - Training [39][  140/  196]   Loss 0.369202   Top1 87.184710   Top5 98.847656   BatchTime 0.388869   LR 0.001077   
2022-11-25 12:11:31,979 - INFO  - Training [39][  160/  196]   Loss 0.372955   Top1 87.001953   Top5 98.818359   BatchTime 0.377604   LR 0.001073   
2022-11-25 12:11:39,039 - INFO  - Training [39][  180/  196]   Loss 0.373383   Top1 86.955295   Top5 98.776042   BatchTime 0.374868   LR 0.001070   
2022-11-25 12:11:45,105 - INFO  - ==> Top1: 86.998    Top5: 98.760    Loss: 0.371

2022-11-25 12:11:45,363 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:11:46,670 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:11:49,191 - INFO  - Validation [39][   20/   40]   Loss 0.330430   Top1 89.316406   Top5 99.550781   BatchTime 0.125945   
2022-11-25 12:11:50,213 - INFO  - Validation [39][   40/   40]   Loss 0.321867   Top1 89.190000   Top5 99.660000   BatchTime 0.088526   
2022-11-25 12:11:50,466 - INFO  - ==> Top1: 89.190    Top5: 99.660    Loss: 0.322

2022-11-25 12:11:50,466 - INFO  - ==> Sparsity : 0.292

2022-11-25 12:11:50,466 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:11:50,467 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:11:50,467 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:11:50,590 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:11:50,591 - INFO  - >>>>>> Epoch  40
2022-11-25 12:11:50,593 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:11:59,903 - INFO  - Training [40][   20/  196]   Loss 0.367029   Top1 87.558594   Top5 98.007812   BatchTime 0.465382   LR 0.001064   
2022-11-25 12:12:07,695 - INFO  - Training [40][   40/  196]   Loss 0.375690   Top1 87.070312   Top5 98.369141   BatchTime 0.427476   LR 0.001060   
2022-11-25 12:12:15,545 - INFO  - Training [40][   60/  196]   Loss 0.372996   Top1 87.102865   Top5 98.489583   BatchTime 0.415819   LR 0.001056   
2022-11-25 12:12:22,996 - INFO  - Training [40][   80/  196]   Loss 0.372834   Top1 87.099609   Top5 98.632812   BatchTime 0.404997   LR 0.001053   
2022-11-25 12:12:30,374 - INFO  - Training [40][  100/  196]   Loss 0.370261   Top1 87.164062   Top5 98.707031   BatchTime 0.397781   LR 0.001049   
2022-11-25 12:12:37,851 - INFO  - Training [40][  120/  196]   Loss 0.368724   Top1 87.180990   Top5 98.750000   BatchTime 0.393791   LR 0.001045   
2022-11-25 12:12:44,384 - INFO  - Training [40][  140/  196]   Loss 0.365147   Top1 87.324219   Top5 98.780692   BatchTime 0.384200   LR 0.001042   
2022-11-25 12:12:50,977 - INFO  - Training [40][  160/  196]   Loss 0.368683   Top1 87.214355   Top5 98.781738   BatchTime 0.377377   LR 0.001038   
2022-11-25 12:12:58,233 - INFO  - Training [40][  180/  196]   Loss 0.368523   Top1 87.194010   Top5 98.745660   BatchTime 0.375755   LR 0.001034   
2022-11-25 12:13:04,064 - INFO  - ==> Top1: 87.186    Top5: 98.746    Loss: 0.368

2022-11-25 12:13:04,317 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:13:05,625 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:13:08,128 - INFO  - Validation [40][   20/   40]   Loss 0.329519   Top1 88.867188   Top5 99.648438   BatchTime 0.125030   
2022-11-25 12:13:09,185 - INFO  - Validation [40][   40/   40]   Loss 0.321460   Top1 89.180000   Top5 99.690000   BatchTime 0.088950   
2022-11-25 12:13:09,414 - INFO  - ==> Top1: 89.180    Top5: 99.690    Loss: 0.321

2022-11-25 12:13:09,414 - INFO  - ==> Sparsity : 0.308

2022-11-25 12:13:09,414 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:13:09,415 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:13:09,415 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:13:09,536 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:13:09,538 - INFO  - >>>>>> Epoch  41
2022-11-25 12:13:09,540 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:13:18,491 - INFO  - Training [41][   20/  196]   Loss 0.377069   Top1 86.660156   Top5 98.457031   BatchTime 0.447462   LR 0.001027   
2022-11-25 12:13:25,787 - INFO  - Training [41][   40/  196]   Loss 0.371509   Top1 86.875000   Top5 98.535156   BatchTime 0.406123   LR 0.001023   
2022-11-25 12:13:33,289 - INFO  - Training [41][   60/  196]   Loss 0.364331   Top1 87.226562   Top5 98.626302   BatchTime 0.395772   LR 0.001020   
2022-11-25 12:13:40,672 - INFO  - Training [41][   80/  196]   Loss 0.357141   Top1 87.539062   Top5 98.740234   BatchTime 0.389123   LR 0.001016   
2022-11-25 12:13:48,011 - INFO  - Training [41][  100/  196]   Loss 0.352533   Top1 87.675781   Top5 98.730469   BatchTime 0.384683   LR 0.001012   
2022-11-25 12:13:55,373 - INFO  - Training [41][  120/  196]   Loss 0.349725   Top1 87.724609   Top5 98.789062   BatchTime 0.381919   LR 0.001008   
2022-11-25 12:14:01,310 - INFO  - Training [41][  140/  196]   Loss 0.349292   Top1 87.756696   Top5 98.842076   BatchTime 0.369770   LR 0.001004   
2022-11-25 12:14:08,476 - INFO  - Training [41][  160/  196]   Loss 0.352539   Top1 87.644043   Top5 98.823242   BatchTime 0.368334   LR 0.001000   
2022-11-25 12:14:15,816 - INFO  - Training [41][  180/  196]   Loss 0.353503   Top1 87.610677   Top5 98.773872   BatchTime 0.368187   LR 0.000996   
2022-11-25 12:14:21,790 - INFO  - ==> Top1: 87.684    Top5: 98.770    Loss: 0.352

2022-11-25 12:14:22,017 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:14:23,568 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:14:26,280 - INFO  - Validation [41][   20/   40]   Loss 0.326083   Top1 89.765625   Top5 99.550781   BatchTime 0.135462   
2022-11-25 12:14:27,525 - INFO  - Validation [41][   40/   40]   Loss 0.314493   Top1 89.870000   Top5 99.650000   BatchTime 0.098862   
2022-11-25 12:14:27,830 - INFO  - ==> Top1: 89.870    Top5: 99.650    Loss: 0.314

2022-11-25 12:14:27,830 - INFO  - ==> Sparsity : 0.314

2022-11-25 12:14:27,830 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:14:27,830 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:14:27,831 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:14:27,950 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:14:27,952 - INFO  - >>>>>> Epoch  42
2022-11-25 12:14:27,954 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:14:37,280 - INFO  - Training [42][   20/  196]   Loss 0.372776   Top1 87.402344   Top5 97.988281   BatchTime 0.466169   LR 0.000988   
2022-11-25 12:14:44,610 - INFO  - Training [42][   40/  196]   Loss 0.375396   Top1 87.158203   Top5 98.339844   BatchTime 0.416357   LR 0.000984   
2022-11-25 12:14:52,122 - INFO  - Training [42][   60/  196]   Loss 0.368708   Top1 87.317708   Top5 98.496094   BatchTime 0.402770   LR 0.000980   
2022-11-25 12:14:59,261 - INFO  - Training [42][   80/  196]   Loss 0.364356   Top1 87.451172   Top5 98.676758   BatchTime 0.391302   LR 0.000976   
2022-11-25 12:15:06,946 - INFO  - Training [42][  100/  196]   Loss 0.360604   Top1 87.554688   Top5 98.703125   BatchTime 0.389897   LR 0.000972   
2022-11-25 12:15:13,294 - INFO  - Training [42][  120/  196]   Loss 0.353191   Top1 87.766927   Top5 98.805339   BatchTime 0.377812   LR 0.000968   
2022-11-25 12:15:19,304 - INFO  - Training [42][  140/  196]   Loss 0.352277   Top1 87.795759   Top5 98.867188   BatchTime 0.366765   LR 0.000964   
2022-11-25 12:15:26,189 - INFO  - Training [42][  160/  196]   Loss 0.352075   Top1 87.783203   Top5 98.872070   BatchTime 0.363951   LR 0.000959   
2022-11-25 12:15:33,588 - INFO  - Training [42][  180/  196]   Loss 0.352068   Top1 87.760417   Top5 98.843316   BatchTime 0.364616   LR 0.000955   
2022-11-25 12:15:39,723 - INFO  - ==> Top1: 87.746    Top5: 98.860    Loss: 0.351

2022-11-25 12:15:39,948 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:15:41,247 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:15:43,702 - INFO  - Validation [42][   20/   40]   Loss 0.482005   Top1 84.863281   Top5 99.218750   BatchTime 0.122672   
2022-11-25 12:15:44,934 - INFO  - Validation [42][   40/   40]   Loss 0.478968   Top1 84.730000   Top5 99.270000   BatchTime 0.092128   
2022-11-25 12:15:45,178 - INFO  - ==> Top1: 84.730    Top5: 99.270    Loss: 0.479

2022-11-25 12:15:45,178 - INFO  - ==> Sparsity : 0.324

2022-11-25 12:15:45,179 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:15:45,179 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:15:45,179 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.230   Top5: 99.680]
2022-11-25 12:15:45,305 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:15:45,307 - INFO  - >>>>>> Epoch  43
2022-11-25 12:15:45,309 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:15:54,657 - INFO  - Training [43][   20/  196]   Loss 0.386105   Top1 86.289062   Top5 98.398438   BatchTime 0.467295   LR 0.000947   
2022-11-25 12:16:02,254 - INFO  - Training [43][   40/  196]   Loss 0.373754   Top1 86.513672   Top5 98.564453   BatchTime 0.423569   LR 0.000943   
2022-11-25 12:16:09,839 - INFO  - Training [43][   60/  196]   Loss 0.367416   Top1 86.861979   Top5 98.697917   BatchTime 0.408793   LR 0.000939   
2022-11-25 12:16:17,321 - INFO  - Training [43][   80/  196]   Loss 0.362364   Top1 87.231445   Top5 98.750000   BatchTime 0.400125   LR 0.000934   
2022-11-25 12:16:24,818 - INFO  - Training [43][  100/  196]   Loss 0.353818   Top1 87.539062   Top5 98.828125   BatchTime 0.395065   LR 0.000930   
2022-11-25 12:16:31,770 - INFO  - Training [43][  120/  196]   Loss 0.349894   Top1 87.679036   Top5 98.909505   BatchTime 0.387155   LR 0.000926   
2022-11-25 12:16:37,754 - INFO  - Training [43][  140/  196]   Loss 0.349389   Top1 87.745536   Top5 98.906250   BatchTime 0.374589   LR 0.000921   
2022-11-25 12:16:44,999 - INFO  - Training [43][  160/  196]   Loss 0.353492   Top1 87.636719   Top5 98.869629   BatchTime 0.373043   LR 0.000917   
2022-11-25 12:16:52,829 - INFO  - Training [43][  180/  196]   Loss 0.353617   Top1 87.610677   Top5 98.838976   BatchTime 0.375097   LR 0.000912   
2022-11-25 12:16:58,919 - INFO  - ==> Top1: 87.652    Top5: 98.846    Loss: 0.352

2022-11-25 12:16:59,142 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:17:00,577 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:17:03,154 - INFO  - Validation [43][   20/   40]   Loss 0.310600   Top1 90.117188   Top5 99.472656   BatchTime 0.128757   
2022-11-25 12:17:04,426 - INFO  - Validation [43][   40/   40]   Loss 0.299237   Top1 90.240000   Top5 99.590000   BatchTime 0.096178   
2022-11-25 12:17:04,694 - INFO  - ==> Top1: 90.240    Top5: 99.590    Loss: 0.299

2022-11-25 12:17:04,695 - INFO  - ==> Sparsity : 0.335

2022-11-25 12:17:04,695 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:17:04,695 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:17:04,696 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 90.240   Top5: 99.590]
2022-11-25 12:17:04,827 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:17:04,829 - INFO  - >>>>>> Epoch  44
2022-11-25 12:17:04,831 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:17:14,231 - INFO  - Training [44][   20/  196]   Loss 0.367454   Top1 87.285156   Top5 98.300781   BatchTime 0.469888   LR 0.000904   
2022-11-25 12:17:21,809 - INFO  - Training [44][   40/  196]   Loss 0.360439   Top1 87.343750   Top5 98.398438   BatchTime 0.424377   LR 0.000900   
2022-11-25 12:17:29,250 - INFO  - Training [44][   60/  196]   Loss 0.351409   Top1 87.656250   Top5 98.541667   BatchTime 0.406935   LR 0.000895   
2022-11-25 12:17:36,496 - INFO  - Training [44][   80/  196]   Loss 0.350056   Top1 87.817383   Top5 98.657227   BatchTime 0.395774   LR 0.000891   
2022-11-25 12:17:43,796 - INFO  - Training [44][  100/  196]   Loss 0.347377   Top1 87.933594   Top5 98.750000   BatchTime 0.389620   LR 0.000886   
2022-11-25 12:17:49,574 - INFO  - Training [44][  120/  196]   Loss 0.341361   Top1 88.141276   Top5 98.811849   BatchTime 0.372830   LR 0.000882   
2022-11-25 12:17:56,947 - INFO  - Training [44][  140/  196]   Loss 0.341100   Top1 88.138951   Top5 98.909040   BatchTime 0.372238   LR 0.000877   
2022-11-25 12:18:04,539 - INFO  - Training [44][  160/  196]   Loss 0.344931   Top1 87.971191   Top5 98.911133   BatchTime 0.373152   LR 0.000873   
2022-11-25 12:18:11,857 - INFO  - Training [44][  180/  196]   Loss 0.345812   Top1 87.916667   Top5 98.851997   BatchTime 0.372352   LR 0.000868   
2022-11-25 12:18:17,879 - INFO  - ==> Top1: 87.918    Top5: 98.858    Loss: 0.345

2022-11-25 12:18:18,112 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:18:19,592 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:18:22,359 - INFO  - Validation [44][   20/   40]   Loss 0.315935   Top1 90.019531   Top5 99.550781   BatchTime 0.138258   
2022-11-25 12:18:23,533 - INFO  - Validation [44][   40/   40]   Loss 0.304914   Top1 89.940000   Top5 99.680000   BatchTime 0.098497   
2022-11-25 12:18:23,788 - INFO  - ==> Top1: 89.940    Top5: 99.680    Loss: 0.305

2022-11-25 12:18:23,789 - INFO  - ==> Sparsity : 0.315

2022-11-25 12:18:23,789 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:18:23,789 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:18:23,789 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 90.240   Top5: 99.590]
2022-11-25 12:18:24,159 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:18:24,161 - INFO  - >>>>>> Epoch  45
2022-11-25 12:18:24,163 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:18:33,882 - INFO  - Training [45][   20/  196]   Loss 0.352060   Top1 87.656250   Top5 98.496094   BatchTime 0.485857   LR 0.000860   
2022-11-25 12:18:41,538 - INFO  - Training [45][   40/  196]   Loss 0.355112   Top1 87.812500   Top5 98.515625   BatchTime 0.434325   LR 0.000855   
2022-11-25 12:18:48,736 - INFO  - Training [45][   60/  196]   Loss 0.347808   Top1 87.923177   Top5 98.632812   BatchTime 0.409518   LR 0.000850   
2022-11-25 12:18:55,921 - INFO  - Training [45][   80/  196]   Loss 0.347478   Top1 87.939453   Top5 98.759766   BatchTime 0.396941   LR 0.000846   
2022-11-25 12:19:02,021 - INFO  - Training [45][  100/  196]   Loss 0.341360   Top1 88.128906   Top5 98.804688   BatchTime 0.378549   LR 0.000841   
2022-11-25 12:19:09,243 - INFO  - Training [45][  120/  196]   Loss 0.338411   Top1 88.229167   Top5 98.883464   BatchTime 0.375648   LR 0.000836   
2022-11-25 12:19:16,605 - INFO  - Training [45][  140/  196]   Loss 0.337914   Top1 88.250558   Top5 98.936942   BatchTime 0.374564   LR 0.000832   
2022-11-25 12:19:23,620 - INFO  - Training [45][  160/  196]   Loss 0.339075   Top1 88.232422   Top5 98.955078   BatchTime 0.371586   LR 0.000827   
2022-11-25 12:19:30,586 - INFO  - Training [45][  180/  196]   Loss 0.339574   Top1 88.240017   Top5 98.912760   BatchTime 0.369002   LR 0.000822   
2022-11-25 12:19:36,469 - INFO  - ==> Top1: 88.320    Top5: 98.926    Loss: 0.337

2022-11-25 12:19:36,748 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:19:38,205 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:19:40,644 - INFO  - Validation [45][   20/   40]   Loss 0.336531   Top1 89.296875   Top5 99.550781   BatchTime 0.121876   
2022-11-25 12:19:41,807 - INFO  - Validation [45][   40/   40]   Loss 0.315002   Top1 89.550000   Top5 99.640000   BatchTime 0.090011   
2022-11-25 12:19:42,088 - INFO  - ==> Top1: 89.550    Top5: 99.640    Loss: 0.315

2022-11-25 12:19:42,088 - INFO  - ==> Sparsity : 0.330

2022-11-25 12:19:42,088 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:19:42,089 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:19:42,089 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 90.240   Top5: 99.590]
2022-11-25 12:19:42,206 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:19:42,208 - INFO  - >>>>>> Epoch  46
2022-11-25 12:19:42,210 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:19:51,799 - INFO  - Training [46][   20/  196]   Loss 0.349147   Top1 87.480469   Top5 98.437500   BatchTime 0.479370   LR 0.000814   
2022-11-25 12:19:59,285 - INFO  - Training [46][   40/  196]   Loss 0.348809   Top1 87.587891   Top5 98.593750   BatchTime 0.426822   LR 0.000809   
2022-11-25 12:20:06,641 - INFO  - Training [46][   60/  196]   Loss 0.342520   Top1 87.910156   Top5 98.710938   BatchTime 0.407140   LR 0.000804   
2022-11-25 12:20:13,073 - INFO  - Training [46][   80/  196]   Loss 0.342078   Top1 87.963867   Top5 98.798828   BatchTime 0.385759   LR 0.000799   
2022-11-25 12:20:19,477 - INFO  - Training [46][  100/  196]   Loss 0.340709   Top1 88.011719   Top5 98.839844   BatchTime 0.372645   LR 0.000794   
2022-11-25 12:20:26,904 - INFO  - Training [46][  120/  196]   Loss 0.338138   Top1 88.037109   Top5 98.912760   BatchTime 0.372425   LR 0.000789   
2022-11-25 12:20:34,318 - INFO  - Training [46][  140/  196]   Loss 0.337978   Top1 88.116629   Top5 98.922991   BatchTime 0.372184   LR 0.000785   
2022-11-25 12:20:41,503 - INFO  - Training [46][  160/  196]   Loss 0.343523   Top1 87.905273   Top5 98.891602   BatchTime 0.370563   LR 0.000780   
2022-11-25 12:20:48,899 - INFO  - Training [46][  180/  196]   Loss 0.343437   Top1 87.892795   Top5 98.836806   BatchTime 0.370481   LR 0.000775   
2022-11-25 12:20:54,903 - INFO  - ==> Top1: 87.970    Top5: 98.838    Loss: 0.341

2022-11-25 12:20:55,173 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:20:56,791 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:21:00,782 - INFO  - Validation [46][   20/   40]   Loss 0.311422   Top1 89.804688   Top5 99.667969   BatchTime 0.199448   
2022-11-25 12:21:01,822 - INFO  - Validation [46][   40/   40]   Loss 0.296332   Top1 90.200000   Top5 99.740000   BatchTime 0.125712   
2022-11-25 12:21:02,062 - INFO  - ==> Top1: 90.200    Top5: 99.740    Loss: 0.296

2022-11-25 12:21:02,062 - INFO  - ==> Sparsity : 0.315

2022-11-25 12:21:02,063 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:21:02,063 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:21:02,063 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 90.240   Top5: 99.590]
2022-11-25 12:21:02,201 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:21:02,202 - INFO  - >>>>>> Epoch  47
2022-11-25 12:21:02,204 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:21:10,959 - INFO  - Training [47][   20/  196]   Loss 0.352909   Top1 87.187500   Top5 98.476562   BatchTime 0.437609   LR 0.000766   
2022-11-25 12:21:18,707 - INFO  - Training [47][   40/  196]   Loss 0.349304   Top1 87.617188   Top5 98.623047   BatchTime 0.412503   LR 0.000761   
2022-11-25 12:21:25,504 - INFO  - Training [47][   60/  196]   Loss 0.350239   Top1 87.701823   Top5 98.717448   BatchTime 0.388274   LR 0.000756   
2022-11-25 12:21:31,547 - INFO  - Training [47][   80/  196]   Loss 0.344311   Top1 87.954102   Top5 98.828125   BatchTime 0.366743   LR 0.000752   
2022-11-25 12:21:37,525 - INFO  - Training [47][  100/  196]   Loss 0.336070   Top1 88.320312   Top5 98.843750   BatchTime 0.353170   LR 0.000747   
2022-11-25 12:21:44,919 - INFO  - Training [47][  120/  196]   Loss 0.330925   Top1 88.486328   Top5 98.896484   BatchTime 0.355934   LR 0.000742   
2022-11-25 12:21:52,348 - INFO  - Training [47][  140/  196]   Loss 0.328752   Top1 88.585379   Top5 98.956473   BatchTime 0.358147   LR 0.000737   
2022-11-25 12:21:59,783 - INFO  - Training [47][  160/  196]   Loss 0.330113   Top1 88.503418   Top5 98.947754   BatchTime 0.359849   LR 0.000732   
2022-11-25 12:22:07,136 - INFO  - Training [47][  180/  196]   Loss 0.329397   Top1 88.491753   Top5 98.940972   BatchTime 0.360715   LR 0.000727   
2022-11-25 12:22:13,394 - INFO  - ==> Top1: 88.546    Top5: 98.964    Loss: 0.328

2022-11-25 12:22:13,654 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:22:15,348 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:22:17,718 - INFO  - Validation [47][   20/   40]   Loss 0.328639   Top1 89.804688   Top5 99.492188   BatchTime 0.118406   
2022-11-25 12:22:18,786 - INFO  - Validation [47][   40/   40]   Loss 0.313807   Top1 90.020000   Top5 99.650000   BatchTime 0.085916   
2022-11-25 12:22:18,979 - INFO  - ==> Top1: 90.020    Top5: 99.650    Loss: 0.314

2022-11-25 12:22:18,979 - INFO  - ==> Sparsity : 0.315

2022-11-25 12:22:18,979 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:22:18,979 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:22:18,979 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 90.240   Top5: 99.590]
2022-11-25 12:22:19,105 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:22:19,106 - INFO  - >>>>>> Epoch  48
2022-11-25 12:22:19,108 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:22:27,717 - INFO  - Training [48][   20/  196]   Loss 0.355345   Top1 87.656250   Top5 98.437500   BatchTime 0.430321   LR 0.000718   
2022-11-25 12:22:35,322 - INFO  - Training [48][   40/  196]   Loss 0.353757   Top1 87.656250   Top5 98.681641   BatchTime 0.405275   LR 0.000713   
2022-11-25 12:22:42,798 - INFO  - Training [48][   60/  196]   Loss 0.349571   Top1 87.786458   Top5 98.684896   BatchTime 0.394796   LR 0.000708   
2022-11-25 12:22:49,164 - INFO  - Training [48][   80/  196]   Loss 0.343966   Top1 87.988281   Top5 98.789062   BatchTime 0.375667   LR 0.000703   
2022-11-25 12:22:56,189 - INFO  - Training [48][  100/  196]   Loss 0.338404   Top1 88.214844   Top5 98.828125   BatchTime 0.370785   LR 0.000698   
2022-11-25 12:23:03,362 - INFO  - Training [48][  120/  196]   Loss 0.332552   Top1 88.408203   Top5 98.902995   BatchTime 0.368760   LR 0.000693   
2022-11-25 12:23:10,829 - INFO  - Training [48][  140/  196]   Loss 0.324725   Top1 88.657924   Top5 99.006696   BatchTime 0.369414   LR 0.000688   
2022-11-25 12:23:18,353 - INFO  - Training [48][  160/  196]   Loss 0.328088   Top1 88.518066   Top5 98.969727   BatchTime 0.370259   LR 0.000683   
2022-11-25 12:23:26,121 - INFO  - Training [48][  180/  196]   Loss 0.327456   Top1 88.517795   Top5 98.925781   BatchTime 0.372277   LR 0.000678   
2022-11-25 12:23:32,277 - INFO  - ==> Top1: 88.536    Top5: 98.918    Loss: 0.327

2022-11-25 12:23:32,557 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:23:34,428 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:23:36,898 - INFO  - Validation [48][   20/   40]   Loss 0.313849   Top1 89.882812   Top5 99.648438   BatchTime 0.123391   
2022-11-25 12:23:38,028 - INFO  - Validation [48][   40/   40]   Loss 0.300851   Top1 90.320000   Top5 99.690000   BatchTime 0.089952   
2022-11-25 12:23:38,325 - INFO  - ==> Top1: 90.320    Top5: 99.690    Loss: 0.301

2022-11-25 12:23:38,325 - INFO  - ==> Sparsity : 0.345

2022-11-25 12:23:38,326 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:23:38,326 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:23:38,326 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.320   Top5: 99.690]
2022-11-25 12:23:38,456 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:23:38,458 - INFO  - >>>>>> Epoch  49
2022-11-25 12:23:38,459 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:23:47,051 - INFO  - Training [49][   20/  196]   Loss 0.324772   Top1 88.593750   Top5 98.613281   BatchTime 0.429458   LR 0.000669   
2022-11-25 12:23:54,630 - INFO  - Training [49][   40/  196]   Loss 0.338666   Top1 88.271484   Top5 98.671875   BatchTime 0.404206   LR 0.000664   
2022-11-25 12:24:00,952 - INFO  - Training [49][   60/  196]   Loss 0.337918   Top1 88.209635   Top5 98.645833   BatchTime 0.374830   LR 0.000659   
2022-11-25 12:24:06,699 - INFO  - Training [49][   80/  196]   Loss 0.338267   Top1 88.129883   Top5 98.793945   BatchTime 0.352957   LR 0.000654   
2022-11-25 12:24:13,233 - INFO  - Training [49][  100/  196]   Loss 0.331626   Top1 88.386719   Top5 98.875000   BatchTime 0.347711   LR 0.000649   
2022-11-25 12:24:20,627 - INFO  - Training [49][  120/  196]   Loss 0.323847   Top1 88.645833   Top5 98.945312   BatchTime 0.351371   LR 0.000644   
2022-11-25 12:24:27,932 - INFO  - Training [49][  140/  196]   Loss 0.322210   Top1 88.755580   Top5 99.009487   BatchTime 0.353356   LR 0.000639   
2022-11-25 12:24:35,028 - INFO  - Training [49][  160/  196]   Loss 0.326869   Top1 88.591309   Top5 98.972168   BatchTime 0.353532   LR 0.000634   
2022-11-25 12:24:42,864 - INFO  - Training [49][  180/  196]   Loss 0.328834   Top1 88.485243   Top5 98.904080   BatchTime 0.357788   LR 0.000629   
2022-11-25 12:24:49,110 - INFO  - ==> Top1: 88.528    Top5: 98.908    Loss: 0.328

2022-11-25 12:24:49,332 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:24:50,643 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:24:53,169 - INFO  - Validation [49][   20/   40]   Loss 0.311574   Top1 89.687500   Top5 99.628906   BatchTime 0.126254   
2022-11-25 12:24:54,344 - INFO  - Validation [49][   40/   40]   Loss 0.304218   Top1 90.020000   Top5 99.700000   BatchTime 0.092511   
2022-11-25 12:24:54,582 - INFO  - ==> Top1: 90.020    Top5: 99.700    Loss: 0.304

2022-11-25 12:24:54,582 - INFO  - ==> Sparsity : 0.335

2022-11-25 12:24:54,583 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:24:54,583 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:24:54,583 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.320   Top5: 99.690]
2022-11-25 12:24:54,726 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:24:54,728 - INFO  - >>>>>> Epoch  50
2022-11-25 12:24:54,730 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:25:03,437 - INFO  - Training [50][   20/  196]   Loss 0.333950   Top1 87.929688   Top5 98.554688   BatchTime 0.435202   LR 0.000620   
2022-11-25 12:25:10,778 - INFO  - Training [50][   40/  196]   Loss 0.326458   Top1 88.593750   Top5 98.710938   BatchTime 0.401128   LR 0.000615   
2022-11-25 12:25:17,955 - INFO  - Training [50][   60/  196]   Loss 0.330654   Top1 88.352865   Top5 98.769531   BatchTime 0.387035   LR 0.000610   
2022-11-25 12:25:24,306 - INFO  - Training [50][   80/  196]   Loss 0.325271   Top1 88.608398   Top5 98.901367   BatchTime 0.369658   LR 0.000605   
2022-11-25 12:25:31,848 - INFO  - Training [50][  100/  196]   Loss 0.318301   Top1 88.800781   Top5 98.898438   BatchTime 0.371150   LR 0.000600   
2022-11-25 12:25:38,971 - INFO  - Training [50][  120/  196]   Loss 0.312810   Top1 89.010417   Top5 98.958333   BatchTime 0.368646   LR 0.000595   
2022-11-25 12:25:46,652 - INFO  - Training [50][  140/  196]   Loss 0.311285   Top1 89.098772   Top5 99.006696   BatchTime 0.370847   LR 0.000590   
2022-11-25 12:25:54,488 - INFO  - Training [50][  160/  196]   Loss 0.315258   Top1 88.945312   Top5 99.016113   BatchTime 0.373467   LR 0.000585   
2022-11-25 12:26:01,711 - INFO  - Training [50][  180/  196]   Loss 0.315999   Top1 88.925781   Top5 98.986545   BatchTime 0.372096   LR 0.000580   
2022-11-25 12:26:07,778 - INFO  - ==> Top1: 88.932    Top5: 98.976    Loss: 0.316

2022-11-25 12:26:08,016 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:26:09,504 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:26:11,946 - INFO  - Validation [50][   20/   40]   Loss 0.311220   Top1 90.214844   Top5 99.687500   BatchTime 0.122008   
2022-11-25 12:26:13,076 - INFO  - Validation [50][   40/   40]   Loss 0.297568   Top1 90.560000   Top5 99.750000   BatchTime 0.089278   
2022-11-25 12:26:13,342 - INFO  - ==> Top1: 90.560    Top5: 99.750    Loss: 0.298

2022-11-25 12:26:13,342 - INFO  - ==> Sparsity : 0.337

2022-11-25 12:26:13,342 - INFO  - Scoreboard best 1 ==> Epoch [50][Top1: 90.560   Top5: 99.750]
2022-11-25 12:26:13,343 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:26:13,343 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:26:18,252 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 12:26:18,254 - INFO  - >>>>>> Epoch  51
2022-11-25 12:26:18,256 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:26:27,058 - INFO  - Training [51][   20/  196]   Loss 0.326406   Top1 88.515625   Top5 98.652344   BatchTime 0.439958   LR 0.000571   
2022-11-25 12:26:34,005 - INFO  - Training [51][   40/  196]   Loss 0.328424   Top1 88.457031   Top5 98.710938   BatchTime 0.393662   LR 0.000566   
2022-11-25 12:26:40,238 - INFO  - Training [51][   60/  196]   Loss 0.325013   Top1 88.639323   Top5 98.802083   BatchTime 0.366320   LR 0.000561   
2022-11-25 12:26:47,464 - INFO  - Training [51][   80/  196]   Loss 0.321815   Top1 88.730469   Top5 98.896484   BatchTime 0.365069   LR 0.000556   
2022-11-25 12:26:54,976 - INFO  - Training [51][  100/  196]   Loss 0.317942   Top1 88.824219   Top5 98.925781   BatchTime 0.367168   LR 0.000551   
2022-11-25 12:27:02,919 - INFO  - Training [51][  120/  196]   Loss 0.313185   Top1 88.968099   Top5 98.987630   BatchTime 0.372170   LR 0.000546   
2022-11-25 12:27:10,375 - INFO  - Training [51][  140/  196]   Loss 0.311412   Top1 89.090402   Top5 99.031808   BatchTime 0.372254   LR 0.000541   
2022-11-25 12:27:17,728 - INFO  - Training [51][  160/  196]   Loss 0.315215   Top1 89.001465   Top5 99.023438   BatchTime 0.371678   LR 0.000536   
2022-11-25 12:27:25,192 - INFO  - Training [51][  180/  196]   Loss 0.317936   Top1 88.851997   Top5 98.977865   BatchTime 0.371848   LR 0.000531   
2022-11-25 12:27:31,179 - INFO  - ==> Top1: 88.936    Top5: 98.988    Loss: 0.316

2022-11-25 12:27:31,429 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:27:32,925 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:27:35,421 - INFO  - Validation [51][   20/   40]   Loss 0.329768   Top1 90.156250   Top5 99.589844   BatchTime 0.124689   
2022-11-25 12:27:36,508 - INFO  - Validation [51][   40/   40]   Loss 0.325619   Top1 90.180000   Top5 99.660000   BatchTime 0.089527   
2022-11-25 12:27:36,747 - INFO  - ==> Top1: 90.180    Top5: 99.660    Loss: 0.326

2022-11-25 12:27:36,748 - INFO  - ==> Sparsity : 0.333

2022-11-25 12:27:36,748 - INFO  - Scoreboard best 1 ==> Epoch [50][Top1: 90.560   Top5: 99.750]
2022-11-25 12:27:36,748 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:27:36,748 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.420   Top5: 99.690]
2022-11-25 12:27:36,871 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:27:36,872 - INFO  - >>>>>> Epoch  52
2022-11-25 12:27:36,874 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:27:45,830 - INFO  - Training [52][   20/  196]   Loss 0.332933   Top1 87.968750   Top5 98.632812   BatchTime 0.447645   LR 0.000523   
2022-11-25 12:27:52,374 - INFO  - Training [52][   40/  196]   Loss 0.332060   Top1 88.193359   Top5 98.720703   BatchTime 0.387441   LR 0.000518   
2022-11-25 12:27:59,257 - INFO  - Training [52][   60/  196]   Loss 0.323317   Top1 88.561198   Top5 98.789062   BatchTime 0.372998   LR 0.000513   
2022-11-25 12:28:06,478 - INFO  - Training [52][   80/  196]   Loss 0.326685   Top1 88.500977   Top5 98.891602   BatchTime 0.370016   LR 0.000508   
2022-11-25 12:28:14,003 - INFO  - Training [52][  100/  196]   Loss 0.320396   Top1 88.734375   Top5 98.914062   BatchTime 0.371260   LR 0.000503   
2022-11-25 12:28:21,954 - INFO  - Training [52][  120/  196]   Loss 0.313564   Top1 89.010417   Top5 98.974609   BatchTime 0.375642   LR 0.000498   
2022-11-25 12:28:29,331 - INFO  - Training [52][  140/  196]   Loss 0.312537   Top1 89.095982   Top5 99.015067   BatchTime 0.374672   LR 0.000493   
2022-11-25 12:28:36,703 - INFO  - Training [52][  160/  196]   Loss 0.313886   Top1 89.003906   Top5 99.047852   BatchTime 0.373911   LR 0.000488   
2022-11-25 12:28:44,127 - INFO  - Training [52][  180/  196]   Loss 0.316200   Top1 88.936632   Top5 98.993056   BatchTime 0.373610   LR 0.000483   
2022-11-25 12:28:50,464 - INFO  - ==> Top1: 89.032    Top5: 98.980    Loss: 0.314

2022-11-25 12:28:50,766 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:28:52,431 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:28:54,941 - INFO  - Validation [52][   20/   40]   Loss 0.301404   Top1 90.683594   Top5 99.687500   BatchTime 0.125403   
2022-11-25 12:28:55,984 - INFO  - Validation [52][   40/   40]   Loss 0.293243   Top1 90.640000   Top5 99.790000   BatchTime 0.088780   
2022-11-25 12:28:56,221 - INFO  - ==> Top1: 90.640    Top5: 99.790    Loss: 0.293

2022-11-25 12:28:56,221 - INFO  - ==> Sparsity : 0.343

2022-11-25 12:28:56,221 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.640   Top5: 99.790]
2022-11-25 12:28:56,222 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 90.560   Top5: 99.750]
2022-11-25 12:28:56,222 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 90.450   Top5: 99.730]
2022-11-25 12:29:01,563 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 12:29:01,567 - INFO  - >>>>>> Epoch  53
2022-11-25 12:29:01,570 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:29:09,449 - INFO  - Training [53][   20/  196]   Loss 0.323890   Top1 89.101562   Top5 98.652344   BatchTime 0.393824   LR 0.000474   
2022-11-25 12:29:16,954 - INFO  - Training [53][   40/  196]   Loss 0.325114   Top1 88.974609   Top5 98.652344   BatchTime 0.384522   LR 0.000470   
2022-11-25 12:29:24,276 - INFO  - Training [53][   60/  196]   Loss 0.319186   Top1 89.108073   Top5 98.743490   BatchTime 0.378386   LR 0.000465   
2022-11-25 12:29:32,339 - INFO  - Training [53][   80/  196]   Loss 0.317430   Top1 89.077148   Top5 98.852539   BatchTime 0.384579   LR 0.000460   
2022-11-25 12:29:39,944 - INFO  - Training [53][  100/  196]   Loss 0.307161   Top1 89.359375   Top5 98.898438   BatchTime 0.383705   LR 0.000455   
2022-11-25 12:29:47,258 - INFO  - Training [53][  120/  196]   Loss 0.304860   Top1 89.427083   Top5 98.945312   BatchTime 0.380709   LR 0.000450   
2022-11-25 12:29:54,646 - INFO  - Training [53][  140/  196]   Loss 0.302258   Top1 89.556362   Top5 98.978795   BatchTime 0.379094   LR 0.000445   
2022-11-25 12:30:01,897 - INFO  - Training [53][  160/  196]   Loss 0.301964   Top1 89.492188   Top5 98.981934   BatchTime 0.377024   LR 0.000441   
2022-11-25 12:30:09,344 - INFO  - Training [53][  180/  196]   Loss 0.304615   Top1 89.405382   Top5 98.964844   BatchTime 0.376501   LR 0.000436   
2022-11-25 12:30:15,332 - INFO  - ==> Top1: 89.394    Top5: 98.970    Loss: 0.305

2022-11-25 12:30:15,550 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:30:16,681 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:30:19,461 - INFO  - Validation [53][   20/   40]   Loss 0.310916   Top1 90.097656   Top5 99.687500   BatchTime 0.138913   
2022-11-25 12:30:20,749 - INFO  - Validation [53][   40/   40]   Loss 0.289665   Top1 90.630000   Top5 99.740000   BatchTime 0.101681   
2022-11-25 12:30:21,287 - INFO  - ==> Top1: 90.630    Top5: 99.740    Loss: 0.290

2022-11-25 12:30:21,288 - INFO  - ==> Sparsity : 0.339

2022-11-25 12:30:21,288 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 90.640   Top5: 99.790]
2022-11-25 12:30:21,289 - INFO  - Scoreboard best 2 ==> Epoch [53][Top1: 90.630   Top5: 99.740]
2022-11-25 12:30:21,289 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 90.560   Top5: 99.750]
2022-11-25 12:30:21,429 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:30:21,430 - INFO  - >>>>>> Epoch  54
2022-11-25 12:30:21,432 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:30:30,144 - INFO  - Training [54][   20/  196]   Loss 0.305657   Top1 89.042969   Top5 98.613281   BatchTime 0.435474   LR 0.000427   
2022-11-25 12:30:37,857 - INFO  - Training [54][   40/  196]   Loss 0.314835   Top1 88.662109   Top5 98.750000   BatchTime 0.410540   LR 0.000423   
2022-11-25 12:30:46,139 - INFO  - Training [54][   60/  196]   Loss 0.310241   Top1 88.990885   Top5 98.808594   BatchTime 0.411733   LR 0.000418   
2022-11-25 12:30:53,703 - INFO  - Training [54][   80/  196]   Loss 0.309441   Top1 89.082031   Top5 98.935547   BatchTime 0.403344   LR 0.000413   
2022-11-25 12:31:01,352 - INFO  - Training [54][  100/  196]   Loss 0.303255   Top1 89.457031   Top5 98.988281   BatchTime 0.399172   LR 0.000408   
2022-11-25 12:31:08,838 - INFO  - Training [54][  120/  196]   Loss 0.298314   Top1 89.622396   Top5 99.023438   BatchTime 0.395022   LR 0.000404   
2022-11-25 12:31:16,310 - INFO  - Training [54][  140/  196]   Loss 0.296163   Top1 89.690290   Top5 99.065290   BatchTime 0.391957   LR 0.000399   
2022-11-25 12:31:23,811 - INFO  - Training [54][  160/  196]   Loss 0.299771   Top1 89.555664   Top5 99.064941   BatchTime 0.389847   LR 0.000394   
2022-11-25 12:31:30,996 - INFO  - Training [54][  180/  196]   Loss 0.299822   Top1 89.542101   Top5 99.042969   BatchTime 0.386444   LR 0.000390   
2022-11-25 12:31:36,078 - INFO  - ==> Top1: 89.586    Top5: 99.046    Loss: 0.298

2022-11-25 12:31:36,277 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:31:37,976 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:31:41,007 - INFO  - Validation [54][   20/   40]   Loss 0.293608   Top1 90.937500   Top5 99.687500   BatchTime 0.151453   
2022-11-25 12:31:41,986 - INFO  - Validation [54][   40/   40]   Loss 0.281860   Top1 91.100000   Top5 99.740000   BatchTime 0.100207   
2022-11-25 12:31:42,223 - INFO  - ==> Top1: 91.100    Top5: 99.740    Loss: 0.282

2022-11-25 12:31:42,223 - INFO  - ==> Sparsity : 0.339

2022-11-25 12:31:42,224 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:31:42,224 - INFO  - Scoreboard best 2 ==> Epoch [52][Top1: 90.640   Top5: 99.790]
2022-11-25 12:31:42,224 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 90.630   Top5: 99.740]
2022-11-25 12:31:46,943 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 12:31:46,945 - INFO  - >>>>>> Epoch  55
2022-11-25 12:31:46,947 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:31:56,256 - INFO  - Training [55][   20/  196]   Loss 0.318323   Top1 88.496094   Top5 98.496094   BatchTime 0.465324   LR 0.000381   
2022-11-25 12:32:03,909 - INFO  - Training [55][   40/  196]   Loss 0.320513   Top1 88.613281   Top5 98.632812   BatchTime 0.424001   LR 0.000377   
2022-11-25 12:32:11,452 - INFO  - Training [55][   60/  196]   Loss 0.307855   Top1 89.160156   Top5 98.736979   BatchTime 0.408375   LR 0.000372   
2022-11-25 12:32:18,905 - INFO  - Training [55][   80/  196]   Loss 0.306266   Top1 89.316406   Top5 98.847656   BatchTime 0.399439   LR 0.000368   
2022-11-25 12:32:26,222 - INFO  - Training [55][  100/  196]   Loss 0.300377   Top1 89.527344   Top5 98.898438   BatchTime 0.392721   LR 0.000363   
2022-11-25 12:32:33,881 - INFO  - Training [55][  120/  196]   Loss 0.295620   Top1 89.667969   Top5 98.964844   BatchTime 0.391094   LR 0.000358   
2022-11-25 12:32:41,328 - INFO  - Training [55][  140/  196]   Loss 0.295459   Top1 89.681920   Top5 99.029018   BatchTime 0.388414   LR 0.000354   
2022-11-25 12:32:48,292 - INFO  - Training [55][  160/  196]   Loss 0.296664   Top1 89.592285   Top5 99.020996   BatchTime 0.383391   LR 0.000349   
2022-11-25 12:32:54,078 - INFO  - Training [55][  180/  196]   Loss 0.296958   Top1 89.572483   Top5 98.984375   BatchTime 0.372932   LR 0.000345   
2022-11-25 12:32:59,771 - INFO  - ==> Top1: 89.668    Top5: 98.976    Loss: 0.295

2022-11-25 12:33:00,033 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:33:01,490 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:33:03,928 - INFO  - Validation [55][   20/   40]   Loss 0.303196   Top1 90.820312   Top5 99.707031   BatchTime 0.121842   
2022-11-25 12:33:05,030 - INFO  - Validation [55][   40/   40]   Loss 0.289878   Top1 90.880000   Top5 99.790000   BatchTime 0.088473   
2022-11-25 12:33:05,251 - INFO  - ==> Top1: 90.880    Top5: 99.790    Loss: 0.290

2022-11-25 12:33:05,251 - INFO  - ==> Sparsity : 0.339

2022-11-25 12:33:05,251 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:33:05,252 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 90.880   Top5: 99.790]
2022-11-25 12:33:05,252 - INFO  - Scoreboard best 3 ==> Epoch [52][Top1: 90.640   Top5: 99.790]
2022-11-25 12:33:05,374 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:33:05,375 - INFO  - >>>>>> Epoch  56
2022-11-25 12:33:05,377 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:33:14,137 - INFO  - Training [56][   20/  196]   Loss 0.303421   Top1 88.828125   Top5 98.535156   BatchTime 0.437889   LR 0.000337   
2022-11-25 12:33:22,102 - INFO  - Training [56][   40/  196]   Loss 0.308444   Top1 88.935547   Top5 98.642578   BatchTime 0.418060   LR 0.000333   
2022-11-25 12:33:29,442 - INFO  - Training [56][   60/  196]   Loss 0.308660   Top1 89.095052   Top5 98.763021   BatchTime 0.401048   LR 0.000328   
2022-11-25 12:33:36,863 - INFO  - Training [56][   80/  196]   Loss 0.304544   Top1 89.238281   Top5 98.862305   BatchTime 0.393537   LR 0.000324   
2022-11-25 12:33:44,303 - INFO  - Training [56][  100/  196]   Loss 0.295144   Top1 89.503906   Top5 98.945312   BatchTime 0.389235   LR 0.000319   
2022-11-25 12:33:52,068 - INFO  - Training [56][  120/  196]   Loss 0.289813   Top1 89.707031   Top5 99.010417   BatchTime 0.389069   LR 0.000315   
2022-11-25 12:33:59,665 - INFO  - Training [56][  140/  196]   Loss 0.288429   Top1 89.771205   Top5 99.062500   BatchTime 0.387747   LR 0.000311   
2022-11-25 12:34:05,903 - INFO  - Training [56][  160/  196]   Loss 0.291492   Top1 89.716797   Top5 99.057617   BatchTime 0.378267   LR 0.000306   
2022-11-25 12:34:12,582 - INFO  - Training [56][  180/  196]   Loss 0.292587   Top1 89.702691   Top5 99.045139   BatchTime 0.373342   LR 0.000302   
2022-11-25 12:34:18,754 - INFO  - ==> Top1: 89.704    Top5: 99.056    Loss: 0.292

2022-11-25 12:34:18,971 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:34:20,457 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:34:22,858 - INFO  - Validation [56][   20/   40]   Loss 0.337411   Top1 89.863281   Top5 99.492188   BatchTime 0.119953   
2022-11-25 12:34:23,870 - INFO  - Validation [56][   40/   40]   Loss 0.327991   Top1 89.830000   Top5 99.660000   BatchTime 0.085282   
2022-11-25 12:34:24,142 - INFO  - ==> Top1: 89.830    Top5: 99.660    Loss: 0.328

2022-11-25 12:34:24,142 - INFO  - ==> Sparsity : 0.340

2022-11-25 12:34:24,143 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:34:24,143 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 90.880   Top5: 99.790]
2022-11-25 12:34:24,143 - INFO  - Scoreboard best 3 ==> Epoch [52][Top1: 90.640   Top5: 99.790]
2022-11-25 12:34:24,274 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:34:24,277 - INFO  - >>>>>> Epoch  57
2022-11-25 12:34:24,279 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:34:33,450 - INFO  - Training [57][   20/  196]   Loss 0.303781   Top1 89.746094   Top5 98.535156   BatchTime 0.458420   LR 0.000294   
2022-11-25 12:34:41,305 - INFO  - Training [57][   40/  196]   Loss 0.303349   Top1 89.580078   Top5 98.564453   BatchTime 0.425572   LR 0.000290   
2022-11-25 12:34:48,872 - INFO  - Training [57][   60/  196]   Loss 0.303106   Top1 89.485677   Top5 98.697917   BatchTime 0.409840   LR 0.000286   
2022-11-25 12:34:56,158 - INFO  - Training [57][   80/  196]   Loss 0.298587   Top1 89.555664   Top5 98.872070   BatchTime 0.398456   LR 0.000282   
2022-11-25 12:35:03,610 - INFO  - Training [57][  100/  196]   Loss 0.293517   Top1 89.792969   Top5 98.929688   BatchTime 0.393285   LR 0.000277   
2022-11-25 12:35:10,976 - INFO  - Training [57][  120/  196]   Loss 0.290942   Top1 89.912109   Top5 98.981120   BatchTime 0.389123   LR 0.000273   
2022-11-25 12:35:17,834 - INFO  - Training [57][  140/  196]   Loss 0.292188   Top1 89.944196   Top5 99.042969   BatchTime 0.382515   LR 0.000269   
2022-11-25 12:35:24,333 - INFO  - Training [57][  160/  196]   Loss 0.295374   Top1 89.768066   Top5 99.028320   BatchTime 0.375320   LR 0.000265   
2022-11-25 12:35:31,606 - INFO  - Training [57][  180/  196]   Loss 0.296609   Top1 89.717882   Top5 98.999566   BatchTime 0.374023   LR 0.000261   
2022-11-25 12:35:37,640 - INFO  - ==> Top1: 89.722    Top5: 98.994    Loss: 0.296

2022-11-25 12:35:37,925 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:35:39,432 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:35:42,062 - INFO  - Validation [57][   20/   40]   Loss 0.300196   Top1 90.859375   Top5 99.648438   BatchTime 0.131438   
2022-11-25 12:35:43,254 - INFO  - Validation [57][   40/   40]   Loss 0.283270   Top1 91.100000   Top5 99.720000   BatchTime 0.095509   
2022-11-25 12:35:43,510 - INFO  - ==> Top1: 91.100    Top5: 99.720    Loss: 0.283

2022-11-25 12:35:43,510 - INFO  - ==> Sparsity : 0.338

2022-11-25 12:35:43,510 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:35:43,510 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.100   Top5: 99.720]
2022-11-25 12:35:43,511 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 90.880   Top5: 99.790]
2022-11-25 12:35:43,639 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:35:43,640 - INFO  - >>>>>> Epoch  58
2022-11-25 12:35:43,642 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:35:53,275 - INFO  - Training [58][   20/  196]   Loss 0.306962   Top1 89.257812   Top5 98.593750   BatchTime 0.481514   LR 0.000254   
2022-11-25 12:36:01,050 - INFO  - Training [58][   40/  196]   Loss 0.307546   Top1 89.257812   Top5 98.789062   BatchTime 0.435125   LR 0.000250   
2022-11-25 12:36:08,564 - INFO  - Training [58][   60/  196]   Loss 0.302946   Top1 89.309896   Top5 98.886719   BatchTime 0.415318   LR 0.000246   
2022-11-25 12:36:15,992 - INFO  - Training [58][   80/  196]   Loss 0.305697   Top1 89.194336   Top5 98.974609   BatchTime 0.404335   LR 0.000242   
2022-11-25 12:36:23,239 - INFO  - Training [58][  100/  196]   Loss 0.296426   Top1 89.613281   Top5 99.031250   BatchTime 0.395935   LR 0.000238   
2022-11-25 12:36:30,754 - INFO  - Training [58][  120/  196]   Loss 0.291810   Top1 89.804688   Top5 99.091797   BatchTime 0.392573   LR 0.000234   
2022-11-25 12:36:36,779 - INFO  - Training [58][  140/  196]   Loss 0.291281   Top1 89.829799   Top5 99.135045   BatchTime 0.379522   LR 0.000230   
2022-11-25 12:36:43,948 - INFO  - Training [58][  160/  196]   Loss 0.294957   Top1 89.709473   Top5 99.096680   BatchTime 0.376887   LR 0.000226   
2022-11-25 12:36:51,392 - INFO  - Training [58][  180/  196]   Loss 0.293777   Top1 89.772135   Top5 99.036458   BatchTime 0.376371   LR 0.000222   
2022-11-25 12:36:57,680 - INFO  - ==> Top1: 89.882    Top5: 99.038    Loss: 0.291

2022-11-25 12:36:58,317 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:36:59,777 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:37:02,424 - INFO  - Validation [58][   20/   40]   Loss 0.296627   Top1 90.644531   Top5 99.667969   BatchTime 0.132231   
2022-11-25 12:37:03,504 - INFO  - Validation [58][   40/   40]   Loss 0.284831   Top1 90.930000   Top5 99.760000   BatchTime 0.093126   
2022-11-25 12:37:03,725 - INFO  - ==> Top1: 90.930    Top5: 99.760    Loss: 0.285

2022-11-25 12:37:03,725 - INFO  - ==> Sparsity : 0.340

2022-11-25 12:37:03,726 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:37:03,726 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.100   Top5: 99.720]
2022-11-25 12:37:03,726 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 90.930   Top5: 99.760]
2022-11-25 12:37:03,842 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:37:03,844 - INFO  - >>>>>> Epoch  59
2022-11-25 12:37:03,846 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:37:12,677 - INFO  - Training [59][   20/  196]   Loss 0.298065   Top1 89.394531   Top5 98.261719   BatchTime 0.441452   LR 0.000215   
2022-11-25 12:37:20,497 - INFO  - Training [59][   40/  196]   Loss 0.308350   Top1 89.091797   Top5 98.486328   BatchTime 0.416231   LR 0.000212   
2022-11-25 12:37:28,108 - INFO  - Training [59][   60/  196]   Loss 0.300171   Top1 89.433594   Top5 98.645833   BatchTime 0.404323   LR 0.000208   
2022-11-25 12:37:35,595 - INFO  - Training [59][   80/  196]   Loss 0.300294   Top1 89.389648   Top5 98.842773   BatchTime 0.396829   LR 0.000204   
2022-11-25 12:37:43,140 - INFO  - Training [59][  100/  196]   Loss 0.294113   Top1 89.621094   Top5 98.925781   BatchTime 0.392915   LR 0.000201   
2022-11-25 12:37:49,581 - INFO  - Training [59][  120/  196]   Loss 0.288631   Top1 89.847005   Top5 98.987630   BatchTime 0.381098   LR 0.000197   
2022-11-25 12:37:56,554 - INFO  - Training [59][  140/  196]   Loss 0.287480   Top1 89.899554   Top5 99.054129   BatchTime 0.376467   LR 0.000193   
2022-11-25 12:38:03,963 - INFO  - Training [59][  160/  196]   Loss 0.290766   Top1 89.743652   Top5 99.050293   BatchTime 0.375713   LR 0.000190   
2022-11-25 12:38:11,111 - INFO  - Training [59][  180/  196]   Loss 0.292641   Top1 89.657118   Top5 99.008247   BatchTime 0.373677   LR 0.000186   
2022-11-25 12:38:17,404 - INFO  - ==> Top1: 89.742    Top5: 99.006    Loss: 0.291

2022-11-25 12:38:17,719 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:38:19,200 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:38:21,854 - INFO  - Validation [59][   20/   40]   Loss 0.319255   Top1 90.390625   Top5 99.492188   BatchTime 0.132600   
2022-11-25 12:38:22,964 - INFO  - Validation [59][   40/   40]   Loss 0.303865   Top1 90.310000   Top5 99.680000   BatchTime 0.094060   
2022-11-25 12:38:23,192 - INFO  - ==> Top1: 90.310    Top5: 99.680    Loss: 0.304

2022-11-25 12:38:23,192 - INFO  - ==> Sparsity : 0.339

2022-11-25 12:38:23,192 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:38:23,193 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 91.100   Top5: 99.720]
2022-11-25 12:38:23,193 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 90.930   Top5: 99.760]
2022-11-25 12:38:23,353 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:38:23,354 - INFO  - >>>>>> Epoch  60
2022-11-25 12:38:23,356 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:38:32,147 - INFO  - Training [60][   20/  196]   Loss 0.307851   Top1 89.023438   Top5 98.847656   BatchTime 0.439395   LR 0.000180   
2022-11-25 12:38:39,807 - INFO  - Training [60][   40/  196]   Loss 0.304946   Top1 89.140625   Top5 98.876953   BatchTime 0.411202   LR 0.000176   
2022-11-25 12:38:47,227 - INFO  - Training [60][   60/  196]   Loss 0.299042   Top1 89.420573   Top5 98.997396   BatchTime 0.397809   LR 0.000173   
2022-11-25 12:38:54,790 - INFO  - Training [60][   80/  196]   Loss 0.290243   Top1 89.814453   Top5 99.101562   BatchTime 0.392886   LR 0.000169   
2022-11-25 12:39:01,989 - INFO  - Training [60][  100/  196]   Loss 0.285041   Top1 90.035156   Top5 99.109375   BatchTime 0.386301   LR 0.000166   
2022-11-25 12:39:08,126 - INFO  - Training [60][  120/  196]   Loss 0.281166   Top1 90.172526   Top5 99.134115   BatchTime 0.373056   LR 0.000162   
2022-11-25 12:39:15,432 - INFO  - Training [60][  140/  196]   Loss 0.280651   Top1 90.206473   Top5 99.162946   BatchTime 0.371951   LR 0.000159   
2022-11-25 12:39:22,705 - INFO  - Training [60][  160/  196]   Loss 0.285432   Top1 90.012207   Top5 99.145508   BatchTime 0.370909   LR 0.000156   
2022-11-25 12:39:30,495 - INFO  - Training [60][  180/  196]   Loss 0.285585   Top1 90.002170   Top5 99.101562   BatchTime 0.372973   LR 0.000152   
2022-11-25 12:39:36,343 - INFO  - ==> Top1: 90.028    Top5: 99.086    Loss: 0.285

2022-11-25 12:39:36,622 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:39:38,258 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:39:40,898 - INFO  - Validation [60][   20/   40]   Loss 0.298141   Top1 90.976562   Top5 99.746094   BatchTime 0.131906   
2022-11-25 12:39:42,039 - INFO  - Validation [60][   40/   40]   Loss 0.281546   Top1 91.230000   Top5 99.800000   BatchTime 0.094489   
2022-11-25 12:39:42,278 - INFO  - ==> Top1: 91.230    Top5: 99.800    Loss: 0.282

2022-11-25 12:39:42,279 - INFO  - ==> Sparsity : 0.341

2022-11-25 12:39:42,279 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.230   Top5: 99.800]
2022-11-25 12:39:42,279 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:39:42,279 - INFO  - Scoreboard best 3 ==> Epoch [57][Top1: 91.100   Top5: 99.720]
2022-11-25 12:39:47,598 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 12:39:47,604 - INFO  - >>>>>> Epoch  61
2022-11-25 12:39:47,606 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:39:56,640 - INFO  - Training [61][   20/  196]   Loss 0.308706   Top1 88.671875   Top5 98.730469   BatchTime 0.451596   LR 0.000147   
2022-11-25 12:40:04,153 - INFO  - Training [61][   40/  196]   Loss 0.300474   Top1 89.179688   Top5 98.906250   BatchTime 0.413620   LR 0.000143   
2022-11-25 12:40:11,551 - INFO  - Training [61][   60/  196]   Loss 0.290806   Top1 89.674479   Top5 98.964844   BatchTime 0.399048   LR 0.000140   
2022-11-25 12:40:17,990 - INFO  - Training [61][   80/  196]   Loss 0.288402   Top1 89.916992   Top5 99.062500   BatchTime 0.379762   LR 0.000137   
2022-11-25 12:40:24,545 - INFO  - Training [61][  100/  196]   Loss 0.279651   Top1 90.230469   Top5 99.093750   BatchTime 0.369360   LR 0.000134   
2022-11-25 12:40:31,885 - INFO  - Training [61][  120/  196]   Loss 0.275625   Top1 90.358073   Top5 99.173177   BatchTime 0.368963   LR 0.000131   
2022-11-25 12:40:39,581 - INFO  - Training [61][  140/  196]   Loss 0.276002   Top1 90.351562   Top5 99.202009   BatchTime 0.371229   LR 0.000128   
2022-11-25 12:40:47,084 - INFO  - Training [61][  160/  196]   Loss 0.279466   Top1 90.231934   Top5 99.177246   BatchTime 0.371719   LR 0.000125   
2022-11-25 12:40:54,622 - INFO  - Training [61][  180/  196]   Loss 0.279262   Top1 90.275608   Top5 99.129774   BatchTime 0.372294   LR 0.000122   
2022-11-25 12:41:00,535 - INFO  - ==> Top1: 90.278    Top5: 99.122    Loss: 0.279

2022-11-25 12:41:00,855 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:41:02,427 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:41:05,102 - INFO  - Validation [61][   20/   40]   Loss 0.289970   Top1 91.074219   Top5 99.726562   BatchTime 0.133649   
2022-11-25 12:41:06,211 - INFO  - Validation [61][   40/   40]   Loss 0.276649   Top1 91.330000   Top5 99.760000   BatchTime 0.094538   
2022-11-25 12:41:06,475 - INFO  - ==> Top1: 91.330    Top5: 99.760    Loss: 0.277

2022-11-25 12:41:06,475 - INFO  - ==> Sparsity : 0.343

2022-11-25 12:41:06,475 - INFO  - Scoreboard best 1 ==> Epoch [61][Top1: 91.330   Top5: 99.760]
2022-11-25 12:41:06,476 - INFO  - Scoreboard best 2 ==> Epoch [60][Top1: 91.230   Top5: 99.800]
2022-11-25 12:41:06,476 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:41:14,074 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 12:41:14,080 - INFO  - >>>>>> Epoch  62
2022-11-25 12:41:14,082 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:41:22,936 - INFO  - Training [62][   20/  196]   Loss 0.276831   Top1 90.410156   Top5 98.457031   BatchTime 0.442551   LR 0.000117   
2022-11-25 12:41:29,568 - INFO  - Training [62][   40/  196]   Loss 0.281813   Top1 90.205078   Top5 98.759766   BatchTime 0.387069   LR 0.000114   
2022-11-25 12:41:36,338 - INFO  - Training [62][   60/  196]   Loss 0.278868   Top1 90.227865   Top5 98.841146   BatchTime 0.370887   LR 0.000111   
2022-11-25 12:41:43,944 - INFO  - Training [62][   80/  196]   Loss 0.278314   Top1 90.292969   Top5 98.979492   BatchTime 0.373242   LR 0.000108   
2022-11-25 12:41:51,502 - INFO  - Training [62][  100/  196]   Loss 0.274765   Top1 90.503906   Top5 99.003906   BatchTime 0.374166   LR 0.000105   
2022-11-25 12:41:58,995 - INFO  - Training [62][  120/  196]   Loss 0.269685   Top1 90.722656   Top5 99.049479   BatchTime 0.374250   LR 0.000102   
2022-11-25 12:42:07,044 - INFO  - Training [62][  140/  196]   Loss 0.272497   Top1 90.633371   Top5 99.093192   BatchTime 0.378278   LR 0.000100   
2022-11-25 12:42:14,462 - INFO  - Training [62][  160/  196]   Loss 0.275360   Top1 90.522461   Top5 99.082031   BatchTime 0.377352   LR 0.000097   
2022-11-25 12:42:21,896 - INFO  - Training [62][  180/  196]   Loss 0.275855   Top1 90.447049   Top5 99.049479   BatchTime 0.376726   LR 0.000094   
2022-11-25 12:42:28,241 - INFO  - ==> Top1: 90.474    Top5: 99.030    Loss: 0.275

2022-11-25 12:42:28,489 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:42:30,471 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:42:33,188 - INFO  - Validation [62][   20/   40]   Loss 0.313336   Top1 90.683594   Top5 99.648438   BatchTime 0.135718   
2022-11-25 12:42:34,331 - INFO  - Validation [62][   40/   40]   Loss 0.295057   Top1 91.000000   Top5 99.680000   BatchTime 0.096451   
2022-11-25 12:42:34,551 - INFO  - ==> Top1: 91.000    Top5: 99.680    Loss: 0.295

2022-11-25 12:42:34,551 - INFO  - ==> Sparsity : 0.345

2022-11-25 12:42:34,552 - INFO  - Scoreboard best 1 ==> Epoch [61][Top1: 91.330   Top5: 99.760]
2022-11-25 12:42:34,552 - INFO  - Scoreboard best 2 ==> Epoch [60][Top1: 91.230   Top5: 99.800]
2022-11-25 12:42:34,552 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:42:34,683 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:42:34,684 - INFO  - >>>>>> Epoch  63
2022-11-25 12:42:34,686 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:42:42,754 - INFO  - Training [63][   20/  196]   Loss 0.300603   Top1 89.257812   Top5 98.632812   BatchTime 0.403263   LR 0.000090   
2022-11-25 12:42:49,226 - INFO  - Training [63][   40/  196]   Loss 0.300364   Top1 89.335938   Top5 98.681641   BatchTime 0.363429   LR 0.000087   
2022-11-25 12:42:56,656 - INFO  - Training [63][   60/  196]   Loss 0.293987   Top1 89.602865   Top5 98.795573   BatchTime 0.366112   LR 0.000085   
2022-11-25 12:43:03,959 - INFO  - Training [63][   80/  196]   Loss 0.288285   Top1 89.853516   Top5 98.930664   BatchTime 0.365880   LR 0.000082   
2022-11-25 12:43:11,279 - INFO  - Training [63][  100/  196]   Loss 0.282521   Top1 90.058594   Top5 98.984375   BatchTime 0.365895   LR 0.000080   
2022-11-25 12:43:19,010 - INFO  - Training [63][  120/  196]   Loss 0.277940   Top1 90.214844   Top5 99.049479   BatchTime 0.369338   LR 0.000077   
2022-11-25 12:43:26,616 - INFO  - Training [63][  140/  196]   Loss 0.273184   Top1 90.438058   Top5 99.109933   BatchTime 0.370902   LR 0.000075   
2022-11-25 12:43:33,897 - INFO  - Training [63][  160/  196]   Loss 0.274697   Top1 90.351562   Top5 99.106445   BatchTime 0.370050   LR 0.000072   
2022-11-25 12:43:41,134 - INFO  - Training [63][  180/  196]   Loss 0.275896   Top1 90.321181   Top5 99.082031   BatchTime 0.369138   LR 0.000070   
2022-11-25 12:43:47,448 - INFO  - ==> Top1: 90.320    Top5: 99.076    Loss: 0.276

2022-11-25 12:43:47,696 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:43:49,392 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:43:52,057 - INFO  - Validation [63][   20/   40]   Loss 0.430152   Top1 87.089844   Top5 99.257812   BatchTime 0.133147   
2022-11-25 12:43:53,174 - INFO  - Validation [63][   40/   40]   Loss 0.428400   Top1 87.000000   Top5 99.370000   BatchTime 0.094489   
2022-11-25 12:43:53,389 - INFO  - ==> Top1: 87.000    Top5: 99.370    Loss: 0.428

2022-11-25 12:43:53,389 - INFO  - ==> Sparsity : 0.346

2022-11-25 12:43:53,389 - INFO  - Scoreboard best 1 ==> Epoch [61][Top1: 91.330   Top5: 99.760]
2022-11-25 12:43:53,389 - INFO  - Scoreboard best 2 ==> Epoch [60][Top1: 91.230   Top5: 99.800]
2022-11-25 12:43:53,390 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:43:53,768 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:43:53,769 - INFO  - >>>>>> Epoch  64
2022-11-25 12:43:53,771 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:44:01,208 - INFO  - Training [64][   20/  196]   Loss 0.284390   Top1 89.902344   Top5 98.574219   BatchTime 0.371712   LR 0.000066   
2022-11-25 12:44:08,399 - INFO  - Training [64][   40/  196]   Loss 0.293832   Top1 89.736328   Top5 98.769531   BatchTime 0.365640   LR 0.000064   
2022-11-25 12:44:15,881 - INFO  - Training [64][   60/  196]   Loss 0.291221   Top1 89.791667   Top5 98.776042   BatchTime 0.368465   LR 0.000062   
2022-11-25 12:44:23,121 - INFO  - Training [64][   80/  196]   Loss 0.286701   Top1 90.009766   Top5 98.911133   BatchTime 0.366845   LR 0.000059   
2022-11-25 12:44:30,745 - INFO  - Training [64][  100/  196]   Loss 0.280816   Top1 90.175781   Top5 98.960938   BatchTime 0.369714   LR 0.000057   
2022-11-25 12:44:38,378 - INFO  - Training [64][  120/  196]   Loss 0.273444   Top1 90.491536   Top5 99.039714   BatchTime 0.371700   LR 0.000055   
2022-11-25 12:44:45,778 - INFO  - Training [64][  140/  196]   Loss 0.271727   Top1 90.588728   Top5 99.101562   BatchTime 0.371456   LR 0.000053   
2022-11-25 12:44:52,868 - INFO  - Training [64][  160/  196]   Loss 0.274713   Top1 90.454102   Top5 99.106445   BatchTime 0.369337   LR 0.000051   
2022-11-25 12:45:00,257 - INFO  - Training [64][  180/  196]   Loss 0.275432   Top1 90.414497   Top5 99.105903   BatchTime 0.369350   LR 0.000049   
2022-11-25 12:45:06,512 - INFO  - ==> Top1: 90.508    Top5: 99.074    Loss: 0.273

2022-11-25 12:45:06,796 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:45:08,221 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:45:11,010 - INFO  - Validation [64][   20/   40]   Loss 0.302811   Top1 90.742188   Top5 99.667969   BatchTime 0.139372   
2022-11-25 12:45:12,171 - INFO  - Validation [64][   40/   40]   Loss 0.291883   Top1 90.970000   Top5 99.700000   BatchTime 0.098698   
2022-11-25 12:45:12,449 - INFO  - ==> Top1: 90.970    Top5: 99.700    Loss: 0.292

2022-11-25 12:45:12,450 - INFO  - ==> Sparsity : 0.346

2022-11-25 12:45:12,450 - INFO  - Scoreboard best 1 ==> Epoch [61][Top1: 91.330   Top5: 99.760]
2022-11-25 12:45:12,450 - INFO  - Scoreboard best 2 ==> Epoch [60][Top1: 91.230   Top5: 99.800]
2022-11-25 12:45:12,450 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:45:12,582 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:45:12,584 - INFO  - >>>>>> Epoch  65
2022-11-25 12:45:12,586 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:45:20,728 - INFO  - Training [65][   20/  196]   Loss 0.298870   Top1 89.199219   Top5 98.574219   BatchTime 0.406962   LR 0.000046   
2022-11-25 12:45:28,165 - INFO  - Training [65][   40/  196]   Loss 0.293214   Top1 89.599609   Top5 98.701172   BatchTime 0.389414   LR 0.000044   
2022-11-25 12:45:35,671 - INFO  - Training [65][   60/  196]   Loss 0.293726   Top1 89.615885   Top5 98.808594   BatchTime 0.384703   LR 0.000042   
2022-11-25 12:45:43,009 - INFO  - Training [65][   80/  196]   Loss 0.286982   Top1 89.838867   Top5 98.999023   BatchTime 0.380200   LR 0.000040   
2022-11-25 12:45:50,874 - INFO  - Training [65][  100/  196]   Loss 0.277590   Top1 90.214844   Top5 99.054688   BatchTime 0.382847   LR 0.000039   
2022-11-25 12:45:58,171 - INFO  - Training [65][  120/  196]   Loss 0.271830   Top1 90.406901   Top5 99.098307   BatchTime 0.379850   LR 0.000037   
2022-11-25 12:46:05,527 - INFO  - Training [65][  140/  196]   Loss 0.271048   Top1 90.407366   Top5 99.148996   BatchTime 0.378125   LR 0.000035   
2022-11-25 12:46:12,995 - INFO  - Training [65][  160/  196]   Loss 0.271534   Top1 90.397949   Top5 99.133301   BatchTime 0.377539   LR 0.000033   
2022-11-25 12:46:20,382 - INFO  - Training [65][  180/  196]   Loss 0.271804   Top1 90.366753   Top5 99.066840   BatchTime 0.376623   LR 0.000032   
2022-11-25 12:46:26,730 - INFO  - ==> Top1: 90.426    Top5: 99.062    Loss: 0.270

2022-11-25 12:46:26,978 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:46:28,511 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:46:31,215 - INFO  - Validation [65][   20/   40]   Loss 0.355743   Top1 89.394531   Top5 99.492188   BatchTime 0.135125   
2022-11-25 12:46:32,272 - INFO  - Validation [65][   40/   40]   Loss 0.349852   Top1 89.260000   Top5 99.560000   BatchTime 0.093991   
2022-11-25 12:46:32,530 - INFO  - ==> Top1: 89.260    Top5: 99.560    Loss: 0.350

2022-11-25 12:46:32,530 - INFO  - ==> Sparsity : 0.347

2022-11-25 12:46:32,531 - INFO  - Scoreboard best 1 ==> Epoch [61][Top1: 91.330   Top5: 99.760]
2022-11-25 12:46:32,531 - INFO  - Scoreboard best 2 ==> Epoch [60][Top1: 91.230   Top5: 99.800]
2022-11-25 12:46:32,531 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:46:32,668 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:46:32,669 - INFO  - >>>>>> Epoch  66
2022-11-25 12:46:32,671 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:46:40,968 - INFO  - Training [66][   20/  196]   Loss 0.301373   Top1 89.453125   Top5 98.671875   BatchTime 0.414711   LR 0.000029   
2022-11-25 12:46:48,203 - INFO  - Training [66][   40/  196]   Loss 0.292480   Top1 89.833984   Top5 98.857422   BatchTime 0.388235   LR 0.000028   
2022-11-25 12:46:55,608 - INFO  - Training [66][   60/  196]   Loss 0.291517   Top1 89.759115   Top5 98.906250   BatchTime 0.382239   LR 0.000026   
2022-11-25 12:47:03,397 - INFO  - Training [66][   80/  196]   Loss 0.287105   Top1 89.882812   Top5 99.047852   BatchTime 0.384035   LR 0.000025   
2022-11-25 12:47:10,715 - INFO  - Training [66][  100/  196]   Loss 0.277928   Top1 90.207031   Top5 99.101562   BatchTime 0.380412   LR 0.000023   
2022-11-25 12:47:18,066 - INFO  - Training [66][  120/  196]   Loss 0.274043   Top1 90.338542   Top5 99.134115   BatchTime 0.378263   LR 0.000022   
2022-11-25 12:47:25,406 - INFO  - Training [66][  140/  196]   Loss 0.272878   Top1 90.404576   Top5 99.160156   BatchTime 0.376657   LR 0.000021   
2022-11-25 12:47:32,706 - INFO  - Training [66][  160/  196]   Loss 0.274700   Top1 90.273438   Top5 99.160156   BatchTime 0.375195   LR 0.000019   
2022-11-25 12:47:39,741 - INFO  - Training [66][  180/  196]   Loss 0.272938   Top1 90.345052   Top5 99.123264   BatchTime 0.372591   LR 0.000018   
2022-11-25 12:47:45,833 - INFO  - ==> Top1: 90.380    Top5: 99.112    Loss: 0.272

2022-11-25 12:47:46,066 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:47:47,240 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:47:50,882 - INFO  - Validation [66][   20/   40]   Loss 0.596077   Top1 82.421875   Top5 98.828125   BatchTime 0.181999   
2022-11-25 12:47:52,300 - INFO  - Validation [66][   40/   40]   Loss 0.588999   Top1 82.190000   Top5 98.950000   BatchTime 0.126455   
2022-11-25 12:47:52,593 - INFO  - ==> Top1: 82.190    Top5: 98.950    Loss: 0.589

2022-11-25 12:47:52,593 - INFO  - ==> Sparsity : 0.347

2022-11-25 12:47:52,594 - INFO  - Scoreboard best 1 ==> Epoch [61][Top1: 91.330   Top5: 99.760]
2022-11-25 12:47:52,594 - INFO  - Scoreboard best 2 ==> Epoch [60][Top1: 91.230   Top5: 99.800]
2022-11-25 12:47:52,594 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:47:52,730 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:47:52,732 - INFO  - >>>>>> Epoch  67
2022-11-25 12:47:52,734 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:48:01,765 - INFO  - Training [67][   20/  196]   Loss 0.295103   Top1 89.218750   Top5 98.789062   BatchTime 0.451416   LR 0.000016   
2022-11-25 12:48:09,239 - INFO  - Training [67][   40/  196]   Loss 0.291832   Top1 89.628906   Top5 98.876953   BatchTime 0.412561   LR 0.000015   
2022-11-25 12:48:17,241 - INFO  - Training [67][   60/  196]   Loss 0.284483   Top1 89.980469   Top5 98.906250   BatchTime 0.408407   LR 0.000014   
2022-11-25 12:48:24,623 - INFO  - Training [67][   80/  196]   Loss 0.282181   Top1 90.048828   Top5 99.023438   BatchTime 0.398579   LR 0.000013   
2022-11-25 12:48:31,922 - INFO  - Training [67][  100/  196]   Loss 0.276456   Top1 90.238281   Top5 99.078125   BatchTime 0.391847   LR 0.000012   
2022-11-25 12:48:39,503 - INFO  - Training [67][  120/  196]   Loss 0.269561   Top1 90.498047   Top5 99.147135   BatchTime 0.389719   LR 0.000011   
2022-11-25 12:48:46,940 - INFO  - Training [67][  140/  196]   Loss 0.267709   Top1 90.538504   Top5 99.215960   BatchTime 0.387160   LR 0.000010   
2022-11-25 12:48:54,292 - INFO  - Training [67][  160/  196]   Loss 0.270718   Top1 90.419922   Top5 99.177246   BatchTime 0.384718   LR 0.000009   
2022-11-25 12:49:01,757 - INFO  - Training [67][  180/  196]   Loss 0.270644   Top1 90.427517   Top5 99.144965   BatchTime 0.383444   LR 0.000008   
2022-11-25 12:49:07,050 - INFO  - ==> Top1: 90.498    Top5: 99.144    Loss: 0.269

2022-11-25 12:49:07,322 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:49:09,279 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:49:12,047 - INFO  - Validation [67][   20/   40]   Loss 0.350536   Top1 89.765625   Top5 99.492188   BatchTime 0.138331   
2022-11-25 12:49:13,124 - INFO  - Validation [67][   40/   40]   Loss 0.337182   Top1 89.640000   Top5 99.620000   BatchTime 0.096082   
2022-11-25 12:49:13,386 - INFO  - ==> Top1: 89.640    Top5: 99.620    Loss: 0.337

2022-11-25 12:49:13,387 - INFO  - ==> Sparsity : 0.347

2022-11-25 12:49:13,387 - INFO  - Scoreboard best 1 ==> Epoch [61][Top1: 91.330   Top5: 99.760]
2022-11-25 12:49:13,387 - INFO  - Scoreboard best 2 ==> Epoch [60][Top1: 91.230   Top5: 99.800]
2022-11-25 12:49:13,387 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:49:13,507 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:49:13,509 - INFO  - >>>>>> Epoch  68
2022-11-25 12:49:13,510 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:49:22,848 - INFO  - Training [68][   20/  196]   Loss 0.278176   Top1 89.746094   Top5 98.710938   BatchTime 0.466732   LR 0.000007   
2022-11-25 12:49:30,372 - INFO  - Training [68][   40/  196]   Loss 0.287451   Top1 89.902344   Top5 98.818359   BatchTime 0.421481   LR 0.000006   
2022-11-25 12:49:37,682 - INFO  - Training [68][   60/  196]   Loss 0.282241   Top1 90.162760   Top5 98.854167   BatchTime 0.402820   LR 0.000006   
2022-11-25 12:49:45,216 - INFO  - Training [68][   80/  196]   Loss 0.278815   Top1 90.278320   Top5 98.964844   BatchTime 0.396287   LR 0.000005   
2022-11-25 12:49:52,853 - INFO  - Training [68][  100/  196]   Loss 0.272375   Top1 90.484375   Top5 99.000000   BatchTime 0.393399   LR 0.000004   
2022-11-25 12:50:00,325 - INFO  - Training [68][  120/  196]   Loss 0.267466   Top1 90.628255   Top5 99.072266   BatchTime 0.390101   LR 0.000004   
2022-11-25 12:50:07,549 - INFO  - Training [68][  140/  196]   Loss 0.266989   Top1 90.678013   Top5 99.107143   BatchTime 0.385970   LR 0.000003   
2022-11-25 12:50:14,812 - INFO  - Training [68][  160/  196]   Loss 0.270806   Top1 90.566406   Top5 99.104004   BatchTime 0.383116   LR 0.000003   
2022-11-25 12:50:21,326 - INFO  - Training [68][  180/  196]   Loss 0.271616   Top1 90.512153   Top5 99.088542   BatchTime 0.376733   LR 0.000002   
2022-11-25 12:50:26,820 - INFO  - ==> Top1: 90.514    Top5: 99.092    Loss: 0.271

2022-11-25 12:50:27,046 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:50:28,466 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:50:31,259 - INFO  - Validation [68][   20/   40]   Loss 0.402186   Top1 87.558594   Top5 99.433594   BatchTime 0.139539   
2022-11-25 12:50:32,438 - INFO  - Validation [68][   40/   40]   Loss 0.394141   Top1 87.670000   Top5 99.510000   BatchTime 0.099256   
2022-11-25 12:50:32,869 - INFO  - ==> Top1: 87.670    Top5: 99.510    Loss: 0.394

2022-11-25 12:50:32,869 - INFO  - ==> Sparsity : 0.347

2022-11-25 12:50:32,869 - INFO  - Scoreboard best 1 ==> Epoch [61][Top1: 91.330   Top5: 99.760]
2022-11-25 12:50:32,870 - INFO  - Scoreboard best 2 ==> Epoch [60][Top1: 91.230   Top5: 99.800]
2022-11-25 12:50:32,870 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 91.100   Top5: 99.740]
2022-11-25 12:50:32,998 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar

2022-11-25 12:50:32,999 - INFO  - >>>>>> Epoch  69
2022-11-25 12:50:33,001 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:50:42,507 - INFO  - Training [69][   20/  196]   Loss 0.287560   Top1 89.531250   Top5 98.808594   BatchTime 0.475154   LR 0.000002   
2022-11-25 12:50:49,959 - INFO  - Training [69][   40/  196]   Loss 0.287938   Top1 89.677734   Top5 98.867188   BatchTime 0.423881   LR 0.000001   
2022-11-25 12:50:57,328 - INFO  - Training [69][   60/  196]   Loss 0.278816   Top1 90.162760   Top5 98.997396   BatchTime 0.405396   LR 0.000001   
2022-11-25 12:51:05,075 - INFO  - Training [69][   80/  196]   Loss 0.275554   Top1 90.322266   Top5 99.091797   BatchTime 0.400879   LR 0.000001   
2022-11-25 12:51:12,369 - INFO  - Training [69][  100/  196]   Loss 0.269761   Top1 90.558594   Top5 99.105469   BatchTime 0.393642   LR 0.000000   
2022-11-25 12:51:19,739 - INFO  - Training [69][  120/  196]   Loss 0.263866   Top1 90.758464   Top5 99.150391   BatchTime 0.389457   LR 0.000000   
2022-11-25 12:51:27,235 - INFO  - Training [69][  140/  196]   Loss 0.262705   Top1 90.828683   Top5 99.190848   BatchTime 0.387358   LR 0.000000   
2022-11-25 12:51:34,507 - INFO  - Training [69][  160/  196]   Loss 0.266549   Top1 90.727539   Top5 99.187012   BatchTime 0.384390   LR 0.000000   
2022-11-25 12:51:40,534 - INFO  - Training [69][  180/  196]   Loss 0.266322   Top1 90.724826   Top5 99.153646   BatchTime 0.375161   LR 0.000000   
2022-11-25 12:51:46,509 - INFO  - ==> Top1: 90.730    Top5: 99.150    Loss: 0.266

2022-11-25 12:51:46,770 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:51:48,958 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:51:53,342 - INFO  - Validation [69][   20/   40]   Loss 0.296965   Top1 91.328125   Top5 99.746094   BatchTime 0.219103   
2022-11-25 12:51:55,393 - INFO  - Validation [69][   40/   40]   Loss 0.281931   Top1 91.480000   Top5 99.760000   BatchTime 0.160823   
2022-11-25 12:51:55,661 - INFO  - ==> Top1: 91.480    Top5: 99.760    Loss: 0.282

2022-11-25 12:51:55,662 - INFO  - ==> Sparsity : 0.347

2022-11-25 12:51:55,662 - INFO  - Scoreboard best 1 ==> Epoch [69][Top1: 91.480   Top5: 99.760]
2022-11-25 12:51:55,662 - INFO  - Scoreboard best 2 ==> Epoch [61][Top1: 91.330   Top5: 99.760]
2022-11-25 12:51:55,662 - INFO  - Scoreboard best 3 ==> Epoch [60][Top1: 91.230   Top5: 99.800]
2022-11-25 12:52:00,935 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/_best.pth.tar
save quantized models...
2022-11-25 12:52:00,940 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 12:52:00,940 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:52:03,570 - INFO  - Validation [   20/   40]   Loss 0.296965   Top1 91.328125   Top5 99.746094   BatchTime 0.131434   
2022-11-25 12:52:04,701 - INFO  - Validation [   40/   40]   Loss 0.281931   Top1 91.480000   Top5 99.760000   BatchTime 0.093978   
2022-11-25 12:52:04,842 - INFO  - ==> Top1: 91.480    Top5: 99.760    Loss: 0.282

2022-11-25 12:52:04,843 - INFO  - ==> Sparsity : 0.000

2022-11-25 12:52:04,843 - INFO  - Program completed sucessfully ... exiting ...
2022-11-25 12:52:04,860 - INFO  - >>>>>> Epoch   0
2022-11-25 12:52:04,862 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:52:13,259 - INFO  - Training [0][   20/  196]   Loss 0.509814   Top1 82.675781   Top5 97.734375   BatchTime 0.419695   LR 0.004999   
2022-11-25 12:52:20,097 - INFO  - Training [0][   40/  196]   Loss 0.529756   Top1 82.031250   Top5 97.841797   BatchTime 0.380801   LR 0.004995   
2022-11-25 12:52:27,083 - INFO  - Training [0][   60/  196]   Loss 0.522994   Top1 82.180990   Top5 97.910156   BatchTime 0.370300   LR 0.004989   
2022-11-25 12:52:33,993 - INFO  - Training [0][   80/  196]   Loss 0.519268   Top1 82.255859   Top5 98.041992   BatchTime 0.364097   LR 0.004980   
2022-11-25 12:52:40,832 - INFO  - Training [0][  100/  196]   Loss 0.512522   Top1 82.449219   Top5 98.121094   BatchTime 0.359674   LR 0.004968   
2022-11-25 12:52:47,074 - INFO  - Training [0][  120/  196]   Loss 0.508112   Top1 82.548828   Top5 98.203125   BatchTime 0.351741   LR 0.004954   
2022-11-25 12:52:52,455 - INFO  - Training [0][  140/  196]   Loss 0.511524   Top1 82.368862   Top5 98.256138   BatchTime 0.339930   LR 0.004938   
2022-11-25 12:52:59,078 - INFO  - Training [0][  160/  196]   Loss 0.516164   Top1 82.221680   Top5 98.229980   BatchTime 0.338828   LR 0.004919   
2022-11-25 12:53:05,845 - INFO  - Training [0][  180/  196]   Loss 0.518519   Top1 82.105035   Top5 98.140191   BatchTime 0.338775   LR 0.004897   
2022-11-25 12:53:12,193 - INFO  - ==> Top1: 82.074    Top5: 98.150    Loss: 0.519

2022-11-25 12:53:12,470 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:53:14,160 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:53:18,467 - INFO  - Validation [0][   20/   40]   Loss 0.514612   Top1 83.066406   Top5 99.199219   BatchTime 0.215284   
2022-11-25 12:53:19,493 - INFO  - Validation [0][   40/   40]   Loss 0.510492   Top1 83.220000   Top5 99.290000   BatchTime 0.133293   
2022-11-25 12:53:19,706 - INFO  - ==> Top1: 83.220    Top5: 99.290    Loss: 0.510

2022-11-25 12:53:19,706 - INFO  - ==> Sparsity : 0.369

2022-11-25 12:53:19,706 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 83.220   Top5: 99.290]
2022-11-25 12:53:25,028 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:53:25,033 - INFO  - >>>>>> Epoch   1
2022-11-25 12:53:25,034 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:53:33,277 - INFO  - Training [1][   20/  196]   Loss 0.556592   Top1 80.781250   Top5 97.070312   BatchTime 0.412023   LR 0.004853   
2022-11-25 12:53:40,136 - INFO  - Training [1][   40/  196]   Loss 0.544163   Top1 81.416016   Top5 97.529297   BatchTime 0.377475   LR 0.004825   
2022-11-25 12:53:47,149 - INFO  - Training [1][   60/  196]   Loss 0.544920   Top1 81.549479   Top5 97.675781   BatchTime 0.368542   LR 0.004794   
2022-11-25 12:53:53,960 - INFO  - Training [1][   80/  196]   Loss 0.545180   Top1 81.396484   Top5 97.851562   BatchTime 0.361533   LR 0.004761   
2022-11-25 12:54:00,286 - INFO  - Training [1][  100/  196]   Loss 0.533951   Top1 81.738281   Top5 97.980469   BatchTime 0.352492   LR 0.004725   
2022-11-25 12:54:05,765 - INFO  - Training [1][  120/  196]   Loss 0.527134   Top1 81.910807   Top5 98.072917   BatchTime 0.339399   LR 0.004687   
2022-11-25 12:54:10,880 - INFO  - Training [1][  140/  196]   Loss 0.524866   Top1 81.978237   Top5 98.152902   BatchTime 0.327444   LR 0.004647   
2022-11-25 12:54:17,295 - INFO  - Training [1][  160/  196]   Loss 0.526782   Top1 81.923828   Top5 98.164062   BatchTime 0.326610   LR 0.004605   
2022-11-25 12:54:24,454 - INFO  - Training [1][  180/  196]   Loss 0.526249   Top1 81.881510   Top5 98.151042   BatchTime 0.330089   LR 0.004560   
2022-11-25 12:54:30,216 - INFO  - ==> Top1: 81.956    Top5: 98.160    Loss: 0.525

2022-11-25 12:54:30,533 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:54:32,998 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:54:35,657 - INFO  - Validation [1][   20/   40]   Loss 0.440961   Top1 85.585938   Top5 99.511719   BatchTime 0.132870   
2022-11-25 12:54:36,892 - INFO  - Validation [1][   40/   40]   Loss 0.433666   Top1 85.610000   Top5 99.580000   BatchTime 0.097317   
2022-11-25 12:54:37,179 - INFO  - ==> Top1: 85.610    Top5: 99.580    Loss: 0.434

2022-11-25 12:54:37,180 - INFO  - ==> Sparsity : 0.366

2022-11-25 12:54:37,180 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 85.610   Top5: 99.580]
2022-11-25 12:54:37,180 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 83.220   Top5: 99.290]
2022-11-25 12:54:42,768 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:54:42,774 - INFO  - >>>>>> Epoch   2
2022-11-25 12:54:42,776 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:54:51,333 - INFO  - Training [2][   20/  196]   Loss 0.507390   Top1 82.656250   Top5 97.753906   BatchTime 0.427696   LR 0.004477   
2022-11-25 12:54:58,261 - INFO  - Training [2][   40/  196]   Loss 0.510347   Top1 82.578125   Top5 97.910156   BatchTime 0.387063   LR 0.004426   
2022-11-25 12:55:05,009 - INFO  - Training [2][   60/  196]   Loss 0.504793   Top1 82.858073   Top5 97.942708   BatchTime 0.370505   LR 0.004374   
2022-11-25 12:55:11,930 - INFO  - Training [2][   80/  196]   Loss 0.508064   Top1 82.705078   Top5 98.061523   BatchTime 0.364380   LR 0.004320   
2022-11-25 12:55:18,620 - INFO  - Training [2][  100/  196]   Loss 0.504502   Top1 82.765625   Top5 98.097656   BatchTime 0.358408   LR 0.004264   
2022-11-25 12:55:23,972 - INFO  - Training [2][  120/  196]   Loss 0.499583   Top1 82.897135   Top5 98.206380   BatchTime 0.343277   LR 0.004206   
2022-11-25 12:55:29,185 - INFO  - Training [2][  140/  196]   Loss 0.499215   Top1 82.921317   Top5 98.247768   BatchTime 0.331471   LR 0.004146   
2022-11-25 12:55:35,913 - INFO  - Training [2][  160/  196]   Loss 0.500572   Top1 82.839355   Top5 98.273926   BatchTime 0.332085   LR 0.004085   
2022-11-25 12:55:42,785 - INFO  - Training [2][  180/  196]   Loss 0.503540   Top1 82.706163   Top5 98.246528   BatchTime 0.333361   LR 0.004022   
2022-11-25 12:55:48,479 - INFO  - ==> Top1: 82.786    Top5: 98.234    Loss: 0.502

2022-11-25 12:55:48,759 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:55:50,570 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:55:53,939 - INFO  - Validation [2][   20/   40]   Loss 0.407038   Top1 86.914062   Top5 99.472656   BatchTime 0.168325   
2022-11-25 12:55:54,938 - INFO  - Validation [2][   40/   40]   Loss 0.392993   Top1 86.970000   Top5 99.560000   BatchTime 0.109160   
2022-11-25 12:55:55,179 - INFO  - ==> Top1: 86.970    Top5: 99.560    Loss: 0.393

2022-11-25 12:55:55,179 - INFO  - ==> Sparsity : 0.362

2022-11-25 12:55:55,179 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 86.970   Top5: 99.560]
2022-11-25 12:55:55,179 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 85.610   Top5: 99.580]
2022-11-25 12:55:55,179 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 83.220   Top5: 99.290]
2022-11-25 12:56:01,102 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:56:01,104 - INFO  - >>>>>> Epoch   3
2022-11-25 12:56:01,106 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:56:09,688 - INFO  - Training [3][   20/  196]   Loss 0.493719   Top1 82.500000   Top5 98.183594   BatchTime 0.428923   LR 0.003907   
2022-11-25 12:56:16,443 - INFO  - Training [3][   40/  196]   Loss 0.497120   Top1 82.656250   Top5 98.173828   BatchTime 0.383330   LR 0.003840   
2022-11-25 12:56:23,269 - INFO  - Training [3][   60/  196]   Loss 0.494389   Top1 82.910156   Top5 98.209635   BatchTime 0.369318   LR 0.003771   
2022-11-25 12:56:30,023 - INFO  - Training [3][   80/  196]   Loss 0.492513   Top1 83.066406   Top5 98.320312   BatchTime 0.361420   LR 0.003701   
2022-11-25 12:56:36,824 - INFO  - Training [3][  100/  196]   Loss 0.487056   Top1 83.214844   Top5 98.382812   BatchTime 0.357143   LR 0.003630   
2022-11-25 12:56:42,361 - INFO  - Training [3][  120/  196]   Loss 0.482263   Top1 83.404948   Top5 98.401693   BatchTime 0.343764   LR 0.003558   
2022-11-25 12:56:48,311 - INFO  - Training [3][  140/  196]   Loss 0.477981   Top1 83.510045   Top5 98.490513   BatchTime 0.337150   LR 0.003484   
2022-11-25 12:56:53,655 - INFO  - Training [3][  160/  196]   Loss 0.480311   Top1 83.417969   Top5 98.464355   BatchTime 0.328407   LR 0.003410   
2022-11-25 12:57:00,658 - INFO  - Training [3][  180/  196]   Loss 0.477564   Top1 83.519965   Top5 98.430990   BatchTime 0.330821   LR 0.003335   
2022-11-25 12:57:06,059 - INFO  - ==> Top1: 83.602    Top5: 98.430    Loss: 0.475

2022-11-25 12:57:06,392 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:57:07,971 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:57:11,958 - INFO  - Validation [3][   20/   40]   Loss 0.404385   Top1 86.875000   Top5 99.355469   BatchTime 0.199258   
2022-11-25 12:57:12,953 - INFO  - Validation [3][   40/   40]   Loss 0.388466   Top1 87.210000   Top5 99.530000   BatchTime 0.124518   
2022-11-25 12:57:13,186 - INFO  - ==> Top1: 87.210    Top5: 99.530    Loss: 0.388

2022-11-25 12:57:13,186 - INFO  - ==> Sparsity : 0.373

2022-11-25 12:57:13,187 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 87.210   Top5: 99.530]
2022-11-25 12:57:13,187 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 86.970   Top5: 99.560]
2022-11-25 12:57:13,187 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 85.610   Top5: 99.580]
2022-11-25 12:57:18,865 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:57:18,869 - INFO  - >>>>>> Epoch   4
2022-11-25 12:57:18,872 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:57:27,490 - INFO  - Training [4][   20/  196]   Loss 0.557534   Top1 79.941406   Top5 96.953125   BatchTime 0.430761   LR 0.003200   
2022-11-25 12:57:34,257 - INFO  - Training [4][   40/  196]   Loss 0.509108   Top1 82.158203   Top5 97.753906   BatchTime 0.384553   LR 0.003122   
2022-11-25 12:57:41,152 - INFO  - Training [4][   60/  196]   Loss 0.490109   Top1 82.805990   Top5 97.988281   BatchTime 0.371283   LR 0.003044   
2022-11-25 12:57:47,961 - INFO  - Training [4][   80/  196]   Loss 0.478864   Top1 83.247070   Top5 98.159180   BatchTime 0.363577   LR 0.002965   
2022-11-25 12:57:54,957 - INFO  - Training [4][  100/  196]   Loss 0.467453   Top1 83.707031   Top5 98.234375   BatchTime 0.360816   LR 0.002886   
2022-11-25 12:58:01,834 - INFO  - Training [4][  120/  196]   Loss 0.464810   Top1 83.815104   Top5 98.333333   BatchTime 0.357988   LR 0.002806   
2022-11-25 12:58:07,121 - INFO  - Training [4][  140/  196]   Loss 0.462108   Top1 83.911830   Top5 98.409598   BatchTime 0.344610   LR 0.002726   
2022-11-25 12:58:14,013 - INFO  - Training [4][  160/  196]   Loss 0.459014   Top1 83.994141   Top5 98.444824   BatchTime 0.344608   LR 0.002646   
2022-11-25 12:58:20,818 - INFO  - Training [4][  180/  196]   Loss 0.453413   Top1 84.179688   Top5 98.444010   BatchTime 0.344123   LR 0.002566   
2022-11-25 12:58:26,844 - INFO  - ==> Top1: 84.264    Top5: 98.472    Loss: 0.451

2022-11-25 12:58:27,094 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:58:28,650 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:58:31,326 - INFO  - Validation [4][   20/   40]   Loss 0.346948   Top1 88.691406   Top5 99.648438   BatchTime 0.133691   
2022-11-25 12:58:32,410 - INFO  - Validation [4][   40/   40]   Loss 0.337081   Top1 88.750000   Top5 99.660000   BatchTime 0.093965   
2022-11-25 12:58:32,646 - INFO  - ==> Top1: 88.750    Top5: 99.660    Loss: 0.337

2022-11-25 12:58:32,647 - INFO  - ==> Sparsity : 0.376

2022-11-25 12:58:32,647 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 88.750   Top5: 99.660]
2022-11-25 12:58:32,647 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 87.210   Top5: 99.530]
2022-11-25 12:58:32,647 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 86.970   Top5: 99.560]
2022-11-25 12:58:39,000 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:58:39,004 - INFO  - >>>>>> Epoch   5
2022-11-25 12:58:39,005 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:58:47,576 - INFO  - Training [5][   20/  196]   Loss 0.434711   Top1 85.234375   Top5 98.320312   BatchTime 0.428413   LR 0.002424   
2022-11-25 12:58:54,250 - INFO  - Training [5][   40/  196]   Loss 0.434188   Top1 84.980469   Top5 98.378906   BatchTime 0.381040   LR 0.002343   
2022-11-25 12:59:01,185 - INFO  - Training [5][   60/  196]   Loss 0.423975   Top1 85.351562   Top5 98.548177   BatchTime 0.369613   LR 0.002263   
2022-11-25 12:59:08,061 - INFO  - Training [5][   80/  196]   Loss 0.416832   Top1 85.629883   Top5 98.681641   BatchTime 0.363163   LR 0.002183   
2022-11-25 12:59:14,585 - INFO  - Training [5][  100/  196]   Loss 0.411178   Top1 85.785156   Top5 98.714844   BatchTime 0.355763   LR 0.002104   
2022-11-25 12:59:20,168 - INFO  - Training [5][  120/  196]   Loss 0.402338   Top1 86.064453   Top5 98.785807   BatchTime 0.342999   LR 0.002024   
2022-11-25 12:59:26,882 - INFO  - Training [5][  140/  196]   Loss 0.401321   Top1 86.040737   Top5 98.803013   BatchTime 0.341955   LR 0.001946   
2022-11-25 12:59:33,652 - INFO  - Training [5][  160/  196]   Loss 0.405084   Top1 85.910645   Top5 98.764648   BatchTime 0.341520   LR 0.001868   
2022-11-25 12:59:41,074 - INFO  - Training [5][  180/  196]   Loss 0.405875   Top1 85.883247   Top5 98.721788   BatchTime 0.344807   LR 0.001790   
2022-11-25 12:59:46,904 - INFO  - ==> Top1: 85.914    Top5: 98.718    Loss: 0.405

2022-11-25 12:59:47,136 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:59:48,528 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:59:51,146 - INFO  - Validation [5][   20/   40]   Loss 0.328266   Top1 89.082031   Top5 99.570312   BatchTime 0.130777   
2022-11-25 12:59:52,245 - INFO  - Validation [5][   40/   40]   Loss 0.311732   Top1 89.700000   Top5 99.660000   BatchTime 0.092891   
2022-11-25 12:59:52,522 - INFO  - ==> Top1: 89.700    Top5: 99.660    Loss: 0.312

2022-11-25 12:59:52,523 - INFO  - ==> Sparsity : 0.375

2022-11-25 12:59:52,523 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 89.700   Top5: 99.660]
2022-11-25 12:59:52,523 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 88.750   Top5: 99.660]
2022-11-25 12:59:52,523 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 87.210   Top5: 99.530]
2022-11-25 12:59:57,865 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:59:57,867 - INFO  - >>>>>> Epoch   6
2022-11-25 12:59:57,869 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:00:06,326 - INFO  - Training [6][   20/  196]   Loss 0.395720   Top1 85.917969   Top5 98.320312   BatchTime 0.422730   LR 0.001655   
2022-11-25 13:00:13,456 - INFO  - Training [6][   40/  196]   Loss 0.391925   Top1 86.005859   Top5 98.457031   BatchTime 0.389613   LR 0.001580   
2022-11-25 13:00:20,272 - INFO  - Training [6][   60/  196]   Loss 0.387348   Top1 86.217448   Top5 98.554688   BatchTime 0.373334   LR 0.001506   
2022-11-25 13:00:26,744 - INFO  - Training [6][   80/  196]   Loss 0.383176   Top1 86.391602   Top5 98.662109   BatchTime 0.360907   LR 0.001432   
2022-11-25 13:00:32,521 - INFO  - Training [6][  100/  196]   Loss 0.380734   Top1 86.566406   Top5 98.730469   BatchTime 0.346496   LR 0.001360   
2022-11-25 13:00:39,377 - INFO  - Training [6][  120/  196]   Loss 0.375145   Top1 86.829427   Top5 98.779297   BatchTime 0.345880   LR 0.001289   
2022-11-25 13:00:46,316 - INFO  - Training [6][  140/  196]   Loss 0.373687   Top1 86.886161   Top5 98.825335   BatchTime 0.346032   LR 0.001220   
2022-11-25 13:00:53,164 - INFO  - Training [6][  160/  196]   Loss 0.373370   Top1 86.901855   Top5 98.828125   BatchTime 0.345575   LR 0.001151   
2022-11-25 13:01:00,009 - INFO  - Training [6][  180/  196]   Loss 0.371689   Top1 86.883681   Top5 98.817274   BatchTime 0.345207   LR 0.001084   
2022-11-25 13:01:05,571 - INFO  - ==> Top1: 86.940    Top5: 98.804    Loss: 0.371

2022-11-25 13:01:05,867 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:01:07,352 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:01:10,001 - INFO  - Validation [6][   20/   40]   Loss 0.290795   Top1 90.351562   Top5 99.667969   BatchTime 0.132358   
2022-11-25 13:01:11,116 - INFO  - Validation [6][   40/   40]   Loss 0.278833   Top1 90.870000   Top5 99.710000   BatchTime 0.094062   
2022-11-25 13:01:11,388 - INFO  - ==> Top1: 90.870    Top5: 99.710    Loss: 0.279

2022-11-25 13:01:11,389 - INFO  - ==> Sparsity : 0.373

2022-11-25 13:01:11,389 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.870   Top5: 99.710]
2022-11-25 13:01:11,390 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.700   Top5: 99.660]
2022-11-25 13:01:11,390 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 88.750   Top5: 99.660]
2022-11-25 13:01:16,555 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 13:01:16,559 - INFO  - >>>>>> Epoch   7
2022-11-25 13:01:16,562 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:01:24,898 - INFO  - Training [7][   20/  196]   Loss 0.387712   Top1 86.191406   Top5 97.988281   BatchTime 0.416714   LR 0.000969   
2022-11-25 13:01:31,849 - INFO  - Training [7][   40/  196]   Loss 0.376897   Top1 86.748047   Top5 98.339844   BatchTime 0.382135   LR 0.000907   
2022-11-25 13:01:38,903 - INFO  - Training [7][   60/  196]   Loss 0.373950   Top1 86.875000   Top5 98.450521   BatchTime 0.372310   LR 0.000845   
2022-11-25 13:01:44,451 - INFO  - Training [7][   80/  196]   Loss 0.363762   Top1 87.182617   Top5 98.623047   BatchTime 0.348590   LR 0.000786   
2022-11-25 13:01:50,967 - INFO  - Training [7][  100/  196]   Loss 0.356203   Top1 87.453125   Top5 98.714844   BatchTime 0.344027   LR 0.000728   
2022-11-25 13:01:57,799 - INFO  - Training [7][  120/  196]   Loss 0.349064   Top1 87.757161   Top5 98.834635   BatchTime 0.343618   LR 0.000673   
2022-11-25 13:02:04,817 - INFO  - Training [7][  140/  196]   Loss 0.345995   Top1 87.845982   Top5 98.900670   BatchTime 0.344663   LR 0.000619   
2022-11-25 13:02:11,980 - INFO  - Training [7][  160/  196]   Loss 0.345638   Top1 87.863770   Top5 98.903809   BatchTime 0.346345   LR 0.000567   
2022-11-25 13:02:18,853 - INFO  - Training [7][  180/  196]   Loss 0.344990   Top1 87.888455   Top5 98.893229   BatchTime 0.346045   LR 0.000517   
2022-11-25 13:02:24,563 - INFO  - ==> Top1: 87.970    Top5: 98.888    Loss: 0.343

2022-11-25 13:02:24,962 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:02:26,749 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:02:29,569 - INFO  - Validation [7][   20/   40]   Loss 0.303913   Top1 90.312500   Top5 99.707031   BatchTime 0.140904   
2022-11-25 13:02:30,659 - INFO  - Validation [7][   40/   40]   Loss 0.282415   Top1 90.920000   Top5 99.790000   BatchTime 0.097697   
2022-11-25 13:02:30,894 - INFO  - ==> Top1: 90.920    Top5: 99.790    Loss: 0.282

2022-11-25 13:02:30,894 - INFO  - ==> Sparsity : 0.373

2022-11-25 13:02:30,895 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:02:30,895 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 90.870   Top5: 99.710]
2022-11-25 13:02:30,895 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 89.700   Top5: 99.660]
2022-11-25 13:02:35,924 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 13:02:35,929 - INFO  - >>>>>> Epoch   8
2022-11-25 13:02:35,931 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:02:44,592 - INFO  - Training [8][   20/  196]   Loss 0.346822   Top1 87.558594   Top5 98.457031   BatchTime 0.432924   LR 0.000434   
2022-11-25 13:02:51,578 - INFO  - Training [8][   40/  196]   Loss 0.346510   Top1 87.695312   Top5 98.662109   BatchTime 0.391102   LR 0.000389   
2022-11-25 13:02:57,464 - INFO  - Training [8][   60/  196]   Loss 0.338593   Top1 88.183594   Top5 98.710938   BatchTime 0.358829   LR 0.000347   
2022-11-25 13:03:04,081 - INFO  - Training [8][   80/  196]   Loss 0.341942   Top1 87.983398   Top5 98.818359   BatchTime 0.351837   LR 0.000308   
2022-11-25 13:03:10,807 - INFO  - Training [8][  100/  196]   Loss 0.333236   Top1 88.257812   Top5 98.898438   BatchTime 0.348729   LR 0.000270   
2022-11-25 13:03:17,570 - INFO  - Training [8][  120/  196]   Loss 0.328718   Top1 88.430990   Top5 98.990885   BatchTime 0.346965   LR 0.000235   
2022-11-25 13:03:24,791 - INFO  - Training [8][  140/  196]   Loss 0.326503   Top1 88.518415   Top5 99.031808   BatchTime 0.348975   LR 0.000202   
2022-11-25 13:03:31,638 - INFO  - Training [8][  160/  196]   Loss 0.329184   Top1 88.452148   Top5 99.013672   BatchTime 0.348147   LR 0.000172   
2022-11-25 13:03:38,430 - INFO  - Training [8][  180/  196]   Loss 0.329115   Top1 88.459201   Top5 98.982205   BatchTime 0.347197   LR 0.000143   
2022-11-25 13:03:44,058 - INFO  - ==> Top1: 88.496    Top5: 98.968    Loss: 0.329

2022-11-25 13:03:44,305 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:03:45,708 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:03:48,299 - INFO  - Validation [8][   20/   40]   Loss 0.278540   Top1 91.054688   Top5 99.765625   BatchTime 0.129458   
2022-11-25 13:03:49,363 - INFO  - Validation [8][   40/   40]   Loss 0.265045   Top1 91.270000   Top5 99.800000   BatchTime 0.091339   
2022-11-25 13:03:49,616 - INFO  - ==> Top1: 91.270    Top5: 99.800    Loss: 0.265

2022-11-25 13:03:49,617 - INFO  - ==> Sparsity : 0.373

2022-11-25 13:03:49,617 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:03:49,617 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:03:49,617 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.870   Top5: 99.710]
2022-11-25 13:03:55,610 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 13:03:55,615 - INFO  - >>>>>> Epoch   9
2022-11-25 13:03:55,618 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:04:04,593 - INFO  - Training [9][   20/  196]   Loss 0.353595   Top1 87.500000   Top5 98.242188   BatchTime 0.448619   LR 0.000100   
2022-11-25 13:04:10,463 - INFO  - Training [9][   40/  196]   Loss 0.344110   Top1 87.939453   Top5 98.525391   BatchTime 0.371059   LR 0.000079   
2022-11-25 13:04:16,233 - INFO  - Training [9][   60/  196]   Loss 0.339212   Top1 88.125000   Top5 98.671875   BatchTime 0.343535   LR 0.000060   
2022-11-25 13:04:23,124 - INFO  - Training [9][   80/  196]   Loss 0.335175   Top1 88.251953   Top5 98.789062   BatchTime 0.343794   LR 0.000044   
2022-11-25 13:04:29,925 - INFO  - Training [9][  100/  196]   Loss 0.330390   Top1 88.390625   Top5 98.843750   BatchTime 0.343039   LR 0.000030   
2022-11-25 13:04:36,961 - INFO  - Training [9][  120/  196]   Loss 0.323004   Top1 88.626302   Top5 98.916016   BatchTime 0.344505   LR 0.000019   
2022-11-25 13:04:43,844 - INFO  - Training [9][  140/  196]   Loss 0.321536   Top1 88.713728   Top5 98.978795   BatchTime 0.344453   LR 0.000010   
2022-11-25 13:04:50,728 - INFO  - Training [9][  160/  196]   Loss 0.324150   Top1 88.571777   Top5 99.008789   BatchTime 0.344420   LR 0.000004   
2022-11-25 13:04:57,596 - INFO  - Training [9][  180/  196]   Loss 0.323873   Top1 88.574219   Top5 98.980035   BatchTime 0.344306   LR 0.000001   
2022-11-25 13:05:03,283 - INFO  - ==> Top1: 88.650    Top5: 98.976    Loss: 0.323

2022-11-25 13:05:03,573 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:05:05,072 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:05:07,781 - INFO  - Validation [9][   20/   40]   Loss 0.294323   Top1 90.781250   Top5 99.707031   BatchTime 0.135312   
2022-11-25 13:05:08,901 - INFO  - Validation [9][   40/   40]   Loss 0.277061   Top1 91.120000   Top5 99.790000   BatchTime 0.095681   
2022-11-25 13:05:09,171 - INFO  - ==> Top1: 91.120    Top5: 99.790    Loss: 0.277

2022-11-25 13:05:09,171 - INFO  - ==> Sparsity : 0.373

2022-11-25 13:05:09,171 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:05:09,171 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:05:09,171 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:05:09,291 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:05:09,292 - INFO  - >>>>>> Epoch  10
2022-11-25 13:05:09,294 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:05:18,358 - INFO  - Training [10][   20/  196]   Loss 0.385294   Top1 85.703125   Top5 98.437500   BatchTime 0.453060   LR 0.002500   
2022-11-25 13:05:24,287 - INFO  - Training [10][   40/  196]   Loss 0.387518   Top1 85.937500   Top5 98.593750   BatchTime 0.374740   LR 0.002499   
2022-11-25 13:05:30,115 - INFO  - Training [10][   60/  196]   Loss 0.385490   Top1 86.263021   Top5 98.717448   BatchTime 0.346973   LR 0.002499   
2022-11-25 13:05:37,000 - INFO  - Training [10][   80/  196]   Loss 0.391386   Top1 86.230469   Top5 98.803711   BatchTime 0.346285   LR 0.002497   
2022-11-25 13:05:43,917 - INFO  - Training [10][  100/  196]   Loss 0.385910   Top1 86.375000   Top5 98.832031   BatchTime 0.346198   LR 0.002496   
2022-11-25 13:05:51,170 - INFO  - Training [10][  120/  196]   Loss 0.383973   Top1 86.455078   Top5 98.899740   BatchTime 0.348937   LR 0.002494   
2022-11-25 13:05:57,959 - INFO  - Training [10][  140/  196]   Loss 0.387008   Top1 86.316964   Top5 98.909040   BatchTime 0.347584   LR 0.002492   
2022-11-25 13:06:04,765 - INFO  - Training [10][  160/  196]   Loss 0.390530   Top1 86.203613   Top5 98.894043   BatchTime 0.346673   LR 0.002490   
2022-11-25 13:06:11,550 - INFO  - Training [10][  180/  196]   Loss 0.390095   Top1 86.191406   Top5 98.854167   BatchTime 0.345845   LR 0.002487   
2022-11-25 13:06:17,104 - INFO  - ==> Top1: 86.246    Top5: 98.842    Loss: 0.390

2022-11-25 13:06:17,353 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:06:18,929 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:06:21,551 - INFO  - Validation [10][   20/   40]   Loss 0.368336   Top1 87.968750   Top5 99.531250   BatchTime 0.130994   
2022-11-25 13:06:22,631 - INFO  - Validation [10][   40/   40]   Loss 0.353132   Top1 88.150000   Top5 99.580000   BatchTime 0.092506   
2022-11-25 13:06:22,860 - INFO  - ==> Top1: 88.150    Top5: 99.580    Loss: 0.353

2022-11-25 13:06:22,860 - INFO  - ==> Sparsity : 0.376

2022-11-25 13:06:22,860 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:06:22,860 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:06:22,860 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:06:22,992 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:06:22,994 - INFO  - >>>>>> Epoch  11
2022-11-25 13:06:22,996 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:06:32,007 - INFO  - Training [11][   20/  196]   Loss 0.400455   Top1 86.250000   Top5 98.242188   BatchTime 0.450434   LR 0.002481   
2022-11-25 13:06:38,710 - INFO  - Training [11][   40/  196]   Loss 0.404263   Top1 86.210938   Top5 98.437500   BatchTime 0.392793   LR 0.002478   
2022-11-25 13:06:43,952 - INFO  - Training [11][   60/  196]   Loss 0.400269   Top1 86.250000   Top5 98.535156   BatchTime 0.349228   LR 0.002474   
2022-11-25 13:06:50,134 - INFO  - Training [11][   80/  196]   Loss 0.402630   Top1 86.035156   Top5 98.632812   BatchTime 0.339196   LR 0.002470   
2022-11-25 13:06:56,977 - INFO  - Training [11][  100/  196]   Loss 0.398813   Top1 86.175781   Top5 98.640625   BatchTime 0.339780   LR 0.002465   
2022-11-25 13:07:04,182 - INFO  - Training [11][  120/  196]   Loss 0.396859   Top1 86.184896   Top5 98.707682   BatchTime 0.343191   LR 0.002460   
2022-11-25 13:07:11,135 - INFO  - Training [11][  140/  196]   Loss 0.398132   Top1 86.074219   Top5 98.741629   BatchTime 0.343829   LR 0.002455   
2022-11-25 13:07:17,842 - INFO  - Training [11][  160/  196]   Loss 0.400424   Top1 86.008301   Top5 98.730469   BatchTime 0.342770   LR 0.002450   
2022-11-25 13:07:24,835 - INFO  - Training [11][  180/  196]   Loss 0.399958   Top1 86.004774   Top5 98.719618   BatchTime 0.343531   LR 0.002444   
2022-11-25 13:07:30,470 - INFO  - ==> Top1: 84.850    Top5: 98.310    Loss: 0.452

2022-11-25 13:07:30,746 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:07:32,192 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:07:34,953 - INFO  - Validation [11][   20/   40]   Loss 2.420888   Top1 10.214844   Top5 50.019531   BatchTime 0.137945   
2022-11-25 13:07:36,046 - INFO  - Validation [11][   40/   40]   Loss 2.420902   Top1 9.990000   Top5 50.000000   BatchTime 0.096314   
2022-11-25 13:07:36,291 - INFO  - ==> Top1: 9.990    Top5: 50.000    Loss: 2.421

2022-11-25 13:07:36,291 - INFO  - ==> Sparsity : 0.373

2022-11-25 13:07:36,292 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:07:36,292 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:07:36,292 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:07:36,417 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:07:36,418 - INFO  - >>>>>> Epoch  12
2022-11-25 13:07:36,420 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:07:45,512 - INFO  - Training [12][   20/  196]   Loss 2.461069   Top1 11.171875   Top5 54.296875   BatchTime 0.454483   LR 0.002433   
2022-11-25 13:07:52,411 - INFO  - Training [12][   40/  196]   Loss 2.366173   Top1 12.128906   Top5 55.996094   BatchTime 0.399715   LR 0.002426   
2022-11-25 13:07:58,326 - INFO  - Training [12][   60/  196]   Loss 2.278921   Top1 15.214844   Top5 61.894531   BatchTime 0.365048   LR 0.002419   
2022-11-25 13:08:04,257 - INFO  - Training [12][   80/  196]   Loss 2.211597   Top1 17.890625   Top5 65.673828   BatchTime 0.347931   LR 0.002412   
2022-11-25 13:08:11,105 - INFO  - Training [12][  100/  196]   Loss 2.155210   Top1 19.910156   Top5 68.621094   BatchTime 0.346821   LR 0.002404   
2022-11-25 13:08:18,427 - INFO  - Training [12][  120/  196]   Loss 2.109240   Top1 21.761068   Top5 70.882161   BatchTime 0.350029   LR 0.002396   
2022-11-25 13:08:25,224 - INFO  - Training [12][  140/  196]   Loss 2.069282   Top1 23.356585   Top5 72.781808   BatchTime 0.348576   LR 0.002388   
2022-11-25 13:08:31,988 - INFO  - Training [12][  160/  196]   Loss 2.042153   Top1 24.418945   Top5 74.045410   BatchTime 0.347279   LR 0.002380   
2022-11-25 13:08:38,881 - INFO  - Training [12][  180/  196]   Loss 2.024511   Top1 24.995660   Top5 74.631076   BatchTime 0.346988   LR 0.002371   
2022-11-25 13:08:44,453 - INFO  - ==> Top1: 24.998    Top5: 74.342    Loss: 2.021

2022-11-25 13:08:44,677 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:08:46,076 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:08:49,102 - INFO  - Validation [12][   20/   40]   Loss 2.391814   Top1 10.117188   Top5 49.941406   BatchTime 0.151191   
2022-11-25 13:08:50,165 - INFO  - Validation [12][   40/   40]   Loss 2.391322   Top1 10.000000   Top5 50.000000   BatchTime 0.102190   
2022-11-25 13:08:50,405 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.391

2022-11-25 13:08:50,405 - INFO  - ==> Sparsity : 0.482

2022-11-25 13:08:50,405 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:08:50,406 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:08:50,406 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:08:50,809 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:08:50,810 - INFO  - >>>>>> Epoch  13
2022-11-25 13:08:50,812 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:08:59,499 - INFO  - Training [13][   20/  196]   Loss 2.078713   Top1 21.894531   Top5 65.097656   BatchTime 0.434201   LR 0.002355   
2022-11-25 13:09:07,016 - INFO  - Training [13][   40/  196]   Loss 2.197727   Top1 16.191406   Top5 57.070312   BatchTime 0.405023   LR 0.002345   
2022-11-25 13:09:13,036 - INFO  - Training [13][   60/  196]   Loss 2.234076   Top1 13.938802   Top5 54.752604   BatchTime 0.370354   LR 0.002336   
2022-11-25 13:09:18,557 - INFO  - Training [13][   80/  196]   Loss 2.252103   Top1 12.973633   Top5 53.408203   BatchTime 0.346777   LR 0.002325   
2022-11-25 13:09:25,769 - INFO  - Training [13][  100/  196]   Loss 2.262501   Top1 12.429688   Top5 52.808594   BatchTime 0.349540   LR 0.002315   
2022-11-25 13:09:32,836 - INFO  - Training [13][  120/  196]   Loss 2.269484   Top1 12.005208   Top5 52.382812   BatchTime 0.350173   LR 0.002304   
2022-11-25 13:09:39,670 - INFO  - Training [13][  140/  196]   Loss 2.274655   Top1 11.640625   Top5 52.045201   BatchTime 0.348963   LR 0.002293   
2022-11-25 13:09:46,496 - INFO  - Training [13][  160/  196]   Loss 2.278381   Top1 11.472168   Top5 51.765137   BatchTime 0.348006   LR 0.002282   
2022-11-25 13:09:53,348 - INFO  - Training [13][  180/  196]   Loss 2.281292   Top1 11.260851   Top5 51.516927   BatchTime 0.347404   LR 0.002271   
2022-11-25 13:09:58,929 - INFO  - ==> Top1: 11.146    Top5: 51.326    Loss: 2.283

2022-11-25 13:09:59,138 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:10:00,586 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:10:03,311 - INFO  - Validation [13][   20/   40]   Loss 2.303663   Top1 9.882812   Top5 49.687500   BatchTime 0.136148   
2022-11-25 13:10:04,454 - INFO  - Validation [13][   40/   40]   Loss 2.303339   Top1 10.000000   Top5 50.000000   BatchTime 0.096652   
2022-11-25 13:10:04,711 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:10:04,712 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:10:04,712 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:10:04,712 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:10:04,712 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:10:04,834 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:10:04,835 - INFO  - >>>>>> Epoch  14
2022-11-25 13:10:04,837 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:10:13,244 - INFO  - Training [14][   20/  196]   Loss 2.304434   Top1 9.902344   Top5 51.035156   BatchTime 0.420210   LR 0.002250   
2022-11-25 13:10:20,591 - INFO  - Training [14][   40/  196]   Loss 2.304369   Top1 10.175781   Top5 50.556641   BatchTime 0.393796   LR 0.002238   
2022-11-25 13:10:26,809 - INFO  - Training [14][   60/  196]   Loss 2.304475   Top1 10.169271   Top5 50.305990   BatchTime 0.366154   LR 0.002225   
2022-11-25 13:10:32,034 - INFO  - Training [14][   80/  196]   Loss 2.304217   Top1 10.126953   Top5 50.239258   BatchTime 0.339932   LR 0.002213   
2022-11-25 13:10:38,951 - INFO  - Training [14][  100/  196]   Loss 2.304236   Top1 9.976562   Top5 50.097656   BatchTime 0.341109   LR 0.002200   
2022-11-25 13:10:46,170 - INFO  - Training [14][  120/  196]   Loss 2.303992   Top1 10.039062   Top5 50.201823   BatchTime 0.344415   LR 0.002186   
2022-11-25 13:10:52,961 - INFO  - Training [14][  140/  196]   Loss 2.304283   Top1 9.930246   Top5 49.874442   BatchTime 0.343724   LR 0.002173   
2022-11-25 13:10:59,734 - INFO  - Training [14][  160/  196]   Loss 2.304229   Top1 9.848633   Top5 49.936523   BatchTime 0.343089   LR 0.002159   
2022-11-25 13:11:06,463 - INFO  - Training [14][  180/  196]   Loss 2.304211   Top1 9.845920   Top5 49.898003   BatchTime 0.342347   LR 0.002145   
2022-11-25 13:11:12,159 - INFO  - ==> Top1: 9.776    Top5: 49.804    Loss: 2.304

2022-11-25 13:11:12,402 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:11:13,783 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:11:16,516 - INFO  - Validation [14][   20/   40]   Loss 2.303211   Top1 9.863281   Top5 49.687500   BatchTime 0.136546   
2022-11-25 13:11:17,654 - INFO  - Validation [14][   40/   40]   Loss 2.303041   Top1 10.000000   Top5 50.000000   BatchTime 0.096746   
2022-11-25 13:11:17,905 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:11:17,905 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:11:17,905 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:11:17,906 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:11:17,906 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:11:18,314 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:11:18,316 - INFO  - >>>>>> Epoch  15
2022-11-25 13:11:18,317 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:11:27,084 - INFO  - Training [15][   20/  196]   Loss 2.302876   Top1 10.214844   Top5 50.644531   BatchTime 0.438164   LR 0.002120   
2022-11-25 13:11:34,375 - INFO  - Training [15][   40/  196]   Loss 2.303743   Top1 9.863281   Top5 49.472656   BatchTime 0.401373   LR 0.002106   
2022-11-25 13:11:40,579 - INFO  - Training [15][   60/  196]   Loss 2.303515   Top1 9.947917   Top5 49.563802   BatchTime 0.370982   LR 0.002091   
2022-11-25 13:11:46,064 - INFO  - Training [15][   80/  196]   Loss 2.303546   Top1 9.750977   Top5 49.453125   BatchTime 0.346802   LR 0.002076   
2022-11-25 13:11:52,581 - INFO  - Training [15][  100/  196]   Loss 2.303435   Top1 9.835938   Top5 49.625000   BatchTime 0.342603   LR 0.002061   
2022-11-25 13:11:59,598 - INFO  - Training [15][  120/  196]   Loss 2.303406   Top1 9.837240   Top5 49.612630   BatchTime 0.343976   LR 0.002045   
2022-11-25 13:12:06,585 - INFO  - Training [15][  140/  196]   Loss 2.303562   Top1 9.868862   Top5 49.475446   BatchTime 0.344742   LR 0.002030   
2022-11-25 13:12:13,375 - INFO  - Training [15][  160/  196]   Loss 2.303554   Top1 9.936523   Top5 49.375000   BatchTime 0.344088   LR 0.002014   
2022-11-25 13:12:20,164 - INFO  - Training [15][  180/  196]   Loss 2.303444   Top1 10.006510   Top5 49.479167   BatchTime 0.343571   LR 0.001998   
2022-11-25 13:12:25,801 - INFO  - ==> Top1: 9.938    Top5: 49.492    Loss: 2.304

2022-11-25 13:12:26,080 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:12:27,629 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:12:30,311 - INFO  - Validation [15][   20/   40]   Loss 2.302798   Top1 9.882812   Top5 49.785156   BatchTime 0.133969   
2022-11-25 13:12:31,435 - INFO  - Validation [15][   40/   40]   Loss 2.302734   Top1 10.000000   Top5 50.000000   BatchTime 0.095086   
2022-11-25 13:12:31,666 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:12:31,666 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:12:31,667 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:12:31,667 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:12:31,667 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:12:31,827 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:12:31,828 - INFO  - >>>>>> Epoch  16
2022-11-25 13:12:31,830 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:12:40,734 - INFO  - Training [16][   20/  196]   Loss 2.303283   Top1 9.687500   Top5 49.687500   BatchTime 0.445014   LR 0.001969   
2022-11-25 13:12:47,727 - INFO  - Training [16][   40/  196]   Loss 2.303111   Top1 10.117188   Top5 49.609375   BatchTime 0.397347   LR 0.001953   
2022-11-25 13:12:54,569 - INFO  - Training [16][   60/  196]   Loss 2.302932   Top1 10.078125   Top5 49.882812   BatchTime 0.378932   LR 0.001936   
2022-11-25 13:12:59,953 - INFO  - Training [16][   80/  196]   Loss 2.303166   Top1 9.956055   Top5 49.614258   BatchTime 0.351500   LR 0.001919   
2022-11-25 13:13:06,316 - INFO  - Training [16][  100/  196]   Loss 2.303080   Top1 9.960938   Top5 49.816406   BatchTime 0.344829   LR 0.001902   
2022-11-25 13:13:13,351 - INFO  - Training [16][  120/  196]   Loss 2.303079   Top1 9.954427   Top5 49.964193   BatchTime 0.345975   LR 0.001885   
2022-11-25 13:13:20,313 - INFO  - Training [16][  140/  196]   Loss 2.303124   Top1 9.955357   Top5 49.941406   BatchTime 0.346282   LR 0.001867   
2022-11-25 13:13:27,258 - INFO  - Training [16][  160/  196]   Loss 2.303109   Top1 9.973145   Top5 49.924316   BatchTime 0.346399   LR 0.001850   
2022-11-25 13:13:34,166 - INFO  - Training [16][  180/  196]   Loss 2.303149   Top1 9.956597   Top5 49.756944   BatchTime 0.346291   LR 0.001832   
2022-11-25 13:13:39,750 - INFO  - ==> Top1: 9.898    Top5: 49.708    Loss: 2.303

2022-11-25 13:13:39,997 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:13:41,350 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:13:44,116 - INFO  - Validation [16][   20/   40]   Loss 2.302734   Top1 9.863281   Top5 49.902344   BatchTime 0.138181   
2022-11-25 13:13:45,180 - INFO  - Validation [16][   40/   40]   Loss 2.302675   Top1 10.000000   Top5 50.000000   BatchTime 0.095702   
2022-11-25 13:13:45,426 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:13:45,426 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:13:45,426 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:13:45,427 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:13:45,427 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:13:45,795 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:13:45,797 - INFO  - >>>>>> Epoch  17
2022-11-25 13:13:45,799 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:13:54,508 - INFO  - Training [17][   20/  196]   Loss 2.302448   Top1 10.722656   Top5 51.542969   BatchTime 0.435329   LR 0.001800   
2022-11-25 13:14:01,922 - INFO  - Training [17][   40/  196]   Loss 2.302822   Top1 10.234375   Top5 50.458984   BatchTime 0.403014   LR 0.001782   
2022-11-25 13:14:08,852 - INFO  - Training [17][   60/  196]   Loss 2.302828   Top1 10.240885   Top5 50.514323   BatchTime 0.384176   LR 0.001764   
2022-11-25 13:14:14,465 - INFO  - Training [17][   80/  196]   Loss 2.302777   Top1 10.263672   Top5 50.375977   BatchTime 0.358291   LR 0.001746   
2022-11-25 13:14:19,946 - INFO  - Training [17][  100/  196]   Loss 2.302803   Top1 10.230469   Top5 50.304688   BatchTime 0.341446   LR 0.001727   
2022-11-25 13:14:25,727 - INFO  - Training [17][  120/  196]   Loss 2.302829   Top1 10.227865   Top5 50.253906   BatchTime 0.332712   LR 0.001708   
2022-11-25 13:14:30,828 - INFO  - Training [17][  140/  196]   Loss 2.302844   Top1 10.128348   Top5 50.228795   BatchTime 0.321617   LR 0.001690   
2022-11-25 13:14:35,893 - INFO  - Training [17][  160/  196]   Loss 2.302997   Top1 10.026855   Top5 50.058594   BatchTime 0.313070   LR 0.001671   
2022-11-25 13:14:40,890 - INFO  - Training [17][  180/  196]   Loss 2.303035   Top1 9.982639   Top5 50.032552   BatchTime 0.306047   LR 0.001652   
2022-11-25 13:14:45,197 - INFO  - ==> Top1: 9.926    Top5: 50.016    Loss: 2.303

2022-11-25 13:14:45,414 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:14:46,566 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:14:49,501 - INFO  - Validation [17][   20/   40]   Loss 2.302740   Top1 10.117188   Top5 49.628906   BatchTime 0.146605   
2022-11-25 13:14:50,557 - INFO  - Validation [17][   40/   40]   Loss 2.302668   Top1 10.000000   Top5 50.000000   BatchTime 0.099703   
2022-11-25 13:14:50,804 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:14:50,805 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:14:50,805 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:14:50,805 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:14:50,805 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:14:50,930 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:14:50,931 - INFO  - >>>>>> Epoch  18
2022-11-25 13:14:50,933 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:14:57,704 - INFO  - Training [18][   20/  196]   Loss 2.302854   Top1 10.117188   Top5 49.785156   BatchTime 0.338441   LR 0.001618   
2022-11-25 13:15:02,708 - INFO  - Training [18][   40/  196]   Loss 2.302783   Top1 10.068359   Top5 49.892578   BatchTime 0.294300   LR 0.001599   
2022-11-25 13:15:07,601 - INFO  - Training [18][   60/  196]   Loss 2.302829   Top1 10.110677   Top5 50.208333   BatchTime 0.277747   LR 0.001579   
2022-11-25 13:15:13,251 - INFO  - Training [18][   80/  196]   Loss 2.302817   Top1 10.092773   Top5 50.190430   BatchTime 0.278941   LR 0.001560   
2022-11-25 13:15:18,147 - INFO  - Training [18][  100/  196]   Loss 2.302871   Top1 10.230469   Top5 50.093750   BatchTime 0.272109   LR 0.001540   
2022-11-25 13:15:23,295 - INFO  - Training [18][  120/  196]   Loss 2.303007   Top1 10.084635   Top5 49.918620   BatchTime 0.269656   LR 0.001521   
2022-11-25 13:15:28,423 - INFO  - Training [18][  140/  196]   Loss 2.303048   Top1 10.089286   Top5 49.740513   BatchTime 0.267766   LR 0.001501   
2022-11-25 13:15:33,601 - INFO  - Training [18][  160/  196]   Loss 2.302989   Top1 10.048828   Top5 49.775391   BatchTime 0.266653   LR 0.001482   
2022-11-25 13:15:38,826 - INFO  - Training [18][  180/  196]   Loss 2.302972   Top1 10.067274   Top5 49.730903   BatchTime 0.266053   LR 0.001462   
2022-11-25 13:15:43,000 - INFO  - ==> Top1: 10.122    Top5: 49.760    Loss: 2.303

2022-11-25 13:15:43,231 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:15:44,342 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:15:47,281 - INFO  - Validation [18][   20/   40]   Loss 2.302666   Top1 10.019531   Top5 50.097656   BatchTime 0.146851   
2022-11-25 13:15:48,359 - INFO  - Validation [18][   40/   40]   Loss 2.302639   Top1 10.000000   Top5 50.000000   BatchTime 0.100384   
2022-11-25 13:15:48,600 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:15:48,601 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:15:48,601 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:15:48,601 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:15:48,601 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:15:48,736 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:15:48,737 - INFO  - >>>>>> Epoch  19
2022-11-25 13:15:48,739 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:15:55,357 - INFO  - Training [19][   20/  196]   Loss 2.302992   Top1 9.746094   Top5 49.121094   BatchTime 0.330744   LR 0.001427   
2022-11-25 13:16:00,239 - INFO  - Training [19][   40/  196]   Loss 2.303015   Top1 9.863281   Top5 49.218750   BatchTime 0.287440   LR 0.001407   
2022-11-25 13:16:05,740 - INFO  - Training [19][   60/  196]   Loss 2.303100   Top1 9.811198   Top5 49.036458   BatchTime 0.283304   LR 0.001387   
2022-11-25 13:16:10,888 - INFO  - Training [19][   80/  196]   Loss 2.303051   Top1 9.838867   Top5 49.340820   BatchTime 0.276828   LR 0.001367   
2022-11-25 13:16:15,957 - INFO  - Training [19][  100/  196]   Loss 2.302952   Top1 9.964844   Top5 49.609375   BatchTime 0.272142   LR 0.001347   
2022-11-25 13:16:21,001 - INFO  - Training [19][  120/  196]   Loss 2.302903   Top1 9.918620   Top5 49.749349   BatchTime 0.268827   LR 0.001327   
2022-11-25 13:16:26,504 - INFO  - Training [19][  140/  196]   Loss 2.302872   Top1 10.036272   Top5 49.852121   BatchTime 0.269723   LR 0.001307   
2022-11-25 13:16:31,960 - INFO  - Training [19][  160/  196]   Loss 2.302888   Top1 10.087891   Top5 49.772949   BatchTime 0.270111   LR 0.001287   
2022-11-25 13:16:36,991 - INFO  - Training [19][  180/  196]   Loss 2.302924   Top1 10.041233   Top5 49.639757   BatchTime 0.268045   LR 0.001266   
2022-11-25 13:16:41,477 - INFO  - ==> Top1: 10.034    Top5: 49.712    Loss: 2.303

2022-11-25 13:16:41,685 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:16:42,871 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:16:45,706 - INFO  - Validation [19][   20/   40]   Loss 2.302574   Top1 9.882812   Top5 50.429688   BatchTime 0.141636   
2022-11-25 13:16:46,777 - INFO  - Validation [19][   40/   40]   Loss 2.302604   Top1 10.000000   Top5 50.000000   BatchTime 0.097614   
2022-11-25 13:16:47,038 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:16:47,039 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:16:47,039 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:16:47,039 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:16:47,039 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:16:47,164 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:16:47,165 - INFO  - >>>>>> Epoch  20
2022-11-25 13:16:47,167 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:16:54,538 - INFO  - Training [20][   20/  196]   Loss 2.303332   Top1 9.453125   Top5 49.335938   BatchTime 0.368402   LR 0.001231   
2022-11-25 13:16:59,647 - INFO  - Training [20][   40/  196]   Loss 2.303247   Top1 9.599609   Top5 49.804688   BatchTime 0.311934   LR 0.001211   
2022-11-25 13:17:04,663 - INFO  - Training [20][   60/  196]   Loss 2.302916   Top1 9.739583   Top5 50.110677   BatchTime 0.291562   LR 0.001191   
2022-11-25 13:17:09,654 - INFO  - Training [20][   80/  196]   Loss 2.302867   Top1 9.716797   Top5 50.253906   BatchTime 0.281057   LR 0.001171   
2022-11-25 13:17:14,745 - INFO  - Training [20][  100/  196]   Loss 2.302876   Top1 9.804688   Top5 50.226562   BatchTime 0.275748   LR 0.001151   
2022-11-25 13:17:19,555 - INFO  - Training [20][  120/  196]   Loss 2.302809   Top1 9.951172   Top5 50.240885   BatchTime 0.269875   LR 0.001131   
2022-11-25 13:17:24,563 - INFO  - Training [20][  140/  196]   Loss 2.302846   Top1 9.955357   Top5 50.122768   BatchTime 0.267091   LR 0.001111   
2022-11-25 13:17:29,572 - INFO  - Training [20][  160/  196]   Loss 2.302865   Top1 9.980469   Top5 50.139160   BatchTime 0.265013   LR 0.001091   
2022-11-25 13:17:35,141 - INFO  - Training [20][  180/  196]   Loss 2.302899   Top1 9.928385   Top5 50.032552   BatchTime 0.266503   LR 0.001071   
2022-11-25 13:17:39,287 - INFO  - ==> Top1: 9.968    Top5: 50.120    Loss: 2.303

2022-11-25 13:17:39,517 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:17:40,628 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:17:43,251 - INFO  - Validation [20][   20/   40]   Loss 2.302891   Top1 9.882812   Top5 49.785156   BatchTime 0.131052   
2022-11-25 13:17:44,533 - INFO  - Validation [20][   40/   40]   Loss 2.302808   Top1 10.000000   Top5 50.000000   BatchTime 0.097589   
2022-11-25 13:17:44,746 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:17:44,747 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:17:44,747 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:17:44,747 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:17:44,747 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:17:44,882 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:17:44,884 - INFO  - >>>>>> Epoch  21
2022-11-25 13:17:44,886 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:17:52,446 - INFO  - Training [21][   20/  196]   Loss 2.303053   Top1 9.941406   Top5 50.058594   BatchTime 0.377885   LR 0.001036   
2022-11-25 13:17:58,014 - INFO  - Training [21][   40/  196]   Loss 2.303159   Top1 9.931641   Top5 49.804688   BatchTime 0.328151   LR 0.001016   
2022-11-25 13:18:03,140 - INFO  - Training [21][   60/  196]   Loss 2.303000   Top1 9.980469   Top5 50.188802   BatchTime 0.304186   LR 0.000996   
2022-11-25 13:18:08,228 - INFO  - Training [21][   80/  196]   Loss 2.303007   Top1 10.058594   Top5 50.253906   BatchTime 0.291735   LR 0.000976   
2022-11-25 13:18:13,059 - INFO  - Training [21][  100/  196]   Loss 2.302965   Top1 9.988281   Top5 50.203125   BatchTime 0.281701   LR 0.000957   
2022-11-25 13:18:18,247 - INFO  - Training [21][  120/  196]   Loss 2.302999   Top1 10.013021   Top5 49.993490   BatchTime 0.277981   LR 0.000937   
2022-11-25 13:18:23,428 - INFO  - Training [21][  140/  196]   Loss 2.302934   Top1 10.047433   Top5 50.066964   BatchTime 0.275277   LR 0.000918   
2022-11-25 13:18:28,678 - INFO  - Training [21][  160/  196]   Loss 2.302879   Top1 9.975586   Top5 50.158691   BatchTime 0.273680   LR 0.000899   
2022-11-25 13:18:34,267 - INFO  - Training [21][  180/  196]   Loss 2.302947   Top1 9.952257   Top5 49.917535   BatchTime 0.274318   LR 0.000879   
2022-11-25 13:18:38,626 - INFO  - ==> Top1: 9.962    Top5: 49.818    Loss: 2.303

2022-11-25 13:18:38,852 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:18:40,014 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:18:43,138 - INFO  - Validation [21][   20/   40]   Loss 2.302572   Top1 10.019531   Top5 50.292969   BatchTime 0.156108   
2022-11-25 13:18:44,246 - INFO  - Validation [21][   40/   40]   Loss 2.302593   Top1 10.000000   Top5 50.000000   BatchTime 0.105754   
2022-11-25 13:18:44,517 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:18:44,517 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:18:44,517 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:18:44,518 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:18:44,518 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:18:44,645 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:18:44,646 - INFO  - >>>>>> Epoch  22
2022-11-25 13:18:44,648 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:18:51,720 - INFO  - Training [22][   20/  196]   Loss 2.302512   Top1 10.859375   Top5 49.589844   BatchTime 0.353461   LR 0.000846   
2022-11-25 13:18:56,841 - INFO  - Training [22][   40/  196]   Loss 2.302948   Top1 9.970703   Top5 49.658203   BatchTime 0.304744   LR 0.000827   
2022-11-25 13:19:02,720 - INFO  - Training [22][   60/  196]   Loss 2.302704   Top1 10.006510   Top5 50.091146   BatchTime 0.301139   LR 0.000808   
2022-11-25 13:19:08,179 - INFO  - Training [22][   80/  196]   Loss 2.302823   Top1 9.990234   Top5 49.965820   BatchTime 0.294100   LR 0.000789   
2022-11-25 13:19:13,629 - INFO  - Training [22][  100/  196]   Loss 2.302837   Top1 9.968750   Top5 49.707031   BatchTime 0.289773   LR 0.000770   
2022-11-25 13:19:18,950 - INFO  - Training [22][  120/  196]   Loss 2.302786   Top1 10.013021   Top5 49.785156   BatchTime 0.285818   LR 0.000752   
2022-11-25 13:19:24,026 - INFO  - Training [22][  140/  196]   Loss 2.302849   Top1 9.974888   Top5 49.771205   BatchTime 0.281246   LR 0.000734   
2022-11-25 13:19:29,177 - INFO  - Training [22][  160/  196]   Loss 2.302884   Top1 9.951172   Top5 49.772949   BatchTime 0.278285   LR 0.000715   
2022-11-25 13:19:34,534 - INFO  - Training [22][  180/  196]   Loss 2.302846   Top1 10.019531   Top5 49.817708   BatchTime 0.277121   LR 0.000697   
2022-11-25 13:19:38,652 - INFO  - ==> Top1: 10.014    Top5: 49.744    Loss: 2.303

2022-11-25 13:19:38,882 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:19:40,147 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:19:43,081 - INFO  - Validation [22][   20/   40]   Loss 2.302703   Top1 9.882812   Top5 49.785156   BatchTime 0.146611   
2022-11-25 13:19:44,160 - INFO  - Validation [22][   40/   40]   Loss 2.302664   Top1 10.000000   Top5 50.000000   BatchTime 0.100293   
2022-11-25 13:19:44,431 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:19:44,431 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:19:44,432 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:19:44,432 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:19:44,432 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:19:44,576 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:19:44,578 - INFO  - >>>>>> Epoch  23
2022-11-25 13:19:44,581 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:19:51,678 - INFO  - Training [23][   20/  196]   Loss 2.302375   Top1 9.960938   Top5 51.679688   BatchTime 0.354651   LR 0.000666   
2022-11-25 13:19:56,872 - INFO  - Training [23][   40/  196]   Loss 2.302532   Top1 9.843750   Top5 51.191406   BatchTime 0.307169   LR 0.000648   
2022-11-25 13:20:02,018 - INFO  - Training [23][   60/  196]   Loss 2.302565   Top1 9.967448   Top5 50.598958   BatchTime 0.290554   LR 0.000630   
2022-11-25 13:20:07,416 - INFO  - Training [23][   80/  196]   Loss 2.302635   Top1 9.946289   Top5 50.590820   BatchTime 0.285395   LR 0.000613   
2022-11-25 13:20:12,595 - INFO  - Training [23][  100/  196]   Loss 2.302692   Top1 9.929688   Top5 50.355469   BatchTime 0.280107   LR 0.000596   
2022-11-25 13:20:18,495 - INFO  - Training [23][  120/  196]   Loss 2.302734   Top1 9.905599   Top5 50.192057   BatchTime 0.282583   LR 0.000579   
2022-11-25 13:20:23,918 - INFO  - Training [23][  140/  196]   Loss 2.302748   Top1 9.905134   Top5 50.184152   BatchTime 0.280945   LR 0.000562   
2022-11-25 13:20:29,151 - INFO  - Training [23][  160/  196]   Loss 2.302779   Top1 9.909668   Top5 50.200195   BatchTime 0.278534   LR 0.000545   
2022-11-25 13:20:34,034 - INFO  - Training [23][  180/  196]   Loss 2.302789   Top1 9.928385   Top5 50.060764   BatchTime 0.274713   LR 0.000529   
2022-11-25 13:20:38,525 - INFO  - ==> Top1: 9.932    Top5: 49.940    Loss: 2.303

2022-11-25 13:20:38,749 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:20:39,828 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:20:42,904 - INFO  - Validation [23][   20/   40]   Loss 2.302658   Top1 9.882812   Top5 49.785156   BatchTime 0.153698   
2022-11-25 13:20:44,014 - INFO  - Validation [23][   40/   40]   Loss 2.302618   Top1 10.000000   Top5 50.000000   BatchTime 0.104611   
2022-11-25 13:20:44,278 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:20:44,278 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:20:44,279 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:20:44,279 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:20:44,279 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:20:44,444 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:20:44,446 - INFO  - >>>>>> Epoch  24
2022-11-25 13:20:44,448 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:20:51,836 - INFO  - Training [24][   20/  196]   Loss 2.303120   Top1 9.648438   Top5 50.039062   BatchTime 0.369265   LR 0.000500   
2022-11-25 13:20:57,482 - INFO  - Training [24][   40/  196]   Loss 2.302765   Top1 9.863281   Top5 50.468750   BatchTime 0.325775   LR 0.000484   
2022-11-25 13:21:02,840 - INFO  - Training [24][   60/  196]   Loss 2.302654   Top1 10.065104   Top5 50.117188   BatchTime 0.306482   LR 0.000468   
2022-11-25 13:21:08,035 - INFO  - Training [24][   80/  196]   Loss 2.302770   Top1 9.921875   Top5 49.731445   BatchTime 0.294803   LR 0.000453   
2022-11-25 13:21:13,219 - INFO  - Training [24][  100/  196]   Loss 2.302743   Top1 9.910156   Top5 49.898438   BatchTime 0.287677   LR 0.000437   
2022-11-25 13:21:18,173 - INFO  - Training [24][  120/  196]   Loss 2.302709   Top1 10.026042   Top5 49.996745   BatchTime 0.281013   LR 0.000422   
2022-11-25 13:21:23,068 - INFO  - Training [24][  140/  196]   Loss 2.302782   Top1 9.997210   Top5 49.916295   BatchTime 0.275831   LR 0.000407   
2022-11-25 13:21:28,280 - INFO  - Training [24][  160/  196]   Loss 2.302780   Top1 9.992676   Top5 49.912109   BatchTime 0.273928   LR 0.000392   
2022-11-25 13:21:34,082 - INFO  - Training [24][  180/  196]   Loss 2.302835   Top1 9.950087   Top5 49.845920   BatchTime 0.275725   LR 0.000378   
2022-11-25 13:21:38,207 - INFO  - ==> Top1: 9.894    Top5: 49.772    Loss: 2.303

2022-11-25 13:21:38,485 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:21:39,950 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:21:42,947 - INFO  - Validation [24][   20/   40]   Loss 2.302635   Top1 9.882812   Top5 49.785156   BatchTime 0.149722   
2022-11-25 13:21:44,072 - INFO  - Validation [24][   40/   40]   Loss 2.302608   Top1 10.000000   Top5 50.000000   BatchTime 0.103008   
2022-11-25 13:21:44,340 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:21:44,341 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:21:44,341 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:21:44,341 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:21:44,341 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:21:44,472 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:21:44,474 - INFO  - >>>>>> Epoch  25
2022-11-25 13:21:44,476 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:21:51,676 - INFO  - Training [25][   20/  196]   Loss 2.303339   Top1 9.179688   Top5 49.531250   BatchTime 0.359870   LR 0.000353   
2022-11-25 13:21:56,711 - INFO  - Training [25][   40/  196]   Loss 2.303044   Top1 9.531250   Top5 49.960938   BatchTime 0.305787   LR 0.000339   
2022-11-25 13:22:02,089 - INFO  - Training [25][   60/  196]   Loss 2.302853   Top1 9.739583   Top5 50.201823   BatchTime 0.293492   LR 0.000325   
2022-11-25 13:22:07,262 - INFO  - Training [25][   80/  196]   Loss 2.302806   Top1 9.765625   Top5 50.097656   BatchTime 0.284777   LR 0.000312   
2022-11-25 13:22:12,486 - INFO  - Training [25][  100/  196]   Loss 2.302742   Top1 9.800781   Top5 50.234375   BatchTime 0.280071   LR 0.000299   
2022-11-25 13:22:17,654 - INFO  - Training [25][  120/  196]   Loss 2.302710   Top1 9.843750   Top5 50.130208   BatchTime 0.276452   LR 0.000286   
2022-11-25 13:22:22,932 - INFO  - Training [25][  140/  196]   Loss 2.302766   Top1 9.773996   Top5 50.083705   BatchTime 0.274657   LR 0.000273   
2022-11-25 13:22:27,961 - INFO  - Training [25][  160/  196]   Loss 2.302786   Top1 9.753418   Top5 50.034180   BatchTime 0.271758   LR 0.000261   
2022-11-25 13:22:32,860 - INFO  - Training [25][  180/  196]   Loss 2.302763   Top1 9.811198   Top5 50.034722   BatchTime 0.268780   LR 0.000248   
2022-11-25 13:22:36,992 - INFO  - ==> Top1: 9.872    Top5: 50.068    Loss: 2.303

2022-11-25 13:22:37,199 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:22:38,315 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:22:41,216 - INFO  - Validation [25][   20/   40]   Loss 2.302622   Top1 9.882812   Top5 49.960938   BatchTime 0.144951   
2022-11-25 13:22:42,804 - INFO  - Validation [25][   40/   40]   Loss 2.302601   Top1 10.000000   Top5 50.000000   BatchTime 0.112192   
2022-11-25 13:22:43,348 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:22:43,348 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:22:43,349 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:22:43,349 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:22:43,349 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:22:43,560 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:22:43,562 - INFO  - >>>>>> Epoch  26
2022-11-25 13:22:43,565 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:22:51,585 - INFO  - Training [26][   20/  196]   Loss 2.303016   Top1 10.039062   Top5 49.570312   BatchTime 0.400800   LR 0.000228   
2022-11-25 13:22:56,677 - INFO  - Training [26][   40/  196]   Loss 2.302827   Top1 10.273438   Top5 50.146484   BatchTime 0.327683   LR 0.000216   
2022-11-25 13:23:02,039 - INFO  - Training [26][   60/  196]   Loss 2.302755   Top1 10.436198   Top5 49.941406   BatchTime 0.307821   LR 0.000205   
2022-11-25 13:23:07,382 - INFO  - Training [26][   80/  196]   Loss 2.302768   Top1 10.278320   Top5 50.107422   BatchTime 0.297649   LR 0.000194   
2022-11-25 13:23:12,516 - INFO  - Training [26][  100/  196]   Loss 2.302752   Top1 10.222656   Top5 50.324219   BatchTime 0.289458   LR 0.000183   
2022-11-25 13:23:17,842 - INFO  - Training [26][  120/  196]   Loss 2.302716   Top1 10.211589   Top5 50.283203   BatchTime 0.285599   LR 0.000173   
2022-11-25 13:23:23,169 - INFO  - Training [26][  140/  196]   Loss 2.302744   Top1 10.164621   Top5 50.312500   BatchTime 0.282850   LR 0.000163   
2022-11-25 13:23:28,629 - INFO  - Training [26][  160/  196]   Loss 2.302687   Top1 10.222168   Top5 50.429688   BatchTime 0.281617   LR 0.000153   
2022-11-25 13:23:33,865 - INFO  - Training [26][  180/  196]   Loss 2.302674   Top1 10.197483   Top5 50.392795   BatchTime 0.279415   LR 0.000144   
2022-11-25 13:23:38,031 - INFO  - ==> Top1: 10.212    Top5: 50.264    Loss: 2.303

2022-11-25 13:23:38,285 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:23:39,418 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:23:42,332 - INFO  - Validation [26][   20/   40]   Loss 2.302601   Top1 9.882812   Top5 49.960938   BatchTime 0.145609   
2022-11-25 13:23:43,390 - INFO  - Validation [26][   40/   40]   Loss 2.302595   Top1 10.000000   Top5 50.000000   BatchTime 0.099254   
2022-11-25 13:23:43,636 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:23:43,636 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:23:43,637 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:23:43,637 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:23:43,637 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:23:43,793 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:23:43,794 - INFO  - >>>>>> Epoch  27
2022-11-25 13:23:43,796 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:23:50,959 - INFO  - Training [27][   20/  196]   Loss 2.302735   Top1 10.117188   Top5 50.488281   BatchTime 0.358018   LR 0.000128   
2022-11-25 13:23:55,939 - INFO  - Training [27][   40/  196]   Loss 2.302812   Top1 10.000000   Top5 50.185547   BatchTime 0.303482   LR 0.000119   
2022-11-25 13:24:02,085 - INFO  - Training [27][   60/  196]   Loss 2.302632   Top1 10.182292   Top5 50.312500   BatchTime 0.304751   LR 0.000111   
2022-11-25 13:24:07,361 - INFO  - Training [27][   80/  196]   Loss 2.302719   Top1 10.019531   Top5 50.239258   BatchTime 0.294514   LR 0.000102   
2022-11-25 13:24:12,519 - INFO  - Training [27][  100/  196]   Loss 2.302689   Top1 10.042969   Top5 50.164062   BatchTime 0.287197   LR 0.000095   
2022-11-25 13:24:17,904 - INFO  - Training [27][  120/  196]   Loss 2.302788   Top1 10.055339   Top5 49.850260   BatchTime 0.284204   LR 0.000087   
2022-11-25 13:24:23,173 - INFO  - Training [27][  140/  196]   Loss 2.302762   Top1 10.044643   Top5 50.053013   BatchTime 0.281228   LR 0.000080   
2022-11-25 13:24:28,744 - INFO  - Training [27][  160/  196]   Loss 2.302684   Top1 10.095215   Top5 50.070801   BatchTime 0.280900   LR 0.000073   
2022-11-25 13:24:33,707 - INFO  - Training [27][  180/  196]   Loss 2.302695   Top1 10.121528   Top5 50.019531   BatchTime 0.277259   LR 0.000066   
2022-11-25 13:24:38,307 - INFO  - ==> Top1: 10.094    Top5: 50.046    Loss: 2.303

2022-11-25 13:24:38,518 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:24:39,731 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:24:42,540 - INFO  - Validation [27][   20/   40]   Loss 2.302603   Top1 9.882812   Top5 49.960938   BatchTime 0.140347   
2022-11-25 13:24:43,630 - INFO  - Validation [27][   40/   40]   Loss 2.302594   Top1 10.000000   Top5 50.000000   BatchTime 0.097435   
2022-11-25 13:24:43,937 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:24:43,938 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:24:43,938 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:24:43,939 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:24:43,939 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:24:44,072 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:24:44,074 - INFO  - >>>>>> Epoch  28
2022-11-25 13:24:44,076 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:24:51,139 - INFO  - Training [28][   20/  196]   Loss 2.303117   Top1 9.433594   Top5 48.261719   BatchTime 0.352965   LR 0.000055   
2022-11-25 13:24:56,505 - INFO  - Training [28][   40/  196]   Loss 2.303007   Top1 9.414062   Top5 48.789062   BatchTime 0.310644   LR 0.000050   
2022-11-25 13:25:01,833 - INFO  - Training [28][   60/  196]   Loss 2.302894   Top1 9.615885   Top5 49.108073   BatchTime 0.295895   LR 0.000044   
2022-11-25 13:25:06,897 - INFO  - Training [28][   80/  196]   Loss 2.302745   Top1 9.682617   Top5 49.819336   BatchTime 0.285225   LR 0.000039   
2022-11-25 13:25:12,680 - INFO  - Training [28][  100/  196]   Loss 2.302722   Top1 9.906250   Top5 49.996094   BatchTime 0.286006   LR 0.000034   
2022-11-25 13:25:18,444 - INFO  - Training [28][  120/  196]   Loss 2.302729   Top1 9.947917   Top5 49.833984   BatchTime 0.286374   LR 0.000030   
2022-11-25 13:25:23,742 - INFO  - Training [28][  140/  196]   Loss 2.302779   Top1 9.933036   Top5 49.821429   BatchTime 0.283306   LR 0.000026   
2022-11-25 13:25:29,046 - INFO  - Training [28][  160/  196]   Loss 2.302793   Top1 9.877930   Top5 49.748535   BatchTime 0.281038   LR 0.000022   
2022-11-25 13:25:34,076 - INFO  - Training [28][  180/  196]   Loss 2.302828   Top1 9.835069   Top5 49.722222   BatchTime 0.277756   LR 0.000018   
2022-11-25 13:25:38,151 - INFO  - ==> Top1: 9.862    Top5: 49.686    Loss: 2.303

2022-11-25 13:25:38,387 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:25:39,454 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:25:42,226 - INFO  - Validation [28][   20/   40]   Loss 2.302602   Top1 9.882812   Top5 49.960938   BatchTime 0.138511   
2022-11-25 13:25:43,329 - INFO  - Validation [28][   40/   40]   Loss 2.302593   Top1 10.000000   Top5 50.000000   BatchTime 0.096820   
2022-11-25 13:25:43,549 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:25:43,549 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:25:43,550 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:25:43,550 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:25:43,550 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:25:43,682 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:25:43,684 - INFO  - >>>>>> Epoch  29
2022-11-25 13:25:43,686 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:25:50,567 - INFO  - Training [29][   20/  196]   Loss 2.302658   Top1 10.820312   Top5 49.550781   BatchTime 0.343911   LR 0.000013   
2022-11-25 13:25:55,942 - INFO  - Training [29][   40/  196]   Loss 2.302698   Top1 10.615234   Top5 50.097656   BatchTime 0.306328   LR 0.000010   
2022-11-25 13:26:01,367 - INFO  - Training [29][   60/  196]   Loss 2.302921   Top1 10.286458   Top5 49.518229   BatchTime 0.294638   LR 0.000008   
2022-11-25 13:26:06,720 - INFO  - Training [29][   80/  196]   Loss 2.302963   Top1 10.034180   Top5 49.418945   BatchTime 0.287886   LR 0.000005   
2022-11-25 13:26:12,138 - INFO  - Training [29][  100/  196]   Loss 2.302837   Top1 10.203125   Top5 49.855469   BatchTime 0.284483   LR 0.000004   
2022-11-25 13:26:17,128 - INFO  - Training [29][  120/  196]   Loss 2.302781   Top1 10.084635   Top5 49.967448   BatchTime 0.278652   LR 0.000002   
2022-11-25 13:26:22,137 - INFO  - Training [29][  140/  196]   Loss 2.302740   Top1 10.078125   Top5 50.078125   BatchTime 0.274622   LR 0.000001   
2022-11-25 13:26:27,288 - INFO  - Training [29][  160/  196]   Loss 2.302787   Top1 9.929199   Top5 50.024414   BatchTime 0.272489   LR 0.000001   
2022-11-25 13:26:33,256 - INFO  - Training [29][  180/  196]   Loss 2.302756   Top1 10.010851   Top5 50.056424   BatchTime 0.275367   LR 0.000000   
2022-11-25 13:26:37,709 - INFO  - ==> Top1: 9.958    Top5: 49.960    Loss: 2.303

2022-11-25 13:26:37,897 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:26:38,989 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:26:41,645 - INFO  - Validation [29][   20/   40]   Loss 2.302601   Top1 9.882812   Top5 49.960938   BatchTime 0.132730   
2022-11-25 13:26:42,750 - INFO  - Validation [29][   40/   40]   Loss 2.302593   Top1 10.000000   Top5 50.000000   BatchTime 0.093999   
2022-11-25 13:26:43,006 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:26:43,006 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:26:43,007 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:26:43,007 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:26:43,007 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:26:43,132 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:26:43,134 - INFO  - >>>>>> Epoch  30
2022-11-25 13:26:43,135 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:26:49,921 - INFO  - Training [30][   20/  196]   Loss 2.302458   Top1 9.707031   Top5 50.312500   BatchTime 0.339126   LR 0.001250   
2022-11-25 13:26:54,948 - INFO  - Training [30][   40/  196]   Loss 2.302692   Top1 9.775391   Top5 50.478516   BatchTime 0.295252   LR 0.001250   
2022-11-25 13:27:00,299 - INFO  - Training [30][   60/  196]   Loss 2.302796   Top1 9.733073   Top5 49.941406   BatchTime 0.286018   LR 0.001250   
2022-11-25 13:27:05,621 - INFO  - Training [30][   80/  196]   Loss 2.302752   Top1 9.833984   Top5 50.112305   BatchTime 0.281033   LR 0.001250   
2022-11-25 13:27:10,728 - INFO  - Training [30][  100/  196]   Loss 2.302688   Top1 9.996094   Top5 50.023438   BatchTime 0.275900   LR 0.001250   
2022-11-25 13:27:15,826 - INFO  - Training [30][  120/  196]   Loss 2.302751   Top1 9.977214   Top5 49.918620   BatchTime 0.272393   LR 0.001249   
2022-11-25 13:27:20,850 - INFO  - Training [30][  140/  196]   Loss 2.302740   Top1 10.016741   Top5 49.955357   BatchTime 0.269367   LR 0.001249   
2022-11-25 13:27:25,987 - INFO  - Training [30][  160/  196]   Loss 2.302837   Top1 9.914551   Top5 49.724121   BatchTime 0.267799   LR 0.001249   
2022-11-25 13:27:31,392 - INFO  - Training [30][  180/  196]   Loss 2.302850   Top1 9.941406   Top5 49.778646   BatchTime 0.268076   LR 0.001248   
2022-11-25 13:27:35,488 - INFO  - ==> Top1: 9.970    Top5: 49.788    Loss: 2.303

2022-11-25 13:27:35,727 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:27:36,924 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:27:39,659 - INFO  - Validation [30][   20/   40]   Loss 2.302578   Top1 10.019531   Top5 50.273438   BatchTime 0.136672   
2022-11-25 13:27:40,704 - INFO  - Validation [30][   40/   40]   Loss 2.302609   Top1 10.000000   Top5 50.000000   BatchTime 0.094477   
2022-11-25 13:27:40,908 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:27:40,908 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:27:40,908 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:27:40,908 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:27:40,909 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:27:41,081 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:27:41,083 - INFO  - >>>>>> Epoch  31
2022-11-25 13:27:41,087 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:27:49,268 - INFO  - Training [31][   20/  196]   Loss 2.302786   Top1 10.078125   Top5 50.390625   BatchTime 0.408849   LR 0.001248   
2022-11-25 13:27:54,501 - INFO  - Training [31][   40/  196]   Loss 2.302662   Top1 10.205078   Top5 50.175781   BatchTime 0.335250   LR 0.001247   
2022-11-25 13:27:59,645 - INFO  - Training [31][   60/  196]   Loss 2.302645   Top1 10.260417   Top5 50.117188   BatchTime 0.309231   LR 0.001247   
2022-11-25 13:28:04,721 - INFO  - Training [31][   80/  196]   Loss 2.302675   Top1 10.097656   Top5 50.097656   BatchTime 0.295371   LR 0.001246   
2022-11-25 13:28:09,623 - INFO  - Training [31][  100/  196]   Loss 2.302648   Top1 10.027344   Top5 50.183594   BatchTime 0.285312   LR 0.001246   
2022-11-25 13:28:14,661 - INFO  - Training [31][  120/  196]   Loss 2.302681   Top1 10.019531   Top5 50.172526   BatchTime 0.279745   LR 0.001245   
2022-11-25 13:28:19,602 - INFO  - Training [31][  140/  196]   Loss 2.302677   Top1 9.994420   Top5 50.256696   BatchTime 0.275070   LR 0.001244   
2022-11-25 13:28:24,912 - INFO  - Training [31][  160/  196]   Loss 2.302741   Top1 9.892578   Top5 50.124512   BatchTime 0.273878   LR 0.001244   
2022-11-25 13:28:29,671 - INFO  - Training [31][  180/  196]   Loss 2.302758   Top1 9.884983   Top5 50.091146   BatchTime 0.269883   LR 0.001243   
2022-11-25 13:28:34,007 - INFO  - ==> Top1: 9.928    Top5: 50.000    Loss: 2.303

2022-11-25 13:28:34,215 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:28:35,402 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:28:38,115 - INFO  - Validation [31][   20/   40]   Loss 2.302587   Top1 9.765625   Top5 50.000000   BatchTime 0.135567   
2022-11-25 13:28:39,192 - INFO  - Validation [31][   40/   40]   Loss 2.302628   Top1 10.000000   Top5 50.000000   BatchTime 0.094717   
2022-11-25 13:28:39,465 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:28:39,465 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:28:39,465 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:28:39,465 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:28:39,465 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:28:39,585 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:28:39,587 - INFO  - >>>>>> Epoch  32
2022-11-25 13:28:39,589 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:28:46,443 - INFO  - Training [32][   20/  196]   Loss 2.303090   Top1 9.726562   Top5 50.234375   BatchTime 0.342604   LR 0.001242   
2022-11-25 13:28:51,376 - INFO  - Training [32][   40/  196]   Loss 2.303097   Top1 9.472656   Top5 49.492188   BatchTime 0.294613   LR 0.001241   
2022-11-25 13:28:56,578 - INFO  - Training [32][   60/  196]   Loss 2.302914   Top1 9.726562   Top5 49.609375   BatchTime 0.283103   LR 0.001240   
2022-11-25 13:29:02,371 - INFO  - Training [32][   80/  196]   Loss 2.302966   Top1 9.692383   Top5 49.355469   BatchTime 0.284748   LR 0.001239   
2022-11-25 13:29:07,709 - INFO  - Training [32][  100/  196]   Loss 2.302994   Top1 9.667969   Top5 49.222656   BatchTime 0.281174   LR 0.001238   
2022-11-25 13:29:12,562 - INFO  - Training [32][  120/  196]   Loss 2.302924   Top1 9.918620   Top5 49.462891   BatchTime 0.274755   LR 0.001237   
2022-11-25 13:29:17,453 - INFO  - Training [32][  140/  196]   Loss 2.302942   Top1 9.899554   Top5 49.444754   BatchTime 0.270436   LR 0.001236   
2022-11-25 13:29:22,479 - INFO  - Training [32][  160/  196]   Loss 2.302909   Top1 9.929199   Top5 49.506836   BatchTime 0.268045   LR 0.001235   
2022-11-25 13:29:27,307 - INFO  - Training [32][  180/  196]   Loss 2.302904   Top1 9.895833   Top5 49.526910   BatchTime 0.265084   LR 0.001234   
2022-11-25 13:29:31,422 - INFO  - ==> Top1: 9.880    Top5: 49.452    Loss: 2.303

2022-11-25 13:29:31,613 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:29:32,695 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:29:35,414 - INFO  - Validation [32][   20/   40]   Loss 2.302586   Top1 9.765625   Top5 50.292969   BatchTime 0.135850   
2022-11-25 13:29:36,540 - INFO  - Validation [32][   40/   40]   Loss 2.302641   Top1 10.000000   Top5 50.000000   BatchTime 0.096082   
2022-11-25 13:29:36,768 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:29:36,769 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:29:36,769 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:29:36,769 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:29:36,769 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:29:36,894 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:29:36,896 - INFO  - >>>>>> Epoch  33
2022-11-25 13:29:36,897 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:29:44,236 - INFO  - Training [33][   20/  196]   Loss 2.302754   Top1 9.667969   Top5 50.156250   BatchTime 0.366782   LR 0.001232   
2022-11-25 13:29:49,510 - INFO  - Training [33][   40/  196]   Loss 2.302831   Top1 9.853516   Top5 49.609375   BatchTime 0.315254   LR 0.001230   
2022-11-25 13:29:54,862 - INFO  - Training [33][   60/  196]   Loss 2.302812   Top1 9.843750   Top5 49.752604   BatchTime 0.299366   LR 0.001229   
2022-11-25 13:30:00,327 - INFO  - Training [33][   80/  196]   Loss 2.302835   Top1 9.882812   Top5 49.877930   BatchTime 0.292834   LR 0.001228   
2022-11-25 13:30:05,380 - INFO  - Training [33][  100/  196]   Loss 2.302853   Top1 9.722656   Top5 49.730469   BatchTime 0.284800   LR 0.001226   
2022-11-25 13:30:10,117 - INFO  - Training [33][  120/  196]   Loss 2.302866   Top1 9.638672   Top5 49.687500   BatchTime 0.276804   LR 0.001225   
2022-11-25 13:30:15,290 - INFO  - Training [33][  140/  196]   Loss 2.302843   Top1 9.729353   Top5 49.762835   BatchTime 0.274207   LR 0.001224   
2022-11-25 13:30:21,431 - INFO  - Training [33][  160/  196]   Loss 2.302840   Top1 9.736328   Top5 49.768066   BatchTime 0.278312   LR 0.001222   
2022-11-25 13:30:26,990 - INFO  - Training [33][  180/  196]   Loss 2.302810   Top1 9.754774   Top5 49.856771   BatchTime 0.278270   LR 0.001221   
2022-11-25 13:30:31,111 - INFO  - ==> Top1: 9.752    Top5: 49.872    Loss: 2.303

2022-11-25 13:30:31,285 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:30:32,373 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:30:35,465 - INFO  - Validation [33][   20/   40]   Loss 2.302570   Top1 10.019531   Top5 50.292969   BatchTime 0.154534   
2022-11-25 13:30:36,533 - INFO  - Validation [33][   40/   40]   Loss 2.302660   Top1 10.000000   Top5 50.000000   BatchTime 0.103963   
2022-11-25 13:30:36,742 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:30:36,742 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:30:36,743 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:30:36,743 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:30:36,743 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:30:36,894 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:30:36,896 - INFO  - >>>>>> Epoch  34
2022-11-25 13:30:36,898 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:30:43,940 - INFO  - Training [34][   20/  196]   Loss 2.302575   Top1 10.253906   Top5 50.000000   BatchTime 0.351977   LR 0.001218   
2022-11-25 13:30:48,916 - INFO  - Training [34][   40/  196]   Loss 2.302601   Top1 10.126953   Top5 49.726562   BatchTime 0.300385   LR 0.001216   
2022-11-25 13:30:54,142 - INFO  - Training [34][   60/  196]   Loss 2.302598   Top1 10.273438   Top5 49.934896   BatchTime 0.287361   LR 0.001215   
2022-11-25 13:30:59,227 - INFO  - Training [34][   80/  196]   Loss 2.302618   Top1 10.234375   Top5 49.853516   BatchTime 0.279079   LR 0.001213   
2022-11-25 13:31:04,386 - INFO  - Training [34][  100/  196]   Loss 2.302721   Top1 10.082031   Top5 49.621094   BatchTime 0.274845   LR 0.001211   
2022-11-25 13:31:09,628 - INFO  - Training [34][  120/  196]   Loss 2.302744   Top1 9.990234   Top5 49.713542   BatchTime 0.272727   LR 0.001209   
2022-11-25 13:31:14,631 - INFO  - Training [34][  140/  196]   Loss 2.302750   Top1 10.002790   Top5 49.684710   BatchTime 0.269495   LR 0.001208   
2022-11-25 13:31:19,904 - INFO  - Training [34][  160/  196]   Loss 2.302722   Top1 10.031738   Top5 49.753418   BatchTime 0.268766   LR 0.001206   
2022-11-25 13:31:24,962 - INFO  - Training [34][  180/  196]   Loss 2.302757   Top1 10.019531   Top5 49.702691   BatchTime 0.267004   LR 0.001204   
2022-11-25 13:31:29,199 - INFO  - ==> Top1: 10.054    Top5: 49.792    Loss: 2.303

2022-11-25 13:31:29,468 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:31:30,837 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:31:34,846 - INFO  - Validation [34][   20/   40]   Loss 2.302558   Top1 10.253906   Top5 50.312500   BatchTime 0.200377   
2022-11-25 13:31:36,298 - INFO  - Validation [34][   40/   40]   Loss 2.302630   Top1 10.000000   Top5 50.000000   BatchTime 0.136491   
2022-11-25 13:31:36,609 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:31:36,609 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:31:36,610 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:31:36,610 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:31:36,610 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:31:36,750 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:31:36,752 - INFO  - >>>>>> Epoch  35
2022-11-25 13:31:36,755 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:31:44,543 - INFO  - Training [35][   20/  196]   Loss 2.303051   Top1 9.433594   Top5 48.769531   BatchTime 0.389239   LR 0.001201   
2022-11-25 13:31:49,601 - INFO  - Training [35][   40/  196]   Loss 2.302860   Top1 9.550781   Top5 49.248047   BatchTime 0.321050   LR 0.001199   
2022-11-25 13:31:54,832 - INFO  - Training [35][   60/  196]   Loss 2.302845   Top1 9.726562   Top5 49.472656   BatchTime 0.301214   LR 0.001197   
2022-11-25 13:31:59,809 - INFO  - Training [35][   80/  196]   Loss 2.302847   Top1 9.736328   Top5 49.418945   BatchTime 0.288128   LR 0.001195   
2022-11-25 13:32:04,962 - INFO  - Training [35][  100/  196]   Loss 2.302812   Top1 9.753906   Top5 49.558594   BatchTime 0.282026   LR 0.001192   
2022-11-25 13:32:10,146 - INFO  - Training [35][  120/  196]   Loss 2.302773   Top1 9.882812   Top5 49.661458   BatchTime 0.278228   LR 0.001190   
2022-11-25 13:32:15,288 - INFO  - Training [35][  140/  196]   Loss 2.302816   Top1 9.846540   Top5 49.584263   BatchTime 0.275200   LR 0.001188   
2022-11-25 13:32:20,300 - INFO  - Training [35][  160/  196]   Loss 2.302862   Top1 9.826660   Top5 49.433594   BatchTime 0.272128   LR 0.001186   
2022-11-25 13:32:25,502 - INFO  - Training [35][  180/  196]   Loss 2.302851   Top1 9.898003   Top5 49.505208   BatchTime 0.270789   LR 0.001184   
2022-11-25 13:32:29,719 - INFO  - ==> Top1: 9.924    Top5: 49.630    Loss: 2.303

2022-11-25 13:32:29,899 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:32:31,070 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:32:33,653 - INFO  - Validation [35][   20/   40]   Loss 2.302622   Top1 10.019531   Top5 50.234375   BatchTime 0.129076   
2022-11-25 13:32:34,781 - INFO  - Validation [35][   40/   40]   Loss 2.302702   Top1 10.000000   Top5 50.000000   BatchTime 0.092746   
2022-11-25 13:32:35,059 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:32:35,059 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:32:35,060 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:32:35,060 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:32:35,060 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:32:35,188 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:32:35,190 - INFO  - >>>>>> Epoch  36
2022-11-25 13:32:35,192 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:32:41,692 - INFO  - Training [36][   20/  196]   Loss 2.302913   Top1 9.238281   Top5 49.843750   BatchTime 0.324844   LR 0.001180   
2022-11-25 13:32:46,977 - INFO  - Training [36][   40/  196]   Loss 2.302706   Top1 9.853516   Top5 50.019531   BatchTime 0.294570   LR 0.001177   
2022-11-25 13:32:52,851 - INFO  - Training [36][   60/  196]   Loss 2.302704   Top1 9.837240   Top5 49.785156   BatchTime 0.294272   LR 0.001175   
2022-11-25 13:32:57,981 - INFO  - Training [36][   80/  196]   Loss 2.302676   Top1 9.995117   Top5 50.122070   BatchTime 0.284824   LR 0.001173   
2022-11-25 13:33:03,108 - INFO  - Training [36][  100/  196]   Loss 2.302751   Top1 10.000000   Top5 49.949219   BatchTime 0.279133   LR 0.001170   
2022-11-25 13:33:08,252 - INFO  - Training [36][  120/  196]   Loss 2.302749   Top1 10.022786   Top5 50.019531   BatchTime 0.275470   LR 0.001168   
2022-11-25 13:33:13,547 - INFO  - Training [36][  140/  196]   Loss 2.302749   Top1 10.027902   Top5 49.980469   BatchTime 0.273939   LR 0.001165   
2022-11-25 13:33:18,819 - INFO  - Training [36][  160/  196]   Loss 2.302763   Top1 10.009766   Top5 49.914551   BatchTime 0.272649   LR 0.001163   
2022-11-25 13:33:24,149 - INFO  - Training [36][  180/  196]   Loss 2.302764   Top1 9.908854   Top5 49.837240   BatchTime 0.271962   LR 0.001160   
2022-11-25 13:33:28,383 - INFO  - ==> Top1: 9.890    Top5: 49.804    Loss: 2.303

2022-11-25 13:33:28,610 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:33:29,926 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:33:32,714 - INFO  - Validation [36][   20/   40]   Loss 2.302616   Top1 10.078125   Top5 50.234375   BatchTime 0.139287   
2022-11-25 13:33:33,793 - INFO  - Validation [36][   40/   40]   Loss 2.302700   Top1 10.000000   Top5 50.000000   BatchTime 0.096631   
2022-11-25 13:33:34,003 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:33:34,003 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:33:34,003 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:33:34,004 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:33:34,004 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:33:34,139 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:33:34,141 - INFO  - >>>>>> Epoch  37
2022-11-25 13:33:34,143 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:33:41,461 - INFO  - Training [37][   20/  196]   Loss 2.302792   Top1 10.000000   Top5 49.843750   BatchTime 0.365780   LR 0.001155   
2022-11-25 13:33:46,796 - INFO  - Training [37][   40/  196]   Loss 2.302744   Top1 9.804688   Top5 50.009766   BatchTime 0.316257   LR 0.001153   
2022-11-25 13:33:51,823 - INFO  - Training [37][   60/  196]   Loss 2.302818   Top1 9.746094   Top5 49.895833   BatchTime 0.294631   LR 0.001150   
2022-11-25 13:33:57,098 - INFO  - Training [37][   80/  196]   Loss 2.302803   Top1 9.882812   Top5 49.853516   BatchTime 0.286907   LR 0.001147   
2022-11-25 13:34:03,178 - INFO  - Training [37][  100/  196]   Loss 2.302805   Top1 9.792969   Top5 49.855469   BatchTime 0.290321   LR 0.001144   
2022-11-25 13:34:08,173 - INFO  - Training [37][  120/  196]   Loss 2.302826   Top1 9.876302   Top5 49.853516   BatchTime 0.283558   LR 0.001142   
2022-11-25 13:34:13,108 - INFO  - Training [37][  140/  196]   Loss 2.302856   Top1 9.790737   Top5 49.584263   BatchTime 0.278297   LR 0.001139   
2022-11-25 13:34:18,239 - INFO  - Training [37][  160/  196]   Loss 2.302842   Top1 9.746094   Top5 49.631348   BatchTime 0.275582   LR 0.001136   
2022-11-25 13:34:23,396 - INFO  - Training [37][  180/  196]   Loss 2.302803   Top1 9.809028   Top5 49.637587   BatchTime 0.273612   LR 0.001133   
2022-11-25 13:34:27,670 - INFO  - ==> Top1: 9.788    Top5: 49.668    Loss: 2.303

2022-11-25 13:34:27,894 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:34:29,171 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:34:31,773 - INFO  - Validation [37][   20/   40]   Loss 2.302630   Top1 9.765625   Top5 49.707031   BatchTime 0.129976   
2022-11-25 13:34:32,798 - INFO  - Validation [37][   40/   40]   Loss 2.302599   Top1 10.000000   Top5 50.000000   BatchTime 0.090640   
2022-11-25 13:34:33,064 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:34:33,064 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:34:33,065 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:34:33,065 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:34:33,065 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:34:33,194 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:34:33,195 - INFO  - >>>>>> Epoch  38
2022-11-25 13:34:33,197 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:34:39,884 - INFO  - Training [38][   20/  196]   Loss 2.302744   Top1 9.628906   Top5 50.312500   BatchTime 0.334225   LR 0.001128   
2022-11-25 13:34:44,960 - INFO  - Training [38][   40/  196]   Loss 2.302571   Top1 10.097656   Top5 50.937500   BatchTime 0.294001   LR 0.001125   
2022-11-25 13:34:50,160 - INFO  - Training [38][   60/  196]   Loss 2.302657   Top1 9.876302   Top5 50.397135   BatchTime 0.282663   LR 0.001122   
2022-11-25 13:34:55,426 - INFO  - Training [38][   80/  196]   Loss 2.302658   Top1 9.902344   Top5 50.375977   BatchTime 0.277831   LR 0.001119   
2022-11-25 13:35:00,266 - INFO  - Training [38][  100/  196]   Loss 2.302690   Top1 9.957031   Top5 50.503906   BatchTime 0.270660   LR 0.001116   
2022-11-25 13:35:05,444 - INFO  - Training [38][  120/  196]   Loss 2.302711   Top1 9.960938   Top5 50.387370   BatchTime 0.268702   LR 0.001112   
2022-11-25 13:35:10,805 - INFO  - Training [38][  140/  196]   Loss 2.302727   Top1 9.921875   Top5 50.371094   BatchTime 0.268606   LR 0.001109   
2022-11-25 13:35:16,159 - INFO  - Training [38][  160/  196]   Loss 2.302787   Top1 9.875488   Top5 50.124512   BatchTime 0.268490   LR 0.001106   
2022-11-25 13:35:21,437 - INFO  - Training [38][  180/  196]   Loss 2.302764   Top1 9.852431   Top5 50.177951   BatchTime 0.267982   LR 0.001103   
2022-11-25 13:35:25,526 - INFO  - ==> Top1: 9.864    Top5: 50.176    Loss: 2.303

2022-11-25 13:35:25,769 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:35:27,098 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:35:29,720 - INFO  - Validation [38][   20/   40]   Loss 2.302642   Top1 10.019531   Top5 50.234375   BatchTime 0.130979   
2022-11-25 13:35:30,759 - INFO  - Validation [38][   40/   40]   Loss 2.302701   Top1 10.000000   Top5 50.000000   BatchTime 0.091477   
2022-11-25 13:35:31,027 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:35:31,028 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:35:31,028 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:35:31,028 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:35:31,028 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:35:31,159 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:35:31,160 - INFO  - >>>>>> Epoch  39
2022-11-25 13:35:31,162 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:35:38,642 - INFO  - Training [39][   20/  196]   Loss 2.302713   Top1 9.980469   Top5 49.394531   BatchTime 0.373862   LR 0.001097   
2022-11-25 13:35:43,710 - INFO  - Training [39][   40/  196]   Loss 2.302708   Top1 9.843750   Top5 49.736328   BatchTime 0.313628   LR 0.001094   
2022-11-25 13:35:49,001 - INFO  - Training [39][   60/  196]   Loss 2.302649   Top1 9.759115   Top5 49.980469   BatchTime 0.297277   LR 0.001090   
2022-11-25 13:35:53,894 - INFO  - Training [39][   80/  196]   Loss 2.302682   Top1 9.814453   Top5 49.736328   BatchTime 0.284120   LR 0.001087   
2022-11-25 13:35:59,406 - INFO  - Training [39][  100/  196]   Loss 2.302679   Top1 9.855469   Top5 49.777344   BatchTime 0.282417   LR 0.001084   
2022-11-25 13:36:04,386 - INFO  - Training [39][  120/  196]   Loss 2.302735   Top1 9.931641   Top5 49.700521   BatchTime 0.276838   LR 0.001080   
2022-11-25 13:36:09,504 - INFO  - Training [39][  140/  196]   Loss 2.302744   Top1 9.919085   Top5 49.511719   BatchTime 0.273850   LR 0.001077   
2022-11-25 13:36:14,383 - INFO  - Training [39][  160/  196]   Loss 2.302809   Top1 9.819336   Top5 49.545898   BatchTime 0.270109   LR 0.001073   
2022-11-25 13:36:19,541 - INFO  - Training [39][  180/  196]   Loss 2.302790   Top1 9.869792   Top5 49.565972   BatchTime 0.268754   LR 0.001070   
2022-11-25 13:36:23,598 - INFO  - ==> Top1: 9.880    Top5: 49.592    Loss: 2.303

2022-11-25 13:36:23,827 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:36:24,823 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:36:27,887 - INFO  - Validation [39][   20/   40]   Loss 2.302619   Top1 10.078125   Top5 50.234375   BatchTime 0.153141   
2022-11-25 13:36:29,871 - INFO  - Validation [39][   40/   40]   Loss 2.302706   Top1 10.000000   Top5 50.000000   BatchTime 0.126168   
2022-11-25 13:36:30,505 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:36:30,505 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:36:30,505 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:36:30,505 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:36:30,506 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:36:30,646 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:36:30,647 - INFO  - >>>>>> Epoch  40
2022-11-25 13:36:30,649 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:36:38,221 - INFO  - Training [40][   20/  196]   Loss 2.302689   Top1 9.824219   Top5 50.156250   BatchTime 0.378454   LR 0.001064   
2022-11-25 13:36:43,338 - INFO  - Training [40][   40/  196]   Loss 2.302645   Top1 9.843750   Top5 50.253906   BatchTime 0.317142   LR 0.001060   
2022-11-25 13:36:48,869 - INFO  - Training [40][   60/  196]   Loss 2.302756   Top1 9.863281   Top5 50.084635   BatchTime 0.303606   LR 0.001056   
2022-11-25 13:36:54,220 - INFO  - Training [40][   80/  196]   Loss 2.302664   Top1 9.980469   Top5 50.170898   BatchTime 0.294591   LR 0.001053   
2022-11-25 13:36:59,470 - INFO  - Training [40][  100/  196]   Loss 2.302662   Top1 9.996094   Top5 50.355469   BatchTime 0.288176   LR 0.001049   
2022-11-25 13:37:04,584 - INFO  - Training [40][  120/  196]   Loss 2.302696   Top1 9.967448   Top5 50.205078   BatchTime 0.282762   LR 0.001045   
2022-11-25 13:37:09,520 - INFO  - Training [40][  140/  196]   Loss 2.302695   Top1 9.946987   Top5 50.184152   BatchTime 0.277625   LR 0.001042   
2022-11-25 13:37:14,570 - INFO  - Training [40][  160/  196]   Loss 2.302692   Top1 9.960938   Top5 50.212402   BatchTime 0.274481   LR 0.001038   
2022-11-25 13:37:19,330 - INFO  - Training [40][  180/  196]   Loss 2.302722   Top1 9.947917   Top5 50.199653   BatchTime 0.270430   LR 0.001034   
2022-11-25 13:37:23,165 - INFO  - ==> Top1: 9.916    Top5: 50.158    Loss: 2.303

2022-11-25 13:37:23,378 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:37:24,476 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:37:27,557 - INFO  - Validation [40][   20/   40]   Loss 2.302595   Top1 10.078125   Top5 50.234375   BatchTime 0.153922   
2022-11-25 13:37:28,622 - INFO  - Validation [40][   40/   40]   Loss 2.302692   Top1 10.000000   Top5 50.000000   BatchTime 0.103596   
2022-11-25 13:37:28,867 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:37:28,868 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:37:28,868 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:37:28,868 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:37:28,868 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:37:28,986 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:37:28,987 - INFO  - >>>>>> Epoch  41
2022-11-25 13:37:28,989 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:37:36,555 - INFO  - Training [41][   20/  196]   Loss 2.302854   Top1 9.492188   Top5 50.996094   BatchTime 0.378191   LR 0.001027   
2022-11-25 13:37:41,873 - INFO  - Training [41][   40/  196]   Loss 2.302995   Top1 9.326172   Top5 49.960938   BatchTime 0.322039   LR 0.001023   
2022-11-25 13:37:47,159 - INFO  - Training [41][   60/  196]   Loss 2.302872   Top1 9.531250   Top5 49.967448   BatchTime 0.302796   LR 0.001020   
2022-11-25 13:37:52,130 - INFO  - Training [41][   80/  196]   Loss 2.302863   Top1 9.624023   Top5 49.863281   BatchTime 0.289230   LR 0.001016   
2022-11-25 13:37:57,419 - INFO  - Training [41][  100/  196]   Loss 2.302916   Top1 9.566406   Top5 49.699219   BatchTime 0.284271   LR 0.001012   
2022-11-25 13:38:03,185 - INFO  - Training [41][  120/  196]   Loss 2.302898   Top1 9.567057   Top5 49.658203   BatchTime 0.284942   LR 0.001008   
2022-11-25 13:38:08,050 - INFO  - Training [41][  140/  196]   Loss 2.302885   Top1 9.581473   Top5 49.718192   BatchTime 0.278986   LR 0.001004   
2022-11-25 13:38:13,368 - INFO  - Training [41][  160/  196]   Loss 2.302856   Top1 9.560547   Top5 49.777832   BatchTime 0.277349   LR 0.001000   
2022-11-25 13:38:18,445 - INFO  - Training [41][  180/  196]   Loss 2.302849   Top1 9.511719   Top5 49.854601   BatchTime 0.274741   LR 0.000996   
2022-11-25 13:38:22,636 - INFO  - ==> Top1: 9.550    Top5: 49.852    Loss: 2.303

2022-11-25 13:38:22,830 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:38:23,933 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:38:26,800 - INFO  - Validation [41][   20/   40]   Loss 2.302613   Top1 10.078125   Top5 50.312500   BatchTime 0.143240   
2022-11-25 13:38:27,838 - INFO  - Validation [41][   40/   40]   Loss 2.302696   Top1 10.000000   Top5 50.000000   BatchTime 0.097567   
2022-11-25 13:38:28,061 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:38:28,061 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:38:28,061 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:38:28,061 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:38:28,061 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:38:28,201 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:38:28,202 - INFO  - >>>>>> Epoch  42
2022-11-25 13:38:28,204 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:38:35,122 - INFO  - Training [42][   20/  196]   Loss 2.302840   Top1 10.175781   Top5 49.746094   BatchTime 0.345724   LR 0.000988   
2022-11-25 13:38:40,304 - INFO  - Training [42][   40/  196]   Loss 2.302839   Top1 9.677734   Top5 50.009766   BatchTime 0.302425   LR 0.000984   
2022-11-25 13:38:45,683 - INFO  - Training [42][   60/  196]   Loss 2.302922   Top1 9.583333   Top5 49.518229   BatchTime 0.291263   LR 0.000980   
2022-11-25 13:38:51,263 - INFO  - Training [42][   80/  196]   Loss 2.302826   Top1 9.780273   Top5 49.785156   BatchTime 0.288196   LR 0.000976   
2022-11-25 13:38:56,403 - INFO  - Training [42][  100/  196]   Loss 2.302898   Top1 9.609375   Top5 49.773438   BatchTime 0.281962   LR 0.000972   
2022-11-25 13:39:01,619 - INFO  - Training [42][  120/  196]   Loss 2.302900   Top1 9.765625   Top5 49.833984   BatchTime 0.278434   LR 0.000968   
2022-11-25 13:39:06,660 - INFO  - Training [42][  140/  196]   Loss 2.302904   Top1 9.773996   Top5 49.782366   BatchTime 0.274660   LR 0.000964   
2022-11-25 13:39:11,652 - INFO  - Training [42][  160/  196]   Loss 2.302895   Top1 9.790039   Top5 49.750977   BatchTime 0.271526   LR 0.000959   
2022-11-25 13:39:16,463 - INFO  - Training [42][  180/  196]   Loss 2.302905   Top1 9.793837   Top5 49.787326   BatchTime 0.268084   LR 0.000955   
2022-11-25 13:39:20,600 - INFO  - ==> Top1: 9.794    Top5: 49.720    Loss: 2.303

2022-11-25 13:39:20,781 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:39:21,879 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:39:24,824 - INFO  - Validation [42][   20/   40]   Loss 2.302582   Top1 10.253906   Top5 50.234375   BatchTime 0.147156   
2022-11-25 13:39:25,870 - INFO  - Validation [42][   40/   40]   Loss 2.302679   Top1 10.000000   Top5 50.000000   BatchTime 0.099722   
2022-11-25 13:39:26,119 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:39:26,119 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:39:26,119 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:39:26,120 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:39:26,120 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:39:26,254 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:39:26,255 - INFO  - >>>>>> Epoch  43
2022-11-25 13:39:26,257 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:39:34,245 - INFO  - Training [43][   20/  196]   Loss 2.302761   Top1 10.292969   Top5 50.273438   BatchTime 0.399272   LR 0.000947   
2022-11-25 13:39:39,225 - INFO  - Training [43][   40/  196]   Loss 2.302854   Top1 10.175781   Top5 49.609375   BatchTime 0.324133   LR 0.000943   
2022-11-25 13:39:44,534 - INFO  - Training [43][   60/  196]   Loss 2.302787   Top1 10.182292   Top5 49.772135   BatchTime 0.304571   LR 0.000939   
2022-11-25 13:39:49,788 - INFO  - Training [43][   80/  196]   Loss 2.302787   Top1 9.975586   Top5 49.760742   BatchTime 0.294098   LR 0.000934   
2022-11-25 13:39:55,333 - INFO  - Training [43][  100/  196]   Loss 2.302748   Top1 9.968750   Top5 49.765625   BatchTime 0.290731   LR 0.000930   
2022-11-25 13:40:00,425 - INFO  - Training [43][  120/  196]   Loss 2.302765   Top1 10.052083   Top5 49.752604   BatchTime 0.284703   LR 0.000926   
2022-11-25 13:40:05,607 - INFO  - Training [43][  140/  196]   Loss 2.302773   Top1 10.080915   Top5 49.771205   BatchTime 0.281050   LR 0.000921   
2022-11-25 13:40:10,888 - INFO  - Training [43][  160/  196]   Loss 2.302782   Top1 9.968262   Top5 49.731445   BatchTime 0.278923   LR 0.000917   
2022-11-25 13:40:15,591 - INFO  - Training [43][  180/  196]   Loss 2.302768   Top1 10.006510   Top5 49.796007   BatchTime 0.274060   LR 0.000912   
2022-11-25 13:40:19,887 - INFO  - ==> Top1: 9.980    Top5: 49.740    Loss: 2.303

2022-11-25 13:40:20,067 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:40:21,156 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:40:24,192 - INFO  - Validation [43][   20/   40]   Loss 2.302607   Top1 10.078125   Top5 50.234375   BatchTime 0.151733   
2022-11-25 13:40:25,236 - INFO  - Validation [43][   40/   40]   Loss 2.302701   Top1 10.000000   Top5 50.000000   BatchTime 0.101966   
2022-11-25 13:40:25,451 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:40:25,452 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:40:25,452 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:40:25,452 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:40:25,452 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:40:25,566 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:40:25,567 - INFO  - >>>>>> Epoch  44
2022-11-25 13:40:25,569 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:40:32,419 - INFO  - Training [44][   20/  196]   Loss 2.302710   Top1 10.000000   Top5 49.824219   BatchTime 0.342402   LR 0.000904   
2022-11-25 13:40:37,510 - INFO  - Training [44][   40/  196]   Loss 2.302831   Top1 9.970703   Top5 49.482422   BatchTime 0.298472   LR 0.000900   
2022-11-25 13:40:42,397 - INFO  - Training [44][   60/  196]   Loss 2.302662   Top1 10.058594   Top5 50.136719   BatchTime 0.280417   LR 0.000895   
2022-11-25 13:40:47,387 - INFO  - Training [44][   80/  196]   Loss 2.302689   Top1 10.029297   Top5 50.200195   BatchTime 0.272701   LR 0.000891   
2022-11-25 13:40:52,466 - INFO  - Training [44][  100/  196]   Loss 2.302617   Top1 10.167969   Top5 50.359375   BatchTime 0.268950   LR 0.000886   
2022-11-25 13:40:57,379 - INFO  - Training [44][  120/  196]   Loss 2.302655   Top1 10.126953   Top5 50.315755   BatchTime 0.265061   LR 0.000882   
2022-11-25 13:41:02,281 - INFO  - Training [44][  140/  196]   Loss 2.302721   Top1 10.106027   Top5 50.170201   BatchTime 0.262211   LR 0.000877   
2022-11-25 13:41:07,457 - INFO  - Training [44][  160/  196]   Loss 2.302751   Top1 10.000000   Top5 50.122070   BatchTime 0.261781   LR 0.000873   
2022-11-25 13:41:12,795 - INFO  - Training [44][  180/  196]   Loss 2.302760   Top1 9.997830   Top5 50.030382   BatchTime 0.262352   LR 0.000868   
2022-11-25 13:41:16,880 - INFO  - ==> Top1: 10.002    Top5: 50.208    Loss: 2.303

2022-11-25 13:41:17,083 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:41:18,182 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:41:21,032 - INFO  - Validation [44][   20/   40]   Loss 2.302977   Top1 9.882812   Top5 49.765625   BatchTime 0.142440   
2022-11-25 13:41:22,104 - INFO  - Validation [44][   40/   40]   Loss 2.302855   Top1 10.000000   Top5 50.000000   BatchTime 0.098018   
2022-11-25 13:41:22,350 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:41:22,350 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:41:22,350 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:41:22,351 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:41:22,351 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:41:22,470 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:41:22,472 - INFO  - >>>>>> Epoch  45
2022-11-25 13:41:22,473 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:41:29,584 - INFO  - Training [45][   20/  196]   Loss 2.302815   Top1 10.195312   Top5 50.566406   BatchTime 0.355394   LR 0.000860   
2022-11-25 13:41:34,652 - INFO  - Training [45][   40/  196]   Loss 2.302767   Top1 10.185547   Top5 50.234375   BatchTime 0.304390   LR 0.000855   
2022-11-25 13:41:39,728 - INFO  - Training [45][   60/  196]   Loss 2.302735   Top1 9.973958   Top5 50.214844   BatchTime 0.287530   LR 0.000850   
2022-11-25 13:41:44,841 - INFO  - Training [45][   80/  196]   Loss 2.302701   Top1 9.960938   Top5 50.341797   BatchTime 0.279564   LR 0.000846   
2022-11-25 13:41:49,932 - INFO  - Training [45][  100/  196]   Loss 2.302746   Top1 9.828125   Top5 50.191406   BatchTime 0.274561   LR 0.000841   
2022-11-25 13:41:54,912 - INFO  - Training [45][  120/  196]   Loss 2.302727   Top1 9.833984   Top5 50.188802   BatchTime 0.270296   LR 0.000836   
2022-11-25 13:42:00,055 - INFO  - Training [45][  140/  196]   Loss 2.302745   Top1 9.860491   Top5 50.086496   BatchTime 0.268419   LR 0.000832   
2022-11-25 13:42:05,328 - INFO  - Training [45][  160/  196]   Loss 2.302787   Top1 9.843750   Top5 49.860840   BatchTime 0.267822   LR 0.000827   
2022-11-25 13:42:10,395 - INFO  - Training [45][  180/  196]   Loss 2.302770   Top1 9.871962   Top5 49.865451   BatchTime 0.266213   LR 0.000822   
2022-11-25 13:42:14,690 - INFO  - ==> Top1: 9.862    Top5: 49.842    Loss: 2.303

2022-11-25 13:42:14,927 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:42:16,342 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:42:19,272 - INFO  - Validation [45][   20/   40]   Loss 2.302584   Top1 10.078125   Top5 50.332031   BatchTime 0.146401   
2022-11-25 13:42:20,332 - INFO  - Validation [45][   40/   40]   Loss 2.302637   Top1 10.000000   Top5 50.000000   BatchTime 0.099706   
2022-11-25 13:42:20,550 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:42:20,550 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:42:20,551 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:42:20,551 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:42:20,551 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:42:20,686 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:42:20,687 - INFO  - >>>>>> Epoch  46
2022-11-25 13:42:20,689 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:42:27,889 - INFO  - Training [46][   20/  196]   Loss 2.302599   Top1 10.664062   Top5 50.156250   BatchTime 0.359867   LR 0.000814   
2022-11-25 13:42:32,973 - INFO  - Training [46][   40/  196]   Loss 2.302720   Top1 9.990234   Top5 49.804688   BatchTime 0.307037   LR 0.000809   
2022-11-25 13:42:38,375 - INFO  - Training [46][   60/  196]   Loss 2.302618   Top1 9.973958   Top5 50.136719   BatchTime 0.294719   LR 0.000804   
2022-11-25 13:42:43,402 - INFO  - Training [46][   80/  196]   Loss 2.302651   Top1 9.941406   Top5 49.951172   BatchTime 0.283876   LR 0.000799   
2022-11-25 13:42:48,407 - INFO  - Training [46][  100/  196]   Loss 2.302681   Top1 9.949219   Top5 49.835938   BatchTime 0.277153   LR 0.000794   
2022-11-25 13:42:53,329 - INFO  - Training [46][  120/  196]   Loss 2.302719   Top1 9.840495   Top5 49.794922   BatchTime 0.271977   LR 0.000789   
2022-11-25 13:42:58,218 - INFO  - Training [46][  140/  196]   Loss 2.302697   Top1 9.866071   Top5 49.907924   BatchTime 0.268041   LR 0.000785   
2022-11-25 13:43:03,140 - INFO  - Training [46][  160/  196]   Loss 2.302687   Top1 9.990234   Top5 49.948730   BatchTime 0.265300   LR 0.000780   
2022-11-25 13:43:08,085 - INFO  - Training [46][  180/  196]   Loss 2.302679   Top1 10.043403   Top5 49.889323   BatchTime 0.263290   LR 0.000775   
2022-11-25 13:43:12,445 - INFO  - ==> Top1: 9.994    Top5: 49.912    Loss: 2.303

2022-11-25 13:43:12,631 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:43:13,683 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:43:16,638 - INFO  - Validation [46][   20/   40]   Loss 2.302580   Top1 10.078125   Top5 50.234375   BatchTime 0.147651   
2022-11-25 13:43:17,679 - INFO  - Validation [46][   40/   40]   Loss 2.302633   Top1 10.000000   Top5 50.000000   BatchTime 0.099849   
2022-11-25 13:43:17,934 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:43:17,935 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:43:17,935 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:43:17,935 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:43:17,935 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:43:18,055 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:43:18,056 - INFO  - >>>>>> Epoch  47
2022-11-25 13:43:18,058 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:43:25,443 - INFO  - Training [47][   20/  196]   Loss 2.302705   Top1 9.531250   Top5 49.902344   BatchTime 0.369128   LR 0.000766   
2022-11-25 13:43:30,504 - INFO  - Training [47][   40/  196]   Loss 2.302817   Top1 9.687500   Top5 49.873047   BatchTime 0.311078   LR 0.000761   
2022-11-25 13:43:35,723 - INFO  - Training [47][   60/  196]   Loss 2.302830   Top1 9.785156   Top5 49.453125   BatchTime 0.294367   LR 0.000756   
2022-11-25 13:43:40,787 - INFO  - Training [47][   80/  196]   Loss 2.302854   Top1 9.946289   Top5 49.628906   BatchTime 0.284079   LR 0.000752   
2022-11-25 13:43:46,135 - INFO  - Training [47][  100/  196]   Loss 2.302870   Top1 9.847656   Top5 49.609375   BatchTime 0.280734   LR 0.000747   
2022-11-25 13:43:51,521 - INFO  - Training [47][  120/  196]   Loss 2.302869   Top1 9.778646   Top5 49.563802   BatchTime 0.278829   LR 0.000742   
2022-11-25 13:43:56,416 - INFO  - Training [47][  140/  196]   Loss 2.302845   Top1 9.760045   Top5 49.592634   BatchTime 0.273963   LR 0.000737   
2022-11-25 13:44:01,411 - INFO  - Training [47][  160/  196]   Loss 2.302799   Top1 9.809570   Top5 49.692383   BatchTime 0.270936   LR 0.000732   
2022-11-25 13:44:06,476 - INFO  - Training [47][  180/  196]   Loss 2.302802   Top1 9.769965   Top5 49.654948   BatchTime 0.268965   LR 0.000727   
2022-11-25 13:44:10,716 - INFO  - ==> Top1: 9.808    Top5: 49.704    Loss: 2.303

2022-11-25 13:44:10,936 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:44:12,094 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:44:15,172 - INFO  - Validation [47][   20/   40]   Loss 2.302619   Top1 9.882812   Top5 49.960938   BatchTime 0.153803   
2022-11-25 13:44:16,285 - INFO  - Validation [47][   40/   40]   Loss 2.302605   Top1 10.000000   Top5 50.000000   BatchTime 0.104731   
2022-11-25 13:44:16,524 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:44:16,525 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:44:16,525 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:44:16,525 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:44:16,525 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:44:16,671 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:44:16,673 - INFO  - >>>>>> Epoch  48
2022-11-25 13:44:16,675 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:44:23,699 - INFO  - Training [48][   20/  196]   Loss 2.302872   Top1 9.863281   Top5 49.550781   BatchTime 0.351076   LR 0.000718   
2022-11-25 13:44:28,603 - INFO  - Training [48][   40/  196]   Loss 2.302803   Top1 9.746094   Top5 49.384766   BatchTime 0.298139   LR 0.000713   
2022-11-25 13:44:33,628 - INFO  - Training [48][   60/  196]   Loss 2.302872   Top1 9.628906   Top5 49.225260   BatchTime 0.282507   LR 0.000708   
2022-11-25 13:44:38,636 - INFO  - Training [48][   80/  196]   Loss 2.302844   Top1 9.692383   Top5 49.165039   BatchTime 0.274484   LR 0.000703   
2022-11-25 13:44:43,772 - INFO  - Training [48][  100/  196]   Loss 2.302837   Top1 9.851562   Top5 49.300781   BatchTime 0.270939   LR 0.000698   
2022-11-25 13:44:48,974 - INFO  - Training [48][  120/  196]   Loss 2.302819   Top1 9.807943   Top5 49.401042   BatchTime 0.269137   LR 0.000693   
2022-11-25 13:44:54,128 - INFO  - Training [48][  140/  196]   Loss 2.302797   Top1 9.935826   Top5 49.372210   BatchTime 0.267499   LR 0.000688   
2022-11-25 13:44:59,171 - INFO  - Training [48][  160/  196]   Loss 2.302823   Top1 9.833984   Top5 49.213867   BatchTime 0.265581   LR 0.000683   
2022-11-25 13:45:04,413 - INFO  - Training [48][  180/  196]   Loss 2.302815   Top1 9.780816   Top5 49.275174   BatchTime 0.265196   LR 0.000678   
2022-11-25 13:45:08,458 - INFO  - ==> Top1: 9.748    Top5: 49.320    Loss: 2.303

2022-11-25 13:45:08,679 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:45:09,841 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:45:13,136 - INFO  - Validation [48][   20/   40]   Loss 2.302667   Top1 9.863281   Top5 49.765625   BatchTime 0.164664   
2022-11-25 13:45:14,229 - INFO  - Validation [48][   40/   40]   Loss 2.302627   Top1 10.000000   Top5 50.000000   BatchTime 0.109663   
2022-11-25 13:45:14,480 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:45:14,480 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:45:14,481 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:45:14,481 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:45:14,481 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:45:14,604 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:45:14,607 - INFO  - >>>>>> Epoch  49
2022-11-25 13:45:14,609 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:45:21,917 - INFO  - Training [49][   20/  196]   Loss 2.302765   Top1 9.687500   Top5 50.390625   BatchTime 0.365248   LR 0.000669   
2022-11-25 13:45:27,025 - INFO  - Training [49][   40/  196]   Loss 2.302752   Top1 9.726562   Top5 50.224609   BatchTime 0.310323   LR 0.000664   
2022-11-25 13:45:31,859 - INFO  - Training [49][   60/  196]   Loss 2.302760   Top1 9.739583   Top5 50.000000   BatchTime 0.287434   LR 0.000659   
2022-11-25 13:45:36,799 - INFO  - Training [49][   80/  196]   Loss 2.302712   Top1 9.799805   Top5 50.317383   BatchTime 0.277324   LR 0.000654   
2022-11-25 13:45:41,751 - INFO  - Training [49][  100/  196]   Loss 2.302755   Top1 9.726562   Top5 50.109375   BatchTime 0.271387   LR 0.000649   
2022-11-25 13:45:46,853 - INFO  - Training [49][  120/  196]   Loss 2.302710   Top1 9.804688   Top5 50.218099   BatchTime 0.268663   LR 0.000644   
2022-11-25 13:45:51,940 - INFO  - Training [49][  140/  196]   Loss 2.302732   Top1 9.765625   Top5 50.066964   BatchTime 0.266622   LR 0.000639   
2022-11-25 13:45:56,738 - INFO  - Training [49][  160/  196]   Loss 2.302748   Top1 9.731445   Top5 49.946289   BatchTime 0.263283   LR 0.000634   
2022-11-25 13:46:01,676 - INFO  - Training [49][  180/  196]   Loss 2.302736   Top1 9.754774   Top5 49.932726   BatchTime 0.261461   LR 0.000629   
2022-11-25 13:46:05,875 - INFO  - ==> Top1: 9.772    Top5: 49.910    Loss: 2.303

2022-11-25 13:46:06,087 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:46:07,111 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:46:09,965 - INFO  - Validation [49][   20/   40]   Loss 2.302647   Top1 9.863281   Top5 49.765625   BatchTime 0.142611   
2022-11-25 13:46:11,014 - INFO  - Validation [49][   40/   40]   Loss 2.302615   Top1 10.000000   Top5 50.000000   BatchTime 0.097517   
2022-11-25 13:46:11,288 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:46:11,288 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:46:11,288 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:46:11,288 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:46:11,289 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:46:11,415 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:46:11,417 - INFO  - >>>>>> Epoch  50
2022-11-25 13:46:11,419 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:46:18,216 - INFO  - Training [50][   20/  196]   Loss 2.302644   Top1 9.746094   Top5 50.488281   BatchTime 0.339744   LR 0.000620   
2022-11-25 13:46:23,421 - INFO  - Training [50][   40/  196]   Loss 2.302593   Top1 10.175781   Top5 50.253906   BatchTime 0.299981   LR 0.000615   
2022-11-25 13:46:28,369 - INFO  - Training [50][   60/  196]   Loss 2.302603   Top1 10.039062   Top5 50.403646   BatchTime 0.282454   LR 0.000610   
2022-11-25 13:46:33,348 - INFO  - Training [50][   80/  196]   Loss 2.302610   Top1 10.029297   Top5 50.371094   BatchTime 0.274081   LR 0.000605   
2022-11-25 13:46:38,431 - INFO  - Training [50][  100/  196]   Loss 2.302661   Top1 9.921875   Top5 50.140625   BatchTime 0.270096   LR 0.000600   
2022-11-25 13:46:43,450 - INFO  - Training [50][  120/  196]   Loss 2.302701   Top1 9.850260   Top5 49.973958   BatchTime 0.266904   LR 0.000595   
2022-11-25 13:46:48,347 - INFO  - Training [50][  140/  196]   Loss 2.302673   Top1 9.907924   Top5 50.019531   BatchTime 0.263749   LR 0.000590   
2022-11-25 13:46:53,438 - INFO  - Training [50][  160/  196]   Loss 2.302658   Top1 9.929199   Top5 50.046387   BatchTime 0.262597   LR 0.000585   
2022-11-25 13:46:58,589 - INFO  - Training [50][  180/  196]   Loss 2.302659   Top1 9.865451   Top5 50.049913   BatchTime 0.262036   LR 0.000580   
2022-11-25 13:47:02,768 - INFO  - ==> Top1: 9.910    Top5: 50.050    Loss: 2.303

2022-11-25 13:47:02,959 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:47:04,049 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:47:06,891 - INFO  - Validation [50][   20/   40]   Loss 2.302820   Top1 9.882812   Top5 49.765625   BatchTime 0.142065   
2022-11-25 13:47:07,942 - INFO  - Validation [50][   40/   40]   Loss 2.302726   Top1 10.000000   Top5 50.000000   BatchTime 0.097287   
2022-11-25 13:47:08,230 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:47:08,231 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:47:08,231 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:47:08,231 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:47:08,231 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:47:08,378 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:47:08,379 - INFO  - >>>>>> Epoch  51
2022-11-25 13:47:08,381 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:47:15,639 - INFO  - Training [51][   20/  196]   Loss 2.302590   Top1 10.195312   Top5 50.312500   BatchTime 0.362781   LR 0.000571   
2022-11-25 13:47:20,578 - INFO  - Training [51][   40/  196]   Loss 2.302695   Top1 10.039062   Top5 49.941406   BatchTime 0.304855   LR 0.000566   
2022-11-25 13:47:25,671 - INFO  - Training [51][   60/  196]   Loss 2.302619   Top1 9.986979   Top5 50.175781   BatchTime 0.288114   LR 0.000561   
2022-11-25 13:47:30,331 - INFO  - Training [51][   80/  196]   Loss 2.302636   Top1 9.946289   Top5 49.946289   BatchTime 0.274345   LR 0.000556   
2022-11-25 13:47:35,261 - INFO  - Training [51][  100/  196]   Loss 2.302600   Top1 10.066406   Top5 49.957031   BatchTime 0.268773   LR 0.000551   
2022-11-25 13:47:40,398 - INFO  - Training [51][  120/  196]   Loss 2.302668   Top1 9.951172   Top5 49.781901   BatchTime 0.266778   LR 0.000546   
2022-11-25 13:47:45,468 - INFO  - Training [51][  140/  196]   Loss 2.302701   Top1 9.891183   Top5 49.746094   BatchTime 0.264883   LR 0.000541   
2022-11-25 13:47:50,402 - INFO  - Training [51][  160/  196]   Loss 2.302711   Top1 9.890137   Top5 49.707031   BatchTime 0.262612   LR 0.000536   
2022-11-25 13:47:55,061 - INFO  - Training [51][  180/  196]   Loss 2.302693   Top1 9.915365   Top5 49.763455   BatchTime 0.259315   LR 0.000531   
2022-11-25 13:47:59,267 - INFO  - ==> Top1: 9.948    Top5: 49.886    Loss: 2.303

2022-11-25 13:47:59,452 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:48:00,507 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:48:03,556 - INFO  - Validation [51][   20/   40]   Loss 2.302777   Top1 9.882812   Top5 50.039062   BatchTime 0.152379   
2022-11-25 13:48:04,576 - INFO  - Validation [51][   40/   40]   Loss 2.302696   Top1 10.000000   Top5 50.000000   BatchTime 0.101672   
2022-11-25 13:48:04,810 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:48:04,811 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:48:04,811 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:48:04,811 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:48:04,811 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:48:04,951 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:48:04,953 - INFO  - >>>>>> Epoch  52
2022-11-25 13:48:04,955 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:48:12,046 - INFO  - Training [52][   20/  196]   Loss 2.302701   Top1 9.453125   Top5 49.707031   BatchTime 0.354330   LR 0.000523   
2022-11-25 13:48:17,058 - INFO  - Training [52][   40/  196]   Loss 2.302684   Top1 9.482422   Top5 49.677734   BatchTime 0.302469   LR 0.000518   
2022-11-25 13:48:22,002 - INFO  - Training [52][   60/  196]   Loss 2.302659   Top1 9.680990   Top5 50.117188   BatchTime 0.284045   LR 0.000513   
2022-11-25 13:48:26,957 - INFO  - Training [52][   80/  196]   Loss 2.302651   Top1 9.682617   Top5 50.112305   BatchTime 0.274972   LR 0.000508   
2022-11-25 13:48:32,095 - INFO  - Training [52][  100/  196]   Loss 2.302606   Top1 9.812500   Top5 50.332031   BatchTime 0.271356   LR 0.000503   
2022-11-25 13:48:37,067 - INFO  - Training [52][  120/  196]   Loss 2.302614   Top1 9.804688   Top5 50.315755   BatchTime 0.267564   LR 0.000498   
2022-11-25 13:48:42,136 - INFO  - Training [52][  140/  196]   Loss 2.302624   Top1 9.827009   Top5 50.304129   BatchTime 0.265546   LR 0.000493   
2022-11-25 13:48:47,109 - INFO  - Training [52][  160/  196]   Loss 2.302639   Top1 9.741211   Top5 50.227051   BatchTime 0.263432   LR 0.000488   
2022-11-25 13:48:52,081 - INFO  - Training [52][  180/  196]   Loss 2.302649   Top1 9.733073   Top5 50.075955   BatchTime 0.261784   LR 0.000483   
2022-11-25 13:48:56,241 - INFO  - ==> Top1: 9.796    Top5: 50.100    Loss: 2.303

2022-11-25 13:48:56,452 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:48:57,576 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:49:00,514 - INFO  - Validation [52][   20/   40]   Loss 2.302590   Top1 10.019531   Top5 50.039062   BatchTime 0.146821   
2022-11-25 13:49:01,597 - INFO  - Validation [52][   40/   40]   Loss 2.302590   Top1 10.000000   Top5 50.000000   BatchTime 0.100479   
2022-11-25 13:49:01,872 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:49:01,872 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:49:01,873 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:49:01,873 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:49:01,873 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:49:02,005 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:49:02,007 - INFO  - >>>>>> Epoch  53
2022-11-25 13:49:02,009 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:49:09,925 - INFO  - Training [53][   20/  196]   Loss 2.302626   Top1 10.351562   Top5 49.570312   BatchTime 0.395678   LR 0.000474   
2022-11-25 13:49:14,944 - INFO  - Training [53][   40/  196]   Loss 2.302726   Top1 10.195312   Top5 49.599609   BatchTime 0.323326   LR 0.000470   
2022-11-25 13:49:19,699 - INFO  - Training [53][   60/  196]   Loss 2.302721   Top1 10.084635   Top5 49.544271   BatchTime 0.294791   LR 0.000465   
2022-11-25 13:49:24,579 - INFO  - Training [53][   80/  196]   Loss 2.302678   Top1 10.058594   Top5 49.780273   BatchTime 0.282100   LR 0.000460   
2022-11-25 13:49:29,629 - INFO  - Training [53][  100/  196]   Loss 2.302658   Top1 9.988281   Top5 49.871094   BatchTime 0.276176   LR 0.000455   
2022-11-25 13:49:34,934 - INFO  - Training [53][  120/  196]   Loss 2.302693   Top1 9.886068   Top5 49.703776   BatchTime 0.274354   LR 0.000450   
2022-11-25 13:49:39,844 - INFO  - Training [53][  140/  196]   Loss 2.302707   Top1 9.799107   Top5 49.500558   BatchTime 0.270228   LR 0.000445   
2022-11-25 13:49:44,952 - INFO  - Training [53][  160/  196]   Loss 2.302702   Top1 9.726562   Top5 49.621582   BatchTime 0.268375   LR 0.000441   
2022-11-25 13:49:49,914 - INFO  - Training [53][  180/  196]   Loss 2.302728   Top1 9.674479   Top5 49.607205   BatchTime 0.266123   LR 0.000436   
2022-11-25 13:49:54,156 - INFO  - ==> Top1: 9.726    Top5: 49.578    Loss: 2.303

2022-11-25 13:49:54,352 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:49:55,860 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:49:58,922 - INFO  - Validation [53][   20/   40]   Loss 2.302773   Top1 9.882812   Top5 50.039062   BatchTime 0.152974   
2022-11-25 13:49:59,990 - INFO  - Validation [53][   40/   40]   Loss 2.302689   Top1 10.000000   Top5 50.000000   BatchTime 0.103198   
2022-11-25 13:50:00,229 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:50:00,229 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:50:00,230 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:50:00,230 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:50:00,230 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:50:00,343 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:50:00,345 - INFO  - >>>>>> Epoch  54
2022-11-25 13:50:00,347 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:50:07,370 - INFO  - Training [54][   20/  196]   Loss 2.302722   Top1 9.667969   Top5 49.121094   BatchTime 0.351036   LR 0.000427   
2022-11-25 13:50:12,306 - INFO  - Training [54][   40/  196]   Loss 2.302819   Top1 9.609375   Top5 48.994141   BatchTime 0.298913   LR 0.000423   
2022-11-25 13:50:17,312 - INFO  - Training [54][   60/  196]   Loss 2.302727   Top1 9.791667   Top5 49.414062   BatchTime 0.282705   LR 0.000418   
2022-11-25 13:50:22,565 - INFO  - Training [54][   80/  196]   Loss 2.302707   Top1 9.902344   Top5 49.550781   BatchTime 0.277696   LR 0.000413   
2022-11-25 13:50:27,659 - INFO  - Training [54][  100/  196]   Loss 2.302647   Top1 9.957031   Top5 49.769531   BatchTime 0.273085   LR 0.000408   
2022-11-25 13:50:32,643 - INFO  - Training [54][  120/  196]   Loss 2.302646   Top1 9.892578   Top5 49.759115   BatchTime 0.269107   LR 0.000404   
2022-11-25 13:50:37,658 - INFO  - Training [54][  140/  196]   Loss 2.302671   Top1 9.857701   Top5 49.575893   BatchTime 0.266483   LR 0.000399   
2022-11-25 13:50:42,618 - INFO  - Training [54][  160/  196]   Loss 2.302671   Top1 9.895020   Top5 49.511719   BatchTime 0.264174   LR 0.000394   
2022-11-25 13:50:48,023 - INFO  - Training [54][  180/  196]   Loss 2.302683   Top1 9.832899   Top5 49.570312   BatchTime 0.264852   LR 0.000390   
2022-11-25 13:50:52,228 - INFO  - ==> Top1: 9.828    Top5: 49.638    Loss: 2.303

2022-11-25 13:50:52,446 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:50:53,590 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:50:56,554 - INFO  - Validation [54][   20/   40]   Loss 2.302739   Top1 9.882812   Top5 50.039062   BatchTime 0.148083   
2022-11-25 13:50:57,604 - INFO  - Validation [54][   40/   40]   Loss 2.302665   Top1 10.000000   Top5 50.000000   BatchTime 0.100310   
2022-11-25 13:50:57,862 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:50:57,863 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:50:57,863 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:50:57,863 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:50:57,863 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:50:57,982 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:50:57,983 - INFO  - >>>>>> Epoch  55
2022-11-25 13:50:57,985 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:51:05,412 - INFO  - Training [55][   20/  196]   Loss 2.302750   Top1 9.589844   Top5 48.886719   BatchTime 0.371224   LR 0.000381   
2022-11-25 13:51:10,449 - INFO  - Training [55][   40/  196]   Loss 2.302711   Top1 9.824219   Top5 49.804688   BatchTime 0.311546   LR 0.000377   
2022-11-25 13:51:15,429 - INFO  - Training [55][   60/  196]   Loss 2.302611   Top1 10.175781   Top5 49.960938   BatchTime 0.290689   LR 0.000372   
2022-11-25 13:51:20,676 - INFO  - Training [55][   80/  196]   Loss 2.302673   Top1 10.126953   Top5 49.672852   BatchTime 0.283605   LR 0.000368   
2022-11-25 13:51:25,609 - INFO  - Training [55][  100/  196]   Loss 2.302684   Top1 10.097656   Top5 49.785156   BatchTime 0.276211   LR 0.000363   
2022-11-25 13:51:30,750 - INFO  - Training [55][  120/  196]   Loss 2.302671   Top1 9.986979   Top5 49.912109   BatchTime 0.273017   LR 0.000358   
2022-11-25 13:51:35,814 - INFO  - Training [55][  140/  196]   Loss 2.302654   Top1 9.988839   Top5 50.008371   BatchTime 0.270187   LR 0.000354   
2022-11-25 13:51:40,903 - INFO  - Training [55][  160/  196]   Loss 2.302664   Top1 10.009766   Top5 50.017090   BatchTime 0.268216   LR 0.000349   
2022-11-25 13:51:45,866 - INFO  - Training [55][  180/  196]   Loss 2.302679   Top1 10.013021   Top5 49.971788   BatchTime 0.265986   LR 0.000345   
2022-11-25 13:51:50,143 - INFO  - ==> Top1: 10.032    Top5: 49.954    Loss: 2.303

2022-11-25 13:51:50,339 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:51:51,426 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:51:54,187 - INFO  - Validation [55][   20/   40]   Loss 2.302753   Top1 9.882812   Top5 49.765625   BatchTime 0.137950   
2022-11-25 13:51:55,251 - INFO  - Validation [55][   40/   40]   Loss 2.302673   Top1 10.000000   Top5 50.000000   BatchTime 0.095578   
2022-11-25 13:51:55,473 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:51:55,473 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:51:55,474 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:51:55,474 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:51:55,474 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:51:55,587 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:51:55,588 - INFO  - >>>>>> Epoch  56
2022-11-25 13:51:55,590 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:52:02,460 - INFO  - Training [56][   20/  196]   Loss 2.302677   Top1 10.019531   Top5 49.785156   BatchTime 0.343385   LR 0.000337   
2022-11-25 13:52:07,705 - INFO  - Training [56][   40/  196]   Loss 2.302781   Top1 9.960938   Top5 49.443359   BatchTime 0.302826   LR 0.000333   
2022-11-25 13:52:12,928 - INFO  - Training [56][   60/  196]   Loss 2.302650   Top1 10.299479   Top5 49.921875   BatchTime 0.288920   LR 0.000328   
2022-11-25 13:52:18,232 - INFO  - Training [56][   80/  196]   Loss 2.302641   Top1 10.253906   Top5 50.073242   BatchTime 0.282983   LR 0.000324   
2022-11-25 13:52:23,406 - INFO  - Training [56][  100/  196]   Loss 2.302631   Top1 10.113281   Top5 50.027344   BatchTime 0.278127   LR 0.000319   
2022-11-25 13:52:28,417 - INFO  - Training [56][  120/  196]   Loss 2.302647   Top1 10.104167   Top5 49.986979   BatchTime 0.273530   LR 0.000315   
2022-11-25 13:52:33,748 - INFO  - Training [56][  140/  196]   Loss 2.302656   Top1 10.097656   Top5 49.952567   BatchTime 0.272535   LR 0.000311   
2022-11-25 13:52:38,886 - INFO  - Training [56][  160/  196]   Loss 2.302659   Top1 10.134277   Top5 49.785156   BatchTime 0.270577   LR 0.000306   
2022-11-25 13:52:43,958 - INFO  - Training [56][  180/  196]   Loss 2.302650   Top1 10.110677   Top5 49.815538   BatchTime 0.268694   LR 0.000302   
2022-11-25 13:52:48,268 - INFO  - ==> Top1: 10.122    Top5: 49.766    Loss: 2.303

2022-11-25 13:52:48,481 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:52:49,562 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:52:52,705 - INFO  - Validation [56][   20/   40]   Loss 2.302748   Top1 9.882812   Top5 49.765625   BatchTime 0.157055   
2022-11-25 13:52:53,821 - INFO  - Validation [56][   40/   40]   Loss 2.302668   Top1 10.000000   Top5 50.000000   BatchTime 0.106425   
2022-11-25 13:52:54,069 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:52:54,069 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:52:54,070 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:52:54,070 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:52:54,070 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:52:54,205 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:52:54,207 - INFO  - >>>>>> Epoch  57
2022-11-25 13:52:54,209 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:53:01,527 - INFO  - Training [57][   20/  196]   Loss 2.302835   Top1 10.156250   Top5 50.175781   BatchTime 0.365780   LR 0.000294   
2022-11-25 13:53:06,933 - INFO  - Training [57][   40/  196]   Loss 2.302814   Top1 9.951172   Top5 49.785156   BatchTime 0.318038   LR 0.000290   
2022-11-25 13:53:12,201 - INFO  - Training [57][   60/  196]   Loss 2.302717   Top1 10.058594   Top5 49.804688   BatchTime 0.299831   LR 0.000286   
2022-11-25 13:53:17,733 - INFO  - Training [57][   80/  196]   Loss 2.302689   Top1 9.951172   Top5 50.053711   BatchTime 0.294011   LR 0.000282   
2022-11-25 13:53:23,023 - INFO  - Training [57][  100/  196]   Loss 2.302728   Top1 9.812500   Top5 49.843750   BatchTime 0.288113   LR 0.000277   
2022-11-25 13:53:28,153 - INFO  - Training [57][  120/  196]   Loss 2.302742   Top1 9.820964   Top5 49.720052   BatchTime 0.282846   LR 0.000273   
2022-11-25 13:53:33,422 - INFO  - Training [57][  140/  196]   Loss 2.302734   Top1 9.882812   Top5 49.656808   BatchTime 0.280073   LR 0.000269   
2022-11-25 13:53:38,813 - INFO  - Training [57][  160/  196]   Loss 2.302731   Top1 9.860840   Top5 49.741211   BatchTime 0.278753   LR 0.000265   
2022-11-25 13:53:43,899 - INFO  - Training [57][  180/  196]   Loss 2.302752   Top1 9.839410   Top5 49.713542   BatchTime 0.276039   LR 0.000261   
2022-11-25 13:53:47,891 - INFO  - ==> Top1: 9.820    Top5: 49.672    Loss: 2.303

2022-11-25 13:53:48,070 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:53:49,036 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:53:51,965 - INFO  - Validation [57][   20/   40]   Loss 2.302749   Top1 9.882812   Top5 49.765625   BatchTime 0.146378   
2022-11-25 13:53:53,084 - INFO  - Validation [57][   40/   40]   Loss 2.302670   Top1 10.000000   Top5 50.000000   BatchTime 0.101146   
2022-11-25 13:53:53,317 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:53:53,317 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:53:53,317 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:53:53,318 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:53:53,318 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:53:53,439 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:53:53,441 - INFO  - >>>>>> Epoch  58
2022-11-25 13:53:53,443 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:53:59,760 - INFO  - Training [58][   20/  196]   Loss 2.302671   Top1 9.863281   Top5 49.726562   BatchTime 0.315731   LR 0.000254   
2022-11-25 13:54:04,838 - INFO  - Training [58][   40/  196]   Loss 2.302666   Top1 9.960938   Top5 49.970703   BatchTime 0.284813   LR 0.000250   
2022-11-25 13:54:09,776 - INFO  - Training [58][   60/  196]   Loss 2.302638   Top1 9.895833   Top5 50.221354   BatchTime 0.272175   LR 0.000246   
2022-11-25 13:54:14,700 - INFO  - Training [58][   80/  196]   Loss 2.302639   Top1 10.014648   Top5 50.083008   BatchTime 0.265687   LR 0.000242   
2022-11-25 13:54:19,755 - INFO  - Training [58][  100/  196]   Loss 2.302621   Top1 9.953125   Top5 50.234375   BatchTime 0.263099   LR 0.000238   
2022-11-25 13:54:24,965 - INFO  - Training [58][  120/  196]   Loss 2.302606   Top1 10.081380   Top5 50.214844   BatchTime 0.262663   LR 0.000234   
2022-11-25 13:54:29,970 - INFO  - Training [58][  140/  196]   Loss 2.302628   Top1 10.005580   Top5 50.108817   BatchTime 0.260890   LR 0.000230   
2022-11-25 13:54:35,060 - INFO  - Training [58][  160/  196]   Loss 2.302635   Top1 10.034180   Top5 50.173340   BatchTime 0.260092   LR 0.000226   
2022-11-25 13:54:40,140 - INFO  - Training [58][  180/  196]   Loss 2.302652   Top1 9.926215   Top5 50.013021   BatchTime 0.259412   LR 0.000222   
2022-11-25 13:54:43,921 - INFO  - ==> Top1: 9.948    Top5: 49.974    Loss: 2.303

2022-11-25 13:54:44,146 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:54:45,235 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:54:47,931 - INFO  - Validation [58][   20/   40]   Loss 2.302741   Top1 9.882812   Top5 50.039062   BatchTime 0.134746   
2022-11-25 13:54:49,035 - INFO  - Validation [58][   40/   40]   Loss 2.302668   Top1 10.000000   Top5 50.000000   BatchTime 0.094966   
2022-11-25 13:54:49,258 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:54:49,258 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:54:49,259 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:54:49,259 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:54:49,259 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:54:49,372 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:54:49,373 - INFO  - >>>>>> Epoch  59
2022-11-25 13:54:49,375 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:54:56,598 - INFO  - Training [59][   20/  196]   Loss 2.302804   Top1 9.472656   Top5 49.335938   BatchTime 0.361036   LR 0.000215   
2022-11-25 13:55:01,629 - INFO  - Training [59][   40/  196]   Loss 2.302840   Top1 9.443359   Top5 49.091797   BatchTime 0.306295   LR 0.000212   
2022-11-25 13:55:06,657 - INFO  - Training [59][   60/  196]   Loss 2.302827   Top1 9.479167   Top5 49.121094   BatchTime 0.287992   LR 0.000208   
2022-11-25 13:55:11,534 - INFO  - Training [59][   80/  196]   Loss 2.302751   Top1 9.721680   Top5 49.467773   BatchTime 0.276959   LR 0.000204   
2022-11-25 13:55:17,205 - INFO  - Training [59][  100/  196]   Loss 2.302727   Top1 9.746094   Top5 49.585938   BatchTime 0.278269   LR 0.000201   
2022-11-25 13:55:22,190 - INFO  - Training [59][  120/  196]   Loss 2.302713   Top1 9.648438   Top5 49.602865   BatchTime 0.273438   LR 0.000197   
2022-11-25 13:55:27,090 - INFO  - Training [59][  140/  196]   Loss 2.302700   Top1 9.709821   Top5 49.567522   BatchTime 0.269376   LR 0.000193   
2022-11-25 13:55:32,119 - INFO  - Training [59][  160/  196]   Loss 2.302687   Top1 9.689941   Top5 49.648438   BatchTime 0.267131   LR 0.000190   
2022-11-25 13:55:37,075 - INFO  - Training [59][  180/  196]   Loss 2.302690   Top1 9.674479   Top5 49.680990   BatchTime 0.264983   LR 0.000186   
2022-11-25 13:55:41,126 - INFO  - ==> Top1: 9.700    Top5: 49.644    Loss: 2.303

2022-11-25 13:55:41,304 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:55:42,218 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:55:44,912 - INFO  - Validation [59][   20/   40]   Loss 2.302736   Top1 9.882812   Top5 50.039062   BatchTime 0.134631   
2022-11-25 13:55:45,988 - INFO  - Validation [59][   40/   40]   Loss 2.302665   Top1 10.000000   Top5 50.000000   BatchTime 0.094220   
2022-11-25 13:55:46,256 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:55:46,256 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:55:46,257 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:55:46,257 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:55:46,257 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:55:46,371 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:55:46,372 - INFO  - >>>>>> Epoch  60
2022-11-25 13:55:46,374 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:55:53,099 - INFO  - Training [60][   20/  196]   Loss 2.302525   Top1 9.980469   Top5 50.468750   BatchTime 0.336118   LR 0.000180   
2022-11-25 13:55:57,889 - INFO  - Training [60][   40/  196]   Loss 2.302555   Top1 9.960938   Top5 50.449219   BatchTime 0.287826   LR 0.000176   
2022-11-25 13:56:02,880 - INFO  - Training [60][   60/  196]   Loss 2.302613   Top1 9.615885   Top5 50.097656   BatchTime 0.275068   LR 0.000173   
2022-11-25 13:56:07,718 - INFO  - Training [60][   80/  196]   Loss 2.302585   Top1 9.716797   Top5 50.234375   BatchTime 0.266767   LR 0.000169   
2022-11-25 13:56:12,799 - INFO  - Training [60][  100/  196]   Loss 2.302580   Top1 9.828125   Top5 50.312500   BatchTime 0.264227   LR 0.000166   
2022-11-25 13:56:18,169 - INFO  - Training [60][  120/  196]   Loss 2.302595   Top1 9.794922   Top5 50.172526   BatchTime 0.264927   LR 0.000162   
2022-11-25 13:56:23,447 - INFO  - Training [60][  140/  196]   Loss 2.302603   Top1 9.782366   Top5 50.086496   BatchTime 0.264786   LR 0.000159   
2022-11-25 13:56:28,773 - INFO  - Training [60][  160/  196]   Loss 2.302610   Top1 9.853516   Top5 50.087891   BatchTime 0.264977   LR 0.000156   
2022-11-25 13:56:33,922 - INFO  - Training [60][  180/  196]   Loss 2.302605   Top1 9.887153   Top5 50.004340   BatchTime 0.264139   LR 0.000152   
2022-11-25 13:56:37,818 - INFO  - ==> Top1: 9.888    Top5: 49.944    Loss: 2.303

2022-11-25 13:56:38,015 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:56:39,112 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:56:41,757 - INFO  - Validation [60][   20/   40]   Loss 2.302736   Top1 9.882812   Top5 49.765625   BatchTime 0.132153   
2022-11-25 13:56:42,799 - INFO  - Validation [60][   40/   40]   Loss 2.302664   Top1 10.000000   Top5 50.000000   BatchTime 0.092139   
2022-11-25 13:56:43,207 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:56:43,207 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:56:43,208 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:56:43,208 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:56:43,208 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:56:43,334 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:56:43,336 - INFO  - >>>>>> Epoch  61
2022-11-25 13:56:43,338 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:56:50,466 - INFO  - Training [61][   20/  196]   Loss 2.302580   Top1 10.234375   Top5 50.097656   BatchTime 0.356294   LR 0.000147   
2022-11-25 13:56:55,618 - INFO  - Training [61][   40/  196]   Loss 2.302601   Top1 9.980469   Top5 49.912109   BatchTime 0.306920   LR 0.000143   
2022-11-25 13:57:00,747 - INFO  - Training [61][   60/  196]   Loss 2.302646   Top1 9.752604   Top5 49.648438   BatchTime 0.290106   LR 0.000140   
2022-11-25 13:57:05,644 - INFO  - Training [61][   80/  196]   Loss 2.302615   Top1 9.809570   Top5 49.863281   BatchTime 0.278791   LR 0.000137   
2022-11-25 13:57:10,631 - INFO  - Training [61][  100/  196]   Loss 2.302605   Top1 9.890625   Top5 49.832031   BatchTime 0.272905   LR 0.000134   
2022-11-25 13:57:15,600 - INFO  - Training [61][  120/  196]   Loss 2.302611   Top1 9.889323   Top5 49.833984   BatchTime 0.268825   LR 0.000131   
2022-11-25 13:57:20,549 - INFO  - Training [61][  140/  196]   Loss 2.302642   Top1 9.944196   Top5 49.804688   BatchTime 0.265774   LR 0.000128   
2022-11-25 13:57:25,649 - INFO  - Training [61][  160/  196]   Loss 2.302669   Top1 9.895020   Top5 49.746094   BatchTime 0.264426   LR 0.000125   
2022-11-25 13:57:30,757 - INFO  - Training [61][  180/  196]   Loss 2.302681   Top1 9.876302   Top5 49.730903   BatchTime 0.263424   LR 0.000122   
2022-11-25 13:57:34,995 - INFO  - ==> Top1: 9.946    Top5: 49.734    Loss: 2.303

2022-11-25 13:57:35,181 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:57:36,258 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:57:38,841 - INFO  - Validation [61][   20/   40]   Loss 2.302736   Top1 9.882812   Top5 49.765625   BatchTime 0.129071   
2022-11-25 13:57:39,910 - INFO  - Validation [61][   40/   40]   Loss 2.302665   Top1 10.000000   Top5 50.000000   BatchTime 0.091253   
2022-11-25 13:57:40,122 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:57:40,122 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:57:40,123 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:57:40,123 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:57:40,123 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:57:40,262 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:57:40,263 - INFO  - >>>>>> Epoch  62
2022-11-25 13:57:40,265 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:57:47,369 - INFO  - Training [62][   20/  196]   Loss 2.302576   Top1 9.785156   Top5 50.156250   BatchTime 0.355041   LR 0.000117   
2022-11-25 13:57:52,041 - INFO  - Training [62][   40/  196]   Loss 2.302593   Top1 9.941406   Top5 50.234375   BatchTime 0.294332   LR 0.000114   
2022-11-25 13:57:57,335 - INFO  - Training [62][   60/  196]   Loss 2.302517   Top1 10.104167   Top5 50.826823   BatchTime 0.284459   LR 0.000111   
2022-11-25 13:58:02,660 - INFO  - Training [62][   80/  196]   Loss 2.302580   Top1 9.921875   Top5 50.332031   BatchTime 0.279896   LR 0.000108   
2022-11-25 13:58:07,954 - INFO  - Training [62][  100/  196]   Loss 2.302649   Top1 9.792969   Top5 50.171875   BatchTime 0.276858   LR 0.000105   
2022-11-25 13:58:12,989 - INFO  - Training [62][  120/  196]   Loss 2.302592   Top1 9.817708   Top5 50.351562   BatchTime 0.272670   LR 0.000102   
2022-11-25 13:58:18,355 - INFO  - Training [62][  140/  196]   Loss 2.302605   Top1 9.874442   Top5 50.256696   BatchTime 0.272045   LR 0.000100   
2022-11-25 13:58:23,760 - INFO  - Training [62][  160/  196]   Loss 2.302622   Top1 9.802246   Top5 50.175781   BatchTime 0.271823   LR 0.000097   
2022-11-25 13:58:28,819 - INFO  - Training [62][  180/  196]   Loss 2.302631   Top1 9.848090   Top5 50.052083   BatchTime 0.269724   LR 0.000094   
2022-11-25 13:58:33,053 - INFO  - ==> Top1: 9.876    Top5: 49.938    Loss: 2.303

2022-11-25 13:58:33,333 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:58:34,563 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:58:38,076 - INFO  - Validation [62][   20/   40]   Loss 2.302736   Top1 9.882812   Top5 49.765625   BatchTime 0.175622   
2022-11-25 13:58:39,204 - INFO  - Validation [62][   40/   40]   Loss 2.302665   Top1 10.000000   Top5 50.000000   BatchTime 0.115998   
2022-11-25 13:58:39,425 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:58:39,425 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:58:39,425 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:58:39,425 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:58:39,425 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:58:39,560 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:58:39,561 - INFO  - >>>>>> Epoch  63
2022-11-25 13:58:39,563 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:58:46,928 - INFO  - Training [63][   20/  196]   Loss 2.302775   Top1 9.609375   Top5 49.023438   BatchTime 0.368111   LR 0.000090   
2022-11-25 13:58:52,201 - INFO  - Training [63][   40/  196]   Loss 2.302725   Top1 9.306641   Top5 49.501953   BatchTime 0.315870   LR 0.000087   
2022-11-25 13:58:57,514 - INFO  - Training [63][   60/  196]   Loss 2.302668   Top1 9.667969   Top5 49.856771   BatchTime 0.299131   LR 0.000085   
2022-11-25 13:59:02,745 - INFO  - Training [63][   80/  196]   Loss 2.302669   Top1 9.648438   Top5 49.931641   BatchTime 0.289734   LR 0.000082   
2022-11-25 13:59:07,622 - INFO  - Training [63][  100/  196]   Loss 2.302661   Top1 9.707031   Top5 50.058594   BatchTime 0.280555   LR 0.000080   
2022-11-25 13:59:12,685 - INFO  - Training [63][  120/  196]   Loss 2.302648   Top1 9.690755   Top5 50.104167   BatchTime 0.275984   LR 0.000077   
2022-11-25 13:59:17,792 - INFO  - Training [63][  140/  196]   Loss 2.302678   Top1 9.665179   Top5 50.053013   BatchTime 0.273037   LR 0.000075   
2022-11-25 13:59:22,897 - INFO  - Training [63][  160/  196]   Loss 2.302659   Top1 9.758301   Top5 50.136719   BatchTime 0.270814   LR 0.000072   
2022-11-25 13:59:28,103 - INFO  - Training [63][  180/  196]   Loss 2.302643   Top1 9.835069   Top5 50.199653   BatchTime 0.269644   LR 0.000070   
2022-11-25 13:59:32,453 - INFO  - ==> Top1: 9.848    Top5: 50.132    Loss: 2.303

2022-11-25 13:59:32,657 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:59:33,625 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:59:36,461 - INFO  - Validation [63][   20/   40]   Loss 2.302733   Top1 9.882812   Top5 49.765625   BatchTime 0.141748   
2022-11-25 13:59:37,500 - INFO  - Validation [63][   40/   40]   Loss 2.302662   Top1 10.000000   Top5 50.000000   BatchTime 0.096846   
2022-11-25 13:59:37,707 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 13:59:37,707 - INFO  - ==> Sparsity : 0.001

2022-11-25 13:59:37,708 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 13:59:37,708 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 13:59:37,708 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 13:59:37,823 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:59:37,824 - INFO  - >>>>>> Epoch  64
2022-11-25 13:59:37,826 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:59:44,637 - INFO  - Training [64][   20/  196]   Loss 2.302707   Top1 9.316406   Top5 50.234375   BatchTime 0.340381   LR 0.000066   
2022-11-25 13:59:50,168 - INFO  - Training [64][   40/  196]   Loss 2.302635   Top1 9.453125   Top5 50.244141   BatchTime 0.308472   LR 0.000064   
2022-11-25 13:59:55,391 - INFO  - Training [64][   60/  196]   Loss 2.302639   Top1 9.583333   Top5 50.279948   BatchTime 0.292695   LR 0.000062   
2022-11-25 14:00:00,571 - INFO  - Training [64][   80/  196]   Loss 2.302719   Top1 9.501953   Top5 49.936523   BatchTime 0.284272   LR 0.000059   
2022-11-25 14:00:06,018 - INFO  - Training [64][  100/  196]   Loss 2.302723   Top1 9.601562   Top5 50.003906   BatchTime 0.281890   LR 0.000057   
2022-11-25 14:00:11,084 - INFO  - Training [64][  120/  196]   Loss 2.302688   Top1 9.759115   Top5 50.048828   BatchTime 0.277125   LR 0.000055   
2022-11-25 14:00:15,873 - INFO  - Training [64][  140/  196]   Loss 2.302689   Top1 9.813058   Top5 50.041853   BatchTime 0.271743   LR 0.000053   
2022-11-25 14:00:21,133 - INFO  - Training [64][  160/  196]   Loss 2.302703   Top1 9.814453   Top5 50.004883   BatchTime 0.270647   LR 0.000051   
2022-11-25 14:00:26,115 - INFO  - Training [64][  180/  196]   Loss 2.302683   Top1 9.939236   Top5 49.967448   BatchTime 0.268254   LR 0.000049   
2022-11-25 14:00:30,061 - INFO  - ==> Top1: 9.930    Top5: 49.942    Loss: 2.303

2022-11-25 14:00:30,362 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:00:31,538 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:00:34,201 - INFO  - Validation [64][   20/   40]   Loss 2.302728   Top1 9.882812   Top5 49.765625   BatchTime 0.133083   
2022-11-25 14:00:35,300 - INFO  - Validation [64][   40/   40]   Loss 2.302658   Top1 10.000000   Top5 50.000000   BatchTime 0.094021   
2022-11-25 14:00:35,541 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 14:00:35,541 - INFO  - ==> Sparsity : 0.001

2022-11-25 14:00:35,541 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 14:00:35,541 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 14:00:35,541 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 14:00:35,676 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:00:35,677 - INFO  - >>>>>> Epoch  65
2022-11-25 14:00:35,679 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:00:42,442 - INFO  - Training [65][   20/  196]   Loss 2.302607   Top1 10.156250   Top5 49.609375   BatchTime 0.338004   LR 0.000046   
2022-11-25 14:00:47,155 - INFO  - Training [65][   40/  196]   Loss 2.302816   Top1 9.941406   Top5 49.531250   BatchTime 0.286844   LR 0.000044   
2022-11-25 14:00:52,351 - INFO  - Training [65][   60/  196]   Loss 2.302621   Top1 10.195312   Top5 49.967448   BatchTime 0.277826   LR 0.000042   
2022-11-25 14:00:57,678 - INFO  - Training [65][   80/  196]   Loss 2.302630   Top1 10.161133   Top5 50.166016   BatchTime 0.274954   LR 0.000040   
2022-11-25 14:01:02,742 - INFO  - Training [65][  100/  196]   Loss 2.302595   Top1 10.277344   Top5 50.351562   BatchTime 0.270601   LR 0.000039   
2022-11-25 14:01:07,451 - INFO  - Training [65][  120/  196]   Loss 2.302584   Top1 10.224609   Top5 50.283203   BatchTime 0.264741   LR 0.000037   
2022-11-25 14:01:12,587 - INFO  - Training [65][  140/  196]   Loss 2.302562   Top1 10.239955   Top5 50.359933   BatchTime 0.263604   LR 0.000035   
2022-11-25 14:01:18,181 - INFO  - Training [65][  160/  196]   Loss 2.302600   Top1 10.168457   Top5 50.244141   BatchTime 0.265616   LR 0.000033   
2022-11-25 14:01:23,214 - INFO  - Training [65][  180/  196]   Loss 2.302613   Top1 10.047743   Top5 50.269097   BatchTime 0.264067   LR 0.000032   
2022-11-25 14:01:27,615 - INFO  - ==> Top1: 10.092    Top5: 50.196    Loss: 2.303

2022-11-25 14:01:27,830 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:01:28,871 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:01:31,850 - INFO  - Validation [65][   20/   40]   Loss 2.302725   Top1 9.882812   Top5 49.765625   BatchTime 0.148884   
2022-11-25 14:01:33,019 - INFO  - Validation [65][   40/   40]   Loss 2.302657   Top1 10.000000   Top5 50.000000   BatchTime 0.103656   
2022-11-25 14:01:33,304 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 14:01:33,304 - INFO  - ==> Sparsity : 0.001

2022-11-25 14:01:33,305 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 14:01:33,305 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 14:01:33,305 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 14:01:33,433 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:01:33,434 - INFO  - >>>>>> Epoch  66
2022-11-25 14:01:33,436 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:01:40,441 - INFO  - Training [66][   20/  196]   Loss 2.302450   Top1 11.015625   Top5 49.843750   BatchTime 0.350079   LR 0.000029   
2022-11-25 14:01:45,592 - INFO  - Training [66][   40/  196]   Loss 2.302626   Top1 10.546875   Top5 49.755859   BatchTime 0.303830   LR 0.000028   
2022-11-25 14:01:50,366 - INFO  - Training [66][   60/  196]   Loss 2.302655   Top1 10.338542   Top5 49.674479   BatchTime 0.282110   LR 0.000026   
2022-11-25 14:01:55,391 - INFO  - Training [66][   80/  196]   Loss 2.302600   Top1 10.263672   Top5 49.916992   BatchTime 0.274397   LR 0.000025   
2022-11-25 14:02:00,576 - INFO  - Training [66][  100/  196]   Loss 2.302542   Top1 10.277344   Top5 50.179688   BatchTime 0.271369   LR 0.000023   
2022-11-25 14:02:05,776 - INFO  - Training [66][  120/  196]   Loss 2.302590   Top1 10.081380   Top5 50.139974   BatchTime 0.269470   LR 0.000022   
2022-11-25 14:02:11,028 - INFO  - Training [66][  140/  196]   Loss 2.302584   Top1 10.025112   Top5 50.156250   BatchTime 0.268489   LR 0.000021   
2022-11-25 14:02:15,866 - INFO  - Training [66][  160/  196]   Loss 2.302592   Top1 10.039062   Top5 50.190430   BatchTime 0.265163   LR 0.000019   
2022-11-25 14:02:21,002 - INFO  - Training [66][  180/  196]   Loss 2.302593   Top1 10.065104   Top5 50.110677   BatchTime 0.264235   LR 0.000018   
2022-11-25 14:02:25,183 - INFO  - ==> Top1: 10.036    Top5: 50.156    Loss: 2.303

2022-11-25 14:02:25,397 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:02:26,360 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:02:29,514 - INFO  - Validation [66][   20/   40]   Loss 2.302725   Top1 9.882812   Top5 49.765625   BatchTime 0.157621   
2022-11-25 14:02:30,556 - INFO  - Validation [66][   40/   40]   Loss 2.302657   Top1 10.000000   Top5 50.000000   BatchTime 0.104868   
2022-11-25 14:02:30,768 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 14:02:30,769 - INFO  - ==> Sparsity : 0.001

2022-11-25 14:02:30,769 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 14:02:30,769 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 14:02:30,769 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 14:02:30,904 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:02:30,905 - INFO  - >>>>>> Epoch  67
2022-11-25 14:02:30,907 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:02:38,341 - INFO  - Training [67][   20/  196]   Loss 2.302425   Top1 10.351562   Top5 50.781250   BatchTime 0.371581   LR 0.000016   
2022-11-25 14:02:43,640 - INFO  - Training [67][   40/  196]   Loss 2.302551   Top1 10.107422   Top5 50.439453   BatchTime 0.318237   LR 0.000015   
2022-11-25 14:02:49,093 - INFO  - Training [67][   60/  196]   Loss 2.302592   Top1 10.143229   Top5 50.169271   BatchTime 0.303053   LR 0.000014   
2022-11-25 14:02:54,633 - INFO  - Training [67][   80/  196]   Loss 2.302600   Top1 10.151367   Top5 50.351562   BatchTime 0.296538   LR 0.000013   
2022-11-25 14:02:59,813 - INFO  - Training [67][  100/  196]   Loss 2.302650   Top1 10.234375   Top5 50.152344   BatchTime 0.289031   LR 0.000012   
2022-11-25 14:03:05,086 - INFO  - Training [67][  120/  196]   Loss 2.302719   Top1 10.058594   Top5 50.055339   BatchTime 0.284800   LR 0.000011   
2022-11-25 14:03:10,088 - INFO  - Training [67][  140/  196]   Loss 2.302731   Top1 10.047433   Top5 49.913504   BatchTime 0.279841   LR 0.000010   
2022-11-25 14:03:14,860 - INFO  - Training [67][  160/  196]   Loss 2.302778   Top1 9.980469   Top5 49.743652   BatchTime 0.274683   LR 0.000009   
2022-11-25 14:03:19,928 - INFO  - Training [67][  180/  196]   Loss 2.302745   Top1 9.913194   Top5 49.911024   BatchTime 0.272320   LR 0.000008   
2022-11-25 14:03:24,085 - INFO  - ==> Top1: 9.924    Top5: 49.918    Loss: 2.303

2022-11-25 14:03:24,295 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:03:25,420 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:03:28,362 - INFO  - Validation [67][   20/   40]   Loss 2.302724   Top1 9.882812   Top5 49.765625   BatchTime 0.147034   
2022-11-25 14:03:29,379 - INFO  - Validation [67][   40/   40]   Loss 2.302656   Top1 10.000000   Top5 50.000000   BatchTime 0.098964   
2022-11-25 14:03:29,609 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 14:03:29,610 - INFO  - ==> Sparsity : 0.001

2022-11-25 14:03:29,610 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 14:03:29,610 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 14:03:29,610 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 14:03:29,726 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:03:29,727 - INFO  - >>>>>> Epoch  68
2022-11-25 14:03:29,729 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:03:36,568 - INFO  - Training [68][   20/  196]   Loss 2.302524   Top1 9.921875   Top5 50.273438   BatchTime 0.341836   LR 0.000007   
2022-11-25 14:03:41,763 - INFO  - Training [68][   40/  196]   Loss 2.302692   Top1 9.960938   Top5 50.185547   BatchTime 0.300789   LR 0.000006   
2022-11-25 14:03:46,680 - INFO  - Training [68][   60/  196]   Loss 2.302608   Top1 10.058594   Top5 50.390625   BatchTime 0.282475   LR 0.000006   
2022-11-25 14:03:51,604 - INFO  - Training [68][   80/  196]   Loss 2.302715   Top1 9.838867   Top5 50.195312   BatchTime 0.273399   LR 0.000005   
2022-11-25 14:03:56,840 - INFO  - Training [68][  100/  196]   Loss 2.302693   Top1 10.007812   Top5 50.207031   BatchTime 0.271086   LR 0.000004   
2022-11-25 14:04:02,028 - INFO  - Training [68][  120/  196]   Loss 2.302692   Top1 9.996745   Top5 50.136719   BatchTime 0.269132   LR 0.000004   
2022-11-25 14:04:06,838 - INFO  - Training [68][  140/  196]   Loss 2.302734   Top1 10.016741   Top5 49.938616   BatchTime 0.265043   LR 0.000003   
2022-11-25 14:04:12,162 - INFO  - Training [68][  160/  196]   Loss 2.302723   Top1 10.095215   Top5 49.829102   BatchTime 0.265189   LR 0.000003   
2022-11-25 14:04:17,090 - INFO  - Training [68][  180/  196]   Loss 2.302725   Top1 10.093316   Top5 49.884983   BatchTime 0.263098   LR 0.000002   
2022-11-25 14:04:21,463 - INFO  - ==> Top1: 10.076    Top5: 49.910    Loss: 2.303

2022-11-25 14:04:21,678 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:04:22,835 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:04:25,781 - INFO  - Validation [68][   20/   40]   Loss 2.302724   Top1 9.882812   Top5 49.765625   BatchTime 0.147221   
2022-11-25 14:04:26,803 - INFO  - Validation [68][   40/   40]   Loss 2.302656   Top1 10.000000   Top5 50.000000   BatchTime 0.099152   
2022-11-25 14:04:27,019 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 14:04:27,020 - INFO  - ==> Sparsity : 0.001

2022-11-25 14:04:27,020 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 14:04:27,020 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 14:04:27,020 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 14:04:27,143 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:04:27,145 - INFO  - >>>>>> Epoch  69
2022-11-25 14:04:27,146 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:04:34,347 - INFO  - Training [69][   20/  196]   Loss 2.302866   Top1 9.960938   Top5 50.214844   BatchTime 0.359858   LR 0.000002   
2022-11-25 14:04:39,264 - INFO  - Training [69][   40/  196]   Loss 2.302800   Top1 9.970703   Top5 50.029297   BatchTime 0.302864   LR 0.000001   
2022-11-25 14:04:44,918 - INFO  - Training [69][   60/  196]   Loss 2.302815   Top1 9.915365   Top5 49.726562   BatchTime 0.296144   LR 0.000001   
2022-11-25 14:04:50,040 - INFO  - Training [69][   80/  196]   Loss 2.302801   Top1 9.882812   Top5 49.873047   BatchTime 0.286139   LR 0.000001   
2022-11-25 14:04:55,215 - INFO  - Training [69][  100/  196]   Loss 2.302781   Top1 9.843750   Top5 49.914062   BatchTime 0.280659   LR 0.000000   
2022-11-25 14:05:00,341 - INFO  - Training [69][  120/  196]   Loss 2.302784   Top1 9.798177   Top5 49.980469   BatchTime 0.276599   LR 0.000000   
2022-11-25 14:05:05,341 - INFO  - Training [69][  140/  196]   Loss 2.302759   Top1 9.874442   Top5 50.025112   BatchTime 0.272798   LR 0.000000   
2022-11-25 14:05:10,138 - INFO  - Training [69][  160/  196]   Loss 2.302765   Top1 9.931641   Top5 49.897461   BatchTime 0.268677   LR 0.000000   
2022-11-25 14:05:14,926 - INFO  - Training [69][  180/  196]   Loss 2.302801   Top1 9.911024   Top5 49.769965   BatchTime 0.265422   LR 0.000000   
2022-11-25 14:05:19,144 - INFO  - ==> Top1: 9.948    Top5: 49.746    Loss: 2.303

2022-11-25 14:05:19,351 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:05:20,310 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:05:23,614 - INFO  - Validation [69][   20/   40]   Loss 2.302724   Top1 9.882812   Top5 49.765625   BatchTime 0.165084   
2022-11-25 14:05:24,696 - INFO  - Validation [69][   40/   40]   Loss 2.302656   Top1 10.000000   Top5 50.000000   BatchTime 0.109607   
2022-11-25 14:05:24,929 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 14:05:24,930 - INFO  - ==> Sparsity : 0.001

2022-11-25 14:05:24,930 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.270   Top5: 99.800]
2022-11-25 14:05:24,930 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 91.120   Top5: 99.790]
2022-11-25 14:05:24,930 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.920   Top5: 99.790]
2022-11-25 14:05:25,062 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111802/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:05:25,063 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 14:05:25,064 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:05:27,957 - INFO  - Validation [   20/   40]   Loss 2.302724   Top1 9.882812   Top5 49.765625   BatchTime 0.144574   
2022-11-25 14:05:29,020 - INFO  - Validation [   40/   40]   Loss 2.302656   Top1 10.000000   Top5 50.000000   BatchTime 0.098874   
2022-11-25 14:05:29,211 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.303

2022-11-25 14:05:29,211 - INFO  - ==> Sparsity : 0.000

2022-11-25 14:05:29,212 - INFO  - Program completed sucessfully ... exiting ...
