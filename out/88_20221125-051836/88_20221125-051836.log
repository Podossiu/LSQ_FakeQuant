2022-11-25 05:18:36,187 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88_20221125-051836.log
2022-11-25 05:18:41,016 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-25 05:18:41,142 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-25 05:18:42,089 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.0005
               maximize: False
               weight_decay: 0.0005
           )
2022-11-25 05:18:42,090 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.0005

2022-11-25 05:18:43,877 - INFO  - >>>>>> Epoch   0
2022-11-25 05:18:43,879 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:18:49,810 - INFO  - Training [0][   20/  196]   Loss 1.290304   Top1 57.480469   Top5 93.242188   BatchTime 0.296435   LR 0.000500   
2022-11-25 05:18:54,797 - INFO  - Training [0][   40/  196]   Loss 1.237710   Top1 58.554688   Top5 94.101562   BatchTime 0.272888   LR 0.000500   
2022-11-25 05:18:59,874 - INFO  - Training [0][   60/  196]   Loss 1.164539   Top1 60.950521   Top5 94.817708   BatchTime 0.266547   LR 0.000499   
2022-11-25 05:19:05,129 - INFO  - Training [0][   80/  196]   Loss 1.111891   Top1 62.788086   Top5 95.200195   BatchTime 0.265594   LR 0.000498   
2022-11-25 05:19:10,621 - INFO  - Training [0][  100/  196]   Loss 1.072263   Top1 64.167969   Top5 95.566406   BatchTime 0.267399   LR 0.000497   
2022-11-25 05:19:16,547 - INFO  - Training [0][  120/  196]   Loss 1.047326   Top1 65.068359   Top5 95.768229   BatchTime 0.272214   LR 0.000495   
2022-11-25 05:19:22,434 - INFO  - Training [0][  140/  196]   Loss 1.025066   Top1 65.828683   Top5 95.934710   BatchTime 0.275378   LR 0.000494   
2022-11-25 05:19:29,263 - INFO  - Training [0][  160/  196]   Loss 0.999382   Top1 66.647949   Top5 96.147461   BatchTime 0.283633   LR 0.000492   
2022-11-25 05:19:36,327 - INFO  - Training [0][  180/  196]   Loss 0.977951   Top1 67.345920   Top5 96.347656   BatchTime 0.291362   LR 0.000490   
2022-11-25 05:19:41,894 - INFO  - ==> Top1: 67.792    Top5: 96.486    Loss: 0.964

2022-11-25 05:19:42,061 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:19:43,085 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:19:45,112 - INFO  - Validation [0][   20/   40]   Loss 0.827062   Top1 72.382812   Top5 97.558594   BatchTime 0.101313   
2022-11-25 05:19:46,190 - INFO  - Validation [0][   40/   40]   Loss 0.820364   Top1 72.380000   Top5 97.710000   BatchTime 0.077610   
2022-11-25 05:19:46,371 - INFO  - ==> Top1: 72.380    Top5: 97.710    Loss: 0.820

2022-11-25 05:19:46,371 - INFO  - ==> Sparsity : 0.267

2022-11-25 05:19:46,372 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 72.380   Top5: 97.710]
2022-11-25 05:19:51,278 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:19:51,280 - INFO  - >>>>>> Epoch   1
2022-11-25 05:19:51,282 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:19:57,208 - INFO  - Training [1][   20/  196]   Loss 0.771163   Top1 73.750000   Top5 98.281250   BatchTime 0.296156   LR 0.000485   
2022-11-25 05:20:03,274 - INFO  - Training [1][   40/  196]   Loss 0.760686   Top1 74.433594   Top5 98.203125   BatchTime 0.299726   LR 0.000482   
2022-11-25 05:20:09,324 - INFO  - Training [1][   60/  196]   Loss 0.751333   Top1 74.804688   Top5 98.216146   BatchTime 0.300650   LR 0.000479   
2022-11-25 05:20:15,214 - INFO  - Training [1][   80/  196]   Loss 0.740936   Top1 75.053711   Top5 98.354492   BatchTime 0.299106   LR 0.000476   
2022-11-25 05:20:21,719 - INFO  - Training [1][  100/  196]   Loss 0.729468   Top1 75.441406   Top5 98.351562   BatchTime 0.304340   LR 0.000473   
2022-11-25 05:20:28,066 - INFO  - Training [1][  120/  196]   Loss 0.723520   Top1 75.553385   Top5 98.375651   BatchTime 0.306505   LR 0.000469   
2022-11-25 05:20:33,851 - INFO  - Training [1][  140/  196]   Loss 0.718275   Top1 75.731027   Top5 98.381696   BatchTime 0.304039   LR 0.000465   
2022-11-25 05:20:40,354 - INFO  - Training [1][  160/  196]   Loss 0.711008   Top1 75.964355   Top5 98.400879   BatchTime 0.306679   LR 0.000460   
2022-11-25 05:20:47,098 - INFO  - Training [1][  180/  196]   Loss 0.708987   Top1 76.022135   Top5 98.407118   BatchTime 0.310071   LR 0.000456   
2022-11-25 05:20:52,530 - INFO  - ==> Top1: 76.120    Top5: 98.424    Loss: 0.705

2022-11-25 05:20:52,732 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:20:54,048 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:20:56,153 - INFO  - Validation [1][   20/   40]   Loss 0.768516   Top1 75.019531   Top5 97.851562   BatchTime 0.105180   
2022-11-25 05:20:57,063 - INFO  - Validation [1][   40/   40]   Loss 0.753583   Top1 74.640000   Top5 98.130000   BatchTime 0.075332   
2022-11-25 05:20:57,228 - INFO  - ==> Top1: 74.640    Top5: 98.130    Loss: 0.754

2022-11-25 05:20:57,228 - INFO  - ==> Sparsity : 0.296

2022-11-25 05:20:57,229 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 74.640   Top5: 98.130]
2022-11-25 05:20:57,229 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 72.380   Top5: 97.710]
2022-11-25 05:21:02,585 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:21:02,588 - INFO  - >>>>>> Epoch   2
2022-11-25 05:21:02,590 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:21:10,155 - INFO  - Training [2][   20/  196]   Loss 0.629220   Top1 78.652344   Top5 98.847656   BatchTime 0.378079   LR 0.000448   
2022-11-25 05:21:16,792 - INFO  - Training [2][   40/  196]   Loss 0.636963   Top1 78.720703   Top5 98.583984   BatchTime 0.354982   LR 0.000443   
2022-11-25 05:21:23,376 - INFO  - Training [2][   60/  196]   Loss 0.624834   Top1 78.958333   Top5 98.769531   BatchTime 0.346382   LR 0.000437   
2022-11-25 05:21:29,776 - INFO  - Training [2][   80/  196]   Loss 0.623406   Top1 79.091797   Top5 98.764648   BatchTime 0.339778   LR 0.000432   
2022-11-25 05:21:36,672 - INFO  - Training [2][  100/  196]   Loss 0.622691   Top1 79.078125   Top5 98.769531   BatchTime 0.340787   LR 0.000426   
2022-11-25 05:21:42,607 - INFO  - Training [2][  120/  196]   Loss 0.620212   Top1 79.166667   Top5 98.805339   BatchTime 0.333446   LR 0.000421   
2022-11-25 05:21:48,230 - INFO  - Training [2][  140/  196]   Loss 0.619980   Top1 79.126674   Top5 98.816964   BatchTime 0.325975   LR 0.000415   
2022-11-25 05:21:54,071 - INFO  - Training [2][  160/  196]   Loss 0.617265   Top1 79.228516   Top5 98.808594   BatchTime 0.321731   LR 0.000409   
2022-11-25 05:21:59,849 - INFO  - Training [2][  180/  196]   Loss 0.610838   Top1 79.405382   Top5 98.823785   BatchTime 0.318087   LR 0.000402   
2022-11-25 05:22:04,579 - INFO  - ==> Top1: 79.500    Top5: 98.830    Loss: 0.607

2022-11-25 05:22:04,792 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:22:06,179 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:22:08,329 - INFO  - Validation [2][   20/   40]   Loss 0.661916   Top1 77.578125   Top5 98.789062   BatchTime 0.107391   
2022-11-25 05:22:09,359 - INFO  - Validation [2][   40/   40]   Loss 0.662213   Top1 77.490000   Top5 98.750000   BatchTime 0.079458   
2022-11-25 05:22:09,543 - INFO  - ==> Top1: 77.490    Top5: 98.750    Loss: 0.662

2022-11-25 05:22:09,544 - INFO  - ==> Sparsity : 0.328

2022-11-25 05:22:09,544 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 77.490   Top5: 98.750]
2022-11-25 05:22:09,544 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 74.640   Top5: 98.130]
2022-11-25 05:22:09,544 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 72.380   Top5: 97.710]
2022-11-25 05:22:14,010 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:22:14,012 - INFO  - >>>>>> Epoch   3
2022-11-25 05:22:14,014 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:22:21,360 - INFO  - Training [3][   20/  196]   Loss 0.540364   Top1 81.796875   Top5 99.023438   BatchTime 0.367166   LR 0.000391   
2022-11-25 05:22:27,882 - INFO  - Training [3][   40/  196]   Loss 0.543351   Top1 81.542969   Top5 99.091797   BatchTime 0.346626   LR 0.000384   
2022-11-25 05:22:34,192 - INFO  - Training [3][   60/  196]   Loss 0.540198   Top1 81.653646   Top5 99.127604   BatchTime 0.336250   LR 0.000377   
2022-11-25 05:22:40,399 - INFO  - Training [3][   80/  196]   Loss 0.539271   Top1 81.503906   Top5 99.179688   BatchTime 0.329774   LR 0.000370   
2022-11-25 05:22:46,730 - INFO  - Training [3][  100/  196]   Loss 0.537962   Top1 81.558594   Top5 99.152344   BatchTime 0.327132   LR 0.000363   
2022-11-25 05:22:53,357 - INFO  - Training [3][  120/  196]   Loss 0.532897   Top1 81.800130   Top5 99.169922   BatchTime 0.327834   LR 0.000356   
2022-11-25 05:22:59,158 - INFO  - Training [3][  140/  196]   Loss 0.536602   Top1 81.819196   Top5 99.146205   BatchTime 0.322432   LR 0.000348   
2022-11-25 05:23:05,254 - INFO  - Training [3][  160/  196]   Loss 0.535565   Top1 81.892090   Top5 99.155273   BatchTime 0.320229   LR 0.000341   
2022-11-25 05:23:11,720 - INFO  - Training [3][  180/  196]   Loss 0.531748   Top1 82.011719   Top5 99.184028   BatchTime 0.320569   LR 0.000333   
2022-11-25 05:23:17,019 - INFO  - ==> Top1: 82.032    Top5: 99.176    Loss: 0.531

2022-11-25 05:23:17,187 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:23:18,225 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:23:20,340 - INFO  - Validation [3][   20/   40]   Loss 0.569279   Top1 81.015625   Top5 98.730469   BatchTime 0.105656   
2022-11-25 05:23:21,354 - INFO  - Validation [3][   40/   40]   Loss 0.561701   Top1 81.120000   Top5 98.960000   BatchTime 0.078201   
2022-11-25 05:23:21,514 - INFO  - ==> Top1: 81.120    Top5: 98.960    Loss: 0.562

2022-11-25 05:23:21,514 - INFO  - ==> Sparsity : 0.336

2022-11-25 05:23:21,514 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 81.120   Top5: 98.960]
2022-11-25 05:23:21,515 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 77.490   Top5: 98.750]
2022-11-25 05:23:21,515 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 74.640   Top5: 98.130]
2022-11-25 05:23:26,404 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:23:26,406 - INFO  - >>>>>> Epoch   4
2022-11-25 05:23:26,408 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:23:33,938 - INFO  - Training [4][   20/  196]   Loss 0.503022   Top1 83.691406   Top5 99.179688   BatchTime 0.376341   LR 0.000320   
2022-11-25 05:23:40,882 - INFO  - Training [4][   40/  196]   Loss 0.499016   Top1 83.417969   Top5 99.228516   BatchTime 0.361777   LR 0.000312   
2022-11-25 05:23:47,527 - INFO  - Training [4][   60/  196]   Loss 0.495116   Top1 83.404948   Top5 99.244792   BatchTime 0.351934   LR 0.000304   
2022-11-25 05:23:54,219 - INFO  - Training [4][   80/  196]   Loss 0.491364   Top1 83.374023   Top5 99.267578   BatchTime 0.347601   LR 0.000296   
2022-11-25 05:24:00,624 - INFO  - Training [4][  100/  196]   Loss 0.487710   Top1 83.476562   Top5 99.257812   BatchTime 0.342129   LR 0.000289   
2022-11-25 05:24:07,180 - INFO  - Training [4][  120/  196]   Loss 0.482870   Top1 83.681641   Top5 99.267578   BatchTime 0.339741   LR 0.000281   
2022-11-25 05:24:13,937 - INFO  - Training [4][  140/  196]   Loss 0.481045   Top1 83.747210   Top5 99.274554   BatchTime 0.339471   LR 0.000273   
2022-11-25 05:24:19,872 - INFO  - Training [4][  160/  196]   Loss 0.475508   Top1 83.886719   Top5 99.318848   BatchTime 0.334128   LR 0.000265   
2022-11-25 05:24:25,032 - INFO  - Training [4][  180/  196]   Loss 0.474113   Top1 83.973524   Top5 99.327257   BatchTime 0.325672   LR 0.000257   
2022-11-25 05:24:29,094 - INFO  - ==> Top1: 83.984    Top5: 99.332    Loss: 0.474

2022-11-25 05:24:29,288 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:24:30,660 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:24:32,941 - INFO  - Validation [4][   20/   40]   Loss 0.511308   Top1 82.871094   Top5 99.238281   BatchTime 0.113980   
2022-11-25 05:24:34,066 - INFO  - Validation [4][   40/   40]   Loss 0.503951   Top1 82.880000   Top5 99.360000   BatchTime 0.085109   
2022-11-25 05:24:34,254 - INFO  - ==> Top1: 82.880    Top5: 99.360    Loss: 0.504

2022-11-25 05:24:34,254 - INFO  - ==> Sparsity : 0.413

2022-11-25 05:24:34,254 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 82.880   Top5: 99.360]
2022-11-25 05:24:34,255 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 81.120   Top5: 98.960]
2022-11-25 05:24:34,255 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 77.490   Top5: 98.750]
2022-11-25 05:24:39,470 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:24:39,472 - INFO  - >>>>>> Epoch   5
2022-11-25 05:24:39,474 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:24:47,052 - INFO  - Training [5][   20/  196]   Loss 0.428443   Top1 85.664062   Top5 99.609375   BatchTime 0.378767   LR 0.000242   
2022-11-25 05:24:53,471 - INFO  - Training [5][   40/  196]   Loss 0.424728   Top1 85.664062   Top5 99.560547   BatchTime 0.349868   LR 0.000234   
2022-11-25 05:25:00,065 - INFO  - Training [5][   60/  196]   Loss 0.428860   Top1 85.423177   Top5 99.537760   BatchTime 0.343144   LR 0.000226   
2022-11-25 05:25:05,585 - INFO  - Training [5][   80/  196]   Loss 0.427823   Top1 85.541992   Top5 99.458008   BatchTime 0.326349   LR 0.000218   
2022-11-25 05:25:10,544 - INFO  - Training [5][  100/  196]   Loss 0.432940   Top1 85.417969   Top5 99.445312   BatchTime 0.310672   LR 0.000210   
2022-11-25 05:25:15,565 - INFO  - Training [5][  120/  196]   Loss 0.432933   Top1 85.367839   Top5 99.472656   BatchTime 0.300732   LR 0.000202   
2022-11-25 05:25:21,293 - INFO  - Training [5][  140/  196]   Loss 0.431139   Top1 85.376674   Top5 99.444754   BatchTime 0.298682   LR 0.000195   
2022-11-25 05:25:28,064 - INFO  - Training [5][  160/  196]   Loss 0.428591   Top1 85.493164   Top5 99.453125   BatchTime 0.303668   LR 0.000187   
2022-11-25 05:25:34,370 - INFO  - Training [5][  180/  196]   Loss 0.427281   Top1 85.466580   Top5 99.472656   BatchTime 0.304960   LR 0.000179   
2022-11-25 05:25:39,491 - INFO  - ==> Top1: 85.554    Top5: 99.476    Loss: 0.425

2022-11-25 05:25:39,678 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:25:40,776 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:25:43,046 - INFO  - Validation [5][   20/   40]   Loss 0.470346   Top1 84.101562   Top5 99.433594   BatchTime 0.113428   
2022-11-25 05:25:44,115 - INFO  - Validation [5][   40/   40]   Loss 0.459344   Top1 84.570000   Top5 99.450000   BatchTime 0.083438   
2022-11-25 05:25:44,304 - INFO  - ==> Top1: 84.570    Top5: 99.450    Loss: 0.459

2022-11-25 05:25:44,304 - INFO  - ==> Sparsity : 0.392

2022-11-25 05:25:44,304 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 84.570   Top5: 99.450]
2022-11-25 05:25:44,305 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 82.880   Top5: 99.360]
2022-11-25 05:25:44,305 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 81.120   Top5: 98.960]
2022-11-25 05:25:49,060 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:25:49,062 - INFO  - >>>>>> Epoch   6
2022-11-25 05:25:49,064 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:25:56,094 - INFO  - Training [6][   20/  196]   Loss 0.380571   Top1 87.324219   Top5 99.609375   BatchTime 0.351391   LR 0.000166   
2022-11-25 05:26:02,279 - INFO  - Training [6][   40/  196]   Loss 0.380244   Top1 87.158203   Top5 99.638672   BatchTime 0.330329   LR 0.000158   
2022-11-25 05:26:07,497 - INFO  - Training [6][   60/  196]   Loss 0.382261   Top1 87.011719   Top5 99.576823   BatchTime 0.307179   LR 0.000151   
2022-11-25 05:26:12,554 - INFO  - Training [6][   80/  196]   Loss 0.382395   Top1 87.001953   Top5 99.555664   BatchTime 0.293594   LR 0.000143   
2022-11-25 05:26:18,478 - INFO  - Training [6][  100/  196]   Loss 0.382050   Top1 87.003906   Top5 99.535156   BatchTime 0.294122   LR 0.000136   
2022-11-25 05:26:25,065 - INFO  - Training [6][  120/  196]   Loss 0.380924   Top1 87.018229   Top5 99.557292   BatchTime 0.299992   LR 0.000129   
2022-11-25 05:26:31,556 - INFO  - Training [6][  140/  196]   Loss 0.380102   Top1 87.025670   Top5 99.570312   BatchTime 0.303499   LR 0.000122   
2022-11-25 05:26:37,949 - INFO  - Training [6][  160/  196]   Loss 0.377444   Top1 87.155762   Top5 99.570312   BatchTime 0.305519   LR 0.000115   
2022-11-25 05:26:44,586 - INFO  - Training [6][  180/  196]   Loss 0.377378   Top1 87.172309   Top5 99.583333   BatchTime 0.308439   LR 0.000108   
2022-11-25 05:26:50,058 - INFO  - ==> Top1: 87.318    Top5: 99.582    Loss: 0.375

2022-11-25 05:26:50,268 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:26:51,579 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:26:53,846 - INFO  - Validation [6][   20/   40]   Loss 0.434124   Top1 85.761719   Top5 99.257812   BatchTime 0.113260   
2022-11-25 05:26:54,960 - INFO  - Validation [6][   40/   40]   Loss 0.433225   Top1 85.430000   Top5 99.370000   BatchTime 0.084487   
2022-11-25 05:26:55,167 - INFO  - ==> Top1: 85.430    Top5: 99.370    Loss: 0.433

2022-11-25 05:26:55,167 - INFO  - ==> Sparsity : 0.398

2022-11-25 05:26:55,168 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 85.430   Top5: 99.370]
2022-11-25 05:26:55,168 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 84.570   Top5: 99.450]
2022-11-25 05:26:55,168 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 82.880   Top5: 99.360]
2022-11-25 05:27:00,644 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:27:00,646 - INFO  - >>>>>> Epoch   7
2022-11-25 05:27:00,648 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:27:08,225 - INFO  - Training [7][   20/  196]   Loss 0.363530   Top1 87.363281   Top5 99.628906   BatchTime 0.378724   LR 0.000097   
2022-11-25 05:27:14,924 - INFO  - Training [7][   40/  196]   Loss 0.351811   Top1 87.763672   Top5 99.619141   BatchTime 0.356841   LR 0.000091   
2022-11-25 05:27:21,235 - INFO  - Training [7][   60/  196]   Loss 0.346437   Top1 88.007812   Top5 99.628906   BatchTime 0.343085   LR 0.000085   
2022-11-25 05:27:27,723 - INFO  - Training [7][   80/  196]   Loss 0.343735   Top1 88.325195   Top5 99.633789   BatchTime 0.338407   LR 0.000079   
2022-11-25 05:27:33,627 - INFO  - Training [7][  100/  196]   Loss 0.339744   Top1 88.390625   Top5 99.648438   BatchTime 0.329766   LR 0.000073   
2022-11-25 05:27:40,391 - INFO  - Training [7][  120/  196]   Loss 0.338867   Top1 88.457031   Top5 99.641927   BatchTime 0.331171   LR 0.000067   
2022-11-25 05:27:47,230 - INFO  - Training [7][  140/  196]   Loss 0.338086   Top1 88.440290   Top5 99.631696   BatchTime 0.332709   LR 0.000062   
2022-11-25 05:27:53,330 - INFO  - Training [7][  160/  196]   Loss 0.337231   Top1 88.540039   Top5 99.645996   BatchTime 0.329244   LR 0.000057   
2022-11-25 05:27:59,633 - INFO  - Training [7][  180/  196]   Loss 0.336680   Top1 88.587240   Top5 99.650608   BatchTime 0.327677   LR 0.000052   
2022-11-25 05:28:05,026 - INFO  - ==> Top1: 88.620    Top5: 99.660    Loss: 0.335

2022-11-25 05:28:05,209 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:28:06,428 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:28:09,037 - INFO  - Validation [7][   20/   40]   Loss 0.393673   Top1 86.464844   Top5 99.433594   BatchTime 0.130325   
2022-11-25 05:28:10,086 - INFO  - Validation [7][   40/   40]   Loss 0.388468   Top1 86.830000   Top5 99.520000   BatchTime 0.091392   
2022-11-25 05:28:10,296 - INFO  - ==> Top1: 86.830    Top5: 99.520    Loss: 0.388

2022-11-25 05:28:10,296 - INFO  - ==> Sparsity : 0.407

2022-11-25 05:28:10,297 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:28:10,297 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 85.430   Top5: 99.370]
2022-11-25 05:28:10,297 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 84.570   Top5: 99.450]
2022-11-25 05:28:15,400 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:28:15,402 - INFO  - >>>>>> Epoch   8
2022-11-25 05:28:15,405 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:28:21,719 - INFO  - Training [8][   20/  196]   Loss 0.302736   Top1 89.746094   Top5 99.726562   BatchTime 0.315609   LR 0.000043   
2022-11-25 05:28:28,423 - INFO  - Training [8][   40/  196]   Loss 0.305890   Top1 89.677734   Top5 99.736328   BatchTime 0.325401   LR 0.000039   
2022-11-25 05:28:34,904 - INFO  - Training [8][   60/  196]   Loss 0.308100   Top1 89.511719   Top5 99.752604   BatchTime 0.324944   LR 0.000035   
2022-11-25 05:28:41,578 - INFO  - Training [8][   80/  196]   Loss 0.311748   Top1 89.433594   Top5 99.741211   BatchTime 0.327137   LR 0.000031   
2022-11-25 05:28:47,038 - INFO  - Training [8][  100/  196]   Loss 0.312042   Top1 89.484375   Top5 99.757812   BatchTime 0.316303   LR 0.000027   
2022-11-25 05:28:52,683 - INFO  - Training [8][  120/  196]   Loss 0.308613   Top1 89.645182   Top5 99.749349   BatchTime 0.310631   LR 0.000023   
2022-11-25 05:28:58,553 - INFO  - Training [8][  140/  196]   Loss 0.309749   Top1 89.620536   Top5 99.737723   BatchTime 0.308185   LR 0.000020   
2022-11-25 05:29:03,562 - INFO  - Training [8][  160/  196]   Loss 0.310262   Top1 89.609375   Top5 99.724121   BatchTime 0.300968   LR 0.000017   
2022-11-25 05:29:08,789 - INFO  - Training [8][  180/  196]   Loss 0.310173   Top1 89.583333   Top5 99.717882   BatchTime 0.296565   LR 0.000014   
2022-11-25 05:29:12,874 - INFO  - ==> Top1: 89.572    Top5: 99.712    Loss: 0.310

2022-11-25 05:29:13,162 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:29:14,264 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:29:16,517 - INFO  - Validation [8][   20/   40]   Loss 0.388256   Top1 86.816406   Top5 99.394531   BatchTime 0.112533   
2022-11-25 05:29:17,647 - INFO  - Validation [8][   40/   40]   Loss 0.382897   Top1 87.090000   Top5 99.500000   BatchTime 0.084538   
2022-11-25 05:29:17,850 - INFO  - ==> Top1: 87.090    Top5: 99.500    Loss: 0.383

2022-11-25 05:29:17,851 - INFO  - ==> Sparsity : 0.431

2022-11-25 05:29:17,851 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:29:17,851 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:29:17,852 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 85.430   Top5: 99.370]
2022-11-25 05:29:22,873 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:29:22,875 - INFO  - >>>>>> Epoch   9
2022-11-25 05:29:22,877 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:29:29,912 - INFO  - Training [9][   20/  196]   Loss 0.290384   Top1 90.136719   Top5 99.746094   BatchTime 0.351646   LR 0.000010   
2022-11-25 05:29:36,627 - INFO  - Training [9][   40/  196]   Loss 0.296397   Top1 90.322266   Top5 99.726562   BatchTime 0.343687   LR 0.000008   
2022-11-25 05:29:42,996 - INFO  - Training [9][   60/  196]   Loss 0.295308   Top1 90.286458   Top5 99.733073   BatchTime 0.335280   LR 0.000006   
2022-11-25 05:29:49,185 - INFO  - Training [9][   80/  196]   Loss 0.293508   Top1 90.307617   Top5 99.736328   BatchTime 0.328823   LR 0.000004   
2022-11-25 05:29:55,242 - INFO  - Training [9][  100/  196]   Loss 0.294788   Top1 90.214844   Top5 99.753906   BatchTime 0.323627   LR 0.000003   
2022-11-25 05:30:01,421 - INFO  - Training [9][  120/  196]   Loss 0.295566   Top1 90.175781   Top5 99.749349   BatchTime 0.321174   LR 0.000002   
2022-11-25 05:30:07,601 - INFO  - Training [9][  140/  196]   Loss 0.295839   Top1 90.136719   Top5 99.768415   BatchTime 0.319438   LR 0.000001   
2022-11-25 05:30:13,501 - INFO  - Training [9][  160/  196]   Loss 0.295801   Top1 90.144043   Top5 99.772949   BatchTime 0.316385   LR 0.000000   
2022-11-25 05:30:19,752 - INFO  - Training [9][  180/  196]   Loss 0.294786   Top1 90.149740   Top5 99.782986   BatchTime 0.315956   LR 0.000000   
2022-11-25 05:30:25,171 - INFO  - ==> Top1: 90.132    Top5: 99.780    Loss: 0.295

2022-11-25 05:30:25,383 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:30:26,693 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:30:28,937 - INFO  - Validation [9][   20/   40]   Loss 0.387453   Top1 86.875000   Top5 99.375000   BatchTime 0.112134   
2022-11-25 05:30:29,993 - INFO  - Validation [9][   40/   40]   Loss 0.381298   Top1 87.220000   Top5 99.510000   BatchTime 0.082464   
2022-11-25 05:30:30,222 - INFO  - ==> Top1: 87.220    Top5: 99.510    Loss: 0.381

2022-11-25 05:30:30,222 - INFO  - ==> Sparsity : 0.435

2022-11-25 05:30:30,222 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:30:30,222 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:30:30,223 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:30:35,449 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:30:35,451 - INFO  - >>>>>> Epoch  10
2022-11-25 05:30:35,453 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:30:42,117 - INFO  - Training [10][   20/  196]   Loss 0.352573   Top1 88.007812   Top5 99.746094   BatchTime 0.333070   LR 0.000250   
2022-11-25 05:30:47,297 - INFO  - Training [10][   40/  196]   Loss 0.366870   Top1 87.470703   Top5 99.638672   BatchTime 0.296041   LR 0.000250   
2022-11-25 05:30:52,569 - INFO  - Training [10][   60/  196]   Loss 0.377007   Top1 87.122396   Top5 99.576823   BatchTime 0.285227   LR 0.000250   
2022-11-25 05:30:57,933 - INFO  - Training [10][   80/  196]   Loss 0.381823   Top1 86.997070   Top5 99.570312   BatchTime 0.280967   LR 0.000250   
2022-11-25 05:31:03,726 - INFO  - Training [10][  100/  196]   Loss 0.389770   Top1 86.765625   Top5 99.562500   BatchTime 0.282704   LR 0.000250   
2022-11-25 05:31:09,175 - INFO  - Training [10][  120/  196]   Loss 0.391064   Top1 86.708984   Top5 99.557292   BatchTime 0.280995   LR 0.000249   
2022-11-25 05:31:15,430 - INFO  - Training [10][  140/  196]   Loss 0.390928   Top1 86.777344   Top5 99.550781   BatchTime 0.285530   LR 0.000249   
2022-11-25 05:31:21,734 - INFO  - Training [10][  160/  196]   Loss 0.392332   Top1 86.696777   Top5 99.565430   BatchTime 0.289240   LR 0.000249   
2022-11-25 05:31:27,623 - INFO  - Training [10][  180/  196]   Loss 0.392175   Top1 86.701389   Top5 99.576823   BatchTime 0.289814   LR 0.000249   
2022-11-25 05:31:31,886 - INFO  - ==> Top1: 86.672    Top5: 99.572    Loss: 0.394

2022-11-25 05:31:32,092 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:31:33,145 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:31:35,474 - INFO  - Validation [10][   20/   40]   Loss 0.488809   Top1 83.105469   Top5 99.199219   BatchTime 0.116383   
2022-11-25 05:31:36,519 - INFO  - Validation [10][   40/   40]   Loss 0.494158   Top1 83.360000   Top5 99.260000   BatchTime 0.084304   
2022-11-25 05:31:36,690 - INFO  - ==> Top1: 83.360    Top5: 99.260    Loss: 0.494

2022-11-25 05:31:36,690 - INFO  - ==> Sparsity : 0.427

2022-11-25 05:31:36,690 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:31:36,691 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:31:36,691 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:31:36,850 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:31:36,852 - INFO  - >>>>>> Epoch  11
2022-11-25 05:31:36,853 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:31:44,849 - INFO  - Training [11][   20/  196]   Loss 0.376111   Top1 86.855469   Top5 99.472656   BatchTime 0.399645   LR 0.000248   
2022-11-25 05:31:51,096 - INFO  - Training [11][   40/  196]   Loss 0.390929   Top1 86.396484   Top5 99.570312   BatchTime 0.355987   LR 0.000248   
2022-11-25 05:31:57,139 - INFO  - Training [11][   60/  196]   Loss 0.387527   Top1 86.529948   Top5 99.550781   BatchTime 0.338045   LR 0.000247   
2022-11-25 05:32:03,908 - INFO  - Training [11][   80/  196]   Loss 0.385654   Top1 86.694336   Top5 99.570312   BatchTime 0.338143   LR 0.000247   
2022-11-25 05:32:09,069 - INFO  - Training [11][  100/  196]   Loss 0.386841   Top1 86.699219   Top5 99.562500   BatchTime 0.322120   LR 0.000247   
2022-11-25 05:32:14,764 - INFO  - Training [11][  120/  196]   Loss 0.390636   Top1 86.614583   Top5 99.563802   BatchTime 0.315891   LR 0.000246   
2022-11-25 05:32:20,544 - INFO  - Training [11][  140/  196]   Loss 0.391750   Top1 86.618304   Top5 99.559152   BatchTime 0.312054   LR 0.000246   
2022-11-25 05:32:25,781 - INFO  - Training [11][  160/  196]   Loss 0.392011   Top1 86.589355   Top5 99.558105   BatchTime 0.305776   LR 0.000245   
2022-11-25 05:32:30,804 - INFO  - Training [11][  180/  196]   Loss 0.392920   Top1 86.592882   Top5 99.563802   BatchTime 0.299706   LR 0.000244   
2022-11-25 05:32:34,790 - INFO  - ==> Top1: 86.586    Top5: 99.560    Loss: 0.394

2022-11-25 05:32:35,075 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:32:36,237 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:32:38,430 - INFO  - Validation [11][   20/   40]   Loss 0.502621   Top1 83.222656   Top5 99.082031   BatchTime 0.109605   
2022-11-25 05:32:39,511 - INFO  - Validation [11][   40/   40]   Loss 0.500533   Top1 83.240000   Top5 99.250000   BatchTime 0.081827   
2022-11-25 05:32:39,700 - INFO  - ==> Top1: 83.240    Top5: 99.250    Loss: 0.501

2022-11-25 05:32:39,700 - INFO  - ==> Sparsity : 0.420

2022-11-25 05:32:39,700 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:32:39,701 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:32:39,701 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:32:39,832 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:32:39,834 - INFO  - >>>>>> Epoch  12
2022-11-25 05:32:39,835 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:32:46,667 - INFO  - Training [12][   20/  196]   Loss 0.382927   Top1 86.972656   Top5 99.472656   BatchTime 0.341446   LR 0.000243   
2022-11-25 05:32:52,437 - INFO  - Training [12][   40/  196]   Loss 0.372962   Top1 87.314453   Top5 99.531250   BatchTime 0.314975   LR 0.000243   
2022-11-25 05:32:59,168 - INFO  - Training [12][   60/  196]   Loss 0.382527   Top1 86.992188   Top5 99.505208   BatchTime 0.322161   LR 0.000242   
2022-11-25 05:33:05,797 - INFO  - Training [12][   80/  196]   Loss 0.377567   Top1 87.207031   Top5 99.506836   BatchTime 0.324490   LR 0.000241   
2022-11-25 05:33:11,744 - INFO  - Training [12][  100/  196]   Loss 0.375276   Top1 87.210938   Top5 99.542969   BatchTime 0.319060   LR 0.000240   
2022-11-25 05:33:18,252 - INFO  - Training [12][  120/  196]   Loss 0.374677   Top1 87.278646   Top5 99.544271   BatchTime 0.320109   LR 0.000240   
2022-11-25 05:33:24,692 - INFO  - Training [12][  140/  196]   Loss 0.376357   Top1 87.226562   Top5 99.547991   BatchTime 0.320385   LR 0.000239   
2022-11-25 05:33:31,719 - INFO  - Training [12][  160/  196]   Loss 0.375043   Top1 87.329102   Top5 99.572754   BatchTime 0.324255   LR 0.000238   
2022-11-25 05:33:38,345 - INFO  - Training [12][  180/  196]   Loss 0.373417   Top1 87.439236   Top5 99.583333   BatchTime 0.325035   LR 0.000237   
2022-11-25 05:33:43,270 - INFO  - ==> Top1: 87.392    Top5: 99.584    Loss: 0.373

2022-11-25 05:33:43,477 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:33:45,055 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:33:47,803 - INFO  - Validation [12][   20/   40]   Loss 0.473083   Top1 84.140625   Top5 99.296875   BatchTime 0.137250   
2022-11-25 05:33:48,968 - INFO  - Validation [12][   40/   40]   Loss 0.466446   Top1 84.200000   Top5 99.280000   BatchTime 0.097754   
2022-11-25 05:33:49,152 - INFO  - ==> Top1: 84.200    Top5: 99.280    Loss: 0.466

2022-11-25 05:33:49,153 - INFO  - ==> Sparsity : 0.424

2022-11-25 05:33:49,153 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:33:49,153 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:33:49,153 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:33:49,267 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:33:49,269 - INFO  - >>>>>> Epoch  13
2022-11-25 05:33:49,271 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:33:56,310 - INFO  - Training [13][   20/  196]   Loss 0.351432   Top1 88.300781   Top5 99.570312   BatchTime 0.351820   LR 0.000235   
2022-11-25 05:34:02,668 - INFO  - Training [13][   40/  196]   Loss 0.344481   Top1 88.437500   Top5 99.599609   BatchTime 0.334867   LR 0.000235   
2022-11-25 05:34:09,231 - INFO  - Training [13][   60/  196]   Loss 0.349846   Top1 88.365885   Top5 99.589844   BatchTime 0.332628   LR 0.000234   
2022-11-25 05:34:14,894 - INFO  - Training [13][   80/  196]   Loss 0.351045   Top1 88.222656   Top5 99.580078   BatchTime 0.320254   LR 0.000233   
2022-11-25 05:34:20,771 - INFO  - Training [13][  100/  196]   Loss 0.354542   Top1 88.058594   Top5 99.546875   BatchTime 0.314970   LR 0.000232   
2022-11-25 05:34:27,621 - INFO  - Training [13][  120/  196]   Loss 0.357875   Top1 87.867839   Top5 99.573568   BatchTime 0.319561   LR 0.000230   
2022-11-25 05:34:34,491 - INFO  - Training [13][  140/  196]   Loss 0.357567   Top1 87.823661   Top5 99.598214   BatchTime 0.322983   LR 0.000229   
2022-11-25 05:34:40,296 - INFO  - Training [13][  160/  196]   Loss 0.356071   Top1 87.885742   Top5 99.604492   BatchTime 0.318888   LR 0.000228   
2022-11-25 05:34:46,897 - INFO  - Training [13][  180/  196]   Loss 0.355343   Top1 87.890625   Top5 99.602865   BatchTime 0.320131   LR 0.000227   
2022-11-25 05:34:52,365 - INFO  - ==> Top1: 87.812    Top5: 99.596    Loss: 0.357

2022-11-25 05:34:52,572 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:34:53,694 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:34:55,956 - INFO  - Validation [13][   20/   40]   Loss 0.434088   Top1 85.371094   Top5 99.296875   BatchTime 0.113050   
2022-11-25 05:34:57,050 - INFO  - Validation [13][   40/   40]   Loss 0.429785   Top1 85.460000   Top5 99.390000   BatchTime 0.083879   
2022-11-25 05:34:57,270 - INFO  - ==> Top1: 85.460    Top5: 99.390    Loss: 0.430

2022-11-25 05:34:57,270 - INFO  - ==> Sparsity : 0.427

2022-11-25 05:34:57,270 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:34:57,271 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:34:57,271 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:34:57,408 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:34:57,409 - INFO  - >>>>>> Epoch  14
2022-11-25 05:34:57,411 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:35:04,968 - INFO  - Training [14][   20/  196]   Loss 0.340139   Top1 88.125000   Top5 99.785156   BatchTime 0.377728   LR 0.000225   
2022-11-25 05:35:11,510 - INFO  - Training [14][   40/  196]   Loss 0.338953   Top1 88.203125   Top5 99.726562   BatchTime 0.352411   LR 0.000224   
2022-11-25 05:35:18,228 - INFO  - Training [14][   60/  196]   Loss 0.336778   Top1 88.365885   Top5 99.700521   BatchTime 0.346911   LR 0.000223   
2022-11-25 05:35:24,537 - INFO  - Training [14][   80/  196]   Loss 0.335360   Top1 88.544922   Top5 99.692383   BatchTime 0.339039   LR 0.000221   
2022-11-25 05:35:30,171 - INFO  - Training [14][  100/  196]   Loss 0.339547   Top1 88.445312   Top5 99.656250   BatchTime 0.327575   LR 0.000220   
2022-11-25 05:35:35,831 - INFO  - Training [14][  120/  196]   Loss 0.341571   Top1 88.378906   Top5 99.661458   BatchTime 0.320146   LR 0.000219   
2022-11-25 05:35:41,285 - INFO  - Training [14][  140/  196]   Loss 0.344957   Top1 88.278460   Top5 99.659598   BatchTime 0.313363   LR 0.000217   
2022-11-25 05:35:47,033 - INFO  - Training [14][  160/  196]   Loss 0.343670   Top1 88.298340   Top5 99.670410   BatchTime 0.310117   LR 0.000216   
2022-11-25 05:35:53,038 - INFO  - Training [14][  180/  196]   Loss 0.343004   Top1 88.320312   Top5 99.676649   BatchTime 0.309019   LR 0.000215   
2022-11-25 05:35:57,828 - INFO  - ==> Top1: 88.334    Top5: 99.664    Loss: 0.343

2022-11-25 05:35:58,074 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:35:59,239 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:36:01,499 - INFO  - Validation [14][   20/   40]   Loss 0.419004   Top1 85.898438   Top5 99.238281   BatchTime 0.112923   
2022-11-25 05:36:02,547 - INFO  - Validation [14][   40/   40]   Loss 0.420385   Top1 85.780000   Top5 99.350000   BatchTime 0.082663   
2022-11-25 05:36:02,769 - INFO  - ==> Top1: 85.780    Top5: 99.350    Loss: 0.420

2022-11-25 05:36:02,770 - INFO  - ==> Sparsity : 0.448

2022-11-25 05:36:02,770 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:36:02,770 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:36:02,770 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:36:02,924 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:36:02,925 - INFO  - >>>>>> Epoch  15
2022-11-25 05:36:02,927 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:36:10,765 - INFO  - Training [15][   20/  196]   Loss 0.316513   Top1 89.335938   Top5 99.765625   BatchTime 0.391759   LR 0.000212   
2022-11-25 05:36:17,564 - INFO  - Training [15][   40/  196]   Loss 0.320259   Top1 89.091797   Top5 99.687500   BatchTime 0.365862   LR 0.000211   
2022-11-25 05:36:23,709 - INFO  - Training [15][   60/  196]   Loss 0.320036   Top1 89.160156   Top5 99.694010   BatchTime 0.346324   LR 0.000209   
2022-11-25 05:36:30,326 - INFO  - Training [15][   80/  196]   Loss 0.317860   Top1 89.282227   Top5 99.721680   BatchTime 0.342446   LR 0.000208   
2022-11-25 05:36:37,072 - INFO  - Training [15][  100/  196]   Loss 0.320887   Top1 89.234375   Top5 99.695312   BatchTime 0.341416   LR 0.000206   
2022-11-25 05:36:43,234 - INFO  - Training [15][  120/  196]   Loss 0.324220   Top1 89.134115   Top5 99.690755   BatchTime 0.335865   LR 0.000205   
2022-11-25 05:36:49,829 - INFO  - Training [15][  140/  196]   Loss 0.322229   Top1 89.154576   Top5 99.690290   BatchTime 0.334991   LR 0.000203   
2022-11-25 05:36:55,957 - INFO  - Training [15][  160/  196]   Loss 0.322861   Top1 89.099121   Top5 99.692383   BatchTime 0.331415   LR 0.000201   
2022-11-25 05:37:02,574 - INFO  - Training [15][  180/  196]   Loss 0.321418   Top1 89.142795   Top5 99.691840   BatchTime 0.331354   LR 0.000200   
2022-11-25 05:37:08,045 - INFO  - ==> Top1: 89.078    Top5: 99.678    Loss: 0.324

2022-11-25 05:37:08,256 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:37:09,549 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:37:11,936 - INFO  - Validation [15][   20/   40]   Loss 0.435706   Top1 85.742188   Top5 99.296875   BatchTime 0.119276   
2022-11-25 05:37:13,038 - INFO  - Validation [15][   40/   40]   Loss 0.423465   Top1 85.920000   Top5 99.410000   BatchTime 0.087195   
2022-11-25 05:37:13,236 - INFO  - ==> Top1: 85.920    Top5: 99.410    Loss: 0.423

2022-11-25 05:37:13,236 - INFO  - ==> Sparsity : 0.467

2022-11-25 05:37:13,236 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:37:13,236 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:37:13,236 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:37:13,530 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:37:13,532 - INFO  - >>>>>> Epoch  16
2022-11-25 05:37:13,534 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:37:21,130 - INFO  - Training [16][   20/  196]   Loss 0.304490   Top1 89.746094   Top5 99.707031   BatchTime 0.379682   LR 0.000197   
2022-11-25 05:37:27,789 - INFO  - Training [16][   40/  196]   Loss 0.312351   Top1 89.414062   Top5 99.667969   BatchTime 0.356333   LR 0.000195   
2022-11-25 05:37:34,198 - INFO  - Training [16][   60/  196]   Loss 0.301649   Top1 89.772135   Top5 99.726562   BatchTime 0.344364   LR 0.000194   
2022-11-25 05:37:40,313 - INFO  - Training [16][   80/  196]   Loss 0.303233   Top1 89.829102   Top5 99.711914   BatchTime 0.334703   LR 0.000192   
2022-11-25 05:37:45,715 - INFO  - Training [16][  100/  196]   Loss 0.302101   Top1 89.867188   Top5 99.742188   BatchTime 0.321783   LR 0.000190   
2022-11-25 05:37:51,927 - INFO  - Training [16][  120/  196]   Loss 0.303336   Top1 89.791667   Top5 99.742839   BatchTime 0.319920   LR 0.000188   
2022-11-25 05:37:58,405 - INFO  - Training [16][  140/  196]   Loss 0.303950   Top1 89.785156   Top5 99.743304   BatchTime 0.320489   LR 0.000187   
2022-11-25 05:38:04,908 - INFO  - Training [16][  160/  196]   Loss 0.305081   Top1 89.743652   Top5 99.738770   BatchTime 0.321063   LR 0.000185   
2022-11-25 05:38:11,270 - INFO  - Training [16][  180/  196]   Loss 0.304636   Top1 89.780816   Top5 99.733073   BatchTime 0.320743   LR 0.000183   
2022-11-25 05:38:16,032 - INFO  - ==> Top1: 89.730    Top5: 99.724    Loss: 0.306

2022-11-25 05:38:16,209 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:38:17,497 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:38:19,931 - INFO  - Validation [16][   20/   40]   Loss 0.462882   Top1 85.117188   Top5 99.375000   BatchTime 0.121619   
2022-11-25 05:38:20,971 - INFO  - Validation [16][   40/   40]   Loss 0.450932   Top1 85.370000   Top5 99.420000   BatchTime 0.086818   
2022-11-25 05:38:21,207 - INFO  - ==> Top1: 85.370    Top5: 99.420    Loss: 0.451

2022-11-25 05:38:21,207 - INFO  - ==> Sparsity : 0.492

2022-11-25 05:38:21,208 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:38:21,208 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:38:21,208 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:38:21,370 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:38:21,372 - INFO  - >>>>>> Epoch  17
2022-11-25 05:38:21,374 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:38:27,781 - INFO  - Training [17][   20/  196]   Loss 0.292772   Top1 90.351562   Top5 99.785156   BatchTime 0.320207   LR 0.000180   
2022-11-25 05:38:32,781 - INFO  - Training [17][   40/  196]   Loss 0.291420   Top1 90.253906   Top5 99.794922   BatchTime 0.285106   LR 0.000178   
2022-11-25 05:38:38,813 - INFO  - Training [17][   60/  196]   Loss 0.292691   Top1 90.182292   Top5 99.765625   BatchTime 0.290595   LR 0.000176   
2022-11-25 05:38:45,309 - INFO  - Training [17][   80/  196]   Loss 0.289324   Top1 90.351562   Top5 99.741211   BatchTime 0.299144   LR 0.000175   
2022-11-25 05:38:51,030 - INFO  - Training [17][  100/  196]   Loss 0.288128   Top1 90.414062   Top5 99.742188   BatchTime 0.296527   LR 0.000173   
2022-11-25 05:38:56,961 - INFO  - Training [17][  120/  196]   Loss 0.289828   Top1 90.266927   Top5 99.749349   BatchTime 0.296532   LR 0.000171   
2022-11-25 05:39:03,612 - INFO  - Training [17][  140/  196]   Loss 0.292158   Top1 90.178571   Top5 99.757254   BatchTime 0.301674   LR 0.000169   
2022-11-25 05:39:10,324 - INFO  - Training [17][  160/  196]   Loss 0.294336   Top1 90.117188   Top5 99.736328   BatchTime 0.305913   LR 0.000167   
2022-11-25 05:39:16,179 - INFO  - Training [17][  180/  196]   Loss 0.294811   Top1 90.108507   Top5 99.737413   BatchTime 0.304453   LR 0.000165   
2022-11-25 05:39:20,380 - INFO  - ==> Top1: 90.152    Top5: 99.734    Loss: 0.293

2022-11-25 05:39:20,775 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:39:22,643 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:39:25,096 - INFO  - Validation [17][   20/   40]   Loss 0.411379   Top1 86.171875   Top5 99.296875   BatchTime 0.122540   
2022-11-25 05:39:26,225 - INFO  - Validation [17][   40/   40]   Loss 0.397580   Top1 86.440000   Top5 99.450000   BatchTime 0.089502   
2022-11-25 05:39:26,411 - INFO  - ==> Top1: 86.440    Top5: 99.450    Loss: 0.398

2022-11-25 05:39:26,411 - INFO  - ==> Sparsity : 0.470

2022-11-25 05:39:26,412 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:39:26,412 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:39:26,412 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.830   Top5: 99.520]
2022-11-25 05:39:26,546 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:39:26,547 - INFO  - >>>>>> Epoch  18
2022-11-25 05:39:26,549 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:39:33,781 - INFO  - Training [18][   20/  196]   Loss 0.262265   Top1 91.464844   Top5 99.824219   BatchTime 0.361460   LR 0.000162   
2022-11-25 05:39:40,276 - INFO  - Training [18][   40/  196]   Loss 0.270489   Top1 91.035156   Top5 99.765625   BatchTime 0.343118   LR 0.000160   
2022-11-25 05:39:46,400 - INFO  - Training [18][   60/  196]   Loss 0.272885   Top1 90.937500   Top5 99.785156   BatchTime 0.330808   LR 0.000158   
2022-11-25 05:39:52,244 - INFO  - Training [18][   80/  196]   Loss 0.275079   Top1 90.800781   Top5 99.775391   BatchTime 0.321155   LR 0.000156   
2022-11-25 05:39:58,928 - INFO  - Training [18][  100/  196]   Loss 0.275616   Top1 90.824219   Top5 99.781250   BatchTime 0.323755   LR 0.000154   
2022-11-25 05:40:05,793 - INFO  - Training [18][  120/  196]   Loss 0.272667   Top1 90.917969   Top5 99.788411   BatchTime 0.327007   LR 0.000152   
2022-11-25 05:40:12,233 - INFO  - Training [18][  140/  196]   Loss 0.273203   Top1 90.876116   Top5 99.796317   BatchTime 0.326294   LR 0.000150   
2022-11-25 05:40:18,406 - INFO  - Training [18][  160/  196]   Loss 0.272180   Top1 90.859375   Top5 99.794922   BatchTime 0.324084   LR 0.000148   
2022-11-25 05:40:25,065 - INFO  - Training [18][  180/  196]   Loss 0.272523   Top1 90.868056   Top5 99.789497   BatchTime 0.325070   LR 0.000146   
2022-11-25 05:40:30,521 - INFO  - ==> Top1: 90.858    Top5: 99.786    Loss: 0.273

2022-11-25 05:40:30,719 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:40:32,027 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:40:34,319 - INFO  - Validation [18][   20/   40]   Loss 0.382902   Top1 87.031250   Top5 99.414062   BatchTime 0.114507   
2022-11-25 05:40:35,380 - INFO  - Validation [18][   40/   40]   Loss 0.378056   Top1 87.300000   Top5 99.560000   BatchTime 0.083785   
2022-11-25 05:40:35,581 - INFO  - ==> Top1: 87.300    Top5: 99.560    Loss: 0.378

2022-11-25 05:40:35,581 - INFO  - ==> Sparsity : 0.481

2022-11-25 05:40:35,581 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 87.300   Top5: 99.560]
2022-11-25 05:40:35,582 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:40:35,582 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 87.090   Top5: 99.500]
2022-11-25 05:40:41,021 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:40:41,024 - INFO  - >>>>>> Epoch  19
2022-11-25 05:40:41,026 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:40:48,252 - INFO  - Training [19][   20/  196]   Loss 0.260530   Top1 91.210938   Top5 99.707031   BatchTime 0.361222   LR 0.000143   
2022-11-25 05:40:54,756 - INFO  - Training [19][   40/  196]   Loss 0.259530   Top1 91.357422   Top5 99.804688   BatchTime 0.343211   LR 0.000141   
2022-11-25 05:41:00,528 - INFO  - Training [19][   60/  196]   Loss 0.257130   Top1 91.399740   Top5 99.811198   BatchTime 0.325011   LR 0.000139   
2022-11-25 05:41:06,589 - INFO  - Training [19][   80/  196]   Loss 0.256748   Top1 91.347656   Top5 99.804688   BatchTime 0.319514   LR 0.000137   
2022-11-25 05:41:12,039 - INFO  - Training [19][  100/  196]   Loss 0.259062   Top1 91.269531   Top5 99.824219   BatchTime 0.310109   LR 0.000135   
2022-11-25 05:41:17,051 - INFO  - Training [19][  120/  196]   Loss 0.258181   Top1 91.344401   Top5 99.830729   BatchTime 0.300189   LR 0.000133   
2022-11-25 05:41:22,593 - INFO  - Training [19][  140/  196]   Loss 0.258408   Top1 91.297433   Top5 99.838170   BatchTime 0.296892   LR 0.000131   
2022-11-25 05:41:29,212 - INFO  - Training [19][  160/  196]   Loss 0.258421   Top1 91.303711   Top5 99.831543   BatchTime 0.301146   LR 0.000129   
2022-11-25 05:41:35,403 - INFO  - Training [19][  180/  196]   Loss 0.257585   Top1 91.323785   Top5 99.839410   BatchTime 0.302078   LR 0.000127   
2022-11-25 05:41:40,902 - INFO  - ==> Top1: 91.340    Top5: 99.842    Loss: 0.257

2022-11-25 05:41:41,079 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:41:42,021 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:41:44,234 - INFO  - Validation [19][   20/   40]   Loss 0.392142   Top1 87.031250   Top5 99.433594   BatchTime 0.110583   
2022-11-25 05:41:45,407 - INFO  - Validation [19][   40/   40]   Loss 0.384355   Top1 87.320000   Top5 99.570000   BatchTime 0.084614   
2022-11-25 05:41:45,597 - INFO  - ==> Top1: 87.320    Top5: 99.570    Loss: 0.384

2022-11-25 05:41:45,598 - INFO  - ==> Sparsity : 0.505

2022-11-25 05:41:45,598 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 87.320   Top5: 99.570]
2022-11-25 05:41:45,598 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 87.300   Top5: 99.560]
2022-11-25 05:41:45,598 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:41:52,625 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:41:52,627 - INFO  - >>>>>> Epoch  20
2022-11-25 05:41:52,629 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:41:59,797 - INFO  - Training [20][   20/  196]   Loss 0.257367   Top1 91.386719   Top5 99.843750   BatchTime 0.358258   LR 0.000123   
2022-11-25 05:42:05,917 - INFO  - Training [20][   40/  196]   Loss 0.242879   Top1 91.777344   Top5 99.843750   BatchTime 0.332130   LR 0.000121   
2022-11-25 05:42:12,652 - INFO  - Training [20][   60/  196]   Loss 0.244198   Top1 91.803385   Top5 99.837240   BatchTime 0.333667   LR 0.000119   
2022-11-25 05:42:18,956 - INFO  - Training [20][   80/  196]   Loss 0.246623   Top1 91.835938   Top5 99.819336   BatchTime 0.329050   LR 0.000117   
2022-11-25 05:42:24,962 - INFO  - Training [20][  100/  196]   Loss 0.246661   Top1 91.792969   Top5 99.824219   BatchTime 0.323297   LR 0.000115   
2022-11-25 05:42:31,077 - INFO  - Training [20][  120/  196]   Loss 0.244478   Top1 91.842448   Top5 99.830729   BatchTime 0.320374   LR 0.000113   
2022-11-25 05:42:37,362 - INFO  - Training [20][  140/  196]   Loss 0.247131   Top1 91.763393   Top5 99.824219   BatchTime 0.319494   LR 0.000111   
2022-11-25 05:42:43,138 - INFO  - Training [20][  160/  196]   Loss 0.247610   Top1 91.730957   Top5 99.821777   BatchTime 0.315659   LR 0.000109   
2022-11-25 05:42:49,720 - INFO  - Training [20][  180/  196]   Loss 0.247051   Top1 91.697049   Top5 99.826389   BatchTime 0.317155   LR 0.000107   
2022-11-25 05:42:55,031 - INFO  - ==> Top1: 91.676    Top5: 99.824    Loss: 0.247

2022-11-25 05:42:55,226 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:42:56,353 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:42:58,675 - INFO  - Validation [20][   20/   40]   Loss 0.412248   Top1 86.679688   Top5 99.472656   BatchTime 0.116011   
2022-11-25 05:42:59,735 - INFO  - Validation [20][   40/   40]   Loss 0.406920   Top1 87.110000   Top5 99.520000   BatchTime 0.084531   
2022-11-25 05:42:59,969 - INFO  - ==> Top1: 87.110    Top5: 99.520    Loss: 0.407

2022-11-25 05:42:59,969 - INFO  - ==> Sparsity : 0.526

2022-11-25 05:42:59,969 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 87.320   Top5: 99.570]
2022-11-25 05:42:59,969 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 87.300   Top5: 99.560]
2022-11-25 05:42:59,969 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 87.220   Top5: 99.510]
2022-11-25 05:43:00,121 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:43:00,122 - INFO  - >>>>>> Epoch  21
2022-11-25 05:43:00,124 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:43:07,122 - INFO  - Training [21][   20/  196]   Loss 0.222886   Top1 92.031250   Top5 99.980469   BatchTime 0.349766   LR 0.000104   
2022-11-25 05:43:13,426 - INFO  - Training [21][   40/  196]   Loss 0.224942   Top1 92.216797   Top5 99.912109   BatchTime 0.332495   LR 0.000102   
2022-11-25 05:43:20,083 - INFO  - Training [21][   60/  196]   Loss 0.223983   Top1 92.213542   Top5 99.921875   BatchTime 0.332603   LR 0.000100   
2022-11-25 05:43:26,231 - INFO  - Training [21][   80/  196]   Loss 0.225623   Top1 92.250977   Top5 99.897461   BatchTime 0.326301   LR 0.000098   
2022-11-25 05:43:32,945 - INFO  - Training [21][  100/  196]   Loss 0.228017   Top1 92.226562   Top5 99.890625   BatchTime 0.328183   LR 0.000096   
2022-11-25 05:43:38,197 - INFO  - Training [21][  120/  196]   Loss 0.228315   Top1 92.242839   Top5 99.892578   BatchTime 0.317254   LR 0.000094   
2022-11-25 05:43:43,882 - INFO  - Training [21][  140/  196]   Loss 0.229870   Top1 92.184710   Top5 99.888393   BatchTime 0.312534   LR 0.000092   
2022-11-25 05:43:50,132 - INFO  - Training [21][  160/  196]   Loss 0.231811   Top1 92.097168   Top5 99.877930   BatchTime 0.312531   LR 0.000090   
2022-11-25 05:43:56,593 - INFO  - Training [21][  180/  196]   Loss 0.232842   Top1 92.046441   Top5 99.869792   BatchTime 0.313698   LR 0.000088   
2022-11-25 05:44:02,054 - INFO  - ==> Top1: 92.130    Top5: 99.866    Loss: 0.231

2022-11-25 05:44:02,265 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:44:03,668 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:44:05,927 - INFO  - Validation [21][   20/   40]   Loss 0.373534   Top1 88.105469   Top5 99.375000   BatchTime 0.112836   
2022-11-25 05:44:06,954 - INFO  - Validation [21][   40/   40]   Loss 0.371413   Top1 88.200000   Top5 99.530000   BatchTime 0.082122   
2022-11-25 05:44:07,175 - INFO  - ==> Top1: 88.200    Top5: 99.530    Loss: 0.371

2022-11-25 05:44:07,175 - INFO  - ==> Sparsity : 0.552

2022-11-25 05:44:07,175 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 88.200   Top5: 99.530]
2022-11-25 05:44:07,175 - INFO  - Scoreboard best 2 ==> Epoch [19][Top1: 87.320   Top5: 99.570]
2022-11-25 05:44:07,176 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 87.300   Top5: 99.560]
2022-11-25 05:44:12,490 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:44:12,495 - INFO  - >>>>>> Epoch  22
2022-11-25 05:44:12,498 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:44:19,199 - INFO  - Training [22][   20/  196]   Loss 0.208071   Top1 93.164062   Top5 99.902344   BatchTime 0.334968   LR 0.000085   
2022-11-25 05:44:25,282 - INFO  - Training [22][   40/  196]   Loss 0.205114   Top1 92.939453   Top5 99.912109   BatchTime 0.319539   LR 0.000083   
2022-11-25 05:44:31,122 - INFO  - Training [22][   60/  196]   Loss 0.209421   Top1 92.968750   Top5 99.895833   BatchTime 0.310365   LR 0.000081   
2022-11-25 05:44:36,612 - INFO  - Training [22][   80/  196]   Loss 0.213073   Top1 92.866211   Top5 99.916992   BatchTime 0.301393   LR 0.000079   
2022-11-25 05:44:42,095 - INFO  - Training [22][  100/  196]   Loss 0.214486   Top1 92.761719   Top5 99.910156   BatchTime 0.295945   LR 0.000077   
2022-11-25 05:44:48,553 - INFO  - Training [22][  120/  196]   Loss 0.216516   Top1 92.714844   Top5 99.905599   BatchTime 0.300440   LR 0.000075   
2022-11-25 05:44:54,675 - INFO  - Training [22][  140/  196]   Loss 0.216954   Top1 92.731585   Top5 99.896763   BatchTime 0.301245   LR 0.000073   
2022-11-25 05:45:01,029 - INFO  - Training [22][  160/  196]   Loss 0.218032   Top1 92.695312   Top5 99.892578   BatchTime 0.303300   LR 0.000072   
2022-11-25 05:45:06,542 - INFO  - Training [22][  180/  196]   Loss 0.218689   Top1 92.688802   Top5 99.884983   BatchTime 0.300231   LR 0.000070   
2022-11-25 05:45:10,635 - INFO  - ==> Top1: 92.758    Top5: 99.888    Loss: 0.217

2022-11-25 05:45:10,776 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:45:11,862 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:45:14,242 - INFO  - Validation [22][   20/   40]   Loss 0.379264   Top1 87.714844   Top5 99.472656   BatchTime 0.118893   
2022-11-25 05:45:15,328 - INFO  - Validation [22][   40/   40]   Loss 0.373313   Top1 87.940000   Top5 99.570000   BatchTime 0.086611   
2022-11-25 05:45:15,528 - INFO  - ==> Top1: 87.940    Top5: 99.570    Loss: 0.373

2022-11-25 05:45:15,528 - INFO  - ==> Sparsity : 0.568

2022-11-25 05:45:15,528 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 88.200   Top5: 99.530]
2022-11-25 05:45:15,529 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 87.940   Top5: 99.570]
2022-11-25 05:45:15,529 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 87.320   Top5: 99.570]
2022-11-25 05:45:15,642 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:45:15,644 - INFO  - >>>>>> Epoch  23
2022-11-25 05:45:15,645 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:45:22,632 - INFO  - Training [23][   20/  196]   Loss 0.188869   Top1 93.710938   Top5 99.882812   BatchTime 0.349218   LR 0.000067   
2022-11-25 05:45:29,593 - INFO  - Training [23][   40/  196]   Loss 0.193635   Top1 93.662109   Top5 99.921875   BatchTime 0.348627   LR 0.000065   
2022-11-25 05:45:35,682 - INFO  - Training [23][   60/  196]   Loss 0.197706   Top1 93.489583   Top5 99.928385   BatchTime 0.333900   LR 0.000063   
2022-11-25 05:45:41,927 - INFO  - Training [23][   80/  196]   Loss 0.199150   Top1 93.305664   Top5 99.912109   BatchTime 0.328489   LR 0.000061   
2022-11-25 05:45:48,673 - INFO  - Training [23][  100/  196]   Loss 0.204112   Top1 93.144531   Top5 99.910156   BatchTime 0.330253   LR 0.000060   
2022-11-25 05:45:55,436 - INFO  - Training [23][  120/  196]   Loss 0.206011   Top1 93.098958   Top5 99.905599   BatchTime 0.331566   LR 0.000058   
2022-11-25 05:46:01,675 - INFO  - Training [23][  140/  196]   Loss 0.205161   Top1 93.119420   Top5 99.905134   BatchTime 0.328759   LR 0.000056   
2022-11-25 05:46:07,847 - INFO  - Training [23][  160/  196]   Loss 0.205862   Top1 93.117676   Top5 99.895020   BatchTime 0.326243   LR 0.000055   
2022-11-25 05:46:13,785 - INFO  - Training [23][  180/  196]   Loss 0.205462   Top1 93.116319   Top5 99.898003   BatchTime 0.322980   LR 0.000053   
2022-11-25 05:46:18,346 - INFO  - ==> Top1: 93.100    Top5: 99.892    Loss: 0.206

2022-11-25 05:46:18,535 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:46:19,732 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:46:22,040 - INFO  - Validation [23][   20/   40]   Loss 0.368765   Top1 88.203125   Top5 99.433594   BatchTime 0.115294   
2022-11-25 05:46:23,153 - INFO  - Validation [23][   40/   40]   Loss 0.362099   Top1 88.520000   Top5 99.590000   BatchTime 0.085492   
2022-11-25 05:46:23,352 - INFO  - ==> Top1: 88.520    Top5: 99.590    Loss: 0.362

2022-11-25 05:46:23,352 - INFO  - ==> Sparsity : 0.573

2022-11-25 05:46:23,353 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 88.520   Top5: 99.590]
2022-11-25 05:46:23,353 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 88.200   Top5: 99.530]
2022-11-25 05:46:23,354 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 87.940   Top5: 99.570]
2022-11-25 05:46:28,429 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:46:28,437 - INFO  - >>>>>> Epoch  24
2022-11-25 05:46:28,438 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:46:35,728 - INFO  - Training [24][   20/  196]   Loss 0.186157   Top1 93.593750   Top5 99.960938   BatchTime 0.364336   LR 0.000050   
2022-11-25 05:46:42,502 - INFO  - Training [24][   40/  196]   Loss 0.193432   Top1 93.505859   Top5 99.902344   BatchTime 0.351519   LR 0.000048   
2022-11-25 05:46:49,049 - INFO  - Training [24][   60/  196]   Loss 0.193628   Top1 93.509115   Top5 99.902344   BatchTime 0.343464   LR 0.000047   
2022-11-25 05:46:55,263 - INFO  - Training [24][   80/  196]   Loss 0.192120   Top1 93.632812   Top5 99.907227   BatchTime 0.335272   LR 0.000045   
2022-11-25 05:47:00,857 - INFO  - Training [24][  100/  196]   Loss 0.191381   Top1 93.652344   Top5 99.914062   BatchTime 0.324159   LR 0.000044   
2022-11-25 05:47:07,067 - INFO  - Training [24][  120/  196]   Loss 0.191328   Top1 93.597005   Top5 99.921875   BatchTime 0.321878   LR 0.000042   
2022-11-25 05:47:13,753 - INFO  - Training [24][  140/  196]   Loss 0.190913   Top1 93.596540   Top5 99.927455   BatchTime 0.323654   LR 0.000041   
2022-11-25 05:47:19,708 - INFO  - Training [24][  160/  196]   Loss 0.188858   Top1 93.654785   Top5 99.931641   BatchTime 0.320415   LR 0.000039   
2022-11-25 05:47:25,919 - INFO  - Training [24][  180/  196]   Loss 0.189512   Top1 93.665365   Top5 99.919705   BatchTime 0.319320   LR 0.000038   
2022-11-25 05:47:30,953 - INFO  - ==> Top1: 93.618    Top5: 99.918    Loss: 0.191

2022-11-25 05:47:31,156 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:47:32,452 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:47:34,777 - INFO  - Validation [24][   20/   40]   Loss 0.371448   Top1 88.242188   Top5 99.492188   BatchTime 0.116121   
2022-11-25 05:47:35,831 - INFO  - Validation [24][   40/   40]   Loss 0.362181   Top1 88.500000   Top5 99.620000   BatchTime 0.084432   
2022-11-25 05:47:36,015 - INFO  - ==> Top1: 88.500    Top5: 99.620    Loss: 0.362

2022-11-25 05:47:36,015 - INFO  - ==> Sparsity : 0.579

2022-11-25 05:47:36,015 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 88.520   Top5: 99.590]
2022-11-25 05:47:36,016 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 88.500   Top5: 99.620]
2022-11-25 05:47:36,016 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 88.200   Top5: 99.530]
2022-11-25 05:47:36,127 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:47:36,128 - INFO  - >>>>>> Epoch  25
2022-11-25 05:47:36,130 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:47:42,601 - INFO  - Training [25][   20/  196]   Loss 0.171508   Top1 94.296875   Top5 99.902344   BatchTime 0.323422   LR 0.000035   
2022-11-25 05:47:48,053 - INFO  - Training [25][   40/  196]   Loss 0.173591   Top1 94.111328   Top5 99.931641   BatchTime 0.298027   LR 0.000034   
2022-11-25 05:47:53,646 - INFO  - Training [25][   60/  196]   Loss 0.175921   Top1 94.205729   Top5 99.908854   BatchTime 0.291900   LR 0.000033   
2022-11-25 05:47:59,606 - INFO  - Training [25][   80/  196]   Loss 0.176979   Top1 94.091797   Top5 99.921875   BatchTime 0.293420   LR 0.000031   
2022-11-25 05:48:04,541 - INFO  - Training [25][  100/  196]   Loss 0.179737   Top1 94.007812   Top5 99.917969   BatchTime 0.284086   LR 0.000030   
2022-11-25 05:48:10,250 - INFO  - Training [25][  120/  196]   Loss 0.181321   Top1 93.955078   Top5 99.925130   BatchTime 0.284312   LR 0.000029   
2022-11-25 05:48:17,079 - INFO  - Training [25][  140/  196]   Loss 0.182014   Top1 93.922991   Top5 99.921875   BatchTime 0.292476   LR 0.000027   
2022-11-25 05:48:23,646 - INFO  - Training [25][  160/  196]   Loss 0.181317   Top1 93.981934   Top5 99.907227   BatchTime 0.296955   LR 0.000026   
2022-11-25 05:48:30,226 - INFO  - Training [25][  180/  196]   Loss 0.181211   Top1 93.977865   Top5 99.904514   BatchTime 0.300518   LR 0.000025   
2022-11-25 05:48:35,759 - INFO  - ==> Top1: 93.986    Top5: 99.906    Loss: 0.181

2022-11-25 05:48:35,975 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:48:37,319 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:48:39,755 - INFO  - Validation [25][   20/   40]   Loss 0.356703   Top1 88.730469   Top5 99.492188   BatchTime 0.121731   
2022-11-25 05:48:40,809 - INFO  - Validation [25][   40/   40]   Loss 0.351122   Top1 88.870000   Top5 99.610000   BatchTime 0.087202   
2022-11-25 05:48:41,023 - INFO  - ==> Top1: 88.870    Top5: 99.610    Loss: 0.351

2022-11-25 05:48:41,023 - INFO  - ==> Sparsity : 0.586

2022-11-25 05:48:41,023 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 05:48:41,024 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 88.520   Top5: 99.590]
2022-11-25 05:48:41,024 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 88.500   Top5: 99.620]
2022-11-25 05:48:46,372 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 05:48:46,376 - INFO  - >>>>>> Epoch  26
2022-11-25 05:48:46,379 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:48:53,962 - INFO  - Training [26][   20/  196]   Loss 0.172121   Top1 94.042969   Top5 99.882812   BatchTime 0.379040   LR 0.000023   
2022-11-25 05:48:59,647 - INFO  - Training [26][   40/  196]   Loss 0.170522   Top1 94.326172   Top5 99.873047   BatchTime 0.331638   LR 0.000022   
2022-11-25 05:49:06,478 - INFO  - Training [26][   60/  196]   Loss 0.169792   Top1 94.375000   Top5 99.889323   BatchTime 0.334942   LR 0.000021   
2022-11-25 05:49:12,997 - INFO  - Training [26][   80/  196]   Loss 0.173741   Top1 94.228516   Top5 99.892578   BatchTime 0.332695   LR 0.000019   
2022-11-25 05:49:19,876 - INFO  - Training [26][  100/  196]   Loss 0.173141   Top1 94.210938   Top5 99.910156   BatchTime 0.334940   LR 0.000018   
2022-11-25 05:49:26,478 - INFO  - Training [26][  120/  196]   Loss 0.174275   Top1 94.166667   Top5 99.895833   BatchTime 0.334137   LR 0.000017   
2022-11-25 05:49:33,646 - INFO  - Training [26][  140/  196]   Loss 0.172806   Top1 94.229911   Top5 99.896763   BatchTime 0.337603   LR 0.000016   
2022-11-25 05:49:39,408 - INFO  - Training [26][  160/  196]   Loss 0.171591   Top1 94.272461   Top5 99.899902   BatchTime 0.331415   LR 0.000015   
2022-11-25 05:49:46,080 - INFO  - Training [26][  180/  196]   Loss 0.171628   Top1 94.288194   Top5 99.908854   BatchTime 0.331659   LR 0.000014   
2022-11-25 05:49:51,566 - INFO  - ==> Top1: 94.260    Top5: 99.906    Loss: 0.172

2022-11-25 05:49:51,768 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:49:52,834 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:49:55,133 - INFO  - Validation [26][   20/   40]   Loss 0.371792   Top1 88.515625   Top5 99.414062   BatchTime 0.114837   
2022-11-25 05:49:56,198 - INFO  - Validation [26][   40/   40]   Loss 0.364212   Top1 88.520000   Top5 99.510000   BatchTime 0.084067   
2022-11-25 05:49:56,407 - INFO  - ==> Top1: 88.520    Top5: 99.510    Loss: 0.364

2022-11-25 05:49:56,408 - INFO  - ==> Sparsity : 0.592

2022-11-25 05:49:56,408 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 05:49:56,408 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 88.520   Top5: 99.590]
2022-11-25 05:49:56,408 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 88.520   Top5: 99.510]
2022-11-25 05:49:56,541 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:49:56,543 - INFO  - >>>>>> Epoch  27
2022-11-25 05:49:56,545 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:50:02,787 - INFO  - Training [27][   20/  196]   Loss 0.175434   Top1 94.277344   Top5 99.902344   BatchTime 0.311995   LR 0.000013   
2022-11-25 05:50:07,821 - INFO  - Training [27][   40/  196]   Loss 0.172231   Top1 94.394531   Top5 99.902344   BatchTime 0.281835   LR 0.000012   
2022-11-25 05:50:13,591 - INFO  - Training [27][   60/  196]   Loss 0.167928   Top1 94.485677   Top5 99.908854   BatchTime 0.284052   LR 0.000011   
2022-11-25 05:50:19,940 - INFO  - Training [27][   80/  196]   Loss 0.172818   Top1 94.355469   Top5 99.912109   BatchTime 0.292402   LR 0.000010   
2022-11-25 05:50:26,187 - INFO  - Training [27][  100/  196]   Loss 0.170641   Top1 94.406250   Top5 99.914062   BatchTime 0.296395   LR 0.000009   
2022-11-25 05:50:31,165 - INFO  - Training [27][  120/  196]   Loss 0.169712   Top1 94.505208   Top5 99.918620   BatchTime 0.288478   LR 0.000009   
2022-11-25 05:50:37,712 - INFO  - Training [27][  140/  196]   Loss 0.171777   Top1 94.411272   Top5 99.916295   BatchTime 0.294030   LR 0.000008   
2022-11-25 05:50:43,905 - INFO  - Training [27][  160/  196]   Loss 0.170022   Top1 94.448242   Top5 99.912109   BatchTime 0.295981   LR 0.000007   
2022-11-25 05:50:50,325 - INFO  - Training [27][  180/  196]   Loss 0.170496   Top1 94.433594   Top5 99.908854   BatchTime 0.298760   LR 0.000007   
2022-11-25 05:50:55,725 - INFO  - ==> Top1: 94.414    Top5: 99.910    Loss: 0.171

2022-11-25 05:50:55,935 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:50:57,378 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:51:00,282 - INFO  - Validation [27][   20/   40]   Loss 0.369126   Top1 88.632812   Top5 99.492188   BatchTime 0.145085   
2022-11-25 05:51:01,348 - INFO  - Validation [27][   40/   40]   Loss 0.363576   Top1 88.700000   Top5 99.590000   BatchTime 0.099199   
2022-11-25 05:51:01,603 - INFO  - ==> Top1: 88.700    Top5: 99.590    Loss: 0.364

2022-11-25 05:51:01,603 - INFO  - ==> Sparsity : 0.595

2022-11-25 05:51:01,604 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 05:51:01,604 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 88.700   Top5: 99.590]
2022-11-25 05:51:01,604 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 88.520   Top5: 99.590]
2022-11-25 05:51:01,946 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:51:01,947 - INFO  - >>>>>> Epoch  28
2022-11-25 05:51:01,949 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:51:08,579 - INFO  - Training [28][   20/  196]   Loss 0.170735   Top1 94.140625   Top5 99.902344   BatchTime 0.331386   LR 0.000006   
2022-11-25 05:51:15,041 - INFO  - Training [28][   40/  196]   Loss 0.175581   Top1 93.955078   Top5 99.902344   BatchTime 0.327243   LR 0.000005   
2022-11-25 05:51:20,809 - INFO  - Training [28][   60/  196]   Loss 0.167946   Top1 94.277344   Top5 99.921875   BatchTime 0.314288   LR 0.000004   
2022-11-25 05:51:26,457 - INFO  - Training [28][   80/  196]   Loss 0.165813   Top1 94.409180   Top5 99.931641   BatchTime 0.306317   LR 0.000004   
2022-11-25 05:51:31,806 - INFO  - Training [28][  100/  196]   Loss 0.167198   Top1 94.339844   Top5 99.929688   BatchTime 0.298544   LR 0.000003   
2022-11-25 05:51:37,576 - INFO  - Training [28][  120/  196]   Loss 0.165287   Top1 94.427083   Top5 99.938151   BatchTime 0.296869   LR 0.000003   
2022-11-25 05:51:43,787 - INFO  - Training [28][  140/  196]   Loss 0.166036   Top1 94.383371   Top5 99.941406   BatchTime 0.298820   LR 0.000003   
2022-11-25 05:51:50,333 - INFO  - Training [28][  160/  196]   Loss 0.164356   Top1 94.458008   Top5 99.938965   BatchTime 0.302380   LR 0.000002   
2022-11-25 05:51:57,331 - INFO  - Training [28][  180/  196]   Loss 0.165226   Top1 94.396701   Top5 99.941406   BatchTime 0.307659   LR 0.000002   
2022-11-25 05:52:02,935 - INFO  - ==> Top1: 94.394    Top5: 99.942    Loss: 0.166

2022-11-25 05:52:03,127 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:52:04,086 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:52:06,548 - INFO  - Validation [28][   20/   40]   Loss 0.358750   Top1 88.886719   Top5 99.453125   BatchTime 0.122928   
2022-11-25 05:52:07,700 - INFO  - Validation [28][   40/   40]   Loss 0.353915   Top1 88.790000   Top5 99.580000   BatchTime 0.090267   
2022-11-25 05:52:07,920 - INFO  - ==> Top1: 88.790    Top5: 99.580    Loss: 0.354

2022-11-25 05:52:07,920 - INFO  - ==> Sparsity : 0.597

2022-11-25 05:52:07,920 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 05:52:07,920 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 05:52:07,921 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 88.700   Top5: 99.590]
2022-11-25 05:52:08,036 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:52:08,037 - INFO  - >>>>>> Epoch  29
2022-11-25 05:52:08,039 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:52:14,359 - INFO  - Training [29][   20/  196]   Loss 0.156211   Top1 94.980469   Top5 99.863281   BatchTime 0.315895   LR 0.000001   
2022-11-25 05:52:20,312 - INFO  - Training [29][   40/  196]   Loss 0.158506   Top1 94.755859   Top5 99.902344   BatchTime 0.306780   LR 0.000001   
2022-11-25 05:52:25,344 - INFO  - Training [29][   60/  196]   Loss 0.159877   Top1 94.694010   Top5 99.921875   BatchTime 0.288377   LR 0.000001   
2022-11-25 05:52:30,941 - INFO  - Training [29][   80/  196]   Loss 0.160447   Top1 94.755859   Top5 99.926758   BatchTime 0.286245   LR 0.000001   
2022-11-25 05:52:37,308 - INFO  - Training [29][  100/  196]   Loss 0.162067   Top1 94.765625   Top5 99.906250   BatchTime 0.292664   LR 0.000000   
2022-11-25 05:52:43,769 - INFO  - Training [29][  120/  196]   Loss 0.160927   Top1 94.781901   Top5 99.905599   BatchTime 0.297727   LR 0.000000   
2022-11-25 05:52:50,569 - INFO  - Training [29][  140/  196]   Loss 0.160748   Top1 94.754464   Top5 99.913504   BatchTime 0.303766   LR 0.000000   
2022-11-25 05:52:57,479 - INFO  - Training [29][  160/  196]   Loss 0.160812   Top1 94.755859   Top5 99.916992   BatchTime 0.308984   LR 0.000000   
2022-11-25 05:53:04,123 - INFO  - Training [29][  180/  196]   Loss 0.162207   Top1 94.707031   Top5 99.913194   BatchTime 0.311560   LR 0.000000   
2022-11-25 05:53:09,464 - INFO  - ==> Top1: 94.694    Top5: 99.910    Loss: 0.162

2022-11-25 05:53:09,641 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:53:10,789 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:53:13,346 - INFO  - Validation [29][   20/   40]   Loss 0.364126   Top1 88.710938   Top5 99.492188   BatchTime 0.127762   
2022-11-25 05:53:14,368 - INFO  - Validation [29][   40/   40]   Loss 0.358271   Top1 88.820000   Top5 99.580000   BatchTime 0.089455   
2022-11-25 05:53:14,604 - INFO  - ==> Top1: 88.820    Top5: 99.580    Loss: 0.358

2022-11-25 05:53:14,604 - INFO  - ==> Sparsity : 0.597

2022-11-25 05:53:14,604 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 05:53:14,605 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 05:53:14,605 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 05:53:14,734 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:53:14,736 - INFO  - >>>>>> Epoch  30
2022-11-25 05:53:14,737 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:53:21,855 - INFO  - Training [30][   20/  196]   Loss 0.165143   Top1 94.492188   Top5 99.902344   BatchTime 0.355764   LR 0.000125   
2022-11-25 05:53:27,484 - INFO  - Training [30][   40/  196]   Loss 0.183853   Top1 93.935547   Top5 99.892578   BatchTime 0.318620   LR 0.000125   
2022-11-25 05:53:33,605 - INFO  - Training [30][   60/  196]   Loss 0.191921   Top1 93.606771   Top5 99.915365   BatchTime 0.314412   LR 0.000125   
2022-11-25 05:53:40,003 - INFO  - Training [30][   80/  196]   Loss 0.201311   Top1 93.154297   Top5 99.902344   BatchTime 0.315794   LR 0.000125   
2022-11-25 05:53:45,090 - INFO  - Training [30][  100/  196]   Loss 0.207076   Top1 93.027344   Top5 99.882812   BatchTime 0.303498   LR 0.000125   
2022-11-25 05:53:50,581 - INFO  - Training [30][  120/  196]   Loss 0.210386   Top1 92.887370   Top5 99.886068   BatchTime 0.298672   LR 0.000125   
2022-11-25 05:53:56,917 - INFO  - Training [30][  140/  196]   Loss 0.217823   Top1 92.631138   Top5 99.880022   BatchTime 0.301259   LR 0.000125   
2022-11-25 05:54:03,323 - INFO  - Training [30][  160/  196]   Loss 0.217451   Top1 92.646484   Top5 99.880371   BatchTime 0.303642   LR 0.000125   
2022-11-25 05:54:09,584 - INFO  - Training [30][  180/  196]   Loss 0.218288   Top1 92.610677   Top5 99.871962   BatchTime 0.304687   LR 0.000125   
2022-11-25 05:54:15,084 - INFO  - ==> Top1: 92.572    Top5: 99.872    Loss: 0.219

2022-11-25 05:54:15,286 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:54:16,634 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:54:19,075 - INFO  - Validation [30][   20/   40]   Loss 0.405667   Top1 87.460938   Top5 99.414062   BatchTime 0.121959   
2022-11-25 05:54:20,243 - INFO  - Validation [30][   40/   40]   Loss 0.399435   Top1 87.590000   Top5 99.530000   BatchTime 0.090186   
2022-11-25 05:54:20,429 - INFO  - ==> Top1: 87.590    Top5: 99.530    Loss: 0.399

2022-11-25 05:54:20,429 - INFO  - ==> Sparsity : 0.590

2022-11-25 05:54:20,429 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 05:54:20,430 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 05:54:20,430 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 05:54:20,567 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:54:20,569 - INFO  - >>>>>> Epoch  31
2022-11-25 05:54:20,571 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:54:27,512 - INFO  - Training [31][   20/  196]   Loss 0.223001   Top1 92.910156   Top5 99.765625   BatchTime 0.346937   LR 0.000125   
2022-11-25 05:54:33,446 - INFO  - Training [31][   40/  196]   Loss 0.226662   Top1 92.382812   Top5 99.824219   BatchTime 0.321833   LR 0.000125   
2022-11-25 05:54:40,058 - INFO  - Training [31][   60/  196]   Loss 0.218452   Top1 92.675781   Top5 99.850260   BatchTime 0.324754   LR 0.000125   
2022-11-25 05:54:45,044 - INFO  - Training [31][   80/  196]   Loss 0.219192   Top1 92.587891   Top5 99.858398   BatchTime 0.305889   LR 0.000125   
2022-11-25 05:54:51,141 - INFO  - Training [31][  100/  196]   Loss 0.219949   Top1 92.582031   Top5 99.863281   BatchTime 0.305673   LR 0.000125   
2022-11-25 05:54:57,651 - INFO  - Training [31][  120/  196]   Loss 0.218820   Top1 92.604167   Top5 99.876302   BatchTime 0.308979   LR 0.000125   
2022-11-25 05:55:03,868 - INFO  - Training [31][  140/  196]   Loss 0.218326   Top1 92.589286   Top5 99.880022   BatchTime 0.309249   LR 0.000124   
2022-11-25 05:55:10,316 - INFO  - Training [31][  160/  196]   Loss 0.217562   Top1 92.614746   Top5 99.868164   BatchTime 0.310888   LR 0.000124   
2022-11-25 05:55:16,044 - INFO  - Training [31][  180/  196]   Loss 0.216080   Top1 92.645399   Top5 99.874132   BatchTime 0.308169   LR 0.000124   
2022-11-25 05:55:20,709 - INFO  - ==> Top1: 92.630    Top5: 99.876    Loss: 0.217

2022-11-25 05:55:20,902 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:55:22,432 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:55:24,917 - INFO  - Validation [31][   20/   40]   Loss 0.407777   Top1 87.187500   Top5 99.570312   BatchTime 0.124157   
2022-11-25 05:55:25,933 - INFO  - Validation [31][   40/   40]   Loss 0.401168   Top1 87.420000   Top5 99.610000   BatchTime 0.087470   
2022-11-25 05:55:26,123 - INFO  - ==> Top1: 87.420    Top5: 99.610    Loss: 0.401

2022-11-25 05:55:26,123 - INFO  - ==> Sparsity : 0.591

2022-11-25 05:55:26,123 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 05:55:26,123 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 05:55:26,124 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 05:55:26,236 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:55:26,237 - INFO  - >>>>>> Epoch  32
2022-11-25 05:55:26,239 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:55:34,120 - INFO  - Training [32][   20/  196]   Loss 0.210419   Top1 93.007812   Top5 99.921875   BatchTime 0.393925   LR 0.000124   
2022-11-25 05:55:40,835 - INFO  - Training [32][   40/  196]   Loss 0.214537   Top1 92.832031   Top5 99.912109   BatchTime 0.364828   LR 0.000124   
2022-11-25 05:55:47,709 - INFO  - Training [32][   60/  196]   Loss 0.215885   Top1 92.773438   Top5 99.895833   BatchTime 0.357796   LR 0.000124   
2022-11-25 05:55:53,243 - INFO  - Training [32][   80/  196]   Loss 0.218460   Top1 92.729492   Top5 99.877930   BatchTime 0.337516   LR 0.000124   
2022-11-25 05:55:58,672 - INFO  - Training [32][  100/  196]   Loss 0.217456   Top1 92.691406   Top5 99.882812   BatchTime 0.324305   LR 0.000124   
2022-11-25 05:56:04,808 - INFO  - Training [32][  120/  196]   Loss 0.217795   Top1 92.666016   Top5 99.886068   BatchTime 0.321386   LR 0.000124   
2022-11-25 05:56:11,368 - INFO  - Training [32][  140/  196]   Loss 0.217247   Top1 92.675781   Top5 99.893973   BatchTime 0.322328   LR 0.000124   
2022-11-25 05:56:17,632 - INFO  - Training [32][  160/  196]   Loss 0.215428   Top1 92.690430   Top5 99.902344   BatchTime 0.321187   LR 0.000123   
2022-11-25 05:56:24,159 - INFO  - Training [32][  180/  196]   Loss 0.216587   Top1 92.638889   Top5 99.902344   BatchTime 0.321761   LR 0.000123   
2022-11-25 05:56:29,602 - INFO  - ==> Top1: 92.572    Top5: 99.908    Loss: 0.219

2022-11-25 05:56:29,773 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:56:30,893 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:56:33,335 - INFO  - Validation [32][   20/   40]   Loss 0.411099   Top1 87.128906   Top5 99.453125   BatchTime 0.122003   
2022-11-25 05:56:34,433 - INFO  - Validation [32][   40/   40]   Loss 0.394178   Top1 87.410000   Top5 99.510000   BatchTime 0.088479   
2022-11-25 05:56:34,639 - INFO  - ==> Top1: 87.410    Top5: 99.510    Loss: 0.394

2022-11-25 05:56:34,639 - INFO  - ==> Sparsity : 0.589

2022-11-25 05:56:34,639 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 05:56:34,639 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 05:56:34,640 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 05:56:34,941 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:56:34,943 - INFO  - >>>>>> Epoch  33
2022-11-25 05:56:34,944 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:56:42,533 - INFO  - Training [33][   20/  196]   Loss 0.219194   Top1 92.617188   Top5 99.824219   BatchTime 0.379304   LR 0.000123   
2022-11-25 05:56:48,872 - INFO  - Training [33][   40/  196]   Loss 0.214230   Top1 92.714844   Top5 99.882812   BatchTime 0.348131   LR 0.000123   
2022-11-25 05:56:55,314 - INFO  - Training [33][   60/  196]   Loss 0.206499   Top1 93.020833   Top5 99.902344   BatchTime 0.339444   LR 0.000123   
2022-11-25 05:57:02,152 - INFO  - Training [33][   80/  196]   Loss 0.202928   Top1 93.188477   Top5 99.907227   BatchTime 0.340061   LR 0.000123   
2022-11-25 05:57:08,731 - INFO  - Training [33][  100/  196]   Loss 0.204400   Top1 93.042969   Top5 99.902344   BatchTime 0.337833   LR 0.000123   
2022-11-25 05:57:15,090 - INFO  - Training [33][  120/  196]   Loss 0.205815   Top1 92.985026   Top5 99.899089   BatchTime 0.334524   LR 0.000123   
2022-11-25 05:57:21,975 - INFO  - Training [33][  140/  196]   Loss 0.207742   Top1 92.957589   Top5 99.891183   BatchTime 0.335914   LR 0.000122   
2022-11-25 05:57:28,627 - INFO  - Training [33][  160/  196]   Loss 0.208320   Top1 92.990723   Top5 99.885254   BatchTime 0.335499   LR 0.000122   
2022-11-25 05:57:35,264 - INFO  - Training [33][  180/  196]   Loss 0.210551   Top1 92.918837   Top5 99.891493   BatchTime 0.335088   LR 0.000122   
2022-11-25 05:57:39,687 - INFO  - ==> Top1: 92.886    Top5: 99.886    Loss: 0.211

2022-11-25 05:57:39,887 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:57:41,365 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:57:43,747 - INFO  - Validation [33][   20/   40]   Loss 0.395951   Top1 87.753906   Top5 99.433594   BatchTime 0.119044   
2022-11-25 05:57:44,824 - INFO  - Validation [33][   40/   40]   Loss 0.387605   Top1 87.750000   Top5 99.510000   BatchTime 0.086448   
2022-11-25 05:57:45,044 - INFO  - ==> Top1: 87.750    Top5: 99.510    Loss: 0.388

2022-11-25 05:57:45,044 - INFO  - ==> Sparsity : 0.588

2022-11-25 05:57:45,045 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 05:57:45,045 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 05:57:45,045 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 05:57:45,205 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:57:45,207 - INFO  - >>>>>> Epoch  34
2022-11-25 05:57:45,209 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:57:52,467 - INFO  - Training [34][   20/  196]   Loss 0.197557   Top1 93.535156   Top5 99.882812   BatchTime 0.362790   LR 0.000122   
2022-11-25 05:57:58,925 - INFO  - Training [34][   40/  196]   Loss 0.203903   Top1 93.164062   Top5 99.892578   BatchTime 0.342840   LR 0.000122   
2022-11-25 05:58:05,196 - INFO  - Training [34][   60/  196]   Loss 0.206187   Top1 92.981771   Top5 99.889323   BatchTime 0.333063   LR 0.000121   
2022-11-25 05:58:12,130 - INFO  - Training [34][   80/  196]   Loss 0.205778   Top1 93.041992   Top5 99.892578   BatchTime 0.336483   LR 0.000121   
2022-11-25 05:58:18,301 - INFO  - Training [34][  100/  196]   Loss 0.208471   Top1 92.890625   Top5 99.882812   BatchTime 0.330887   LR 0.000121   
2022-11-25 05:58:24,509 - INFO  - Training [34][  120/  196]   Loss 0.207185   Top1 92.942708   Top5 99.889323   BatchTime 0.327474   LR 0.000121   
2022-11-25 05:58:31,158 - INFO  - Training [34][  140/  196]   Loss 0.208321   Top1 92.865513   Top5 99.888393   BatchTime 0.328187   LR 0.000121   
2022-11-25 05:58:37,343 - INFO  - Training [34][  160/  196]   Loss 0.208886   Top1 92.895508   Top5 99.887695   BatchTime 0.325819   LR 0.000121   
2022-11-25 05:58:44,090 - INFO  - Training [34][  180/  196]   Loss 0.208764   Top1 92.894965   Top5 99.893663   BatchTime 0.327102   LR 0.000120   
2022-11-25 05:58:49,534 - INFO  - ==> Top1: 92.886    Top5: 99.894    Loss: 0.209

2022-11-25 05:58:49,735 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:58:51,222 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 05:58:53,611 - INFO  - Validation [34][   20/   40]   Loss 0.393624   Top1 87.832031   Top5 99.335938   BatchTime 0.119368   
2022-11-25 05:58:54,717 - INFO  - Validation [34][   40/   40]   Loss 0.385077   Top1 87.910000   Top5 99.580000   BatchTime 0.087339   
2022-11-25 05:58:54,924 - INFO  - ==> Top1: 87.910    Top5: 99.580    Loss: 0.385

2022-11-25 05:58:54,924 - INFO  - ==> Sparsity : 0.590

2022-11-25 05:58:54,925 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 05:58:54,925 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 05:58:54,926 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 05:58:55,111 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 05:58:55,112 - INFO  - >>>>>> Epoch  35
2022-11-25 05:58:55,114 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 05:59:02,771 - INFO  - Training [35][   20/  196]   Loss 0.184891   Top1 93.671875   Top5 99.902344   BatchTime 0.382667   LR 0.000120   
2022-11-25 05:59:08,930 - INFO  - Training [35][   40/  196]   Loss 0.179389   Top1 93.984375   Top5 99.912109   BatchTime 0.345328   LR 0.000120   
2022-11-25 05:59:15,611 - INFO  - Training [35][   60/  196]   Loss 0.183309   Top1 93.860677   Top5 99.889323   BatchTime 0.341553   LR 0.000120   
2022-11-25 05:59:21,602 - INFO  - Training [35][   80/  196]   Loss 0.187035   Top1 93.686523   Top5 99.887695   BatchTime 0.331058   LR 0.000119   
2022-11-25 05:59:27,301 - INFO  - Training [35][  100/  196]   Loss 0.189361   Top1 93.554688   Top5 99.898438   BatchTime 0.321832   LR 0.000119   
2022-11-25 05:59:33,702 - INFO  - Training [35][  120/  196]   Loss 0.191193   Top1 93.564453   Top5 99.895833   BatchTime 0.321533   LR 0.000119   
2022-11-25 05:59:39,687 - INFO  - Training [35][  140/  196]   Loss 0.191162   Top1 93.596540   Top5 99.905134   BatchTime 0.318350   LR 0.000119   
2022-11-25 05:59:45,459 - INFO  - Training [35][  160/  196]   Loss 0.192421   Top1 93.554688   Top5 99.904785   BatchTime 0.314634   LR 0.000119   
2022-11-25 05:59:51,957 - INFO  - Training [35][  180/  196]   Loss 0.193589   Top1 93.511285   Top5 99.900174   BatchTime 0.315772   LR 0.000118   
2022-11-25 05:59:57,048 - INFO  - ==> Top1: 93.482    Top5: 99.900    Loss: 0.194

2022-11-25 05:59:57,194 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 05:59:58,238 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:00:00,969 - INFO  - Validation [35][   20/   40]   Loss 0.425656   Top1 87.128906   Top5 99.296875   BatchTime 0.136454   
2022-11-25 06:00:02,085 - INFO  - Validation [35][   40/   40]   Loss 0.426009   Top1 86.960000   Top5 99.510000   BatchTime 0.096155   
2022-11-25 06:00:02,314 - INFO  - ==> Top1: 86.960    Top5: 99.510    Loss: 0.426

2022-11-25 06:00:02,314 - INFO  - ==> Sparsity : 0.590

2022-11-25 06:00:02,315 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:00:02,315 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:00:02,315 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:00:02,429 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:00:02,431 - INFO  - >>>>>> Epoch  36
2022-11-25 06:00:02,433 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:00:09,300 - INFO  - Training [36][   20/  196]   Loss 0.228916   Top1 92.089844   Top5 99.765625   BatchTime 0.343229   LR 0.000118   
2022-11-25 06:00:15,970 - INFO  - Training [36][   40/  196]   Loss 0.215392   Top1 92.724609   Top5 99.843750   BatchTime 0.338368   LR 0.000118   
2022-11-25 06:00:22,408 - INFO  - Training [36][   60/  196]   Loss 0.209597   Top1 92.936198   Top5 99.869792   BatchTime 0.332888   LR 0.000117   
2022-11-25 06:00:28,947 - INFO  - Training [36][   80/  196]   Loss 0.206867   Top1 93.061523   Top5 99.877930   BatchTime 0.331399   LR 0.000117   
2022-11-25 06:00:35,581 - INFO  - Training [36][  100/  196]   Loss 0.203208   Top1 93.183594   Top5 99.878906   BatchTime 0.331457   LR 0.000117   
2022-11-25 06:00:42,275 - INFO  - Training [36][  120/  196]   Loss 0.200672   Top1 93.268229   Top5 99.879557   BatchTime 0.332001   LR 0.000117   
2022-11-25 06:00:48,624 - INFO  - Training [36][  140/  196]   Loss 0.198845   Top1 93.339844   Top5 99.896763   BatchTime 0.329919   LR 0.000117   
2022-11-25 06:00:54,816 - INFO  - Training [36][  160/  196]   Loss 0.198025   Top1 93.395996   Top5 99.899902   BatchTime 0.327375   LR 0.000116   
2022-11-25 06:01:01,433 - INFO  - Training [36][  180/  196]   Loss 0.196347   Top1 93.457031   Top5 99.900174   BatchTime 0.327765   LR 0.000116   
2022-11-25 06:01:06,912 - INFO  - ==> Top1: 93.408    Top5: 99.902    Loss: 0.198

2022-11-25 06:01:07,088 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:01:08,215 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:01:10,609 - INFO  - Validation [36][   20/   40]   Loss 0.429981   Top1 87.304688   Top5 99.414062   BatchTime 0.119631   
2022-11-25 06:01:11,662 - INFO  - Validation [36][   40/   40]   Loss 0.415008   Top1 87.370000   Top5 99.540000   BatchTime 0.086126   
2022-11-25 06:01:11,884 - INFO  - ==> Top1: 87.370    Top5: 99.540    Loss: 0.415

2022-11-25 06:01:11,884 - INFO  - ==> Sparsity : 0.595

2022-11-25 06:01:11,885 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:01:11,885 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:01:11,885 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:01:12,009 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:01:12,010 - INFO  - >>>>>> Epoch  37
2022-11-25 06:01:12,012 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:01:18,058 - INFO  - Training [37][   20/  196]   Loss 0.188318   Top1 93.417969   Top5 99.960938   BatchTime 0.302198   LR 0.000116   
2022-11-25 06:01:23,333 - INFO  - Training [37][   40/  196]   Loss 0.185405   Top1 93.720703   Top5 99.912109   BatchTime 0.282960   LR 0.000115   
2022-11-25 06:01:28,553 - INFO  - Training [37][   60/  196]   Loss 0.189681   Top1 93.548177   Top5 99.921875   BatchTime 0.275646   LR 0.000115   
2022-11-25 06:01:34,176 - INFO  - Training [37][   80/  196]   Loss 0.188313   Top1 93.554688   Top5 99.921875   BatchTime 0.277014   LR 0.000115   
2022-11-25 06:01:40,388 - INFO  - Training [37][  100/  196]   Loss 0.190667   Top1 93.445312   Top5 99.910156   BatchTime 0.283731   LR 0.000114   
2022-11-25 06:01:46,304 - INFO  - Training [37][  120/  196]   Loss 0.190915   Top1 93.430990   Top5 99.895833   BatchTime 0.285744   LR 0.000114   
2022-11-25 06:01:52,415 - INFO  - Training [37][  140/  196]   Loss 0.191127   Top1 93.443080   Top5 99.893973   BatchTime 0.288575   LR 0.000114   
2022-11-25 06:01:58,728 - INFO  - Training [37][  160/  196]   Loss 0.190577   Top1 93.449707   Top5 99.890137   BatchTime 0.291956   LR 0.000114   
2022-11-25 06:02:03,802 - INFO  - Training [37][  180/  196]   Loss 0.190436   Top1 93.467882   Top5 99.898003   BatchTime 0.287705   LR 0.000113   
2022-11-25 06:02:07,961 - INFO  - ==> Top1: 93.480    Top5: 99.904    Loss: 0.190

2022-11-25 06:02:08,154 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:02:09,208 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:02:11,646 - INFO  - Validation [37][   20/   40]   Loss 0.420303   Top1 87.578125   Top5 99.531250   BatchTime 0.121806   
2022-11-25 06:02:12,797 - INFO  - Validation [37][   40/   40]   Loss 0.409032   Top1 87.560000   Top5 99.610000   BatchTime 0.089683   
2022-11-25 06:02:13,016 - INFO  - ==> Top1: 87.560    Top5: 99.610    Loss: 0.409

2022-11-25 06:02:13,017 - INFO  - ==> Sparsity : 0.601

2022-11-25 06:02:13,017 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:02:13,017 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:02:13,017 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:02:13,172 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:02:13,173 - INFO  - >>>>>> Epoch  38
2022-11-25 06:02:13,175 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:02:20,345 - INFO  - Training [38][   20/  196]   Loss 0.179997   Top1 93.906250   Top5 99.980469   BatchTime 0.358331   LR 0.000113   
2022-11-25 06:02:27,220 - INFO  - Training [38][   40/  196]   Loss 0.184865   Top1 93.857422   Top5 99.882812   BatchTime 0.351046   LR 0.000112   
2022-11-25 06:02:33,921 - INFO  - Training [38][   60/  196]   Loss 0.182092   Top1 93.932292   Top5 99.902344   BatchTime 0.345706   LR 0.000112   
2022-11-25 06:02:40,240 - INFO  - Training [38][   80/  196]   Loss 0.180664   Top1 93.969727   Top5 99.916992   BatchTime 0.338276   LR 0.000112   
2022-11-25 06:02:46,391 - INFO  - Training [38][  100/  196]   Loss 0.183936   Top1 93.859375   Top5 99.906250   BatchTime 0.332120   LR 0.000112   
2022-11-25 06:02:52,784 - INFO  - Training [38][  120/  196]   Loss 0.184997   Top1 93.873698   Top5 99.895833   BatchTime 0.330046   LR 0.000111   
2022-11-25 06:03:00,115 - INFO  - Training [38][  140/  196]   Loss 0.185538   Top1 93.833705   Top5 99.905134   BatchTime 0.335259   LR 0.000111   
2022-11-25 06:03:06,811 - INFO  - Training [38][  160/  196]   Loss 0.185661   Top1 93.793945   Top5 99.904785   BatchTime 0.335203   LR 0.000111   
2022-11-25 06:03:13,449 - INFO  - Training [38][  180/  196]   Loss 0.187383   Top1 93.728299   Top5 99.902344   BatchTime 0.334837   LR 0.000110   
2022-11-25 06:03:18,891 - INFO  - ==> Top1: 93.708    Top5: 99.910    Loss: 0.187

2022-11-25 06:03:19,101 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:03:20,457 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:03:22,791 - INFO  - Validation [38][   20/   40]   Loss 0.416638   Top1 87.363281   Top5 99.453125   BatchTime 0.116651   
2022-11-25 06:03:23,721 - INFO  - Validation [38][   40/   40]   Loss 0.405427   Top1 87.680000   Top5 99.540000   BatchTime 0.081579   
2022-11-25 06:03:23,997 - INFO  - ==> Top1: 87.680    Top5: 99.540    Loss: 0.405

2022-11-25 06:03:23,997 - INFO  - ==> Sparsity : 0.605

2022-11-25 06:03:23,998 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:03:23,998 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:03:23,998 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:03:24,160 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:03:24,162 - INFO  - >>>>>> Epoch  39
2022-11-25 06:03:24,163 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:03:31,799 - INFO  - Training [39][   20/  196]   Loss 0.188447   Top1 93.652344   Top5 99.941406   BatchTime 0.381629   LR 0.000110   
2022-11-25 06:03:37,146 - INFO  - Training [39][   40/  196]   Loss 0.179852   Top1 93.916016   Top5 99.941406   BatchTime 0.324485   LR 0.000109   
2022-11-25 06:03:42,583 - INFO  - Training [39][   60/  196]   Loss 0.174988   Top1 94.134115   Top5 99.947917   BatchTime 0.306950   LR 0.000109   
2022-11-25 06:03:47,902 - INFO  - Training [39][   80/  196]   Loss 0.174535   Top1 94.057617   Top5 99.946289   BatchTime 0.296691   LR 0.000109   
2022-11-25 06:03:53,529 - INFO  - Training [39][  100/  196]   Loss 0.176194   Top1 93.980469   Top5 99.941406   BatchTime 0.293621   LR 0.000108   
2022-11-25 06:03:59,453 - INFO  - Training [39][  120/  196]   Loss 0.176492   Top1 93.945312   Top5 99.921875   BatchTime 0.294054   LR 0.000108   
2022-11-25 06:04:05,979 - INFO  - Training [39][  140/  196]   Loss 0.176819   Top1 93.914621   Top5 99.921875   BatchTime 0.298659   LR 0.000108   
2022-11-25 06:04:11,599 - INFO  - Training [39][  160/  196]   Loss 0.179312   Top1 93.867188   Top5 99.914551   BatchTime 0.296454   LR 0.000107   
2022-11-25 06:04:16,878 - INFO  - Training [39][  180/  196]   Loss 0.180873   Top1 93.823785   Top5 99.919705   BatchTime 0.292838   LR 0.000107   
2022-11-25 06:04:21,541 - INFO  - ==> Top1: 93.798    Top5: 99.912    Loss: 0.182

2022-11-25 06:04:21,727 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:04:22,863 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:04:25,182 - INFO  - Validation [39][   20/   40]   Loss 0.402868   Top1 87.949219   Top5 99.550781   BatchTime 0.115848   
2022-11-25 06:04:26,303 - INFO  - Validation [39][   40/   40]   Loss 0.392631   Top1 87.920000   Top5 99.640000   BatchTime 0.085962   
2022-11-25 06:04:26,526 - INFO  - ==> Top1: 87.920    Top5: 99.640    Loss: 0.393

2022-11-25 06:04:26,526 - INFO  - ==> Sparsity : 0.607

2022-11-25 06:04:26,526 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:04:26,527 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:04:26,527 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:04:26,898 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:04:26,900 - INFO  - >>>>>> Epoch  40
2022-11-25 06:04:26,902 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:04:34,057 - INFO  - Training [40][   20/  196]   Loss 0.178451   Top1 94.121094   Top5 99.902344   BatchTime 0.357645   LR 0.000106   
2022-11-25 06:04:39,983 - INFO  - Training [40][   40/  196]   Loss 0.174120   Top1 94.238281   Top5 99.892578   BatchTime 0.326968   LR 0.000106   
2022-11-25 06:04:45,853 - INFO  - Training [40][   60/  196]   Loss 0.179055   Top1 94.016927   Top5 99.908854   BatchTime 0.315808   LR 0.000106   
2022-11-25 06:04:52,288 - INFO  - Training [40][   80/  196]   Loss 0.176022   Top1 94.052734   Top5 99.916992   BatchTime 0.317289   LR 0.000105   
2022-11-25 06:04:58,349 - INFO  - Training [40][  100/  196]   Loss 0.176127   Top1 94.027344   Top5 99.914062   BatchTime 0.314444   LR 0.000105   
2022-11-25 06:05:04,717 - INFO  - Training [40][  120/  196]   Loss 0.175672   Top1 94.013672   Top5 99.905599   BatchTime 0.315103   LR 0.000105   
2022-11-25 06:05:11,140 - INFO  - Training [40][  140/  196]   Loss 0.174545   Top1 94.040179   Top5 99.913504   BatchTime 0.315964   LR 0.000104   
2022-11-25 06:05:17,911 - INFO  - Training [40][  160/  196]   Loss 0.174192   Top1 94.052734   Top5 99.912109   BatchTime 0.318785   LR 0.000104   
2022-11-25 06:05:24,629 - INFO  - Training [40][  180/  196]   Loss 0.175333   Top1 93.993056   Top5 99.911024   BatchTime 0.320688   LR 0.000103   
2022-11-25 06:05:28,939 - INFO  - ==> Top1: 93.972    Top5: 99.912    Loss: 0.175

2022-11-25 06:05:29,098 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:05:30,095 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:05:32,544 - INFO  - Validation [40][   20/   40]   Loss 0.421467   Top1 87.636719   Top5 99.414062   BatchTime 0.122376   
2022-11-25 06:05:33,634 - INFO  - Validation [40][   40/   40]   Loss 0.408596   Top1 87.900000   Top5 99.510000   BatchTime 0.088442   
2022-11-25 06:05:33,866 - INFO  - ==> Top1: 87.900    Top5: 99.510    Loss: 0.409

2022-11-25 06:05:33,866 - INFO  - ==> Sparsity : 0.605

2022-11-25 06:05:33,867 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:05:33,867 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:05:33,867 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:05:34,014 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:05:34,016 - INFO  - >>>>>> Epoch  41
2022-11-25 06:05:34,017 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:05:41,736 - INFO  - Training [41][   20/  196]   Loss 0.169991   Top1 94.277344   Top5 99.863281   BatchTime 0.385799   LR 0.000103   
2022-11-25 06:05:48,304 - INFO  - Training [41][   40/  196]   Loss 0.164439   Top1 94.541016   Top5 99.863281   BatchTime 0.357084   LR 0.000102   
2022-11-25 06:05:54,697 - INFO  - Training [41][   60/  196]   Loss 0.164424   Top1 94.563802   Top5 99.882812   BatchTime 0.344613   LR 0.000102   
2022-11-25 06:06:00,374 - INFO  - Training [41][   80/  196]   Loss 0.164760   Top1 94.589844   Top5 99.907227   BatchTime 0.329425   LR 0.000102   
2022-11-25 06:06:06,613 - INFO  - Training [41][  100/  196]   Loss 0.165490   Top1 94.527344   Top5 99.914062   BatchTime 0.325931   LR 0.000101   
2022-11-25 06:06:12,915 - INFO  - Training [41][  120/  196]   Loss 0.166016   Top1 94.492188   Top5 99.902344   BatchTime 0.324124   LR 0.000101   
2022-11-25 06:06:19,049 - INFO  - Training [41][  140/  196]   Loss 0.166862   Top1 94.450335   Top5 99.910714   BatchTime 0.321629   LR 0.000100   
2022-11-25 06:06:25,139 - INFO  - Training [41][  160/  196]   Loss 0.168570   Top1 94.382324   Top5 99.914551   BatchTime 0.319490   LR 0.000100   
2022-11-25 06:06:30,558 - INFO  - Training [41][  180/  196]   Loss 0.168723   Top1 94.379340   Top5 99.915365   BatchTime 0.314095   LR 0.000100   
2022-11-25 06:06:34,721 - INFO  - ==> Top1: 94.414    Top5: 99.918    Loss: 0.168

2022-11-25 06:06:34,924 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:06:36,673 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:06:39,039 - INFO  - Validation [41][   20/   40]   Loss 0.397664   Top1 88.359375   Top5 99.550781   BatchTime 0.118232   
2022-11-25 06:06:40,127 - INFO  - Validation [41][   40/   40]   Loss 0.388085   Top1 88.310000   Top5 99.690000   BatchTime 0.086319   
2022-11-25 06:06:40,369 - INFO  - ==> Top1: 88.310    Top5: 99.690    Loss: 0.388

2022-11-25 06:06:40,369 - INFO  - ==> Sparsity : 0.606

2022-11-25 06:06:40,369 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:06:40,370 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:06:40,370 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:06:40,530 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:06:40,531 - INFO  - >>>>>> Epoch  42
2022-11-25 06:06:40,533 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:06:47,454 - INFO  - Training [42][   20/  196]   Loss 0.161167   Top1 94.433594   Top5 99.882812   BatchTime 0.345875   LR 0.000099   
2022-11-25 06:06:53,634 - INFO  - Training [42][   40/  196]   Loss 0.164565   Top1 94.335938   Top5 99.912109   BatchTime 0.327447   LR 0.000098   
2022-11-25 06:06:59,962 - INFO  - Training [42][   60/  196]   Loss 0.168304   Top1 94.199219   Top5 99.915365   BatchTime 0.323757   LR 0.000098   
2022-11-25 06:07:05,925 - INFO  - Training [42][   80/  196]   Loss 0.170014   Top1 94.213867   Top5 99.912109   BatchTime 0.317354   LR 0.000098   
2022-11-25 06:07:11,804 - INFO  - Training [42][  100/  196]   Loss 0.169430   Top1 94.281250   Top5 99.921875   BatchTime 0.312681   LR 0.000097   
2022-11-25 06:07:17,741 - INFO  - Training [42][  120/  196]   Loss 0.167667   Top1 94.316406   Top5 99.912109   BatchTime 0.310038   LR 0.000097   
2022-11-25 06:07:23,163 - INFO  - Training [42][  140/  196]   Loss 0.167538   Top1 94.321987   Top5 99.921875   BatchTime 0.304475   LR 0.000096   
2022-11-25 06:07:28,250 - INFO  - Training [42][  160/  196]   Loss 0.169302   Top1 94.267578   Top5 99.912109   BatchTime 0.298210   LR 0.000096   
2022-11-25 06:07:32,970 - INFO  - Training [42][  180/  196]   Loss 0.170796   Top1 94.249132   Top5 99.911024   BatchTime 0.291297   LR 0.000096   
2022-11-25 06:07:37,147 - INFO  - ==> Top1: 94.178    Top5: 99.918    Loss: 0.172

2022-11-25 06:07:37,323 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:07:38,407 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:07:40,910 - INFO  - Validation [42][   20/   40]   Loss 0.404831   Top1 87.988281   Top5 99.414062   BatchTime 0.125015   
2022-11-25 06:07:41,957 - INFO  - Validation [42][   40/   40]   Loss 0.390583   Top1 87.990000   Top5 99.590000   BatchTime 0.088700   
2022-11-25 06:07:42,145 - INFO  - ==> Top1: 87.990    Top5: 99.590    Loss: 0.391

2022-11-25 06:07:42,145 - INFO  - ==> Sparsity : 0.608

2022-11-25 06:07:42,145 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:07:42,146 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:07:42,146 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:07:42,274 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:07:42,275 - INFO  - >>>>>> Epoch  43
2022-11-25 06:07:42,277 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:07:50,381 - INFO  - Training [43][   20/  196]   Loss 0.153203   Top1 95.019531   Top5 99.960938   BatchTime 0.405071   LR 0.000095   
2022-11-25 06:07:56,347 - INFO  - Training [43][   40/  196]   Loss 0.153021   Top1 95.087891   Top5 99.941406   BatchTime 0.351705   LR 0.000094   
2022-11-25 06:08:01,609 - INFO  - Training [43][   60/  196]   Loss 0.159667   Top1 94.837240   Top5 99.960938   BatchTime 0.322166   LR 0.000094   
2022-11-25 06:08:07,592 - INFO  - Training [43][   80/  196]   Loss 0.157612   Top1 94.868164   Top5 99.956055   BatchTime 0.316414   LR 0.000093   
2022-11-25 06:08:13,960 - INFO  - Training [43][  100/  196]   Loss 0.156834   Top1 94.839844   Top5 99.957031   BatchTime 0.316801   LR 0.000093   
2022-11-25 06:08:19,598 - INFO  - Training [43][  120/  196]   Loss 0.155599   Top1 94.886068   Top5 99.957682   BatchTime 0.310985   LR 0.000093   
2022-11-25 06:08:25,660 - INFO  - Training [43][  140/  196]   Loss 0.155804   Top1 94.810268   Top5 99.955357   BatchTime 0.309859   LR 0.000092   
2022-11-25 06:08:32,102 - INFO  - Training [43][  160/  196]   Loss 0.157570   Top1 94.704590   Top5 99.946289   BatchTime 0.311392   LR 0.000092   
2022-11-25 06:08:38,801 - INFO  - Training [43][  180/  196]   Loss 0.159210   Top1 94.663628   Top5 99.934896   BatchTime 0.314008   LR 0.000091   
2022-11-25 06:08:44,589 - INFO  - ==> Top1: 94.686    Top5: 99.936    Loss: 0.160

2022-11-25 06:08:44,762 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:08:45,872 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:08:48,302 - INFO  - Validation [43][   20/   40]   Loss 0.402199   Top1 87.675781   Top5 99.628906   BatchTime 0.121403   
2022-11-25 06:08:49,378 - INFO  - Validation [43][   40/   40]   Loss 0.386736   Top1 88.420000   Top5 99.700000   BatchTime 0.087623   
2022-11-25 06:08:49,621 - INFO  - ==> Top1: 88.420    Top5: 99.700    Loss: 0.387

2022-11-25 06:08:49,621 - INFO  - ==> Sparsity : 0.611

2022-11-25 06:08:49,622 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:08:49,622 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:08:49,622 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:08:49,789 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:08:49,790 - INFO  - >>>>>> Epoch  44
2022-11-25 06:08:49,792 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:08:57,866 - INFO  - Training [44][   20/  196]   Loss 0.135496   Top1 95.449219   Top5 99.980469   BatchTime 0.403536   LR 0.000090   
2022-11-25 06:09:03,848 - INFO  - Training [44][   40/  196]   Loss 0.138572   Top1 95.302734   Top5 99.980469   BatchTime 0.351334   LR 0.000090   
2022-11-25 06:09:10,307 - INFO  - Training [44][   60/  196]   Loss 0.144504   Top1 95.123698   Top5 99.967448   BatchTime 0.341863   LR 0.000090   
2022-11-25 06:09:16,616 - INFO  - Training [44][   80/  196]   Loss 0.144300   Top1 95.195312   Top5 99.970703   BatchTime 0.335255   LR 0.000089   
2022-11-25 06:09:22,316 - INFO  - Training [44][  100/  196]   Loss 0.147364   Top1 95.062500   Top5 99.968750   BatchTime 0.325205   LR 0.000089   
2022-11-25 06:09:27,564 - INFO  - Training [44][  120/  196]   Loss 0.149498   Top1 94.967448   Top5 99.960938   BatchTime 0.314734   LR 0.000088   
2022-11-25 06:09:32,944 - INFO  - Training [44][  140/  196]   Loss 0.151053   Top1 94.913504   Top5 99.958147   BatchTime 0.308203   LR 0.000088   
2022-11-25 06:09:39,289 - INFO  - Training [44][  160/  196]   Loss 0.150598   Top1 94.914551   Top5 99.953613   BatchTime 0.309331   LR 0.000087   
2022-11-25 06:09:45,551 - INFO  - Training [44][  180/  196]   Loss 0.151114   Top1 94.895833   Top5 99.950087   BatchTime 0.309753   LR 0.000087   
2022-11-25 06:09:51,085 - INFO  - ==> Top1: 94.864    Top5: 99.950    Loss: 0.152

2022-11-25 06:09:51,248 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:09:52,270 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:09:54,892 - INFO  - Validation [44][   20/   40]   Loss 0.413549   Top1 87.695312   Top5 99.531250   BatchTime 0.130964   
2022-11-25 06:09:55,951 - INFO  - Validation [44][   40/   40]   Loss 0.398916   Top1 88.080000   Top5 99.620000   BatchTime 0.091961   
2022-11-25 06:09:56,157 - INFO  - ==> Top1: 88.080    Top5: 99.620    Loss: 0.399

2022-11-25 06:09:56,157 - INFO  - ==> Sparsity : 0.623

2022-11-25 06:09:56,157 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:09:56,157 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:09:56,157 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:09:56,318 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:09:56,319 - INFO  - >>>>>> Epoch  45
2022-11-25 06:09:56,321 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:10:03,885 - INFO  - Training [45][   20/  196]   Loss 0.158253   Top1 94.843750   Top5 99.921875   BatchTime 0.378030   LR 0.000086   
2022-11-25 06:10:10,272 - INFO  - Training [45][   40/  196]   Loss 0.146981   Top1 95.156250   Top5 99.951172   BatchTime 0.348709   LR 0.000086   
2022-11-25 06:10:16,069 - INFO  - Training [45][   60/  196]   Loss 0.145962   Top1 95.091146   Top5 99.967448   BatchTime 0.329073   LR 0.000085   
2022-11-25 06:10:22,241 - INFO  - Training [45][   80/  196]   Loss 0.149586   Top1 94.941406   Top5 99.956055   BatchTime 0.323964   LR 0.000085   
2022-11-25 06:10:28,395 - INFO  - Training [45][  100/  196]   Loss 0.148351   Top1 95.039062   Top5 99.957031   BatchTime 0.320707   LR 0.000084   
2022-11-25 06:10:34,775 - INFO  - Training [45][  120/  196]   Loss 0.146397   Top1 95.117188   Top5 99.960938   BatchTime 0.320417   LR 0.000084   
2022-11-25 06:10:40,795 - INFO  - Training [45][  140/  196]   Loss 0.147292   Top1 95.108817   Top5 99.944196   BatchTime 0.317645   LR 0.000083   
2022-11-25 06:10:47,058 - INFO  - Training [45][  160/  196]   Loss 0.147214   Top1 95.087891   Top5 99.938965   BatchTime 0.317082   LR 0.000083   
2022-11-25 06:10:53,422 - INFO  - Training [45][  180/  196]   Loss 0.148111   Top1 95.036892   Top5 99.941406   BatchTime 0.317209   LR 0.000082   
2022-11-25 06:10:58,779 - INFO  - ==> Top1: 95.018    Top5: 99.940    Loss: 0.149

2022-11-25 06:10:58,990 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:11:00,442 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:11:02,868 - INFO  - Validation [45][   20/   40]   Loss 0.408868   Top1 88.203125   Top5 99.433594   BatchTime 0.121189   
2022-11-25 06:11:04,013 - INFO  - Validation [45][   40/   40]   Loss 0.396730   Top1 88.290000   Top5 99.550000   BatchTime 0.089212   
2022-11-25 06:11:04,214 - INFO  - ==> Top1: 88.290    Top5: 99.550    Loss: 0.397

2022-11-25 06:11:04,214 - INFO  - ==> Sparsity : 0.625

2022-11-25 06:11:04,215 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:11:04,215 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:11:04,215 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:11:04,334 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:11:04,335 - INFO  - >>>>>> Epoch  46
2022-11-25 06:11:04,337 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:11:12,432 - INFO  - Training [46][   20/  196]   Loss 0.145724   Top1 95.273438   Top5 99.921875   BatchTime 0.404626   LR 0.000081   
2022-11-25 06:11:18,623 - INFO  - Training [46][   40/  196]   Loss 0.146043   Top1 95.195312   Top5 99.941406   BatchTime 0.357091   LR 0.000081   
2022-11-25 06:11:24,374 - INFO  - Training [46][   60/  196]   Loss 0.140800   Top1 95.338542   Top5 99.960938   BatchTime 0.333915   LR 0.000080   
2022-11-25 06:11:30,598 - INFO  - Training [46][   80/  196]   Loss 0.142914   Top1 95.327148   Top5 99.960938   BatchTime 0.328225   LR 0.000080   
2022-11-25 06:11:37,602 - INFO  - Training [46][  100/  196]   Loss 0.141699   Top1 95.292969   Top5 99.960938   BatchTime 0.332628   LR 0.000079   
2022-11-25 06:11:43,922 - INFO  - Training [46][  120/  196]   Loss 0.139622   Top1 95.358073   Top5 99.967448   BatchTime 0.329848   LR 0.000079   
2022-11-25 06:11:49,833 - INFO  - Training [46][  140/  196]   Loss 0.140698   Top1 95.290179   Top5 99.966518   BatchTime 0.324955   LR 0.000078   
2022-11-25 06:11:55,323 - INFO  - Training [46][  160/  196]   Loss 0.140071   Top1 95.341797   Top5 99.965820   BatchTime 0.318647   LR 0.000078   
2022-11-25 06:12:01,810 - INFO  - Training [46][  180/  196]   Loss 0.140889   Top1 95.314670   Top5 99.967448   BatchTime 0.319278   LR 0.000077   
2022-11-25 06:12:06,638 - INFO  - ==> Top1: 95.276    Top5: 99.966    Loss: 0.142

2022-11-25 06:12:06,814 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:12:08,061 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:12:10,575 - INFO  - Validation [46][   20/   40]   Loss 0.416447   Top1 87.812500   Top5 99.394531   BatchTime 0.125620   
2022-11-25 06:12:11,598 - INFO  - Validation [46][   40/   40]   Loss 0.401948   Top1 88.000000   Top5 99.560000   BatchTime 0.088371   
2022-11-25 06:12:11,809 - INFO  - ==> Top1: 88.000    Top5: 99.560    Loss: 0.402

2022-11-25 06:12:11,809 - INFO  - ==> Sparsity : 0.627

2022-11-25 06:12:11,809 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:12:11,809 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:12:11,810 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:12:11,921 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:12:11,922 - INFO  - >>>>>> Epoch  47
2022-11-25 06:12:11,924 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:12:18,809 - INFO  - Training [47][   20/  196]   Loss 0.132937   Top1 95.742188   Top5 99.960938   BatchTime 0.344114   LR 0.000077   
2022-11-25 06:12:24,481 - INFO  - Training [47][   40/  196]   Loss 0.142011   Top1 95.244141   Top5 99.980469   BatchTime 0.313858   LR 0.000076   
2022-11-25 06:12:31,164 - INFO  - Training [47][   60/  196]   Loss 0.140462   Top1 95.260417   Top5 99.986979   BatchTime 0.320623   LR 0.000076   
2022-11-25 06:12:37,449 - INFO  - Training [47][   80/  196]   Loss 0.137265   Top1 95.405273   Top5 99.960938   BatchTime 0.319027   LR 0.000075   
2022-11-25 06:12:43,312 - INFO  - Training [47][  100/  196]   Loss 0.138728   Top1 95.335938   Top5 99.953125   BatchTime 0.313848   LR 0.000075   
2022-11-25 06:12:49,789 - INFO  - Training [47][  120/  196]   Loss 0.139852   Top1 95.292969   Top5 99.954427   BatchTime 0.315520   LR 0.000074   
2022-11-25 06:12:55,151 - INFO  - Training [47][  140/  196]   Loss 0.139559   Top1 95.290179   Top5 99.952567   BatchTime 0.308747   LR 0.000074   
2022-11-25 06:13:01,421 - INFO  - Training [47][  160/  196]   Loss 0.139820   Top1 95.290527   Top5 99.956055   BatchTime 0.309339   LR 0.000073   
2022-11-25 06:13:08,134 - INFO  - Training [47][  180/  196]   Loss 0.139893   Top1 95.269097   Top5 99.950087   BatchTime 0.312261   LR 0.000073   
2022-11-25 06:13:13,572 - INFO  - ==> Top1: 95.254    Top5: 99.950    Loss: 0.140

2022-11-25 06:13:13,777 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:13:15,121 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:13:17,479 - INFO  - Validation [47][   20/   40]   Loss 0.400892   Top1 88.691406   Top5 99.472656   BatchTime 0.117784   
2022-11-25 06:13:18,605 - INFO  - Validation [47][   40/   40]   Loss 0.382679   Top1 88.690000   Top5 99.660000   BatchTime 0.087051   
2022-11-25 06:13:18,841 - INFO  - ==> Top1: 88.690    Top5: 99.660    Loss: 0.383

2022-11-25 06:13:18,841 - INFO  - ==> Sparsity : 0.629

2022-11-25 06:13:18,842 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:13:18,842 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:13:18,842 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.790   Top5: 99.580]
2022-11-25 06:13:19,003 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:13:19,004 - INFO  - >>>>>> Epoch  48
2022-11-25 06:13:19,006 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:13:26,333 - INFO  - Training [48][   20/  196]   Loss 0.118078   Top1 95.957031   Top5 99.960938   BatchTime 0.366197   LR 0.000072   
2022-11-25 06:13:31,817 - INFO  - Training [48][   40/  196]   Loss 0.122947   Top1 95.859375   Top5 99.980469   BatchTime 0.320211   LR 0.000071   
2022-11-25 06:13:37,066 - INFO  - Training [48][   60/  196]   Loss 0.126623   Top1 95.748698   Top5 99.967448   BatchTime 0.300951   LR 0.000071   
2022-11-25 06:13:43,354 - INFO  - Training [48][   80/  196]   Loss 0.128945   Top1 95.678711   Top5 99.951172   BatchTime 0.304314   LR 0.000070   
2022-11-25 06:13:50,147 - INFO  - Training [48][  100/  196]   Loss 0.130110   Top1 95.625000   Top5 99.960938   BatchTime 0.311380   LR 0.000070   
2022-11-25 06:13:56,756 - INFO  - Training [48][  120/  196]   Loss 0.130728   Top1 95.589193   Top5 99.967448   BatchTime 0.314556   LR 0.000069   
2022-11-25 06:14:02,817 - INFO  - Training [48][  140/  196]   Loss 0.130611   Top1 95.622210   Top5 99.963728   BatchTime 0.312912   LR 0.000069   
2022-11-25 06:14:08,984 - INFO  - Training [48][  160/  196]   Loss 0.130789   Top1 95.664062   Top5 99.960938   BatchTime 0.312340   LR 0.000068   
2022-11-25 06:14:14,624 - INFO  - Training [48][  180/  196]   Loss 0.131142   Top1 95.642361   Top5 99.958767   BatchTime 0.308970   LR 0.000068   
2022-11-25 06:14:19,914 - INFO  - ==> Top1: 95.592    Top5: 99.958    Loss: 0.133

2022-11-25 06:14:20,244 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:14:21,647 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:14:24,113 - INFO  - Validation [48][   20/   40]   Loss 0.405965   Top1 88.593750   Top5 99.511719   BatchTime 0.123230   
2022-11-25 06:14:25,168 - INFO  - Validation [48][   40/   40]   Loss 0.386989   Top1 88.960000   Top5 99.620000   BatchTime 0.088001   
2022-11-25 06:14:25,376 - INFO  - ==> Top1: 88.960    Top5: 99.620    Loss: 0.387

2022-11-25 06:14:25,377 - INFO  - ==> Sparsity : 0.630

2022-11-25 06:14:25,377 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:14:25,377 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:14:25,377 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:14:30,142 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 06:14:30,145 - INFO  - >>>>>> Epoch  49
2022-11-25 06:14:30,147 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:14:36,787 - INFO  - Training [49][   20/  196]   Loss 0.139352   Top1 95.390625   Top5 99.980469   BatchTime 0.331926   LR 0.000067   
2022-11-25 06:14:43,611 - INFO  - Training [49][   40/  196]   Loss 0.133553   Top1 95.683594   Top5 99.970703   BatchTime 0.336552   LR 0.000066   
2022-11-25 06:14:50,488 - INFO  - Training [49][   60/  196]   Loss 0.135404   Top1 95.501302   Top5 99.980469   BatchTime 0.338986   LR 0.000066   
2022-11-25 06:14:56,776 - INFO  - Training [49][   80/  196]   Loss 0.134522   Top1 95.483398   Top5 99.960938   BatchTime 0.332835   LR 0.000065   
2022-11-25 06:15:03,498 - INFO  - Training [49][  100/  196]   Loss 0.132097   Top1 95.585938   Top5 99.968750   BatchTime 0.333491   LR 0.000065   
2022-11-25 06:15:08,909 - INFO  - Training [49][  120/  196]   Loss 0.129008   Top1 95.712891   Top5 99.970703   BatchTime 0.322996   LR 0.000064   
2022-11-25 06:15:14,833 - INFO  - Training [49][  140/  196]   Loss 0.130479   Top1 95.661272   Top5 99.966518   BatchTime 0.319172   LR 0.000064   
2022-11-25 06:15:20,330 - INFO  - Training [49][  160/  196]   Loss 0.129496   Top1 95.661621   Top5 99.968262   BatchTime 0.313625   LR 0.000063   
2022-11-25 06:15:26,935 - INFO  - Training [49][  180/  196]   Loss 0.130176   Top1 95.625000   Top5 99.969618   BatchTime 0.315477   LR 0.000063   
2022-11-25 06:15:32,409 - INFO  - ==> Top1: 95.608    Top5: 99.970    Loss: 0.130

2022-11-25 06:15:32,681 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:15:34,219 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:15:36,491 - INFO  - Validation [49][   20/   40]   Loss 0.392050   Top1 88.593750   Top5 99.589844   BatchTime 0.113516   
2022-11-25 06:15:37,516 - INFO  - Validation [49][   40/   40]   Loss 0.381337   Top1 88.710000   Top5 99.670000   BatchTime 0.082393   
2022-11-25 06:15:37,706 - INFO  - ==> Top1: 88.710    Top5: 99.670    Loss: 0.381

2022-11-25 06:15:37,707 - INFO  - ==> Sparsity : 0.633

2022-11-25 06:15:37,707 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:15:37,707 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:15:37,707 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:15:37,821 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:15:37,823 - INFO  - >>>>>> Epoch  50
2022-11-25 06:15:37,825 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:15:44,854 - INFO  - Training [50][   20/  196]   Loss 0.118484   Top1 96.250000   Top5 99.941406   BatchTime 0.351344   LR 0.000062   
2022-11-25 06:15:50,975 - INFO  - Training [50][   40/  196]   Loss 0.124635   Top1 95.957031   Top5 99.941406   BatchTime 0.328704   LR 0.000062   
2022-11-25 06:15:56,820 - INFO  - Training [50][   60/  196]   Loss 0.121789   Top1 95.944010   Top5 99.960938   BatchTime 0.316548   LR 0.000061   
2022-11-25 06:16:02,473 - INFO  - Training [50][   80/  196]   Loss 0.121580   Top1 96.000977   Top5 99.960938   BatchTime 0.308072   LR 0.000061   
2022-11-25 06:16:09,141 - INFO  - Training [50][  100/  196]   Loss 0.122054   Top1 95.984375   Top5 99.964844   BatchTime 0.313134   LR 0.000060   
2022-11-25 06:16:15,704 - INFO  - Training [50][  120/  196]   Loss 0.123920   Top1 95.911458   Top5 99.967448   BatchTime 0.315638   LR 0.000060   
2022-11-25 06:16:22,507 - INFO  - Training [50][  140/  196]   Loss 0.123891   Top1 95.895647   Top5 99.966518   BatchTime 0.319140   LR 0.000059   
2022-11-25 06:16:28,790 - INFO  - Training [50][  160/  196]   Loss 0.122412   Top1 95.937500   Top5 99.965820   BatchTime 0.318516   LR 0.000059   
2022-11-25 06:16:34,865 - INFO  - Training [50][  180/  196]   Loss 0.122840   Top1 95.928819   Top5 99.963108   BatchTime 0.316875   LR 0.000058   
2022-11-25 06:16:39,974 - INFO  - ==> Top1: 95.930    Top5: 99.964    Loss: 0.123

2022-11-25 06:16:40,147 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:16:41,215 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:16:43,604 - INFO  - Validation [50][   20/   40]   Loss 0.403844   Top1 88.613281   Top5 99.531250   BatchTime 0.119390   
2022-11-25 06:16:44,744 - INFO  - Validation [50][   40/   40]   Loss 0.390018   Top1 88.710000   Top5 99.670000   BatchTime 0.088204   
2022-11-25 06:16:44,941 - INFO  - ==> Top1: 88.710    Top5: 99.670    Loss: 0.390

2022-11-25 06:16:44,941 - INFO  - ==> Sparsity : 0.634

2022-11-25 06:16:44,941 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:16:44,942 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:16:44,942 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 88.820   Top5: 99.580]
2022-11-25 06:16:45,071 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:16:45,072 - INFO  - >>>>>> Epoch  51
2022-11-25 06:16:45,074 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:16:52,455 - INFO  - Training [51][   20/  196]   Loss 0.113967   Top1 95.878906   Top5 99.960938   BatchTime 0.368916   LR 0.000057   
2022-11-25 06:16:58,922 - INFO  - Training [51][   40/  196]   Loss 0.110065   Top1 96.259766   Top5 99.980469   BatchTime 0.346139   LR 0.000057   
2022-11-25 06:17:05,607 - INFO  - Training [51][   60/  196]   Loss 0.113826   Top1 96.080729   Top5 99.980469   BatchTime 0.342176   LR 0.000056   
2022-11-25 06:17:11,376 - INFO  - Training [51][   80/  196]   Loss 0.114981   Top1 96.098633   Top5 99.956055   BatchTime 0.328749   LR 0.000056   
2022-11-25 06:17:16,898 - INFO  - Training [51][  100/  196]   Loss 0.115595   Top1 96.042969   Top5 99.957031   BatchTime 0.318215   LR 0.000055   
2022-11-25 06:17:22,641 - INFO  - Training [51][  120/  196]   Loss 0.117547   Top1 95.986328   Top5 99.957682   BatchTime 0.313035   LR 0.000055   
2022-11-25 06:17:28,633 - INFO  - Training [51][  140/  196]   Loss 0.117964   Top1 95.987723   Top5 99.960938   BatchTime 0.311116   LR 0.000054   
2022-11-25 06:17:34,763 - INFO  - Training [51][  160/  196]   Loss 0.118929   Top1 95.957031   Top5 99.965820   BatchTime 0.310539   LR 0.000054   
2022-11-25 06:17:41,305 - INFO  - Training [51][  180/  196]   Loss 0.119016   Top1 95.948351   Top5 99.969618   BatchTime 0.312377   LR 0.000053   
2022-11-25 06:17:46,730 - INFO  - ==> Top1: 95.944    Top5: 99.970    Loss: 0.119

2022-11-25 06:17:46,942 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:17:48,565 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:17:50,925 - INFO  - Validation [51][   20/   40]   Loss 0.394117   Top1 88.847656   Top5 99.511719   BatchTime 0.117898   
2022-11-25 06:17:52,027 - INFO  - Validation [51][   40/   40]   Loss 0.386649   Top1 89.070000   Top5 99.640000   BatchTime 0.086524   
2022-11-25 06:17:52,252 - INFO  - ==> Top1: 89.070    Top5: 99.640    Loss: 0.387

2022-11-25 06:17:52,252 - INFO  - ==> Sparsity : 0.637

2022-11-25 06:17:52,253 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:17:52,253 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:17:52,253 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:17:57,058 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 06:17:57,060 - INFO  - >>>>>> Epoch  52
2022-11-25 06:17:57,061 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:18:03,599 - INFO  - Training [52][   20/  196]   Loss 0.108758   Top1 96.464844   Top5 100.000000   BatchTime 0.326779   LR 0.000052   
2022-11-25 06:18:08,785 - INFO  - Training [52][   40/  196]   Loss 0.119290   Top1 95.966797   Top5 99.990234   BatchTime 0.293020   LR 0.000052   
2022-11-25 06:18:14,768 - INFO  - Training [52][   60/  196]   Loss 0.117626   Top1 96.035156   Top5 99.986979   BatchTime 0.295077   LR 0.000051   
2022-11-25 06:18:20,846 - INFO  - Training [52][   80/  196]   Loss 0.116130   Top1 96.069336   Top5 99.975586   BatchTime 0.297268   LR 0.000051   
2022-11-25 06:18:26,597 - INFO  - Training [52][  100/  196]   Loss 0.116350   Top1 96.015625   Top5 99.964844   BatchTime 0.295325   LR 0.000050   
2022-11-25 06:18:32,307 - INFO  - Training [52][  120/  196]   Loss 0.117351   Top1 96.009115   Top5 99.967448   BatchTime 0.293689   LR 0.000050   
2022-11-25 06:18:38,400 - INFO  - Training [52][  140/  196]   Loss 0.117242   Top1 96.035156   Top5 99.969308   BatchTime 0.295251   LR 0.000049   
2022-11-25 06:18:44,871 - INFO  - Training [52][  160/  196]   Loss 0.115012   Top1 96.127930   Top5 99.973145   BatchTime 0.298792   LR 0.000049   
2022-11-25 06:18:51,134 - INFO  - Training [52][  180/  196]   Loss 0.115766   Top1 96.117622   Top5 99.976128   BatchTime 0.300385   LR 0.000048   
2022-11-25 06:18:56,383 - INFO  - ==> Top1: 96.126    Top5: 99.978    Loss: 0.116

2022-11-25 06:18:56,592 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:18:58,129 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:19:00,844 - INFO  - Validation [52][   20/   40]   Loss 0.408992   Top1 88.730469   Top5 99.492188   BatchTime 0.135635   
2022-11-25 06:19:01,963 - INFO  - Validation [52][   40/   40]   Loss 0.391317   Top1 88.840000   Top5 99.610000   BatchTime 0.095785   
2022-11-25 06:19:02,143 - INFO  - ==> Top1: 88.840    Top5: 99.610    Loss: 0.391

2022-11-25 06:19:02,143 - INFO  - ==> Sparsity : 0.639

2022-11-25 06:19:02,144 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:19:02,144 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:19:02,144 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:19:02,264 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:19:02,265 - INFO  - >>>>>> Epoch  53
2022-11-25 06:19:02,267 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:19:09,846 - INFO  - Training [53][   20/  196]   Loss 0.101889   Top1 96.542969   Top5 100.000000   BatchTime 0.378837   LR 0.000047   
2022-11-25 06:19:16,101 - INFO  - Training [53][   40/  196]   Loss 0.109039   Top1 96.318359   Top5 99.970703   BatchTime 0.345801   LR 0.000047   
2022-11-25 06:19:21,220 - INFO  - Training [53][   60/  196]   Loss 0.108390   Top1 96.419271   Top5 99.960938   BatchTime 0.315854   LR 0.000046   
2022-11-25 06:19:26,576 - INFO  - Training [53][   80/  196]   Loss 0.108594   Top1 96.381836   Top5 99.960938   BatchTime 0.303839   LR 0.000046   
2022-11-25 06:19:32,032 - INFO  - Training [53][  100/  196]   Loss 0.108735   Top1 96.296875   Top5 99.957031   BatchTime 0.297622   LR 0.000046   
2022-11-25 06:19:37,773 - INFO  - Training [53][  120/  196]   Loss 0.108473   Top1 96.360677   Top5 99.957682   BatchTime 0.295863   LR 0.000045   
2022-11-25 06:19:44,126 - INFO  - Training [53][  140/  196]   Loss 0.109904   Top1 96.319754   Top5 99.960938   BatchTime 0.298971   LR 0.000045   
2022-11-25 06:19:50,775 - INFO  - Training [53][  160/  196]   Loss 0.110929   Top1 96.240234   Top5 99.963379   BatchTime 0.303160   LR 0.000044   
2022-11-25 06:19:57,479 - INFO  - Training [53][  180/  196]   Loss 0.111794   Top1 96.213108   Top5 99.967448   BatchTime 0.306720   LR 0.000044   
2022-11-25 06:20:03,056 - INFO  - ==> Top1: 96.240    Top5: 99.968    Loss: 0.111

2022-11-25 06:20:03,234 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:20:04,345 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:20:06,902 - INFO  - Validation [53][   20/   40]   Loss 0.417422   Top1 88.554688   Top5 99.609375   BatchTime 0.127745   
2022-11-25 06:20:08,020 - INFO  - Validation [53][   40/   40]   Loss 0.406450   Top1 88.410000   Top5 99.690000   BatchTime 0.091836   
2022-11-25 06:20:08,232 - INFO  - ==> Top1: 88.410    Top5: 99.690    Loss: 0.406

2022-11-25 06:20:08,232 - INFO  - ==> Sparsity : 0.641

2022-11-25 06:20:08,233 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:20:08,233 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:20:08,233 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:20:08,370 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:20:08,372 - INFO  - >>>>>> Epoch  54
2022-11-25 06:20:08,373 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:20:15,031 - INFO  - Training [54][   20/  196]   Loss 0.116082   Top1 96.210938   Top5 99.941406   BatchTime 0.332750   LR 0.000043   
2022-11-25 06:20:20,329 - INFO  - Training [54][   40/  196]   Loss 0.109795   Top1 96.435547   Top5 99.960938   BatchTime 0.298821   LR 0.000042   
2022-11-25 06:20:25,801 - INFO  - Training [54][   60/  196]   Loss 0.109369   Top1 96.419271   Top5 99.967448   BatchTime 0.290415   LR 0.000042   
2022-11-25 06:20:31,731 - INFO  - Training [54][   80/  196]   Loss 0.107123   Top1 96.503906   Top5 99.975586   BatchTime 0.291939   LR 0.000041   
2022-11-25 06:20:38,589 - INFO  - Training [54][  100/  196]   Loss 0.107211   Top1 96.484375   Top5 99.980469   BatchTime 0.302129   LR 0.000041   
2022-11-25 06:20:45,455 - INFO  - Training [54][  120/  196]   Loss 0.106965   Top1 96.477865   Top5 99.980469   BatchTime 0.308989   LR 0.000040   
2022-11-25 06:20:51,572 - INFO  - Training [54][  140/  196]   Loss 0.107395   Top1 96.470424   Top5 99.977679   BatchTime 0.308539   LR 0.000040   
2022-11-25 06:20:58,479 - INFO  - Training [54][  160/  196]   Loss 0.107180   Top1 96.489258   Top5 99.980469   BatchTime 0.313140   LR 0.000039   
2022-11-25 06:21:05,293 - INFO  - Training [54][  180/  196]   Loss 0.107819   Top1 96.475694   Top5 99.982639   BatchTime 0.316202   LR 0.000039   
2022-11-25 06:21:10,503 - INFO  - ==> Top1: 96.510    Top5: 99.984    Loss: 0.107

2022-11-25 06:21:10,684 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:21:12,108 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:21:14,836 - INFO  - Validation [54][   20/   40]   Loss 0.411212   Top1 88.554688   Top5 99.550781   BatchTime 0.136207   
2022-11-25 06:21:15,939 - INFO  - Validation [54][   40/   40]   Loss 0.400078   Top1 88.690000   Top5 99.610000   BatchTime 0.095700   
2022-11-25 06:21:16,145 - INFO  - ==> Top1: 88.690    Top5: 99.610    Loss: 0.400

2022-11-25 06:21:16,146 - INFO  - ==> Sparsity : 0.643

2022-11-25 06:21:16,146 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:21:16,146 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:21:16,146 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 88.870   Top5: 99.610]
2022-11-25 06:21:16,281 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:21:16,283 - INFO  - >>>>>> Epoch  55
2022-11-25 06:21:16,285 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:21:23,484 - INFO  - Training [55][   20/  196]   Loss 0.107348   Top1 96.562500   Top5 99.980469   BatchTime 0.359858   LR 0.000038   
2022-11-25 06:21:30,103 - INFO  - Training [55][   40/  196]   Loss 0.104980   Top1 96.513672   Top5 99.970703   BatchTime 0.345394   LR 0.000038   
2022-11-25 06:21:36,772 - INFO  - Training [55][   60/  196]   Loss 0.105303   Top1 96.523438   Top5 99.980469   BatchTime 0.341419   LR 0.000037   
2022-11-25 06:21:42,154 - INFO  - Training [55][   80/  196]   Loss 0.104943   Top1 96.484375   Top5 99.980469   BatchTime 0.323334   LR 0.000037   
2022-11-25 06:21:47,944 - INFO  - Training [55][  100/  196]   Loss 0.104331   Top1 96.531250   Top5 99.976562   BatchTime 0.316564   LR 0.000036   
2022-11-25 06:21:54,520 - INFO  - Training [55][  120/  196]   Loss 0.104301   Top1 96.523438   Top5 99.973958   BatchTime 0.318609   LR 0.000036   
2022-11-25 06:22:00,482 - INFO  - Training [55][  140/  196]   Loss 0.104412   Top1 96.529018   Top5 99.972098   BatchTime 0.315678   LR 0.000035   
2022-11-25 06:22:06,826 - INFO  - Training [55][  160/  196]   Loss 0.103469   Top1 96.582031   Top5 99.975586   BatchTime 0.315867   LR 0.000035   
2022-11-25 06:22:12,379 - INFO  - Training [55][  180/  196]   Loss 0.103113   Top1 96.586372   Top5 99.978299   BatchTime 0.311620   LR 0.000034   
2022-11-25 06:22:16,535 - INFO  - ==> Top1: 96.576    Top5: 99.978    Loss: 0.103

2022-11-25 06:22:16,712 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:22:17,663 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:22:20,076 - INFO  - Validation [55][   20/   40]   Loss 0.403969   Top1 89.140625   Top5 99.589844   BatchTime 0.120539   
2022-11-25 06:22:21,206 - INFO  - Validation [55][   40/   40]   Loss 0.395597   Top1 89.050000   Top5 99.670000   BatchTime 0.088532   
2022-11-25 06:22:21,414 - INFO  - ==> Top1: 89.050    Top5: 99.670    Loss: 0.396

2022-11-25 06:22:21,414 - INFO  - ==> Sparsity : 0.647

2022-11-25 06:22:21,414 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:22:21,415 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 89.050   Top5: 99.670]
2022-11-25 06:22:21,415 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:22:21,550 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:22:21,552 - INFO  - >>>>>> Epoch  56
2022-11-25 06:22:21,553 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:22:29,615 - INFO  - Training [56][   20/  196]   Loss 0.084076   Top1 97.480469   Top5 100.000000   BatchTime 0.402951   LR 0.000034   
2022-11-25 06:22:36,325 - INFO  - Training [56][   40/  196]   Loss 0.090967   Top1 97.070312   Top5 99.980469   BatchTime 0.369219   LR 0.000033   
2022-11-25 06:22:42,960 - INFO  - Training [56][   60/  196]   Loss 0.096649   Top1 96.783854   Top5 99.986979   BatchTime 0.356728   LR 0.000033   
2022-11-25 06:22:49,532 - INFO  - Training [56][   80/  196]   Loss 0.097882   Top1 96.713867   Top5 99.990234   BatchTime 0.349697   LR 0.000032   
2022-11-25 06:22:56,066 - INFO  - Training [56][  100/  196]   Loss 0.098670   Top1 96.671875   Top5 99.992188   BatchTime 0.345094   LR 0.000032   
2022-11-25 06:23:02,371 - INFO  - Training [56][  120/  196]   Loss 0.098338   Top1 96.666667   Top5 99.990234   BatchTime 0.340123   LR 0.000031   
2022-11-25 06:23:08,577 - INFO  - Training [56][  140/  196]   Loss 0.098309   Top1 96.693638   Top5 99.988839   BatchTime 0.335858   LR 0.000031   
2022-11-25 06:23:15,279 - INFO  - Training [56][  160/  196]   Loss 0.098533   Top1 96.684570   Top5 99.990234   BatchTime 0.335765   LR 0.000031   
2022-11-25 06:23:21,995 - INFO  - Training [56][  180/  196]   Loss 0.097667   Top1 96.710069   Top5 99.991319   BatchTime 0.335767   LR 0.000030   
2022-11-25 06:23:27,364 - INFO  - ==> Top1: 96.672    Top5: 99.992    Loss: 0.098

2022-11-25 06:23:27,655 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:23:29,228 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:23:31,660 - INFO  - Validation [56][   20/   40]   Loss 0.402256   Top1 88.691406   Top5 99.628906   BatchTime 0.121505   
2022-11-25 06:23:32,740 - INFO  - Validation [56][   40/   40]   Loss 0.392772   Top1 88.910000   Top5 99.700000   BatchTime 0.087773   
2022-11-25 06:23:32,947 - INFO  - ==> Top1: 88.910    Top5: 99.700    Loss: 0.393

2022-11-25 06:23:32,947 - INFO  - ==> Sparsity : 0.650

2022-11-25 06:23:32,948 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:23:32,948 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 89.050   Top5: 99.670]
2022-11-25 06:23:32,948 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:23:33,102 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:23:33,103 - INFO  - >>>>>> Epoch  57
2022-11-25 06:23:33,105 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:23:40,311 - INFO  - Training [57][   20/  196]   Loss 0.082757   Top1 97.441406   Top5 99.960938   BatchTime 0.360158   LR 0.000029   
2022-11-25 06:23:46,873 - INFO  - Training [57][   40/  196]   Loss 0.090245   Top1 97.167969   Top5 99.970703   BatchTime 0.344132   LR 0.000029   
2022-11-25 06:23:53,534 - INFO  - Training [57][   60/  196]   Loss 0.092628   Top1 97.128906   Top5 99.967448   BatchTime 0.340427   LR 0.000029   
2022-11-25 06:23:59,860 - INFO  - Training [57][   80/  196]   Loss 0.092907   Top1 97.070312   Top5 99.970703   BatchTime 0.334398   LR 0.000028   
2022-11-25 06:24:06,007 - INFO  - Training [57][  100/  196]   Loss 0.094629   Top1 97.031250   Top5 99.976562   BatchTime 0.328989   LR 0.000028   
2022-11-25 06:24:11,837 - INFO  - Training [57][  120/  196]   Loss 0.095114   Top1 96.992188   Top5 99.977214   BatchTime 0.322736   LR 0.000027   
2022-11-25 06:24:17,610 - INFO  - Training [57][  140/  196]   Loss 0.095672   Top1 96.947545   Top5 99.969308   BatchTime 0.317868   LR 0.000027   
2022-11-25 06:24:23,586 - INFO  - Training [57][  160/  196]   Loss 0.095404   Top1 96.928711   Top5 99.970703   BatchTime 0.315486   LR 0.000027   
2022-11-25 06:24:30,136 - INFO  - Training [57][  180/  196]   Loss 0.096588   Top1 96.872830   Top5 99.971788   BatchTime 0.316822   LR 0.000026   
2022-11-25 06:24:34,704 - INFO  - ==> Top1: 96.880    Top5: 99.972    Loss: 0.096

2022-11-25 06:24:34,920 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:24:36,226 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:24:38,632 - INFO  - Validation [57][   20/   40]   Loss 0.418262   Top1 88.515625   Top5 99.589844   BatchTime 0.120217   
2022-11-25 06:24:39,788 - INFO  - Validation [57][   40/   40]   Loss 0.403672   Top1 88.750000   Top5 99.690000   BatchTime 0.089008   
2022-11-25 06:24:39,993 - INFO  - ==> Top1: 88.750    Top5: 99.690    Loss: 0.404

2022-11-25 06:24:39,994 - INFO  - ==> Sparsity : 0.653

2022-11-25 06:24:39,994 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:24:39,994 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 89.050   Top5: 99.670]
2022-11-25 06:24:39,994 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:24:40,299 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:24:40,301 - INFO  - >>>>>> Epoch  58
2022-11-25 06:24:40,303 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:24:47,788 - INFO  - Training [58][   20/  196]   Loss 0.095167   Top1 96.972656   Top5 99.960938   BatchTime 0.374135   LR 0.000025   
2022-11-25 06:24:54,690 - INFO  - Training [58][   40/  196]   Loss 0.096008   Top1 96.787109   Top5 99.970703   BatchTime 0.359620   LR 0.000025   
2022-11-25 06:25:00,867 - INFO  - Training [58][   60/  196]   Loss 0.095782   Top1 96.881510   Top5 99.973958   BatchTime 0.342706   LR 0.000025   
2022-11-25 06:25:06,566 - INFO  - Training [58][   80/  196]   Loss 0.092834   Top1 96.982422   Top5 99.980469   BatchTime 0.328263   LR 0.000024   
2022-11-25 06:25:12,651 - INFO  - Training [58][  100/  196]   Loss 0.095666   Top1 96.808594   Top5 99.984375   BatchTime 0.323454   LR 0.000024   
2022-11-25 06:25:19,447 - INFO  - Training [58][  120/  196]   Loss 0.094739   Top1 96.852214   Top5 99.986979   BatchTime 0.326185   LR 0.000023   
2022-11-25 06:25:26,126 - INFO  - Training [58][  140/  196]   Loss 0.096291   Top1 96.791295   Top5 99.986049   BatchTime 0.327288   LR 0.000023   
2022-11-25 06:25:32,829 - INFO  - Training [58][  160/  196]   Loss 0.095979   Top1 96.840820   Top5 99.985352   BatchTime 0.328270   LR 0.000023   
2022-11-25 06:25:38,070 - INFO  - Training [58][  180/  196]   Loss 0.096435   Top1 96.812066   Top5 99.982639   BatchTime 0.320915   LR 0.000022   
2022-11-25 06:25:42,185 - INFO  - ==> Top1: 96.814    Top5: 99.982    Loss: 0.097

2022-11-25 06:25:42,333 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:25:43,446 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:25:46,060 - INFO  - Validation [58][   20/   40]   Loss 0.414868   Top1 88.750000   Top5 99.609375   BatchTime 0.130613   
2022-11-25 06:25:47,239 - INFO  - Validation [58][   40/   40]   Loss 0.404516   Top1 88.800000   Top5 99.680000   BatchTime 0.094771   
2022-11-25 06:25:47,469 - INFO  - ==> Top1: 88.800    Top5: 99.680    Loss: 0.405

2022-11-25 06:25:47,469 - INFO  - ==> Sparsity : 0.656

2022-11-25 06:25:47,470 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:25:47,470 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 89.050   Top5: 99.670]
2022-11-25 06:25:47,470 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:25:47,637 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:25:47,638 - INFO  - >>>>>> Epoch  59
2022-11-25 06:25:47,640 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:25:54,468 - INFO  - Training [59][   20/  196]   Loss 0.091294   Top1 96.855469   Top5 99.980469   BatchTime 0.341258   LR 0.000022   
2022-11-25 06:26:00,659 - INFO  - Training [59][   40/  196]   Loss 0.093664   Top1 96.748047   Top5 99.980469   BatchTime 0.325405   LR 0.000021   
2022-11-25 06:26:06,103 - INFO  - Training [59][   60/  196]   Loss 0.094030   Top1 96.705729   Top5 99.980469   BatchTime 0.307661   LR 0.000021   
2022-11-25 06:26:11,887 - INFO  - Training [59][   80/  196]   Loss 0.094656   Top1 96.689453   Top5 99.975586   BatchTime 0.303047   LR 0.000020   
2022-11-25 06:26:18,689 - INFO  - Training [59][  100/  196]   Loss 0.093055   Top1 96.792969   Top5 99.972656   BatchTime 0.310460   LR 0.000020   
2022-11-25 06:26:24,973 - INFO  - Training [59][  120/  196]   Loss 0.094700   Top1 96.767578   Top5 99.973958   BatchTime 0.311083   LR 0.000020   
2022-11-25 06:26:30,738 - INFO  - Training [59][  140/  196]   Loss 0.094149   Top1 96.824777   Top5 99.974888   BatchTime 0.307820   LR 0.000019   
2022-11-25 06:26:36,786 - INFO  - Training [59][  160/  196]   Loss 0.092270   Top1 96.928711   Top5 99.978027   BatchTime 0.307140   LR 0.000019   
2022-11-25 06:26:42,968 - INFO  - Training [59][  180/  196]   Loss 0.092051   Top1 96.950955   Top5 99.980469   BatchTime 0.307359   LR 0.000019   
2022-11-25 06:26:47,446 - INFO  - ==> Top1: 96.974    Top5: 99.982    Loss: 0.092

2022-11-25 06:26:47,645 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:26:48,884 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:26:51,481 - INFO  - Validation [59][   20/   40]   Loss 0.409502   Top1 88.808594   Top5 99.589844   BatchTime 0.129766   
2022-11-25 06:26:52,573 - INFO  - Validation [59][   40/   40]   Loss 0.397003   Top1 88.940000   Top5 99.680000   BatchTime 0.092194   
2022-11-25 06:26:52,775 - INFO  - ==> Top1: 88.940    Top5: 99.680    Loss: 0.397

2022-11-25 06:26:52,775 - INFO  - ==> Sparsity : 0.657

2022-11-25 06:26:52,775 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:26:52,775 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 89.050   Top5: 99.670]
2022-11-25 06:26:52,776 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 88.960   Top5: 99.620]
2022-11-25 06:26:52,936 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:26:52,938 - INFO  - >>>>>> Epoch  60
2022-11-25 06:26:52,940 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:27:00,130 - INFO  - Training [60][   20/  196]   Loss 0.083232   Top1 96.953125   Top5 99.960938   BatchTime 0.359385   LR 0.000018   
2022-11-25 06:27:06,575 - INFO  - Training [60][   40/  196]   Loss 0.086396   Top1 97.099609   Top5 99.980469   BatchTime 0.340820   LR 0.000018   
2022-11-25 06:27:11,576 - INFO  - Training [60][   60/  196]   Loss 0.087129   Top1 97.148438   Top5 99.980469   BatchTime 0.310553   LR 0.000017   
2022-11-25 06:27:17,002 - INFO  - Training [60][   80/  196]   Loss 0.089701   Top1 97.045898   Top5 99.985352   BatchTime 0.300748   LR 0.000017   
2022-11-25 06:27:23,273 - INFO  - Training [60][  100/  196]   Loss 0.089748   Top1 97.011719   Top5 99.988281   BatchTime 0.303303   LR 0.000017   
2022-11-25 06:27:30,138 - INFO  - Training [60][  120/  196]   Loss 0.088767   Top1 97.067057   Top5 99.990234   BatchTime 0.309960   LR 0.000016   
2022-11-25 06:27:36,454 - INFO  - Training [60][  140/  196]   Loss 0.090194   Top1 97.011719   Top5 99.988839   BatchTime 0.310791   LR 0.000016   
2022-11-25 06:27:42,260 - INFO  - Training [60][  160/  196]   Loss 0.091425   Top1 96.953125   Top5 99.987793   BatchTime 0.308234   LR 0.000016   
2022-11-25 06:27:48,923 - INFO  - Training [60][  180/  196]   Loss 0.090480   Top1 96.981337   Top5 99.989149   BatchTime 0.311001   LR 0.000015   
2022-11-25 06:27:54,571 - INFO  - ==> Top1: 96.966    Top5: 99.988    Loss: 0.091

2022-11-25 06:27:54,753 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:27:55,934 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:27:58,535 - INFO  - Validation [60][   20/   40]   Loss 0.408763   Top1 88.906250   Top5 99.511719   BatchTime 0.129990   
2022-11-25 06:27:59,575 - INFO  - Validation [60][   40/   40]   Loss 0.399420   Top1 89.000000   Top5 99.640000   BatchTime 0.090982   
2022-11-25 06:27:59,795 - INFO  - ==> Top1: 89.000    Top5: 99.640    Loss: 0.399

2022-11-25 06:27:59,795 - INFO  - ==> Sparsity : 0.660

2022-11-25 06:27:59,795 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:27:59,796 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 89.050   Top5: 99.670]
2022-11-25 06:27:59,796 - INFO  - Scoreboard best 3 ==> Epoch [60][Top1: 89.000   Top5: 99.640]
2022-11-25 06:27:59,926 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:27:59,927 - INFO  - >>>>>> Epoch  61
2022-11-25 06:27:59,929 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:28:08,042 - INFO  - Training [61][   20/  196]   Loss 0.076218   Top1 97.441406   Top5 99.980469   BatchTime 0.405533   LR 0.000015   
2022-11-25 06:28:14,901 - INFO  - Training [61][   40/  196]   Loss 0.079036   Top1 97.373047   Top5 99.990234   BatchTime 0.374234   LR 0.000014   
2022-11-25 06:28:21,695 - INFO  - Training [61][   60/  196]   Loss 0.084382   Top1 97.226562   Top5 99.980469   BatchTime 0.362723   LR 0.000014   
2022-11-25 06:28:27,898 - INFO  - Training [61][   80/  196]   Loss 0.084243   Top1 97.202148   Top5 99.970703   BatchTime 0.349578   LR 0.000014   
2022-11-25 06:28:34,444 - INFO  - Training [61][  100/  196]   Loss 0.083584   Top1 97.246094   Top5 99.976562   BatchTime 0.345124   LR 0.000013   
2022-11-25 06:28:41,315 - INFO  - Training [61][  120/  196]   Loss 0.083870   Top1 97.268880   Top5 99.980469   BatchTime 0.344858   LR 0.000013   
2022-11-25 06:28:47,622 - INFO  - Training [61][  140/  196]   Loss 0.084481   Top1 97.243304   Top5 99.980469   BatchTime 0.340640   LR 0.000013   
2022-11-25 06:28:54,535 - INFO  - Training [61][  160/  196]   Loss 0.085539   Top1 97.224121   Top5 99.980469   BatchTime 0.341266   LR 0.000012   
2022-11-25 06:29:01,164 - INFO  - Training [61][  180/  196]   Loss 0.086755   Top1 97.189670   Top5 99.978299   BatchTime 0.340175   LR 0.000012   
2022-11-25 06:29:06,273 - INFO  - ==> Top1: 97.158    Top5: 99.980    Loss: 0.088

2022-11-25 06:29:06,495 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:29:08,205 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:29:10,732 - INFO  - Validation [61][   20/   40]   Loss 0.412433   Top1 88.984375   Top5 99.550781   BatchTime 0.126286   
2022-11-25 06:29:11,759 - INFO  - Validation [61][   40/   40]   Loss 0.401227   Top1 89.080000   Top5 99.710000   BatchTime 0.088810   
2022-11-25 06:29:11,964 - INFO  - ==> Top1: 89.080    Top5: 99.710    Loss: 0.401

2022-11-25 06:29:11,964 - INFO  - ==> Sparsity : 0.662

2022-11-25 06:29:11,965 - INFO  - Scoreboard best 1 ==> Epoch [61][Top1: 89.080   Top5: 99.710]
2022-11-25 06:29:11,965 - INFO  - Scoreboard best 2 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:29:11,965 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 89.050   Top5: 99.670]
2022-11-25 06:29:17,109 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 06:29:17,111 - INFO  - >>>>>> Epoch  62
2022-11-25 06:29:17,113 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:29:23,806 - INFO  - Training [62][   20/  196]   Loss 0.089939   Top1 97.128906   Top5 99.980469   BatchTime 0.334564   LR 0.000012   
2022-11-25 06:29:28,806 - INFO  - Training [62][   40/  196]   Loss 0.086008   Top1 97.177734   Top5 99.990234   BatchTime 0.292269   LR 0.000011   
2022-11-25 06:29:34,176 - INFO  - Training [62][   60/  196]   Loss 0.085748   Top1 97.239583   Top5 99.993490   BatchTime 0.284348   LR 0.000011   
2022-11-25 06:29:40,158 - INFO  - Training [62][   80/  196]   Loss 0.084861   Top1 97.290039   Top5 99.980469   BatchTime 0.288033   LR 0.000011   
2022-11-25 06:29:46,406 - INFO  - Training [62][  100/  196]   Loss 0.087013   Top1 97.257812   Top5 99.976562   BatchTime 0.292907   LR 0.000011   
2022-11-25 06:29:52,134 - INFO  - Training [62][  120/  196]   Loss 0.085587   Top1 97.262370   Top5 99.980469   BatchTime 0.291823   LR 0.000010   
2022-11-25 06:29:57,865 - INFO  - Training [62][  140/  196]   Loss 0.084794   Top1 97.290737   Top5 99.980469   BatchTime 0.291068   LR 0.000010   
2022-11-25 06:30:03,872 - INFO  - Training [62][  160/  196]   Loss 0.084162   Top1 97.290039   Top5 99.980469   BatchTime 0.292229   LR 0.000010   
2022-11-25 06:30:10,427 - INFO  - Training [62][  180/  196]   Loss 0.084351   Top1 97.263455   Top5 99.980469   BatchTime 0.296174   LR 0.000009   
2022-11-25 06:30:15,638 - INFO  - ==> Top1: 97.242    Top5: 99.980    Loss: 0.085

2022-11-25 06:30:15,848 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:30:17,404 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:30:19,786 - INFO  - Validation [62][   20/   40]   Loss 0.406944   Top1 88.984375   Top5 99.531250   BatchTime 0.119005   
2022-11-25 06:30:20,859 - INFO  - Validation [62][   40/   40]   Loss 0.396032   Top1 89.160000   Top5 99.700000   BatchTime 0.086331   
2022-11-25 06:30:21,099 - INFO  - ==> Top1: 89.160    Top5: 99.700    Loss: 0.396

2022-11-25 06:30:21,099 - INFO  - ==> Sparsity : 0.663

2022-11-25 06:30:21,100 - INFO  - Scoreboard best 1 ==> Epoch [62][Top1: 89.160   Top5: 99.700]
2022-11-25 06:30:21,100 - INFO  - Scoreboard best 2 ==> Epoch [61][Top1: 89.080   Top5: 99.710]
2022-11-25 06:30:21,100 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:30:25,948 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 06:30:25,950 - INFO  - >>>>>> Epoch  63
2022-11-25 06:30:25,952 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:30:32,857 - INFO  - Training [63][   20/  196]   Loss 0.077427   Top1 97.539062   Top5 99.980469   BatchTime 0.345160   LR 0.000009   
2022-11-25 06:30:38,928 - INFO  - Training [63][   40/  196]   Loss 0.079033   Top1 97.480469   Top5 99.990234   BatchTime 0.324345   LR 0.000009   
2022-11-25 06:30:45,486 - INFO  - Training [63][   60/  196]   Loss 0.079271   Top1 97.467448   Top5 99.993490   BatchTime 0.325522   LR 0.000008   
2022-11-25 06:30:52,305 - INFO  - Training [63][   80/  196]   Loss 0.079459   Top1 97.470703   Top5 99.990234   BatchTime 0.329383   LR 0.000008   
2022-11-25 06:30:58,339 - INFO  - Training [63][  100/  196]   Loss 0.079330   Top1 97.445312   Top5 99.992188   BatchTime 0.323840   LR 0.000008   
2022-11-25 06:31:04,537 - INFO  - Training [63][  120/  196]   Loss 0.079886   Top1 97.428385   Top5 99.990234   BatchTime 0.321522   LR 0.000008   
2022-11-25 06:31:11,336 - INFO  - Training [63][  140/  196]   Loss 0.080366   Top1 97.424665   Top5 99.988839   BatchTime 0.324151   LR 0.000007   
2022-11-25 06:31:17,885 - INFO  - Training [63][  160/  196]   Loss 0.081276   Top1 97.421875   Top5 99.982910   BatchTime 0.324561   LR 0.000007   
2022-11-25 06:31:24,314 - INFO  - Training [63][  180/  196]   Loss 0.082265   Top1 97.374132   Top5 99.980469   BatchTime 0.324216   LR 0.000007   
2022-11-25 06:31:29,823 - INFO  - ==> Top1: 97.382    Top5: 99.980    Loss: 0.082

2022-11-25 06:31:29,998 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:31:31,040 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:31:33,507 - INFO  - Validation [63][   20/   40]   Loss 0.408110   Top1 89.140625   Top5 99.550781   BatchTime 0.123258   
2022-11-25 06:31:34,613 - INFO  - Validation [63][   40/   40]   Loss 0.397835   Top1 89.000000   Top5 99.680000   BatchTime 0.089278   
2022-11-25 06:31:34,832 - INFO  - ==> Top1: 89.000    Top5: 99.680    Loss: 0.398

2022-11-25 06:31:34,832 - INFO  - ==> Sparsity : 0.664

2022-11-25 06:31:34,833 - INFO  - Scoreboard best 1 ==> Epoch [62][Top1: 89.160   Top5: 99.700]
2022-11-25 06:31:34,833 - INFO  - Scoreboard best 2 ==> Epoch [61][Top1: 89.080   Top5: 99.710]
2022-11-25 06:31:34,833 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 89.070   Top5: 99.640]
2022-11-25 06:31:35,149 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:31:35,151 - INFO  - >>>>>> Epoch  64
2022-11-25 06:31:35,153 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:31:42,027 - INFO  - Training [64][   20/  196]   Loss 0.090591   Top1 97.050781   Top5 99.980469   BatchTime 0.343600   LR 0.000007   
2022-11-25 06:31:48,348 - INFO  - Training [64][   40/  196]   Loss 0.087049   Top1 97.138672   Top5 99.980469   BatchTime 0.329824   LR 0.000006   
2022-11-25 06:31:53,946 - INFO  - Training [64][   60/  196]   Loss 0.083171   Top1 97.298177   Top5 99.986979   BatchTime 0.313185   LR 0.000006   
2022-11-25 06:31:59,774 - INFO  - Training [64][   80/  196]   Loss 0.083549   Top1 97.329102   Top5 99.975586   BatchTime 0.307735   LR 0.000006   
2022-11-25 06:32:06,431 - INFO  - Training [64][  100/  196]   Loss 0.083658   Top1 97.289062   Top5 99.980469   BatchTime 0.312756   LR 0.000006   
2022-11-25 06:32:13,157 - INFO  - Training [64][  120/  196]   Loss 0.082777   Top1 97.333984   Top5 99.980469   BatchTime 0.316684   LR 0.000006   
2022-11-25 06:32:19,486 - INFO  - Training [64][  140/  196]   Loss 0.082443   Top1 97.340960   Top5 99.983259   BatchTime 0.316647   LR 0.000005   
2022-11-25 06:32:25,841 - INFO  - Training [64][  160/  196]   Loss 0.082165   Top1 97.343750   Top5 99.982910   BatchTime 0.316785   LR 0.000005   
2022-11-25 06:32:32,662 - INFO  - Training [64][  180/  196]   Loss 0.082264   Top1 97.343750   Top5 99.982639   BatchTime 0.319478   LR 0.000005   
2022-11-25 06:32:37,506 - INFO  - ==> Top1: 97.386    Top5: 99.984    Loss: 0.082

2022-11-25 06:32:37,688 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:32:38,766 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:32:41,167 - INFO  - Validation [64][   20/   40]   Loss 0.412081   Top1 89.199219   Top5 99.492188   BatchTime 0.119948   
2022-11-25 06:32:42,269 - INFO  - Validation [64][   40/   40]   Loss 0.399872   Top1 89.270000   Top5 99.640000   BatchTime 0.087549   
2022-11-25 06:32:42,518 - INFO  - ==> Top1: 89.270    Top5: 99.640    Loss: 0.400

2022-11-25 06:32:42,519 - INFO  - ==> Sparsity : 0.665

2022-11-25 06:32:42,519 - INFO  - Scoreboard best 1 ==> Epoch [64][Top1: 89.270   Top5: 99.640]
2022-11-25 06:32:42,519 - INFO  - Scoreboard best 2 ==> Epoch [62][Top1: 89.160   Top5: 99.700]
2022-11-25 06:32:42,519 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 89.080   Top5: 99.710]
2022-11-25 06:32:48,228 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 06:32:48,233 - INFO  - >>>>>> Epoch  65
2022-11-25 06:32:48,236 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:32:54,570 - INFO  - Training [65][   20/  196]   Loss 0.081299   Top1 97.265625   Top5 99.980469   BatchTime 0.316570   LR 0.000005   
2022-11-25 06:33:00,378 - INFO  - Training [65][   40/  196]   Loss 0.080061   Top1 97.470703   Top5 99.980469   BatchTime 0.303492   LR 0.000004   
2022-11-25 06:33:06,841 - INFO  - Training [65][   60/  196]   Loss 0.078100   Top1 97.584635   Top5 99.986979   BatchTime 0.310038   LR 0.000004   
2022-11-25 06:33:12,641 - INFO  - Training [65][   80/  196]   Loss 0.079245   Top1 97.529297   Top5 99.980469   BatchTime 0.305036   LR 0.000004   
2022-11-25 06:33:18,929 - INFO  - Training [65][  100/  196]   Loss 0.077992   Top1 97.566406   Top5 99.984375   BatchTime 0.306907   LR 0.000004   
2022-11-25 06:33:25,175 - INFO  - Training [65][  120/  196]   Loss 0.077396   Top1 97.555339   Top5 99.983724   BatchTime 0.307800   LR 0.000004   
2022-11-25 06:33:31,492 - INFO  - Training [65][  140/  196]   Loss 0.077751   Top1 97.539062   Top5 99.983259   BatchTime 0.308953   LR 0.000004   
2022-11-25 06:33:38,194 - INFO  - Training [65][  160/  196]   Loss 0.079092   Top1 97.487793   Top5 99.982910   BatchTime 0.312222   LR 0.000003   
2022-11-25 06:33:43,315 - INFO  - Training [65][  180/  196]   Loss 0.079139   Top1 97.478299   Top5 99.982639   BatchTime 0.305978   LR 0.000003   
2022-11-25 06:33:47,455 - INFO  - ==> Top1: 97.464    Top5: 99.984    Loss: 0.079

2022-11-25 06:33:47,629 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:33:48,650 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:33:51,131 - INFO  - Validation [65][   20/   40]   Loss 0.411782   Top1 88.964844   Top5 99.550781   BatchTime 0.123968   
2022-11-25 06:33:52,187 - INFO  - Validation [65][   40/   40]   Loss 0.395995   Top1 89.190000   Top5 99.660000   BatchTime 0.088388   
2022-11-25 06:33:52,384 - INFO  - ==> Top1: 89.190    Top5: 99.660    Loss: 0.396

2022-11-25 06:33:52,384 - INFO  - ==> Sparsity : 0.666

2022-11-25 06:33:52,384 - INFO  - Scoreboard best 1 ==> Epoch [64][Top1: 89.270   Top5: 99.640]
2022-11-25 06:33:52,384 - INFO  - Scoreboard best 2 ==> Epoch [65][Top1: 89.190   Top5: 99.660]
2022-11-25 06:33:52,384 - INFO  - Scoreboard best 3 ==> Epoch [62][Top1: 89.160   Top5: 99.700]
2022-11-25 06:33:52,505 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:33:52,506 - INFO  - >>>>>> Epoch  66
2022-11-25 06:33:52,508 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:34:00,500 - INFO  - Training [66][   20/  196]   Loss 0.083133   Top1 97.246094   Top5 99.960938   BatchTime 0.399451   LR 0.000003   
2022-11-25 06:34:07,139 - INFO  - Training [66][   40/  196]   Loss 0.084162   Top1 97.285156   Top5 99.970703   BatchTime 0.365698   LR 0.000003   
2022-11-25 06:34:13,800 - INFO  - Training [66][   60/  196]   Loss 0.080106   Top1 97.428385   Top5 99.973958   BatchTime 0.354815   LR 0.000003   
2022-11-25 06:34:20,731 - INFO  - Training [66][   80/  196]   Loss 0.080751   Top1 97.480469   Top5 99.980469   BatchTime 0.352750   LR 0.000002   
2022-11-25 06:34:26,448 - INFO  - Training [66][  100/  196]   Loss 0.080062   Top1 97.488281   Top5 99.980469   BatchTime 0.339371   LR 0.000002   
2022-11-25 06:34:32,983 - INFO  - Training [66][  120/  196]   Loss 0.080867   Top1 97.447917   Top5 99.983724   BatchTime 0.337269   LR 0.000002   
2022-11-25 06:34:39,627 - INFO  - Training [66][  140/  196]   Loss 0.080644   Top1 97.463728   Top5 99.980469   BatchTime 0.336537   LR 0.000002   
2022-11-25 06:34:46,306 - INFO  - Training [66][  160/  196]   Loss 0.079266   Top1 97.519531   Top5 99.980469   BatchTime 0.336215   LR 0.000002   
2022-11-25 06:34:52,714 - INFO  - Training [66][  180/  196]   Loss 0.078882   Top1 97.523872   Top5 99.982639   BatchTime 0.334460   LR 0.000002   
2022-11-25 06:34:57,823 - INFO  - ==> Top1: 97.520    Top5: 99.984    Loss: 0.079

2022-11-25 06:34:58,048 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:34:59,437 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:35:02,080 - INFO  - Validation [66][   20/   40]   Loss 0.415881   Top1 89.140625   Top5 99.570312   BatchTime 0.132037   
2022-11-25 06:35:03,174 - INFO  - Validation [66][   40/   40]   Loss 0.400383   Top1 89.280000   Top5 99.690000   BatchTime 0.093366   
2022-11-25 06:35:03,388 - INFO  - ==> Top1: 89.280    Top5: 99.690    Loss: 0.400

2022-11-25 06:35:03,388 - INFO  - ==> Sparsity : 0.666

2022-11-25 06:35:03,388 - INFO  - Scoreboard best 1 ==> Epoch [66][Top1: 89.280   Top5: 99.690]
2022-11-25 06:35:03,388 - INFO  - Scoreboard best 2 ==> Epoch [64][Top1: 89.270   Top5: 99.640]
2022-11-25 06:35:03,389 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 89.190   Top5: 99.660]
2022-11-25 06:35:08,778 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 06:35:08,782 - INFO  - >>>>>> Epoch  67
2022-11-25 06:35:08,785 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:35:15,384 - INFO  - Training [67][   20/  196]   Loss 0.072928   Top1 97.656250   Top5 100.000000   BatchTime 0.329857   LR 0.000002   
2022-11-25 06:35:21,463 - INFO  - Training [67][   40/  196]   Loss 0.076564   Top1 97.597656   Top5 99.990234   BatchTime 0.316913   LR 0.000002   
2022-11-25 06:35:27,204 - INFO  - Training [67][   60/  196]   Loss 0.076398   Top1 97.591146   Top5 99.993490   BatchTime 0.306946   LR 0.000001   
2022-11-25 06:35:33,121 - INFO  - Training [67][   80/  196]   Loss 0.075171   Top1 97.607422   Top5 99.990234   BatchTime 0.304174   LR 0.000001   
2022-11-25 06:35:39,114 - INFO  - Training [67][  100/  196]   Loss 0.077093   Top1 97.527344   Top5 99.984375   BatchTime 0.303267   LR 0.000001   
2022-11-25 06:35:45,327 - INFO  - Training [67][  120/  196]   Loss 0.079011   Top1 97.480469   Top5 99.986979   BatchTime 0.304498   LR 0.000001   
2022-11-25 06:35:51,758 - INFO  - Training [67][  140/  196]   Loss 0.078335   Top1 97.539062   Top5 99.986049   BatchTime 0.306925   LR 0.000001   
2022-11-25 06:35:58,480 - INFO  - Training [67][  160/  196]   Loss 0.076928   Top1 97.597656   Top5 99.987793   BatchTime 0.310577   LR 0.000001   
2022-11-25 06:36:04,778 - INFO  - Training [67][  180/  196]   Loss 0.077849   Top1 97.567274   Top5 99.986979   BatchTime 0.311058   LR 0.000001   
2022-11-25 06:36:10,315 - INFO  - ==> Top1: 97.552    Top5: 99.988    Loss: 0.078

2022-11-25 06:36:10,535 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:36:12,107 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:36:14,579 - INFO  - Validation [67][   20/   40]   Loss 0.407602   Top1 89.453125   Top5 99.550781   BatchTime 0.123527   
2022-11-25 06:36:15,674 - INFO  - Validation [67][   40/   40]   Loss 0.399629   Top1 89.240000   Top5 99.670000   BatchTime 0.089149   
2022-11-25 06:36:15,913 - INFO  - ==> Top1: 89.240    Top5: 99.670    Loss: 0.400

2022-11-25 06:36:15,913 - INFO  - ==> Sparsity : 0.666

2022-11-25 06:36:15,913 - INFO  - Scoreboard best 1 ==> Epoch [66][Top1: 89.280   Top5: 99.690]
2022-11-25 06:36:15,914 - INFO  - Scoreboard best 2 ==> Epoch [64][Top1: 89.270   Top5: 99.640]
2022-11-25 06:36:15,914 - INFO  - Scoreboard best 3 ==> Epoch [67][Top1: 89.240   Top5: 99.670]
2022-11-25 06:36:16,069 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:36:16,070 - INFO  - >>>>>> Epoch  68
2022-11-25 06:36:16,072 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:36:23,676 - INFO  - Training [68][   20/  196]   Loss 0.086511   Top1 97.304688   Top5 100.000000   BatchTime 0.380081   LR 0.000001   
2022-11-25 06:36:29,604 - INFO  - Training [68][   40/  196]   Loss 0.080740   Top1 97.402344   Top5 100.000000   BatchTime 0.338225   LR 0.000001   
2022-11-25 06:36:36,518 - INFO  - Training [68][   60/  196]   Loss 0.078470   Top1 97.467448   Top5 99.986979   BatchTime 0.340714   LR 0.000001   
2022-11-25 06:36:42,953 - INFO  - Training [68][   80/  196]   Loss 0.079097   Top1 97.485352   Top5 99.990234   BatchTime 0.335969   LR 0.000000   
2022-11-25 06:36:49,218 - INFO  - Training [68][  100/  196]   Loss 0.078347   Top1 97.515625   Top5 99.984375   BatchTime 0.331430   LR 0.000000   
2022-11-25 06:36:54,839 - INFO  - Training [68][  120/  196]   Loss 0.078280   Top1 97.503255   Top5 99.983724   BatchTime 0.323028   LR 0.000000   
2022-11-25 06:37:01,313 - INFO  - Training [68][  140/  196]   Loss 0.077361   Top1 97.544643   Top5 99.986049   BatchTime 0.323125   LR 0.000000   
2022-11-25 06:37:07,098 - INFO  - Training [68][  160/  196]   Loss 0.077118   Top1 97.561035   Top5 99.985352   BatchTime 0.318892   LR 0.000000   
2022-11-25 06:37:12,731 - INFO  - Training [68][  180/  196]   Loss 0.077841   Top1 97.508681   Top5 99.986979   BatchTime 0.314755   LR 0.000000   
2022-11-25 06:37:17,212 - INFO  - ==> Top1: 97.500    Top5: 99.988    Loss: 0.078

2022-11-25 06:37:17,415 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:37:18,641 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:37:21,349 - INFO  - Validation [68][   20/   40]   Loss 0.413959   Top1 89.238281   Top5 99.453125   BatchTime 0.135274   
2022-11-25 06:37:22,465 - INFO  - Validation [68][   40/   40]   Loss 0.400405   Top1 89.110000   Top5 99.610000   BatchTime 0.095535   
2022-11-25 06:37:22,689 - INFO  - ==> Top1: 89.110    Top5: 99.610    Loss: 0.400

2022-11-25 06:37:22,689 - INFO  - ==> Sparsity : 0.666

2022-11-25 06:37:22,690 - INFO  - Scoreboard best 1 ==> Epoch [66][Top1: 89.280   Top5: 99.690]
2022-11-25 06:37:22,690 - INFO  - Scoreboard best 2 ==> Epoch [64][Top1: 89.270   Top5: 99.640]
2022-11-25 06:37:22,690 - INFO  - Scoreboard best 3 ==> Epoch [67][Top1: 89.240   Top5: 99.670]
2022-11-25 06:37:22,848 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar

2022-11-25 06:37:22,850 - INFO  - >>>>>> Epoch  69
2022-11-25 06:37:22,851 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:37:29,579 - INFO  - Training [69][   20/  196]   Loss 0.077520   Top1 97.656250   Top5 100.000000   BatchTime 0.336232   LR 0.000000   
2022-11-25 06:37:34,854 - INFO  - Training [69][   40/  196]   Loss 0.077071   Top1 97.558594   Top5 99.990234   BatchTime 0.300000   LR 0.000000   
2022-11-25 06:37:40,123 - INFO  - Training [69][   60/  196]   Loss 0.077642   Top1 97.513021   Top5 99.986979   BatchTime 0.287817   LR 0.000000   
2022-11-25 06:37:45,341 - INFO  - Training [69][   80/  196]   Loss 0.077969   Top1 97.490234   Top5 99.980469   BatchTime 0.281084   LR 0.000000   
2022-11-25 06:37:50,699 - INFO  - Training [69][  100/  196]   Loss 0.076557   Top1 97.554688   Top5 99.980469   BatchTime 0.278449   LR 0.000000   
2022-11-25 06:37:56,511 - INFO  - Training [69][  120/  196]   Loss 0.075527   Top1 97.594401   Top5 99.983724   BatchTime 0.280464   LR 0.000000   
2022-11-25 06:38:02,103 - INFO  - Training [69][  140/  196]   Loss 0.074895   Top1 97.628348   Top5 99.983259   BatchTime 0.280342   LR 0.000000   
2022-11-25 06:38:07,345 - INFO  - Training [69][  160/  196]   Loss 0.076029   Top1 97.580566   Top5 99.980469   BatchTime 0.278061   LR 0.000000   
2022-11-25 06:38:12,361 - INFO  - Training [69][  180/  196]   Loss 0.076737   Top1 97.556424   Top5 99.982639   BatchTime 0.275032   LR 0.000000   
2022-11-25 06:38:16,801 - INFO  - ==> Top1: 97.568    Top5: 99.984    Loss: 0.077

2022-11-25 06:38:17,030 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:38:18,389 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:38:20,942 - INFO  - Validation [69][   20/   40]   Loss 0.411167   Top1 89.199219   Top5 99.589844   BatchTime 0.127557   
2022-11-25 06:38:22,079 - INFO  - Validation [69][   40/   40]   Loss 0.398819   Top1 89.330000   Top5 99.720000   BatchTime 0.092210   
2022-11-25 06:38:22,304 - INFO  - ==> Top1: 89.330    Top5: 99.720    Loss: 0.399

2022-11-25 06:38:22,304 - INFO  - ==> Sparsity : 0.666

2022-11-25 06:38:22,304 - INFO  - Scoreboard best 1 ==> Epoch [69][Top1: 89.330   Top5: 99.720]
2022-11-25 06:38:22,305 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 89.280   Top5: 99.690]
2022-11-25 06:38:22,305 - INFO  - Scoreboard best 3 ==> Epoch [64][Top1: 89.270   Top5: 99.640]
2022-11-25 06:38:28,870 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/_best.pth.tar
save quantized models...
2022-11-25 06:38:28,877 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 06:38:28,877 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:38:31,691 - INFO  - Validation [   20/   40]   Loss 0.411167   Top1 89.199219   Top5 99.589844   BatchTime 0.140618   
2022-11-25 06:38:32,823 - INFO  - Validation [   40/   40]   Loss 0.398819   Top1 89.330000   Top5 99.720000   BatchTime 0.098612   
2022-11-25 06:38:32,990 - INFO  - ==> Top1: 89.330    Top5: 99.720    Loss: 0.399

2022-11-25 06:38:32,990 - INFO  - ==> Sparsity : 0.000

2022-11-25 06:38:32,991 - INFO  - Program completed sucessfully ... exiting ...
2022-11-25 06:38:33,013 - INFO  - >>>>>> Epoch   0
2022-11-25 06:38:33,014 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:38:39,511 - INFO  - Training [0][   20/  196]   Loss 0.341326   Top1 88.828125   Top5 99.882812   BatchTime 0.324728   LR 0.000500   
2022-11-25 06:38:44,324 - INFO  - Training [0][   40/  196]   Loss 0.348891   Top1 88.476562   Top5 99.765625   BatchTime 0.282690   LR 0.000500   
2022-11-25 06:38:49,109 - INFO  - Training [0][   60/  196]   Loss 0.347311   Top1 88.287760   Top5 99.759115   BatchTime 0.268197   LR 0.000499   
2022-11-25 06:38:53,707 - INFO  - Training [0][   80/  196]   Loss 0.352465   Top1 88.100586   Top5 99.721680   BatchTime 0.258627   LR 0.000498   
2022-11-25 06:38:58,574 - INFO  - Training [0][  100/  196]   Loss 0.347876   Top1 88.265625   Top5 99.722656   BatchTime 0.255571   LR 0.000497   
2022-11-25 06:39:03,421 - INFO  - Training [0][  120/  196]   Loss 0.344859   Top1 88.414714   Top5 99.729818   BatchTime 0.253359   LR 0.000495   
2022-11-25 06:39:08,193 - INFO  - Training [0][  140/  196]   Loss 0.340913   Top1 88.482143   Top5 99.734933   BatchTime 0.251254   LR 0.000494   
2022-11-25 06:39:12,914 - INFO  - Training [0][  160/  196]   Loss 0.338354   Top1 88.520508   Top5 99.738770   BatchTime 0.249352   LR 0.000492   
2022-11-25 06:39:17,615 - INFO  - Training [0][  180/  196]   Loss 0.336451   Top1 88.608941   Top5 99.739583   BatchTime 0.247764   LR 0.000490   
2022-11-25 06:39:21,588 - INFO  - ==> Top1: 88.536    Top5: 99.742    Loss: 0.337

2022-11-25 06:39:21,748 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:39:22,668 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:39:25,402 - INFO  - Validation [0][   20/   40]   Loss 0.586822   Top1 81.992188   Top5 99.062500   BatchTime 0.136607   
2022-11-25 06:39:26,565 - INFO  - Validation [0][   40/   40]   Loss 0.582602   Top1 82.210000   Top5 99.240000   BatchTime 0.097394   
2022-11-25 06:39:26,797 - INFO  - ==> Top1: 82.210    Top5: 99.240    Loss: 0.583

2022-11-25 06:39:26,798 - INFO  - ==> Sparsity : 0.694

2022-11-25 06:39:26,798 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 82.210   Top5: 99.240]
2022-11-25 06:39:33,402 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 06:39:33,407 - INFO  - >>>>>> Epoch   1
2022-11-25 06:39:33,410 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:39:39,999 - INFO  - Training [1][   20/  196]   Loss 0.324093   Top1 88.710938   Top5 99.785156   BatchTime 0.329319   LR 0.000485   
2022-11-25 06:39:44,716 - INFO  - Training [1][   40/  196]   Loss 0.318520   Top1 89.042969   Top5 99.765625   BatchTime 0.282584   LR 0.000482   
2022-11-25 06:39:49,489 - INFO  - Training [1][   60/  196]   Loss 0.313314   Top1 89.127604   Top5 99.746094   BatchTime 0.267940   LR 0.000479   
2022-11-25 06:39:54,164 - INFO  - Training [1][   80/  196]   Loss 0.315838   Top1 89.106445   Top5 99.741211   BatchTime 0.259380   LR 0.000476   
2022-11-25 06:39:58,829 - INFO  - Training [1][  100/  196]   Loss 0.316474   Top1 89.062500   Top5 99.746094   BatchTime 0.254159   LR 0.000473   
2022-11-25 06:40:03,299 - INFO  - Training [1][  120/  196]   Loss 0.321023   Top1 88.925781   Top5 99.739583   BatchTime 0.249051   LR 0.000469   
2022-11-25 06:40:08,052 - INFO  - Training [1][  140/  196]   Loss 0.320841   Top1 88.967634   Top5 99.740513   BatchTime 0.247419   LR 0.000465   
2022-11-25 06:40:12,494 - INFO  - Training [1][  160/  196]   Loss 0.318983   Top1 89.052734   Top5 99.743652   BatchTime 0.244256   LR 0.000460   
2022-11-25 06:40:17,381 - INFO  - Training [1][  180/  196]   Loss 0.318651   Top1 89.001736   Top5 99.748264   BatchTime 0.244264   LR 0.000456   
2022-11-25 06:40:21,890 - INFO  - ==> Top1: 88.930    Top5: 99.736    Loss: 0.320

2022-11-25 06:40:22,111 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:40:23,204 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:40:25,881 - INFO  - Validation [1][   20/   40]   Loss 0.521790   Top1 83.769531   Top5 99.062500   BatchTime 0.133783   
2022-11-25 06:40:27,007 - INFO  - Validation [1][   40/   40]   Loss 0.510624   Top1 83.730000   Top5 99.260000   BatchTime 0.095051   
2022-11-25 06:40:27,216 - INFO  - ==> Top1: 83.730    Top5: 99.260    Loss: 0.511

2022-11-25 06:40:27,216 - INFO  - ==> Sparsity : 0.704

2022-11-25 06:40:27,217 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 83.730   Top5: 99.260]
2022-11-25 06:40:27,217 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 82.210   Top5: 99.240]
2022-11-25 06:40:34,142 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 06:40:34,148 - INFO  - >>>>>> Epoch   2
2022-11-25 06:40:34,152 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:40:40,780 - INFO  - Training [2][   20/  196]   Loss 0.305797   Top1 89.199219   Top5 99.804688   BatchTime 0.331263   LR 0.000448   
2022-11-25 06:40:45,525 - INFO  - Training [2][   40/  196]   Loss 0.291052   Top1 89.638672   Top5 99.794922   BatchTime 0.284249   LR 0.000443   
2022-11-25 06:40:50,336 - INFO  - Training [2][   60/  196]   Loss 0.289586   Top1 89.791667   Top5 99.785156   BatchTime 0.269674   LR 0.000437   
2022-11-25 06:40:55,179 - INFO  - Training [2][   80/  196]   Loss 0.292300   Top1 89.853516   Top5 99.775391   BatchTime 0.262798   LR 0.000432   
2022-11-25 06:41:00,170 - INFO  - Training [2][  100/  196]   Loss 0.293981   Top1 89.859375   Top5 99.757812   BatchTime 0.260149   LR 0.000426   
2022-11-25 06:41:05,293 - INFO  - Training [2][  120/  196]   Loss 0.288743   Top1 90.019531   Top5 99.775391   BatchTime 0.259471   LR 0.000421   
2022-11-25 06:41:10,360 - INFO  - Training [2][  140/  196]   Loss 0.289067   Top1 89.997210   Top5 99.779576   BatchTime 0.258604   LR 0.000415   
2022-11-25 06:41:15,346 - INFO  - Training [2][  160/  196]   Loss 0.289710   Top1 89.948730   Top5 99.782715   BatchTime 0.257437   LR 0.000409   
2022-11-25 06:41:20,084 - INFO  - Training [2][  180/  196]   Loss 0.287128   Top1 90.073785   Top5 99.791667   BatchTime 0.255157   LR 0.000402   
2022-11-25 06:41:23,898 - INFO  - ==> Top1: 90.000    Top5: 99.784    Loss: 0.289

2022-11-25 06:41:24,237 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:41:25,997 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:41:28,605 - INFO  - Validation [2][   20/   40]   Loss 0.462788   Top1 85.175781   Top5 99.277344   BatchTime 0.130328   
2022-11-25 06:41:29,789 - INFO  - Validation [2][   40/   40]   Loss 0.465568   Top1 85.000000   Top5 99.430000   BatchTime 0.094775   
2022-11-25 06:41:30,034 - INFO  - ==> Top1: 85.000    Top5: 99.430    Loss: 0.466

2022-11-25 06:41:30,034 - INFO  - ==> Sparsity : 0.710

2022-11-25 06:41:30,034 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 85.000   Top5: 99.430]
2022-11-25 06:41:30,034 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 83.730   Top5: 99.260]
2022-11-25 06:41:30,035 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 82.210   Top5: 99.240]
2022-11-25 06:41:36,833 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 06:41:36,835 - INFO  - >>>>>> Epoch   3
2022-11-25 06:41:36,837 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:41:43,656 - INFO  - Training [3][   20/  196]   Loss 0.259549   Top1 90.878906   Top5 99.843750   BatchTime 0.340794   LR 0.000391   
2022-11-25 06:41:48,456 - INFO  - Training [3][   40/  196]   Loss 0.260631   Top1 90.869141   Top5 99.853516   BatchTime 0.290402   LR 0.000384   
2022-11-25 06:41:53,391 - INFO  - Training [3][   60/  196]   Loss 0.266836   Top1 90.540365   Top5 99.863281   BatchTime 0.275839   LR 0.000377   
2022-11-25 06:41:58,346 - INFO  - Training [3][   80/  196]   Loss 0.268740   Top1 90.532227   Top5 99.873047   BatchTime 0.268821   LR 0.000370   
2022-11-25 06:42:03,679 - INFO  - Training [3][  100/  196]   Loss 0.266598   Top1 90.597656   Top5 99.851562   BatchTime 0.268382   LR 0.000363   
2022-11-25 06:42:08,178 - INFO  - Training [3][  120/  196]   Loss 0.263632   Top1 90.651042   Top5 99.863281   BatchTime 0.261143   LR 0.000356   
2022-11-25 06:42:12,689 - INFO  - Training [3][  140/  196]   Loss 0.263335   Top1 90.711496   Top5 99.854911   BatchTime 0.256063   LR 0.000348   
2022-11-25 06:42:17,440 - INFO  - Training [3][  160/  196]   Loss 0.264199   Top1 90.664062   Top5 99.848633   BatchTime 0.253748   LR 0.000341   
2022-11-25 06:42:22,093 - INFO  - Training [3][  180/  196]   Loss 0.263342   Top1 90.679253   Top5 99.848090   BatchTime 0.251402   LR 0.000333   
2022-11-25 06:42:25,878 - INFO  - ==> Top1: 90.650    Top5: 99.846    Loss: 0.264

2022-11-25 06:42:26,202 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:42:27,810 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:42:30,605 - INFO  - Validation [3][   20/   40]   Loss 0.420512   Top1 87.363281   Top5 99.179688   BatchTime 0.139688   
2022-11-25 06:42:31,714 - INFO  - Validation [3][   40/   40]   Loss 0.411360   Top1 87.010000   Top5 99.400000   BatchTime 0.097556   
2022-11-25 06:42:31,961 - INFO  - ==> Top1: 87.010    Top5: 99.400    Loss: 0.411

2022-11-25 06:42:31,961 - INFO  - ==> Sparsity : 0.714

2022-11-25 06:42:31,962 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 87.010   Top5: 99.400]
2022-11-25 06:42:31,962 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 85.000   Top5: 99.430]
2022-11-25 06:42:31,962 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 83.730   Top5: 99.260]
2022-11-25 06:42:38,190 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 06:42:38,193 - INFO  - >>>>>> Epoch   4
2022-11-25 06:42:38,195 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:42:44,905 - INFO  - Training [4][   20/  196]   Loss 0.221808   Top1 92.441406   Top5 99.863281   BatchTime 0.335397   LR 0.000320   
2022-11-25 06:42:49,706 - INFO  - Training [4][   40/  196]   Loss 0.225872   Top1 92.304688   Top5 99.843750   BatchTime 0.287707   LR 0.000312   
2022-11-25 06:42:54,702 - INFO  - Training [4][   60/  196]   Loss 0.228345   Top1 92.207031   Top5 99.876302   BatchTime 0.275079   LR 0.000304   
2022-11-25 06:42:59,860 - INFO  - Training [4][   80/  196]   Loss 0.234044   Top1 92.070312   Top5 99.873047   BatchTime 0.270779   LR 0.000296   
2022-11-25 06:43:04,629 - INFO  - Training [4][  100/  196]   Loss 0.235722   Top1 91.964844   Top5 99.875000   BatchTime 0.264309   LR 0.000289   
2022-11-25 06:43:09,461 - INFO  - Training [4][  120/  196]   Loss 0.233684   Top1 92.037760   Top5 99.889323   BatchTime 0.260527   LR 0.000281   
2022-11-25 06:43:14,217 - INFO  - Training [4][  140/  196]   Loss 0.231619   Top1 92.117746   Top5 99.896763   BatchTime 0.257278   LR 0.000273   
2022-11-25 06:43:19,208 - INFO  - Training [4][  160/  196]   Loss 0.233019   Top1 92.001953   Top5 99.892578   BatchTime 0.256313   LR 0.000265   
2022-11-25 06:43:23,991 - INFO  - Training [4][  180/  196]   Loss 0.230101   Top1 92.078993   Top5 99.895833   BatchTime 0.254407   LR 0.000257   
2022-11-25 06:43:28,181 - INFO  - ==> Top1: 92.052    Top5: 99.902    Loss: 0.231

2022-11-25 06:43:28,377 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:43:29,896 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:43:32,524 - INFO  - Validation [4][   20/   40]   Loss 0.394037   Top1 87.558594   Top5 99.414062   BatchTime 0.131198   
2022-11-25 06:43:33,724 - INFO  - Validation [4][   40/   40]   Loss 0.393233   Top1 87.490000   Top5 99.520000   BatchTime 0.095642   
2022-11-25 06:43:33,956 - INFO  - ==> Top1: 87.490    Top5: 99.520    Loss: 0.393

2022-11-25 06:43:33,956 - INFO  - ==> Sparsity : 0.716

2022-11-25 06:43:33,957 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 87.490   Top5: 99.520]
2022-11-25 06:43:33,957 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 87.010   Top5: 99.400]
2022-11-25 06:43:33,957 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 85.000   Top5: 99.430]
2022-11-25 06:43:39,925 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 06:43:39,933 - INFO  - >>>>>> Epoch   5
2022-11-25 06:43:39,936 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:43:46,668 - INFO  - Training [5][   20/  196]   Loss 0.211270   Top1 92.636719   Top5 99.960938   BatchTime 0.336452   LR 0.000242   
2022-11-25 06:43:51,412 - INFO  - Training [5][   40/  196]   Loss 0.208673   Top1 92.783203   Top5 99.951172   BatchTime 0.286828   LR 0.000234   
2022-11-25 06:43:55,941 - INFO  - Training [5][   60/  196]   Loss 0.202565   Top1 92.864583   Top5 99.915365   BatchTime 0.266698   LR 0.000226   
2022-11-25 06:44:00,633 - INFO  - Training [5][   80/  196]   Loss 0.203828   Top1 92.822266   Top5 99.916992   BatchTime 0.258667   LR 0.000218   
2022-11-25 06:44:05,222 - INFO  - Training [5][  100/  196]   Loss 0.203001   Top1 92.839844   Top5 99.914062   BatchTime 0.252829   LR 0.000210   
2022-11-25 06:44:09,721 - INFO  - Training [5][  120/  196]   Loss 0.202101   Top1 92.845052   Top5 99.915365   BatchTime 0.248182   LR 0.000202   
2022-11-25 06:44:14,257 - INFO  - Training [5][  140/  196]   Loss 0.204616   Top1 92.748326   Top5 99.913504   BatchTime 0.245128   LR 0.000195   
2022-11-25 06:44:18,893 - INFO  - Training [5][  160/  196]   Loss 0.202737   Top1 92.832031   Top5 99.919434   BatchTime 0.243462   LR 0.000187   
2022-11-25 06:44:23,459 - INFO  - Training [5][  180/  196]   Loss 0.199034   Top1 92.949219   Top5 99.921875   BatchTime 0.241774   LR 0.000179   
2022-11-25 06:44:27,082 - INFO  - ==> Top1: 92.950    Top5: 99.924    Loss: 0.199

2022-11-25 06:44:27,267 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:44:28,383 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:44:31,223 - INFO  - Validation [5][   20/   40]   Loss 0.367166   Top1 88.164062   Top5 99.531250   BatchTime 0.141891   
2022-11-25 06:44:32,364 - INFO  - Validation [5][   40/   40]   Loss 0.362598   Top1 88.350000   Top5 99.580000   BatchTime 0.099491   
2022-11-25 06:44:32,607 - INFO  - ==> Top1: 88.350    Top5: 99.580    Loss: 0.363

2022-11-25 06:44:32,607 - INFO  - ==> Sparsity : 0.717

2022-11-25 06:44:32,607 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 88.350   Top5: 99.580]
2022-11-25 06:44:32,607 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 87.490   Top5: 99.520]
2022-11-25 06:44:32,608 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 87.010   Top5: 99.400]
2022-11-25 06:44:37,255 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 06:44:37,257 - INFO  - >>>>>> Epoch   6
2022-11-25 06:44:37,258 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:44:43,246 - INFO  - Training [6][   20/  196]   Loss 0.169732   Top1 93.886719   Top5 99.941406   BatchTime 0.299278   LR 0.000166   
2022-11-25 06:44:48,359 - INFO  - Training [6][   40/  196]   Loss 0.171077   Top1 94.082031   Top5 99.921875   BatchTime 0.277444   LR 0.000158   
2022-11-25 06:44:52,648 - INFO  - Training [6][   60/  196]   Loss 0.173223   Top1 94.010417   Top5 99.928385   BatchTime 0.256456   LR 0.000151   
2022-11-25 06:44:57,093 - INFO  - Training [6][   80/  196]   Loss 0.168347   Top1 94.111328   Top5 99.926758   BatchTime 0.247898   LR 0.000143   
2022-11-25 06:45:01,434 - INFO  - Training [6][  100/  196]   Loss 0.169296   Top1 94.093750   Top5 99.917969   BatchTime 0.241732   LR 0.000136   
2022-11-25 06:45:05,943 - INFO  - Training [6][  120/  196]   Loss 0.167476   Top1 94.140625   Top5 99.925130   BatchTime 0.239015   LR 0.000129   
2022-11-25 06:45:10,692 - INFO  - Training [6][  140/  196]   Loss 0.166290   Top1 94.168527   Top5 99.930246   BatchTime 0.238793   LR 0.000122   
2022-11-25 06:45:15,504 - INFO  - Training [6][  160/  196]   Loss 0.167049   Top1 94.106445   Top5 99.929199   BatchTime 0.239016   LR 0.000115   
2022-11-25 06:45:19,931 - INFO  - Training [6][  180/  196]   Loss 0.164491   Top1 94.225260   Top5 99.928385   BatchTime 0.237051   LR 0.000108   
2022-11-25 06:45:23,989 - INFO  - ==> Top1: 94.224    Top5: 99.926    Loss: 0.165

2022-11-25 06:45:24,185 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:45:25,270 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:45:28,083 - INFO  - Validation [6][   20/   40]   Loss 0.384046   Top1 88.476562   Top5 99.648438   BatchTime 0.140572   
2022-11-25 06:45:29,203 - INFO  - Validation [6][   40/   40]   Loss 0.369206   Top1 88.670000   Top5 99.700000   BatchTime 0.098271   
2022-11-25 06:45:29,460 - INFO  - ==> Top1: 88.670    Top5: 99.700    Loss: 0.369

2022-11-25 06:45:29,461 - INFO  - ==> Sparsity : 0.718

2022-11-25 06:45:29,461 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 88.670   Top5: 99.700]
2022-11-25 06:45:29,461 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 88.350   Top5: 99.580]
2022-11-25 06:45:29,461 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 87.490   Top5: 99.520]
2022-11-25 06:45:34,055 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 06:45:34,057 - INFO  - >>>>>> Epoch   7
2022-11-25 06:45:34,059 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:45:40,302 - INFO  - Training [7][   20/  196]   Loss 0.144881   Top1 94.882812   Top5 99.980469   BatchTime 0.312019   LR 0.000097   
2022-11-25 06:45:45,122 - INFO  - Training [7][   40/  196]   Loss 0.143939   Top1 94.990234   Top5 99.970703   BatchTime 0.276506   LR 0.000091   
2022-11-25 06:45:49,852 - INFO  - Training [7][   60/  196]   Loss 0.142202   Top1 95.071615   Top5 99.973958   BatchTime 0.263172   LR 0.000085   
2022-11-25 06:45:54,423 - INFO  - Training [7][   80/  196]   Loss 0.142915   Top1 95.073242   Top5 99.956055   BatchTime 0.254519   LR 0.000079   
2022-11-25 06:45:58,909 - INFO  - Training [7][  100/  196]   Loss 0.144387   Top1 94.976562   Top5 99.964844   BatchTime 0.248467   LR 0.000073   
2022-11-25 06:46:03,638 - INFO  - Training [7][  120/  196]   Loss 0.143433   Top1 95.000000   Top5 99.964193   BatchTime 0.246469   LR 0.000067   
2022-11-25 06:46:08,056 - INFO  - Training [7][  140/  196]   Loss 0.142681   Top1 95.011161   Top5 99.963728   BatchTime 0.242810   LR 0.000062   
2022-11-25 06:46:12,446 - INFO  - Training [7][  160/  196]   Loss 0.140957   Top1 95.063477   Top5 99.968262   BatchTime 0.239900   LR 0.000057   
2022-11-25 06:46:16,525 - INFO  - Training [7][  180/  196]   Loss 0.139778   Top1 95.058594   Top5 99.967448   BatchTime 0.235906   LR 0.000052   
2022-11-25 06:46:19,879 - INFO  - ==> Top1: 95.080    Top5: 99.968    Loss: 0.140

2022-11-25 06:46:20,072 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:46:21,304 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:46:24,134 - INFO  - Validation [7][   20/   40]   Loss 0.352463   Top1 89.140625   Top5 99.667969   BatchTime 0.141411   
2022-11-25 06:46:25,211 - INFO  - Validation [7][   40/   40]   Loss 0.342417   Top1 89.510000   Top5 99.730000   BatchTime 0.097631   
2022-11-25 06:46:25,459 - INFO  - ==> Top1: 89.510    Top5: 99.730    Loss: 0.342

2022-11-25 06:46:25,460 - INFO  - ==> Sparsity : 0.718

2022-11-25 06:46:25,460 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:46:25,460 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 88.670   Top5: 99.700]
2022-11-25 06:46:25,460 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 88.350   Top5: 99.580]
2022-11-25 06:46:30,362 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 06:46:30,364 - INFO  - >>>>>> Epoch   8
2022-11-25 06:46:30,367 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:46:36,952 - INFO  - Training [8][   20/  196]   Loss 0.123463   Top1 95.898438   Top5 99.902344   BatchTime 0.329143   LR 0.000043   
2022-11-25 06:46:41,620 - INFO  - Training [8][   40/  196]   Loss 0.119202   Top1 95.996094   Top5 99.931641   BatchTime 0.281277   LR 0.000039   
2022-11-25 06:46:46,181 - INFO  - Training [8][   60/  196]   Loss 0.123522   Top1 95.683594   Top5 99.954427   BatchTime 0.263525   LR 0.000035   
2022-11-25 06:46:50,658 - INFO  - Training [8][   80/  196]   Loss 0.126516   Top1 95.517578   Top5 99.956055   BatchTime 0.253610   LR 0.000031   
2022-11-25 06:46:55,406 - INFO  - Training [8][  100/  196]   Loss 0.126779   Top1 95.558594   Top5 99.949219   BatchTime 0.250363   LR 0.000027   
2022-11-25 06:47:00,242 - INFO  - Training [8][  120/  196]   Loss 0.124838   Top1 95.618490   Top5 99.954427   BatchTime 0.248934   LR 0.000023   
2022-11-25 06:47:05,073 - INFO  - Training [8][  140/  196]   Loss 0.123550   Top1 95.644531   Top5 99.960938   BatchTime 0.247884   LR 0.000020   
2022-11-25 06:47:09,614 - INFO  - Training [8][  160/  196]   Loss 0.123324   Top1 95.673828   Top5 99.963379   BatchTime 0.245280   LR 0.000017   
2022-11-25 06:47:14,007 - INFO  - Training [8][  180/  196]   Loss 0.122708   Top1 95.696615   Top5 99.960938   BatchTime 0.242429   LR 0.000014   
2022-11-25 06:47:17,792 - INFO  - ==> Top1: 95.676    Top5: 99.962    Loss: 0.123

2022-11-25 06:47:17,981 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:47:19,114 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:47:22,073 - INFO  - Validation [8][   20/   40]   Loss 0.353448   Top1 89.414062   Top5 99.687500   BatchTime 0.147830   
2022-11-25 06:47:23,091 - INFO  - Validation [8][   40/   40]   Loss 0.344514   Top1 89.620000   Top5 99.770000   BatchTime 0.099374   
2022-11-25 06:47:23,343 - INFO  - ==> Top1: 89.620    Top5: 99.770    Loss: 0.345

2022-11-25 06:47:23,343 - INFO  - ==> Sparsity : 0.718

2022-11-25 06:47:23,343 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:47:23,344 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:47:23,344 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 88.670   Top5: 99.700]
2022-11-25 06:47:28,475 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 06:47:28,477 - INFO  - >>>>>> Epoch   9
2022-11-25 06:47:28,479 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:47:35,114 - INFO  - Training [9][   20/  196]   Loss 0.114615   Top1 96.269531   Top5 99.960938   BatchTime 0.331649   LR 0.000010   
2022-11-25 06:47:39,706 - INFO  - Training [9][   40/  196]   Loss 0.118854   Top1 95.751953   Top5 99.951172   BatchTime 0.280616   LR 0.000008   
2022-11-25 06:47:44,515 - INFO  - Training [9][   60/  196]   Loss 0.116383   Top1 95.852865   Top5 99.947917   BatchTime 0.267223   LR 0.000006   
2022-11-25 06:47:49,130 - INFO  - Training [9][   80/  196]   Loss 0.114408   Top1 95.957031   Top5 99.951172   BatchTime 0.258111   LR 0.000004   
2022-11-25 06:47:53,845 - INFO  - Training [9][  100/  196]   Loss 0.112310   Top1 96.007812   Top5 99.957031   BatchTime 0.253638   LR 0.000003   
2022-11-25 06:47:58,599 - INFO  - Training [9][  120/  196]   Loss 0.111747   Top1 96.025391   Top5 99.964193   BatchTime 0.250978   LR 0.000002   
2022-11-25 06:48:03,356 - INFO  - Training [9][  140/  196]   Loss 0.111673   Top1 96.065848   Top5 99.966518   BatchTime 0.249101   LR 0.000001   
2022-11-25 06:48:08,299 - INFO  - Training [9][  160/  196]   Loss 0.111702   Top1 96.054688   Top5 99.968262   BatchTime 0.248858   LR 0.000000   
2022-11-25 06:48:12,889 - INFO  - Training [9][  180/  196]   Loss 0.111208   Top1 96.078559   Top5 99.967448   BatchTime 0.246709   LR 0.000000   
2022-11-25 06:48:16,482 - INFO  - ==> Top1: 96.084    Top5: 99.968    Loss: 0.112

2022-11-25 06:48:16,666 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:48:17,622 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:48:20,612 - INFO  - Validation [9][   20/   40]   Loss 0.353066   Top1 89.648438   Top5 99.628906   BatchTime 0.149408   
2022-11-25 06:48:21,698 - INFO  - Validation [9][   40/   40]   Loss 0.343429   Top1 89.810000   Top5 99.690000   BatchTime 0.101855   
2022-11-25 06:48:21,961 - INFO  - ==> Top1: 89.810    Top5: 99.690    Loss: 0.343

2022-11-25 06:48:21,961 - INFO  - ==> Sparsity : 0.718

2022-11-25 06:48:21,962 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:48:21,962 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:48:21,962 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:48:27,041 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 06:48:27,044 - INFO  - >>>>>> Epoch  10
2022-11-25 06:48:27,046 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:48:33,802 - INFO  - Training [10][   20/  196]   Loss 0.140573   Top1 95.078125   Top5 99.960938   BatchTime 0.337707   LR 0.000250   
2022-11-25 06:48:38,301 - INFO  - Training [10][   40/  196]   Loss 0.158661   Top1 94.306641   Top5 99.960938   BatchTime 0.281313   LR 0.000250   
2022-11-25 06:48:42,853 - INFO  - Training [10][   60/  196]   Loss 0.171373   Top1 93.893229   Top5 99.960938   BatchTime 0.263419   LR 0.000250   
2022-11-25 06:48:47,674 - INFO  - Training [10][   80/  196]   Loss 0.179332   Top1 93.691406   Top5 99.936523   BatchTime 0.257822   LR 0.000250   
2022-11-25 06:48:52,434 - INFO  - Training [10][  100/  196]   Loss 0.183104   Top1 93.574219   Top5 99.933594   BatchTime 0.253849   LR 0.000250   
2022-11-25 06:48:57,138 - INFO  - Training [10][  120/  196]   Loss 0.189454   Top1 93.382161   Top5 99.912109   BatchTime 0.250745   LR 0.000249   
2022-11-25 06:49:01,818 - INFO  - Training [10][  140/  196]   Loss 0.193396   Top1 93.203125   Top5 99.916295   BatchTime 0.248350   LR 0.000249   
2022-11-25 06:49:06,500 - INFO  - Training [10][  160/  196]   Loss 0.194880   Top1 93.151855   Top5 99.914551   BatchTime 0.246567   LR 0.000249   
2022-11-25 06:49:10,947 - INFO  - Training [10][  180/  196]   Loss 0.199046   Top1 93.012153   Top5 99.904514   BatchTime 0.243878   LR 0.000249   
2022-11-25 06:49:14,870 - INFO  - ==> Top1: 92.986    Top5: 99.906    Loss: 0.199

2022-11-25 06:49:15,063 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:49:16,228 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:49:19,190 - INFO  - Validation [10][   20/   40]   Loss 0.438099   Top1 87.011719   Top5 99.414062   BatchTime 0.147990   
2022-11-25 06:49:20,286 - INFO  - Validation [10][   40/   40]   Loss 0.420838   Top1 87.070000   Top5 99.540000   BatchTime 0.101398   
2022-11-25 06:49:20,547 - INFO  - ==> Top1: 87.070    Top5: 99.540    Loss: 0.421

2022-11-25 06:49:20,547 - INFO  - ==> Sparsity : 0.720

2022-11-25 06:49:20,548 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:49:20,548 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:49:20,548 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:49:20,683 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:49:20,684 - INFO  - >>>>>> Epoch  11
2022-11-25 06:49:20,686 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:49:27,294 - INFO  - Training [11][   20/  196]   Loss 0.532516   Top1 82.753906   Top5 97.011719   BatchTime 0.330259   LR 0.000248   
2022-11-25 06:49:31,917 - INFO  - Training [11][   40/  196]   Loss 0.501437   Top1 83.691406   Top5 98.134766   BatchTime 0.280712   LR 0.000248   
2022-11-25 06:49:36,680 - INFO  - Training [11][   60/  196]   Loss 0.450473   Top1 85.039062   Top5 98.619792   BatchTime 0.266516   LR 0.000247   
2022-11-25 06:49:41,199 - INFO  - Training [11][   80/  196]   Loss 0.415775   Top1 86.015625   Top5 98.911133   BatchTime 0.256371   LR 0.000247   
2022-11-25 06:49:45,902 - INFO  - Training [11][  100/  196]   Loss 0.388828   Top1 86.855469   Top5 99.089844   BatchTime 0.252130   LR 0.000247   
2022-11-25 06:49:50,660 - INFO  - Training [11][  120/  196]   Loss 0.367543   Top1 87.565104   Top5 99.189453   BatchTime 0.249752   LR 0.000246   
2022-11-25 06:49:55,293 - INFO  - Training [11][  140/  196]   Loss 0.350479   Top1 88.111049   Top5 99.294085   BatchTime 0.247172   LR 0.000246   
2022-11-25 06:50:00,091 - INFO  - Training [11][  160/  196]   Loss 0.336257   Top1 88.554688   Top5 99.367676   BatchTime 0.246259   LR 0.000245   
2022-11-25 06:50:04,555 - INFO  - Training [11][  180/  196]   Loss 0.325845   Top1 88.869358   Top5 99.424913   BatchTime 0.243694   LR 0.000244   
2022-11-25 06:50:08,245 - INFO  - ==> Top1: 89.100    Top5: 99.458    Loss: 0.319

2022-11-25 06:50:08,409 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:50:09,526 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:50:12,504 - INFO  - Validation [11][   20/   40]   Loss 0.427027   Top1 86.894531   Top5 99.511719   BatchTime 0.148799   
2022-11-25 06:50:13,585 - INFO  - Validation [11][   40/   40]   Loss 0.419085   Top1 86.880000   Top5 99.630000   BatchTime 0.101430   
2022-11-25 06:50:13,841 - INFO  - ==> Top1: 86.880    Top5: 99.630    Loss: 0.419

2022-11-25 06:50:13,841 - INFO  - ==> Sparsity : 0.725

2022-11-25 06:50:13,841 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:50:13,841 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:50:13,841 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:50:13,956 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:50:13,957 - INFO  - >>>>>> Epoch  12
2022-11-25 06:50:13,959 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:50:20,252 - INFO  - Training [12][   20/  196]   Loss 0.203832   Top1 92.968750   Top5 99.863281   BatchTime 0.314542   LR 0.000243   
2022-11-25 06:50:24,855 - INFO  - Training [12][   40/  196]   Loss 0.205626   Top1 93.037109   Top5 99.882812   BatchTime 0.272351   LR 0.000243   
2022-11-25 06:50:30,191 - INFO  - Training [12][   60/  196]   Loss 0.208144   Top1 92.851562   Top5 99.882812   BatchTime 0.270492   LR 0.000242   
2022-11-25 06:50:35,119 - INFO  - Training [12][   80/  196]   Loss 0.204322   Top1 92.963867   Top5 99.887695   BatchTime 0.264471   LR 0.000241   
2022-11-25 06:50:39,757 - INFO  - Training [12][  100/  196]   Loss 0.208407   Top1 92.812500   Top5 99.894531   BatchTime 0.257951   LR 0.000240   
2022-11-25 06:50:44,324 - INFO  - Training [12][  120/  196]   Loss 0.207845   Top1 92.802734   Top5 99.902344   BatchTime 0.253022   LR 0.000240   
2022-11-25 06:50:48,929 - INFO  - Training [12][  140/  196]   Loss 0.207584   Top1 92.809710   Top5 99.902344   BatchTime 0.249766   LR 0.000239   
2022-11-25 06:50:53,703 - INFO  - Training [12][  160/  196]   Loss 0.206640   Top1 92.790527   Top5 99.907227   BatchTime 0.248379   LR 0.000238   
2022-11-25 06:50:58,370 - INFO  - Training [12][  180/  196]   Loss 0.207507   Top1 92.814670   Top5 99.904514   BatchTime 0.246711   LR 0.000237   
2022-11-25 06:51:02,054 - INFO  - ==> Top1: 92.758    Top5: 99.908    Loss: 0.208

2022-11-25 06:51:02,226 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:51:03,287 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:51:06,242 - INFO  - Validation [12][   20/   40]   Loss 0.403498   Top1 87.285156   Top5 99.453125   BatchTime 0.147623   
2022-11-25 06:51:07,343 - INFO  - Validation [12][   40/   40]   Loss 0.389719   Top1 87.600000   Top5 99.620000   BatchTime 0.101350   
2022-11-25 06:51:07,581 - INFO  - ==> Top1: 87.600    Top5: 99.620    Loss: 0.390

2022-11-25 06:51:07,581 - INFO  - ==> Sparsity : 0.726

2022-11-25 06:51:07,581 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:51:07,582 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:51:07,582 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:51:07,702 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:51:07,703 - INFO  - >>>>>> Epoch  13
2022-11-25 06:51:07,705 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:51:14,070 - INFO  - Training [13][   20/  196]   Loss 0.188649   Top1 93.359375   Top5 99.882812   BatchTime 0.318140   LR 0.000235   
2022-11-25 06:51:18,583 - INFO  - Training [13][   40/  196]   Loss 0.188553   Top1 93.281250   Top5 99.873047   BatchTime 0.271889   LR 0.000235   
2022-11-25 06:51:23,086 - INFO  - Training [13][   60/  196]   Loss 0.184123   Top1 93.541667   Top5 99.895833   BatchTime 0.256310   LR 0.000234   
2022-11-25 06:51:27,653 - INFO  - Training [13][   80/  196]   Loss 0.184452   Top1 93.559570   Top5 99.916992   BatchTime 0.249317   LR 0.000233   
2022-11-25 06:51:32,285 - INFO  - Training [13][  100/  196]   Loss 0.186061   Top1 93.496094   Top5 99.917969   BatchTime 0.245772   LR 0.000232   
2022-11-25 06:51:37,058 - INFO  - Training [13][  120/  196]   Loss 0.182262   Top1 93.623047   Top5 99.925130   BatchTime 0.244585   LR 0.000230   
2022-11-25 06:51:41,565 - INFO  - Training [13][  140/  196]   Loss 0.184353   Top1 93.557478   Top5 99.927455   BatchTime 0.241834   LR 0.000229   
2022-11-25 06:51:46,277 - INFO  - Training [13][  160/  196]   Loss 0.185657   Top1 93.491211   Top5 99.921875   BatchTime 0.241058   LR 0.000228   
2022-11-25 06:51:50,571 - INFO  - Training [13][  180/  196]   Loss 0.185746   Top1 93.470052   Top5 99.919705   BatchTime 0.238126   LR 0.000227   
2022-11-25 06:51:54,307 - INFO  - ==> Top1: 93.502    Top5: 99.922    Loss: 0.185

2022-11-25 06:51:54,542 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:51:55,629 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:51:58,549 - INFO  - Validation [13][   20/   40]   Loss 0.417932   Top1 87.148438   Top5 99.550781   BatchTime 0.145906   
2022-11-25 06:51:59,665 - INFO  - Validation [13][   40/   40]   Loss 0.406117   Top1 87.530000   Top5 99.670000   BatchTime 0.100850   
2022-11-25 06:51:59,924 - INFO  - ==> Top1: 87.530    Top5: 99.670    Loss: 0.406

2022-11-25 06:51:59,924 - INFO  - ==> Sparsity : 0.727

2022-11-25 06:51:59,924 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:51:59,924 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:51:59,924 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:52:00,055 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:52:00,056 - INFO  - >>>>>> Epoch  14
2022-11-25 06:52:00,058 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:52:06,158 - INFO  - Training [14][   20/  196]   Loss 0.174717   Top1 93.554688   Top5 99.921875   BatchTime 0.304870   LR 0.000225   
2022-11-25 06:52:10,711 - INFO  - Training [14][   40/  196]   Loss 0.172352   Top1 93.652344   Top5 99.921875   BatchTime 0.266253   LR 0.000224   
2022-11-25 06:52:15,728 - INFO  - Training [14][   60/  196]   Loss 0.174839   Top1 93.567708   Top5 99.921875   BatchTime 0.261126   LR 0.000223   
2022-11-25 06:52:20,418 - INFO  - Training [14][   80/  196]   Loss 0.179058   Top1 93.559570   Top5 99.926758   BatchTime 0.254466   LR 0.000221   
2022-11-25 06:52:25,255 - INFO  - Training [14][  100/  196]   Loss 0.177554   Top1 93.652344   Top5 99.933594   BatchTime 0.251939   LR 0.000220   
2022-11-25 06:52:29,907 - INFO  - Training [14][  120/  196]   Loss 0.176245   Top1 93.766276   Top5 99.934896   BatchTime 0.248715   LR 0.000219   
2022-11-25 06:52:34,478 - INFO  - Training [14][  140/  196]   Loss 0.175565   Top1 93.777902   Top5 99.935826   BatchTime 0.245837   LR 0.000217   
2022-11-25 06:52:39,322 - INFO  - Training [14][  160/  196]   Loss 0.175080   Top1 93.771973   Top5 99.931641   BatchTime 0.245377   LR 0.000216   
2022-11-25 06:52:43,708 - INFO  - Training [14][  180/  196]   Loss 0.175897   Top1 93.754340   Top5 99.924045   BatchTime 0.242481   LR 0.000215   
2022-11-25 06:52:47,344 - INFO  - ==> Top1: 93.762    Top5: 99.926    Loss: 0.177

2022-11-25 06:52:47,540 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:52:48,730 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:52:51,790 - INFO  - Validation [14][   20/   40]   Loss 0.381406   Top1 88.750000   Top5 99.570312   BatchTime 0.152918   
2022-11-25 06:52:52,909 - INFO  - Validation [14][   40/   40]   Loss 0.377993   Top1 88.480000   Top5 99.640000   BatchTime 0.104430   
2022-11-25 06:52:53,193 - INFO  - ==> Top1: 88.480    Top5: 99.640    Loss: 0.378

2022-11-25 06:52:53,193 - INFO  - ==> Sparsity : 0.728

2022-11-25 06:52:53,194 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:52:53,194 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:52:53,194 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:52:53,316 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:52:53,318 - INFO  - >>>>>> Epoch  15
2022-11-25 06:52:53,319 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:53:00,082 - INFO  - Training [15][   20/  196]   Loss 0.171030   Top1 93.789062   Top5 99.980469   BatchTime 0.338033   LR 0.000212   
2022-11-25 06:53:04,579 - INFO  - Training [15][   40/  196]   Loss 0.163501   Top1 94.091797   Top5 99.951172   BatchTime 0.281431   LR 0.000211   
2022-11-25 06:53:09,078 - INFO  - Training [15][   60/  196]   Loss 0.164687   Top1 94.082031   Top5 99.947917   BatchTime 0.262604   LR 0.000209   
2022-11-25 06:53:13,809 - INFO  - Training [15][   80/  196]   Loss 0.162300   Top1 94.208984   Top5 99.951172   BatchTime 0.256092   LR 0.000208   
2022-11-25 06:53:18,423 - INFO  - Training [15][  100/  196]   Loss 0.164465   Top1 94.183594   Top5 99.941406   BatchTime 0.251008   LR 0.000206   
2022-11-25 06:53:23,107 - INFO  - Training [15][  120/  196]   Loss 0.166159   Top1 94.108073   Top5 99.941406   BatchTime 0.248206   LR 0.000205   
2022-11-25 06:53:27,579 - INFO  - Training [15][  140/  196]   Loss 0.167778   Top1 94.076451   Top5 99.946987   BatchTime 0.244695   LR 0.000203   
2022-11-25 06:53:32,193 - INFO  - Training [15][  160/  196]   Loss 0.167894   Top1 94.077148   Top5 99.948730   BatchTime 0.242940   LR 0.000201   
2022-11-25 06:53:36,954 - INFO  - Training [15][  180/  196]   Loss 0.167345   Top1 94.095052   Top5 99.950087   BatchTime 0.242401   LR 0.000200   
2022-11-25 06:53:40,760 - INFO  - ==> Top1: 94.078    Top5: 99.946    Loss: 0.167

2022-11-25 06:53:40,918 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:53:42,143 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:53:45,104 - INFO  - Validation [15][   20/   40]   Loss 0.393919   Top1 87.968750   Top5 99.472656   BatchTime 0.147980   
2022-11-25 06:53:46,166 - INFO  - Validation [15][   40/   40]   Loss 0.386579   Top1 88.120000   Top5 99.610000   BatchTime 0.100548   
2022-11-25 06:53:46,413 - INFO  - ==> Top1: 88.120    Top5: 99.610    Loss: 0.387

2022-11-25 06:53:46,413 - INFO  - ==> Sparsity : 0.729

2022-11-25 06:53:46,413 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:53:46,413 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:53:46,414 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:53:46,548 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:53:46,550 - INFO  - >>>>>> Epoch  16
2022-11-25 06:53:46,551 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:53:53,557 - INFO  - Training [16][   20/  196]   Loss 0.155852   Top1 94.863281   Top5 99.921875   BatchTime 0.350131   LR 0.000197   
2022-11-25 06:53:58,367 - INFO  - Training [16][   40/  196]   Loss 0.154523   Top1 94.667969   Top5 99.931641   BatchTime 0.295325   LR 0.000195   
2022-11-25 06:54:03,149 - INFO  - Training [16][   60/  196]   Loss 0.158788   Top1 94.524740   Top5 99.928385   BatchTime 0.276586   LR 0.000194   
2022-11-25 06:54:07,908 - INFO  - Training [16][   80/  196]   Loss 0.160374   Top1 94.438477   Top5 99.931641   BatchTime 0.266921   LR 0.000192   
2022-11-25 06:54:12,478 - INFO  - Training [16][  100/  196]   Loss 0.163020   Top1 94.281250   Top5 99.933594   BatchTime 0.259235   LR 0.000190   
2022-11-25 06:54:16,959 - INFO  - Training [16][  120/  196]   Loss 0.161370   Top1 94.332682   Top5 99.938151   BatchTime 0.253370   LR 0.000188   
2022-11-25 06:54:21,677 - INFO  - Training [16][  140/  196]   Loss 0.160834   Top1 94.369420   Top5 99.924665   BatchTime 0.250875   LR 0.000187   
2022-11-25 06:54:26,381 - INFO  - Training [16][  160/  196]   Loss 0.162484   Top1 94.338379   Top5 99.926758   BatchTime 0.248911   LR 0.000185   
2022-11-25 06:54:31,073 - INFO  - Training [16][  180/  196]   Loss 0.162647   Top1 94.346788   Top5 99.924045   BatchTime 0.247324   LR 0.000183   
2022-11-25 06:54:34,717 - INFO  - ==> Top1: 94.306    Top5: 99.924    Loss: 0.163

2022-11-25 06:54:34,896 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:54:36,082 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:54:39,096 - INFO  - Validation [16][   20/   40]   Loss 0.386109   Top1 88.085938   Top5 99.628906   BatchTime 0.150626   
2022-11-25 06:54:40,171 - INFO  - Validation [16][   40/   40]   Loss 0.388862   Top1 88.000000   Top5 99.690000   BatchTime 0.102186   
2022-11-25 06:54:40,435 - INFO  - ==> Top1: 88.000    Top5: 99.690    Loss: 0.389

2022-11-25 06:54:40,435 - INFO  - ==> Sparsity : 0.730

2022-11-25 06:54:40,436 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:54:40,436 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:54:40,436 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:54:40,570 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:54:40,572 - INFO  - >>>>>> Epoch  17
2022-11-25 06:54:40,573 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:54:47,096 - INFO  - Training [17][   20/  196]   Loss 0.152507   Top1 94.453125   Top5 99.902344   BatchTime 0.326019   LR 0.000180   
2022-11-25 06:54:51,591 - INFO  - Training [17][   40/  196]   Loss 0.155805   Top1 94.482422   Top5 99.931641   BatchTime 0.275368   LR 0.000178   
2022-11-25 06:54:56,183 - INFO  - Training [17][   60/  196]   Loss 0.154545   Top1 94.472656   Top5 99.954427   BatchTime 0.260116   LR 0.000176   
2022-11-25 06:55:00,838 - INFO  - Training [17][   80/  196]   Loss 0.152906   Top1 94.497070   Top5 99.956055   BatchTime 0.253277   LR 0.000175   
2022-11-25 06:55:05,348 - INFO  - Training [17][  100/  196]   Loss 0.151982   Top1 94.570312   Top5 99.953125   BatchTime 0.247715   LR 0.000173   
2022-11-25 06:55:10,253 - INFO  - Training [17][  120/  196]   Loss 0.152909   Top1 94.554036   Top5 99.954427   BatchTime 0.247308   LR 0.000171   
2022-11-25 06:55:14,934 - INFO  - Training [17][  140/  196]   Loss 0.153648   Top1 94.514509   Top5 99.960938   BatchTime 0.245407   LR 0.000169   
2022-11-25 06:55:19,392 - INFO  - Training [17][  160/  196]   Loss 0.152894   Top1 94.577637   Top5 99.951172   BatchTime 0.242598   LR 0.000167   
2022-11-25 06:55:23,832 - INFO  - Training [17][  180/  196]   Loss 0.153407   Top1 94.555122   Top5 99.952257   BatchTime 0.240306   LR 0.000165   
2022-11-25 06:55:27,453 - INFO  - ==> Top1: 94.604    Top5: 99.950    Loss: 0.153

2022-11-25 06:55:27,610 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:55:28,548 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:55:31,567 - INFO  - Validation [17][   20/   40]   Loss 0.420519   Top1 87.773438   Top5 99.453125   BatchTime 0.150915   
2022-11-25 06:55:32,745 - INFO  - Validation [17][   40/   40]   Loss 0.409527   Top1 87.720000   Top5 99.590000   BatchTime 0.104913   
2022-11-25 06:55:33,008 - INFO  - ==> Top1: 87.720    Top5: 99.590    Loss: 0.410

2022-11-25 06:55:33,009 - INFO  - ==> Sparsity : 0.730

2022-11-25 06:55:33,009 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:55:33,009 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:55:33,009 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:55:33,147 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:55:33,149 - INFO  - >>>>>> Epoch  18
2022-11-25 06:55:33,150 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:55:39,730 - INFO  - Training [18][   20/  196]   Loss 0.138666   Top1 95.136719   Top5 99.960938   BatchTime 0.328840   LR 0.000162   
2022-11-25 06:55:44,498 - INFO  - Training [18][   40/  196]   Loss 0.140917   Top1 95.205078   Top5 99.960938   BatchTime 0.283627   LR 0.000160   
2022-11-25 06:55:49,339 - INFO  - Training [18][   60/  196]   Loss 0.141009   Top1 95.084635   Top5 99.967448   BatchTime 0.269765   LR 0.000158   
2022-11-25 06:55:54,040 - INFO  - Training [18][   80/  196]   Loss 0.136893   Top1 95.219727   Top5 99.970703   BatchTime 0.261084   LR 0.000156   
2022-11-25 06:55:58,700 - INFO  - Training [18][  100/  196]   Loss 0.134554   Top1 95.265625   Top5 99.972656   BatchTime 0.255465   LR 0.000154   
2022-11-25 06:56:03,507 - INFO  - Training [18][  120/  196]   Loss 0.134626   Top1 95.218099   Top5 99.977214   BatchTime 0.252945   LR 0.000152   
2022-11-25 06:56:07,998 - INFO  - Training [18][  140/  196]   Loss 0.133795   Top1 95.203683   Top5 99.974888   BatchTime 0.248891   LR 0.000150   
2022-11-25 06:56:12,634 - INFO  - Training [18][  160/  196]   Loss 0.133920   Top1 95.200195   Top5 99.963379   BatchTime 0.246753   LR 0.000148   
2022-11-25 06:56:17,179 - INFO  - Training [18][  180/  196]   Loss 0.135527   Top1 95.106337   Top5 99.960938   BatchTime 0.244586   LR 0.000146   
2022-11-25 06:56:20,811 - INFO  - ==> Top1: 95.070    Top5: 99.956    Loss: 0.137

2022-11-25 06:56:21,036 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:56:22,571 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:56:25,461 - INFO  - Validation [18][   20/   40]   Loss 0.389279   Top1 88.671875   Top5 99.511719   BatchTime 0.144418   
2022-11-25 06:56:26,600 - INFO  - Validation [18][   40/   40]   Loss 0.376060   Top1 88.720000   Top5 99.620000   BatchTime 0.100685   
2022-11-25 06:56:26,859 - INFO  - ==> Top1: 88.720    Top5: 99.620    Loss: 0.376

2022-11-25 06:56:26,860 - INFO  - ==> Sparsity : 0.731

2022-11-25 06:56:26,860 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:56:26,860 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:56:26,860 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:56:26,985 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:56:26,986 - INFO  - >>>>>> Epoch  19
2022-11-25 06:56:26,988 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:56:33,351 - INFO  - Training [19][   20/  196]   Loss 0.146920   Top1 94.746094   Top5 99.941406   BatchTime 0.318012   LR 0.000143   
2022-11-25 06:56:38,095 - INFO  - Training [19][   40/  196]   Loss 0.139861   Top1 95.029297   Top5 99.960938   BatchTime 0.277595   LR 0.000141   
2022-11-25 06:56:42,653 - INFO  - Training [19][   60/  196]   Loss 0.133106   Top1 95.292969   Top5 99.967448   BatchTime 0.261042   LR 0.000139   
2022-11-25 06:56:47,512 - INFO  - Training [19][   80/  196]   Loss 0.131857   Top1 95.351562   Top5 99.965820   BatchTime 0.256518   LR 0.000137   
2022-11-25 06:56:52,335 - INFO  - Training [19][  100/  196]   Loss 0.131166   Top1 95.367188   Top5 99.968750   BatchTime 0.253440   LR 0.000135   
2022-11-25 06:56:57,042 - INFO  - Training [19][  120/  196]   Loss 0.129855   Top1 95.419922   Top5 99.970703   BatchTime 0.250419   LR 0.000133   
2022-11-25 06:57:01,465 - INFO  - Training [19][  140/  196]   Loss 0.130627   Top1 95.410156   Top5 99.969308   BatchTime 0.246243   LR 0.000131   
2022-11-25 06:57:06,140 - INFO  - Training [19][  160/  196]   Loss 0.130548   Top1 95.368652   Top5 99.965820   BatchTime 0.244678   LR 0.000129   
2022-11-25 06:57:10,497 - INFO  - Training [19][  180/  196]   Loss 0.131284   Top1 95.345052   Top5 99.958767   BatchTime 0.241700   LR 0.000127   
2022-11-25 06:57:14,112 - INFO  - ==> Top1: 95.372    Top5: 99.958    Loss: 0.131

2022-11-25 06:57:14,292 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:57:15,367 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:57:18,301 - INFO  - Validation [19][   20/   40]   Loss 0.388251   Top1 88.613281   Top5 99.687500   BatchTime 0.146646   
2022-11-25 06:57:19,426 - INFO  - Validation [19][   40/   40]   Loss 0.382450   Top1 88.690000   Top5 99.760000   BatchTime 0.101455   
2022-11-25 06:57:19,668 - INFO  - ==> Top1: 88.690    Top5: 99.760    Loss: 0.382

2022-11-25 06:57:19,669 - INFO  - ==> Sparsity : 0.731

2022-11-25 06:57:19,669 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:57:19,669 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:57:19,669 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:57:19,784 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:57:19,786 - INFO  - >>>>>> Epoch  20
2022-11-25 06:57:19,787 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:57:26,437 - INFO  - Training [20][   20/  196]   Loss 0.113341   Top1 96.074219   Top5 99.980469   BatchTime 0.332340   LR 0.000123   
2022-11-25 06:57:31,161 - INFO  - Training [20][   40/  196]   Loss 0.113636   Top1 96.044922   Top5 99.990234   BatchTime 0.284271   LR 0.000121   
2022-11-25 06:57:35,890 - INFO  - Training [20][   60/  196]   Loss 0.117566   Top1 95.924479   Top5 99.986979   BatchTime 0.268334   LR 0.000119   
2022-11-25 06:57:40,487 - INFO  - Training [20][   80/  196]   Loss 0.116315   Top1 95.903320   Top5 99.985352   BatchTime 0.258715   LR 0.000117   
2022-11-25 06:57:45,043 - INFO  - Training [20][  100/  196]   Loss 0.115202   Top1 95.921875   Top5 99.980469   BatchTime 0.252526   LR 0.000115   
2022-11-25 06:57:49,631 - INFO  - Training [20][  120/  196]   Loss 0.116524   Top1 95.852865   Top5 99.977214   BatchTime 0.248671   LR 0.000113   
2022-11-25 06:57:54,375 - INFO  - Training [20][  140/  196]   Loss 0.117185   Top1 95.825893   Top5 99.977679   BatchTime 0.247031   LR 0.000111   
2022-11-25 06:57:58,953 - INFO  - Training [20][  160/  196]   Loss 0.116352   Top1 95.871582   Top5 99.980469   BatchTime 0.244765   LR 0.000109   
2022-11-25 06:58:03,901 - INFO  - Training [20][  180/  196]   Loss 0.115432   Top1 95.894097   Top5 99.978299   BatchTime 0.245061   LR 0.000107   
2022-11-25 06:58:07,517 - INFO  - ==> Top1: 95.890    Top5: 99.978    Loss: 0.115

2022-11-25 06:58:07,668 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:58:08,618 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:58:11,624 - INFO  - Validation [20][   20/   40]   Loss 0.378326   Top1 88.886719   Top5 99.550781   BatchTime 0.150236   
2022-11-25 06:58:12,788 - INFO  - Validation [20][   40/   40]   Loss 0.373973   Top1 88.960000   Top5 99.670000   BatchTime 0.104230   
2022-11-25 06:58:13,031 - INFO  - ==> Top1: 88.960    Top5: 99.670    Loss: 0.374

2022-11-25 06:58:13,031 - INFO  - ==> Sparsity : 0.731

2022-11-25 06:58:13,031 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:58:13,032 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:58:13,032 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.510   Top5: 99.730]
2022-11-25 06:58:13,151 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:58:13,153 - INFO  - >>>>>> Epoch  21
2022-11-25 06:58:13,154 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:58:19,778 - INFO  - Training [21][   20/  196]   Loss 0.103062   Top1 96.289062   Top5 99.980469   BatchTime 0.331061   LR 0.000104   
2022-11-25 06:58:24,402 - INFO  - Training [21][   40/  196]   Loss 0.108581   Top1 96.201172   Top5 99.970703   BatchTime 0.281121   LR 0.000102   
2022-11-25 06:58:29,172 - INFO  - Training [21][   60/  196]   Loss 0.107597   Top1 96.210938   Top5 99.960938   BatchTime 0.266917   LR 0.000100   
2022-11-25 06:58:33,967 - INFO  - Training [21][   80/  196]   Loss 0.109568   Top1 96.147461   Top5 99.965820   BatchTime 0.260118   LR 0.000098   
2022-11-25 06:58:38,620 - INFO  - Training [21][  100/  196]   Loss 0.111737   Top1 96.078125   Top5 99.964844   BatchTime 0.254624   LR 0.000096   
2022-11-25 06:58:43,301 - INFO  - Training [21][  120/  196]   Loss 0.109757   Top1 96.184896   Top5 99.970703   BatchTime 0.251197   LR 0.000094   
2022-11-25 06:58:47,814 - INFO  - Training [21][  140/  196]   Loss 0.107617   Top1 96.250000   Top5 99.972098   BatchTime 0.247545   LR 0.000092   
2022-11-25 06:58:52,657 - INFO  - Training [21][  160/  196]   Loss 0.108235   Top1 96.223145   Top5 99.975586   BatchTime 0.246869   LR 0.000090   
2022-11-25 06:58:57,333 - INFO  - Training [21][  180/  196]   Loss 0.107296   Top1 96.241319   Top5 99.978299   BatchTime 0.245419   LR 0.000088   
2022-11-25 06:59:01,039 - INFO  - ==> Top1: 96.248    Top5: 99.978    Loss: 0.107

2022-11-25 06:59:01,235 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:59:02,327 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:59:05,330 - INFO  - Validation [21][   20/   40]   Loss 0.366559   Top1 89.765625   Top5 99.667969   BatchTime 0.150095   
2022-11-25 06:59:06,581 - INFO  - Validation [21][   40/   40]   Loss 0.362767   Top1 89.620000   Top5 99.780000   BatchTime 0.106310   
2022-11-25 06:59:06,836 - INFO  - ==> Top1: 89.620    Top5: 99.780    Loss: 0.363

2022-11-25 06:59:06,836 - INFO  - ==> Sparsity : 0.732

2022-11-25 06:59:06,837 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 06:59:06,837 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 89.620   Top5: 99.780]
2022-11-25 06:59:06,837 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 89.620   Top5: 99.770]
2022-11-25 06:59:06,957 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 06:59:06,959 - INFO  - >>>>>> Epoch  22
2022-11-25 06:59:06,960 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 06:59:13,135 - INFO  - Training [22][   20/  196]   Loss 0.094933   Top1 96.523438   Top5 100.000000   BatchTime 0.308557   LR 0.000085   
2022-11-25 06:59:17,650 - INFO  - Training [22][   40/  196]   Loss 0.094381   Top1 96.503906   Top5 100.000000   BatchTime 0.267170   LR 0.000083   
2022-11-25 06:59:22,203 - INFO  - Training [22][   60/  196]   Loss 0.096902   Top1 96.477865   Top5 99.980469   BatchTime 0.254001   LR 0.000081   
2022-11-25 06:59:27,117 - INFO  - Training [22][   80/  196]   Loss 0.097508   Top1 96.479492   Top5 99.985352   BatchTime 0.251918   LR 0.000079   
2022-11-25 06:59:31,767 - INFO  - Training [22][  100/  196]   Loss 0.097759   Top1 96.519531   Top5 99.988281   BatchTime 0.248031   LR 0.000077   
2022-11-25 06:59:36,433 - INFO  - Training [22][  120/  196]   Loss 0.098011   Top1 96.484375   Top5 99.990234   BatchTime 0.245581   LR 0.000075   
2022-11-25 06:59:41,309 - INFO  - Training [22][  140/  196]   Loss 0.100197   Top1 96.417411   Top5 99.988839   BatchTime 0.245323   LR 0.000073   
2022-11-25 06:59:46,379 - INFO  - Training [22][  160/  196]   Loss 0.099681   Top1 96.411133   Top5 99.987793   BatchTime 0.246344   LR 0.000072   
2022-11-25 06:59:51,159 - INFO  - Training [22][  180/  196]   Loss 0.097913   Top1 96.486545   Top5 99.989149   BatchTime 0.245526   LR 0.000070   
2022-11-25 06:59:55,046 - INFO  - ==> Top1: 96.490    Top5: 99.990    Loss: 0.098

2022-11-25 06:59:55,222 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 06:59:56,620 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 06:59:59,560 - INFO  - Validation [22][   20/   40]   Loss 0.370531   Top1 90.019531   Top5 99.648438   BatchTime 0.146884   
2022-11-25 07:00:00,623 - INFO  - Validation [22][   40/   40]   Loss 0.364527   Top1 89.980000   Top5 99.740000   BatchTime 0.100042   
2022-11-25 07:00:00,876 - INFO  - ==> Top1: 89.980    Top5: 99.740    Loss: 0.365

2022-11-25 07:00:00,876 - INFO  - ==> Sparsity : 0.732

2022-11-25 07:00:00,876 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:00:00,876 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 07:00:00,877 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 89.620   Top5: 99.780]
2022-11-25 07:00:06,343 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 07:00:06,345 - INFO  - >>>>>> Epoch  23
2022-11-25 07:00:06,347 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:00:13,131 - INFO  - Training [23][   20/  196]   Loss 0.086292   Top1 96.992188   Top5 100.000000   BatchTime 0.339116   LR 0.000067   
2022-11-25 07:00:18,162 - INFO  - Training [23][   40/  196]   Loss 0.088975   Top1 96.894531   Top5 100.000000   BatchTime 0.295313   LR 0.000065   
2022-11-25 07:00:22,856 - INFO  - Training [23][   60/  196]   Loss 0.088712   Top1 96.907552   Top5 99.986979   BatchTime 0.275114   LR 0.000063   
2022-11-25 07:00:27,659 - INFO  - Training [23][   80/  196]   Loss 0.090496   Top1 96.796875   Top5 99.980469   BatchTime 0.266374   LR 0.000061   
2022-11-25 07:00:32,466 - INFO  - Training [23][  100/  196]   Loss 0.090912   Top1 96.750000   Top5 99.980469   BatchTime 0.261167   LR 0.000060   
2022-11-25 07:00:37,298 - INFO  - Training [23][  120/  196]   Loss 0.092289   Top1 96.699219   Top5 99.983724   BatchTime 0.257902   LR 0.000058   
2022-11-25 07:00:41,878 - INFO  - Training [23][  140/  196]   Loss 0.093010   Top1 96.674107   Top5 99.986049   BatchTime 0.253772   LR 0.000056   
2022-11-25 07:00:46,625 - INFO  - Training [23][  160/  196]   Loss 0.093837   Top1 96.652832   Top5 99.985352   BatchTime 0.251718   LR 0.000055   
2022-11-25 07:00:51,198 - INFO  - Training [23][  180/  196]   Loss 0.094302   Top1 96.649306   Top5 99.980469   BatchTime 0.249159   LR 0.000053   
2022-11-25 07:00:54,814 - INFO  - ==> Top1: 96.632    Top5: 99.980    Loss: 0.095

2022-11-25 07:00:55,006 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:00:56,121 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:00:59,017 - INFO  - Validation [23][   20/   40]   Loss 0.380539   Top1 89.355469   Top5 99.589844   BatchTime 0.144716   
2022-11-25 07:01:00,015 - INFO  - Validation [23][   40/   40]   Loss 0.376844   Top1 89.410000   Top5 99.700000   BatchTime 0.097315   
2022-11-25 07:01:00,286 - INFO  - ==> Top1: 89.410    Top5: 99.700    Loss: 0.377

2022-11-25 07:01:00,287 - INFO  - ==> Sparsity : 0.732

2022-11-25 07:01:00,287 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:01:00,287 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 07:01:00,287 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 89.620   Top5: 99.780]
2022-11-25 07:01:00,425 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:01:00,426 - INFO  - >>>>>> Epoch  24
2022-11-25 07:01:00,428 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:01:07,849 - INFO  - Training [24][   20/  196]   Loss 0.087380   Top1 96.699219   Top5 99.980469   BatchTime 0.370924   LR 0.000050   
2022-11-25 07:01:12,625 - INFO  - Training [24][   40/  196]   Loss 0.087106   Top1 96.865234   Top5 99.960938   BatchTime 0.304846   LR 0.000048   
2022-11-25 07:01:17,244 - INFO  - Training [24][   60/  196]   Loss 0.085823   Top1 96.875000   Top5 99.973958   BatchTime 0.280219   LR 0.000047   
2022-11-25 07:01:21,791 - INFO  - Training [24][   80/  196]   Loss 0.085856   Top1 96.923828   Top5 99.975586   BatchTime 0.267006   LR 0.000045   
2022-11-25 07:01:26,594 - INFO  - Training [24][  100/  196]   Loss 0.087790   Top1 96.851562   Top5 99.980469   BatchTime 0.261626   LR 0.000044   
2022-11-25 07:01:31,375 - INFO  - Training [24][  120/  196]   Loss 0.087478   Top1 96.927083   Top5 99.977214   BatchTime 0.257867   LR 0.000042   
2022-11-25 07:01:36,175 - INFO  - Training [24][  140/  196]   Loss 0.087092   Top1 96.941964   Top5 99.980469   BatchTime 0.255311   LR 0.000041   
2022-11-25 07:01:40,878 - INFO  - Training [24][  160/  196]   Loss 0.086895   Top1 96.953125   Top5 99.980469   BatchTime 0.252794   LR 0.000039   
2022-11-25 07:01:45,416 - INFO  - Training [24][  180/  196]   Loss 0.086856   Top1 96.946615   Top5 99.980469   BatchTime 0.249912   LR 0.000038   
2022-11-25 07:01:49,380 - INFO  - ==> Top1: 96.948    Top5: 99.982    Loss: 0.086

2022-11-25 07:01:49,570 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:01:50,762 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:01:53,757 - INFO  - Validation [24][   20/   40]   Loss 0.380365   Top1 89.765625   Top5 99.550781   BatchTime 0.149685   
2022-11-25 07:01:54,930 - INFO  - Validation [24][   40/   40]   Loss 0.372505   Top1 89.710000   Top5 99.700000   BatchTime 0.104177   
2022-11-25 07:01:55,234 - INFO  - ==> Top1: 89.710    Top5: 99.700    Loss: 0.373

2022-11-25 07:01:55,234 - INFO  - ==> Sparsity : 0.732

2022-11-25 07:01:55,234 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:01:55,234 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 07:01:55,235 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 89.710   Top5: 99.700]
2022-11-25 07:01:55,360 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:01:55,362 - INFO  - >>>>>> Epoch  25
2022-11-25 07:01:55,364 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:02:02,262 - INFO  - Training [25][   20/  196]   Loss 0.070680   Top1 97.343750   Top5 99.980469   BatchTime 0.344782   LR 0.000035   
2022-11-25 07:02:06,945 - INFO  - Training [25][   40/  196]   Loss 0.076020   Top1 97.412109   Top5 99.980469   BatchTime 0.289456   LR 0.000034   
2022-11-25 07:02:11,735 - INFO  - Training [25][   60/  196]   Loss 0.075486   Top1 97.402344   Top5 99.986979   BatchTime 0.272806   LR 0.000033   
2022-11-25 07:02:16,176 - INFO  - Training [25][   80/  196]   Loss 0.077064   Top1 97.348633   Top5 99.990234   BatchTime 0.260117   LR 0.000031   
2022-11-25 07:02:20,834 - INFO  - Training [25][  100/  196]   Loss 0.077617   Top1 97.332031   Top5 99.992188   BatchTime 0.254677   LR 0.000030   
2022-11-25 07:02:25,562 - INFO  - Training [25][  120/  196]   Loss 0.078579   Top1 97.252604   Top5 99.990234   BatchTime 0.251623   LR 0.000029   
2022-11-25 07:02:30,154 - INFO  - Training [25][  140/  196]   Loss 0.079076   Top1 97.243304   Top5 99.986049   BatchTime 0.248477   LR 0.000027   
2022-11-25 07:02:34,915 - INFO  - Training [25][  160/  196]   Loss 0.078058   Top1 97.280273   Top5 99.985352   BatchTime 0.247174   LR 0.000026   
2022-11-25 07:02:39,613 - INFO  - Training [25][  180/  196]   Loss 0.077783   Top1 97.291667   Top5 99.986979   BatchTime 0.245812   LR 0.000025   
2022-11-25 07:02:43,593 - INFO  - ==> Top1: 97.276    Top5: 99.986    Loss: 0.078

2022-11-25 07:02:43,777 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:02:44,945 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:02:47,908 - INFO  - Validation [25][   20/   40]   Loss 0.370892   Top1 90.039062   Top5 99.531250   BatchTime 0.148080   
2022-11-25 07:02:48,992 - INFO  - Validation [25][   40/   40]   Loss 0.365479   Top1 89.940000   Top5 99.680000   BatchTime 0.101141   
2022-11-25 07:02:49,231 - INFO  - ==> Top1: 89.940    Top5: 99.680    Loss: 0.365

2022-11-25 07:02:49,231 - INFO  - ==> Sparsity : 0.732

2022-11-25 07:02:49,232 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:02:49,232 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 89.940   Top5: 99.680]
2022-11-25 07:02:49,232 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 89.810   Top5: 99.690]
2022-11-25 07:02:49,368 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:02:49,370 - INFO  - >>>>>> Epoch  26
2022-11-25 07:02:49,372 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:02:56,070 - INFO  - Training [26][   20/  196]   Loss 0.069511   Top1 97.695312   Top5 100.000000   BatchTime 0.334784   LR 0.000023   
2022-11-25 07:03:00,863 - INFO  - Training [26][   40/  196]   Loss 0.071911   Top1 97.402344   Top5 100.000000   BatchTime 0.287212   LR 0.000022   
2022-11-25 07:03:05,371 - INFO  - Training [26][   60/  196]   Loss 0.076028   Top1 97.291667   Top5 100.000000   BatchTime 0.266602   LR 0.000021   
2022-11-25 07:03:09,908 - INFO  - Training [26][   80/  196]   Loss 0.076021   Top1 97.358398   Top5 100.000000   BatchTime 0.256661   LR 0.000019   
2022-11-25 07:03:15,215 - INFO  - Training [26][  100/  196]   Loss 0.073800   Top1 97.453125   Top5 100.000000   BatchTime 0.258404   LR 0.000018   
2022-11-25 07:03:20,175 - INFO  - Training [26][  120/  196]   Loss 0.073435   Top1 97.454427   Top5 100.000000   BatchTime 0.256668   LR 0.000017   
2022-11-25 07:03:25,169 - INFO  - Training [26][  140/  196]   Loss 0.073643   Top1 97.433036   Top5 99.997210   BatchTime 0.255670   LR 0.000016   
2022-11-25 07:03:30,435 - INFO  - Training [26][  160/  196]   Loss 0.073183   Top1 97.446289   Top5 99.992676   BatchTime 0.256625   LR 0.000015   
2022-11-25 07:03:35,100 - INFO  - Training [26][  180/  196]   Loss 0.074495   Top1 97.417535   Top5 99.993490   BatchTime 0.254027   LR 0.000014   
2022-11-25 07:03:38,840 - INFO  - ==> Top1: 97.410    Top5: 99.990    Loss: 0.075

2022-11-25 07:03:39,074 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:03:40,333 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:03:43,277 - INFO  - Validation [26][   20/   40]   Loss 0.370496   Top1 90.117188   Top5 99.648438   BatchTime 0.147101   
2022-11-25 07:03:44,401 - INFO  - Validation [26][   40/   40]   Loss 0.368330   Top1 89.900000   Top5 99.760000   BatchTime 0.101656   
2022-11-25 07:03:44,663 - INFO  - ==> Top1: 89.900    Top5: 99.760    Loss: 0.368

2022-11-25 07:03:44,663 - INFO  - ==> Sparsity : 0.732

2022-11-25 07:03:44,663 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:03:44,663 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 89.940   Top5: 99.680]
2022-11-25 07:03:44,664 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.900   Top5: 99.760]
2022-11-25 07:03:44,780 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:03:44,782 - INFO  - >>>>>> Epoch  27
2022-11-25 07:03:44,784 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:03:51,189 - INFO  - Training [27][   20/  196]   Loss 0.063690   Top1 97.929688   Top5 100.000000   BatchTime 0.320121   LR 0.000013   
2022-11-25 07:03:55,684 - INFO  - Training [27][   40/  196]   Loss 0.067421   Top1 97.822266   Top5 99.980469   BatchTime 0.272424   LR 0.000012   
2022-11-25 07:04:00,191 - INFO  - Training [27][   60/  196]   Loss 0.069615   Top1 97.662760   Top5 99.980469   BatchTime 0.256726   LR 0.000011   
2022-11-25 07:04:05,038 - INFO  - Training [27][   80/  196]   Loss 0.069387   Top1 97.631836   Top5 99.985352   BatchTime 0.253142   LR 0.000010   
2022-11-25 07:04:09,495 - INFO  - Training [27][  100/  196]   Loss 0.070478   Top1 97.597656   Top5 99.984375   BatchTime 0.247081   LR 0.000009   
2022-11-25 07:04:14,094 - INFO  - Training [27][  120/  196]   Loss 0.070746   Top1 97.574870   Top5 99.986979   BatchTime 0.244227   LR 0.000009   
2022-11-25 07:04:18,626 - INFO  - Training [27][  140/  196]   Loss 0.071374   Top1 97.527902   Top5 99.988839   BatchTime 0.241706   LR 0.000008   
2022-11-25 07:04:23,171 - INFO  - Training [27][  160/  196]   Loss 0.071272   Top1 97.553711   Top5 99.987793   BatchTime 0.239897   LR 0.000007   
2022-11-25 07:04:27,771 - INFO  - Training [27][  180/  196]   Loss 0.071345   Top1 97.547743   Top5 99.984809   BatchTime 0.238796   LR 0.000007   
2022-11-25 07:04:31,387 - INFO  - ==> Top1: 97.514    Top5: 99.984    Loss: 0.072

2022-11-25 07:04:31,599 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:04:32,846 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:04:35,820 - INFO  - Validation [27][   20/   40]   Loss 0.367935   Top1 90.351562   Top5 99.648438   BatchTime 0.148633   
2022-11-25 07:04:36,956 - INFO  - Validation [27][   40/   40]   Loss 0.366921   Top1 90.010000   Top5 99.750000   BatchTime 0.102737   
2022-11-25 07:04:37,215 - INFO  - ==> Top1: 90.010    Top5: 99.750    Loss: 0.367

2022-11-25 07:04:37,215 - INFO  - ==> Sparsity : 0.732

2022-11-25 07:04:37,215 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:04:37,216 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:04:37,216 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.940   Top5: 99.680]
2022-11-25 07:04:42,637 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 07:04:42,639 - INFO  - >>>>>> Epoch  28
2022-11-25 07:04:42,641 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:04:49,496 - INFO  - Training [28][   20/  196]   Loss 0.073798   Top1 97.382812   Top5 99.980469   BatchTime 0.342642   LR 0.000006   
2022-11-25 07:04:54,414 - INFO  - Training [28][   40/  196]   Loss 0.069947   Top1 97.509766   Top5 99.980469   BatchTime 0.294288   LR 0.000005   
2022-11-25 07:04:59,372 - INFO  - Training [28][   60/  196]   Loss 0.069960   Top1 97.545573   Top5 99.980469   BatchTime 0.278824   LR 0.000004   
2022-11-25 07:05:04,101 - INFO  - Training [28][   80/  196]   Loss 0.069725   Top1 97.529297   Top5 99.985352   BatchTime 0.268218   LR 0.000004   
2022-11-25 07:05:09,298 - INFO  - Training [28][  100/  196]   Loss 0.069659   Top1 97.589844   Top5 99.988281   BatchTime 0.266551   LR 0.000003   
2022-11-25 07:05:14,195 - INFO  - Training [28][  120/  196]   Loss 0.069999   Top1 97.584635   Top5 99.990234   BatchTime 0.262930   LR 0.000003   
2022-11-25 07:05:19,248 - INFO  - Training [28][  140/  196]   Loss 0.071440   Top1 97.547433   Top5 99.988839   BatchTime 0.261458   LR 0.000003   
2022-11-25 07:05:23,807 - INFO  - Training [28][  160/  196]   Loss 0.072049   Top1 97.519531   Top5 99.990234   BatchTime 0.257272   LR 0.000002   
2022-11-25 07:05:28,245 - INFO  - Training [28][  180/  196]   Loss 0.071532   Top1 97.539062   Top5 99.991319   BatchTime 0.253343   LR 0.000002   
2022-11-25 07:05:31,864 - INFO  - ==> Top1: 97.546    Top5: 99.992    Loss: 0.072

2022-11-25 07:05:32,081 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:05:33,329 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:05:36,316 - INFO  - Validation [28][   20/   40]   Loss 0.375390   Top1 90.019531   Top5 99.667969   BatchTime 0.149290   
2022-11-25 07:05:37,399 - INFO  - Validation [28][   40/   40]   Loss 0.370741   Top1 89.830000   Top5 99.750000   BatchTime 0.101717   
2022-11-25 07:05:37,662 - INFO  - ==> Top1: 89.830    Top5: 99.750    Loss: 0.371

2022-11-25 07:05:37,662 - INFO  - ==> Sparsity : 0.732

2022-11-25 07:05:37,663 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:05:37,663 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:05:37,663 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.940   Top5: 99.680]
2022-11-25 07:05:37,781 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:05:37,783 - INFO  - >>>>>> Epoch  29
2022-11-25 07:05:37,784 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:05:44,350 - INFO  - Training [29][   20/  196]   Loss 0.070568   Top1 97.636719   Top5 100.000000   BatchTime 0.328136   LR 0.000001   
2022-11-25 07:05:48,939 - INFO  - Training [29][   40/  196]   Loss 0.070770   Top1 97.597656   Top5 99.960938   BatchTime 0.278798   LR 0.000001   
2022-11-25 07:05:53,439 - INFO  - Training [29][   60/  196]   Loss 0.070717   Top1 97.552083   Top5 99.967448   BatchTime 0.260870   LR 0.000001   
2022-11-25 07:05:58,079 - INFO  - Training [29][   80/  196]   Loss 0.070121   Top1 97.519531   Top5 99.970703   BatchTime 0.253652   LR 0.000001   
2022-11-25 07:06:02,676 - INFO  - Training [29][  100/  196]   Loss 0.068401   Top1 97.578125   Top5 99.976562   BatchTime 0.248891   LR 0.000000   
2022-11-25 07:06:07,362 - INFO  - Training [29][  120/  196]   Loss 0.067910   Top1 97.597656   Top5 99.977214   BatchTime 0.246454   LR 0.000000   
2022-11-25 07:06:11,903 - INFO  - Training [29][  140/  196]   Loss 0.067259   Top1 97.619978   Top5 99.980469   BatchTime 0.243681   LR 0.000000   
2022-11-25 07:06:16,353 - INFO  - Training [29][  160/  196]   Loss 0.068600   Top1 97.563477   Top5 99.982910   BatchTime 0.241032   LR 0.000000   
2022-11-25 07:06:20,722 - INFO  - Training [29][  180/  196]   Loss 0.069032   Top1 97.541233   Top5 99.982639   BatchTime 0.238524   LR 0.000000   
2022-11-25 07:06:24,656 - INFO  - ==> Top1: 97.580    Top5: 99.984    Loss: 0.069

2022-11-25 07:06:24,822 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:06:25,870 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:06:28,951 - INFO  - Validation [29][   20/   40]   Loss 0.372575   Top1 90.253906   Top5 99.687500   BatchTime 0.153956   
2022-11-25 07:06:30,164 - INFO  - Validation [29][   40/   40]   Loss 0.366807   Top1 89.950000   Top5 99.770000   BatchTime 0.107306   
2022-11-25 07:06:30,410 - INFO  - ==> Top1: 89.950    Top5: 99.770    Loss: 0.367

2022-11-25 07:06:30,411 - INFO  - ==> Sparsity : 0.732

2022-11-25 07:06:30,411 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:06:30,411 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:06:30,411 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:06:30,539 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:06:30,540 - INFO  - >>>>>> Epoch  30
2022-11-25 07:06:30,542 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:06:37,756 - INFO  - Training [30][   20/  196]   Loss 0.083056   Top1 97.246094   Top5 100.000000   BatchTime 0.360583   LR 0.000125   
2022-11-25 07:06:42,728 - INFO  - Training [30][   40/  196]   Loss 0.085109   Top1 97.099609   Top5 99.990234   BatchTime 0.304584   LR 0.000125   
2022-11-25 07:06:47,630 - INFO  - Training [30][   60/  196]   Loss 0.089148   Top1 96.894531   Top5 99.986979   BatchTime 0.284756   LR 0.000125   
2022-11-25 07:06:52,724 - INFO  - Training [30][   80/  196]   Loss 0.098320   Top1 96.567383   Top5 99.985352   BatchTime 0.277238   LR 0.000125   
2022-11-25 07:06:57,661 - INFO  - Training [30][  100/  196]   Loss 0.101192   Top1 96.425781   Top5 99.984375   BatchTime 0.271161   LR 0.000125   
2022-11-25 07:07:02,495 - INFO  - Training [30][  120/  196]   Loss 0.103265   Top1 96.341146   Top5 99.986979   BatchTime 0.266249   LR 0.000125   
2022-11-25 07:07:06,984 - INFO  - Training [30][  140/  196]   Loss 0.105306   Top1 96.255580   Top5 99.986049   BatchTime 0.260279   LR 0.000125   
2022-11-25 07:07:11,455 - INFO  - Training [30][  160/  196]   Loss 0.106031   Top1 96.196289   Top5 99.982910   BatchTime 0.255686   LR 0.000125   
2022-11-25 07:07:15,916 - INFO  - Training [30][  180/  196]   Loss 0.106020   Top1 96.210938   Top5 99.982639   BatchTime 0.252062   LR 0.000125   
2022-11-25 07:07:19,831 - INFO  - ==> Top1: 96.186    Top5: 99.984    Loss: 0.106

2022-11-25 07:07:20,100 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:07:21,124 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:07:24,100 - INFO  - Validation [30][   20/   40]   Loss 0.407783   Top1 88.730469   Top5 99.609375   BatchTime 0.148659   
2022-11-25 07:07:25,162 - INFO  - Validation [30][   40/   40]   Loss 0.397219   Top1 88.920000   Top5 99.680000   BatchTime 0.100899   
2022-11-25 07:07:25,421 - INFO  - ==> Top1: 88.920    Top5: 99.680    Loss: 0.397

2022-11-25 07:07:25,421 - INFO  - ==> Sparsity : 0.732

2022-11-25 07:07:25,422 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:07:25,422 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:07:25,422 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:07:25,557 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:07:25,559 - INFO  - >>>>>> Epoch  31
2022-11-25 07:07:25,561 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:07:32,472 - INFO  - Training [31][   20/  196]   Loss 0.106480   Top1 96.171875   Top5 100.000000   BatchTime 0.345415   LR 0.000125   
2022-11-25 07:07:36,938 - INFO  - Training [31][   40/  196]   Loss 0.104090   Top1 96.308594   Top5 100.000000   BatchTime 0.284361   LR 0.000125   
2022-11-25 07:07:41,495 - INFO  - Training [31][   60/  196]   Loss 0.105595   Top1 96.315104   Top5 99.980469   BatchTime 0.265531   LR 0.000125   
2022-11-25 07:07:45,841 - INFO  - Training [31][   80/  196]   Loss 0.107930   Top1 96.186523   Top5 99.975586   BatchTime 0.253470   LR 0.000125   
2022-11-25 07:07:50,109 - INFO  - Training [31][  100/  196]   Loss 0.108794   Top1 96.140625   Top5 99.976562   BatchTime 0.245446   LR 0.000125   
2022-11-25 07:07:54,651 - INFO  - Training [31][  120/  196]   Loss 0.110252   Top1 96.083984   Top5 99.980469   BatchTime 0.242390   LR 0.000125   
2022-11-25 07:07:59,292 - INFO  - Training [31][  140/  196]   Loss 0.111754   Top1 96.068638   Top5 99.977679   BatchTime 0.240914   LR 0.000124   
2022-11-25 07:08:04,150 - INFO  - Training [31][  160/  196]   Loss 0.112659   Top1 96.030273   Top5 99.978027   BatchTime 0.241162   LR 0.000124   
2022-11-25 07:08:08,430 - INFO  - Training [31][  180/  196]   Loss 0.110671   Top1 96.121962   Top5 99.976128   BatchTime 0.238145   LR 0.000124   
2022-11-25 07:08:12,217 - INFO  - ==> Top1: 96.142    Top5: 99.976    Loss: 0.110

2022-11-25 07:08:12,422 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:08:13,610 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:08:16,524 - INFO  - Validation [31][   20/   40]   Loss 0.412878   Top1 88.457031   Top5 99.492188   BatchTime 0.145632   
2022-11-25 07:08:17,532 - INFO  - Validation [31][   40/   40]   Loss 0.399196   Top1 88.740000   Top5 99.650000   BatchTime 0.098030   
2022-11-25 07:08:17,802 - INFO  - ==> Top1: 88.740    Top5: 99.650    Loss: 0.399

2022-11-25 07:08:17,802 - INFO  - ==> Sparsity : 0.733

2022-11-25 07:08:17,803 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:08:17,803 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:08:17,803 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:08:17,915 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:08:17,916 - INFO  - >>>>>> Epoch  32
2022-11-25 07:08:17,918 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:08:24,325 - INFO  - Training [32][   20/  196]   Loss 0.100148   Top1 96.464844   Top5 99.960938   BatchTime 0.320205   LR 0.000124   
2022-11-25 07:08:28,828 - INFO  - Training [32][   40/  196]   Loss 0.103560   Top1 96.289062   Top5 99.980469   BatchTime 0.272676   LR 0.000124   
2022-11-25 07:08:33,377 - INFO  - Training [32][   60/  196]   Loss 0.105157   Top1 96.197917   Top5 99.986979   BatchTime 0.257600   LR 0.000124   
2022-11-25 07:08:38,496 - INFO  - Training [32][   80/  196]   Loss 0.104401   Top1 96.220703   Top5 99.990234   BatchTime 0.257187   LR 0.000124   
2022-11-25 07:08:43,656 - INFO  - Training [32][  100/  196]   Loss 0.107146   Top1 96.187500   Top5 99.988281   BatchTime 0.257352   LR 0.000124   
2022-11-25 07:08:48,466 - INFO  - Training [32][  120/  196]   Loss 0.107001   Top1 96.188151   Top5 99.983724   BatchTime 0.254540   LR 0.000124   
2022-11-25 07:08:53,156 - INFO  - Training [32][  140/  196]   Loss 0.106478   Top1 96.236049   Top5 99.983259   BatchTime 0.251677   LR 0.000124   
2022-11-25 07:08:57,947 - INFO  - Training [32][  160/  196]   Loss 0.107057   Top1 96.210938   Top5 99.982910   BatchTime 0.250165   LR 0.000123   
2022-11-25 07:09:02,988 - INFO  - Training [32][  180/  196]   Loss 0.107381   Top1 96.195747   Top5 99.984809   BatchTime 0.250373   LR 0.000123   
2022-11-25 07:09:06,847 - INFO  - ==> Top1: 96.162    Top5: 99.986    Loss: 0.108

2022-11-25 07:09:07,066 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:09:08,340 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:09:11,423 - INFO  - Validation [32][   20/   40]   Loss 0.396470   Top1 89.218750   Top5 99.531250   BatchTime 0.154072   
2022-11-25 07:09:12,485 - INFO  - Validation [32][   40/   40]   Loss 0.389845   Top1 89.030000   Top5 99.670000   BatchTime 0.103587   
2022-11-25 07:09:12,744 - INFO  - ==> Top1: 89.030    Top5: 99.670    Loss: 0.390

2022-11-25 07:09:12,744 - INFO  - ==> Sparsity : 0.733

2022-11-25 07:09:12,744 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:09:12,744 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:09:12,745 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:09:12,861 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:09:12,863 - INFO  - >>>>>> Epoch  33
2022-11-25 07:09:12,864 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:09:19,441 - INFO  - Training [33][   20/  196]   Loss 0.105607   Top1 96.093750   Top5 99.960938   BatchTime 0.328729   LR 0.000123   
2022-11-25 07:09:24,460 - INFO  - Training [33][   40/  196]   Loss 0.106354   Top1 96.035156   Top5 99.960938   BatchTime 0.289818   LR 0.000123   
2022-11-25 07:09:29,387 - INFO  - Training [33][   60/  196]   Loss 0.103863   Top1 96.165365   Top5 99.973958   BatchTime 0.275336   LR 0.000123   
2022-11-25 07:09:34,687 - INFO  - Training [33][   80/  196]   Loss 0.105946   Top1 96.176758   Top5 99.970703   BatchTime 0.272743   LR 0.000123   
2022-11-25 07:09:39,363 - INFO  - Training [33][  100/  196]   Loss 0.106463   Top1 96.175781   Top5 99.972656   BatchTime 0.264953   LR 0.000123   
2022-11-25 07:09:43,707 - INFO  - Training [33][  120/  196]   Loss 0.107523   Top1 96.165365   Top5 99.973958   BatchTime 0.256994   LR 0.000123   
2022-11-25 07:09:47,989 - INFO  - Training [33][  140/  196]   Loss 0.106949   Top1 96.180246   Top5 99.977679   BatchTime 0.250869   LR 0.000122   
2022-11-25 07:09:52,469 - INFO  - Training [33][  160/  196]   Loss 0.107934   Top1 96.171875   Top5 99.975586   BatchTime 0.247509   LR 0.000122   
2022-11-25 07:09:56,906 - INFO  - Training [33][  180/  196]   Loss 0.107770   Top1 96.143663   Top5 99.978299   BatchTime 0.244658   LR 0.000122   
2022-11-25 07:10:00,586 - INFO  - ==> Top1: 96.166    Top5: 99.980    Loss: 0.107

2022-11-25 07:10:00,777 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:10:01,902 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:10:04,903 - INFO  - Validation [33][   20/   40]   Loss 0.404821   Top1 88.964844   Top5 99.628906   BatchTime 0.149968   
2022-11-25 07:10:06,031 - INFO  - Validation [33][   40/   40]   Loss 0.402983   Top1 88.860000   Top5 99.700000   BatchTime 0.103182   
2022-11-25 07:10:06,302 - INFO  - ==> Top1: 88.860    Top5: 99.700    Loss: 0.403

2022-11-25 07:10:06,303 - INFO  - ==> Sparsity : 0.734

2022-11-25 07:10:06,303 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:10:06,303 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:10:06,303 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:10:06,443 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:10:06,444 - INFO  - >>>>>> Epoch  34
2022-11-25 07:10:06,446 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:10:13,265 - INFO  - Training [34][   20/  196]   Loss 0.099942   Top1 96.464844   Top5 100.000000   BatchTime 0.340826   LR 0.000122   
2022-11-25 07:10:17,788 - INFO  - Training [34][   40/  196]   Loss 0.099377   Top1 96.503906   Top5 100.000000   BatchTime 0.283487   LR 0.000122   
2022-11-25 07:10:22,264 - INFO  - Training [34][   60/  196]   Loss 0.101629   Top1 96.380208   Top5 100.000000   BatchTime 0.263588   LR 0.000121   
2022-11-25 07:10:26,956 - INFO  - Training [34][   80/  196]   Loss 0.101187   Top1 96.381836   Top5 99.995117   BatchTime 0.256344   LR 0.000121   
2022-11-25 07:10:32,221 - INFO  - Training [34][  100/  196]   Loss 0.100846   Top1 96.417969   Top5 99.988281   BatchTime 0.257725   LR 0.000121   
2022-11-25 07:10:37,201 - INFO  - Training [34][  120/  196]   Loss 0.099450   Top1 96.425781   Top5 99.986979   BatchTime 0.256268   LR 0.000121   
2022-11-25 07:10:42,174 - INFO  - Training [34][  140/  196]   Loss 0.100420   Top1 96.403460   Top5 99.986049   BatchTime 0.255181   LR 0.000121   
2022-11-25 07:10:47,016 - INFO  - Training [34][  160/  196]   Loss 0.101625   Top1 96.340332   Top5 99.987793   BatchTime 0.253541   LR 0.000121   
2022-11-25 07:10:51,707 - INFO  - Training [34][  180/  196]   Loss 0.101824   Top1 96.375868   Top5 99.984809   BatchTime 0.251431   LR 0.000120   
2022-11-25 07:10:55,517 - INFO  - ==> Top1: 96.388    Top5: 99.986    Loss: 0.102

2022-11-25 07:10:55,684 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:10:56,675 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:10:59,619 - INFO  - Validation [34][   20/   40]   Loss 0.422978   Top1 88.320312   Top5 99.453125   BatchTime 0.147083   
2022-11-25 07:11:00,655 - INFO  - Validation [34][   40/   40]   Loss 0.414774   Top1 88.530000   Top5 99.590000   BatchTime 0.099446   
2022-11-25 07:11:00,942 - INFO  - ==> Top1: 88.530    Top5: 99.590    Loss: 0.415

2022-11-25 07:11:00,942 - INFO  - ==> Sparsity : 0.734

2022-11-25 07:11:00,943 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:11:00,943 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:11:00,943 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:11:01,097 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:11:01,098 - INFO  - >>>>>> Epoch  35
2022-11-25 07:11:01,100 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:11:07,442 - INFO  - Training [35][   20/  196]   Loss 0.098179   Top1 96.269531   Top5 100.000000   BatchTime 0.316947   LR 0.000120   
2022-11-25 07:11:11,886 - INFO  - Training [35][   40/  196]   Loss 0.097189   Top1 96.298828   Top5 99.980469   BatchTime 0.269560   LR 0.000120   
2022-11-25 07:11:16,155 - INFO  - Training [35][   60/  196]   Loss 0.103946   Top1 96.276042   Top5 99.980469   BatchTime 0.250864   LR 0.000120   
2022-11-25 07:11:20,423 - INFO  - Training [35][   80/  196]   Loss 0.103748   Top1 96.303711   Top5 99.985352   BatchTime 0.241498   LR 0.000119   
2022-11-25 07:11:24,844 - INFO  - Training [35][  100/  196]   Loss 0.106235   Top1 96.285156   Top5 99.980469   BatchTime 0.237408   LR 0.000119   
2022-11-25 07:11:29,185 - INFO  - Training [35][  120/  196]   Loss 0.105312   Top1 96.321615   Top5 99.970703   BatchTime 0.234008   LR 0.000119   
2022-11-25 07:11:34,539 - INFO  - Training [35][  140/  196]   Loss 0.105247   Top1 96.303013   Top5 99.974888   BatchTime 0.238819   LR 0.000119   
2022-11-25 07:11:39,446 - INFO  - Training [35][  160/  196]   Loss 0.105117   Top1 96.296387   Top5 99.978027   BatchTime 0.239637   LR 0.000119   
2022-11-25 07:11:44,465 - INFO  - Training [35][  180/  196]   Loss 0.104609   Top1 96.312934   Top5 99.980469   BatchTime 0.240892   LR 0.000118   
2022-11-25 07:11:48,504 - INFO  - ==> Top1: 96.290    Top5: 99.978    Loss: 0.104

2022-11-25 07:11:48,686 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:11:49,803 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:11:52,968 - INFO  - Validation [35][   20/   40]   Loss 0.407545   Top1 88.828125   Top5 99.570312   BatchTime 0.158173   
2022-11-25 07:11:54,132 - INFO  - Validation [35][   40/   40]   Loss 0.402585   Top1 89.020000   Top5 99.660000   BatchTime 0.108202   
2022-11-25 07:11:54,396 - INFO  - ==> Top1: 89.020    Top5: 99.660    Loss: 0.403

2022-11-25 07:11:54,396 - INFO  - ==> Sparsity : 0.735

2022-11-25 07:11:54,396 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:11:54,397 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:11:54,397 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:11:54,524 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:11:54,526 - INFO  - >>>>>> Epoch  36
2022-11-25 07:11:54,528 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:12:01,176 - INFO  - Training [36][   20/  196]   Loss 0.086592   Top1 96.894531   Top5 100.000000   BatchTime 0.332240   LR 0.000118   
2022-11-25 07:12:06,151 - INFO  - Training [36][   40/  196]   Loss 0.092679   Top1 96.660156   Top5 100.000000   BatchTime 0.290510   LR 0.000118   
2022-11-25 07:12:10,914 - INFO  - Training [36][   60/  196]   Loss 0.095782   Top1 96.542969   Top5 99.993490   BatchTime 0.273064   LR 0.000117   
2022-11-25 07:12:15,888 - INFO  - Training [36][   80/  196]   Loss 0.095220   Top1 96.533203   Top5 99.990234   BatchTime 0.266969   LR 0.000117   
2022-11-25 07:12:20,697 - INFO  - Training [36][  100/  196]   Loss 0.095440   Top1 96.507812   Top5 99.992188   BatchTime 0.261656   LR 0.000117   
2022-11-25 07:12:25,659 - INFO  - Training [36][  120/  196]   Loss 0.095791   Top1 96.494141   Top5 99.990234   BatchTime 0.259402   LR 0.000117   
2022-11-25 07:12:31,037 - INFO  - Training [36][  140/  196]   Loss 0.096126   Top1 96.540179   Top5 99.986049   BatchTime 0.260757   LR 0.000117   
2022-11-25 07:12:36,153 - INFO  - Training [36][  160/  196]   Loss 0.097690   Top1 96.469727   Top5 99.982910   BatchTime 0.260134   LR 0.000116   
2022-11-25 07:12:41,228 - INFO  - Training [36][  180/  196]   Loss 0.098768   Top1 96.440972   Top5 99.984809   BatchTime 0.259425   LR 0.000116   
2022-11-25 07:12:45,395 - INFO  - ==> Top1: 96.410    Top5: 99.986    Loss: 0.100

2022-11-25 07:12:45,681 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:12:47,105 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:12:50,173 - INFO  - Validation [36][   20/   40]   Loss 0.401853   Top1 88.984375   Top5 99.550781   BatchTime 0.153305   
2022-11-25 07:12:51,384 - INFO  - Validation [36][   40/   40]   Loss 0.394677   Top1 89.020000   Top5 99.670000   BatchTime 0.106936   
2022-11-25 07:12:51,643 - INFO  - ==> Top1: 89.020    Top5: 99.670    Loss: 0.395

2022-11-25 07:12:51,643 - INFO  - ==> Sparsity : 0.735

2022-11-25 07:12:51,644 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:12:51,644 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:12:51,644 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:12:51,760 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:12:51,762 - INFO  - >>>>>> Epoch  37
2022-11-25 07:12:51,763 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:12:58,411 - INFO  - Training [37][   20/  196]   Loss 0.089699   Top1 96.757812   Top5 100.000000   BatchTime 0.332232   LR 0.000116   
2022-11-25 07:13:03,195 - INFO  - Training [37][   40/  196]   Loss 0.089002   Top1 96.738281   Top5 100.000000   BatchTime 0.285730   LR 0.000115   
2022-11-25 07:13:08,001 - INFO  - Training [37][   60/  196]   Loss 0.088954   Top1 96.783854   Top5 99.986979   BatchTime 0.270590   LR 0.000115   
2022-11-25 07:13:12,353 - INFO  - Training [37][   80/  196]   Loss 0.089557   Top1 96.796875   Top5 99.990234   BatchTime 0.257338   LR 0.000115   
2022-11-25 07:13:16,676 - INFO  - Training [37][  100/  196]   Loss 0.090030   Top1 96.800781   Top5 99.988281   BatchTime 0.249096   LR 0.000114   
2022-11-25 07:13:21,310 - INFO  - Training [37][  120/  196]   Loss 0.091326   Top1 96.728516   Top5 99.990234   BatchTime 0.246193   LR 0.000114   
2022-11-25 07:13:26,168 - INFO  - Training [37][  140/  196]   Loss 0.091943   Top1 96.688058   Top5 99.988839   BatchTime 0.245722   LR 0.000114   
2022-11-25 07:13:30,991 - INFO  - Training [37][  160/  196]   Loss 0.092759   Top1 96.652832   Top5 99.982910   BatchTime 0.245154   LR 0.000114   
2022-11-25 07:13:35,669 - INFO  - Training [37][  180/  196]   Loss 0.093859   Top1 96.608073   Top5 99.984809   BatchTime 0.243899   LR 0.000113   
2022-11-25 07:13:40,387 - INFO  - ==> Top1: 96.590    Top5: 99.984    Loss: 0.094

2022-11-25 07:13:40,585 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:13:41,699 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:13:44,802 - INFO  - Validation [37][   20/   40]   Loss 0.404363   Top1 89.121094   Top5 99.667969   BatchTime 0.155030   
2022-11-25 07:13:45,920 - INFO  - Validation [37][   40/   40]   Loss 0.398395   Top1 89.050000   Top5 99.730000   BatchTime 0.105479   
2022-11-25 07:13:46,231 - INFO  - ==> Top1: 89.050    Top5: 99.730    Loss: 0.398

2022-11-25 07:13:46,232 - INFO  - ==> Sparsity : 0.735

2022-11-25 07:13:46,232 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:13:46,232 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:13:46,232 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:13:46,356 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:13:46,358 - INFO  - >>>>>> Epoch  38
2022-11-25 07:13:46,360 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:13:53,413 - INFO  - Training [38][   20/  196]   Loss 0.081383   Top1 97.109375   Top5 100.000000   BatchTime 0.352530   LR 0.000113   
2022-11-25 07:13:58,226 - INFO  - Training [38][   40/  196]   Loss 0.095379   Top1 96.601562   Top5 100.000000   BatchTime 0.296595   LR 0.000112   
2022-11-25 07:14:02,760 - INFO  - Training [38][   60/  196]   Loss 0.090465   Top1 96.783854   Top5 99.986979   BatchTime 0.273278   LR 0.000112   
2022-11-25 07:14:07,189 - INFO  - Training [38][   80/  196]   Loss 0.090075   Top1 96.845703   Top5 99.985352   BatchTime 0.260327   LR 0.000112   
2022-11-25 07:14:11,403 - INFO  - Training [38][  100/  196]   Loss 0.088552   Top1 96.878906   Top5 99.984375   BatchTime 0.250401   LR 0.000112   
2022-11-25 07:14:15,927 - INFO  - Training [38][  120/  196]   Loss 0.090230   Top1 96.826172   Top5 99.977214   BatchTime 0.246364   LR 0.000111   
2022-11-25 07:14:21,104 - INFO  - Training [38][  140/  196]   Loss 0.090139   Top1 96.810826   Top5 99.980469   BatchTime 0.248147   LR 0.000111   
2022-11-25 07:14:25,814 - INFO  - Training [38][  160/  196]   Loss 0.090963   Top1 96.728516   Top5 99.980469   BatchTime 0.246564   LR 0.000111   
2022-11-25 07:14:30,465 - INFO  - Training [38][  180/  196]   Loss 0.090291   Top1 96.733941   Top5 99.982639   BatchTime 0.245008   LR 0.000110   
2022-11-25 07:14:34,513 - INFO  - ==> Top1: 96.718    Top5: 99.984    Loss: 0.090

2022-11-25 07:14:34,744 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:14:35,867 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:14:39,096 - INFO  - Validation [38][   20/   40]   Loss 0.413595   Top1 88.847656   Top5 99.531250   BatchTime 0.161391   
2022-11-25 07:14:40,254 - INFO  - Validation [38][   40/   40]   Loss 0.400105   Top1 89.010000   Top5 99.620000   BatchTime 0.109630   
2022-11-25 07:14:40,544 - INFO  - ==> Top1: 89.010    Top5: 99.620    Loss: 0.400

2022-11-25 07:14:40,544 - INFO  - ==> Sparsity : 0.736

2022-11-25 07:14:40,545 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:14:40,545 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:14:40,545 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:14:40,685 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:14:40,687 - INFO  - >>>>>> Epoch  39
2022-11-25 07:14:40,689 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:14:48,226 - INFO  - Training [39][   20/  196]   Loss 0.085924   Top1 96.757812   Top5 99.980469   BatchTime 0.376737   LR 0.000110   
2022-11-25 07:14:52,882 - INFO  - Training [39][   40/  196]   Loss 0.086732   Top1 96.933594   Top5 99.980469   BatchTime 0.304741   LR 0.000109   
2022-11-25 07:14:57,830 - INFO  - Training [39][   60/  196]   Loss 0.090190   Top1 96.751302   Top5 99.973958   BatchTime 0.285626   LR 0.000109   
2022-11-25 07:15:02,714 - INFO  - Training [39][   80/  196]   Loss 0.090966   Top1 96.704102   Top5 99.970703   BatchTime 0.275269   LR 0.000109   
2022-11-25 07:15:07,494 - INFO  - Training [39][  100/  196]   Loss 0.091730   Top1 96.679688   Top5 99.964844   BatchTime 0.268012   LR 0.000108   
2022-11-25 07:15:12,216 - INFO  - Training [39][  120/  196]   Loss 0.091302   Top1 96.738281   Top5 99.964193   BatchTime 0.262695   LR 0.000108   
2022-11-25 07:15:17,063 - INFO  - Training [39][  140/  196]   Loss 0.090889   Top1 96.752232   Top5 99.963728   BatchTime 0.259792   LR 0.000108   
2022-11-25 07:15:21,725 - INFO  - Training [39][  160/  196]   Loss 0.090732   Top1 96.777344   Top5 99.968262   BatchTime 0.256455   LR 0.000107   
2022-11-25 07:15:26,419 - INFO  - Training [39][  180/  196]   Loss 0.090606   Top1 96.753472   Top5 99.969618   BatchTime 0.254034   LR 0.000107   
2022-11-25 07:15:30,201 - INFO  - ==> Top1: 96.724    Top5: 99.972    Loss: 0.091

2022-11-25 07:15:30,390 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:15:31,575 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:15:34,695 - INFO  - Validation [39][   20/   40]   Loss 0.409268   Top1 89.257812   Top5 99.628906   BatchTime 0.155906   
2022-11-25 07:15:35,814 - INFO  - Validation [39][   40/   40]   Loss 0.404377   Top1 89.300000   Top5 99.680000   BatchTime 0.105947   
2022-11-25 07:15:36,039 - INFO  - ==> Top1: 89.300    Top5: 99.680    Loss: 0.404

2022-11-25 07:15:36,040 - INFO  - ==> Sparsity : 0.736

2022-11-25 07:15:36,040 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:15:36,040 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:15:36,040 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:15:36,162 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:15:36,164 - INFO  - >>>>>> Epoch  40
2022-11-25 07:15:36,166 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:15:42,918 - INFO  - Training [40][   20/  196]   Loss 0.077911   Top1 97.265625   Top5 100.000000   BatchTime 0.337485   LR 0.000106   
2022-11-25 07:15:47,681 - INFO  - Training [40][   40/  196]   Loss 0.080786   Top1 97.109375   Top5 99.990234   BatchTime 0.287821   LR 0.000106   
2022-11-25 07:15:52,510 - INFO  - Training [40][   60/  196]   Loss 0.081399   Top1 97.070312   Top5 99.993490   BatchTime 0.272355   LR 0.000106   
2022-11-25 07:15:57,658 - INFO  - Training [40][   80/  196]   Loss 0.084331   Top1 96.997070   Top5 99.995117   BatchTime 0.268615   LR 0.000105   
2022-11-25 07:16:02,650 - INFO  - Training [40][  100/  196]   Loss 0.083031   Top1 97.062500   Top5 99.996094   BatchTime 0.264807   LR 0.000105   
2022-11-25 07:16:07,382 - INFO  - Training [40][  120/  196]   Loss 0.084164   Top1 97.021484   Top5 99.996745   BatchTime 0.260107   LR 0.000105   
2022-11-25 07:16:12,061 - INFO  - Training [40][  140/  196]   Loss 0.084836   Top1 96.969866   Top5 99.997210   BatchTime 0.256368   LR 0.000104   
2022-11-25 07:16:16,720 - INFO  - Training [40][  160/  196]   Loss 0.085146   Top1 96.987305   Top5 99.997559   BatchTime 0.253440   LR 0.000104   
2022-11-25 07:16:21,371 - INFO  - Training [40][  180/  196]   Loss 0.085306   Top1 96.974826   Top5 99.995660   BatchTime 0.251121   LR 0.000103   
2022-11-25 07:16:25,562 - INFO  - ==> Top1: 96.918    Top5: 99.994    Loss: 0.087

2022-11-25 07:16:25,741 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:16:27,191 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:16:30,304 - INFO  - Validation [40][   20/   40]   Loss 0.408006   Top1 89.433594   Top5 99.511719   BatchTime 0.155531   
2022-11-25 07:16:31,478 - INFO  - Validation [40][   40/   40]   Loss 0.403846   Top1 89.370000   Top5 99.570000   BatchTime 0.107132   
2022-11-25 07:16:31,732 - INFO  - ==> Top1: 89.370    Top5: 99.570    Loss: 0.404

2022-11-25 07:16:31,732 - INFO  - ==> Sparsity : 0.736

2022-11-25 07:16:31,733 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:16:31,733 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:16:31,733 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:16:31,869 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:16:31,871 - INFO  - >>>>>> Epoch  41
2022-11-25 07:16:31,873 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:16:38,654 - INFO  - Training [41][   20/  196]   Loss 0.084691   Top1 96.914062   Top5 99.980469   BatchTime 0.338944   LR 0.000103   
2022-11-25 07:16:43,428 - INFO  - Training [41][   40/  196]   Loss 0.081468   Top1 97.001953   Top5 99.990234   BatchTime 0.288810   LR 0.000102   
2022-11-25 07:16:48,248 - INFO  - Training [41][   60/  196]   Loss 0.083872   Top1 96.953125   Top5 99.993490   BatchTime 0.272881   LR 0.000102   
2022-11-25 07:16:53,082 - INFO  - Training [41][   80/  196]   Loss 0.082565   Top1 97.006836   Top5 99.990234   BatchTime 0.265086   LR 0.000102   
2022-11-25 07:16:57,851 - INFO  - Training [41][  100/  196]   Loss 0.083698   Top1 96.968750   Top5 99.976562   BatchTime 0.259749   LR 0.000101   
2022-11-25 07:17:03,407 - INFO  - Training [41][  120/  196]   Loss 0.085010   Top1 96.891276   Top5 99.977214   BatchTime 0.262763   LR 0.000101   
2022-11-25 07:17:08,639 - INFO  - Training [41][  140/  196]   Loss 0.086663   Top1 96.810826   Top5 99.980469   BatchTime 0.262590   LR 0.000100   
2022-11-25 07:17:13,483 - INFO  - Training [41][  160/  196]   Loss 0.086941   Top1 96.796875   Top5 99.982910   BatchTime 0.260043   LR 0.000100   
2022-11-25 07:17:18,168 - INFO  - Training [41][  180/  196]   Loss 0.086831   Top1 96.807726   Top5 99.980469   BatchTime 0.257174   LR 0.000100   
2022-11-25 07:17:22,124 - INFO  - ==> Top1: 96.824    Top5: 99.982    Loss: 0.087

2022-11-25 07:17:22,318 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:17:23,451 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:17:26,544 - INFO  - Validation [41][   20/   40]   Loss 0.429085   Top1 88.886719   Top5 99.589844   BatchTime 0.154570   
2022-11-25 07:17:27,709 - INFO  - Validation [41][   40/   40]   Loss 0.411852   Top1 88.920000   Top5 99.640000   BatchTime 0.106409   
2022-11-25 07:17:27,962 - INFO  - ==> Top1: 88.920    Top5: 99.640    Loss: 0.412

2022-11-25 07:17:27,962 - INFO  - ==> Sparsity : 0.737

2022-11-25 07:17:27,962 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:17:27,963 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:17:27,963 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:17:28,088 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:17:28,090 - INFO  - >>>>>> Epoch  42
2022-11-25 07:17:28,092 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:17:34,737 - INFO  - Training [42][   20/  196]   Loss 0.069624   Top1 97.656250   Top5 99.980469   BatchTime 0.332132   LR 0.000099   
2022-11-25 07:17:39,818 - INFO  - Training [42][   40/  196]   Loss 0.075987   Top1 97.392578   Top5 99.990234   BatchTime 0.293099   LR 0.000098   
2022-11-25 07:17:44,612 - INFO  - Training [42][   60/  196]   Loss 0.080176   Top1 97.180990   Top5 99.986979   BatchTime 0.275293   LR 0.000098   
2022-11-25 07:17:49,431 - INFO  - Training [42][   80/  196]   Loss 0.076999   Top1 97.343750   Top5 99.990234   BatchTime 0.266706   LR 0.000098   
2022-11-25 07:17:54,489 - INFO  - Training [42][  100/  196]   Loss 0.076199   Top1 97.355469   Top5 99.992188   BatchTime 0.263942   LR 0.000097   
2022-11-25 07:17:59,109 - INFO  - Training [42][  120/  196]   Loss 0.078784   Top1 97.265625   Top5 99.993490   BatchTime 0.258450   LR 0.000097   
2022-11-25 07:18:03,891 - INFO  - Training [42][  140/  196]   Loss 0.079080   Top1 97.287946   Top5 99.988839   BatchTime 0.255689   LR 0.000096   
2022-11-25 07:18:09,515 - INFO  - Training [42][  160/  196]   Loss 0.078545   Top1 97.309570   Top5 99.987793   BatchTime 0.258874   LR 0.000096   
2022-11-25 07:18:14,534 - INFO  - Training [42][  180/  196]   Loss 0.079278   Top1 97.246094   Top5 99.989149   BatchTime 0.257995   LR 0.000096   
2022-11-25 07:18:18,505 - INFO  - ==> Top1: 97.238    Top5: 99.990    Loss: 0.080

2022-11-25 07:18:18,696 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:18:20,056 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:18:23,162 - INFO  - Validation [42][   20/   40]   Loss 0.437504   Top1 88.769531   Top5 99.648438   BatchTime 0.155215   
2022-11-25 07:18:24,384 - INFO  - Validation [42][   40/   40]   Loss 0.425117   Top1 88.830000   Top5 99.730000   BatchTime 0.108170   
2022-11-25 07:18:24,654 - INFO  - ==> Top1: 88.830    Top5: 99.730    Loss: 0.425

2022-11-25 07:18:24,655 - INFO  - ==> Sparsity : 0.737

2022-11-25 07:18:24,655 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:18:24,655 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:18:24,655 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:18:24,792 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:18:24,794 - INFO  - >>>>>> Epoch  43
2022-11-25 07:18:24,795 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:18:31,784 - INFO  - Training [43][   20/  196]   Loss 0.079308   Top1 97.187500   Top5 99.960938   BatchTime 0.349305   LR 0.000095   
2022-11-25 07:18:36,711 - INFO  - Training [43][   40/  196]   Loss 0.074990   Top1 97.402344   Top5 99.980469   BatchTime 0.297832   LR 0.000094   
2022-11-25 07:18:41,667 - INFO  - Training [43][   60/  196]   Loss 0.074242   Top1 97.402344   Top5 99.986979   BatchTime 0.281151   LR 0.000094   
2022-11-25 07:18:46,709 - INFO  - Training [43][   80/  196]   Loss 0.074529   Top1 97.456055   Top5 99.990234   BatchTime 0.273888   LR 0.000093   
2022-11-25 07:18:51,751 - INFO  - Training [43][  100/  196]   Loss 0.076894   Top1 97.328125   Top5 99.992188   BatchTime 0.269528   LR 0.000093   
2022-11-25 07:18:56,897 - INFO  - Training [43][  120/  196]   Loss 0.076684   Top1 97.333984   Top5 99.990234   BatchTime 0.267487   LR 0.000093   
2022-11-25 07:19:01,939 - INFO  - Training [43][  140/  196]   Loss 0.077046   Top1 97.304688   Top5 99.988839   BatchTime 0.265289   LR 0.000092   
2022-11-25 07:19:06,943 - INFO  - Training [43][  160/  196]   Loss 0.076549   Top1 97.326660   Top5 99.987793   BatchTime 0.263403   LR 0.000092   
2022-11-25 07:19:12,605 - INFO  - Training [43][  180/  196]   Loss 0.076875   Top1 97.289497   Top5 99.989149   BatchTime 0.265586   LR 0.000091   
2022-11-25 07:19:16,609 - INFO  - ==> Top1: 97.246    Top5: 99.990    Loss: 0.078

2022-11-25 07:19:16,784 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:19:17,981 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:19:21,056 - INFO  - Validation [43][   20/   40]   Loss 0.407988   Top1 89.257812   Top5 99.648438   BatchTime 0.153642   
2022-11-25 07:19:22,185 - INFO  - Validation [43][   40/   40]   Loss 0.403473   Top1 89.120000   Top5 99.710000   BatchTime 0.105051   
2022-11-25 07:19:22,456 - INFO  - ==> Top1: 89.120    Top5: 99.710    Loss: 0.403

2022-11-25 07:19:22,456 - INFO  - ==> Sparsity : 0.737

2022-11-25 07:19:22,456 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:19:22,457 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:19:22,457 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:19:22,584 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:19:22,586 - INFO  - >>>>>> Epoch  44
2022-11-25 07:19:22,588 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:19:29,273 - INFO  - Training [44][   20/  196]   Loss 0.072300   Top1 97.285156   Top5 100.000000   BatchTime 0.334113   LR 0.000090   
2022-11-25 07:19:34,143 - INFO  - Training [44][   40/  196]   Loss 0.072567   Top1 97.255859   Top5 100.000000   BatchTime 0.288795   LR 0.000090   
2022-11-25 07:19:39,143 - INFO  - Training [44][   60/  196]   Loss 0.071808   Top1 97.278646   Top5 100.000000   BatchTime 0.275871   LR 0.000090   
2022-11-25 07:19:44,132 - INFO  - Training [44][   80/  196]   Loss 0.072063   Top1 97.255859   Top5 99.995117   BatchTime 0.269256   LR 0.000089   
2022-11-25 07:19:49,029 - INFO  - Training [44][  100/  196]   Loss 0.075096   Top1 97.214844   Top5 99.996094   BatchTime 0.264382   LR 0.000089   
2022-11-25 07:19:53,970 - INFO  - Training [44][  120/  196]   Loss 0.076548   Top1 97.184245   Top5 99.996745   BatchTime 0.261485   LR 0.000088   
2022-11-25 07:19:58,936 - INFO  - Training [44][  140/  196]   Loss 0.077056   Top1 97.198661   Top5 99.997210   BatchTime 0.259604   LR 0.000088   
2022-11-25 07:20:03,823 - INFO  - Training [44][  160/  196]   Loss 0.077813   Top1 97.165527   Top5 99.997559   BatchTime 0.257699   LR 0.000087   
2022-11-25 07:20:08,394 - INFO  - Training [44][  180/  196]   Loss 0.077308   Top1 97.194010   Top5 99.997830   BatchTime 0.254454   LR 0.000087   
2022-11-25 07:20:12,325 - INFO  - ==> Top1: 97.158    Top5: 99.996    Loss: 0.078

2022-11-25 07:20:12,588 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:20:14,579 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:20:17,534 - INFO  - Validation [44][   20/   40]   Loss 0.412460   Top1 89.121094   Top5 99.648438   BatchTime 0.147580   
2022-11-25 07:20:18,743 - INFO  - Validation [44][   40/   40]   Loss 0.411202   Top1 89.060000   Top5 99.690000   BatchTime 0.104052   
2022-11-25 07:20:18,978 - INFO  - ==> Top1: 89.060    Top5: 99.690    Loss: 0.411

2022-11-25 07:20:18,978 - INFO  - ==> Sparsity : 0.737

2022-11-25 07:20:18,979 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:20:18,979 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:20:18,979 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:20:19,469 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:20:19,471 - INFO  - >>>>>> Epoch  45
2022-11-25 07:20:19,473 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:20:26,178 - INFO  - Training [45][   20/  196]   Loss 0.070619   Top1 97.519531   Top5 99.960938   BatchTime 0.335135   LR 0.000086   
2022-11-25 07:20:31,088 - INFO  - Training [45][   40/  196]   Loss 0.071974   Top1 97.490234   Top5 99.970703   BatchTime 0.290325   LR 0.000086   
2022-11-25 07:20:35,911 - INFO  - Training [45][   60/  196]   Loss 0.073389   Top1 97.454427   Top5 99.980469   BatchTime 0.273934   LR 0.000085   
2022-11-25 07:20:40,582 - INFO  - Training [45][   80/  196]   Loss 0.073267   Top1 97.421875   Top5 99.980469   BatchTime 0.263835   LR 0.000085   
2022-11-25 07:20:45,310 - INFO  - Training [45][  100/  196]   Loss 0.074520   Top1 97.371094   Top5 99.984375   BatchTime 0.258343   LR 0.000084   
2022-11-25 07:20:50,188 - INFO  - Training [45][  120/  196]   Loss 0.073651   Top1 97.373047   Top5 99.986979   BatchTime 0.255936   LR 0.000084   
2022-11-25 07:20:55,099 - INFO  - Training [45][  140/  196]   Loss 0.072773   Top1 97.393973   Top5 99.988839   BatchTime 0.254454   LR 0.000083   
2022-11-25 07:21:00,037 - INFO  - Training [45][  160/  196]   Loss 0.072774   Top1 97.416992   Top5 99.987793   BatchTime 0.253504   LR 0.000083   
2022-11-25 07:21:04,912 - INFO  - Training [45][  180/  196]   Loss 0.072838   Top1 97.421875   Top5 99.986979   BatchTime 0.252419   LR 0.000082   
2022-11-25 07:21:08,868 - INFO  - ==> Top1: 97.408    Top5: 99.988    Loss: 0.073

2022-11-25 07:21:09,090 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:21:10,308 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:21:13,324 - INFO  - Validation [45][   20/   40]   Loss 0.414483   Top1 89.628906   Top5 99.589844   BatchTime 0.150665   
2022-11-25 07:21:14,494 - INFO  - Validation [45][   40/   40]   Loss 0.407130   Top1 89.400000   Top5 99.680000   BatchTime 0.104606   
2022-11-25 07:21:14,748 - INFO  - ==> Top1: 89.400    Top5: 99.680    Loss: 0.407

2022-11-25 07:21:14,749 - INFO  - ==> Sparsity : 0.738

2022-11-25 07:21:14,749 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:21:14,749 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:21:14,749 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:21:14,873 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:21:14,874 - INFO  - >>>>>> Epoch  46
2022-11-25 07:21:14,876 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:21:22,297 - INFO  - Training [46][   20/  196]   Loss 0.066088   Top1 97.460938   Top5 99.980469   BatchTime 0.370909   LR 0.000081   
2022-11-25 07:21:27,570 - INFO  - Training [46][   40/  196]   Loss 0.067240   Top1 97.509766   Top5 99.980469   BatchTime 0.317287   LR 0.000081   
2022-11-25 07:21:32,630 - INFO  - Training [46][   60/  196]   Loss 0.067263   Top1 97.565104   Top5 99.980469   BatchTime 0.295858   LR 0.000080   
2022-11-25 07:21:37,462 - INFO  - Training [46][   80/  196]   Loss 0.067140   Top1 97.583008   Top5 99.985352   BatchTime 0.282285   LR 0.000080   
2022-11-25 07:21:42,080 - INFO  - Training [46][  100/  196]   Loss 0.069366   Top1 97.535156   Top5 99.988281   BatchTime 0.272015   LR 0.000079   
2022-11-25 07:21:46,412 - INFO  - Training [46][  120/  196]   Loss 0.069275   Top1 97.587891   Top5 99.986979   BatchTime 0.262778   LR 0.000079   
2022-11-25 07:21:50,973 - INFO  - Training [46][  140/  196]   Loss 0.069117   Top1 97.575335   Top5 99.986049   BatchTime 0.257810   LR 0.000078   
2022-11-25 07:21:55,911 - INFO  - Training [46][  160/  196]   Loss 0.069049   Top1 97.561035   Top5 99.985352   BatchTime 0.256451   LR 0.000078   
2022-11-25 07:22:00,657 - INFO  - Training [46][  180/  196]   Loss 0.069292   Top1 97.536892   Top5 99.986979   BatchTime 0.254321   LR 0.000077   
2022-11-25 07:22:04,547 - INFO  - ==> Top1: 97.530    Top5: 99.988    Loss: 0.069

2022-11-25 07:22:04,727 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:22:05,711 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:22:08,711 - INFO  - Validation [46][   20/   40]   Loss 0.410328   Top1 89.492188   Top5 99.531250   BatchTime 0.149881   
2022-11-25 07:22:09,880 - INFO  - Validation [46][   40/   40]   Loss 0.406674   Top1 89.610000   Top5 99.650000   BatchTime 0.104174   
2022-11-25 07:22:10,177 - INFO  - ==> Top1: 89.610    Top5: 99.650    Loss: 0.407

2022-11-25 07:22:10,178 - INFO  - ==> Sparsity : 0.738

2022-11-25 07:22:10,178 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:22:10,178 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:22:10,178 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:22:10,307 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:22:10,308 - INFO  - >>>>>> Epoch  47
2022-11-25 07:22:10,310 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:22:17,909 - INFO  - Training [47][   20/  196]   Loss 0.071638   Top1 97.304688   Top5 99.980469   BatchTime 0.379794   LR 0.000077   
2022-11-25 07:22:23,030 - INFO  - Training [47][   40/  196]   Loss 0.072798   Top1 97.236328   Top5 99.990234   BatchTime 0.317935   LR 0.000076   
2022-11-25 07:22:28,358 - INFO  - Training [47][   60/  196]   Loss 0.074079   Top1 97.285156   Top5 99.993490   BatchTime 0.300754   LR 0.000076   
2022-11-25 07:22:33,119 - INFO  - Training [47][   80/  196]   Loss 0.074551   Top1 97.294922   Top5 99.990234   BatchTime 0.285074   LR 0.000075   
2022-11-25 07:22:37,886 - INFO  - Training [47][  100/  196]   Loss 0.071490   Top1 97.449219   Top5 99.992188   BatchTime 0.275730   LR 0.000075   
2022-11-25 07:22:42,757 - INFO  - Training [47][  120/  196]   Loss 0.069367   Top1 97.539062   Top5 99.990234   BatchTime 0.270367   LR 0.000074   
2022-11-25 07:22:47,562 - INFO  - Training [47][  140/  196]   Loss 0.068747   Top1 97.564174   Top5 99.991629   BatchTime 0.266063   LR 0.000074   
2022-11-25 07:22:52,286 - INFO  - Training [47][  160/  196]   Loss 0.067191   Top1 97.607422   Top5 99.992676   BatchTime 0.262330   LR 0.000073   
2022-11-25 07:22:57,006 - INFO  - Training [47][  180/  196]   Loss 0.067513   Top1 97.573785   Top5 99.993490   BatchTime 0.259405   LR 0.000073   
2022-11-25 07:23:01,044 - INFO  - ==> Top1: 97.590    Top5: 99.994    Loss: 0.067

2022-11-25 07:23:01,238 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:23:02,401 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:23:05,492 - INFO  - Validation [47][   20/   40]   Loss 0.408437   Top1 89.746094   Top5 99.570312   BatchTime 0.154459   
2022-11-25 07:23:06,660 - INFO  - Validation [47][   40/   40]   Loss 0.407589   Top1 89.610000   Top5 99.640000   BatchTime 0.106440   
2022-11-25 07:23:06,899 - INFO  - ==> Top1: 89.610    Top5: 99.640    Loss: 0.408

2022-11-25 07:23:06,899 - INFO  - ==> Sparsity : 0.738

2022-11-25 07:23:06,899 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:23:06,900 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:23:06,900 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:23:07,028 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:23:07,030 - INFO  - >>>>>> Epoch  48
2022-11-25 07:23:07,032 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:23:13,415 - INFO  - Training [48][   20/  196]   Loss 0.067874   Top1 97.480469   Top5 100.000000   BatchTime 0.319003   LR 0.000072   
2022-11-25 07:23:17,741 - INFO  - Training [48][   40/  196]   Loss 0.063663   Top1 97.705078   Top5 100.000000   BatchTime 0.267661   LR 0.000071   
2022-11-25 07:23:22,193 - INFO  - Training [48][   60/  196]   Loss 0.065501   Top1 97.708333   Top5 100.000000   BatchTime 0.252635   LR 0.000071   
2022-11-25 07:23:27,430 - INFO  - Training [48][   80/  196]   Loss 0.066690   Top1 97.709961   Top5 100.000000   BatchTime 0.254945   LR 0.000070   
2022-11-25 07:23:32,084 - INFO  - Training [48][  100/  196]   Loss 0.065347   Top1 97.773438   Top5 100.000000   BatchTime 0.250494   LR 0.000070   
2022-11-25 07:23:36,862 - INFO  - Training [48][  120/  196]   Loss 0.064593   Top1 97.799479   Top5 99.996745   BatchTime 0.248557   LR 0.000069   
2022-11-25 07:23:41,943 - INFO  - Training [48][  140/  196]   Loss 0.064128   Top1 97.790179   Top5 99.997210   BatchTime 0.249343   LR 0.000069   
2022-11-25 07:23:47,109 - INFO  - Training [48][  160/  196]   Loss 0.064976   Top1 97.758789   Top5 99.992676   BatchTime 0.250459   LR 0.000068   
2022-11-25 07:23:51,909 - INFO  - Training [48][  180/  196]   Loss 0.065619   Top1 97.727865   Top5 99.991319   BatchTime 0.249298   LR 0.000068   
2022-11-25 07:23:56,026 - INFO  - ==> Top1: 97.726    Top5: 99.990    Loss: 0.066

2022-11-25 07:23:56,226 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:23:57,462 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:24:00,615 - INFO  - Validation [48][   20/   40]   Loss 0.419997   Top1 89.589844   Top5 99.648438   BatchTime 0.157566   
2022-11-25 07:24:01,665 - INFO  - Validation [48][   40/   40]   Loss 0.404382   Top1 89.620000   Top5 99.730000   BatchTime 0.105059   
2022-11-25 07:24:01,937 - INFO  - ==> Top1: 89.620    Top5: 99.730    Loss: 0.404

2022-11-25 07:24:01,937 - INFO  - ==> Sparsity : 0.738

2022-11-25 07:24:01,938 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:24:01,938 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:24:01,938 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:24:02,068 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:24:02,069 - INFO  - >>>>>> Epoch  49
2022-11-25 07:24:02,071 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:24:08,750 - INFO  - Training [49][   20/  196]   Loss 0.059426   Top1 97.851562   Top5 100.000000   BatchTime 0.333827   LR 0.000067   
2022-11-25 07:24:13,461 - INFO  - Training [49][   40/  196]   Loss 0.059164   Top1 97.900391   Top5 99.990234   BatchTime 0.284686   LR 0.000066   
2022-11-25 07:24:18,086 - INFO  - Training [49][   60/  196]   Loss 0.057155   Top1 97.936198   Top5 99.993490   BatchTime 0.266874   LR 0.000066   
2022-11-25 07:24:23,331 - INFO  - Training [49][   80/  196]   Loss 0.059862   Top1 97.939453   Top5 99.995117   BatchTime 0.265720   LR 0.000065   
2022-11-25 07:24:28,995 - INFO  - Training [49][  100/  196]   Loss 0.060334   Top1 97.910156   Top5 99.996094   BatchTime 0.269208   LR 0.000065   
2022-11-25 07:24:35,925 - INFO  - Training [49][  120/  196]   Loss 0.059640   Top1 97.926432   Top5 99.996745   BatchTime 0.282095   LR 0.000064   
2022-11-25 07:24:42,567 - INFO  - Training [49][  140/  196]   Loss 0.060232   Top1 97.904576   Top5 99.994420   BatchTime 0.289233   LR 0.000064   
2022-11-25 07:24:49,317 - INFO  - Training [49][  160/  196]   Loss 0.059837   Top1 97.907715   Top5 99.995117   BatchTime 0.295268   LR 0.000063   
2022-11-25 07:24:55,735 - INFO  - Training [49][  180/  196]   Loss 0.059965   Top1 97.890625   Top5 99.995660   BatchTime 0.298115   LR 0.000063   
2022-11-25 07:25:01,493 - INFO  - ==> Top1: 97.872    Top5: 99.996    Loss: 0.060

2022-11-25 07:25:01,670 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:25:03,146 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:25:06,210 - INFO  - Validation [49][   20/   40]   Loss 0.428666   Top1 89.335938   Top5 99.589844   BatchTime 0.153115   
2022-11-25 07:25:07,269 - INFO  - Validation [49][   40/   40]   Loss 0.417880   Top1 89.280000   Top5 99.670000   BatchTime 0.103022   
2022-11-25 07:25:07,515 - INFO  - ==> Top1: 89.280    Top5: 99.670    Loss: 0.418

2022-11-25 07:25:07,515 - INFO  - ==> Sparsity : 0.738

2022-11-25 07:25:07,515 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:25:07,515 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:25:07,516 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:25:07,638 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:25:07,639 - INFO  - >>>>>> Epoch  50
2022-11-25 07:25:07,641 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:25:16,208 - INFO  - Training [50][   20/  196]   Loss 0.054511   Top1 97.988281   Top5 99.980469   BatchTime 0.428231   LR 0.000062   
2022-11-25 07:25:22,589 - INFO  - Training [50][   40/  196]   Loss 0.053223   Top1 98.017578   Top5 99.990234   BatchTime 0.373635   LR 0.000062   
2022-11-25 07:25:29,228 - INFO  - Training [50][   60/  196]   Loss 0.053665   Top1 98.001302   Top5 99.993490   BatchTime 0.359732   LR 0.000061   
2022-11-25 07:25:36,095 - INFO  - Training [50][   80/  196]   Loss 0.053139   Top1 98.041992   Top5 99.995117   BatchTime 0.355637   LR 0.000061   
2022-11-25 07:25:42,607 - INFO  - Training [50][  100/  196]   Loss 0.052882   Top1 98.105469   Top5 99.996094   BatchTime 0.349634   LR 0.000060   
2022-11-25 07:25:48,459 - INFO  - Training [50][  120/  196]   Loss 0.054895   Top1 98.053385   Top5 99.996745   BatchTime 0.340123   LR 0.000060   
2022-11-25 07:25:53,831 - INFO  - Training [50][  140/  196]   Loss 0.055283   Top1 98.002232   Top5 99.997210   BatchTime 0.329907   LR 0.000059   
2022-11-25 07:25:59,428 - INFO  - Training [50][  160/  196]   Loss 0.055820   Top1 97.956543   Top5 99.997559   BatchTime 0.323652   LR 0.000059   
2022-11-25 07:26:06,128 - INFO  - Training [50][  180/  196]   Loss 0.055540   Top1 97.960069   Top5 99.997830   BatchTime 0.324911   LR 0.000058   
2022-11-25 07:26:11,623 - INFO  - ==> Top1: 97.934    Top5: 99.996    Loss: 0.056

2022-11-25 07:26:11,800 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:26:13,200 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:26:16,156 - INFO  - Validation [50][   20/   40]   Loss 0.427682   Top1 89.433594   Top5 99.687500   BatchTime 0.147703   
2022-11-25 07:26:17,177 - INFO  - Validation [50][   40/   40]   Loss 0.418280   Top1 89.680000   Top5 99.720000   BatchTime 0.099383   
2022-11-25 07:26:17,445 - INFO  - ==> Top1: 89.680    Top5: 99.720    Loss: 0.418

2022-11-25 07:26:17,445 - INFO  - ==> Sparsity : 0.738

2022-11-25 07:26:17,446 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:26:17,446 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:26:17,446 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:26:17,607 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:26:17,609 - INFO  - >>>>>> Epoch  51
2022-11-25 07:26:17,611 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:26:25,956 - INFO  - Training [51][   20/  196]   Loss 0.056023   Top1 98.125000   Top5 99.980469   BatchTime 0.417132   LR 0.000057   
2022-11-25 07:26:32,650 - INFO  - Training [51][   40/  196]   Loss 0.055005   Top1 98.125000   Top5 99.990234   BatchTime 0.375899   LR 0.000057   
2022-11-25 07:26:39,818 - INFO  - Training [51][   60/  196]   Loss 0.053525   Top1 98.177083   Top5 99.986979   BatchTime 0.370067   LR 0.000056   
2022-11-25 07:26:46,663 - INFO  - Training [51][   80/  196]   Loss 0.054123   Top1 98.149414   Top5 99.985352   BatchTime 0.363110   LR 0.000056   
2022-11-25 07:26:53,303 - INFO  - Training [51][  100/  196]   Loss 0.054728   Top1 98.078125   Top5 99.988281   BatchTime 0.356893   LR 0.000055   
2022-11-25 07:27:00,008 - INFO  - Training [51][  120/  196]   Loss 0.053819   Top1 98.095703   Top5 99.990234   BatchTime 0.353280   LR 0.000055   
2022-11-25 07:27:07,022 - INFO  - Training [51][  140/  196]   Loss 0.054770   Top1 98.055246   Top5 99.991629   BatchTime 0.352917   LR 0.000054   
2022-11-25 07:27:12,635 - INFO  - Training [51][  160/  196]   Loss 0.055319   Top1 98.037109   Top5 99.992676   BatchTime 0.343880   LR 0.000054   
2022-11-25 07:27:17,899 - INFO  - Training [51][  180/  196]   Loss 0.055548   Top1 98.042535   Top5 99.993490   BatchTime 0.334916   LR 0.000053   
2022-11-25 07:27:22,155 - INFO  - ==> Top1: 98.022    Top5: 99.994    Loss: 0.056

2022-11-25 07:27:22,353 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:27:23,724 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:27:26,692 - INFO  - Validation [51][   20/   40]   Loss 0.429403   Top1 89.160156   Top5 99.765625   BatchTime 0.148297   
2022-11-25 07:27:27,793 - INFO  - Validation [51][   40/   40]   Loss 0.412021   Top1 89.610000   Top5 99.830000   BatchTime 0.101690   
2022-11-25 07:27:28,046 - INFO  - ==> Top1: 89.610    Top5: 99.830    Loss: 0.412

2022-11-25 07:27:28,046 - INFO  - ==> Sparsity : 0.738

2022-11-25 07:27:28,046 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:27:28,046 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:27:28,046 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:27:28,175 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:27:28,177 - INFO  - >>>>>> Epoch  52
2022-11-25 07:27:28,179 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:27:36,428 - INFO  - Training [52][   20/  196]   Loss 0.055615   Top1 97.968750   Top5 100.000000   BatchTime 0.412302   LR 0.000052   
2022-11-25 07:27:43,202 - INFO  - Training [52][   40/  196]   Loss 0.055882   Top1 97.968750   Top5 99.990234   BatchTime 0.375499   LR 0.000052   
2022-11-25 07:27:49,932 - INFO  - Training [52][   60/  196]   Loss 0.057660   Top1 97.903646   Top5 99.986979   BatchTime 0.362508   LR 0.000051   
2022-11-25 07:27:56,636 - INFO  - Training [52][   80/  196]   Loss 0.058568   Top1 97.895508   Top5 99.990234   BatchTime 0.355671   LR 0.000051   
2022-11-25 07:28:03,307 - INFO  - Training [52][  100/  196]   Loss 0.058371   Top1 97.937500   Top5 99.992188   BatchTime 0.351248   LR 0.000050   
2022-11-25 07:28:10,050 - INFO  - Training [52][  120/  196]   Loss 0.057734   Top1 97.952474   Top5 99.993490   BatchTime 0.348895   LR 0.000050   
2022-11-25 07:28:16,876 - INFO  - Training [52][  140/  196]   Loss 0.056835   Top1 97.979911   Top5 99.994420   BatchTime 0.347810   LR 0.000049   
2022-11-25 07:28:23,556 - INFO  - Training [52][  160/  196]   Loss 0.056644   Top1 97.988281   Top5 99.992676   BatchTime 0.346087   LR 0.000049   
2022-11-25 07:28:30,311 - INFO  - Training [52][  180/  196]   Loss 0.056372   Top1 97.996962   Top5 99.993490   BatchTime 0.345159   LR 0.000048   
2022-11-25 07:28:34,949 - INFO  - ==> Top1: 97.990    Top5: 99.994    Loss: 0.057

2022-11-25 07:28:35,291 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:28:36,985 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:28:40,524 - INFO  - Validation [52][   20/   40]   Loss 0.427706   Top1 89.570312   Top5 99.726562   BatchTime 0.176832   
2022-11-25 07:28:41,657 - INFO  - Validation [52][   40/   40]   Loss 0.415425   Top1 89.570000   Top5 99.750000   BatchTime 0.116732   
2022-11-25 07:28:42,564 - INFO  - ==> Top1: 89.570    Top5: 99.750    Loss: 0.415

2022-11-25 07:28:42,565 - INFO  - ==> Sparsity : 0.738

2022-11-25 07:28:42,565 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:28:42,565 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:28:42,565 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 89.950   Top5: 99.770]
2022-11-25 07:28:42,706 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:28:42,708 - INFO  - >>>>>> Epoch  53
2022-11-25 07:28:42,710 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:28:50,790 - INFO  - Training [53][   20/  196]   Loss 0.049397   Top1 98.359375   Top5 100.000000   BatchTime 0.403872   LR 0.000047   
2022-11-25 07:28:57,595 - INFO  - Training [53][   40/  196]   Loss 0.049204   Top1 98.320312   Top5 100.000000   BatchTime 0.372047   LR 0.000047   
2022-11-25 07:29:04,285 - INFO  - Training [53][   60/  196]   Loss 0.048925   Top1 98.320312   Top5 100.000000   BatchTime 0.359525   LR 0.000046   
2022-11-25 07:29:10,811 - INFO  - Training [53][   80/  196]   Loss 0.048897   Top1 98.305664   Top5 99.990234   BatchTime 0.351222   LR 0.000046   
2022-11-25 07:29:17,445 - INFO  - Training [53][  100/  196]   Loss 0.049287   Top1 98.312500   Top5 99.992188   BatchTime 0.347317   LR 0.000046   
2022-11-25 07:29:24,124 - INFO  - Training [53][  120/  196]   Loss 0.048735   Top1 98.330078   Top5 99.990234   BatchTime 0.345091   LR 0.000045   
2022-11-25 07:29:30,785 - INFO  - Training [53][  140/  196]   Loss 0.048326   Top1 98.359375   Top5 99.988839   BatchTime 0.343371   LR 0.000045   
2022-11-25 07:29:37,699 - INFO  - Training [53][  160/  196]   Loss 0.048673   Top1 98.344727   Top5 99.990234   BatchTime 0.343656   LR 0.000044   
2022-11-25 07:29:44,707 - INFO  - Training [53][  180/  196]   Loss 0.048696   Top1 98.328993   Top5 99.989149   BatchTime 0.344406   LR 0.000044   
2022-11-25 07:29:50,562 - INFO  - ==> Top1: 98.292    Top5: 99.990    Loss: 0.049

2022-11-25 07:29:50,724 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:29:52,002 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:29:54,999 - INFO  - Validation [53][   20/   40]   Loss 0.415280   Top1 90.136719   Top5 99.667969   BatchTime 0.149802   
2022-11-25 07:29:56,191 - INFO  - Validation [53][   40/   40]   Loss 0.407339   Top1 90.010000   Top5 99.780000   BatchTime 0.104693   
2022-11-25 07:29:56,594 - INFO  - ==> Top1: 90.010    Top5: 99.780    Loss: 0.407

2022-11-25 07:29:56,595 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:29:56,595 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 90.010   Top5: 99.780]
2022-11-25 07:29:56,595 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:29:56,596 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:30:03,158 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 07:30:03,163 - INFO  - >>>>>> Epoch  54
2022-11-25 07:30:03,168 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:30:11,575 - INFO  - Training [54][   20/  196]   Loss 0.047980   Top1 98.359375   Top5 100.000000   BatchTime 0.420095   LR 0.000043   
2022-11-25 07:30:18,445 - INFO  - Training [54][   40/  196]   Loss 0.052002   Top1 98.046875   Top5 100.000000   BatchTime 0.381796   LR 0.000042   
2022-11-25 07:30:25,128 - INFO  - Training [54][   60/  196]   Loss 0.049324   Top1 98.216146   Top5 100.000000   BatchTime 0.365911   LR 0.000042   
2022-11-25 07:30:31,912 - INFO  - Training [54][   80/  196]   Loss 0.051696   Top1 98.120117   Top5 100.000000   BatchTime 0.359230   LR 0.000041   
2022-11-25 07:30:38,505 - INFO  - Training [54][  100/  196]   Loss 0.051179   Top1 98.128906   Top5 100.000000   BatchTime 0.353318   LR 0.000041   
2022-11-25 07:30:45,388 - INFO  - Training [54][  120/  196]   Loss 0.050831   Top1 98.147786   Top5 100.000000   BatchTime 0.351788   LR 0.000040   
2022-11-25 07:30:52,520 - INFO  - Training [54][  140/  196]   Loss 0.050985   Top1 98.155692   Top5 100.000000   BatchTime 0.352475   LR 0.000040   
2022-11-25 07:30:59,848 - INFO  - Training [54][  160/  196]   Loss 0.049937   Top1 98.193359   Top5 99.997559   BatchTime 0.354213   LR 0.000039   
2022-11-25 07:31:08,296 - INFO  - Training [54][  180/  196]   Loss 0.049266   Top1 98.231337   Top5 99.997830   BatchTime 0.361787   LR 0.000039   
2022-11-25 07:31:15,183 - INFO  - ==> Top1: 98.248    Top5: 99.998    Loss: 0.049

2022-11-25 07:31:15,369 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:31:17,163 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:31:20,157 - INFO  - Validation [54][   20/   40]   Loss 0.425511   Top1 90.019531   Top5 99.707031   BatchTime 0.149650   
2022-11-25 07:31:21,218 - INFO  - Validation [54][   40/   40]   Loss 0.423324   Top1 89.820000   Top5 99.780000   BatchTime 0.101339   
2022-11-25 07:31:21,489 - INFO  - ==> Top1: 89.820    Top5: 99.780    Loss: 0.423

2022-11-25 07:31:21,490 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:31:21,490 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 90.010   Top5: 99.780]
2022-11-25 07:31:21,490 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:31:21,490 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 89.980   Top5: 99.740]
2022-11-25 07:31:22,031 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:31:22,033 - INFO  - >>>>>> Epoch  55
2022-11-25 07:31:22,034 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:31:31,956 - INFO  - Training [55][   20/  196]   Loss 0.055568   Top1 98.203125   Top5 99.980469   BatchTime 0.495946   LR 0.000038   
2022-11-25 07:31:39,106 - INFO  - Training [55][   40/  196]   Loss 0.050972   Top1 98.281250   Top5 99.990234   BatchTime 0.426721   LR 0.000038   
2022-11-25 07:31:46,562 - INFO  - Training [55][   60/  196]   Loss 0.050768   Top1 98.326823   Top5 99.993490   BatchTime 0.408750   LR 0.000037   
2022-11-25 07:31:54,887 - INFO  - Training [55][   80/  196]   Loss 0.050791   Top1 98.295898   Top5 99.995117   BatchTime 0.410625   LR 0.000037   
2022-11-25 07:32:03,405 - INFO  - Training [55][  100/  196]   Loss 0.050961   Top1 98.281250   Top5 99.996094   BatchTime 0.413675   LR 0.000036   
2022-11-25 07:32:11,720 - INFO  - Training [55][  120/  196]   Loss 0.049126   Top1 98.339844   Top5 99.996745   BatchTime 0.414024   LR 0.000036   
2022-11-25 07:32:20,100 - INFO  - Training [55][  140/  196]   Loss 0.049621   Top1 98.300781   Top5 99.997210   BatchTime 0.414731   LR 0.000035   
2022-11-25 07:32:28,474 - INFO  - Training [55][  160/  196]   Loss 0.048987   Top1 98.310547   Top5 99.997559   BatchTime 0.415228   LR 0.000035   
2022-11-25 07:32:36,802 - INFO  - Training [55][  180/  196]   Loss 0.048748   Top1 98.302951   Top5 99.997830   BatchTime 0.415359   LR 0.000034   
2022-11-25 07:32:42,914 - INFO  - ==> Top1: 98.304    Top5: 99.998    Loss: 0.049

2022-11-25 07:32:43,257 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:32:44,977 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:32:48,038 - INFO  - Validation [55][   20/   40]   Loss 0.425614   Top1 90.292969   Top5 99.609375   BatchTime 0.152984   
2022-11-25 07:32:49,070 - INFO  - Validation [55][   40/   40]   Loss 0.415032   Top1 90.160000   Top5 99.690000   BatchTime 0.102285   
2022-11-25 07:32:49,376 - INFO  - ==> Top1: 90.160    Top5: 99.690    Loss: 0.415

2022-11-25 07:32:49,376 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:32:49,376 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:32:49,376 - INFO  - Scoreboard best 2 ==> Epoch [53][Top1: 90.010   Top5: 99.780]
2022-11-25 07:32:49,377 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:32:54,484 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 07:32:54,489 - INFO  - >>>>>> Epoch  56
2022-11-25 07:32:54,491 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:33:02,945 - INFO  - Training [56][   20/  196]   Loss 0.051279   Top1 98.261719   Top5 100.000000   BatchTime 0.422571   LR 0.000034   
2022-11-25 07:33:08,881 - INFO  - Training [56][   40/  196]   Loss 0.046709   Top1 98.466797   Top5 99.990234   BatchTime 0.359678   LR 0.000033   
2022-11-25 07:33:13,860 - INFO  - Training [56][   60/  196]   Loss 0.044714   Top1 98.457031   Top5 99.993490   BatchTime 0.322765   LR 0.000033   
2022-11-25 07:33:19,917 - INFO  - Training [56][   80/  196]   Loss 0.044938   Top1 98.486328   Top5 99.995117   BatchTime 0.317789   LR 0.000032   
2022-11-25 07:33:27,473 - INFO  - Training [56][  100/  196]   Loss 0.045287   Top1 98.457031   Top5 99.992188   BatchTime 0.329795   LR 0.000032   
2022-11-25 07:33:35,615 - INFO  - Training [56][  120/  196]   Loss 0.045397   Top1 98.440755   Top5 99.993490   BatchTime 0.342674   LR 0.000031   
2022-11-25 07:33:43,718 - INFO  - Training [56][  140/  196]   Loss 0.045577   Top1 98.429129   Top5 99.994420   BatchTime 0.351602   LR 0.000031   
2022-11-25 07:33:51,860 - INFO  - Training [56][  160/  196]   Loss 0.045969   Top1 98.417969   Top5 99.995117   BatchTime 0.358535   LR 0.000031   
2022-11-25 07:34:00,034 - INFO  - Training [56][  180/  196]   Loss 0.045585   Top1 98.439670   Top5 99.995660   BatchTime 0.364108   LR 0.000030   
2022-11-25 07:34:07,197 - INFO  - ==> Top1: 98.416    Top5: 99.996    Loss: 0.046

2022-11-25 07:34:07,396 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:34:09,478 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:34:12,829 - INFO  - Validation [56][   20/   40]   Loss 0.435555   Top1 89.472656   Top5 99.589844   BatchTime 0.167417   
2022-11-25 07:34:14,496 - INFO  - Validation [56][   40/   40]   Loss 0.422345   Top1 89.480000   Top5 99.700000   BatchTime 0.125409   
2022-11-25 07:34:14,763 - INFO  - ==> Top1: 89.480    Top5: 99.700    Loss: 0.422

2022-11-25 07:34:14,763 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:34:14,764 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:34:14,764 - INFO  - Scoreboard best 2 ==> Epoch [53][Top1: 90.010   Top5: 99.780]
2022-11-25 07:34:14,764 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:34:14,893 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:34:14,894 - INFO  - >>>>>> Epoch  57
2022-11-25 07:34:14,896 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:34:25,306 - INFO  - Training [57][   20/  196]   Loss 0.041282   Top1 98.554688   Top5 100.000000   BatchTime 0.520384   LR 0.000029   
2022-11-25 07:34:33,632 - INFO  - Training [57][   40/  196]   Loss 0.043542   Top1 98.417969   Top5 100.000000   BatchTime 0.468350   LR 0.000029   
2022-11-25 07:34:41,759 - INFO  - Training [57][   60/  196]   Loss 0.043661   Top1 98.430990   Top5 99.993490   BatchTime 0.447679   LR 0.000029   
2022-11-25 07:34:48,823 - INFO  - Training [57][   80/  196]   Loss 0.041921   Top1 98.505859   Top5 99.990234   BatchTime 0.424050   LR 0.000028   
2022-11-25 07:34:56,119 - INFO  - Training [57][  100/  196]   Loss 0.043515   Top1 98.488281   Top5 99.992188   BatchTime 0.412203   LR 0.000028   
2022-11-25 07:35:04,534 - INFO  - Training [57][  120/  196]   Loss 0.042987   Top1 98.505859   Top5 99.990234   BatchTime 0.413623   LR 0.000027   
2022-11-25 07:35:12,305 - INFO  - Training [57][  140/  196]   Loss 0.043870   Top1 98.454241   Top5 99.988839   BatchTime 0.410045   LR 0.000027   
2022-11-25 07:35:19,477 - INFO  - Training [57][  160/  196]   Loss 0.043835   Top1 98.449707   Top5 99.990234   BatchTime 0.403613   LR 0.000027   
2022-11-25 07:35:27,838 - INFO  - Training [57][  180/  196]   Loss 0.043747   Top1 98.454861   Top5 99.991319   BatchTime 0.405217   LR 0.000026   
2022-11-25 07:35:35,158 - INFO  - ==> Top1: 98.458    Top5: 99.992    Loss: 0.044

2022-11-25 07:35:35,401 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:35:37,297 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:35:40,517 - INFO  - Validation [57][   20/   40]   Loss 0.427649   Top1 89.960938   Top5 99.628906   BatchTime 0.160912   
2022-11-25 07:35:41,644 - INFO  - Validation [57][   40/   40]   Loss 0.418679   Top1 89.940000   Top5 99.720000   BatchTime 0.108649   
2022-11-25 07:35:41,963 - INFO  - ==> Top1: 89.940    Top5: 99.720    Loss: 0.419

2022-11-25 07:35:41,963 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:35:41,963 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:35:41,963 - INFO  - Scoreboard best 2 ==> Epoch [53][Top1: 90.010   Top5: 99.780]
2022-11-25 07:35:41,964 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.010   Top5: 99.750]
2022-11-25 07:35:42,104 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:35:42,106 - INFO  - >>>>>> Epoch  58
2022-11-25 07:35:42,107 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:35:52,943 - INFO  - Training [58][   20/  196]   Loss 0.040635   Top1 98.574219   Top5 100.000000   BatchTime 0.541642   LR 0.000025   
2022-11-25 07:36:01,622 - INFO  - Training [58][   40/  196]   Loss 0.043259   Top1 98.583984   Top5 100.000000   BatchTime 0.487809   LR 0.000025   
2022-11-25 07:36:10,479 - INFO  - Training [58][   60/  196]   Loss 0.043222   Top1 98.613281   Top5 100.000000   BatchTime 0.472807   LR 0.000025   
2022-11-25 07:36:18,848 - INFO  - Training [58][   80/  196]   Loss 0.043448   Top1 98.569336   Top5 99.995117   BatchTime 0.459218   LR 0.000024   
2022-11-25 07:36:26,589 - INFO  - Training [58][  100/  196]   Loss 0.043157   Top1 98.582031   Top5 99.996094   BatchTime 0.444787   LR 0.000024   
2022-11-25 07:36:33,971 - INFO  - Training [58][  120/  196]   Loss 0.043222   Top1 98.551432   Top5 99.996745   BatchTime 0.432165   LR 0.000023   
2022-11-25 07:36:42,303 - INFO  - Training [58][  140/  196]   Loss 0.042902   Top1 98.551897   Top5 99.997210   BatchTime 0.429944   LR 0.000023   
2022-11-25 07:36:50,419 - INFO  - Training [58][  160/  196]   Loss 0.042947   Top1 98.547363   Top5 99.997559   BatchTime 0.426927   LR 0.000023   
2022-11-25 07:36:57,393 - INFO  - Training [58][  180/  196]   Loss 0.043288   Top1 98.550347   Top5 99.995660   BatchTime 0.418233   LR 0.000022   
2022-11-25 07:37:04,167 - INFO  - ==> Top1: 98.526    Top5: 99.996    Loss: 0.044

2022-11-25 07:37:04,372 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:37:06,196 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:37:09,337 - INFO  - Validation [58][   20/   40]   Loss 0.417921   Top1 90.058594   Top5 99.628906   BatchTime 0.156929   
2022-11-25 07:37:10,606 - INFO  - Validation [58][   40/   40]   Loss 0.416352   Top1 90.110000   Top5 99.730000   BatchTime 0.110190   
2022-11-25 07:37:10,907 - INFO  - ==> Top1: 90.110    Top5: 99.730    Loss: 0.416

2022-11-25 07:37:10,907 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:37:10,908 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:37:10,908 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 90.110   Top5: 99.730]
2022-11-25 07:37:10,908 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 90.010   Top5: 99.780]
2022-11-25 07:37:11,358 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:37:11,360 - INFO  - >>>>>> Epoch  59
2022-11-25 07:37:11,361 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:37:22,150 - INFO  - Training [59][   20/  196]   Loss 0.036807   Top1 98.769531   Top5 100.000000   BatchTime 0.539296   LR 0.000022   
2022-11-25 07:37:30,842 - INFO  - Training [59][   40/  196]   Loss 0.040125   Top1 98.681641   Top5 99.990234   BatchTime 0.486962   LR 0.000021   
2022-11-25 07:37:39,475 - INFO  - Training [59][   60/  196]   Loss 0.041306   Top1 98.626302   Top5 99.993490   BatchTime 0.468518   LR 0.000021   
2022-11-25 07:37:48,343 - INFO  - Training [59][   80/  196]   Loss 0.041627   Top1 98.549805   Top5 99.995117   BatchTime 0.462230   LR 0.000020   
2022-11-25 07:37:56,926 - INFO  - Training [59][  100/  196]   Loss 0.041376   Top1 98.582031   Top5 99.996094   BatchTime 0.455617   LR 0.000020   
2022-11-25 07:38:05,243 - INFO  - Training [59][  120/  196]   Loss 0.041113   Top1 98.570964   Top5 99.996745   BatchTime 0.448987   LR 0.000020   
2022-11-25 07:38:12,666 - INFO  - Training [59][  140/  196]   Loss 0.040896   Top1 98.554688   Top5 99.997210   BatchTime 0.437869   LR 0.000019   
2022-11-25 07:38:19,940 - INFO  - Training [59][  160/  196]   Loss 0.040761   Top1 98.566895   Top5 99.997559   BatchTime 0.428597   LR 0.000019   
2022-11-25 07:38:27,794 - INFO  - Training [59][  180/  196]   Loss 0.040366   Top1 98.587240   Top5 99.997830   BatchTime 0.424608   LR 0.000019   
2022-11-25 07:38:33,630 - INFO  - ==> Top1: 98.574    Top5: 99.998    Loss: 0.041

2022-11-25 07:38:33,892 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:38:36,061 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:38:40,195 - INFO  - Validation [59][   20/   40]   Loss 0.422051   Top1 90.175781   Top5 99.726562   BatchTime 0.206613   
2022-11-25 07:38:41,262 - INFO  - Validation [59][   40/   40]   Loss 0.419193   Top1 90.070000   Top5 99.770000   BatchTime 0.130005   
2022-11-25 07:38:41,541 - INFO  - ==> Top1: 90.070    Top5: 99.770    Loss: 0.419

2022-11-25 07:38:41,541 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:38:41,541 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:38:41,542 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 90.110   Top5: 99.730]
2022-11-25 07:38:41,542 - INFO  - Scoreboard best 3 ==> Epoch [59][Top1: 90.070   Top5: 99.770]
2022-11-25 07:38:41,667 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:38:41,669 - INFO  - >>>>>> Epoch  60
2022-11-25 07:38:41,670 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:38:52,138 - INFO  - Training [60][   20/  196]   Loss 0.042273   Top1 98.359375   Top5 100.000000   BatchTime 0.523225   LR 0.000018   
2022-11-25 07:39:00,574 - INFO  - Training [60][   40/  196]   Loss 0.039999   Top1 98.583984   Top5 100.000000   BatchTime 0.472535   LR 0.000018   
2022-11-25 07:39:08,821 - INFO  - Training [60][   60/  196]   Loss 0.040098   Top1 98.567708   Top5 100.000000   BatchTime 0.452466   LR 0.000017   
2022-11-25 07:39:17,060 - INFO  - Training [60][   80/  196]   Loss 0.038647   Top1 98.657227   Top5 100.000000   BatchTime 0.442338   LR 0.000017   
2022-11-25 07:39:25,431 - INFO  - Training [60][  100/  196]   Loss 0.036863   Top1 98.730469   Top5 100.000000   BatchTime 0.437576   LR 0.000017   
2022-11-25 07:39:33,855 - INFO  - Training [60][  120/  196]   Loss 0.037857   Top1 98.717448   Top5 100.000000   BatchTime 0.434845   LR 0.000016   
2022-11-25 07:39:42,914 - INFO  - Training [60][  140/  196]   Loss 0.037706   Top1 98.730469   Top5 100.000000   BatchTime 0.437429   LR 0.000016   
2022-11-25 07:39:50,775 - INFO  - Training [60][  160/  196]   Loss 0.037441   Top1 98.730469   Top5 100.000000   BatchTime 0.431886   LR 0.000016   
2022-11-25 07:39:59,060 - INFO  - Training [60][  180/  196]   Loss 0.036680   Top1 98.760851   Top5 100.000000   BatchTime 0.429922   LR 0.000015   
2022-11-25 07:40:05,914 - INFO  - ==> Top1: 98.736    Top5: 100.000    Loss: 0.037

2022-11-25 07:40:06,147 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:40:08,085 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:40:11,564 - INFO  - Validation [60][   20/   40]   Loss 0.430274   Top1 90.292969   Top5 99.726562   BatchTime 0.173773   
2022-11-25 07:40:12,736 - INFO  - Validation [60][   40/   40]   Loss 0.419054   Top1 90.170000   Top5 99.770000   BatchTime 0.116180   
2022-11-25 07:40:13,088 - INFO  - ==> Top1: 90.170    Top5: 99.770    Loss: 0.419

2022-11-25 07:40:13,088 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:40:13,088 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 90.170   Top5: 99.770]
2022-11-25 07:40:13,088 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:40:13,089 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 90.110   Top5: 99.730]
2022-11-25 07:40:19,615 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 07:40:19,617 - INFO  - >>>>>> Epoch  61
2022-11-25 07:40:19,620 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:40:30,246 - INFO  - Training [61][   20/  196]   Loss 0.037474   Top1 98.789062   Top5 100.000000   BatchTime 0.531185   LR 0.000015   
2022-11-25 07:40:38,885 - INFO  - Training [61][   40/  196]   Loss 0.038696   Top1 98.720703   Top5 100.000000   BatchTime 0.481572   LR 0.000014   
2022-11-25 07:40:47,874 - INFO  - Training [61][   60/  196]   Loss 0.040593   Top1 98.678385   Top5 100.000000   BatchTime 0.470865   LR 0.000014   
2022-11-25 07:40:56,742 - INFO  - Training [61][   80/  196]   Loss 0.039698   Top1 98.691406   Top5 100.000000   BatchTime 0.463998   LR 0.000014   
2022-11-25 07:41:05,352 - INFO  - Training [61][  100/  196]   Loss 0.040041   Top1 98.671875   Top5 100.000000   BatchTime 0.457293   LR 0.000013   
2022-11-25 07:41:14,256 - INFO  - Training [61][  120/  196]   Loss 0.038983   Top1 98.707682   Top5 100.000000   BatchTime 0.455281   LR 0.000013   
2022-11-25 07:41:22,034 - INFO  - Training [61][  140/  196]   Loss 0.039083   Top1 98.688616   Top5 100.000000   BatchTime 0.445794   LR 0.000013   
2022-11-25 07:41:30,505 - INFO  - Training [61][  160/  196]   Loss 0.038747   Top1 98.698730   Top5 99.997559   BatchTime 0.443011   LR 0.000012   
2022-11-25 07:41:39,314 - INFO  - Training [61][  180/  196]   Loss 0.039412   Top1 98.680556   Top5 99.997830   BatchTime 0.442730   LR 0.000012   
2022-11-25 07:41:46,088 - INFO  - ==> Top1: 98.642    Top5: 99.998    Loss: 0.040

2022-11-25 07:41:46,283 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:41:49,390 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:41:52,643 - INFO  - Validation [61][   20/   40]   Loss 0.419631   Top1 90.292969   Top5 99.589844   BatchTime 0.162534   
2022-11-25 07:41:53,870 - INFO  - Validation [61][   40/   40]   Loss 0.416352   Top1 90.120000   Top5 99.680000   BatchTime 0.111967   
2022-11-25 07:41:54,177 - INFO  - ==> Top1: 90.120    Top5: 99.680    Loss: 0.416

2022-11-25 07:41:54,177 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:41:54,178 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 90.170   Top5: 99.770]
2022-11-25 07:41:54,178 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:41:54,178 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 90.120   Top5: 99.680]
2022-11-25 07:41:54,304 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:41:54,305 - INFO  - >>>>>> Epoch  62
2022-11-25 07:41:54,307 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:42:04,936 - INFO  - Training [62][   20/  196]   Loss 0.041476   Top1 98.613281   Top5 100.000000   BatchTime 0.531324   LR 0.000012   
2022-11-25 07:42:13,799 - INFO  - Training [62][   40/  196]   Loss 0.038886   Top1 98.691406   Top5 100.000000   BatchTime 0.487223   LR 0.000011   
2022-11-25 07:42:22,411 - INFO  - Training [62][   60/  196]   Loss 0.038859   Top1 98.730469   Top5 100.000000   BatchTime 0.468345   LR 0.000011   
2022-11-25 07:42:31,222 - INFO  - Training [62][   80/  196]   Loss 0.037380   Top1 98.750000   Top5 100.000000   BatchTime 0.461407   LR 0.000011   
2022-11-25 07:42:39,942 - INFO  - Training [62][  100/  196]   Loss 0.037461   Top1 98.714844   Top5 100.000000   BatchTime 0.456316   LR 0.000011   
2022-11-25 07:42:48,757 - INFO  - Training [62][  120/  196]   Loss 0.036397   Top1 98.746745   Top5 100.000000   BatchTime 0.453725   LR 0.000010   
2022-11-25 07:42:56,612 - INFO  - Training [62][  140/  196]   Loss 0.036146   Top1 98.769531   Top5 100.000000   BatchTime 0.445011   LR 0.000010   
2022-11-25 07:43:05,199 - INFO  - Training [62][  160/  196]   Loss 0.035839   Top1 98.762207   Top5 100.000000   BatchTime 0.443053   LR 0.000010   
2022-11-25 07:43:14,019 - INFO  - Training [62][  180/  196]   Loss 0.036240   Top1 98.747830   Top5 100.000000   BatchTime 0.442826   LR 0.000009   
2022-11-25 07:43:20,910 - INFO  - ==> Top1: 98.732    Top5: 100.000    Loss: 0.037

2022-11-25 07:43:21,118 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:43:23,002 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:43:26,187 - INFO  - Validation [62][   20/   40]   Loss 0.424755   Top1 90.214844   Top5 99.648438   BatchTime 0.159163   
2022-11-25 07:43:27,620 - INFO  - Validation [62][   40/   40]   Loss 0.425023   Top1 90.040000   Top5 99.710000   BatchTime 0.115395   
2022-11-25 07:43:27,938 - INFO  - ==> Top1: 90.040    Top5: 99.710    Loss: 0.425

2022-11-25 07:43:27,938 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:43:27,938 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 90.170   Top5: 99.770]
2022-11-25 07:43:27,938 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:43:27,939 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 90.120   Top5: 99.680]
2022-11-25 07:43:28,392 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:43:28,395 - INFO  - >>>>>> Epoch  63
2022-11-25 07:43:28,396 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:43:37,904 - INFO  - Training [63][   20/  196]   Loss 0.033540   Top1 98.750000   Top5 100.000000   BatchTime 0.475229   LR 0.000009   
2022-11-25 07:43:46,619 - INFO  - Training [63][   40/  196]   Loss 0.036513   Top1 98.671875   Top5 100.000000   BatchTime 0.455492   LR 0.000009   
2022-11-25 07:43:55,190 - INFO  - Training [63][   60/  196]   Loss 0.034593   Top1 98.828125   Top5 100.000000   BatchTime 0.446519   LR 0.000008   
2022-11-25 07:44:04,270 - INFO  - Training [63][   80/  196]   Loss 0.035527   Top1 98.784180   Top5 99.995117   BatchTime 0.448384   LR 0.000008   
2022-11-25 07:44:13,101 - INFO  - Training [63][  100/  196]   Loss 0.036291   Top1 98.773438   Top5 99.996094   BatchTime 0.447019   LR 0.000008   
2022-11-25 07:44:21,682 - INFO  - Training [63][  120/  196]   Loss 0.035990   Top1 98.789062   Top5 99.996745   BatchTime 0.444017   LR 0.000008   
2022-11-25 07:44:29,733 - INFO  - Training [63][  140/  196]   Loss 0.035794   Top1 98.783482   Top5 99.997210   BatchTime 0.438094   LR 0.000007   
2022-11-25 07:44:37,663 - INFO  - Training [63][  160/  196]   Loss 0.036178   Top1 98.779297   Top5 99.997559   BatchTime 0.432894   LR 0.000007   
2022-11-25 07:44:46,571 - INFO  - Training [63][  180/  196]   Loss 0.035956   Top1 98.780382   Top5 99.997830   BatchTime 0.434285   LR 0.000007   
2022-11-25 07:44:53,582 - INFO  - ==> Top1: 98.792    Top5: 99.998    Loss: 0.036

2022-11-25 07:44:53,763 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:44:55,602 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:44:58,672 - INFO  - Validation [63][   20/   40]   Loss 0.424678   Top1 90.273438   Top5 99.707031   BatchTime 0.153426   
2022-11-25 07:44:59,795 - INFO  - Validation [63][   40/   40]   Loss 0.422959   Top1 90.100000   Top5 99.740000   BatchTime 0.104783   
2022-11-25 07:45:00,048 - INFO  - ==> Top1: 90.100    Top5: 99.740    Loss: 0.423

2022-11-25 07:45:00,048 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:45:00,048 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 90.170   Top5: 99.770]
2022-11-25 07:45:00,048 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:45:00,048 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 90.120   Top5: 99.680]
2022-11-25 07:45:00,191 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:45:00,193 - INFO  - >>>>>> Epoch  64
2022-11-25 07:45:00,195 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:45:09,626 - INFO  - Training [64][   20/  196]   Loss 0.027952   Top1 98.964844   Top5 100.000000   BatchTime 0.471426   LR 0.000007   
2022-11-25 07:45:16,918 - INFO  - Training [64][   40/  196]   Loss 0.031690   Top1 98.857422   Top5 100.000000   BatchTime 0.418021   LR 0.000006   
2022-11-25 07:45:24,952 - INFO  - Training [64][   60/  196]   Loss 0.030893   Top1 98.958333   Top5 100.000000   BatchTime 0.412575   LR 0.000006   
2022-11-25 07:45:33,878 - INFO  - Training [64][   80/  196]   Loss 0.033501   Top1 98.876953   Top5 100.000000   BatchTime 0.421001   LR 0.000006   
2022-11-25 07:45:42,672 - INFO  - Training [64][  100/  196]   Loss 0.033605   Top1 98.851562   Top5 100.000000   BatchTime 0.424743   LR 0.000006   
2022-11-25 07:45:51,220 - INFO  - Training [64][  120/  196]   Loss 0.033538   Top1 98.860677   Top5 100.000000   BatchTime 0.425183   LR 0.000006   
2022-11-25 07:46:00,012 - INFO  - Training [64][  140/  196]   Loss 0.033113   Top1 98.861607   Top5 100.000000   BatchTime 0.427243   LR 0.000005   
2022-11-25 07:46:07,342 - INFO  - Training [64][  160/  196]   Loss 0.033684   Top1 98.845215   Top5 100.000000   BatchTime 0.419649   LR 0.000005   
2022-11-25 07:46:16,008 - INFO  - Training [64][  180/  196]   Loss 0.033906   Top1 98.830295   Top5 100.000000   BatchTime 0.421162   LR 0.000005   
2022-11-25 07:46:23,219 - INFO  - ==> Top1: 98.830    Top5: 100.000    Loss: 0.034

2022-11-25 07:46:23,443 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:46:25,219 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:46:28,416 - INFO  - Validation [64][   20/   40]   Loss 0.422507   Top1 90.292969   Top5 99.687500   BatchTime 0.159766   
2022-11-25 07:46:29,482 - INFO  - Validation [64][   40/   40]   Loss 0.415789   Top1 89.930000   Top5 99.740000   BatchTime 0.106524   
2022-11-25 07:46:29,774 - INFO  - ==> Top1: 89.930    Top5: 99.740    Loss: 0.416

2022-11-25 07:46:29,774 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:46:29,775 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 90.170   Top5: 99.770]
2022-11-25 07:46:29,775 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:46:29,775 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 90.120   Top5: 99.680]
2022-11-25 07:46:29,905 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:46:29,907 - INFO  - >>>>>> Epoch  65
2022-11-25 07:46:29,908 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:46:40,471 - INFO  - Training [65][   20/  196]   Loss 0.028746   Top1 99.042969   Top5 99.980469   BatchTime 0.527979   LR 0.000005   
2022-11-25 07:46:48,627 - INFO  - Training [65][   40/  196]   Loss 0.033150   Top1 98.955078   Top5 99.990234   BatchTime 0.467899   LR 0.000004   
2022-11-25 07:46:56,276 - INFO  - Training [65][   60/  196]   Loss 0.034395   Top1 98.925781   Top5 99.993490   BatchTime 0.439420   LR 0.000004   
2022-11-25 07:47:04,238 - INFO  - Training [65][   80/  196]   Loss 0.035644   Top1 98.803711   Top5 99.995117   BatchTime 0.429084   LR 0.000004   
2022-11-25 07:47:13,006 - INFO  - Training [65][  100/  196]   Loss 0.036820   Top1 98.734375   Top5 99.996094   BatchTime 0.430945   LR 0.000004   
2022-11-25 07:47:22,194 - INFO  - Training [65][  120/  196]   Loss 0.037064   Top1 98.743490   Top5 99.996745   BatchTime 0.435690   LR 0.000004   
2022-11-25 07:47:31,063 - INFO  - Training [65][  140/  196]   Loss 0.037014   Top1 98.766741   Top5 99.997210   BatchTime 0.436794   LR 0.000004   
2022-11-25 07:47:38,753 - INFO  - Training [65][  160/  196]   Loss 0.036793   Top1 98.762207   Top5 99.997559   BatchTime 0.430259   LR 0.000003   
2022-11-25 07:47:47,035 - INFO  - Training [65][  180/  196]   Loss 0.036442   Top1 98.767361   Top5 99.997830   BatchTime 0.428462   LR 0.000003   
2022-11-25 07:47:54,200 - INFO  - ==> Top1: 98.782    Top5: 99.998    Loss: 0.036

2022-11-25 07:47:54,388 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:47:56,296 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:47:59,417 - INFO  - Validation [65][   20/   40]   Loss 0.420661   Top1 90.410156   Top5 99.707031   BatchTime 0.155997   
2022-11-25 07:48:00,471 - INFO  - Validation [65][   40/   40]   Loss 0.417878   Top1 90.140000   Top5 99.750000   BatchTime 0.104337   
2022-11-25 07:48:00,762 - INFO  - ==> Top1: 90.140    Top5: 99.750    Loss: 0.418

2022-11-25 07:48:00,762 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:48:00,763 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 90.170   Top5: 99.770]
2022-11-25 07:48:00,763 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:48:00,763 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.140   Top5: 99.750]
2022-11-25 07:48:00,895 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:48:00,897 - INFO  - >>>>>> Epoch  66
2022-11-25 07:48:00,899 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:48:11,590 - INFO  - Training [66][   20/  196]   Loss 0.029913   Top1 99.082031   Top5 100.000000   BatchTime 0.534421   LR 0.000003   
2022-11-25 07:48:20,760 - INFO  - Training [66][   40/  196]   Loss 0.030100   Top1 99.052734   Top5 100.000000   BatchTime 0.496460   LR 0.000003   
2022-11-25 07:48:28,937 - INFO  - Training [66][   60/  196]   Loss 0.034438   Top1 98.893229   Top5 100.000000   BatchTime 0.467265   LR 0.000003   
2022-11-25 07:48:36,065 - INFO  - Training [66][   80/  196]   Loss 0.035316   Top1 98.818359   Top5 100.000000   BatchTime 0.439544   LR 0.000002   
2022-11-25 07:48:44,323 - INFO  - Training [66][  100/  196]   Loss 0.035533   Top1 98.777344   Top5 100.000000   BatchTime 0.434210   LR 0.000002   
2022-11-25 07:48:52,980 - INFO  - Training [66][  120/  196]   Loss 0.035259   Top1 98.779297   Top5 100.000000   BatchTime 0.433988   LR 0.000002   
2022-11-25 07:49:01,484 - INFO  - Training [66][  140/  196]   Loss 0.035535   Top1 98.772321   Top5 99.997210   BatchTime 0.432726   LR 0.000002   
2022-11-25 07:49:09,881 - INFO  - Training [66][  160/  196]   Loss 0.035599   Top1 98.771973   Top5 99.997559   BatchTime 0.431117   LR 0.000002   
2022-11-25 07:49:17,258 - INFO  - Training [66][  180/  196]   Loss 0.034904   Top1 98.797743   Top5 99.997830   BatchTime 0.424202   LR 0.000002   
2022-11-25 07:49:24,565 - INFO  - ==> Top1: 98.808    Top5: 99.996    Loss: 0.035

2022-11-25 07:49:24,748 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:49:26,599 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:49:29,617 - INFO  - Validation [66][   20/   40]   Loss 0.431201   Top1 90.117188   Top5 99.746094   BatchTime 0.150811   
2022-11-25 07:49:30,674 - INFO  - Validation [66][   40/   40]   Loss 0.423184   Top1 90.000000   Top5 99.760000   BatchTime 0.101821   
2022-11-25 07:49:30,942 - INFO  - ==> Top1: 90.000    Top5: 99.760    Loss: 0.423

2022-11-25 07:49:30,942 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:49:30,942 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 90.170   Top5: 99.770]
2022-11-25 07:49:30,943 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:49:30,943 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.140   Top5: 99.750]
2022-11-25 07:49:31,065 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:49:31,066 - INFO  - >>>>>> Epoch  67
2022-11-25 07:49:31,069 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:49:41,944 - INFO  - Training [67][   20/  196]   Loss 0.036034   Top1 98.730469   Top5 100.000000   BatchTime 0.543602   LR 0.000002   
2022-11-25 07:49:50,427 - INFO  - Training [67][   40/  196]   Loss 0.034599   Top1 98.828125   Top5 100.000000   BatchTime 0.483892   LR 0.000002   
2022-11-25 07:49:58,527 - INFO  - Training [67][   60/  196]   Loss 0.034749   Top1 98.776042   Top5 100.000000   BatchTime 0.457582   LR 0.000001   
2022-11-25 07:50:06,282 - INFO  - Training [67][   80/  196]   Loss 0.035909   Top1 98.745117   Top5 100.000000   BatchTime 0.440131   LR 0.000001   
2022-11-25 07:50:13,341 - INFO  - Training [67][  100/  196]   Loss 0.035747   Top1 98.734375   Top5 99.996094   BatchTime 0.422691   LR 0.000001   
2022-11-25 07:50:21,484 - INFO  - Training [67][  120/  196]   Loss 0.036190   Top1 98.701172   Top5 99.996745   BatchTime 0.420095   LR 0.000001   
2022-11-25 07:50:30,628 - INFO  - Training [67][  140/  196]   Loss 0.035968   Top1 98.724888   Top5 99.997210   BatchTime 0.425398   LR 0.000001   
2022-11-25 07:50:39,928 - INFO  - Training [67][  160/  196]   Loss 0.036637   Top1 98.715820   Top5 99.997559   BatchTime 0.430349   LR 0.000001   
2022-11-25 07:50:47,330 - INFO  - Training [67][  180/  196]   Loss 0.036419   Top1 98.717448   Top5 99.997830   BatchTime 0.423652   LR 0.000001   
2022-11-25 07:50:53,270 - INFO  - ==> Top1: 98.718    Top5: 99.998    Loss: 0.037

2022-11-25 07:50:53,460 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:50:54,993 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:50:58,655 - INFO  - Validation [67][   20/   40]   Loss 0.422731   Top1 90.351562   Top5 99.687500   BatchTime 0.183031   
2022-11-25 07:50:59,747 - INFO  - Validation [67][   40/   40]   Loss 0.417403   Top1 90.220000   Top5 99.730000   BatchTime 0.118822   
2022-11-25 07:51:00,043 - INFO  - ==> Top1: 90.220    Top5: 99.730    Loss: 0.417

2022-11-25 07:51:00,043 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:51:00,043 - INFO  - Scoreboard best 1 ==> Epoch [67][Top1: 90.220   Top5: 99.730]
2022-11-25 07:51:00,043 - INFO  - Scoreboard best 2 ==> Epoch [60][Top1: 90.170   Top5: 99.770]
2022-11-25 07:51:00,043 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 90.160   Top5: 99.690]
2022-11-25 07:51:05,205 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 07:51:05,208 - INFO  - >>>>>> Epoch  68
2022-11-25 07:51:05,211 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:51:15,644 - INFO  - Training [68][   20/  196]   Loss 0.032900   Top1 98.945312   Top5 100.000000   BatchTime 0.521527   LR 0.000001   
2022-11-25 07:51:24,560 - INFO  - Training [68][   40/  196]   Loss 0.035345   Top1 98.808594   Top5 100.000000   BatchTime 0.483663   LR 0.000001   
2022-11-25 07:51:33,164 - INFO  - Training [68][   60/  196]   Loss 0.034153   Top1 98.847656   Top5 100.000000   BatchTime 0.465843   LR 0.000001   
2022-11-25 07:51:41,558 - INFO  - Training [68][   80/  196]   Loss 0.033558   Top1 98.862305   Top5 100.000000   BatchTime 0.454307   LR 0.000000   
2022-11-25 07:51:48,808 - INFO  - Training [68][  100/  196]   Loss 0.032933   Top1 98.859375   Top5 100.000000   BatchTime 0.435947   LR 0.000000   
2022-11-25 07:51:57,543 - INFO  - Training [68][  120/  196]   Loss 0.033986   Top1 98.844401   Top5 100.000000   BatchTime 0.436076   LR 0.000000   
2022-11-25 07:52:06,137 - INFO  - Training [68][  140/  196]   Loss 0.034188   Top1 98.830915   Top5 100.000000   BatchTime 0.435166   LR 0.000000   
2022-11-25 07:52:14,857 - INFO  - Training [68][  160/  196]   Loss 0.033594   Top1 98.850098   Top5 100.000000   BatchTime 0.435267   LR 0.000000   
2022-11-25 07:52:23,781 - INFO  - Training [68][  180/  196]   Loss 0.033136   Top1 98.873698   Top5 100.000000   BatchTime 0.436483   LR 0.000000   
2022-11-25 07:52:30,181 - INFO  - ==> Top1: 98.858    Top5: 99.998    Loss: 0.034

2022-11-25 07:52:30,538 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:52:33,261 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:52:37,384 - INFO  - Validation [68][   20/   40]   Loss 0.428957   Top1 90.390625   Top5 99.687500   BatchTime 0.206051   
2022-11-25 07:52:38,423 - INFO  - Validation [68][   40/   40]   Loss 0.422713   Top1 90.170000   Top5 99.770000   BatchTime 0.128996   
2022-11-25 07:52:38,763 - INFO  - ==> Top1: 90.170    Top5: 99.770    Loss: 0.423

2022-11-25 07:52:38,763 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:52:38,763 - INFO  - Scoreboard best 1 ==> Epoch [67][Top1: 90.220   Top5: 99.730]
2022-11-25 07:52:38,764 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.170   Top5: 99.770]
2022-11-25 07:52:38,764 - INFO  - Scoreboard best 3 ==> Epoch [60][Top1: 90.170   Top5: 99.770]
2022-11-25 07:52:39,178 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar

2022-11-25 07:52:39,179 - INFO  - >>>>>> Epoch  69
2022-11-25 07:52:39,181 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 07:52:50,077 - INFO  - Training [69][   20/  196]   Loss 0.028231   Top1 99.023438   Top5 100.000000   BatchTime 0.544647   LR 0.000000   
2022-11-25 07:52:58,691 - INFO  - Training [69][   40/  196]   Loss 0.029986   Top1 98.974609   Top5 100.000000   BatchTime 0.487677   LR 0.000000   
2022-11-25 07:53:07,296 - INFO  - Training [69][   60/  196]   Loss 0.030728   Top1 98.945312   Top5 100.000000   BatchTime 0.468535   LR 0.000000   
2022-11-25 07:53:15,385 - INFO  - Training [69][   80/  196]   Loss 0.032659   Top1 98.886719   Top5 99.995117   BatchTime 0.452514   LR 0.000000   
2022-11-25 07:53:22,972 - INFO  - Training [69][  100/  196]   Loss 0.032726   Top1 98.859375   Top5 99.996094   BatchTime 0.437878   LR 0.000000   
2022-11-25 07:53:31,721 - INFO  - Training [69][  120/  196]   Loss 0.033476   Top1 98.824870   Top5 99.996745   BatchTime 0.437806   LR 0.000000   
2022-11-25 07:53:40,596 - INFO  - Training [69][  140/  196]   Loss 0.033697   Top1 98.808594   Top5 99.997210   BatchTime 0.438652   LR 0.000000   
2022-11-25 07:53:49,444 - INFO  - Training [69][  160/  196]   Loss 0.033822   Top1 98.813477   Top5 99.997559   BatchTime 0.439121   LR 0.000000   
2022-11-25 07:53:58,359 - INFO  - Training [69][  180/  196]   Loss 0.033584   Top1 98.817274   Top5 99.997830   BatchTime 0.439857   LR 0.000000   
2022-11-25 07:54:05,150 - INFO  - ==> Top1: 98.816    Top5: 99.998    Loss: 0.034

2022-11-25 07:54:05,343 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 07:54:07,217 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:54:10,885 - INFO  - Validation [69][   20/   40]   Loss 0.425921   Top1 90.527344   Top5 99.765625   BatchTime 0.183276   
2022-11-25 07:54:12,138 - INFO  - Validation [69][   40/   40]   Loss 0.418487   Top1 90.270000   Top5 99.770000   BatchTime 0.122967   
2022-11-25 07:54:12,427 - INFO  - ==> Top1: 90.270    Top5: 99.770    Loss: 0.418

2022-11-25 07:54:12,427 - INFO  - ==> Sparsity : 0.739

2022-11-25 07:54:12,427 - INFO  - Scoreboard best 1 ==> Epoch [69][Top1: 90.270   Top5: 99.770]
2022-11-25 07:54:12,428 - INFO  - Scoreboard best 2 ==> Epoch [67][Top1: 90.220   Top5: 99.730]
2022-11-25 07:54:12,428 - INFO  - Scoreboard best 3 ==> Epoch [68][Top1: 90.170   Top5: 99.770]
2022-11-25 07:54:18,107 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-051836/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 07:54:18,110 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 07:54:18,110 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 07:54:21,183 - INFO  - Validation [   20/   40]   Loss 0.425921   Top1 90.527344   Top5 99.765625   BatchTime 0.153557   
2022-11-25 07:54:22,263 - INFO  - Validation [   40/   40]   Loss 0.418487   Top1 90.270000   Top5 99.770000   BatchTime 0.103776   
2022-11-25 07:54:22,446 - INFO  - ==> Top1: 90.270    Top5: 99.770    Loss: 0.418

2022-11-25 07:54:22,446 - INFO  - ==> Sparsity : 0.000

2022-11-25 07:54:22,447 - INFO  - Program completed sucessfully ... exiting ...
