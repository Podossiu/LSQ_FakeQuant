2022-11-25 10:28:22,291 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-102822/88_20221125-102822.log
2022-11-25 10:28:26,569 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-25 10:28:28,365 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-25 10:28:29,090 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
2022-11-25 10:28:29,090 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005

2022-11-25 10:28:29,340 - INFO  - >>>>>> Epoch   0
2022-11-25 10:28:29,342 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:28:38,474 - INFO  - Training [0][   20/  196]   Loss 1.611376   Top1 53.398438   Top5 89.160156   BatchTime 0.456485   LR 0.004999   
2022-11-25 10:28:46,722 - INFO  - Training [0][   40/  196]   Loss 1.551107   Top1 52.568359   Top5 89.375000   BatchTime 0.434441   LR 0.004995   
2022-11-25 10:28:55,146 - INFO  - Training [0][   60/  196]   Loss 1.453531   Top1 54.895833   Top5 90.735677   BatchTime 0.430017   LR 0.004989   
2022-11-25 10:29:03,432 - INFO  - Training [0][   80/  196]   Loss 1.387360   Top1 56.997070   Top5 91.538086   BatchTime 0.426084   LR 0.004980   
2022-11-25 10:29:11,769 - INFO  - Training [0][  100/  196]   Loss 1.332664   Top1 58.406250   Top5 92.183594   BatchTime 0.424245   LR 0.004968   
2022-11-25 10:29:18,941 - INFO  - Training [0][  120/  196]   Loss 1.287025   Top1 59.853516   Top5 92.679036   BatchTime 0.413300   LR 0.004954   
2022-11-25 10:29:24,968 - INFO  - Training [0][  140/  196]   Loss 1.255807   Top1 60.756138   Top5 92.999442   BatchTime 0.397308   LR 0.004938   
2022-11-25 10:29:32,533 - INFO  - Training [0][  160/  196]   Loss 1.233939   Top1 61.462402   Top5 93.259277   BatchTime 0.394922   LR 0.004919   
2022-11-25 10:29:41,021 - INFO  - Training [0][  180/  196]   Loss 1.211923   Top1 62.131076   Top5 93.452691   BatchTime 0.398196   LR 0.004897   
2022-11-25 10:29:48,025 - INFO  - ==> Top1: 62.668    Top5: 93.596    Loss: 1.194

2022-11-25 10:29:48,263 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:29:49,605 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:29:51,785 - INFO  - Validation [0][   20/   40]   Loss 0.711598   Top1 77.070312   Top5 98.066406   BatchTime 0.108951   
2022-11-25 10:29:52,856 - INFO  - Validation [0][   40/   40]   Loss 0.716208   Top1 76.540000   Top5 97.960000   BatchTime 0.081256   
2022-11-25 10:29:53,046 - INFO  - ==> Top1: 76.540    Top5: 97.960    Loss: 0.716

2022-11-25 10:29:53,046 - INFO  - ==> Sparsity : 0.353

2022-11-25 10:29:53,047 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 76.540   Top5: 97.960]
2022-11-25 10:29:58,246 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-102822/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-102822/_best.pth.tar
save quantized models...
2022-11-25 10:29:58,248 - INFO  - >>>>>> Epoch   1
2022-11-25 10:29:58,250 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:30:06,793 - INFO  - Training [1][   20/  196]   Loss 0.998995   Top1 67.929688   Top5 95.253906   BatchTime 0.427018   LR 0.004853   
2022-11-25 10:30:13,867 - INFO  - Training [1][   40/  196]   Loss 0.995723   Top1 68.925781   Top5 95.400391   BatchTime 0.390363   LR 0.004825   
2022-11-25 10:30:21,224 - INFO  - Training [1][   60/  196]   Loss 0.986206   Top1 69.082031   Top5 95.546875   BatchTime 0.382846   LR 0.004794   
2022-11-25 10:30:28,354 - INFO  - Training [1][   80/  196]   Loss 0.980940   Top1 69.208984   Top5 95.678711   BatchTime 0.376264   LR 0.004761   
2022-11-25 10:30:35,512 - INFO  - Training [1][  100/  196]   Loss 0.964892   Top1 69.742188   Top5 95.746094   BatchTime 0.372588   LR 0.004725   
2022-11-25 10:30:41,728 - INFO  - Training [1][  120/  196]   Loss 0.952230   Top1 70.159505   Top5 95.947266   BatchTime 0.362290   LR 0.004687   
2022-11-25 10:30:49,017 - INFO  - Training [1][  140/  196]   Loss 0.943636   Top1 70.496652   Top5 96.074219   BatchTime 0.362597   LR 0.004647   
2022-11-25 10:30:56,598 - INFO  - Training [1][  160/  196]   Loss 0.937684   Top1 70.646973   Top5 96.149902   BatchTime 0.364655   LR 0.004605   
2022-11-25 10:31:04,202 - INFO  - Training [1][  180/  196]   Loss 0.926140   Top1 71.069878   Top5 96.206597   BatchTime 0.366382   LR 0.004560   
2022-11-25 10:31:10,178 - INFO  - ==> Top1: 71.224    Top5: 96.198    Loss: 0.922

2022-11-25 10:31:10,434 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:31:11,885 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:31:14,105 - INFO  - Validation [1][   20/   40]   Loss 0.721811   Top1 76.875000   Top5 98.222656   BatchTime 0.110859   
2022-11-25 10:31:15,272 - INFO  - Validation [1][   40/   40]   Loss 0.724747   Top1 76.860000   Top5 98.220000   BatchTime 0.084636   
2022-11-25 10:31:15,482 - INFO  - ==> Top1: 76.860    Top5: 98.220    Loss: 0.725

2022-11-25 10:31:15,482 - INFO  - ==> Sparsity : 0.385

2022-11-25 10:31:15,483 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.860   Top5: 98.220]
2022-11-25 10:31:15,483 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 76.540   Top5: 97.960]
2022-11-25 10:31:21,149 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-102822/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-102822/_best.pth.tar
save quantized models...
2022-11-25 10:31:21,151 - INFO  - >>>>>> Epoch   2
2022-11-25 10:31:21,153 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:31:29,970 - INFO  - Training [2][   20/  196]   Loss 0.893217   Top1 71.699219   Top5 95.937500   BatchTime 0.440734   LR 0.004477   
2022-11-25 10:31:37,235 - INFO  - Training [2][   40/  196]   Loss 0.887082   Top1 72.519531   Top5 95.937500   BatchTime 0.401989   LR 0.004426   
2022-11-25 10:31:44,573 - INFO  - Training [2][   60/  196]   Loss 0.894165   Top1 72.226562   Top5 95.944010   BatchTime 0.390287   LR 0.004374   
2022-11-25 10:31:51,632 - INFO  - Training [2][   80/  196]   Loss 0.893639   Top1 72.080078   Top5 96.074219   BatchTime 0.380957   LR 0.004320   
2022-11-25 10:31:57,935 - INFO  - Training [2][  100/  196]   Loss 0.880479   Top1 72.468750   Top5 96.230469   BatchTime 0.367785   LR 0.004264   
2022-11-25 10:32:05,092 - INFO  - Training [2][  120/  196]   Loss 0.869335   Top1 72.945964   Top5 96.396484   BatchTime 0.366128   LR 0.004206   
2022-11-25 10:32:12,843 - INFO  - Training [2][  140/  196]   Loss 0.877715   Top1 72.564174   Top5 96.286272   BatchTime 0.369188   LR 0.004146   
2022-11-25 10:32:20,160 - INFO  - Training [2][  160/  196]   Loss 1.068692   Top1 66.157227   Top5 92.797852   BatchTime 0.368774   LR 0.004085   
2022-11-25 10:32:27,613 - INFO  - Training [2][  180/  196]   Loss 1.198591   Top1 60.659722   Top5 90.338542   BatchTime 0.369201   LR 0.004022   
2022-11-25 10:32:33,517 - INFO  - ==> Top1: 57.420    Top5: 89.018    Loss: 1.276

2022-11-25 10:32:33,787 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:32:35,161 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:32:37,647 - INFO  - Validation [2][   20/   40]   Loss 2.248263   Top1 17.656250   Top5 76.875000   BatchTime 0.124205   
2022-11-25 10:32:38,782 - INFO  - Validation [2][   40/   40]   Loss 2.246361   Top1 17.800000   Top5 77.040000   BatchTime 0.090492   
2022-11-25 10:32:38,989 - INFO  - ==> Top1: 17.800    Top5: 77.040    Loss: 2.246

2022-11-25 10:32:38,989 - INFO  - ==> Sparsity : 0.394

2022-11-25 10:32:38,990 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.860   Top5: 98.220]
2022-11-25 10:32:38,990 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 76.540   Top5: 97.960]
2022-11-25 10:32:38,990 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 17.800   Top5: 77.040]
2022-11-25 10:32:39,122 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-102822/_checkpoint.pth.tar

2022-11-25 10:32:39,123 - INFO  - >>>>>> Epoch   3
2022-11-25 10:32:39,125 - INFO  - Training: 50000 samples (256 per mini-batch)
