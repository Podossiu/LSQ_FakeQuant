2022-10-28 07:37:38,421 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-073738/88_20221028-073738.log
2022-10-28 07:37:40,175 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 07:37:40,209 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-28 07:37:40,373 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 07:37:40,373 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 07:37:41,622 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 07:37:41,622 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 07:37:44,572 - INFO  - Validation [   20/   40]   Loss 3047.717822   Top1 12.753906   Top5 57.070312   BatchTime 0.145362   
2022-10-28 07:37:46,167 - INFO  - Validation [   40/   40]   Loss 3031.409704   Top1 12.670000   Top5 56.460000   BatchTime 0.112547   
2022-10-28 07:37:46,224 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-28 07:37:46,225 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 07:37:46,225 - INFO  - >>>>>> Epoch   0
2022-10-28 07:37:46,225 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 07:37:48,451 - INFO  - Training [0][   20/  196]   Loss 1.146936   Top1 70.996094   Top5 97.089844   BatchTime 0.111293   LR 0.001000   
2022-10-28 07:37:50,148 - INFO  - Training [0][   40/  196]   Loss 0.881796   Top1 76.005859   Top5 97.900391   BatchTime 0.098069   LR 0.001000   
2022-10-28 07:37:51,843 - INFO  - Training [0][   60/  196]   Loss 0.753579   Top1 78.756510   Top5 98.346354   BatchTime 0.093622   LR 0.001000   
2022-10-28 07:37:53,534 - INFO  - Training [0][   80/  196]   Loss 0.670122   Top1 80.502930   Top5 98.676758   BatchTime 0.091361   LR 0.001000   
2022-10-28 07:37:55,235 - INFO  - Training [0][  100/  196]   Loss 0.620599   Top1 81.628906   Top5 98.812500   BatchTime 0.090097   LR 0.001000   
2022-10-28 07:37:56,926 - INFO  - Training [0][  120/  196]   Loss 0.578948   Top1 82.591146   Top5 98.955078   BatchTime 0.089171   LR 0.001000   
2022-10-28 07:37:58,620 - INFO  - Training [0][  140/  196]   Loss 0.548420   Top1 83.362165   Top5 99.048549   BatchTime 0.088531   LR 0.001000   
2022-10-28 07:38:00,317 - INFO  - Training [0][  160/  196]   Loss 0.522957   Top1 83.913574   Top5 99.133301   BatchTime 0.088070   LR 0.001000   
2022-10-28 07:38:01,988 - INFO  - Training [0][  180/  196]   Loss 0.501974   Top1 84.411892   Top5 99.186198   BatchTime 0.087569   LR 0.001000   
2022-10-28 07:38:03,355 - INFO  - ==> Top1: 84.840    Top5: 99.220    Loss: 0.486

2022-10-28 07:38:03,443 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 07:38:05,050 - INFO  - Validation [0][   20/   40]   Loss 0.426943   Top1 86.894531   Top5 99.453125   BatchTime 0.080342   
2022-10-28 07:38:06,122 - INFO  - Validation [0][   40/   40]   Loss 0.418694   Top1 86.790000   Top5 99.480000   BatchTime 0.066978   
2022-10-28 07:38:06,193 - INFO  - ==> Top1: 86.790    Top5: 99.480    Loss: 0.419

2022-10-28 07:38:06,193 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 07:38:07,900 - INFO  - Validation [0][   20/   40]   Loss 2.491025   Top1 10.000000   Top5 49.453125   BatchTime 0.085305   
2022-10-28 07:38:08,837 - INFO  - Validation [0][   40/   40]   Loss 2.489744   Top1 10.000000   Top5 49.830000   BatchTime 0.066076   
2022-10-28 07:38:08,915 - INFO  - ==> Top1: 10.000    Top5: 49.830    Loss: 2.490

2022-10-28 07:38:08,915 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 07:38:08,915 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 10.000   Top5: 49.830]
2022-10-28 07:38:08,950 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221028-073738/88_checkpoint.pth.tar

2022-10-28 07:38:08,950 - INFO  - >>>>>> Epoch   1
2022-10-28 07:38:08,950 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 07:38:11,243 - INFO  - Training [1][   20/  196]   Loss 0.298642   Top1 89.960938   Top5 99.648438   BatchTime 0.114613   LR 0.001000   
2022-10-28 07:38:12,936 - INFO  - Training [1][   40/  196]   Loss 0.288387   Top1 90.117188   Top5 99.746094   BatchTime 0.099625   LR 0.001000   
2022-10-28 07:38:14,633 - INFO  - Training [1][   60/  196]   Loss 0.291237   Top1 90.019531   Top5 99.726562   BatchTime 0.094700   LR 0.001000   
2022-10-28 07:38:16,334 - INFO  - Training [1][   80/  196]   Loss 0.287515   Top1 90.122070   Top5 99.755859   BatchTime 0.092287   LR 0.001000   
2022-10-28 07:38:18,052 - INFO  - Training [1][  100/  196]   Loss 0.285508   Top1 90.179688   Top5 99.785156   BatchTime 0.091010   LR 0.001000   
2022-10-28 07:38:19,755 - INFO  - Training [1][  120/  196]   Loss 0.283498   Top1 90.240885   Top5 99.781901   BatchTime 0.090029   LR 0.001000   
2022-10-28 07:38:21,456 - INFO  - Training [1][  140/  196]   Loss 0.282239   Top1 90.195312   Top5 99.779576   BatchTime 0.089323   LR 0.001000   
2022-10-28 07:38:23,159 - INFO  - Training [1][  160/  196]   Loss 0.278410   Top1 90.327148   Top5 99.790039   BatchTime 0.088796   LR 0.001000   
2022-10-28 07:38:24,841 - INFO  - Training [1][  180/  196]   Loss 0.278685   Top1 90.321181   Top5 99.785156   BatchTime 0.088279   LR 0.001000   
2022-10-28 07:38:26,221 - INFO  - ==> Top1: 90.354    Top5: 99.788    Loss: 0.278

2022-10-28 07:38:26,300 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 07:38:27,943 - INFO  - Validation [1][   20/   40]   Loss 0.380409   Top1 88.222656   Top5 99.492188   BatchTime 0.082137   
2022-10-28 07:38:29,023 - INFO  - Validation [1][   40/   40]   Loss 0.373060   Top1 88.310000   Top5 99.530000   BatchTime 0.068074   
2022-10-28 07:38:29,103 - INFO  - ==> Top1: 88.310    Top5: 99.530    Loss: 0.373

2022-10-28 07:38:29,103 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 07:38:30,774 - INFO  - Validation [1][   20/   40]   Loss 2.493264   Top1 13.515625   Top5 50.390625   BatchTime 0.083503   
2022-10-28 07:38:31,706 - INFO  - Validation [1][   40/   40]   Loss 2.491745   Top1 13.620000   Top5 50.960000   BatchTime 0.065051   
2022-10-28 07:38:31,786 - INFO  - ==> Top1: 13.620    Top5: 50.960    Loss: 2.492

2022-10-28 07:38:31,786 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 13.620   Top5: 50.960]
2022-10-28 07:38:31,787 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 07:38:31,787 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 10.000   Top5: 49.830]
2022-10-28 07:38:33,531 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221028-073738/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221028-073738/88_best.pth.tar
save quantized models...
2022-10-28 07:38:33,531 - INFO  - >>>>>> Epoch   2
2022-10-28 07:38:33,532 - INFO  - Training: 50000 samples (256 per mini-batch)
