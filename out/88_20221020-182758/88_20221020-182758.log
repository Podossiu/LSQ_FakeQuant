2022-10-20 18:27:58,855 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221020-182758/88_20221020-182758.log
2022-10-20 18:28:00,040 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-20 18:28:00,073 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-20 18:28:00,076 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-20 18:28:00,076 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-20 18:28:01,240 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-20 18:28:01,240 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:28:02,094 - INFO  - Validation [   20/   40]   Loss 3047.717615   Top1 12.753906   Top5 57.070312   BatchTime 0.042667   
2022-10-20 18:28:02,236 - INFO  - Validation [   40/   40]   Loss 3031.409504   Top1 12.670000   Top5 56.460000   BatchTime 0.024878   
2022-10-20 18:28:02,295 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-20 18:28:02,295 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-20 18:28:02,295 - INFO  - >>>>>> Epoch   0
2022-10-20 18:28:02,295 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:28:03,343 - INFO  - Training [0][   20/  196]   Loss 1.113433   Top1 69.980469   Top5 97.285156   BatchTime 0.052347   LR 0.001000   
2022-10-20 18:28:03,855 - INFO  - Training [0][   40/  196]   Loss 0.851823   Top1 75.673828   Top5 98.242188   BatchTime 0.038979   LR 0.001000   
2022-10-20 18:28:04,368 - INFO  - Training [0][   60/  196]   Loss 0.727292   Top1 78.776042   Top5 98.619792   BatchTime 0.034539   LR 0.001000   
2022-10-20 18:28:04,884 - INFO  - Training [0][   80/  196]   Loss 0.654475   Top1 80.576172   Top5 98.818359   BatchTime 0.032349   LR 0.001000   
2022-10-20 18:28:05,396 - INFO  - Training [0][  100/  196]   Loss 0.604448   Top1 81.718750   Top5 98.968750   BatchTime 0.031006   LR 0.001000   
2022-10-20 18:28:05,909 - INFO  - Training [0][  120/  196]   Loss 0.567436   Top1 82.578125   Top5 99.075521   BatchTime 0.030113   LR 0.001000   
2022-10-20 18:28:06,424 - INFO  - Training [0][  140/  196]   Loss 0.536665   Top1 83.337054   Top5 99.146205   BatchTime 0.029486   LR 0.001000   
2022-10-20 18:28:06,939 - INFO  - Training [0][  160/  196]   Loss 0.509847   Top1 84.060059   Top5 99.218750   BatchTime 0.029021   LR 0.001000   
2022-10-20 18:28:07,451 - INFO  - Training [0][  180/  196]   Loss 0.487667   Top1 84.663628   Top5 99.273003   BatchTime 0.028638   LR 0.001000   
2022-10-20 18:28:07,924 - INFO  - ==> Top1: 84.978    Top5: 99.298    Loss: 0.475

2022-10-20 18:28:07,948 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:28:08,573 - INFO  - Validation [0][   20/   40]   Loss 0.437156   Top1 86.718750   Top5 99.394531   BatchTime 0.031263   
2022-10-20 18:28:08,702 - INFO  - Validation [0][   40/   40]   Loss 0.429060   Top1 86.650000   Top5 99.490000   BatchTime 0.018839   
2022-10-20 18:28:08,766 - INFO  - ==> Top1: 86.650    Top5: 99.490    Loss: 0.429

2022-10-20 18:28:08,766 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:28:11,609 - INFO  - Validation [0][   20/   40]   Loss 0.437156   Top1 86.718750   Top5 99.394531   BatchTime 0.142132   
2022-10-20 18:28:13,729 - INFO  - Validation [0][   40/   40]   Loss 0.429060   Top1 86.650000   Top5 99.490000   BatchTime 0.124077   
2022-10-20 18:28:13,802 - INFO  - ==> Top1: 86.650    Top5: 99.490    Loss: 0.429

2022-10-20 18:28:13,802 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 86.650   Top5: 99.490]
2022-10-20 18:28:13,802 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-20 18:28:15,068 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182758/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-182758/88_best.pth.tar
save quantized models...
2022-10-20 18:28:15,068 - INFO  - >>>>>> Epoch   1
2022-10-20 18:28:15,069 - INFO  - Training: 50000 samples (256 per mini-batch)
