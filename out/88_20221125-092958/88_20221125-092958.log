2022-11-25 09:29:58,734 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/88_20221125-092958.log
2022-11-25 09:30:03,048 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-25 09:30:04,907 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-25 09:30:05,875 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
2022-11-25 09:30:05,875 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005

2022-11-25 09:30:05,913 - INFO  - >>>>>> Epoch   0
2022-11-25 09:30:05,915 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:30:13,451 - INFO  - Training [0][   20/  196]   Loss 1.598686   Top1 53.750000   Top5 88.808594   BatchTime 0.376707   LR 0.004999   
2022-11-25 09:30:19,192 - INFO  - Training [0][   40/  196]   Loss 1.617351   Top1 49.111328   Top5 87.880859   BatchTime 0.331867   LR 0.004995   
2022-11-25 09:30:25,641 - INFO  - Training [0][   60/  196]   Loss 1.559282   Top1 49.863281   Top5 88.580729   BatchTime 0.328731   LR 0.004989   
2022-11-25 09:30:31,680 - INFO  - Training [0][   80/  196]   Loss 1.510892   Top1 50.971680   Top5 89.433594   BatchTime 0.322031   LR 0.004980   
2022-11-25 09:30:37,490 - INFO  - Training [0][  100/  196]   Loss 1.460392   Top1 52.355469   Top5 90.203125   BatchTime 0.315730   LR 0.004968   
2022-11-25 09:30:43,762 - INFO  - Training [0][  120/  196]   Loss 1.420127   Top1 53.551432   Top5 90.716146   BatchTime 0.315369   LR 0.004954   
2022-11-25 09:30:49,718 - INFO  - Training [0][  140/  196]   Loss 1.388969   Top1 54.458705   Top5 91.146763   BatchTime 0.312863   LR 0.004938   
2022-11-25 09:30:58,419 - INFO  - Training [0][  160/  196]   Loss 1.367151   Top1 55.119629   Top5 91.416016   BatchTime 0.328130   LR 0.004919   
2022-11-25 09:31:07,087 - INFO  - Training [0][  180/  196]   Loss 1.350450   Top1 55.562066   Top5 91.401910   BatchTime 0.339828   LR 0.004897   
2022-11-25 09:31:14,054 - INFO  - ==> Top1: 56.262    Top5: 91.642    Loss: 1.330

2022-11-25 09:31:14,270 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:31:15,539 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:31:18,599 - INFO  - Validation [0][   20/   40]   Loss 0.928237   Top1 70.019531   Top5 97.324219   BatchTime 0.152945   
2022-11-25 09:31:20,108 - INFO  - Validation [0][   40/   40]   Loss 0.924852   Top1 70.330000   Top5 97.390000   BatchTime 0.114191   
2022-11-25 09:31:20,596 - INFO  - ==> Top1: 70.330    Top5: 97.390    Loss: 0.925

2022-11-25 09:31:20,596 - INFO  - ==> Sparsity : 0.198

2022-11-25 09:31:20,598 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 70.330   Top5: 97.390]
2022-11-25 09:31:26,987 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 09:31:26,989 - INFO  - >>>>>> Epoch   1
2022-11-25 09:31:26,992 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:31:35,515 - INFO  - Training [1][   20/  196]   Loss 1.136294   Top1 62.734375   Top5 93.671875   BatchTime 0.426003   LR 0.004853   
2022-11-25 09:31:42,819 - INFO  - Training [1][   40/  196]   Loss 1.122122   Top1 63.085938   Top5 93.818359   BatchTime 0.395598   LR 0.004825   
2022-11-25 09:31:50,353 - INFO  - Training [1][   60/  196]   Loss 1.120949   Top1 63.085938   Top5 93.886719   BatchTime 0.389300   LR 0.004794   
2022-11-25 09:31:57,544 - INFO  - Training [1][   80/  196]   Loss 1.106637   Top1 63.569336   Top5 94.091797   BatchTime 0.381866   LR 0.004761   
2022-11-25 09:32:04,214 - INFO  - Training [1][  100/  196]   Loss 1.093952   Top1 63.976562   Top5 94.300781   BatchTime 0.372193   LR 0.004725   
2022-11-25 09:32:10,399 - INFO  - Training [1][  120/  196]   Loss 1.082156   Top1 64.430339   Top5 94.475911   BatchTime 0.361694   LR 0.004687   
2022-11-25 09:32:16,405 - INFO  - Training [1][  140/  196]   Loss 1.068323   Top1 64.902344   Top5 94.704241   BatchTime 0.352923   LR 0.004647   
2022-11-25 09:32:24,084 - INFO  - Training [1][  160/  196]   Loss 1.061843   Top1 65.053711   Top5 94.821777   BatchTime 0.356803   LR 0.004605   
2022-11-25 09:32:31,477 - INFO  - Training [1][  180/  196]   Loss 1.050016   Top1 65.373264   Top5 94.904514   BatchTime 0.358230   LR 0.004560   
2022-11-25 09:32:37,370 - INFO  - ==> Top1: 65.564    Top5: 94.916    Loss: 1.043

2022-11-25 09:32:37,649 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:32:38,991 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:32:41,319 - INFO  - Validation [1][   20/   40]   Loss 1.434128   Top1 55.351562   Top5 92.656250   BatchTime 0.116341   
2022-11-25 09:32:42,398 - INFO  - Validation [1][   40/   40]   Loss 1.458105   Top1 55.270000   Top5 92.400000   BatchTime 0.085148   
2022-11-25 09:32:42,612 - INFO  - ==> Top1: 55.270    Top5: 92.400    Loss: 1.458

2022-11-25 09:32:42,612 - INFO  - ==> Sparsity : 0.317

2022-11-25 09:32:42,612 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 70.330   Top5: 97.390]
2022-11-25 09:32:42,613 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 55.270   Top5: 92.400]
2022-11-25 09:32:42,769 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:32:42,770 - INFO  - >>>>>> Epoch   2
2022-11-25 09:32:42,772 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:32:51,852 - INFO  - Training [2][   20/  196]   Loss 0.977011   Top1 67.890625   Top5 94.804688   BatchTime 0.453865   LR 0.004477   
2022-11-25 09:32:59,332 - INFO  - Training [2][   40/  196]   Loss 0.985617   Top1 67.607422   Top5 95.068359   BatchTime 0.413919   LR 0.004426   
2022-11-25 09:33:06,754 - INFO  - Training [2][   60/  196]   Loss 0.967201   Top1 68.085938   Top5 95.371094   BatchTime 0.399649   LR 0.004374   
2022-11-25 09:33:14,386 - INFO  - Training [2][   80/  196]   Loss 0.960701   Top1 68.457031   Top5 95.590820   BatchTime 0.395136   LR 0.004320   
2022-11-25 09:33:22,416 - INFO  - Training [2][  100/  196]   Loss 0.949220   Top1 68.761719   Top5 95.734375   BatchTime 0.396407   LR 0.004264   
2022-11-25 09:33:28,903 - INFO  - Training [2][  120/  196]   Loss 0.936864   Top1 69.205729   Top5 95.852865   BatchTime 0.384400   LR 0.004206   
2022-11-25 09:33:34,880 - INFO  - Training [2][  140/  196]   Loss 0.933415   Top1 69.218750   Top5 95.943080   BatchTime 0.372179   LR 0.004146   
2022-11-25 09:33:41,446 - INFO  - Training [2][  160/  196]   Loss 0.934604   Top1 69.191895   Top5 95.947266   BatchTime 0.366690   LR 0.004085   
2022-11-25 09:33:49,029 - INFO  - Training [2][  180/  196]   Loss 0.931072   Top1 69.320747   Top5 95.930990   BatchTime 0.368073   LR 0.004022   
2022-11-25 09:33:55,098 - INFO  - ==> Top1: 69.422    Top5: 95.984    Loss: 0.927

2022-11-25 09:33:55,546 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:33:57,270 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:33:59,892 - INFO  - Validation [2][   20/   40]   Loss 0.649223   Top1 77.539062   Top5 98.671875   BatchTime 0.130984   
2022-11-25 09:34:01,012 - INFO  - Validation [2][   40/   40]   Loss 0.641239   Top1 77.720000   Top5 98.770000   BatchTime 0.093499   
2022-11-25 09:34:01,213 - INFO  - ==> Top1: 77.720    Top5: 98.770    Loss: 0.641

2022-11-25 09:34:01,214 - INFO  - ==> Sparsity : 0.271

2022-11-25 09:34:01,214 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 77.720   Top5: 98.770]
2022-11-25 09:34:01,214 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.330   Top5: 97.390]
2022-11-25 09:34:01,214 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 55.270   Top5: 92.400]
2022-11-25 09:34:06,639 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 09:34:06,644 - INFO  - >>>>>> Epoch   3
2022-11-25 09:34:06,647 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:34:15,465 - INFO  - Training [3][   20/  196]   Loss 0.899869   Top1 69.824219   Top5 95.761719   BatchTime 0.440695   LR 0.003907   
2022-11-25 09:34:23,186 - INFO  - Training [3][   40/  196]   Loss 0.890098   Top1 70.693359   Top5 95.810547   BatchTime 0.413371   LR 0.003840   
2022-11-25 09:34:30,452 - INFO  - Training [3][   60/  196]   Loss 0.878094   Top1 71.282552   Top5 95.970052   BatchTime 0.396689   LR 0.003771   
2022-11-25 09:34:37,626 - INFO  - Training [3][   80/  196]   Loss 0.873506   Top1 71.420898   Top5 96.108398   BatchTime 0.387183   LR 0.003701   
2022-11-25 09:34:44,950 - INFO  - Training [3][  100/  196]   Loss 0.866945   Top1 71.683594   Top5 96.218750   BatchTime 0.382987   LR 0.003630   
2022-11-25 09:34:51,440 - INFO  - Training [3][  120/  196]   Loss 0.857317   Top1 71.998698   Top5 96.344401   BatchTime 0.373244   LR 0.003558   
2022-11-25 09:34:58,552 - INFO  - Training [3][  140/  196]   Loss 0.855657   Top1 71.992188   Top5 96.422991   BatchTime 0.370719   LR 0.003484   
2022-11-25 09:35:05,954 - INFO  - Training [3][  160/  196]   Loss 0.858279   Top1 71.928711   Top5 96.425781   BatchTime 0.370639   LR 0.003410   
2022-11-25 09:35:13,456 - INFO  - Training [3][  180/  196]   Loss 0.855724   Top1 72.016059   Top5 96.388889   BatchTime 0.371137   LR 0.003335   
2022-11-25 09:35:19,977 - INFO  - ==> Top1: 72.136    Top5: 96.452    Loss: 0.851

2022-11-25 09:35:20,217 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:35:22,157 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:35:24,706 - INFO  - Validation [3][   20/   40]   Loss 0.719594   Top1 76.777344   Top5 98.125000   BatchTime 0.127326   
2022-11-25 09:35:25,864 - INFO  - Validation [3][   40/   40]   Loss 0.708344   Top1 76.640000   Top5 98.210000   BatchTime 0.092641   
2022-11-25 09:35:26,093 - INFO  - ==> Top1: 76.640    Top5: 98.210    Loss: 0.708

2022-11-25 09:35:26,093 - INFO  - ==> Sparsity : 0.325

2022-11-25 09:35:26,094 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 77.720   Top5: 98.770]
2022-11-25 09:35:26,094 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 76.640   Top5: 98.210]
2022-11-25 09:35:26,094 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 70.330   Top5: 97.390]
2022-11-25 09:35:26,223 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:35:26,224 - INFO  - >>>>>> Epoch   4
2022-11-25 09:35:26,226 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:35:35,082 - INFO  - Training [4][   20/  196]   Loss 0.845025   Top1 72.050781   Top5 96.132812   BatchTime 0.442661   LR 0.003200   
2022-11-25 09:35:42,859 - INFO  - Training [4][   40/  196]   Loss 0.836292   Top1 72.656250   Top5 96.386719   BatchTime 0.415747   LR 0.003122   
2022-11-25 09:35:50,372 - INFO  - Training [4][   60/  196]   Loss 0.825427   Top1 72.838542   Top5 96.516927   BatchTime 0.402380   LR 0.003044   
2022-11-25 09:35:57,624 - INFO  - Training [4][   80/  196]   Loss 0.818837   Top1 73.110352   Top5 96.772461   BatchTime 0.392432   LR 0.002965   
2022-11-25 09:36:04,401 - INFO  - Training [4][  100/  196]   Loss 0.805414   Top1 73.609375   Top5 96.867188   BatchTime 0.381719   LR 0.002886   
2022-11-25 09:36:11,291 - INFO  - Training [4][  120/  196]   Loss 0.798377   Top1 73.844401   Top5 96.966146   BatchTime 0.375515   LR 0.002806   
2022-11-25 09:36:18,826 - INFO  - Training [4][  140/  196]   Loss 0.792535   Top1 74.037388   Top5 97.025670   BatchTime 0.375686   LR 0.002726   
2022-11-25 09:36:26,730 - INFO  - Training [4][  160/  196]   Loss 0.793443   Top1 74.074707   Top5 96.997070   BatchTime 0.378125   LR 0.002646   
2022-11-25 09:36:34,253 - INFO  - Training [4][  180/  196]   Loss 0.789635   Top1 74.153646   Top5 96.970486   BatchTime 0.377906   LR 0.002566   
2022-11-25 09:36:40,365 - INFO  - ==> Top1: 74.232    Top5: 96.984    Loss: 0.786

2022-11-25 09:36:40,677 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:36:42,370 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:36:44,854 - INFO  - Validation [4][   20/   40]   Loss 0.591085   Top1 80.019531   Top5 98.554688   BatchTime 0.124086   
2022-11-25 09:36:45,922 - INFO  - Validation [4][   40/   40]   Loss 0.575301   Top1 80.620000   Top5 98.680000   BatchTime 0.088756   
2022-11-25 09:36:46,118 - INFO  - ==> Top1: 80.620    Top5: 98.680    Loss: 0.575

2022-11-25 09:36:46,118 - INFO  - ==> Sparsity : 0.351

2022-11-25 09:36:46,118 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 80.620   Top5: 98.680]
2022-11-25 09:36:46,119 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 77.720   Top5: 98.770]
2022-11-25 09:36:46,119 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 76.640   Top5: 98.210]
2022-11-25 09:36:51,699 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 09:36:51,700 - INFO  - >>>>>> Epoch   5
2022-11-25 09:36:51,702 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:37:00,449 - INFO  - Training [5][   20/  196]   Loss 0.754766   Top1 75.312500   Top5 96.503906   BatchTime 0.437212   LR 0.002424   
2022-11-25 09:37:07,703 - INFO  - Training [5][   40/  196]   Loss 0.766011   Top1 75.126953   Top5 96.796875   BatchTime 0.399972   LR 0.002343   
2022-11-25 09:37:15,022 - INFO  - Training [5][   60/  196]   Loss 0.754218   Top1 75.371094   Top5 96.985677   BatchTime 0.388620   LR 0.002263   
2022-11-25 09:37:22,396 - INFO  - Training [5][   80/  196]   Loss 0.756940   Top1 75.195312   Top5 97.099609   BatchTime 0.383642   LR 0.002183   
2022-11-25 09:37:28,771 - INFO  - Training [5][  100/  196]   Loss 0.747913   Top1 75.523438   Top5 97.226562   BatchTime 0.370660   LR 0.002104   
2022-11-25 09:37:36,256 - INFO  - Training [5][  120/  196]   Loss 0.744348   Top1 75.742188   Top5 97.265625   BatchTime 0.371262   LR 0.002024   
2022-11-25 09:37:43,568 - INFO  - Training [5][  140/  196]   Loss 0.741058   Top1 75.884487   Top5 97.301897   BatchTime 0.370449   LR 0.001946   
2022-11-25 09:37:51,130 - INFO  - Training [5][  160/  196]   Loss 0.743332   Top1 75.812988   Top5 97.290039   BatchTime 0.371409   LR 0.001868   
2022-11-25 09:37:58,695 - INFO  - Training [5][  180/  196]   Loss 0.741017   Top1 75.883247   Top5 97.200521   BatchTime 0.372167   LR 0.001790   
2022-11-25 09:38:04,907 - INFO  - ==> Top1: 75.920    Top5: 97.192    Loss: 0.739

2022-11-25 09:38:05,169 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:38:06,890 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:38:09,491 - INFO  - Validation [5][   20/   40]   Loss 0.616378   Top1 79.316406   Top5 98.671875   BatchTime 0.129946   
2022-11-25 09:38:10,600 - INFO  - Validation [5][   40/   40]   Loss 0.617281   Top1 79.360000   Top5 98.640000   BatchTime 0.092724   
2022-11-25 09:38:10,789 - INFO  - ==> Top1: 79.360    Top5: 98.640    Loss: 0.617

2022-11-25 09:38:10,789 - INFO  - ==> Sparsity : 0.350

2022-11-25 09:38:10,790 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 80.620   Top5: 98.680]
2022-11-25 09:38:10,790 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 79.360   Top5: 98.640]
2022-11-25 09:38:10,790 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 77.720   Top5: 98.770]
2022-11-25 09:38:11,111 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:38:11,112 - INFO  - >>>>>> Epoch   6
2022-11-25 09:38:11,114 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:38:19,636 - INFO  - Training [6][   20/  196]   Loss 0.723852   Top1 76.152344   Top5 96.660156   BatchTime 0.425997   LR 0.001655   
2022-11-25 09:38:27,329 - INFO  - Training [6][   40/  196]   Loss 0.729894   Top1 76.220703   Top5 96.953125   BatchTime 0.405322   LR 0.001580   
2022-11-25 09:38:34,847 - INFO  - Training [6][   60/  196]   Loss 0.718034   Top1 76.490885   Top5 97.128906   BatchTime 0.395512   LR 0.001506   
2022-11-25 09:38:42,445 - INFO  - Training [6][   80/  196]   Loss 0.714822   Top1 76.533203   Top5 97.211914   BatchTime 0.391604   LR 0.001432   
2022-11-25 09:38:49,488 - INFO  - Training [6][  100/  196]   Loss 0.708857   Top1 76.796875   Top5 97.273438   BatchTime 0.383709   LR 0.001360   
2022-11-25 09:38:57,455 - INFO  - Training [6][  120/  196]   Loss 0.700611   Top1 77.031250   Top5 97.434896   BatchTime 0.386150   LR 0.001289   
2022-11-25 09:39:04,883 - INFO  - Training [6][  140/  196]   Loss 0.698556   Top1 77.101004   Top5 97.466518   BatchTime 0.384041   LR 0.001220   
2022-11-25 09:39:12,532 - INFO  - Training [6][  160/  196]   Loss 0.699968   Top1 77.023926   Top5 97.443848   BatchTime 0.383844   LR 0.001151   
2022-11-25 09:39:19,895 - INFO  - Training [6][  180/  196]   Loss 0.699491   Top1 77.078993   Top5 97.417535   BatchTime 0.382101   LR 0.001084   
2022-11-25 09:39:25,902 - INFO  - ==> Top1: 77.200    Top5: 97.424    Loss: 0.698

2022-11-25 09:39:26,154 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:39:27,668 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:39:30,131 - INFO  - Validation [6][   20/   40]   Loss 0.580947   Top1 80.468750   Top5 98.613281   BatchTime 0.123051   
2022-11-25 09:39:31,405 - INFO  - Validation [6][   40/   40]   Loss 0.576368   Top1 80.560000   Top5 98.690000   BatchTime 0.093398   
2022-11-25 09:39:31,649 - INFO  - ==> Top1: 80.560    Top5: 98.690    Loss: 0.576

2022-11-25 09:39:31,649 - INFO  - ==> Sparsity : 0.362

2022-11-25 09:39:31,649 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 80.620   Top5: 98.680]
2022-11-25 09:39:31,650 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 80.560   Top5: 98.690]
2022-11-25 09:39:31,650 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 79.360   Top5: 98.640]
2022-11-25 09:39:31,813 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:39:31,815 - INFO  - >>>>>> Epoch   7
2022-11-25 09:39:31,816 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:39:41,469 - INFO  - Training [7][   20/  196]   Loss 0.681465   Top1 77.148438   Top5 97.011719   BatchTime 0.482487   LR 0.000969   
2022-11-25 09:39:48,898 - INFO  - Training [7][   40/  196]   Loss 0.686659   Top1 77.529297   Top5 97.080078   BatchTime 0.426983   LR 0.000907   
2022-11-25 09:39:56,377 - INFO  - Training [7][   60/  196]   Loss 0.675715   Top1 77.779948   Top5 97.278646   BatchTime 0.409290   LR 0.000845   
2022-11-25 09:40:02,755 - INFO  - Training [7][   80/  196]   Loss 0.671794   Top1 77.871094   Top5 97.495117   BatchTime 0.386698   LR 0.000786   
2022-11-25 09:40:09,671 - INFO  - Training [7][  100/  196]   Loss 0.669891   Top1 78.074219   Top5 97.507812   BatchTime 0.378519   LR 0.000728   
2022-11-25 09:40:16,931 - INFO  - Training [7][  120/  196]   Loss 0.661791   Top1 78.382161   Top5 97.646484   BatchTime 0.375931   LR 0.000673   
2022-11-25 09:40:23,736 - INFO  - Training [7][  140/  196]   Loss 0.660173   Top1 78.532366   Top5 97.723214   BatchTime 0.370829   LR 0.000619   
2022-11-25 09:40:30,697 - INFO  - Training [7][  160/  196]   Loss 0.661838   Top1 78.427734   Top5 97.712402   BatchTime 0.367982   LR 0.000567   
2022-11-25 09:40:38,321 - INFO  - Training [7][  180/  196]   Loss 0.660613   Top1 78.461372   Top5 97.671441   BatchTime 0.369452   LR 0.000517   
2022-11-25 09:40:44,466 - INFO  - ==> Top1: 78.548    Top5: 97.692    Loss: 0.658

2022-11-25 09:40:44,766 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:40:46,677 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:40:49,145 - INFO  - Validation [7][   20/   40]   Loss 0.558351   Top1 80.625000   Top5 99.160156   BatchTime 0.123292   
2022-11-25 09:40:50,216 - INFO  - Validation [7][   40/   40]   Loss 0.557051   Top1 80.630000   Top5 99.250000   BatchTime 0.088445   
2022-11-25 09:40:50,456 - INFO  - ==> Top1: 80.630    Top5: 99.250    Loss: 0.557

2022-11-25 09:40:50,456 - INFO  - ==> Sparsity : 0.443

2022-11-25 09:40:50,456 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 80.630   Top5: 99.250]
2022-11-25 09:40:50,457 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 80.620   Top5: 98.680]
2022-11-25 09:40:50,457 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 80.560   Top5: 98.690]
2022-11-25 09:40:56,372 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 09:40:56,376 - INFO  - >>>>>> Epoch   8
2022-11-25 09:40:56,379 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:41:05,355 - INFO  - Training [8][   20/  196]   Loss 0.652126   Top1 78.437500   Top5 97.285156   BatchTime 0.448668   LR 0.000434   
2022-11-25 09:41:12,844 - INFO  - Training [8][   40/  196]   Loss 0.651632   Top1 78.759766   Top5 97.607422   BatchTime 0.411549   LR 0.000389   
2022-11-25 09:41:19,294 - INFO  - Training [8][   60/  196]   Loss 0.657353   Top1 78.522135   Top5 97.760417   BatchTime 0.381870   LR 0.000347   
2022-11-25 09:41:26,440 - INFO  - Training [8][   80/  196]   Loss 0.648341   Top1 78.886719   Top5 97.768555   BatchTime 0.375718   LR 0.000308   
2022-11-25 09:41:33,996 - INFO  - Training [8][  100/  196]   Loss 0.642622   Top1 79.011719   Top5 97.812500   BatchTime 0.376134   LR 0.000270   
2022-11-25 09:41:42,400 - INFO  - Training [8][  120/  196]   Loss 0.637007   Top1 79.231771   Top5 97.903646   BatchTime 0.383480   LR 0.000235   
2022-11-25 09:41:50,004 - INFO  - Training [8][  140/  196]   Loss 0.636557   Top1 79.246652   Top5 97.960379   BatchTime 0.383010   LR 0.000202   
2022-11-25 09:41:57,648 - INFO  - Training [8][  160/  196]   Loss 0.639511   Top1 79.182129   Top5 97.922363   BatchTime 0.382907   LR 0.000172   
2022-11-25 09:42:05,666 - INFO  - Training [8][  180/  196]   Loss 0.637335   Top1 79.181858   Top5 97.858073   BatchTime 0.384910   LR 0.000143   
2022-11-25 09:42:11,872 - INFO  - ==> Top1: 79.238    Top5: 97.852    Loss: 0.636

2022-11-25 09:42:12,132 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:42:13,852 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:42:16,489 - INFO  - Validation [8][   20/   40]   Loss 0.589226   Top1 80.312500   Top5 98.828125   BatchTime 0.131761   
2022-11-25 09:42:17,596 - INFO  - Validation [8][   40/   40]   Loss 0.585463   Top1 80.300000   Top5 98.910000   BatchTime 0.093551   
2022-11-25 09:42:17,791 - INFO  - ==> Top1: 80.300    Top5: 98.910    Loss: 0.585

2022-11-25 09:42:17,792 - INFO  - ==> Sparsity : 0.475

2022-11-25 09:42:17,792 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 80.630   Top5: 99.250]
2022-11-25 09:42:17,792 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 80.620   Top5: 98.680]
2022-11-25 09:42:17,792 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 80.560   Top5: 98.690]
2022-11-25 09:42:17,913 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:42:17,916 - INFO  - >>>>>> Epoch   9
2022-11-25 09:42:17,918 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:42:26,783 - INFO  - Training [9][   20/  196]   Loss 0.649296   Top1 78.476562   Top5 97.304688   BatchTime 0.443110   LR 0.000100   
2022-11-25 09:42:33,147 - INFO  - Training [9][   40/  196]   Loss 0.641506   Top1 78.593750   Top5 97.539062   BatchTime 0.380665   LR 0.000079   
2022-11-25 09:42:40,259 - INFO  - Training [9][   60/  196]   Loss 0.635062   Top1 78.977865   Top5 97.682292   BatchTime 0.372308   LR 0.000060   
2022-11-25 09:42:47,882 - INFO  - Training [9][   80/  196]   Loss 0.631888   Top1 79.160156   Top5 97.822266   BatchTime 0.374516   LR 0.000044   
2022-11-25 09:42:55,433 - INFO  - Training [9][  100/  196]   Loss 0.626350   Top1 79.355469   Top5 97.910156   BatchTime 0.375124   LR 0.000030   
2022-11-25 09:43:02,779 - INFO  - Training [9][  120/  196]   Loss 0.625769   Top1 79.391276   Top5 97.897135   BatchTime 0.373816   LR 0.000019   
2022-11-25 09:43:10,299 - INFO  - Training [9][  140/  196]   Loss 0.619955   Top1 79.617746   Top5 97.991071   BatchTime 0.374128   LR 0.000010   
2022-11-25 09:43:17,653 - INFO  - Training [9][  160/  196]   Loss 0.623687   Top1 79.470215   Top5 97.905273   BatchTime 0.373322   LR 0.000004   
2022-11-25 09:43:25,284 - INFO  - Training [9][  180/  196]   Loss 0.623857   Top1 79.422743   Top5 97.855903   BatchTime 0.374237   LR 0.000001   
2022-11-25 09:43:31,677 - INFO  - ==> Top1: 79.368    Top5: 97.840    Loss: 0.625

2022-11-25 09:43:31,915 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:43:33,484 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:43:35,917 - INFO  - Validation [9][   20/   40]   Loss 0.527732   Top1 81.796875   Top5 98.964844   BatchTime 0.121588   
2022-11-25 09:43:37,066 - INFO  - Validation [9][   40/   40]   Loss 0.525864   Top1 81.890000   Top5 99.100000   BatchTime 0.089525   
2022-11-25 09:43:37,307 - INFO  - ==> Top1: 81.890    Top5: 99.100    Loss: 0.526

2022-11-25 09:43:37,307 - INFO  - ==> Sparsity : 0.489

2022-11-25 09:43:37,307 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 81.890   Top5: 99.100]
2022-11-25 09:43:37,308 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 80.630   Top5: 99.250]
2022-11-25 09:43:37,308 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 80.620   Top5: 98.680]
2022-11-25 09:43:43,360 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 09:43:43,364 - INFO  - >>>>>> Epoch  10
2022-11-25 09:43:43,367 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:43:51,427 - INFO  - Training [10][   20/  196]   Loss 0.672092   Top1 78.105469   Top5 97.246094   BatchTime 0.402768   LR 0.002500   
2022-11-25 09:43:58,623 - INFO  - Training [10][   40/  196]   Loss 0.683434   Top1 77.714844   Top5 97.402344   BatchTime 0.381234   LR 0.002499   
2022-11-25 09:44:06,063 - INFO  - Training [10][   60/  196]   Loss 0.688490   Top1 77.662760   Top5 97.278646   BatchTime 0.378189   LR 0.002499   
2022-11-25 09:44:13,664 - INFO  - Training [10][   80/  196]   Loss 0.695772   Top1 77.436523   Top5 97.343750   BatchTime 0.378652   LR 0.002497   
2022-11-25 09:44:21,665 - INFO  - Training [10][  100/  196]   Loss 0.697300   Top1 77.414062   Top5 97.363281   BatchTime 0.382938   LR 0.002496   
2022-11-25 09:44:29,317 - INFO  - Training [10][  120/  196]   Loss 0.697819   Top1 77.402344   Top5 97.434896   BatchTime 0.382877   LR 0.002494   
2022-11-25 09:44:36,931 - INFO  - Training [10][  140/  196]   Loss 0.696974   Top1 77.374442   Top5 97.427455   BatchTime 0.382563   LR 0.002492   
2022-11-25 09:44:44,715 - INFO  - Training [10][  160/  196]   Loss 0.702739   Top1 77.138672   Top5 97.397461   BatchTime 0.383397   LR 0.002490   
2022-11-25 09:44:52,527 - INFO  - Training [10][  180/  196]   Loss 0.698621   Top1 77.296007   Top5 97.356771   BatchTime 0.384196   LR 0.002487   
2022-11-25 09:44:58,575 - INFO  - ==> Top1: 77.330    Top5: 97.416    Loss: 0.696

2022-11-25 09:44:58,825 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:45:00,487 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:45:03,023 - INFO  - Validation [10][   20/   40]   Loss 0.527131   Top1 82.480469   Top5 98.925781   BatchTime 0.126726   
2022-11-25 09:45:04,072 - INFO  - Validation [10][   40/   40]   Loss 0.514366   Top1 82.830000   Top5 99.130000   BatchTime 0.089586   
2022-11-25 09:45:04,275 - INFO  - ==> Top1: 82.830    Top5: 99.130    Loss: 0.514

2022-11-25 09:45:04,275 - INFO  - ==> Sparsity : 0.355

2022-11-25 09:45:04,275 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 82.830   Top5: 99.130]
2022-11-25 09:45:04,276 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 81.890   Top5: 99.100]
2022-11-25 09:45:04,276 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 80.630   Top5: 99.250]
2022-11-25 09:45:11,872 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 09:45:11,878 - INFO  - >>>>>> Epoch  11
2022-11-25 09:45:11,881 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:45:21,009 - INFO  - Training [11][   20/  196]   Loss 0.684969   Top1 77.558594   Top5 96.835938   BatchTime 0.456265   LR 0.002481   
2022-11-25 09:45:28,283 - INFO  - Training [11][   40/  196]   Loss 0.706079   Top1 77.080078   Top5 97.060547   BatchTime 0.409988   LR 0.002478   
2022-11-25 09:45:36,061 - INFO  - Training [11][   60/  196]   Loss 0.700188   Top1 77.246094   Top5 97.213542   BatchTime 0.402950   LR 0.002474   
2022-11-25 09:45:43,689 - INFO  - Training [11][   80/  196]   Loss 0.695975   Top1 77.265625   Top5 97.353516   BatchTime 0.397565   LR 0.002470   
2022-11-25 09:45:52,050 - INFO  - Training [11][  100/  196]   Loss 0.686074   Top1 77.648438   Top5 97.410156   BatchTime 0.401656   LR 0.002465   
2022-11-25 09:45:59,737 - INFO  - Training [11][  120/  196]   Loss 0.684622   Top1 77.669271   Top5 97.500000   BatchTime 0.398770   LR 0.002460   
2022-11-25 09:46:07,197 - INFO  - Training [11][  140/  196]   Loss 0.684437   Top1 77.678571   Top5 97.589286   BatchTime 0.395091   LR 0.002455   
2022-11-25 09:46:15,158 - INFO  - Training [11][  160/  196]   Loss 0.686655   Top1 77.653809   Top5 97.526855   BatchTime 0.395457   LR 0.002450   
2022-11-25 09:46:22,314 - INFO  - Training [11][  180/  196]   Loss 0.685334   Top1 77.651910   Top5 97.489149   BatchTime 0.391274   LR 0.002444   
2022-11-25 09:46:27,620 - INFO  - ==> Top1: 77.716    Top5: 97.478    Loss: 0.685

2022-11-25 09:46:27,887 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:46:29,247 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:46:31,698 - INFO  - Validation [11][   20/   40]   Loss 0.580436   Top1 80.351562   Top5 98.613281   BatchTime 0.122485   
2022-11-25 09:46:32,849 - INFO  - Validation [11][   40/   40]   Loss 0.578953   Top1 80.710000   Top5 98.730000   BatchTime 0.090027   
2022-11-25 09:46:33,065 - INFO  - ==> Top1: 80.710    Top5: 98.730    Loss: 0.579

2022-11-25 09:46:33,065 - INFO  - ==> Sparsity : 0.372

2022-11-25 09:46:33,065 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 82.830   Top5: 99.130]
2022-11-25 09:46:33,066 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 81.890   Top5: 99.100]
2022-11-25 09:46:33,066 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 80.710   Top5: 98.730]
2022-11-25 09:46:33,378 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:46:33,379 - INFO  - >>>>>> Epoch  12
2022-11-25 09:46:33,381 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:46:42,054 - INFO  - Training [12][   20/  196]   Loss 0.674206   Top1 78.007812   Top5 97.187500   BatchTime 0.433518   LR 0.002433   
2022-11-25 09:46:49,371 - INFO  - Training [12][   40/  196]   Loss 0.685180   Top1 77.568359   Top5 97.363281   BatchTime 0.399689   LR 0.002426   
2022-11-25 09:46:57,178 - INFO  - Training [12][   60/  196]   Loss 0.684738   Top1 77.656250   Top5 97.389323   BatchTime 0.396562   LR 0.002419   
2022-11-25 09:47:04,640 - INFO  - Training [12][   80/  196]   Loss 0.679698   Top1 77.783203   Top5 97.529297   BatchTime 0.390703   LR 0.002412   
2022-11-25 09:47:12,335 - INFO  - Training [12][  100/  196]   Loss 0.668122   Top1 78.269531   Top5 97.589844   BatchTime 0.389512   LR 0.002404   
2022-11-25 09:47:19,477 - INFO  - Training [12][  120/  196]   Loss 0.661434   Top1 78.512370   Top5 97.659505   BatchTime 0.384104   LR 0.002396   
2022-11-25 09:47:27,060 - INFO  - Training [12][  140/  196]   Loss 0.659456   Top1 78.543527   Top5 97.720424   BatchTime 0.383395   LR 0.002388   
2022-11-25 09:47:34,285 - INFO  - Training [12][  160/  196]   Loss 0.663662   Top1 78.381348   Top5 97.653809   BatchTime 0.380625   LR 0.002380   
2022-11-25 09:47:40,834 - INFO  - Training [12][  180/  196]   Loss 0.663642   Top1 78.370226   Top5 97.573785   BatchTime 0.374721   LR 0.002371   
2022-11-25 09:47:46,171 - INFO  - ==> Top1: 78.386    Top5: 97.586    Loss: 0.664

2022-11-25 09:47:46,434 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:47:47,923 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:47:50,671 - INFO  - Validation [12][   20/   40]   Loss 0.558280   Top1 81.074219   Top5 98.808594   BatchTime 0.137280   
2022-11-25 09:47:51,748 - INFO  - Validation [12][   40/   40]   Loss 0.549049   Top1 81.600000   Top5 98.940000   BatchTime 0.095580   
2022-11-25 09:47:51,957 - INFO  - ==> Top1: 81.600    Top5: 98.940    Loss: 0.549

2022-11-25 09:47:51,958 - INFO  - ==> Sparsity : 0.378

2022-11-25 09:47:51,958 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 82.830   Top5: 99.130]
2022-11-25 09:47:51,958 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 81.890   Top5: 99.100]
2022-11-25 09:47:51,958 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 81.600   Top5: 98.940]
2022-11-25 09:47:52,109 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:47:52,111 - INFO  - >>>>>> Epoch  13
2022-11-25 09:47:52,114 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:48:01,685 - INFO  - Training [13][   20/  196]   Loss 0.672951   Top1 77.734375   Top5 96.992188   BatchTime 0.478321   LR 0.002355   
2022-11-25 09:48:09,165 - INFO  - Training [13][   40/  196]   Loss 0.653510   Top1 78.330078   Top5 97.451172   BatchTime 0.426185   LR 0.002345   
2022-11-25 09:48:16,920 - INFO  - Training [13][   60/  196]   Loss 0.650350   Top1 78.613281   Top5 97.532552   BatchTime 0.413368   LR 0.002336   
2022-11-25 09:48:24,184 - INFO  - Training [13][   80/  196]   Loss 0.650130   Top1 78.627930   Top5 97.675781   BatchTime 0.400818   LR 0.002325   
2022-11-25 09:48:31,579 - INFO  - Training [13][  100/  196]   Loss 0.647477   Top1 78.707031   Top5 97.660156   BatchTime 0.394606   LR 0.002315   
2022-11-25 09:48:39,206 - INFO  - Training [13][  120/  196]   Loss 0.646799   Top1 78.779297   Top5 97.727865   BatchTime 0.392397   LR 0.002304   
2022-11-25 09:48:46,925 - INFO  - Training [13][  140/  196]   Loss 0.645827   Top1 78.830915   Top5 97.784598   BatchTime 0.391473   LR 0.002293   
2022-11-25 09:48:54,826 - INFO  - Training [13][  160/  196]   Loss 0.647283   Top1 78.876953   Top5 97.770996   BatchTime 0.391921   LR 0.002282   
2022-11-25 09:49:01,389 - INFO  - Training [13][  180/  196]   Loss 0.647278   Top1 78.834635   Top5 97.723524   BatchTime 0.384835   LR 0.002271   
2022-11-25 09:49:08,481 - INFO  - ==> Top1: 78.822    Top5: 97.720    Loss: 0.647

2022-11-25 09:49:08,752 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:49:10,138 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:49:12,749 - INFO  - Validation [13][   20/   40]   Loss 0.516347   Top1 82.050781   Top5 99.003906   BatchTime 0.130460   
2022-11-25 09:49:13,861 - INFO  - Validation [13][   40/   40]   Loss 0.514837   Top1 82.170000   Top5 99.070000   BatchTime 0.093033   
2022-11-25 09:49:14,076 - INFO  - ==> Top1: 82.170    Top5: 99.070    Loss: 0.515

2022-11-25 09:49:14,076 - INFO  - ==> Sparsity : 0.385

2022-11-25 09:49:14,076 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 82.830   Top5: 99.130]
2022-11-25 09:49:14,076 - INFO  - Scoreboard best 2 ==> Epoch [13][Top1: 82.170   Top5: 99.070]
2022-11-25 09:49:14,076 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 81.890   Top5: 99.100]
2022-11-25 09:49:14,199 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:49:14,201 - INFO  - >>>>>> Epoch  14
2022-11-25 09:49:14,202 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:49:23,219 - INFO  - Training [14][   20/  196]   Loss 0.672787   Top1 77.773438   Top5 97.246094   BatchTime 0.450711   LR 0.002250   
2022-11-25 09:49:30,631 - INFO  - Training [14][   40/  196]   Loss 0.663915   Top1 78.261719   Top5 97.617188   BatchTime 0.410640   LR 0.002238   
2022-11-25 09:49:37,929 - INFO  - Training [14][   60/  196]   Loss 0.650836   Top1 78.828125   Top5 97.675781   BatchTime 0.395401   LR 0.002225   
2022-11-25 09:49:45,229 - INFO  - Training [14][   80/  196]   Loss 0.645951   Top1 78.959961   Top5 97.729492   BatchTime 0.387793   LR 0.002213   
2022-11-25 09:49:52,580 - INFO  - Training [14][  100/  196]   Loss 0.639341   Top1 79.179688   Top5 97.742188   BatchTime 0.383747   LR 0.002200   
2022-11-25 09:50:00,057 - INFO  - Training [14][  120/  196]   Loss 0.633163   Top1 79.410807   Top5 97.809245   BatchTime 0.382099   LR 0.002186   
2022-11-25 09:50:07,612 - INFO  - Training [14][  140/  196]   Loss 0.635470   Top1 79.383371   Top5 97.779018   BatchTime 0.381476   LR 0.002173   
2022-11-25 09:50:14,673 - INFO  - Training [14][  160/  196]   Loss 0.633689   Top1 79.392090   Top5 97.775879   BatchTime 0.377919   LR 0.002159   
2022-11-25 09:50:21,616 - INFO  - Training [14][  180/  196]   Loss 0.632761   Top1 79.390191   Top5 97.719184   BatchTime 0.374503   LR 0.002145   
2022-11-25 09:50:27,676 - INFO  - ==> Top1: 79.454    Top5: 97.762    Loss: 0.632

2022-11-25 09:50:27,984 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:50:29,772 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:50:32,351 - INFO  - Validation [14][   20/   40]   Loss 0.531806   Top1 83.281250   Top5 99.023438   BatchTime 0.128869   
2022-11-25 09:50:33,427 - INFO  - Validation [14][   40/   40]   Loss 0.520357   Top1 83.300000   Top5 99.160000   BatchTime 0.091344   
2022-11-25 09:50:33,637 - INFO  - ==> Top1: 83.300    Top5: 99.160    Loss: 0.520

2022-11-25 09:50:33,638 - INFO  - ==> Sparsity : 0.405

2022-11-25 09:50:33,638 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 83.300   Top5: 99.160]
2022-11-25 09:50:33,638 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 82.830   Top5: 99.130]
2022-11-25 09:50:33,638 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 82.170   Top5: 99.070]
2022-11-25 09:50:39,682 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 09:50:39,684 - INFO  - >>>>>> Epoch  15
2022-11-25 09:50:39,686 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:50:48,043 - INFO  - Training [15][   20/  196]   Loss 0.633971   Top1 79.726562   Top5 97.265625   BatchTime 0.417723   LR 0.002120   
2022-11-25 09:50:55,232 - INFO  - Training [15][   40/  196]   Loss 0.629117   Top1 79.843750   Top5 97.597656   BatchTime 0.388595   LR 0.002106   
2022-11-25 09:51:02,670 - INFO  - Training [15][   60/  196]   Loss 0.633999   Top1 79.459635   Top5 97.669271   BatchTime 0.383032   LR 0.002091   
2022-11-25 09:51:09,487 - INFO  - Training [15][   80/  196]   Loss 0.632540   Top1 79.467773   Top5 97.758789   BatchTime 0.372476   LR 0.002076   
2022-11-25 09:51:17,271 - INFO  - Training [15][  100/  196]   Loss 0.624025   Top1 79.640625   Top5 97.824219   BatchTime 0.375827   LR 0.002061   
2022-11-25 09:51:24,650 - INFO  - Training [15][  120/  196]   Loss 0.619627   Top1 79.736328   Top5 97.913411   BatchTime 0.374676   LR 0.002045   
2022-11-25 09:51:31,128 - INFO  - Training [15][  140/  196]   Loss 0.616504   Top1 79.958147   Top5 97.971540   BatchTime 0.367423   LR 0.002030   
2022-11-25 09:51:37,550 - INFO  - Training [15][  160/  196]   Loss 0.619484   Top1 79.880371   Top5 97.939453   BatchTime 0.361632   LR 0.002014   
2022-11-25 09:51:45,360 - INFO  - Training [15][  180/  196]   Loss 0.618341   Top1 79.852431   Top5 97.912326   BatchTime 0.364840   LR 0.001998   
2022-11-25 09:51:51,734 - INFO  - ==> Top1: 79.894    Top5: 97.896    Loss: 0.617

2022-11-25 09:51:52,003 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:51:53,924 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:51:56,561 - INFO  - Validation [15][   20/   40]   Loss 0.532389   Top1 83.007812   Top5 98.906250   BatchTime 0.131779   
2022-11-25 09:51:57,653 - INFO  - Validation [15][   40/   40]   Loss 0.527124   Top1 82.940000   Top5 99.070000   BatchTime 0.093183   
2022-11-25 09:51:58,060 - INFO  - ==> Top1: 82.940    Top5: 99.070    Loss: 0.527

2022-11-25 09:51:58,060 - INFO  - ==> Sparsity : 0.395

2022-11-25 09:51:58,061 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 83.300   Top5: 99.160]
2022-11-25 09:51:58,061 - INFO  - Scoreboard best 2 ==> Epoch [15][Top1: 82.940   Top5: 99.070]
2022-11-25 09:51:58,061 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 82.830   Top5: 99.130]
2022-11-25 09:51:58,402 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:51:58,404 - INFO  - >>>>>> Epoch  16
2022-11-25 09:51:58,406 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:52:07,863 - INFO  - Training [16][   20/  196]   Loss 0.613367   Top1 79.589844   Top5 97.617188   BatchTime 0.472736   LR 0.001969   
2022-11-25 09:52:15,219 - INFO  - Training [16][   40/  196]   Loss 0.613797   Top1 79.726562   Top5 97.753906   BatchTime 0.420258   LR 0.001953   
2022-11-25 09:52:22,806 - INFO  - Training [16][   60/  196]   Loss 0.612723   Top1 79.752604   Top5 97.858073   BatchTime 0.406617   LR 0.001936   
2022-11-25 09:52:29,964 - INFO  - Training [16][   80/  196]   Loss 0.607780   Top1 80.068359   Top5 97.983398   BatchTime 0.394442   LR 0.001919   
2022-11-25 09:52:37,236 - INFO  - Training [16][  100/  196]   Loss 0.597821   Top1 80.402344   Top5 98.023438   BatchTime 0.388269   LR 0.001902   
2022-11-25 09:52:43,883 - INFO  - Training [16][  120/  196]   Loss 0.598088   Top1 80.387370   Top5 98.069661   BatchTime 0.378951   LR 0.001885   
2022-11-25 09:52:50,089 - INFO  - Training [16][  140/  196]   Loss 0.596277   Top1 80.485491   Top5 98.108259   BatchTime 0.369145   LR 0.001867   
2022-11-25 09:52:57,256 - INFO  - Training [16][  160/  196]   Loss 0.595820   Top1 80.544434   Top5 98.125000   BatchTime 0.367792   LR 0.001850   
2022-11-25 09:53:04,988 - INFO  - Training [16][  180/  196]   Loss 0.595412   Top1 80.598958   Top5 98.096788   BatchTime 0.369880   LR 0.001832   
2022-11-25 09:53:10,695 - INFO  - ==> Top1: 80.642    Top5: 98.106    Loss: 0.593

2022-11-25 09:53:10,963 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:53:12,696 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:53:15,291 - INFO  - Validation [16][   20/   40]   Loss 0.456452   Top1 85.273438   Top5 99.062500   BatchTime 0.129649   
2022-11-25 09:53:16,339 - INFO  - Validation [16][   40/   40]   Loss 0.449590   Top1 85.250000   Top5 99.160000   BatchTime 0.091016   
2022-11-25 09:53:16,583 - INFO  - ==> Top1: 85.250    Top5: 99.160    Loss: 0.450

2022-11-25 09:53:16,583 - INFO  - ==> Sparsity : 0.395

2022-11-25 09:53:16,584 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 85.250   Top5: 99.160]
2022-11-25 09:53:16,584 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 83.300   Top5: 99.160]
2022-11-25 09:53:16,584 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 82.940   Top5: 99.070]
2022-11-25 09:53:22,667 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 09:53:22,670 - INFO  - >>>>>> Epoch  17
2022-11-25 09:53:22,672 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:53:32,677 - INFO  - Training [17][   20/  196]   Loss 0.615549   Top1 79.394531   Top5 97.597656   BatchTime 0.500162   LR 0.001800   
2022-11-25 09:53:40,292 - INFO  - Training [17][   40/  196]   Loss 0.598043   Top1 80.341797   Top5 97.753906   BatchTime 0.440454   LR 0.001782   
2022-11-25 09:53:47,579 - INFO  - Training [17][   60/  196]   Loss 0.589818   Top1 80.598958   Top5 97.805990   BatchTime 0.415077   LR 0.001764   
2022-11-25 09:53:54,621 - INFO  - Training [17][   80/  196]   Loss 0.592961   Top1 80.502930   Top5 97.905273   BatchTime 0.399335   LR 0.001746   
2022-11-25 09:54:02,083 - INFO  - Training [17][  100/  196]   Loss 0.588534   Top1 80.820312   Top5 97.925781   BatchTime 0.394083   LR 0.001727   
2022-11-25 09:54:08,721 - INFO  - Training [17][  120/  196]   Loss 0.584138   Top1 80.983073   Top5 97.998047   BatchTime 0.383719   LR 0.001708   
2022-11-25 09:54:15,836 - INFO  - Training [17][  140/  196]   Loss 0.580615   Top1 81.222098   Top5 98.063616   BatchTime 0.379726   LR 0.001690   
2022-11-25 09:54:23,708 - INFO  - Training [17][  160/  196]   Loss 0.582422   Top1 81.157227   Top5 98.063965   BatchTime 0.381458   LR 0.001671   
2022-11-25 09:54:31,264 - INFO  - Training [17][  180/  196]   Loss 0.581109   Top1 81.223958   Top5 98.036024   BatchTime 0.381052   LR 0.001652   
2022-11-25 09:54:37,751 - INFO  - ==> Top1: 81.218    Top5: 98.040    Loss: 0.581

2022-11-25 09:54:38,015 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:54:39,721 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:54:42,238 - INFO  - Validation [17][   20/   40]   Loss 0.604357   Top1 80.761719   Top5 98.593750   BatchTime 0.125750   
2022-11-25 09:54:43,301 - INFO  - Validation [17][   40/   40]   Loss 0.590395   Top1 80.680000   Top5 98.820000   BatchTime 0.089478   
2022-11-25 09:54:43,529 - INFO  - ==> Top1: 80.680    Top5: 98.820    Loss: 0.590

2022-11-25 09:54:43,529 - INFO  - ==> Sparsity : 0.397

2022-11-25 09:54:43,530 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 85.250   Top5: 99.160]
2022-11-25 09:54:43,530 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 83.300   Top5: 99.160]
2022-11-25 09:54:43,530 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 82.940   Top5: 99.070]
2022-11-25 09:54:43,663 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:54:43,665 - INFO  - >>>>>> Epoch  18
2022-11-25 09:54:43,667 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:54:53,239 - INFO  - Training [18][   20/  196]   Loss 0.584606   Top1 80.820312   Top5 97.402344   BatchTime 0.478473   LR 0.001618   
2022-11-25 09:55:00,917 - INFO  - Training [18][   40/  196]   Loss 0.587288   Top1 80.732422   Top5 97.626953   BatchTime 0.431193   LR 0.001599   
2022-11-25 09:55:08,518 - INFO  - Training [18][   60/  196]   Loss 0.583127   Top1 80.885417   Top5 97.832031   BatchTime 0.414141   LR 0.001579   
2022-11-25 09:55:15,694 - INFO  - Training [18][   80/  196]   Loss 0.583556   Top1 80.908203   Top5 97.924805   BatchTime 0.400298   LR 0.001560   
2022-11-25 09:55:22,109 - INFO  - Training [18][  100/  196]   Loss 0.575767   Top1 81.214844   Top5 98.000000   BatchTime 0.384387   LR 0.001540   
2022-11-25 09:55:29,035 - INFO  - Training [18][  120/  196]   Loss 0.564127   Top1 81.621094   Top5 98.108724   BatchTime 0.378045   LR 0.001521   
2022-11-25 09:55:37,044 - INFO  - Training [18][  140/  196]   Loss 0.564751   Top1 81.704799   Top5 98.186384   BatchTime 0.381244   LR 0.001501   
2022-11-25 09:55:44,795 - INFO  - Training [18][  160/  196]   Loss 0.566853   Top1 81.606445   Top5 98.171387   BatchTime 0.382027   LR 0.001482   
2022-11-25 09:55:52,179 - INFO  - Training [18][  180/  196]   Loss 0.565555   Top1 81.614583   Top5 98.140191   BatchTime 0.380601   LR 0.001462   
2022-11-25 09:55:58,182 - INFO  - ==> Top1: 81.714    Top5: 98.150    Loss: 0.562

2022-11-25 09:55:58,583 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:56:01,935 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:56:04,678 - INFO  - Validation [18][   20/   40]   Loss 0.578993   Top1 82.460938   Top5 99.003906   BatchTime 0.137066   
2022-11-25 09:56:05,730 - INFO  - Validation [18][   40/   40]   Loss 0.569601   Top1 82.580000   Top5 99.140000   BatchTime 0.094835   
2022-11-25 09:56:05,940 - INFO  - ==> Top1: 82.580    Top5: 99.140    Loss: 0.570

2022-11-25 09:56:05,940 - INFO  - ==> Sparsity : 0.405

2022-11-25 09:56:05,941 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 85.250   Top5: 99.160]
2022-11-25 09:56:05,941 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 83.300   Top5: 99.160]
2022-11-25 09:56:05,941 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 82.940   Top5: 99.070]
2022-11-25 09:56:06,070 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:56:06,072 - INFO  - >>>>>> Epoch  19
2022-11-25 09:56:06,074 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:56:15,077 - INFO  - Training [19][   20/  196]   Loss 0.569059   Top1 81.308594   Top5 97.812500   BatchTime 0.449988   LR 0.001427   
2022-11-25 09:56:22,411 - INFO  - Training [19][   40/  196]   Loss 0.553617   Top1 82.060547   Top5 98.007812   BatchTime 0.408366   LR 0.001407   
2022-11-25 09:56:30,250 - INFO  - Training [19][   60/  196]   Loss 0.552040   Top1 82.141927   Top5 98.059896   BatchTime 0.402888   LR 0.001387   
2022-11-25 09:56:36,756 - INFO  - Training [19][   80/  196]   Loss 0.555816   Top1 81.992188   Top5 98.076172   BatchTime 0.383490   LR 0.001367   
2022-11-25 09:56:43,562 - INFO  - Training [19][  100/  196]   Loss 0.548711   Top1 82.175781   Top5 98.187500   BatchTime 0.374847   LR 0.001347   
2022-11-25 09:56:50,786 - INFO  - Training [19][  120/  196]   Loss 0.543345   Top1 82.382812   Top5 98.291016   BatchTime 0.372572   LR 0.001327   
2022-11-25 09:56:58,240 - INFO  - Training [19][  140/  196]   Loss 0.544825   Top1 82.329799   Top5 98.300781   BatchTime 0.372592   LR 0.001307   
2022-11-25 09:57:05,999 - INFO  - Training [19][  160/  196]   Loss 0.549443   Top1 82.197266   Top5 98.269043   BatchTime 0.374510   LR 0.001287   
2022-11-25 09:57:13,174 - INFO  - Training [19][  180/  196]   Loss 0.548745   Top1 82.274306   Top5 98.235677   BatchTime 0.372760   LR 0.001266   
2022-11-25 09:57:19,514 - INFO  - ==> Top1: 82.322    Top5: 98.244    Loss: 0.547

2022-11-25 09:57:19,788 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:57:21,308 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:57:24,139 - INFO  - Validation [19][   20/   40]   Loss 0.699928   Top1 77.500000   Top5 98.457031   BatchTime 0.141460   
2022-11-25 09:57:25,232 - INFO  - Validation [19][   40/   40]   Loss 0.692527   Top1 77.790000   Top5 98.410000   BatchTime 0.098060   
2022-11-25 09:57:25,451 - INFO  - ==> Top1: 77.790    Top5: 98.410    Loss: 0.693

2022-11-25 09:57:25,452 - INFO  - ==> Sparsity : 0.426

2022-11-25 09:57:25,452 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 85.250   Top5: 99.160]
2022-11-25 09:57:25,452 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 83.300   Top5: 99.160]
2022-11-25 09:57:25,453 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 82.940   Top5: 99.070]
2022-11-25 09:57:25,614 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 09:57:25,616 - INFO  - >>>>>> Epoch  20
2022-11-25 09:57:25,618 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:57:34,459 - INFO  - Training [20][   20/  196]   Loss 0.553093   Top1 82.070312   Top5 97.558594   BatchTime 0.441932   LR 0.001231   
2022-11-25 09:57:41,790 - INFO  - Training [20][   40/  196]   Loss 0.550732   Top1 82.119141   Top5 97.939453   BatchTime 0.404226   LR 0.001211   
2022-11-25 09:57:49,080 - INFO  - Training [20][   60/  196]   Loss 0.545613   Top1 82.460938   Top5 98.020833   BatchTime 0.390998   LR 0.001191   
2022-11-25 09:57:56,104 - INFO  - Training [20][   80/  196]   Loss 0.543936   Top1 82.465820   Top5 98.159180   BatchTime 0.381035   LR 0.001171   
2022-11-25 09:58:04,130 - INFO  - Training [20][  100/  196]   Loss 0.542268   Top1 82.527344   Top5 98.292969   BatchTime 0.385092   LR 0.001151   
2022-11-25 09:58:11,633 - INFO  - Training [20][  120/  196]   Loss 0.538451   Top1 82.600911   Top5 98.336589   BatchTime 0.383430   LR 0.001131   
2022-11-25 09:58:19,285 - INFO  - Training [20][  140/  196]   Loss 0.536530   Top1 82.720424   Top5 98.404018   BatchTime 0.383316   LR 0.001111   
2022-11-25 09:58:26,957 - INFO  - Training [20][  160/  196]   Loss 0.537934   Top1 82.614746   Top5 98.381348   BatchTime 0.383350   LR 0.001091   
2022-11-25 09:58:34,012 - INFO  - Training [20][  180/  196]   Loss 0.535691   Top1 82.701823   Top5 98.339844   BatchTime 0.379951   LR 0.001071   
2022-11-25 09:58:39,865 - INFO  - ==> Top1: 82.754    Top5: 98.346    Loss: 0.534

2022-11-25 09:58:40,149 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 09:58:41,835 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 09:58:44,548 - INFO  - Validation [20][   20/   40]   Loss 0.399779   Top1 86.660156   Top5 99.335938   BatchTime 0.135527   
2022-11-25 09:58:45,654 - INFO  - Validation [20][   40/   40]   Loss 0.393591   Top1 86.470000   Top5 99.420000   BatchTime 0.095431   
2022-11-25 09:58:45,875 - INFO  - ==> Top1: 86.470    Top5: 99.420    Loss: 0.394

2022-11-25 09:58:45,875 - INFO  - ==> Sparsity : 0.450

2022-11-25 09:58:45,876 - INFO  - Scoreboard best 1 ==> Epoch [20][Top1: 86.470   Top5: 99.420]
2022-11-25 09:58:45,876 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 85.250   Top5: 99.160]
2022-11-25 09:58:45,876 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 83.300   Top5: 99.160]
2022-11-25 09:58:51,905 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 09:58:51,908 - INFO  - >>>>>> Epoch  21
2022-11-25 09:58:51,909 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 09:59:00,814 - INFO  - Training [21][   20/  196]   Loss 0.533370   Top1 82.460938   Top5 97.890625   BatchTime 0.445090   LR 0.001036   
2022-11-25 09:59:08,178 - INFO  - Training [21][   40/  196]   Loss 0.532274   Top1 82.558594   Top5 98.125000   BatchTime 0.406662   LR 0.001016   
2022-11-25 09:59:15,211 - INFO  - Training [21][   60/  196]   Loss 0.529791   Top1 82.656250   Top5 98.125000   BatchTime 0.388314   LR 0.000996   
2022-11-25 09:59:23,253 - INFO  - Training [21][   80/  196]   Loss 0.529625   Top1 82.792969   Top5 98.222656   BatchTime 0.391760   LR 0.000976   
2022-11-25 09:59:30,857 - INFO  - Training [21][  100/  196]   Loss 0.526107   Top1 82.890625   Top5 98.230469   BatchTime 0.389449   LR 0.000957   
2022-11-25 09:59:38,101 - INFO  - Training [21][  120/  196]   Loss 0.518795   Top1 83.121745   Top5 98.330078   BatchTime 0.384902   LR 0.000937   
2022-11-25 09:59:46,103 - INFO  - Training [21][  140/  196]   Loss 0.519354   Top1 83.211496   Top5 98.359375   BatchTime 0.387077   LR 0.000918   
2022-11-25 09:59:53,833 - INFO  - Training [21][  160/  196]   Loss 0.521168   Top1 83.112793   Top5 98.371582   BatchTime 0.387002   LR 0.000899   
2022-11-25 10:00:01,578 - INFO  - Training [21][  180/  196]   Loss 0.520292   Top1 83.187934   Top5 98.328993   BatchTime 0.387031   LR 0.000879   
2022-11-25 10:00:08,102 - INFO  - ==> Top1: 83.310    Top5: 98.346    Loss: 0.518

2022-11-25 10:00:08,388 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:00:09,891 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:00:12,431 - INFO  - Validation [21][   20/   40]   Loss 0.450629   Top1 85.058594   Top5 99.199219   BatchTime 0.126924   
2022-11-25 10:00:13,469 - INFO  - Validation [21][   40/   40]   Loss 0.442036   Top1 85.270000   Top5 99.250000   BatchTime 0.089398   
2022-11-25 10:00:13,714 - INFO  - ==> Top1: 85.270    Top5: 99.250    Loss: 0.442

2022-11-25 10:00:13,715 - INFO  - ==> Sparsity : 0.501

2022-11-25 10:00:13,715 - INFO  - Scoreboard best 1 ==> Epoch [20][Top1: 86.470   Top5: 99.420]
2022-11-25 10:00:13,716 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 85.270   Top5: 99.250]
2022-11-25 10:00:13,716 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 85.250   Top5: 99.160]
2022-11-25 10:00:13,859 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:00:13,861 - INFO  - >>>>>> Epoch  22
2022-11-25 10:00:13,863 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:00:22,293 - INFO  - Training [22][   20/  196]   Loss 0.542702   Top1 82.558594   Top5 97.539062   BatchTime 0.421371   LR 0.000846   
2022-11-25 10:00:28,911 - INFO  - Training [22][   40/  196]   Loss 0.521406   Top1 83.046875   Top5 98.076172   BatchTime 0.376147   LR 0.000827   
2022-11-25 10:00:36,082 - INFO  - Training [22][   60/  196]   Loss 0.520497   Top1 83.177083   Top5 98.177083   BatchTime 0.370266   LR 0.000808   
2022-11-25 10:00:43,108 - INFO  - Training [22][   80/  196]   Loss 0.515355   Top1 83.256836   Top5 98.330078   BatchTime 0.365535   LR 0.000789   
2022-11-25 10:00:50,098 - INFO  - Training [22][  100/  196]   Loss 0.511234   Top1 83.449219   Top5 98.339844   BatchTime 0.362321   LR 0.000770   
2022-11-25 10:00:57,695 - INFO  - Training [22][  120/  196]   Loss 0.504616   Top1 83.688151   Top5 98.378906   BatchTime 0.365247   LR 0.000752   
2022-11-25 10:01:05,397 - INFO  - Training [22][  140/  196]   Loss 0.503010   Top1 83.724888   Top5 98.423549   BatchTime 0.368077   LR 0.000734   
2022-11-25 10:01:12,660 - INFO  - Training [22][  160/  196]   Loss 0.504838   Top1 83.715820   Top5 98.410645   BatchTime 0.367460   LR 0.000715   
2022-11-25 10:01:19,875 - INFO  - Training [22][  180/  196]   Loss 0.503466   Top1 83.708767   Top5 98.404948   BatchTime 0.366716   LR 0.000697   
2022-11-25 10:01:26,166 - INFO  - ==> Top1: 83.764    Top5: 98.404    Loss: 0.503

2022-11-25 10:01:26,765 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:01:28,543 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:01:31,074 - INFO  - Validation [22][   20/   40]   Loss 0.729263   Top1 76.308594   Top5 97.753906   BatchTime 0.126507   
2022-11-25 10:01:32,047 - INFO  - Validation [22][   40/   40]   Loss 0.733109   Top1 76.020000   Top5 97.810000   BatchTime 0.087582   
2022-11-25 10:01:32,262 - INFO  - ==> Top1: 76.020    Top5: 97.810    Loss: 0.733

2022-11-25 10:01:32,262 - INFO  - ==> Sparsity : 0.492

2022-11-25 10:01:32,262 - INFO  - Scoreboard best 1 ==> Epoch [20][Top1: 86.470   Top5: 99.420]
2022-11-25 10:01:32,263 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 85.270   Top5: 99.250]
2022-11-25 10:01:32,263 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 85.250   Top5: 99.160]
2022-11-25 10:01:32,417 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:01:32,419 - INFO  - >>>>>> Epoch  23
2022-11-25 10:01:32,420 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:01:40,588 - INFO  - Training [23][   20/  196]   Loss 0.510079   Top1 82.949219   Top5 98.125000   BatchTime 0.408259   LR 0.000666   
2022-11-25 10:01:47,503 - INFO  - Training [23][   40/  196]   Loss 0.511038   Top1 83.525391   Top5 98.164062   BatchTime 0.376995   LR 0.000648   
2022-11-25 10:01:54,484 - INFO  - Training [23][   60/  196]   Loss 0.510385   Top1 83.541667   Top5 98.235677   BatchTime 0.367675   LR 0.000630   
2022-11-25 10:02:01,973 - INFO  - Training [23][   80/  196]   Loss 0.507965   Top1 83.676758   Top5 98.334961   BatchTime 0.369372   LR 0.000613   
2022-11-25 10:02:09,925 - INFO  - Training [23][  100/  196]   Loss 0.498413   Top1 83.906250   Top5 98.402344   BatchTime 0.375021   LR 0.000596   
2022-11-25 10:02:17,442 - INFO  - Training [23][  120/  196]   Loss 0.496561   Top1 84.016927   Top5 98.457031   BatchTime 0.375153   LR 0.000579   
2022-11-25 10:02:24,760 - INFO  - Training [23][  140/  196]   Loss 0.492666   Top1 84.174107   Top5 98.535156   BatchTime 0.373831   LR 0.000562   
2022-11-25 10:02:32,312 - INFO  - Training [23][  160/  196]   Loss 0.493902   Top1 84.094238   Top5 98.496094   BatchTime 0.374300   LR 0.000545   
2022-11-25 10:02:39,583 - INFO  - Training [23][  180/  196]   Loss 0.492039   Top1 84.149306   Top5 98.470052   BatchTime 0.373107   LR 0.000529   
2022-11-25 10:02:45,452 - INFO  - ==> Top1: 84.208    Top5: 98.478    Loss: 0.490

2022-11-25 10:02:45,734 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:02:47,430 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:02:49,986 - INFO  - Validation [23][   20/   40]   Loss 0.406179   Top1 86.367188   Top5 99.511719   BatchTime 0.127690   
2022-11-25 10:02:51,047 - INFO  - Validation [23][   40/   40]   Loss 0.390165   Top1 86.860000   Top5 99.590000   BatchTime 0.090388   
2022-11-25 10:02:51,287 - INFO  - ==> Top1: 86.860    Top5: 99.590    Loss: 0.390

2022-11-25 10:02:51,288 - INFO  - ==> Sparsity : 0.550

2022-11-25 10:02:51,288 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 86.860   Top5: 99.590]
2022-11-25 10:02:51,288 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 86.470   Top5: 99.420]
2022-11-25 10:02:51,288 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 85.270   Top5: 99.250]
2022-11-25 10:02:56,582 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 10:02:56,584 - INFO  - >>>>>> Epoch  24
2022-11-25 10:02:56,586 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:03:06,058 - INFO  - Training [24][   20/  196]   Loss 0.504607   Top1 83.125000   Top5 98.027344   BatchTime 0.473466   LR 0.000500   
2022-11-25 10:03:13,324 - INFO  - Training [24][   40/  196]   Loss 0.496771   Top1 83.652344   Top5 98.144531   BatchTime 0.418396   LR 0.000484   
2022-11-25 10:03:20,932 - INFO  - Training [24][   60/  196]   Loss 0.494462   Top1 83.743490   Top5 98.196615   BatchTime 0.405725   LR 0.000468   
2022-11-25 10:03:28,223 - INFO  - Training [24][   80/  196]   Loss 0.495401   Top1 83.857422   Top5 98.339844   BatchTime 0.395423   LR 0.000453   
2022-11-25 10:03:35,569 - INFO  - Training [24][  100/  196]   Loss 0.486052   Top1 84.218750   Top5 98.429688   BatchTime 0.389797   LR 0.000437   
2022-11-25 10:03:42,780 - INFO  - Training [24][  120/  196]   Loss 0.479385   Top1 84.485677   Top5 98.548177   BatchTime 0.384927   LR 0.000422   
2022-11-25 10:03:50,817 - INFO  - Training [24][  140/  196]   Loss 0.476868   Top1 84.642857   Top5 98.630022   BatchTime 0.387339   LR 0.000407   
2022-11-25 10:03:58,207 - INFO  - Training [24][  160/  196]   Loss 0.478051   Top1 84.614258   Top5 98.627930   BatchTime 0.385112   LR 0.000392   
2022-11-25 10:04:05,643 - INFO  - Training [24][  180/  196]   Loss 0.479265   Top1 84.526910   Top5 98.576389   BatchTime 0.383633   LR 0.000378   
2022-11-25 10:04:11,148 - INFO  - ==> Top1: 84.488    Top5: 98.562    Loss: 0.481

2022-11-25 10:04:11,462 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:04:13,235 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:04:16,149 - INFO  - Validation [24][   20/   40]   Loss 0.453815   Top1 85.781250   Top5 99.160156   BatchTime 0.145579   
2022-11-25 10:04:17,358 - INFO  - Validation [24][   40/   40]   Loss 0.440520   Top1 85.660000   Top5 99.250000   BatchTime 0.103021   
2022-11-25 10:04:17,560 - INFO  - ==> Top1: 85.660    Top5: 99.250    Loss: 0.441

2022-11-25 10:04:17,560 - INFO  - ==> Sparsity : 0.568

2022-11-25 10:04:17,561 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 86.860   Top5: 99.590]
2022-11-25 10:04:17,561 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 86.470   Top5: 99.420]
2022-11-25 10:04:17,561 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 85.660   Top5: 99.250]
2022-11-25 10:04:17,958 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:04:17,960 - INFO  - >>>>>> Epoch  25
2022-11-25 10:04:17,962 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:04:26,290 - INFO  - Training [25][   20/  196]   Loss 0.488460   Top1 83.886719   Top5 97.929688   BatchTime 0.416299   LR 0.000353   
2022-11-25 10:04:33,668 - INFO  - Training [25][   40/  196]   Loss 0.488458   Top1 84.169922   Top5 98.222656   BatchTime 0.392595   LR 0.000339   
2022-11-25 10:04:40,957 - INFO  - Training [25][   60/  196]   Loss 0.485577   Top1 84.153646   Top5 98.378906   BatchTime 0.383203   LR 0.000325   
2022-11-25 10:04:48,278 - INFO  - Training [25][   80/  196]   Loss 0.479177   Top1 84.375000   Top5 98.505859   BatchTime 0.378917   LR 0.000312   
2022-11-25 10:04:55,622 - INFO  - Training [25][  100/  196]   Loss 0.473713   Top1 84.515625   Top5 98.570312   BatchTime 0.376569   LR 0.000299   
2022-11-25 10:05:02,739 - INFO  - Training [25][  120/  196]   Loss 0.468267   Top1 84.700521   Top5 98.639323   BatchTime 0.373116   LR 0.000286   
2022-11-25 10:05:10,073 - INFO  - Training [25][  140/  196]   Loss 0.466264   Top1 84.773996   Top5 98.705357   BatchTime 0.372200   LR 0.000273   
2022-11-25 10:05:17,442 - INFO  - Training [25][  160/  196]   Loss 0.471309   Top1 84.614258   Top5 98.659668   BatchTime 0.371728   LR 0.000261   
2022-11-25 10:05:24,632 - INFO  - Training [25][  180/  196]   Loss 0.469250   Top1 84.704861   Top5 98.650174   BatchTime 0.370371   LR 0.000248   
2022-11-25 10:05:30,470 - INFO  - ==> Top1: 84.766    Top5: 98.634    Loss: 0.469

2022-11-25 10:05:30,782 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:05:32,401 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:05:35,094 - INFO  - Validation [25][   20/   40]   Loss 0.555431   Top1 82.324219   Top5 98.750000   BatchTime 0.134524   
2022-11-25 10:05:36,298 - INFO  - Validation [25][   40/   40]   Loss 0.547961   Top1 81.950000   Top5 98.900000   BatchTime 0.097374   
2022-11-25 10:05:36,503 - INFO  - ==> Top1: 81.950    Top5: 98.900    Loss: 0.548

2022-11-25 10:05:36,503 - INFO  - ==> Sparsity : 0.576

2022-11-25 10:05:36,504 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 86.860   Top5: 99.590]
2022-11-25 10:05:36,504 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 86.470   Top5: 99.420]
2022-11-25 10:05:36,504 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 85.660   Top5: 99.250]
2022-11-25 10:05:36,668 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:05:36,670 - INFO  - >>>>>> Epoch  26
2022-11-25 10:05:36,671 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:05:46,040 - INFO  - Training [26][   20/  196]   Loss 0.486573   Top1 83.535156   Top5 98.105469   BatchTime 0.468312   LR 0.000228   
2022-11-25 10:05:53,505 - INFO  - Training [26][   40/  196]   Loss 0.487217   Top1 83.544922   Top5 98.359375   BatchTime 0.420781   LR 0.000216   
2022-11-25 10:06:00,906 - INFO  - Training [26][   60/  196]   Loss 0.486966   Top1 83.561198   Top5 98.398438   BatchTime 0.403867   LR 0.000205   
2022-11-25 10:06:09,141 - INFO  - Training [26][   80/  196]   Loss 0.480594   Top1 83.876953   Top5 98.525391   BatchTime 0.405834   LR 0.000194   
2022-11-25 10:06:17,296 - INFO  - Training [26][  100/  196]   Loss 0.475226   Top1 84.125000   Top5 98.562500   BatchTime 0.406212   LR 0.000183   
2022-11-25 10:06:24,279 - INFO  - Training [26][  120/  196]   Loss 0.470667   Top1 84.466146   Top5 98.632812   BatchTime 0.396705   LR 0.000173   
2022-11-25 10:06:31,473 - INFO  - Training [26][  140/  196]   Loss 0.469156   Top1 84.430804   Top5 98.699777   BatchTime 0.391420   LR 0.000163   
2022-11-25 10:06:39,283 - INFO  - Training [26][  160/  196]   Loss 0.470097   Top1 84.501953   Top5 98.662109   BatchTime 0.391299   LR 0.000153   
2022-11-25 10:06:46,549 - INFO  - Training [26][  180/  196]   Loss 0.469527   Top1 84.576823   Top5 98.617622   BatchTime 0.388189   LR 0.000144   
2022-11-25 10:06:52,322 - INFO  - ==> Top1: 84.700    Top5: 98.622    Loss: 0.467

2022-11-25 10:06:52,583 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:06:54,126 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:06:57,699 - INFO  - Validation [26][   20/   40]   Loss 0.612007   Top1 80.488281   Top5 98.554688   BatchTime 0.178542   
2022-11-25 10:06:59,939 - INFO  - Validation [26][   40/   40]   Loss 0.604029   Top1 80.470000   Top5 98.690000   BatchTime 0.145300   
2022-11-25 10:07:00,316 - INFO  - ==> Top1: 80.470    Top5: 98.690    Loss: 0.604

2022-11-25 10:07:00,316 - INFO  - ==> Sparsity : 0.596

2022-11-25 10:07:00,317 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 86.860   Top5: 99.590]
2022-11-25 10:07:00,317 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 86.470   Top5: 99.420]
2022-11-25 10:07:00,317 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 85.660   Top5: 99.250]
2022-11-25 10:07:00,438 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:07:00,439 - INFO  - >>>>>> Epoch  27
2022-11-25 10:07:00,441 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:07:09,662 - INFO  - Training [27][   20/  196]   Loss 0.478161   Top1 84.179688   Top5 98.125000   BatchTime 0.460919   LR 0.000128   
2022-11-25 10:07:16,872 - INFO  - Training [27][   40/  196]   Loss 0.490316   Top1 83.837891   Top5 98.222656   BatchTime 0.410709   LR 0.000119   
2022-11-25 10:07:24,041 - INFO  - Training [27][   60/  196]   Loss 0.473794   Top1 84.277344   Top5 98.346354   BatchTime 0.393290   LR 0.000111   
2022-11-25 10:07:31,166 - INFO  - Training [27][   80/  196]   Loss 0.469394   Top1 84.560547   Top5 98.471680   BatchTime 0.384031   LR 0.000102   
2022-11-25 10:07:38,026 - INFO  - Training [27][  100/  196]   Loss 0.466247   Top1 84.750000   Top5 98.500000   BatchTime 0.375822   LR 0.000095   
2022-11-25 10:07:45,276 - INFO  - Training [27][  120/  196]   Loss 0.459409   Top1 84.996745   Top5 98.610026   BatchTime 0.373602   LR 0.000087   
2022-11-25 10:07:52,387 - INFO  - Training [27][  140/  196]   Loss 0.457389   Top1 85.125558   Top5 98.649554   BatchTime 0.371020   LR 0.000080   
2022-11-25 10:07:59,128 - INFO  - Training [27][  160/  196]   Loss 0.459117   Top1 85.126953   Top5 98.598633   BatchTime 0.366775   LR 0.000073   
2022-11-25 10:08:06,377 - INFO  - Training [27][  180/  196]   Loss 0.457898   Top1 85.162760   Top5 98.602431   BatchTime 0.366293   LR 0.000066   
2022-11-25 10:08:11,918 - INFO  - ==> Top1: 85.174    Top5: 98.602    Loss: 0.457

2022-11-25 10:08:12,299 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:08:13,896 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:08:18,260 - INFO  - Validation [27][   20/   40]   Loss 0.430821   Top1 86.074219   Top5 99.238281   BatchTime 0.218097   
2022-11-25 10:08:19,881 - INFO  - Validation [27][   40/   40]   Loss 0.415671   Top1 86.480000   Top5 99.380000   BatchTime 0.149593   
2022-11-25 10:08:20,118 - INFO  - ==> Top1: 86.480    Top5: 99.380    Loss: 0.416

2022-11-25 10:08:20,118 - INFO  - ==> Sparsity : 0.595

2022-11-25 10:08:20,119 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 86.860   Top5: 99.590]
2022-11-25 10:08:20,119 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 86.480   Top5: 99.380]
2022-11-25 10:08:20,119 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 86.470   Top5: 99.420]
2022-11-25 10:08:20,267 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:08:20,269 - INFO  - >>>>>> Epoch  28
2022-11-25 10:08:20,270 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:08:30,119 - INFO  - Training [28][   20/  196]   Loss 0.465974   Top1 84.804688   Top5 98.320312   BatchTime 0.492282   LR 0.000055   
2022-11-25 10:08:38,171 - INFO  - Training [28][   40/  196]   Loss 0.471322   Top1 84.687500   Top5 98.515625   BatchTime 0.447462   LR 0.000050   
2022-11-25 10:08:46,100 - INFO  - Training [28][   60/  196]   Loss 0.475010   Top1 84.674479   Top5 98.535156   BatchTime 0.430450   LR 0.000044   
2022-11-25 10:08:53,636 - INFO  - Training [28][   80/  196]   Loss 0.473061   Top1 84.750977   Top5 98.681641   BatchTime 0.417038   LR 0.000039   
2022-11-25 10:09:01,474 - INFO  - Training [28][  100/  196]   Loss 0.465094   Top1 84.984375   Top5 98.675781   BatchTime 0.412007   LR 0.000034   
2022-11-25 10:09:09,159 - INFO  - Training [28][  120/  196]   Loss 0.454803   Top1 85.364583   Top5 98.763021   BatchTime 0.407385   LR 0.000030   
2022-11-25 10:09:16,296 - INFO  - Training [28][  140/  196]   Loss 0.453661   Top1 85.415737   Top5 98.805804   BatchTime 0.400159   LR 0.000026   
2022-11-25 10:09:23,652 - INFO  - Training [28][  160/  196]   Loss 0.456975   Top1 85.234375   Top5 98.776855   BatchTime 0.396115   LR 0.000022   
2022-11-25 10:09:30,869 - INFO  - Training [28][  180/  196]   Loss 0.456601   Top1 85.190972   Top5 98.700087   BatchTime 0.392194   LR 0.000018   
2022-11-25 10:09:36,539 - INFO  - ==> Top1: 85.292    Top5: 98.702    Loss: 0.454

2022-11-25 10:09:36,753 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:09:37,774 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:09:40,442 - INFO  - Validation [28][   20/   40]   Loss 0.366365   Top1 88.496094   Top5 99.531250   BatchTime 0.133311   
2022-11-25 10:09:41,541 - INFO  - Validation [28][   40/   40]   Loss 0.350466   Top1 88.660000   Top5 99.590000   BatchTime 0.094141   
2022-11-25 10:09:41,769 - INFO  - ==> Top1: 88.660    Top5: 99.590    Loss: 0.350

2022-11-25 10:09:41,769 - INFO  - ==> Sparsity : 0.600

2022-11-25 10:09:41,769 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:09:41,770 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 86.860   Top5: 99.590]
2022-11-25 10:09:41,770 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 86.480   Top5: 99.380]
2022-11-25 10:09:47,931 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 10:09:47,936 - INFO  - >>>>>> Epoch  29
2022-11-25 10:09:47,939 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:09:56,790 - INFO  - Training [29][   20/  196]   Loss 0.477132   Top1 84.277344   Top5 98.066406   BatchTime 0.442384   LR 0.000013   
2022-11-25 10:10:04,363 - INFO  - Training [29][   40/  196]   Loss 0.467907   Top1 84.667969   Top5 98.242188   BatchTime 0.410508   LR 0.000010   
2022-11-25 10:10:11,665 - INFO  - Training [29][   60/  196]   Loss 0.471246   Top1 84.667969   Top5 98.378906   BatchTime 0.395377   LR 0.000008   
2022-11-25 10:10:19,141 - INFO  - Training [29][   80/  196]   Loss 0.460224   Top1 85.078125   Top5 98.471680   BatchTime 0.389984   LR 0.000005   
2022-11-25 10:10:26,566 - INFO  - Training [29][  100/  196]   Loss 0.453417   Top1 85.414062   Top5 98.546875   BatchTime 0.386229   LR 0.000004   
2022-11-25 10:10:34,043 - INFO  - Training [29][  120/  196]   Loss 0.449544   Top1 85.569661   Top5 98.613281   BatchTime 0.384166   LR 0.000002   
2022-11-25 10:10:41,491 - INFO  - Training [29][  140/  196]   Loss 0.450951   Top1 85.544085   Top5 98.652344   BatchTime 0.382485   LR 0.000001   
2022-11-25 10:10:48,066 - INFO  - Training [29][  160/  196]   Loss 0.454611   Top1 85.371094   Top5 98.632812   BatchTime 0.375767   LR 0.000001   
2022-11-25 10:10:54,866 - INFO  - Training [29][  180/  196]   Loss 0.453850   Top1 85.401476   Top5 98.613281   BatchTime 0.371793   LR 0.000000   
2022-11-25 10:11:01,201 - INFO  - ==> Top1: 85.402    Top5: 98.608    Loss: 0.453

2022-11-25 10:11:01,472 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:11:03,039 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:11:05,737 - INFO  - Validation [29][   20/   40]   Loss 0.381476   Top1 87.402344   Top5 99.550781   BatchTime 0.134815   
2022-11-25 10:11:06,885 - INFO  - Validation [29][   40/   40]   Loss 0.371006   Top1 87.360000   Top5 99.600000   BatchTime 0.096105   
2022-11-25 10:11:07,108 - INFO  - ==> Top1: 87.360    Top5: 99.600    Loss: 0.371

2022-11-25 10:11:07,108 - INFO  - ==> Sparsity : 0.601

2022-11-25 10:11:07,109 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:11:07,109 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 87.360   Top5: 99.600]
2022-11-25 10:11:07,109 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 86.860   Top5: 99.590]
2022-11-25 10:11:07,276 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:11:07,278 - INFO  - >>>>>> Epoch  30
2022-11-25 10:11:07,279 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:11:16,250 - INFO  - Training [30][   20/  196]   Loss 0.489592   Top1 84.003906   Top5 98.222656   BatchTime 0.448367   LR 0.001250   
2022-11-25 10:11:23,924 - INFO  - Training [30][   40/  196]   Loss 0.491876   Top1 84.033203   Top5 98.310547   BatchTime 0.416047   LR 0.001250   
2022-11-25 10:11:31,072 - INFO  - Training [30][   60/  196]   Loss 0.503221   Top1 83.619792   Top5 98.313802   BatchTime 0.396495   LR 0.001250   
2022-11-25 10:11:38,614 - INFO  - Training [30][   80/  196]   Loss 0.507106   Top1 83.417969   Top5 98.388672   BatchTime 0.391646   LR 0.001250   
2022-11-25 10:11:46,252 - INFO  - Training [30][  100/  196]   Loss 0.502589   Top1 83.726562   Top5 98.464844   BatchTime 0.389690   LR 0.001250   
2022-11-25 10:11:53,605 - INFO  - Training [30][  120/  196]   Loss 0.496589   Top1 83.997396   Top5 98.512370   BatchTime 0.386016   LR 0.001249   
2022-11-25 10:12:00,883 - INFO  - Training [30][  140/  196]   Loss 0.495232   Top1 84.123884   Top5 98.537946   BatchTime 0.382858   LR 0.001249   
2022-11-25 10:12:07,070 - INFO  - Training [30][  160/  196]   Loss 0.495170   Top1 84.121094   Top5 98.564453   BatchTime 0.373670   LR 0.001249   
2022-11-25 10:12:13,560 - INFO  - Training [30][  180/  196]   Loss 0.498508   Top1 83.999566   Top5 98.515625   BatchTime 0.368203   LR 0.001248   
2022-11-25 10:12:19,477 - INFO  - ==> Top1: 83.952    Top5: 98.498    Loss: 0.500

2022-11-25 10:12:19,756 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:12:21,431 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:12:24,030 - INFO  - Validation [30][   20/   40]   Loss 0.501358   Top1 84.355469   Top5 99.335938   BatchTime 0.129846   
2022-11-25 10:12:25,086 - INFO  - Validation [30][   40/   40]   Loss 0.484971   Top1 84.600000   Top5 99.410000   BatchTime 0.091318   
2022-11-25 10:12:25,336 - INFO  - ==> Top1: 84.600    Top5: 99.410    Loss: 0.485

2022-11-25 10:12:25,337 - INFO  - ==> Sparsity : 0.490

2022-11-25 10:12:25,337 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:12:25,337 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 87.360   Top5: 99.600]
2022-11-25 10:12:25,338 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 86.860   Top5: 99.590]
2022-11-25 10:12:25,698 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:12:25,700 - INFO  - >>>>>> Epoch  31
2022-11-25 10:12:25,702 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:12:33,444 - INFO  - Training [31][   20/  196]   Loss 0.528666   Top1 82.617188   Top5 97.812500   BatchTime 0.386935   LR 0.001248   
2022-11-25 10:12:38,642 - INFO  - Training [31][   40/  196]   Loss 0.524968   Top1 82.705078   Top5 97.968750   BatchTime 0.323422   LR 0.001247   
2022-11-25 10:12:44,468 - INFO  - Training [31][   60/  196]   Loss 0.516382   Top1 82.988281   Top5 98.190104   BatchTime 0.312720   LR 0.001247   
2022-11-25 10:12:50,057 - INFO  - Training [31][   80/  196]   Loss 0.510567   Top1 83.222656   Top5 98.334961   BatchTime 0.304401   LR 0.001246   
2022-11-25 10:12:56,251 - INFO  - Training [31][  100/  196]   Loss 0.504646   Top1 83.574219   Top5 98.367188   BatchTime 0.305454   LR 0.001246   
2022-11-25 10:13:01,728 - INFO  - Training [31][  120/  196]   Loss 0.503322   Top1 83.675130   Top5 98.437500   BatchTime 0.300187   LR 0.001245   
2022-11-25 10:13:07,538 - INFO  - Training [31][  140/  196]   Loss 0.505353   Top1 83.627232   Top5 98.440290   BatchTime 0.298803   LR 0.001244   
2022-11-25 10:13:14,681 - INFO  - Training [31][  160/  196]   Loss 0.507737   Top1 83.535156   Top5 98.425293   BatchTime 0.306094   LR 0.001244   
2022-11-25 10:13:21,671 - INFO  - Training [31][  180/  196]   Loss 0.506416   Top1 83.615451   Top5 98.372396   BatchTime 0.310920   LR 0.001243   
2022-11-25 10:13:27,534 - INFO  - ==> Top1: 83.654    Top5: 98.390    Loss: 0.505

2022-11-25 10:13:27,823 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:13:29,493 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:13:32,196 - INFO  - Validation [31][   20/   40]   Loss 0.416449   Top1 86.210938   Top5 99.453125   BatchTime 0.135089   
2022-11-25 10:13:33,214 - INFO  - Validation [31][   40/   40]   Loss 0.407952   Top1 86.160000   Top5 99.520000   BatchTime 0.093000   
2022-11-25 10:13:33,461 - INFO  - ==> Top1: 86.160    Top5: 99.520    Loss: 0.408

2022-11-25 10:13:33,462 - INFO  - ==> Sparsity : 0.547

2022-11-25 10:13:33,462 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:13:33,462 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 87.360   Top5: 99.600]
2022-11-25 10:13:33,462 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 86.860   Top5: 99.590]
2022-11-25 10:13:33,600 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:13:33,602 - INFO  - >>>>>> Epoch  32
2022-11-25 10:13:33,603 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:13:42,493 - INFO  - Training [32][   20/  196]   Loss 0.513219   Top1 83.339844   Top5 98.027344   BatchTime 0.444378   LR 0.001242   
2022-11-25 10:13:50,472 - INFO  - Training [32][   40/  196]   Loss 0.517268   Top1 83.447266   Top5 98.164062   BatchTime 0.421645   LR 0.001241   
2022-11-25 10:13:57,700 - INFO  - Training [32][   60/  196]   Loss 0.509576   Top1 83.665365   Top5 98.300781   BatchTime 0.401576   LR 0.001240   
2022-11-25 10:14:04,971 - INFO  - Training [32][   80/  196]   Loss 0.506395   Top1 83.808594   Top5 98.422852   BatchTime 0.392068   LR 0.001239   
2022-11-25 10:14:11,932 - INFO  - Training [32][  100/  196]   Loss 0.498714   Top1 84.058594   Top5 98.492188   BatchTime 0.383257   LR 0.001238   
2022-11-25 10:14:18,589 - INFO  - Training [32][  120/  196]   Loss 0.493247   Top1 84.251302   Top5 98.593750   BatchTime 0.374858   LR 0.001237   
2022-11-25 10:14:25,421 - INFO  - Training [32][  140/  196]   Loss 0.496350   Top1 84.143415   Top5 98.618862   BatchTime 0.370107   LR 0.001236   
2022-11-25 10:14:31,815 - INFO  - Training [32][  160/  196]   Loss 0.498198   Top1 84.025879   Top5 98.579102   BatchTime 0.363804   LR 0.001235   
2022-11-25 10:14:36,918 - INFO  - Training [32][  180/  196]   Loss 0.496796   Top1 84.025608   Top5 98.546007   BatchTime 0.351732   LR 0.001234   
2022-11-25 10:14:42,437 - INFO  - ==> Top1: 84.128    Top5: 98.534    Loss: 0.495

2022-11-25 10:14:42,725 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:14:46,212 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:14:49,092 - INFO  - Validation [32][   20/   40]   Loss 0.565584   Top1 80.859375   Top5 99.160156   BatchTime 0.143916   
2022-11-25 10:14:50,161 - INFO  - Validation [32][   40/   40]   Loss 0.569154   Top1 80.890000   Top5 99.090000   BatchTime 0.098689   
2022-11-25 10:14:50,404 - INFO  - ==> Top1: 80.890    Top5: 99.090    Loss: 0.569

2022-11-25 10:14:50,404 - INFO  - ==> Sparsity : 0.549

2022-11-25 10:14:50,405 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:14:50,405 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 87.360   Top5: 99.600]
2022-11-25 10:14:50,405 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 86.860   Top5: 99.590]
2022-11-25 10:14:50,542 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:14:50,544 - INFO  - >>>>>> Epoch  33
2022-11-25 10:14:50,546 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:14:59,393 - INFO  - Training [33][   20/  196]   Loss 0.519354   Top1 82.792969   Top5 98.007812   BatchTime 0.442213   LR 0.001232   
2022-11-25 10:15:06,300 - INFO  - Training [33][   40/  196]   Loss 0.508692   Top1 83.359375   Top5 98.212891   BatchTime 0.393792   LR 0.001230   
2022-11-25 10:15:13,926 - INFO  - Training [33][   60/  196]   Loss 0.507832   Top1 83.470052   Top5 98.287760   BatchTime 0.389625   LR 0.001229   
2022-11-25 10:15:21,318 - INFO  - Training [33][   80/  196]   Loss 0.501832   Top1 83.813477   Top5 98.413086   BatchTime 0.384620   LR 0.001228   
2022-11-25 10:15:28,915 - INFO  - Training [33][  100/  196]   Loss 0.497673   Top1 83.812500   Top5 98.460938   BatchTime 0.383661   LR 0.001226   
2022-11-25 10:15:36,169 - INFO  - Training [33][  120/  196]   Loss 0.492308   Top1 84.026693   Top5 98.515625   BatchTime 0.380169   LR 0.001225   
2022-11-25 10:15:43,647 - INFO  - Training [33][  140/  196]   Loss 0.491423   Top1 84.023438   Top5 98.579799   BatchTime 0.379269   LR 0.001224   
2022-11-25 10:15:50,988 - INFO  - Training [33][  160/  196]   Loss 0.494254   Top1 83.918457   Top5 98.581543   BatchTime 0.377741   LR 0.001222   
2022-11-25 10:15:57,137 - INFO  - Training [33][  180/  196]   Loss 0.495113   Top1 83.875868   Top5 98.543837   BatchTime 0.369931   LR 0.001221   
2022-11-25 10:16:01,293 - INFO  - ==> Top1: 83.996    Top5: 98.554    Loss: 0.493

2022-11-25 10:16:01,497 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:16:03,121 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:16:05,857 - INFO  - Validation [33][   20/   40]   Loss 0.386318   Top1 87.734375   Top5 99.375000   BatchTime 0.136703   
2022-11-25 10:16:06,875 - INFO  - Validation [33][   40/   40]   Loss 0.368664   Top1 87.970000   Top5 99.510000   BatchTime 0.093799   
2022-11-25 10:16:07,101 - INFO  - ==> Top1: 87.970    Top5: 99.510    Loss: 0.369

2022-11-25 10:16:07,101 - INFO  - ==> Sparsity : 0.505

2022-11-25 10:16:07,101 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:16:07,102 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 87.970   Top5: 99.510]
2022-11-25 10:16:07,102 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 87.360   Top5: 99.600]
2022-11-25 10:16:07,219 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:16:07,221 - INFO  - >>>>>> Epoch  34
2022-11-25 10:16:07,223 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:16:16,228 - INFO  - Training [34][   20/  196]   Loss 0.511152   Top1 83.496094   Top5 97.871094   BatchTime 0.450128   LR 0.001218   
2022-11-25 10:16:23,563 - INFO  - Training [34][   40/  196]   Loss 0.506081   Top1 83.486328   Top5 98.134766   BatchTime 0.408455   LR 0.001216   
2022-11-25 10:16:30,914 - INFO  - Training [34][   60/  196]   Loss 0.500099   Top1 83.919271   Top5 98.177083   BatchTime 0.394811   LR 0.001215   
2022-11-25 10:16:37,945 - INFO  - Training [34][   80/  196]   Loss 0.490488   Top1 84.165039   Top5 98.364258   BatchTime 0.383996   LR 0.001213   
2022-11-25 10:16:44,815 - INFO  - Training [34][  100/  196]   Loss 0.485468   Top1 84.308594   Top5 98.460938   BatchTime 0.375901   LR 0.001211   
2022-11-25 10:16:52,400 - INFO  - Training [34][  120/  196]   Loss 0.481886   Top1 84.567057   Top5 98.479818   BatchTime 0.376457   LR 0.001209   
2022-11-25 10:16:59,629 - INFO  - Training [34][  140/  196]   Loss 0.480995   Top1 84.575893   Top5 98.523996   BatchTime 0.374312   LR 0.001208   
2022-11-25 10:17:06,790 - INFO  - Training [34][  160/  196]   Loss 0.482815   Top1 84.494629   Top5 98.520508   BatchTime 0.372275   LR 0.001206   
2022-11-25 10:17:14,165 - INFO  - Training [34][  180/  196]   Loss 0.484742   Top1 84.379340   Top5 98.496094   BatchTime 0.371882   LR 0.001204   
2022-11-25 10:17:19,710 - INFO  - ==> Top1: 84.358    Top5: 98.496    Loss: 0.484

2022-11-25 10:17:19,912 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:17:21,088 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:17:23,909 - INFO  - Validation [34][   20/   40]   Loss 0.455394   Top1 86.289062   Top5 99.199219   BatchTime 0.140913   
2022-11-25 10:17:25,054 - INFO  - Validation [34][   40/   40]   Loss 0.436784   Top1 86.570000   Top5 99.370000   BatchTime 0.099092   
2022-11-25 10:17:25,289 - INFO  - ==> Top1: 86.570    Top5: 99.370    Loss: 0.437

2022-11-25 10:17:25,290 - INFO  - ==> Sparsity : 0.506

2022-11-25 10:17:25,290 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:17:25,290 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 87.970   Top5: 99.510]
2022-11-25 10:17:25,290 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 87.360   Top5: 99.600]
2022-11-25 10:17:25,409 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:17:25,411 - INFO  - >>>>>> Epoch  35
2022-11-25 10:17:25,413 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:17:34,360 - INFO  - Training [35][   20/  196]   Loss 0.487882   Top1 84.062500   Top5 97.910156   BatchTime 0.447210   LR 0.001201   
2022-11-25 10:17:41,879 - INFO  - Training [35][   40/  196]   Loss 0.489753   Top1 84.042969   Top5 98.261719   BatchTime 0.411591   LR 0.001199   
2022-11-25 10:17:49,614 - INFO  - Training [35][   60/  196]   Loss 0.482165   Top1 84.322917   Top5 98.391927   BatchTime 0.403311   LR 0.001197   
2022-11-25 10:17:57,336 - INFO  - Training [35][   80/  196]   Loss 0.483615   Top1 84.462891   Top5 98.457031   BatchTime 0.398999   LR 0.001195   
2022-11-25 10:18:04,762 - INFO  - Training [35][  100/  196]   Loss 0.480593   Top1 84.523438   Top5 98.515625   BatchTime 0.393466   LR 0.001192   
2022-11-25 10:18:11,920 - INFO  - Training [35][  120/  196]   Loss 0.479497   Top1 84.570312   Top5 98.554688   BatchTime 0.387531   LR 0.001190   
2022-11-25 10:18:19,213 - INFO  - Training [35][  140/  196]   Loss 0.476973   Top1 84.634487   Top5 98.610491   BatchTime 0.384263   LR 0.001188   
2022-11-25 10:18:26,587 - INFO  - Training [35][  160/  196]   Loss 0.480723   Top1 84.501953   Top5 98.569336   BatchTime 0.382317   LR 0.001186   
2022-11-25 10:18:33,930 - INFO  - Training [35][  180/  196]   Loss 0.480737   Top1 84.459635   Top5 98.554688   BatchTime 0.380635   LR 0.001184   
2022-11-25 10:18:39,395 - INFO  - ==> Top1: 84.488    Top5: 98.562    Loss: 0.479

2022-11-25 10:18:39,662 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:18:41,098 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:18:44,744 - INFO  - Validation [35][   20/   40]   Loss 0.394624   Top1 86.386719   Top5 99.316406   BatchTime 0.182183   
2022-11-25 10:18:46,802 - INFO  - Validation [35][   40/   40]   Loss 0.375699   Top1 87.010000   Top5 99.410000   BatchTime 0.142552   
2022-11-25 10:18:47,019 - INFO  - ==> Top1: 87.010    Top5: 99.410    Loss: 0.376

2022-11-25 10:18:47,019 - INFO  - ==> Sparsity : 0.536

2022-11-25 10:18:47,019 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:18:47,019 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 87.970   Top5: 99.510]
2022-11-25 10:18:47,020 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 87.360   Top5: 99.600]
2022-11-25 10:18:47,182 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:18:47,184 - INFO  - >>>>>> Epoch  36
2022-11-25 10:18:47,185 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:18:56,408 - INFO  - Training [36][   20/  196]   Loss 0.504932   Top1 83.730469   Top5 97.851562   BatchTime 0.460977   LR 0.001180   
2022-11-25 10:19:03,388 - INFO  - Training [36][   40/  196]   Loss 0.497213   Top1 83.896484   Top5 98.144531   BatchTime 0.405004   LR 0.001177   
2022-11-25 10:19:10,660 - INFO  - Training [36][   60/  196]   Loss 0.486056   Top1 84.440104   Top5 98.339844   BatchTime 0.391194   LR 0.001175   
2022-11-25 10:19:17,725 - INFO  - Training [36][   80/  196]   Loss 0.485600   Top1 84.516602   Top5 98.461914   BatchTime 0.381708   LR 0.001173   
2022-11-25 10:19:25,248 - INFO  - Training [36][  100/  196]   Loss 0.480926   Top1 84.636719   Top5 98.464844   BatchTime 0.380590   LR 0.001170   
2022-11-25 10:19:32,626 - INFO  - Training [36][  120/  196]   Loss 0.473593   Top1 84.899089   Top5 98.548177   BatchTime 0.378644   LR 0.001168   
2022-11-25 10:19:39,767 - INFO  - Training [36][  140/  196]   Loss 0.471595   Top1 84.919085   Top5 98.596540   BatchTime 0.375557   LR 0.001165   
2022-11-25 10:19:46,994 - INFO  - Training [36][  160/  196]   Loss 0.477291   Top1 84.770508   Top5 98.559570   BatchTime 0.373784   LR 0.001163   
2022-11-25 10:19:54,445 - INFO  - Training [36][  180/  196]   Loss 0.476106   Top1 84.778646   Top5 98.500434   BatchTime 0.373646   LR 0.001160   
2022-11-25 10:19:59,825 - INFO  - ==> Top1: 84.734    Top5: 98.510    Loss: 0.476

2022-11-25 10:20:00,071 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:20:01,617 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:20:04,665 - INFO  - Validation [36][   20/   40]   Loss 0.469235   Top1 84.531250   Top5 99.101562   BatchTime 0.152315   
2022-11-25 10:20:05,993 - INFO  - Validation [36][   40/   40]   Loss 0.471515   Top1 84.380000   Top5 99.280000   BatchTime 0.109365   
2022-11-25 10:20:06,533 - INFO  - ==> Top1: 84.380    Top5: 99.280    Loss: 0.472

2022-11-25 10:20:06,533 - INFO  - ==> Sparsity : 0.542

2022-11-25 10:20:06,533 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:20:06,534 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 87.970   Top5: 99.510]
2022-11-25 10:20:06,534 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 87.360   Top5: 99.600]
2022-11-25 10:20:06,675 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:20:06,676 - INFO  - >>>>>> Epoch  37
2022-11-25 10:20:06,678 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:20:13,662 - INFO  - Training [37][   20/  196]   Loss 0.502388   Top1 83.652344   Top5 97.968750   BatchTime 0.349067   LR 0.001155   
2022-11-25 10:20:20,273 - INFO  - Training [37][   40/  196]   Loss 0.500438   Top1 84.033203   Top5 98.173828   BatchTime 0.339798   LR 0.001153   
2022-11-25 10:20:27,633 - INFO  - Training [37][   60/  196]   Loss 0.488819   Top1 84.329427   Top5 98.287760   BatchTime 0.349204   LR 0.001150   
2022-11-25 10:20:35,224 - INFO  - Training [37][   80/  196]   Loss 0.488206   Top1 84.296875   Top5 98.417969   BatchTime 0.356778   LR 0.001147   
2022-11-25 10:20:42,360 - INFO  - Training [37][  100/  196]   Loss 0.480269   Top1 84.503906   Top5 98.484375   BatchTime 0.356785   LR 0.001144   
2022-11-25 10:20:49,988 - INFO  - Training [37][  120/  196]   Loss 0.475041   Top1 84.661458   Top5 98.548177   BatchTime 0.360890   LR 0.001142   
2022-11-25 10:20:57,657 - INFO  - Training [37][  140/  196]   Loss 0.472019   Top1 84.807478   Top5 98.602121   BatchTime 0.364109   LR 0.001139   
2022-11-25 10:21:04,740 - INFO  - Training [37][  160/  196]   Loss 0.473950   Top1 84.719238   Top5 98.627930   BatchTime 0.362863   LR 0.001136   
2022-11-25 10:21:12,239 - INFO  - Training [37][  180/  196]   Loss 0.475921   Top1 84.674479   Top5 98.565538   BatchTime 0.364207   LR 0.001133   
2022-11-25 10:21:17,887 - INFO  - ==> Top1: 84.752    Top5: 98.600    Loss: 0.472

2022-11-25 10:21:18,231 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:21:20,155 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:21:22,902 - INFO  - Validation [37][   20/   40]   Loss 0.357450   Top1 88.437500   Top5 99.531250   BatchTime 0.137259   
2022-11-25 10:21:23,935 - INFO  - Validation [37][   40/   40]   Loss 0.344319   Top1 88.610000   Top5 99.660000   BatchTime 0.094449   
2022-11-25 10:21:24,166 - INFO  - ==> Top1: 88.610    Top5: 99.660    Loss: 0.344

2022-11-25 10:21:24,166 - INFO  - ==> Sparsity : 0.520

2022-11-25 10:21:24,166 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:21:24,166 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 88.610   Top5: 99.660]
2022-11-25 10:21:24,167 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 87.970   Top5: 99.510]
2022-11-25 10:21:24,310 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:21:24,312 - INFO  - >>>>>> Epoch  38
2022-11-25 10:21:24,314 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:21:32,092 - INFO  - Training [38][   20/  196]   Loss 0.476278   Top1 85.078125   Top5 98.183594   BatchTime 0.388785   LR 0.001128   
2022-11-25 10:21:38,103 - INFO  - Training [38][   40/  196]   Loss 0.481140   Top1 84.667969   Top5 98.398438   BatchTime 0.344668   LR 0.001125   
2022-11-25 10:21:46,539 - INFO  - Training [38][   60/  196]   Loss 0.479355   Top1 84.680990   Top5 98.489583   BatchTime 0.370374   LR 0.001122   
2022-11-25 10:21:54,008 - INFO  - Training [38][   80/  196]   Loss 0.478294   Top1 84.599609   Top5 98.500977   BatchTime 0.371144   LR 0.001119   
2022-11-25 10:22:01,496 - INFO  - Training [38][  100/  196]   Loss 0.470849   Top1 84.781250   Top5 98.578125   BatchTime 0.371797   LR 0.001116   
2022-11-25 10:22:08,779 - INFO  - Training [38][  120/  196]   Loss 0.465521   Top1 84.980469   Top5 98.665365   BatchTime 0.370517   LR 0.001112   
2022-11-25 10:22:16,431 - INFO  - Training [38][  140/  196]   Loss 0.464308   Top1 85.050223   Top5 98.713728   BatchTime 0.372243   LR 0.001109   
2022-11-25 10:22:23,659 - INFO  - Training [38][  160/  196]   Loss 0.468305   Top1 84.943848   Top5 98.691406   BatchTime 0.370885   LR 0.001106   
2022-11-25 10:22:30,922 - INFO  - Training [38][  180/  196]   Loss 0.466096   Top1 85.047743   Top5 98.687066   BatchTime 0.370026   LR 0.001103   
2022-11-25 10:22:36,792 - INFO  - ==> Top1: 85.150    Top5: 98.686    Loss: 0.463

2022-11-25 10:22:37,042 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:22:38,946 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:22:41,610 - INFO  - Validation [38][   20/   40]   Loss 0.384577   Top1 87.714844   Top5 99.570312   BatchTime 0.133089   
2022-11-25 10:22:42,690 - INFO  - Validation [38][   40/   40]   Loss 0.377989   Top1 87.650000   Top5 99.580000   BatchTime 0.093551   
2022-11-25 10:22:42,933 - INFO  - ==> Top1: 87.650    Top5: 99.580    Loss: 0.378

2022-11-25 10:22:42,933 - INFO  - ==> Sparsity : 0.531

2022-11-25 10:22:42,933 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:22:42,933 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 88.610   Top5: 99.660]
2022-11-25 10:22:42,934 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 87.970   Top5: 99.510]
2022-11-25 10:22:43,076 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:22:43,078 - INFO  - >>>>>> Epoch  39
2022-11-25 10:22:43,080 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:22:51,639 - INFO  - Training [39][   20/  196]   Loss 0.493443   Top1 83.925781   Top5 98.125000   BatchTime 0.427843   LR 0.001097   
2022-11-25 10:22:57,858 - INFO  - Training [39][   40/  196]   Loss 0.486264   Top1 84.042969   Top5 98.330078   BatchTime 0.369376   LR 0.001094   
2022-11-25 10:23:03,916 - INFO  - Training [39][   60/  196]   Loss 0.476737   Top1 84.251302   Top5 98.333333   BatchTime 0.347217   LR 0.001090   
2022-11-25 10:23:10,963 - INFO  - Training [39][   80/  196]   Loss 0.476968   Top1 84.365234   Top5 98.447266   BatchTime 0.348498   LR 0.001087   
2022-11-25 10:23:18,711 - INFO  - Training [39][  100/  196]   Loss 0.467620   Top1 84.769531   Top5 98.546875   BatchTime 0.356279   LR 0.001084   
2022-11-25 10:23:26,837 - INFO  - Training [39][  120/  196]   Loss 0.460172   Top1 85.045573   Top5 98.623047   BatchTime 0.364621   LR 0.001080   
2022-11-25 10:23:34,061 - INFO  - Training [39][  140/  196]   Loss 0.456347   Top1 85.159040   Top5 98.699777   BatchTime 0.364125   LR 0.001077   
2022-11-25 10:23:41,331 - INFO  - Training [39][  160/  196]   Loss 0.458942   Top1 85.100098   Top5 98.718262   BatchTime 0.364050   LR 0.001073   
2022-11-25 10:23:48,748 - INFO  - Training [39][  180/  196]   Loss 0.457984   Top1 85.130208   Top5 98.704427   BatchTime 0.364805   LR 0.001070   
2022-11-25 10:23:55,058 - INFO  - ==> Top1: 85.214    Top5: 98.710    Loss: 0.456

2022-11-25 10:23:55,337 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:23:57,198 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:23:59,959 - INFO  - Validation [39][   20/   40]   Loss 0.418066   Top1 86.171875   Top5 99.160156   BatchTime 0.137902   
2022-11-25 10:24:01,061 - INFO  - Validation [39][   40/   40]   Loss 0.401768   Top1 86.440000   Top5 99.340000   BatchTime 0.096498   
2022-11-25 10:24:01,292 - INFO  - ==> Top1: 86.440    Top5: 99.340    Loss: 0.402

2022-11-25 10:24:01,292 - INFO  - ==> Sparsity : 0.520

2022-11-25 10:24:01,293 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:24:01,293 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 88.610   Top5: 99.660]
2022-11-25 10:24:01,293 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 87.970   Top5: 99.510]
2022-11-25 10:24:01,454 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:24:01,455 - INFO  - >>>>>> Epoch  40
2022-11-25 10:24:01,457 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:24:10,645 - INFO  - Training [40][   20/  196]   Loss 0.464695   Top1 84.746094   Top5 98.378906   BatchTime 0.459263   LR 0.001064   
2022-11-25 10:24:16,986 - INFO  - Training [40][   40/  196]   Loss 0.459996   Top1 85.283203   Top5 98.593750   BatchTime 0.388137   LR 0.001060   
2022-11-25 10:24:23,698 - INFO  - Training [40][   60/  196]   Loss 0.461471   Top1 85.084635   Top5 98.723958   BatchTime 0.370633   LR 0.001056   
2022-11-25 10:24:30,764 - INFO  - Training [40][   80/  196]   Loss 0.462296   Top1 85.078125   Top5 98.769531   BatchTime 0.366296   LR 0.001053   
2022-11-25 10:24:38,360 - INFO  - Training [40][  100/  196]   Loss 0.455893   Top1 85.320312   Top5 98.789062   BatchTime 0.368999   LR 0.001049   
2022-11-25 10:24:46,279 - INFO  - Training [40][  120/  196]   Loss 0.451010   Top1 85.468750   Top5 98.857422   BatchTime 0.373490   LR 0.001045   
2022-11-25 10:24:53,378 - INFO  - Training [40][  140/  196]   Loss 0.447429   Top1 85.597098   Top5 98.900670   BatchTime 0.370839   LR 0.001042   
2022-11-25 10:25:00,430 - INFO  - Training [40][  160/  196]   Loss 0.449883   Top1 85.500488   Top5 98.840332   BatchTime 0.368559   LR 0.001038   
2022-11-25 10:25:07,992 - INFO  - Training [40][  180/  196]   Loss 0.448319   Top1 85.540365   Top5 98.812934   BatchTime 0.369619   LR 0.001034   
2022-11-25 10:25:13,740 - INFO  - ==> Top1: 85.576    Top5: 98.822    Loss: 0.447

2022-11-25 10:25:13,994 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:25:15,637 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:25:18,328 - INFO  - Validation [40][   20/   40]   Loss 0.368785   Top1 88.027344   Top5 99.511719   BatchTime 0.134434   
2022-11-25 10:25:19,430 - INFO  - Validation [40][   40/   40]   Loss 0.350648   Top1 88.170000   Top5 99.610000   BatchTime 0.094789   
2022-11-25 10:25:19,678 - INFO  - ==> Top1: 88.170    Top5: 99.610    Loss: 0.351

2022-11-25 10:25:19,679 - INFO  - ==> Sparsity : 0.547

2022-11-25 10:25:19,679 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:25:19,679 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 88.610   Top5: 99.660]
2022-11-25 10:25:19,679 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 88.170   Top5: 99.610]
2022-11-25 10:25:19,806 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:25:19,807 - INFO  - >>>>>> Epoch  41
2022-11-25 10:25:19,809 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:25:28,919 - INFO  - Training [41][   20/  196]   Loss 0.445477   Top1 85.507812   Top5 98.359375   BatchTime 0.455351   LR 0.001027   
2022-11-25 10:25:37,014 - INFO  - Training [41][   40/  196]   Loss 0.442169   Top1 85.849609   Top5 98.398438   BatchTime 0.430048   LR 0.001023   
2022-11-25 10:25:43,652 - INFO  - Training [41][   60/  196]   Loss 0.447832   Top1 85.611979   Top5 98.391927   BatchTime 0.397335   LR 0.001020   
2022-11-25 10:25:51,260 - INFO  - Training [41][   80/  196]   Loss 0.445335   Top1 85.634766   Top5 98.530273   BatchTime 0.393094   LR 0.001016   
2022-11-25 10:25:58,824 - INFO  - Training [41][  100/  196]   Loss 0.439527   Top1 85.796875   Top5 98.570312   BatchTime 0.390117   LR 0.001012   
2022-11-25 10:26:06,136 - INFO  - Training [41][  120/  196]   Loss 0.438982   Top1 85.810547   Top5 98.636068   BatchTime 0.386034   LR 0.001008   
2022-11-25 10:26:13,289 - INFO  - Training [41][  140/  196]   Loss 0.437974   Top1 85.792411   Top5 98.691406   BatchTime 0.381974   LR 0.001004   
2022-11-25 10:26:20,579 - INFO  - Training [41][  160/  196]   Loss 0.440915   Top1 85.725098   Top5 98.723145   BatchTime 0.379790   LR 0.001000   
2022-11-25 10:26:28,079 - INFO  - Training [41][  180/  196]   Loss 0.441212   Top1 85.683594   Top5 98.697917   BatchTime 0.379257   LR 0.000996   
2022-11-25 10:26:34,428 - INFO  - ==> Top1: 85.722    Top5: 98.712    Loss: 0.441

2022-11-25 10:26:34,738 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:26:36,433 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:26:39,104 - INFO  - Validation [41][   20/   40]   Loss 0.428238   Top1 86.621094   Top5 99.296875   BatchTime 0.133451   
2022-11-25 10:26:40,143 - INFO  - Validation [41][   40/   40]   Loss 0.409724   Top1 86.900000   Top5 99.380000   BatchTime 0.092712   
2022-11-25 10:26:40,360 - INFO  - ==> Top1: 86.900    Top5: 99.380    Loss: 0.410

2022-11-25 10:26:40,360 - INFO  - ==> Sparsity : 0.546

2022-11-25 10:26:40,360 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:26:40,360 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 88.610   Top5: 99.660]
2022-11-25 10:26:40,360 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 88.170   Top5: 99.610]
2022-11-25 10:26:40,667 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:26:40,669 - INFO  - >>>>>> Epoch  42
2022-11-25 10:26:40,670 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:26:49,081 - INFO  - Training [42][   20/  196]   Loss 0.443055   Top1 85.507812   Top5 98.359375   BatchTime 0.420375   LR 0.000988   
2022-11-25 10:26:55,627 - INFO  - Training [42][   40/  196]   Loss 0.446875   Top1 85.546875   Top5 98.466797   BatchTime 0.373843   LR 0.000984   
2022-11-25 10:27:02,246 - INFO  - Training [42][   60/  196]   Loss 0.448563   Top1 85.449219   Top5 98.496094   BatchTime 0.359547   LR 0.000980   
2022-11-25 10:27:09,275 - INFO  - Training [42][   80/  196]   Loss 0.444240   Top1 85.595703   Top5 98.583984   BatchTime 0.357525   LR 0.000976   
2022-11-25 10:27:16,681 - INFO  - Training [42][  100/  196]   Loss 0.435677   Top1 85.894531   Top5 98.656250   BatchTime 0.360074   LR 0.000972   
2022-11-25 10:27:24,011 - INFO  - Training [42][  120/  196]   Loss 0.431773   Top1 86.041667   Top5 98.720703   BatchTime 0.361144   LR 0.000968   
2022-11-25 10:27:31,666 - INFO  - Training [42][  140/  196]   Loss 0.430347   Top1 86.077009   Top5 98.766741   BatchTime 0.364230   LR 0.000964   
2022-11-25 10:27:39,184 - INFO  - Training [42][  160/  196]   Loss 0.436254   Top1 85.830078   Top5 98.715820   BatchTime 0.365687   LR 0.000959   
2022-11-25 10:27:46,631 - INFO  - Training [42][  180/  196]   Loss 0.436289   Top1 85.844184   Top5 98.697917   BatchTime 0.366429   LR 0.000955   
2022-11-25 10:27:52,894 - INFO  - ==> Top1: 85.900    Top5: 98.712    Loss: 0.436

2022-11-25 10:27:53,201 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:27:54,850 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:27:57,528 - INFO  - Validation [42][   20/   40]   Loss 0.448481   Top1 85.878906   Top5 99.140625   BatchTime 0.133791   
2022-11-25 10:27:58,592 - INFO  - Validation [42][   40/   40]   Loss 0.434177   Top1 86.150000   Top5 99.280000   BatchTime 0.093519   
2022-11-25 10:27:58,816 - INFO  - ==> Top1: 86.150    Top5: 99.280    Loss: 0.434

2022-11-25 10:27:58,817 - INFO  - ==> Sparsity : 0.551

2022-11-25 10:27:58,817 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:27:58,817 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 88.610   Top5: 99.660]
2022-11-25 10:27:58,817 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 88.170   Top5: 99.610]
2022-11-25 10:27:58,937 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:27:58,938 - INFO  - >>>>>> Epoch  43
2022-11-25 10:27:58,940 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:28:08,532 - INFO  - Training [43][   20/  196]   Loss 0.447014   Top1 85.703125   Top5 98.300781   BatchTime 0.479480   LR 0.000947   
2022-11-25 10:28:15,752 - INFO  - Training [43][   40/  196]   Loss 0.450171   Top1 85.488281   Top5 98.466797   BatchTime 0.420234   LR 0.000943   
2022-11-25 10:28:22,156 - INFO  - Training [43][   60/  196]   Loss 0.444229   Top1 85.657552   Top5 98.476562   BatchTime 0.386886   LR 0.000939   
2022-11-25 10:28:29,284 - INFO  - Training [43][   80/  196]   Loss 0.447550   Top1 85.468750   Top5 98.662109   BatchTime 0.379263   LR 0.000934   
2022-11-25 10:28:36,749 - INFO  - Training [43][  100/  196]   Loss 0.439461   Top1 85.722656   Top5 98.750000   BatchTime 0.378065   LR 0.000930   
2022-11-25 10:28:44,476 - INFO  - Training [43][  120/  196]   Loss 0.434002   Top1 85.901693   Top5 98.824870   BatchTime 0.379441   LR 0.000926   
2022-11-25 10:28:51,643 - INFO  - Training [43][  140/  196]   Loss 0.429585   Top1 86.090960   Top5 98.889509   BatchTime 0.376429   LR 0.000921   
2022-11-25 10:28:58,928 - INFO  - Training [43][  160/  196]   Loss 0.432412   Top1 85.939941   Top5 98.869629   BatchTime 0.374907   LR 0.000917   
2022-11-25 10:29:06,402 - INFO  - Training [43][  180/  196]   Loss 0.432272   Top1 85.917969   Top5 98.828125   BatchTime 0.374772   LR 0.000912   
2022-11-25 10:29:12,454 - INFO  - ==> Top1: 86.046    Top5: 98.846    Loss: 0.430

2022-11-25 10:29:12,773 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:29:14,709 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:29:18,669 - INFO  - Validation [43][   20/   40]   Loss 0.345103   Top1 88.964844   Top5 99.550781   BatchTime 0.197890   
2022-11-25 10:29:20,614 - INFO  - Validation [43][   40/   40]   Loss 0.333826   Top1 88.910000   Top5 99.600000   BatchTime 0.147575   
2022-11-25 10:29:20,857 - INFO  - ==> Top1: 88.910    Top5: 99.600    Loss: 0.334

2022-11-25 10:29:20,858 - INFO  - ==> Sparsity : 0.561

2022-11-25 10:29:20,858 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 88.910   Top5: 99.600]
2022-11-25 10:29:20,858 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:29:20,858 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 88.610   Top5: 99.660]
2022-11-25 10:29:26,328 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 10:29:26,330 - INFO  - >>>>>> Epoch  44
2022-11-25 10:29:26,333 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:29:35,290 - INFO  - Training [44][   20/  196]   Loss 0.439560   Top1 85.527344   Top5 98.066406   BatchTime 0.447741   LR 0.000904   
2022-11-25 10:29:41,808 - INFO  - Training [44][   40/  196]   Loss 0.439684   Top1 85.761719   Top5 98.330078   BatchTime 0.386804   LR 0.000900   
2022-11-25 10:29:49,335 - INFO  - Training [44][   60/  196]   Loss 0.438931   Top1 85.865885   Top5 98.411458   BatchTime 0.383321   LR 0.000895   
2022-11-25 10:29:57,133 - INFO  - Training [44][   80/  196]   Loss 0.434093   Top1 86.064453   Top5 98.515625   BatchTime 0.384967   LR 0.000891   
2022-11-25 10:30:04,423 - INFO  - Training [44][  100/  196]   Loss 0.427876   Top1 86.253906   Top5 98.597656   BatchTime 0.380878   LR 0.000886   
2022-11-25 10:30:11,774 - INFO  - Training [44][  120/  196]   Loss 0.422365   Top1 86.448568   Top5 98.645833   BatchTime 0.378651   LR 0.000882   
2022-11-25 10:30:19,729 - INFO  - Training [44][  140/  196]   Loss 0.422705   Top1 86.537388   Top5 98.713728   BatchTime 0.381378   LR 0.000877   
2022-11-25 10:30:27,837 - INFO  - Training [44][  160/  196]   Loss 0.423165   Top1 86.525879   Top5 98.720703   BatchTime 0.384381   LR 0.000873   
2022-11-25 10:30:35,723 - INFO  - Training [44][  180/  196]   Loss 0.422013   Top1 86.493056   Top5 98.719618   BatchTime 0.385480   LR 0.000868   
2022-11-25 10:30:42,227 - INFO  - ==> Top1: 86.556    Top5: 98.722    Loss: 0.420

2022-11-25 10:30:42,584 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:30:44,120 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:30:47,762 - INFO  - Validation [44][   20/   40]   Loss 0.382752   Top1 87.597656   Top5 99.433594   BatchTime 0.182024   
2022-11-25 10:30:48,749 - INFO  - Validation [44][   40/   40]   Loss 0.367920   Top1 87.880000   Top5 99.520000   BatchTime 0.115686   
2022-11-25 10:30:48,991 - INFO  - ==> Top1: 87.880    Top5: 99.520    Loss: 0.368

2022-11-25 10:30:48,992 - INFO  - ==> Sparsity : 0.567

2022-11-25 10:30:48,992 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 88.910   Top5: 99.600]
2022-11-25 10:30:48,992 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:30:48,992 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 88.610   Top5: 99.660]
2022-11-25 10:30:49,149 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:30:49,151 - INFO  - >>>>>> Epoch  45
2022-11-25 10:30:49,152 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:30:57,342 - INFO  - Training [45][   20/  196]   Loss 0.429352   Top1 85.839844   Top5 98.437500   BatchTime 0.409331   LR 0.000860   
2022-11-25 10:31:04,247 - INFO  - Training [45][   40/  196]   Loss 0.432865   Top1 85.800781   Top5 98.583984   BatchTime 0.377292   LR 0.000855   
2022-11-25 10:31:11,759 - INFO  - Training [45][   60/  196]   Loss 0.433472   Top1 85.917969   Top5 98.658854   BatchTime 0.376722   LR 0.000850   
2022-11-25 10:31:19,574 - INFO  - Training [45][   80/  196]   Loss 0.433902   Top1 85.932617   Top5 98.808594   BatchTime 0.380232   LR 0.000846   
2022-11-25 10:31:26,683 - INFO  - Training [45][  100/  196]   Loss 0.423411   Top1 86.261719   Top5 98.882812   BatchTime 0.375278   LR 0.000841   
2022-11-25 10:31:33,812 - INFO  - Training [45][  120/  196]   Loss 0.414336   Top1 86.608073   Top5 98.912760   BatchTime 0.372134   LR 0.000836   
2022-11-25 10:31:41,328 - INFO  - Training [45][  140/  196]   Loss 0.412789   Top1 86.690848   Top5 98.959263   BatchTime 0.372659   LR 0.000832   
2022-11-25 10:31:48,419 - INFO  - Training [45][  160/  196]   Loss 0.416334   Top1 86.560059   Top5 98.935547   BatchTime 0.370397   LR 0.000827   
2022-11-25 10:31:56,181 - INFO  - Training [45][  180/  196]   Loss 0.417597   Top1 86.508247   Top5 98.901910   BatchTime 0.372359   LR 0.000822   
2022-11-25 10:32:02,268 - INFO  - ==> Top1: 86.498    Top5: 98.874    Loss: 0.417

2022-11-25 10:32:02,558 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:32:04,336 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:32:07,027 - INFO  - Validation [45][   20/   40]   Loss 0.380386   Top1 87.636719   Top5 99.375000   BatchTime 0.134450   
2022-11-25 10:32:08,090 - INFO  - Validation [45][   40/   40]   Loss 0.372908   Top1 87.850000   Top5 99.410000   BatchTime 0.093795   
2022-11-25 10:32:08,322 - INFO  - ==> Top1: 87.850    Top5: 99.410    Loss: 0.373

2022-11-25 10:32:08,322 - INFO  - ==> Sparsity : 0.603

2022-11-25 10:32:08,322 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 88.910   Top5: 99.600]
2022-11-25 10:32:08,322 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:32:08,323 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 88.610   Top5: 99.660]
2022-11-25 10:32:08,458 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:32:08,459 - INFO  - >>>>>> Epoch  46
2022-11-25 10:32:08,461 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:32:16,457 - INFO  - Training [46][   20/  196]   Loss 0.413989   Top1 86.523438   Top5 98.144531   BatchTime 0.399671   LR 0.000814   
2022-11-25 10:32:23,962 - INFO  - Training [46][   40/  196]   Loss 0.427381   Top1 86.308594   Top5 98.417969   BatchTime 0.387442   LR 0.000809   
2022-11-25 10:32:31,039 - INFO  - Training [46][   60/  196]   Loss 0.431049   Top1 86.367188   Top5 98.463542   BatchTime 0.376258   LR 0.000804   
2022-11-25 10:32:38,895 - INFO  - Training [46][   80/  196]   Loss 0.433181   Top1 86.308594   Top5 98.593750   BatchTime 0.380385   LR 0.000799   
2022-11-25 10:32:46,328 - INFO  - Training [46][  100/  196]   Loss 0.425454   Top1 86.468750   Top5 98.648438   BatchTime 0.378637   LR 0.000794   
2022-11-25 10:32:53,687 - INFO  - Training [46][  120/  196]   Loss 0.422055   Top1 86.549479   Top5 98.684896   BatchTime 0.376858   LR 0.000789   
2022-11-25 10:33:00,757 - INFO  - Training [46][  140/  196]   Loss 0.419784   Top1 86.685268   Top5 98.744420   BatchTime 0.373519   LR 0.000785   
2022-11-25 10:33:08,151 - INFO  - Training [46][  160/  196]   Loss 0.419530   Top1 86.604004   Top5 98.750000   BatchTime 0.373041   LR 0.000780   
2022-11-25 10:33:15,987 - INFO  - Training [46][  180/  196]   Loss 0.418431   Top1 86.592882   Top5 98.728299   BatchTime 0.375123   LR 0.000775   
2022-11-25 10:33:22,023 - INFO  - ==> Top1: 86.578    Top5: 98.724    Loss: 0.418

2022-11-25 10:33:22,265 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:33:23,642 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:33:26,454 - INFO  - Validation [46][   20/   40]   Loss 0.379888   Top1 87.207031   Top5 99.492188   BatchTime 0.140481   
2022-11-25 10:33:27,518 - INFO  - Validation [46][   40/   40]   Loss 0.369980   Top1 87.550000   Top5 99.560000   BatchTime 0.096858   
2022-11-25 10:33:27,759 - INFO  - ==> Top1: 87.550    Top5: 99.560    Loss: 0.370

2022-11-25 10:33:27,759 - INFO  - ==> Sparsity : 0.547

2022-11-25 10:33:27,759 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 88.910   Top5: 99.600]
2022-11-25 10:33:27,759 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:33:27,760 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 88.610   Top5: 99.660]
2022-11-25 10:33:27,924 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:33:27,925 - INFO  - >>>>>> Epoch  47
2022-11-25 10:33:27,927 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:33:36,422 - INFO  - Training [47][   20/  196]   Loss 0.419689   Top1 86.464844   Top5 98.398438   BatchTime 0.424605   LR 0.000766   
2022-11-25 10:33:43,460 - INFO  - Training [47][   40/  196]   Loss 0.420262   Top1 86.650391   Top5 98.564453   BatchTime 0.388247   LR 0.000761   
2022-11-25 10:33:50,776 - INFO  - Training [47][   60/  196]   Loss 0.422889   Top1 86.640625   Top5 98.574219   BatchTime 0.380768   LR 0.000756   
2022-11-25 10:33:58,019 - INFO  - Training [47][   80/  196]   Loss 0.422861   Top1 86.513672   Top5 98.696289   BatchTime 0.376116   LR 0.000752   
2022-11-25 10:34:05,343 - INFO  - Training [47][  100/  196]   Loss 0.418322   Top1 86.605469   Top5 98.750000   BatchTime 0.374129   LR 0.000747   
2022-11-25 10:34:12,842 - INFO  - Training [47][  120/  196]   Loss 0.410712   Top1 86.871745   Top5 98.841146   BatchTime 0.374268   LR 0.000742   
2022-11-25 10:34:20,976 - INFO  - Training [47][  140/  196]   Loss 0.404945   Top1 87.047991   Top5 98.900670   BatchTime 0.378893   LR 0.000737   
2022-11-25 10:34:28,312 - INFO  - Training [47][  160/  196]   Loss 0.408528   Top1 86.904297   Top5 98.889160   BatchTime 0.377384   LR 0.000732   
2022-11-25 10:34:35,604 - INFO  - Training [47][  180/  196]   Loss 0.410085   Top1 86.807726   Top5 98.862847   BatchTime 0.375965   LR 0.000727   
2022-11-25 10:34:41,694 - INFO  - ==> Top1: 86.826    Top5: 98.866    Loss: 0.409

2022-11-25 10:34:41,970 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:34:43,487 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:34:47,835 - INFO  - Validation [47][   20/   40]   Loss 0.319233   Top1 89.960938   Top5 99.492188   BatchTime 0.217301   
2022-11-25 10:34:49,176 - INFO  - Validation [47][   40/   40]   Loss 0.303738   Top1 89.900000   Top5 99.600000   BatchTime 0.142169   
2022-11-25 10:34:49,411 - INFO  - ==> Top1: 89.900    Top5: 99.600    Loss: 0.304

2022-11-25 10:34:49,411 - INFO  - ==> Sparsity : 0.569

2022-11-25 10:34:49,411 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:34:49,411 - INFO  - Scoreboard best 2 ==> Epoch [43][Top1: 88.910   Top5: 99.600]
2022-11-25 10:34:49,412 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 88.660   Top5: 99.590]
2022-11-25 10:34:56,056 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 10:34:56,058 - INFO  - >>>>>> Epoch  48
2022-11-25 10:34:56,060 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:35:05,650 - INFO  - Training [48][   20/  196]   Loss 0.413621   Top1 86.308594   Top5 98.437500   BatchTime 0.479410   LR 0.000718   
2022-11-25 10:35:13,277 - INFO  - Training [48][   40/  196]   Loss 0.421107   Top1 86.171875   Top5 98.515625   BatchTime 0.430369   LR 0.000713   
2022-11-25 10:35:20,756 - INFO  - Training [48][   60/  196]   Loss 0.416295   Top1 86.425781   Top5 98.548177   BatchTime 0.411558   LR 0.000708   
2022-11-25 10:35:28,292 - INFO  - Training [48][   80/  196]   Loss 0.410941   Top1 86.611328   Top5 98.686523   BatchTime 0.402866   LR 0.000703   
2022-11-25 10:35:35,588 - INFO  - Training [48][  100/  196]   Loss 0.407855   Top1 86.765625   Top5 98.734375   BatchTime 0.395255   LR 0.000698   
2022-11-25 10:35:42,962 - INFO  - Training [48][  120/  196]   Loss 0.401008   Top1 86.985677   Top5 98.811849   BatchTime 0.390827   LR 0.000693   
2022-11-25 10:35:50,676 - INFO  - Training [48][  140/  196]   Loss 0.394768   Top1 87.207031   Top5 98.917411   BatchTime 0.390097   LR 0.000688   
2022-11-25 10:35:58,306 - INFO  - Training [48][  160/  196]   Loss 0.399222   Top1 87.065430   Top5 98.889160   BatchTime 0.389020   LR 0.000683   
2022-11-25 10:36:06,096 - INFO  - Training [48][  180/  196]   Loss 0.398703   Top1 87.061632   Top5 98.869358   BatchTime 0.389070   LR 0.000678   
2022-11-25 10:36:12,231 - INFO  - ==> Top1: 87.084    Top5: 98.872    Loss: 0.399

2022-11-25 10:36:12,472 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:36:15,100 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:36:18,245 - INFO  - Validation [48][   20/   40]   Loss 0.338376   Top1 89.003906   Top5 99.667969   BatchTime 0.157185   
2022-11-25 10:36:19,360 - INFO  - Validation [48][   40/   40]   Loss 0.323125   Top1 89.250000   Top5 99.680000   BatchTime 0.106458   
2022-11-25 10:36:19,569 - INFO  - ==> Top1: 89.250    Top5: 99.680    Loss: 0.323

2022-11-25 10:36:19,570 - INFO  - ==> Sparsity : 0.569

2022-11-25 10:36:19,570 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:36:19,570 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 89.250   Top5: 99.680]
2022-11-25 10:36:19,570 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 88.910   Top5: 99.600]
2022-11-25 10:36:19,704 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:36:19,706 - INFO  - >>>>>> Epoch  49
2022-11-25 10:36:19,708 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:36:28,936 - INFO  - Training [49][   20/  196]   Loss 0.397864   Top1 86.757812   Top5 98.417969   BatchTime 0.461310   LR 0.000669   
2022-11-25 10:36:36,082 - INFO  - Training [49][   40/  196]   Loss 0.407870   Top1 86.816406   Top5 98.496094   BatchTime 0.409287   LR 0.000664   
2022-11-25 10:36:43,395 - INFO  - Training [49][   60/  196]   Loss 0.409429   Top1 86.705729   Top5 98.574219   BatchTime 0.394753   LR 0.000659   
2022-11-25 10:36:51,115 - INFO  - Training [49][   80/  196]   Loss 0.410394   Top1 86.694336   Top5 98.754883   BatchTime 0.392557   LR 0.000654   
2022-11-25 10:36:58,357 - INFO  - Training [49][  100/  196]   Loss 0.403421   Top1 86.941406   Top5 98.800781   BatchTime 0.386463   LR 0.000649   
2022-11-25 10:37:05,957 - INFO  - Training [49][  120/  196]   Loss 0.397383   Top1 87.207031   Top5 98.844401   BatchTime 0.385384   LR 0.000644   
2022-11-25 10:37:13,048 - INFO  - Training [49][  140/  196]   Loss 0.396978   Top1 87.223772   Top5 98.914621   BatchTime 0.380983   LR 0.000639   
2022-11-25 10:37:20,365 - INFO  - Training [49][  160/  196]   Loss 0.401179   Top1 87.048340   Top5 98.881836   BatchTime 0.379086   LR 0.000634   
2022-11-25 10:37:28,181 - INFO  - Training [49][  180/  196]   Loss 0.404194   Top1 86.946615   Top5 98.860677   BatchTime 0.380389   LR 0.000629   
2022-11-25 10:37:33,887 - INFO  - ==> Top1: 86.996    Top5: 98.850    Loss: 0.403

2022-11-25 10:37:34,141 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:37:36,185 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:37:39,068 - INFO  - Validation [49][   20/   40]   Loss 0.343247   Top1 89.062500   Top5 99.550781   BatchTime 0.144060   
2022-11-25 10:37:40,592 - INFO  - Validation [49][   40/   40]   Loss 0.329176   Top1 89.370000   Top5 99.650000   BatchTime 0.110109   
2022-11-25 10:37:40,830 - INFO  - ==> Top1: 89.370    Top5: 99.650    Loss: 0.329

2022-11-25 10:37:40,830 - INFO  - ==> Sparsity : 0.568

2022-11-25 10:37:40,831 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:37:40,831 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 89.370   Top5: 99.650]
2022-11-25 10:37:40,831 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 89.250   Top5: 99.680]
2022-11-25 10:37:40,964 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:37:40,966 - INFO  - >>>>>> Epoch  50
2022-11-25 10:37:40,968 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:37:49,881 - INFO  - Training [50][   20/  196]   Loss 0.413559   Top1 86.679688   Top5 98.359375   BatchTime 0.445535   LR 0.000620   
2022-11-25 10:37:57,782 - INFO  - Training [50][   40/  196]   Loss 0.407981   Top1 87.167969   Top5 98.466797   BatchTime 0.420308   LR 0.000615   
2022-11-25 10:38:04,780 - INFO  - Training [50][   60/  196]   Loss 0.404914   Top1 87.194010   Top5 98.483073   BatchTime 0.396826   LR 0.000610   
2022-11-25 10:38:12,707 - INFO  - Training [50][   80/  196]   Loss 0.402078   Top1 87.177734   Top5 98.642578   BatchTime 0.396705   LR 0.000605   
2022-11-25 10:38:19,956 - INFO  - Training [50][  100/  196]   Loss 0.396174   Top1 87.343750   Top5 98.730469   BatchTime 0.389861   LR 0.000600   
2022-11-25 10:38:27,277 - INFO  - Training [50][  120/  196]   Loss 0.391371   Top1 87.539062   Top5 98.828125   BatchTime 0.385886   LR 0.000595   
2022-11-25 10:38:34,446 - INFO  - Training [50][  140/  196]   Loss 0.390990   Top1 87.533482   Top5 98.914621   BatchTime 0.381965   LR 0.000590   
2022-11-25 10:38:41,627 - INFO  - Training [50][  160/  196]   Loss 0.394326   Top1 87.412109   Top5 98.918457   BatchTime 0.379100   LR 0.000585   
2022-11-25 10:38:48,611 - INFO  - Training [50][  180/  196]   Loss 0.395666   Top1 87.382812   Top5 98.865017   BatchTime 0.375781   LR 0.000580   
2022-11-25 10:38:54,247 - INFO  - ==> Top1: 87.390    Top5: 98.854    Loss: 0.395

2022-11-25 10:38:54,444 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:38:55,913 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:38:59,697 - INFO  - Validation [50][   20/   40]   Loss 0.334174   Top1 89.335938   Top5 99.531250   BatchTime 0.189136   
2022-11-25 10:39:00,765 - INFO  - Validation [50][   40/   40]   Loss 0.321010   Top1 89.620000   Top5 99.640000   BatchTime 0.121268   
2022-11-25 10:39:00,980 - INFO  - ==> Top1: 89.620    Top5: 99.640    Loss: 0.321

2022-11-25 10:39:00,981 - INFO  - ==> Sparsity : 0.572

2022-11-25 10:39:00,981 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:39:00,981 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 89.620   Top5: 99.640]
2022-11-25 10:39:00,981 - INFO  - Scoreboard best 3 ==> Epoch [49][Top1: 89.370   Top5: 99.650]
2022-11-25 10:39:01,107 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:39:01,109 - INFO  - >>>>>> Epoch  51
2022-11-25 10:39:01,110 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:39:09,128 - INFO  - Training [51][   20/  196]   Loss 0.401859   Top1 87.167969   Top5 98.125000   BatchTime 0.400728   LR 0.000571   
2022-11-25 10:39:16,437 - INFO  - Training [51][   40/  196]   Loss 0.405587   Top1 87.187500   Top5 98.203125   BatchTime 0.383093   LR 0.000566   
2022-11-25 10:39:23,786 - INFO  - Training [51][   60/  196]   Loss 0.398222   Top1 87.363281   Top5 98.463542   BatchTime 0.377877   LR 0.000561   
2022-11-25 10:39:31,245 - INFO  - Training [51][   80/  196]   Loss 0.398368   Top1 87.236328   Top5 98.608398   BatchTime 0.376649   LR 0.000556   
2022-11-25 10:39:38,418 - INFO  - Training [51][  100/  196]   Loss 0.393108   Top1 87.410156   Top5 98.695312   BatchTime 0.373044   LR 0.000551   
2022-11-25 10:39:45,873 - INFO  - Training [51][  120/  196]   Loss 0.384801   Top1 87.682292   Top5 98.785807   BatchTime 0.372990   LR 0.000546   
2022-11-25 10:39:53,289 - INFO  - Training [51][  140/  196]   Loss 0.386200   Top1 87.670201   Top5 98.872768   BatchTime 0.372678   LR 0.000541   
2022-11-25 10:40:00,350 - INFO  - Training [51][  160/  196]   Loss 0.387098   Top1 87.590332   Top5 98.872070   BatchTime 0.370226   LR 0.000536   
2022-11-25 10:40:07,442 - INFO  - Training [51][  180/  196]   Loss 0.388102   Top1 87.534722   Top5 98.823785   BatchTime 0.368491   LR 0.000531   
2022-11-25 10:40:13,125 - INFO  - ==> Top1: 87.580    Top5: 98.842    Loss: 0.387

2022-11-25 10:40:13,395 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:40:16,688 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:40:19,522 - INFO  - Validation [51][   20/   40]   Loss 0.685636   Top1 79.628906   Top5 98.730469   BatchTime 0.141607   
2022-11-25 10:40:20,726 - INFO  - Validation [51][   40/   40]   Loss 0.670042   Top1 80.010000   Top5 98.760000   BatchTime 0.100928   
2022-11-25 10:40:21,138 - INFO  - ==> Top1: 80.010    Top5: 98.760    Loss: 0.670

2022-11-25 10:40:21,138 - INFO  - ==> Sparsity : 0.575

2022-11-25 10:40:21,139 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:40:21,139 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 89.620   Top5: 99.640]
2022-11-25 10:40:21,139 - INFO  - Scoreboard best 3 ==> Epoch [49][Top1: 89.370   Top5: 99.650]
2022-11-25 10:40:21,302 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:40:21,303 - INFO  - >>>>>> Epoch  52
2022-11-25 10:40:21,305 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:40:30,041 - INFO  - Training [52][   20/  196]   Loss 0.380544   Top1 87.656250   Top5 98.574219   BatchTime 0.436652   LR 0.000523   
2022-11-25 10:40:35,822 - INFO  - Training [52][   40/  196]   Loss 0.394957   Top1 87.177734   Top5 98.779297   BatchTime 0.362864   LR 0.000518   
2022-11-25 10:40:42,887 - INFO  - Training [52][   60/  196]   Loss 0.392508   Top1 87.187500   Top5 98.795573   BatchTime 0.359659   LR 0.000513   
2022-11-25 10:40:50,148 - INFO  - Training [52][   80/  196]   Loss 0.392150   Top1 87.285156   Top5 98.823242   BatchTime 0.360504   LR 0.000508   
2022-11-25 10:40:57,532 - INFO  - Training [52][  100/  196]   Loss 0.385264   Top1 87.523438   Top5 98.898438   BatchTime 0.362246   LR 0.000503   
2022-11-25 10:41:04,924 - INFO  - Training [52][  120/  196]   Loss 0.377777   Top1 87.819010   Top5 98.984375   BatchTime 0.363465   LR 0.000498   
2022-11-25 10:41:12,094 - INFO  - Training [52][  140/  196]   Loss 0.375854   Top1 87.932478   Top5 99.009487   BatchTime 0.362757   LR 0.000493   
2022-11-25 10:41:19,216 - INFO  - Training [52][  160/  196]   Loss 0.381411   Top1 87.795410   Top5 98.967285   BatchTime 0.361923   LR 0.000488   
2022-11-25 10:41:26,647 - INFO  - Training [52][  180/  196]   Loss 0.382488   Top1 87.782118   Top5 98.921441   BatchTime 0.362995   LR 0.000483   
2022-11-25 10:41:32,558 - INFO  - ==> Top1: 87.866    Top5: 98.912    Loss: 0.381

2022-11-25 10:41:32,832 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:41:34,261 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:41:37,020 - INFO  - Validation [52][   20/   40]   Loss 0.408127   Top1 87.246094   Top5 99.375000   BatchTime 0.137857   
2022-11-25 10:41:38,243 - INFO  - Validation [52][   40/   40]   Loss 0.390231   Top1 87.500000   Top5 99.440000   BatchTime 0.099500   
2022-11-25 10:41:38,576 - INFO  - ==> Top1: 87.500    Top5: 99.440    Loss: 0.390

2022-11-25 10:41:38,576 - INFO  - ==> Sparsity : 0.580

2022-11-25 10:41:38,576 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:41:38,576 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 89.620   Top5: 99.640]
2022-11-25 10:41:38,576 - INFO  - Scoreboard best 3 ==> Epoch [49][Top1: 89.370   Top5: 99.650]
2022-11-25 10:41:38,715 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:41:38,716 - INFO  - >>>>>> Epoch  53
2022-11-25 10:41:38,718 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:41:48,534 - INFO  - Training [53][   20/  196]   Loss 0.409583   Top1 86.386719   Top5 98.085938   BatchTime 0.490657   LR 0.000474   
2022-11-25 10:41:55,554 - INFO  - Training [53][   40/  196]   Loss 0.399228   Top1 87.187500   Top5 98.515625   BatchTime 0.420830   LR 0.000470   
2022-11-25 10:42:02,990 - INFO  - Training [53][   60/  196]   Loss 0.388484   Top1 87.617188   Top5 98.704427   BatchTime 0.404483   LR 0.000465   
2022-11-25 10:42:10,254 - INFO  - Training [53][   80/  196]   Loss 0.386526   Top1 87.553711   Top5 98.818359   BatchTime 0.394166   LR 0.000460   
2022-11-25 10:42:17,670 - INFO  - Training [53][  100/  196]   Loss 0.379078   Top1 87.820312   Top5 98.855469   BatchTime 0.389488   LR 0.000455   
2022-11-25 10:42:24,784 - INFO  - Training [53][  120/  196]   Loss 0.375039   Top1 88.027344   Top5 98.893229   BatchTime 0.383853   LR 0.000450   
2022-11-25 10:42:32,084 - INFO  - Training [53][  140/  196]   Loss 0.372466   Top1 88.147321   Top5 98.936942   BatchTime 0.381161   LR 0.000445   
2022-11-25 10:42:39,232 - INFO  - Training [53][  160/  196]   Loss 0.374665   Top1 88.037109   Top5 98.930664   BatchTime 0.378187   LR 0.000441   
2022-11-25 10:42:47,067 - INFO  - Training [53][  180/  196]   Loss 0.374053   Top1 88.096788   Top5 98.908420   BatchTime 0.379698   LR 0.000436   
2022-11-25 10:42:52,950 - INFO  - ==> Top1: 88.140    Top5: 98.890    Loss: 0.372

2022-11-25 10:42:53,332 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:42:54,911 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:42:57,532 - INFO  - Validation [53][   20/   40]   Loss 0.343118   Top1 89.238281   Top5 99.511719   BatchTime 0.130958   
2022-11-25 10:42:58,690 - INFO  - Validation [53][   40/   40]   Loss 0.328857   Top1 89.470000   Top5 99.590000   BatchTime 0.094438   
2022-11-25 10:42:58,935 - INFO  - ==> Top1: 89.470    Top5: 99.590    Loss: 0.329

2022-11-25 10:42:58,935 - INFO  - ==> Sparsity : 0.578

2022-11-25 10:42:58,936 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:42:58,936 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 89.620   Top5: 99.640]
2022-11-25 10:42:58,936 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 89.470   Top5: 99.590]
2022-11-25 10:42:59,361 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:42:59,363 - INFO  - >>>>>> Epoch  54
2022-11-25 10:42:59,365 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:43:09,242 - INFO  - Training [54][   20/  196]   Loss 0.396307   Top1 87.285156   Top5 98.457031   BatchTime 0.493671   LR 0.000427   
2022-11-25 10:43:14,986 - INFO  - Training [54][   40/  196]   Loss 0.395704   Top1 87.294922   Top5 98.681641   BatchTime 0.390428   LR 0.000423   
2022-11-25 10:43:20,976 - INFO  - Training [54][   60/  196]   Loss 0.393205   Top1 87.467448   Top5 98.704427   BatchTime 0.360133   LR 0.000418   
2022-11-25 10:43:28,150 - INFO  - Training [54][   80/  196]   Loss 0.381745   Top1 87.836914   Top5 98.813477   BatchTime 0.359769   LR 0.000413   
2022-11-25 10:43:35,539 - INFO  - Training [54][  100/  196]   Loss 0.376250   Top1 87.964844   Top5 98.839844   BatchTime 0.361702   LR 0.000408   
2022-11-25 10:43:42,941 - INFO  - Training [54][  120/  196]   Loss 0.371047   Top1 88.082682   Top5 98.893229   BatchTime 0.363104   LR 0.000404   
2022-11-25 10:43:50,343 - INFO  - Training [54][  140/  196]   Loss 0.369837   Top1 88.169643   Top5 98.928571   BatchTime 0.364097   LR 0.000399   
2022-11-25 10:43:57,690 - INFO  - Training [54][  160/  196]   Loss 0.372919   Top1 88.037109   Top5 98.935547   BatchTime 0.364507   LR 0.000394   
2022-11-25 10:44:04,580 - INFO  - Training [54][  180/  196]   Loss 0.373305   Top1 88.033854   Top5 98.895399   BatchTime 0.362281   LR 0.000390   
2022-11-25 10:44:10,035 - INFO  - ==> Top1: 88.078    Top5: 98.886    Loss: 0.372

2022-11-25 10:44:10,294 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:44:11,802 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:44:14,516 - INFO  - Validation [54][   20/   40]   Loss 0.446952   Top1 86.503906   Top5 99.179688   BatchTime 0.135624   
2022-11-25 10:44:15,575 - INFO  - Validation [54][   40/   40]   Loss 0.421995   Top1 86.850000   Top5 99.370000   BatchTime 0.094285   
2022-11-25 10:44:15,792 - INFO  - ==> Top1: 86.850    Top5: 99.370    Loss: 0.422

2022-11-25 10:44:15,793 - INFO  - ==> Sparsity : 0.614

2022-11-25 10:44:15,793 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:44:15,793 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 89.620   Top5: 99.640]
2022-11-25 10:44:15,793 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 89.470   Top5: 99.590]
2022-11-25 10:44:15,916 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:44:15,918 - INFO  - >>>>>> Epoch  55
2022-11-25 10:44:15,920 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:44:25,374 - INFO  - Training [55][   20/  196]   Loss 0.377608   Top1 88.007812   Top5 98.378906   BatchTime 0.472620   LR 0.000381   
2022-11-25 10:44:33,164 - INFO  - Training [55][   40/  196]   Loss 0.381148   Top1 87.656250   Top5 98.574219   BatchTime 0.431056   LR 0.000377   
2022-11-25 10:44:39,514 - INFO  - Training [55][   60/  196]   Loss 0.382637   Top1 87.513021   Top5 98.645833   BatchTime 0.393191   LR 0.000372   
2022-11-25 10:44:46,242 - INFO  - Training [55][   80/  196]   Loss 0.380467   Top1 87.636719   Top5 98.779297   BatchTime 0.379002   LR 0.000368   
2022-11-25 10:44:53,677 - INFO  - Training [55][  100/  196]   Loss 0.375548   Top1 87.843750   Top5 98.843750   BatchTime 0.377542   LR 0.000363   
2022-11-25 10:45:00,961 - INFO  - Training [55][  120/  196]   Loss 0.367634   Top1 88.095703   Top5 98.902995   BatchTime 0.375319   LR 0.000358   
2022-11-25 10:45:08,548 - INFO  - Training [55][  140/  196]   Loss 0.366048   Top1 88.191964   Top5 98.956473   BatchTime 0.375894   LR 0.000354   
2022-11-25 10:45:16,070 - INFO  - Training [55][  160/  196]   Loss 0.369272   Top1 88.024902   Top5 98.925781   BatchTime 0.375921   LR 0.000349   
2022-11-25 10:45:23,404 - INFO  - Training [55][  180/  196]   Loss 0.370989   Top1 87.992622   Top5 98.891059   BatchTime 0.374895   LR 0.000345   
2022-11-25 10:45:29,377 - INFO  - ==> Top1: 87.994    Top5: 98.914    Loss: 0.370

2022-11-25 10:45:29,631 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:45:31,187 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:45:33,971 - INFO  - Validation [55][   20/   40]   Loss 0.350328   Top1 89.160156   Top5 99.531250   BatchTime 0.139086   
2022-11-25 10:45:34,983 - INFO  - Validation [55][   40/   40]   Loss 0.321709   Top1 89.540000   Top5 99.620000   BatchTime 0.094849   
2022-11-25 10:45:35,284 - INFO  - ==> Top1: 89.540    Top5: 99.620    Loss: 0.322

2022-11-25 10:45:35,284 - INFO  - ==> Sparsity : 0.615

2022-11-25 10:45:35,284 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:45:35,284 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 89.620   Top5: 99.640]
2022-11-25 10:45:35,285 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 89.540   Top5: 99.620]
2022-11-25 10:45:35,417 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:45:35,419 - INFO  - >>>>>> Epoch  56
2022-11-25 10:45:35,421 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:45:45,296 - INFO  - Training [56][   20/  196]   Loss 0.391060   Top1 87.578125   Top5 98.593750   BatchTime 0.493634   LR 0.000337   
2022-11-25 10:45:52,774 - INFO  - Training [56][   40/  196]   Loss 0.384311   Top1 87.783203   Top5 98.750000   BatchTime 0.433766   LR 0.000333   
2022-11-25 10:46:00,145 - INFO  - Training [56][   60/  196]   Loss 0.382467   Top1 87.825521   Top5 98.834635   BatchTime 0.412031   LR 0.000328   
2022-11-25 10:46:05,940 - INFO  - Training [56][   80/  196]   Loss 0.380185   Top1 87.807617   Top5 98.984375   BatchTime 0.381451   LR 0.000324   
2022-11-25 10:46:12,623 - INFO  - Training [56][  100/  196]   Loss 0.377556   Top1 87.925781   Top5 98.988281   BatchTime 0.371996   LR 0.000319   
2022-11-25 10:46:19,219 - INFO  - Training [56][  120/  196]   Loss 0.371280   Top1 88.147786   Top5 99.029948   BatchTime 0.364956   LR 0.000315   
2022-11-25 10:46:26,681 - INFO  - Training [56][  140/  196]   Loss 0.368559   Top1 88.270089   Top5 99.048549   BatchTime 0.366124   LR 0.000311   
2022-11-25 10:46:33,862 - INFO  - Training [56][  160/  196]   Loss 0.370541   Top1 88.220215   Top5 99.023438   BatchTime 0.365239   LR 0.000306   
2022-11-25 10:46:41,402 - INFO  - Training [56][  180/  196]   Loss 0.370207   Top1 88.250868   Top5 98.984375   BatchTime 0.366545   LR 0.000302   
2022-11-25 10:46:48,012 - INFO  - ==> Top1: 88.320    Top5: 98.972    Loss: 0.368

2022-11-25 10:46:48,315 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:46:49,877 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:46:52,792 - INFO  - Validation [56][   20/   40]   Loss 0.326570   Top1 90.078125   Top5 99.667969   BatchTime 0.145655   
2022-11-25 10:46:54,118 - INFO  - Validation [56][   40/   40]   Loss 0.306005   Top1 90.270000   Top5 99.720000   BatchTime 0.105979   
2022-11-25 10:46:54,746 - INFO  - ==> Top1: 90.270    Top5: 99.720    Loss: 0.306

2022-11-25 10:46:54,747 - INFO  - ==> Sparsity : 0.609

2022-11-25 10:46:54,747 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 10:46:54,747 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:46:54,747 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 89.620   Top5: 99.640]
2022-11-25 10:47:00,926 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 10:47:00,928 - INFO  - >>>>>> Epoch  57
2022-11-25 10:47:00,930 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:47:09,894 - INFO  - Training [57][   20/  196]   Loss 0.385956   Top1 87.246094   Top5 98.515625   BatchTime 0.448067   LR 0.000294   
2022-11-25 10:47:16,869 - INFO  - Training [57][   40/  196]   Loss 0.379663   Top1 87.753906   Top5 98.642578   BatchTime 0.398410   LR 0.000290   
2022-11-25 10:47:24,045 - INFO  - Training [57][   60/  196]   Loss 0.378718   Top1 87.675781   Top5 98.743490   BatchTime 0.385212   LR 0.000286   
2022-11-25 10:47:30,049 - INFO  - Training [57][   80/  196]   Loss 0.375548   Top1 87.822266   Top5 98.862305   BatchTime 0.363953   LR 0.000282   
2022-11-25 10:47:37,196 - INFO  - Training [57][  100/  196]   Loss 0.371304   Top1 87.980469   Top5 98.929688   BatchTime 0.362627   LR 0.000277   
2022-11-25 10:47:44,301 - INFO  - Training [57][  120/  196]   Loss 0.363153   Top1 88.326823   Top5 98.974609   BatchTime 0.361401   LR 0.000273   
2022-11-25 10:47:51,482 - INFO  - Training [57][  140/  196]   Loss 0.359799   Top1 88.390067   Top5 99.034598   BatchTime 0.361064   LR 0.000269   
2022-11-25 10:47:58,755 - INFO  - Training [57][  160/  196]   Loss 0.360656   Top1 88.315430   Top5 99.020996   BatchTime 0.361385   LR 0.000265   
2022-11-25 10:48:06,759 - INFO  - Training [57][  180/  196]   Loss 0.361149   Top1 88.315972   Top5 98.953993   BatchTime 0.365700   LR 0.000261   
2022-11-25 10:48:13,244 - INFO  - ==> Top1: 88.342    Top5: 98.958    Loss: 0.360

2022-11-25 10:48:13,562 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:48:15,371 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:48:18,040 - INFO  - Validation [57][   20/   40]   Loss 0.421748   Top1 87.246094   Top5 99.355469   BatchTime 0.133355   
2022-11-25 10:48:19,141 - INFO  - Validation [57][   40/   40]   Loss 0.397188   Top1 87.550000   Top5 99.500000   BatchTime 0.094220   
2022-11-25 10:48:19,354 - INFO  - ==> Top1: 87.550    Top5: 99.500    Loss: 0.397

2022-11-25 10:48:19,354 - INFO  - ==> Sparsity : 0.620

2022-11-25 10:48:19,355 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 10:48:19,355 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:48:19,355 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 89.620   Top5: 99.640]
2022-11-25 10:48:19,506 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:48:19,508 - INFO  - >>>>>> Epoch  58
2022-11-25 10:48:19,510 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:48:28,496 - INFO  - Training [58][   20/  196]   Loss 0.378878   Top1 87.363281   Top5 98.339844   BatchTime 0.449183   LR 0.000254   
2022-11-25 10:48:35,688 - INFO  - Training [58][   40/  196]   Loss 0.372648   Top1 87.880859   Top5 98.632812   BatchTime 0.404396   LR 0.000250   
2022-11-25 10:48:42,990 - INFO  - Training [58][   60/  196]   Loss 0.362397   Top1 88.268229   Top5 98.723958   BatchTime 0.391287   LR 0.000246   
2022-11-25 10:48:49,671 - INFO  - Training [58][   80/  196]   Loss 0.361129   Top1 88.344727   Top5 98.823242   BatchTime 0.376981   LR 0.000242   
2022-11-25 10:48:55,955 - INFO  - Training [58][  100/  196]   Loss 0.356168   Top1 88.566406   Top5 98.871094   BatchTime 0.364428   LR 0.000238   
2022-11-25 10:49:03,213 - INFO  - Training [58][  120/  196]   Loss 0.352240   Top1 88.688151   Top5 98.929036   BatchTime 0.364165   LR 0.000234   
2022-11-25 10:49:10,361 - INFO  - Training [58][  140/  196]   Loss 0.351088   Top1 88.769531   Top5 99.003906   BatchTime 0.363198   LR 0.000230   
2022-11-25 10:49:17,451 - INFO  - Training [58][  160/  196]   Loss 0.356908   Top1 88.620605   Top5 98.962402   BatchTime 0.362113   LR 0.000226   
2022-11-25 10:49:24,810 - INFO  - Training [58][  180/  196]   Loss 0.356666   Top1 88.643663   Top5 98.967014   BatchTime 0.362760   LR 0.000222   
2022-11-25 10:49:31,230 - INFO  - ==> Top1: 88.640    Top5: 98.968    Loss: 0.356

2022-11-25 10:49:31,499 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:49:33,426 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:49:36,140 - INFO  - Validation [58][   20/   40]   Loss 0.334467   Top1 89.238281   Top5 99.511719   BatchTime 0.135606   
2022-11-25 10:49:37,264 - INFO  - Validation [58][   40/   40]   Loss 0.315377   Top1 89.710000   Top5 99.620000   BatchTime 0.095910   
2022-11-25 10:49:37,512 - INFO  - ==> Top1: 89.710    Top5: 99.620    Loss: 0.315

2022-11-25 10:49:37,512 - INFO  - ==> Sparsity : 0.623

2022-11-25 10:49:37,512 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 10:49:37,512 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:49:37,513 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 89.710   Top5: 99.620]
2022-11-25 10:49:37,649 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:49:37,650 - INFO  - >>>>>> Epoch  59
2022-11-25 10:49:37,652 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:49:46,662 - INFO  - Training [59][   20/  196]   Loss 0.377868   Top1 87.382812   Top5 98.554688   BatchTime 0.450371   LR 0.000215   
2022-11-25 10:49:54,199 - INFO  - Training [59][   40/  196]   Loss 0.366024   Top1 87.900391   Top5 98.750000   BatchTime 0.413598   LR 0.000212   
2022-11-25 10:50:01,153 - INFO  - Training [59][   60/  196]   Loss 0.357050   Top1 88.509115   Top5 98.756510   BatchTime 0.391637   LR 0.000208   
2022-11-25 10:50:08,988 - INFO  - Training [59][   80/  196]   Loss 0.355229   Top1 88.569336   Top5 98.881836   BatchTime 0.391657   LR 0.000204   
2022-11-25 10:50:15,584 - INFO  - Training [59][  100/  196]   Loss 0.351857   Top1 88.660156   Top5 98.898438   BatchTime 0.379288   LR 0.000201   
2022-11-25 10:50:22,222 - INFO  - Training [59][  120/  196]   Loss 0.348707   Top1 88.860677   Top5 98.958333   BatchTime 0.371392   LR 0.000197   
2022-11-25 10:50:29,299 - INFO  - Training [59][  140/  196]   Loss 0.349577   Top1 88.856027   Top5 99.012277   BatchTime 0.368884   LR 0.000193   
2022-11-25 10:50:36,266 - INFO  - Training [59][  160/  196]   Loss 0.351482   Top1 88.781738   Top5 99.018555   BatchTime 0.366316   LR 0.000190   
2022-11-25 10:50:43,274 - INFO  - Training [59][  180/  196]   Loss 0.349113   Top1 88.875868   Top5 99.008247   BatchTime 0.364549   LR 0.000186   
2022-11-25 10:50:49,625 - INFO  - ==> Top1: 88.920    Top5: 99.012    Loss: 0.348

2022-11-25 10:50:49,868 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:50:51,308 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:50:53,930 - INFO  - Validation [59][   20/   40]   Loss 0.471981   Top1 86.367188   Top5 99.082031   BatchTime 0.130998   
2022-11-25 10:50:54,978 - INFO  - Validation [59][   40/   40]   Loss 0.454212   Top1 86.400000   Top5 99.230000   BatchTime 0.091705   
2022-11-25 10:50:55,236 - INFO  - ==> Top1: 86.400    Top5: 99.230    Loss: 0.454

2022-11-25 10:50:55,236 - INFO  - ==> Sparsity : 0.622

2022-11-25 10:50:55,237 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 10:50:55,237 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:50:55,237 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 89.710   Top5: 99.620]
2022-11-25 10:50:55,386 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:50:55,387 - INFO  - >>>>>> Epoch  60
2022-11-25 10:50:55,389 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:51:04,150 - INFO  - Training [60][   20/  196]   Loss 0.368860   Top1 87.812500   Top5 98.574219   BatchTime 0.437908   LR 0.000180   
2022-11-25 10:51:11,433 - INFO  - Training [60][   40/  196]   Loss 0.370607   Top1 88.066406   Top5 98.662109   BatchTime 0.401037   LR 0.000176   
2022-11-25 10:51:18,636 - INFO  - Training [60][   60/  196]   Loss 0.364803   Top1 88.320312   Top5 98.736979   BatchTime 0.387413   LR 0.000173   
2022-11-25 10:51:25,641 - INFO  - Training [60][   80/  196]   Loss 0.360022   Top1 88.452148   Top5 98.862305   BatchTime 0.378119   LR 0.000169   
2022-11-25 10:51:32,667 - INFO  - Training [60][  100/  196]   Loss 0.354954   Top1 88.703125   Top5 98.921875   BatchTime 0.372752   LR 0.000166   
2022-11-25 10:51:39,056 - INFO  - Training [60][  120/  196]   Loss 0.350074   Top1 88.880208   Top5 98.961589   BatchTime 0.363865   LR 0.000162   
2022-11-25 10:51:45,921 - INFO  - Training [60][  140/  196]   Loss 0.347337   Top1 88.909040   Top5 99.031808   BatchTime 0.360919   LR 0.000159   
2022-11-25 10:51:53,424 - INFO  - Training [60][  160/  196]   Loss 0.348751   Top1 88.869629   Top5 99.055176   BatchTime 0.362698   LR 0.000156   
2022-11-25 10:52:00,790 - INFO  - Training [60][  180/  196]   Loss 0.349806   Top1 88.854167   Top5 99.027778   BatchTime 0.363320   LR 0.000152   
2022-11-25 10:52:07,054 - INFO  - ==> Top1: 88.874    Top5: 99.030    Loss: 0.350

2022-11-25 10:52:07,319 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:52:08,903 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:52:11,685 - INFO  - Validation [60][   20/   40]   Loss 0.385344   Top1 88.515625   Top5 99.355469   BatchTime 0.139028   
2022-11-25 10:52:12,794 - INFO  - Validation [60][   40/   40]   Loss 0.365289   Top1 88.520000   Top5 99.520000   BatchTime 0.097225   
2022-11-25 10:52:13,017 - INFO  - ==> Top1: 88.520    Top5: 99.520    Loss: 0.365

2022-11-25 10:52:13,017 - INFO  - ==> Sparsity : 0.629

2022-11-25 10:52:13,017 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 10:52:13,017 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:52:13,018 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 89.710   Top5: 99.620]
2022-11-25 10:52:13,163 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:52:13,165 - INFO  - >>>>>> Epoch  61
2022-11-25 10:52:13,167 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:52:22,362 - INFO  - Training [61][   20/  196]   Loss 0.378197   Top1 87.792969   Top5 98.828125   BatchTime 0.459609   LR 0.000147   
2022-11-25 10:52:30,131 - INFO  - Training [61][   40/  196]   Loss 0.373088   Top1 87.958984   Top5 98.876953   BatchTime 0.424037   LR 0.000143   
2022-11-25 10:52:37,432 - INFO  - Training [61][   60/  196]   Loss 0.373191   Top1 88.007812   Top5 98.854167   BatchTime 0.404378   LR 0.000140   
2022-11-25 10:52:44,666 - INFO  - Training [61][   80/  196]   Loss 0.373109   Top1 88.041992   Top5 98.935547   BatchTime 0.393701   LR 0.000137   
2022-11-25 10:52:51,580 - INFO  - Training [61][  100/  196]   Loss 0.365477   Top1 88.328125   Top5 99.007812   BatchTime 0.384101   LR 0.000134   
2022-11-25 10:52:57,966 - INFO  - Training [61][  120/  196]   Loss 0.356587   Top1 88.639323   Top5 99.042969   BatchTime 0.373305   LR 0.000131   
2022-11-25 10:53:05,060 - INFO  - Training [61][  140/  196]   Loss 0.355720   Top1 88.730469   Top5 99.059710   BatchTime 0.370642   LR 0.000128   
2022-11-25 10:53:12,436 - INFO  - Training [61][  160/  196]   Loss 0.357812   Top1 88.601074   Top5 99.047852   BatchTime 0.370415   LR 0.000125   
2022-11-25 10:53:20,576 - INFO  - Training [61][  180/  196]   Loss 0.359719   Top1 88.476562   Top5 99.021267   BatchTime 0.374476   LR 0.000122   
2022-11-25 10:53:26,368 - INFO  - ==> Top1: 88.556    Top5: 99.002    Loss: 0.357

2022-11-25 10:53:26,658 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:53:28,373 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:53:31,046 - INFO  - Validation [61][   20/   40]   Loss 0.345366   Top1 89.550781   Top5 99.628906   BatchTime 0.133537   
2022-11-25 10:53:32,066 - INFO  - Validation [61][   40/   40]   Loss 0.326486   Top1 89.520000   Top5 99.690000   BatchTime 0.092266   
2022-11-25 10:53:32,274 - INFO  - ==> Top1: 89.520    Top5: 99.690    Loss: 0.326

2022-11-25 10:53:32,274 - INFO  - ==> Sparsity : 0.634

2022-11-25 10:53:32,274 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 10:53:32,274 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:53:32,275 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 89.710   Top5: 99.620]
2022-11-25 10:53:32,396 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:53:32,397 - INFO  - >>>>>> Epoch  62
2022-11-25 10:53:32,399 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:53:42,243 - INFO  - Training [62][   20/  196]   Loss 0.360119   Top1 88.457031   Top5 98.476562   BatchTime 0.492059   LR 0.000117   
2022-11-25 10:53:50,081 - INFO  - Training [62][   40/  196]   Loss 0.360851   Top1 88.349609   Top5 98.681641   BatchTime 0.441989   LR 0.000114   
2022-11-25 10:53:58,392 - INFO  - Training [62][   60/  196]   Loss 0.353917   Top1 88.815104   Top5 98.802083   BatchTime 0.433164   LR 0.000111   
2022-11-25 10:54:06,596 - INFO  - Training [62][   80/  196]   Loss 0.355067   Top1 88.808594   Top5 98.920898   BatchTime 0.427433   LR 0.000108   
2022-11-25 10:54:14,170 - INFO  - Training [62][  100/  196]   Loss 0.347704   Top1 89.035156   Top5 98.996094   BatchTime 0.417685   LR 0.000105   
2022-11-25 10:54:20,997 - INFO  - Training [62][  120/  196]   Loss 0.340776   Top1 89.303385   Top5 99.055990   BatchTime 0.404953   LR 0.000102   
2022-11-25 10:54:28,690 - INFO  - Training [62][  140/  196]   Loss 0.339887   Top1 89.377790   Top5 99.087612   BatchTime 0.402059   LR 0.000100   
2022-11-25 10:54:36,855 - INFO  - Training [62][  160/  196]   Loss 0.342958   Top1 89.199219   Top5 99.084473   BatchTime 0.402830   LR 0.000097   
2022-11-25 10:54:44,657 - INFO  - Training [62][  180/  196]   Loss 0.343679   Top1 89.184028   Top5 99.019097   BatchTime 0.401411   LR 0.000094   
2022-11-25 10:54:50,613 - INFO  - ==> Top1: 89.224    Top5: 99.022    Loss: 0.342

2022-11-25 10:54:50,838 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:54:52,203 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:54:54,932 - INFO  - Validation [62][   20/   40]   Loss 0.400745   Top1 87.949219   Top5 99.238281   BatchTime 0.136358   
2022-11-25 10:54:55,973 - INFO  - Validation [62][   40/   40]   Loss 0.387197   Top1 87.930000   Top5 99.430000   BatchTime 0.094210   
2022-11-25 10:54:56,187 - INFO  - ==> Top1: 87.930    Top5: 99.430    Loss: 0.387

2022-11-25 10:54:56,187 - INFO  - ==> Sparsity : 0.643

2022-11-25 10:54:56,187 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 10:54:56,188 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:54:56,188 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 89.710   Top5: 99.620]
2022-11-25 10:54:56,309 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:54:56,311 - INFO  - >>>>>> Epoch  63
2022-11-25 10:54:56,313 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:55:06,328 - INFO  - Training [63][   20/  196]   Loss 0.370530   Top1 88.125000   Top5 98.496094   BatchTime 0.500588   LR 0.000090   
2022-11-25 10:55:13,876 - INFO  - Training [63][   40/  196]   Loss 0.377111   Top1 87.910156   Top5 98.623047   BatchTime 0.439009   LR 0.000087   
2022-11-25 10:55:21,101 - INFO  - Training [63][   60/  196]   Loss 0.372832   Top1 88.164062   Top5 98.769531   BatchTime 0.413077   LR 0.000085   
2022-11-25 10:55:28,024 - INFO  - Training [63][   80/  196]   Loss 0.370442   Top1 88.183594   Top5 98.920898   BatchTime 0.396342   LR 0.000082   
2022-11-25 10:55:34,065 - INFO  - Training [63][  100/  196]   Loss 0.361607   Top1 88.558594   Top5 98.933594   BatchTime 0.377483   LR 0.000080   
2022-11-25 10:55:41,542 - INFO  - Training [63][  120/  196]   Loss 0.354156   Top1 88.863932   Top5 98.974609   BatchTime 0.376877   LR 0.000077   
2022-11-25 10:55:48,920 - INFO  - Training [63][  140/  196]   Loss 0.353718   Top1 88.847656   Top5 99.037388   BatchTime 0.375742   LR 0.000075   
2022-11-25 10:55:56,603 - INFO  - Training [63][  160/  196]   Loss 0.353582   Top1 88.808594   Top5 99.018555   BatchTime 0.376789   LR 0.000072   
2022-11-25 10:56:03,783 - INFO  - Training [63][  180/  196]   Loss 0.353761   Top1 88.815104   Top5 98.993056   BatchTime 0.374811   LR 0.000070   
2022-11-25 10:56:09,484 - INFO  - ==> Top1: 88.838    Top5: 98.978    Loss: 0.352

2022-11-25 10:56:09,874 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:56:11,850 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:56:14,621 - INFO  - Validation [63][   20/   40]   Loss 0.337431   Top1 89.550781   Top5 99.433594   BatchTime 0.138440   
2022-11-25 10:56:15,747 - INFO  - Validation [63][   40/   40]   Loss 0.316069   Top1 89.920000   Top5 99.560000   BatchTime 0.097370   
2022-11-25 10:56:15,968 - INFO  - ==> Top1: 89.920    Top5: 99.560    Loss: 0.316

2022-11-25 10:56:15,969 - INFO  - ==> Sparsity : 0.647

2022-11-25 10:56:15,969 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 10:56:15,969 - INFO  - Scoreboard best 2 ==> Epoch [63][Top1: 89.920   Top5: 99.560]
2022-11-25 10:56:15,969 - INFO  - Scoreboard best 3 ==> Epoch [47][Top1: 89.900   Top5: 99.600]
2022-11-25 10:56:16,098 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:56:16,099 - INFO  - >>>>>> Epoch  64
2022-11-25 10:56:16,101 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:56:25,265 - INFO  - Training [64][   20/  196]   Loss 0.347274   Top1 88.671875   Top5 98.398438   BatchTime 0.458088   LR 0.000066   
2022-11-25 10:56:32,549 - INFO  - Training [64][   40/  196]   Loss 0.346150   Top1 88.808594   Top5 98.701172   BatchTime 0.411124   LR 0.000064   
2022-11-25 10:56:39,934 - INFO  - Training [64][   60/  196]   Loss 0.347141   Top1 88.886719   Top5 98.776042   BatchTime 0.397163   LR 0.000062   
2022-11-25 10:56:47,338 - INFO  - Training [64][   80/  196]   Loss 0.349195   Top1 88.676758   Top5 98.911133   BatchTime 0.390430   LR 0.000059   
2022-11-25 10:56:53,574 - INFO  - Training [64][  100/  196]   Loss 0.343649   Top1 88.917969   Top5 98.976562   BatchTime 0.374698   LR 0.000057   
2022-11-25 10:57:00,721 - INFO  - Training [64][  120/  196]   Loss 0.341900   Top1 89.016927   Top5 99.029948   BatchTime 0.371807   LR 0.000055   
2022-11-25 10:57:08,234 - INFO  - Training [64][  140/  196]   Loss 0.340521   Top1 89.082031   Top5 99.062500   BatchTime 0.372354   LR 0.000053   
2022-11-25 10:57:16,066 - INFO  - Training [64][  160/  196]   Loss 0.343512   Top1 88.972168   Top5 99.094238   BatchTime 0.374764   LR 0.000051   
2022-11-25 10:57:23,499 - INFO  - Training [64][  180/  196]   Loss 0.343614   Top1 88.967014   Top5 99.062500   BatchTime 0.374417   LR 0.000049   
2022-11-25 10:57:29,956 - INFO  - ==> Top1: 89.026    Top5: 99.058    Loss: 0.342

2022-11-25 10:57:30,243 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:57:31,830 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:57:34,607 - INFO  - Validation [64][   20/   40]   Loss 0.325520   Top1 89.667969   Top5 99.453125   BatchTime 0.138754   
2022-11-25 10:57:35,716 - INFO  - Validation [64][   40/   40]   Loss 0.305595   Top1 90.120000   Top5 99.590000   BatchTime 0.097101   
2022-11-25 10:57:35,938 - INFO  - ==> Top1: 90.120    Top5: 99.590    Loss: 0.306

2022-11-25 10:57:35,938 - INFO  - ==> Sparsity : 0.650

2022-11-25 10:57:35,939 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 10:57:35,939 - INFO  - Scoreboard best 2 ==> Epoch [64][Top1: 90.120   Top5: 99.590]
2022-11-25 10:57:35,939 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 89.920   Top5: 99.560]
2022-11-25 10:57:36,071 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:57:36,073 - INFO  - >>>>>> Epoch  65
2022-11-25 10:57:36,075 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:57:44,898 - INFO  - Training [65][   20/  196]   Loss 0.348132   Top1 88.457031   Top5 98.574219   BatchTime 0.441044   LR 0.000046   
2022-11-25 10:57:52,362 - INFO  - Training [65][   40/  196]   Loss 0.354627   Top1 88.349609   Top5 98.798828   BatchTime 0.407123   LR 0.000044   
2022-11-25 10:57:59,580 - INFO  - Training [65][   60/  196]   Loss 0.353407   Top1 88.541667   Top5 98.834635   BatchTime 0.391698   LR 0.000042   
2022-11-25 10:58:06,810 - INFO  - Training [65][   80/  196]   Loss 0.350723   Top1 88.696289   Top5 98.930664   BatchTime 0.384150   LR 0.000040   
2022-11-25 10:58:13,006 - INFO  - Training [65][  100/  196]   Loss 0.345148   Top1 88.992188   Top5 98.992188   BatchTime 0.369277   LR 0.000039   
2022-11-25 10:58:20,494 - INFO  - Training [65][  120/  196]   Loss 0.338778   Top1 89.248047   Top5 99.065755   BatchTime 0.370135   LR 0.000037   
2022-11-25 10:58:27,884 - INFO  - Training [65][  140/  196]   Loss 0.338704   Top1 89.274554   Top5 99.118304   BatchTime 0.370042   LR 0.000035   
2022-11-25 10:58:35,504 - INFO  - Training [65][  160/  196]   Loss 0.339451   Top1 89.245605   Top5 99.106445   BatchTime 0.371410   LR 0.000033   
2022-11-25 10:58:43,218 - INFO  - Training [65][  180/  196]   Loss 0.339453   Top1 89.238281   Top5 99.047309   BatchTime 0.372996   LR 0.000032   
2022-11-25 10:58:49,463 - INFO  - ==> Top1: 89.258    Top5: 99.050    Loss: 0.339

2022-11-25 10:58:49,737 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:58:51,321 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:58:54,085 - INFO  - Validation [65][   20/   40]   Loss 0.342434   Top1 89.531250   Top5 99.550781   BatchTime 0.138120   
2022-11-25 10:58:55,167 - INFO  - Validation [65][   40/   40]   Loss 0.318328   Top1 90.010000   Top5 99.670000   BatchTime 0.096126   
2022-11-25 10:58:55,416 - INFO  - ==> Top1: 90.010    Top5: 99.670    Loss: 0.318

2022-11-25 10:58:55,416 - INFO  - ==> Sparsity : 0.652

2022-11-25 10:58:55,417 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 10:58:55,417 - INFO  - Scoreboard best 2 ==> Epoch [64][Top1: 90.120   Top5: 99.590]
2022-11-25 10:58:55,417 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 90.010   Top5: 99.670]
2022-11-25 10:58:55,535 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 10:58:55,537 - INFO  - >>>>>> Epoch  66
2022-11-25 10:58:55,540 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:59:04,951 - INFO  - Training [66][   20/  196]   Loss 0.347351   Top1 88.847656   Top5 98.496094   BatchTime 0.470425   LR 0.000029   
2022-11-25 10:59:12,449 - INFO  - Training [66][   40/  196]   Loss 0.354778   Top1 88.632812   Top5 98.720703   BatchTime 0.422657   LR 0.000028   
2022-11-25 10:59:19,479 - INFO  - Training [66][   60/  196]   Loss 0.359171   Top1 88.339844   Top5 98.678385   BatchTime 0.398937   LR 0.000026   
2022-11-25 10:59:26,329 - INFO  - Training [66][   80/  196]   Loss 0.354494   Top1 88.588867   Top5 98.833008   BatchTime 0.384832   LR 0.000025   
2022-11-25 10:59:32,723 - INFO  - Training [66][  100/  196]   Loss 0.347604   Top1 88.871094   Top5 98.843750   BatchTime 0.371800   LR 0.000023   
2022-11-25 10:59:40,605 - INFO  - Training [66][  120/  196]   Loss 0.341069   Top1 89.101562   Top5 98.951823   BatchTime 0.375517   LR 0.000022   
2022-11-25 10:59:48,443 - INFO  - Training [66][  140/  196]   Loss 0.338749   Top1 89.218750   Top5 99.026228   BatchTime 0.377856   LR 0.000021   
2022-11-25 10:59:55,688 - INFO  - Training [66][  160/  196]   Loss 0.340588   Top1 89.152832   Top5 99.033203   BatchTime 0.375904   LR 0.000019   
2022-11-25 11:00:03,556 - INFO  - Training [66][  180/  196]   Loss 0.342669   Top1 89.095052   Top5 98.997396   BatchTime 0.377847   LR 0.000018   
2022-11-25 11:00:09,560 - INFO  - ==> Top1: 89.172    Top5: 98.998    Loss: 0.341

2022-11-25 11:00:09,838 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:00:11,536 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:00:14,326 - INFO  - Validation [66][   20/   40]   Loss 0.343005   Top1 89.707031   Top5 99.472656   BatchTime 0.139347   
2022-11-25 11:00:15,549 - INFO  - Validation [66][   40/   40]   Loss 0.319012   Top1 90.060000   Top5 99.630000   BatchTime 0.100265   
2022-11-25 11:00:15,795 - INFO  - ==> Top1: 90.060    Top5: 99.630    Loss: 0.319

2022-11-25 11:00:15,795 - INFO  - ==> Sparsity : 0.654

2022-11-25 11:00:15,795 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 11:00:15,796 - INFO  - Scoreboard best 2 ==> Epoch [64][Top1: 90.120   Top5: 99.590]
2022-11-25 11:00:15,796 - INFO  - Scoreboard best 3 ==> Epoch [66][Top1: 90.060   Top5: 99.630]
2022-11-25 11:00:16,171 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 11:00:16,173 - INFO  - >>>>>> Epoch  67
2022-11-25 11:00:16,174 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:00:25,080 - INFO  - Training [67][   20/  196]   Loss 0.366236   Top1 88.496094   Top5 98.652344   BatchTime 0.445146   LR 0.000016   
2022-11-25 11:00:32,119 - INFO  - Training [67][   40/  196]   Loss 0.365087   Top1 88.720703   Top5 98.652344   BatchTime 0.398555   LR 0.000015   
2022-11-25 11:00:39,782 - INFO  - Training [67][   60/  196]   Loss 0.354994   Top1 88.919271   Top5 98.750000   BatchTime 0.393422   LR 0.000014   
2022-11-25 11:00:46,335 - INFO  - Training [67][   80/  196]   Loss 0.354321   Top1 88.837891   Top5 98.881836   BatchTime 0.376970   LR 0.000013   
2022-11-25 11:00:52,895 - INFO  - Training [67][  100/  196]   Loss 0.349843   Top1 88.960938   Top5 98.921875   BatchTime 0.367176   LR 0.000012   
2022-11-25 11:01:00,452 - INFO  - Training [67][  120/  196]   Loss 0.346515   Top1 89.049479   Top5 98.987630   BatchTime 0.368957   LR 0.000011   
2022-11-25 11:01:08,408 - INFO  - Training [67][  140/  196]   Loss 0.342524   Top1 89.165737   Top5 99.059710   BatchTime 0.373074   LR 0.000010   
2022-11-25 11:01:15,922 - INFO  - Training [67][  160/  196]   Loss 0.345148   Top1 89.101562   Top5 99.038086   BatchTime 0.373400   LR 0.000009   
2022-11-25 11:01:23,484 - INFO  - Training [67][  180/  196]   Loss 0.343989   Top1 89.116753   Top5 99.036458   BatchTime 0.373927   LR 0.000008   
2022-11-25 11:01:29,385 - INFO  - ==> Top1: 89.160    Top5: 99.030    Loss: 0.343

2022-11-25 11:01:29,613 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:01:31,082 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:01:33,817 - INFO  - Validation [67][   20/   40]   Loss 0.327016   Top1 89.667969   Top5 99.707031   BatchTime 0.136647   
2022-11-25 11:01:34,888 - INFO  - Validation [67][   40/   40]   Loss 0.309624   Top1 90.040000   Top5 99.700000   BatchTime 0.095109   
2022-11-25 11:01:35,138 - INFO  - ==> Top1: 90.040    Top5: 99.700    Loss: 0.310

2022-11-25 11:01:35,139 - INFO  - ==> Sparsity : 0.655

2022-11-25 11:01:35,139 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 11:01:35,139 - INFO  - Scoreboard best 2 ==> Epoch [64][Top1: 90.120   Top5: 99.590]
2022-11-25 11:01:35,139 - INFO  - Scoreboard best 3 ==> Epoch [66][Top1: 90.060   Top5: 99.630]
2022-11-25 11:01:35,284 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 11:01:35,285 - INFO  - >>>>>> Epoch  68
2022-11-25 11:01:35,287 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:01:44,452 - INFO  - Training [68][   20/  196]   Loss 0.361809   Top1 88.398438   Top5 98.515625   BatchTime 0.458094   LR 0.000007   
2022-11-25 11:01:51,842 - INFO  - Training [68][   40/  196]   Loss 0.359559   Top1 88.457031   Top5 98.701172   BatchTime 0.413807   LR 0.000006   
2022-11-25 11:01:58,807 - INFO  - Training [68][   60/  196]   Loss 0.354916   Top1 88.593750   Top5 98.743490   BatchTime 0.391954   LR 0.000006   
2022-11-25 11:02:05,952 - INFO  - Training [68][   80/  196]   Loss 0.354581   Top1 88.608398   Top5 98.833008   BatchTime 0.383277   LR 0.000005   
2022-11-25 11:02:12,463 - INFO  - Training [68][  100/  196]   Loss 0.343497   Top1 88.996094   Top5 98.894531   BatchTime 0.371726   LR 0.000004   
2022-11-25 11:02:19,478 - INFO  - Training [68][  120/  196]   Loss 0.338947   Top1 89.137370   Top5 98.948568   BatchTime 0.368235   LR 0.000004   
2022-11-25 11:02:27,313 - INFO  - Training [68][  140/  196]   Loss 0.336406   Top1 89.235491   Top5 99.029018   BatchTime 0.371590   LR 0.000003   
2022-11-25 11:02:34,653 - INFO  - Training [68][  160/  196]   Loss 0.339094   Top1 89.130859   Top5 98.981934   BatchTime 0.371014   LR 0.000003   
2022-11-25 11:02:42,048 - INFO  - Training [68][  180/  196]   Loss 0.340705   Top1 89.053819   Top5 98.964844   BatchTime 0.370877   LR 0.000002   
2022-11-25 11:02:48,074 - INFO  - ==> Top1: 89.068    Top5: 98.978    Loss: 0.341

2022-11-25 11:02:48,300 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:02:49,920 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:02:52,671 - INFO  - Validation [68][   20/   40]   Loss 0.324552   Top1 90.195312   Top5 99.589844   BatchTime 0.137467   
2022-11-25 11:02:53,778 - INFO  - Validation [68][   40/   40]   Loss 0.306479   Top1 90.370000   Top5 99.670000   BatchTime 0.096405   
2022-11-25 11:02:53,996 - INFO  - ==> Top1: 90.370    Top5: 99.670    Loss: 0.306

2022-11-25 11:02:53,996 - INFO  - ==> Sparsity : 0.655

2022-11-25 11:02:53,997 - INFO  - Scoreboard best 1 ==> Epoch [68][Top1: 90.370   Top5: 99.670]
2022-11-25 11:02:53,997 - INFO  - Scoreboard best 2 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 11:02:53,997 - INFO  - Scoreboard best 3 ==> Epoch [64][Top1: 90.120   Top5: 99.590]
2022-11-25 11:02:59,383 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_best.pth.tar
save quantized models...
2022-11-25 11:02:59,386 - INFO  - >>>>>> Epoch  69
2022-11-25 11:02:59,389 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:03:08,242 - INFO  - Training [69][   20/  196]   Loss 0.353509   Top1 88.652344   Top5 98.574219   BatchTime 0.442558   LR 0.000002   
2022-11-25 11:03:15,462 - INFO  - Training [69][   40/  196]   Loss 0.352358   Top1 88.603516   Top5 98.681641   BatchTime 0.401776   LR 0.000001   
2022-11-25 11:03:23,055 - INFO  - Training [69][   60/  196]   Loss 0.352010   Top1 88.691406   Top5 98.710938   BatchTime 0.394392   LR 0.000001   
2022-11-25 11:03:29,684 - INFO  - Training [69][   80/  196]   Loss 0.346814   Top1 88.925781   Top5 98.862305   BatchTime 0.378663   LR 0.000001   
2022-11-25 11:03:37,028 - INFO  - Training [69][  100/  196]   Loss 0.344286   Top1 89.160156   Top5 98.921875   BatchTime 0.376369   LR 0.000000   
2022-11-25 11:03:44,879 - INFO  - Training [69][  120/  196]   Loss 0.341227   Top1 89.225260   Top5 99.003906   BatchTime 0.379063   LR 0.000000   
2022-11-25 11:03:52,666 - INFO  - Training [69][  140/  196]   Loss 0.339741   Top1 89.257812   Top5 99.079241   BatchTime 0.380533   LR 0.000000   
2022-11-25 11:04:00,304 - INFO  - Training [69][  160/  196]   Loss 0.344203   Top1 89.067383   Top5 99.045410   BatchTime 0.380699   LR 0.000000   
2022-11-25 11:04:07,508 - INFO  - Training [69][  180/  196]   Loss 0.344066   Top1 89.027778   Top5 99.001736   BatchTime 0.378422   LR 0.000000   
2022-11-25 11:04:13,418 - INFO  - ==> Top1: 89.008    Top5: 98.974    Loss: 0.344

2022-11-25 11:04:13,706 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:04:15,121 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:04:17,924 - INFO  - Validation [69][   20/   40]   Loss 0.329207   Top1 90.273438   Top5 99.472656   BatchTime 0.140022   
2022-11-25 11:04:19,019 - INFO  - Validation [69][   40/   40]   Loss 0.310160   Top1 90.350000   Top5 99.590000   BatchTime 0.097405   
2022-11-25 11:04:19,270 - INFO  - ==> Top1: 90.350    Top5: 99.590    Loss: 0.310

2022-11-25 11:04:19,270 - INFO  - ==> Sparsity : 0.655

2022-11-25 11:04:19,270 - INFO  - Scoreboard best 1 ==> Epoch [68][Top1: 90.370   Top5: 99.670]
2022-11-25 11:04:19,270 - INFO  - Scoreboard best 2 ==> Epoch [69][Top1: 90.350   Top5: 99.590]
2022-11-25 11:04:19,271 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 90.270   Top5: 99.720]
2022-11-25 11:04:19,603 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/_checkpoint.pth.tar

2022-11-25 11:04:19,604 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 11:04:19,605 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:04:22,350 - INFO  - Validation [   20/   40]   Loss 0.329207   Top1 90.273438   Top5 99.472656   BatchTime 0.137179   
2022-11-25 11:04:23,364 - INFO  - Validation [   40/   40]   Loss 0.310160   Top1 90.350000   Top5 99.590000   BatchTime 0.093950   
2022-11-25 11:04:23,523 - INFO  - ==> Top1: 90.350    Top5: 99.590    Loss: 0.310

2022-11-25 11:04:23,523 - INFO  - ==> Sparsity : 0.000

2022-11-25 11:04:23,524 - INFO  - Program completed sucessfully ... exiting ...
2022-11-25 11:04:23,544 - INFO  - >>>>>> Epoch   0
2022-11-25 11:04:23,546 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:04:32,144 - INFO  - Training [0][   20/  196]   Loss 0.588464   Top1 79.687500   Top5 97.617188   BatchTime 0.429759   LR 0.004999   
2022-11-25 11:04:39,005 - INFO  - Training [0][   40/  196]   Loss 0.574153   Top1 80.224609   Top5 97.890625   BatchTime 0.386407   LR 0.004995   
2022-11-25 11:04:45,484 - INFO  - Training [0][   60/  196]   Loss 0.569526   Top1 80.247396   Top5 97.877604   BatchTime 0.365582   LR 0.004989   
2022-11-25 11:04:51,888 - INFO  - Training [0][   80/  196]   Loss 0.566016   Top1 80.400391   Top5 98.061523   BatchTime 0.354240   LR 0.004980   
2022-11-25 11:04:59,195 - INFO  - Training [0][  100/  196]   Loss 0.560746   Top1 80.492188   Top5 98.167969   BatchTime 0.356457   LR 0.004968   
2022-11-25 11:05:06,591 - INFO  - Training [0][  120/  196]   Loss 0.551908   Top1 80.719401   Top5 98.268229   BatchTime 0.358680   LR 0.004954   
2022-11-25 11:05:13,747 - INFO  - Training [0][  140/  196]   Loss 0.550495   Top1 80.809152   Top5 98.320312   BatchTime 0.358555   LR 0.004938   
2022-11-25 11:05:20,589 - INFO  - Training [0][  160/  196]   Loss 0.552037   Top1 80.778809   Top5 98.251953   BatchTime 0.356498   LR 0.004919   
2022-11-25 11:05:27,717 - INFO  - Training [0][  180/  196]   Loss 0.554797   Top1 80.690104   Top5 98.211806   BatchTime 0.356486   LR 0.004897   
2022-11-25 11:05:33,285 - INFO  - ==> Top1: 80.760    Top5: 98.196    Loss: 0.554

2022-11-25 11:05:33,500 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:05:35,116 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:05:37,762 - INFO  - Validation [0][   20/   40]   Loss 0.535097   Top1 82.636719   Top5 98.925781   BatchTime 0.132210   
2022-11-25 11:05:38,842 - INFO  - Validation [0][   40/   40]   Loss 0.527173   Top1 82.560000   Top5 99.060000   BatchTime 0.093112   
2022-11-25 11:05:39,077 - INFO  - ==> Top1: 82.560    Top5: 99.060    Loss: 0.527

2022-11-25 11:05:39,077 - INFO  - ==> Sparsity : 0.706

2022-11-25 11:05:39,078 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 82.560   Top5: 99.060]
2022-11-25 11:05:44,511 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 11:05:44,514 - INFO  - >>>>>> Epoch   1
2022-11-25 11:05:44,516 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:05:53,223 - INFO  - Training [1][   20/  196]   Loss 0.582532   Top1 79.433594   Top5 97.695312   BatchTime 0.435258   LR 0.004853   
2022-11-25 11:05:59,881 - INFO  - Training [1][   40/  196]   Loss 0.583104   Top1 79.628906   Top5 97.812500   BatchTime 0.384065   LR 0.004825   
2022-11-25 11:06:05,795 - INFO  - Training [1][   60/  196]   Loss 0.570378   Top1 80.000000   Top5 97.858073   BatchTime 0.354611   LR 0.004794   
2022-11-25 11:06:12,451 - INFO  - Training [1][   80/  196]   Loss 0.570413   Top1 80.039062   Top5 97.924805   BatchTime 0.349152   LR 0.004761   
2022-11-25 11:06:20,085 - INFO  - Training [1][  100/  196]   Loss 0.565324   Top1 80.292969   Top5 97.988281   BatchTime 0.355666   LR 0.004725   
2022-11-25 11:06:26,795 - INFO  - Training [1][  120/  196]   Loss 0.557119   Top1 80.611979   Top5 98.076172   BatchTime 0.352301   LR 0.004687   
2022-11-25 11:06:33,554 - INFO  - Training [1][  140/  196]   Loss 0.560132   Top1 80.613839   Top5 98.099888   BatchTime 0.350254   LR 0.004647   
2022-11-25 11:06:40,507 - INFO  - Training [1][  160/  196]   Loss 0.560746   Top1 80.578613   Top5 98.120117   BatchTime 0.349928   LR 0.004605   
2022-11-25 11:06:47,456 - INFO  - Training [1][  180/  196]   Loss 0.560214   Top1 80.529514   Top5 98.070747   BatchTime 0.349652   LR 0.004560   
2022-11-25 11:06:53,203 - INFO  - ==> Top1: 79.414    Top5: 97.278    Loss: 0.588

2022-11-25 11:06:53,424 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:06:54,939 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:06:57,779 - INFO  - Validation [1][   20/   40]   Loss 129.338466   Top1 10.253906   Top5 50.214844   BatchTime 0.141923   
2022-11-25 11:06:58,933 - INFO  - Validation [1][   40/   40]   Loss 129.811661   Top1 10.000000   Top5 50.000000   BatchTime 0.099822   
2022-11-25 11:06:59,185 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 129.812

2022-11-25 11:06:59,185 - INFO  - ==> Sparsity : 0.313

2022-11-25 11:06:59,185 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 82.560   Top5: 99.060]
2022-11-25 11:06:59,186 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 10.000   Top5: 50.000]
2022-11-25 11:06:59,310 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/88hard_pruning_checkpoint.pth.tar

2022-11-25 11:06:59,312 - INFO  - >>>>>> Epoch   2
2022-11-25 11:06:59,314 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:07:07,801 - INFO  - Training [2][   20/  196]   Loss 2.347130   Top1 9.414062   Top5 49.667969   BatchTime 0.424212   LR 0.004477   
2022-11-25 11:07:14,718 - INFO  - Training [2][   40/  196]   Loss 2.349835   Top1 9.580078   Top5 49.492188   BatchTime 0.385031   LR 0.004426   
2022-11-25 11:07:21,594 - INFO  - Training [2][   60/  196]   Loss 2.343809   Top1 9.524740   Top5 49.648438   BatchTime 0.371284   LR 0.004374   
2022-11-25 11:07:27,400 - INFO  - Training [2][   80/  196]   Loss 2.340528   Top1 9.448242   Top5 49.565430   BatchTime 0.351044   LR 0.004320   
2022-11-25 11:07:34,483 - INFO  - Training [2][  100/  196]   Loss 2.337079   Top1 9.617188   Top5 49.914062   BatchTime 0.351657   LR 0.004264   
2022-11-25 11:07:41,848 - INFO  - Training [2][  120/  196]   Loss 2.332750   Top1 9.746094   Top5 50.182292   BatchTime 0.354422   LR 0.004206   
2022-11-25 11:07:48,734 - INFO  - Training [2][  140/  196]   Loss 2.330411   Top1 9.665179   Top5 50.066964   BatchTime 0.352977   LR 0.004146   
2022-11-25 11:07:56,367 - INFO  - Training [2][  160/  196]   Loss 2.328286   Top1 9.746094   Top5 50.026855   BatchTime 0.356560   LR 0.004085   
2022-11-25 11:08:04,070 - INFO  - Training [2][  180/  196]   Loss 2.326547   Top1 9.756944   Top5 50.093316   BatchTime 0.359739   LR 0.004022   
2022-11-25 11:08:09,701 - INFO  - ==> Top1: 9.718    Top5: 49.888    Loss: 2.326

2022-11-25 11:08:09,988 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:08:11,755 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:08:14,553 - INFO  - Validation [2][   20/   40]   Loss 88.262582   Top1 10.253906   Top5 50.468750   BatchTime 0.139825   
2022-11-25 11:08:15,657 - INFO  - Validation [2][   40/   40]   Loss 88.634898   Top1 10.000000   Top5 50.000000   BatchTime 0.097530   
2022-11-25 11:08:15,899 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 88.635

2022-11-25 11:08:15,899 - INFO  - ==> Sparsity : 0.282

2022-11-25 11:08:15,899 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 82.560   Top5: 99.060]
2022-11-25 11:08:15,899 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
2022-11-25 11:08:15,899 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 10.000   Top5: 50.000]
2022-11-25 11:08:16,045 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/88hard_pruning_checkpoint.pth.tar

2022-11-25 11:08:16,047 - INFO  - >>>>>> Epoch   3
2022-11-25 11:08:16,048 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:08:24,938 - INFO  - Training [3][   20/  196]   Loss 2.318510   Top1 8.867188   Top5 49.433594   BatchTime 0.444349   LR 0.003907   
2022-11-25 11:08:32,043 - INFO  - Training [3][   40/  196]   Loss 2.313197   Top1 9.365234   Top5 50.000000   BatchTime 0.399767   LR 0.003840   
2022-11-25 11:08:38,743 - INFO  - Training [3][   60/  196]   Loss 2.311741   Top1 9.746094   Top5 49.882812   BatchTime 0.378194   LR 0.003771   
2022-11-25 11:08:44,352 - INFO  - Training [3][   80/  196]   Loss 2.310970   Top1 9.814453   Top5 49.848633   BatchTime 0.353755   LR 0.003701   
2022-11-25 11:08:50,990 - INFO  - Training [3][  100/  196]   Loss 2.310525   Top1 9.937500   Top5 49.882812   BatchTime 0.349386   LR 0.003630   
2022-11-25 11:08:58,765 - INFO  - Training [3][  120/  196]   Loss 2.310022   Top1 9.876302   Top5 49.902344   BatchTime 0.355947   LR 0.003558   
2022-11-25 11:09:05,578 - INFO  - Training [3][  140/  196]   Loss 2.309443   Top1 9.882812   Top5 49.997210   BatchTime 0.353760   LR 0.003484   
2022-11-25 11:09:12,388 - INFO  - Training [3][  160/  196]   Loss 2.308920   Top1 10.048828   Top5 50.095215   BatchTime 0.352098   LR 0.003410   
2022-11-25 11:09:19,160 - INFO  - Training [3][  180/  196]   Loss 2.308550   Top1 10.108507   Top5 50.188802   BatchTime 0.350601   LR 0.003335   
2022-11-25 11:09:24,713 - INFO  - ==> Top1: 10.102    Top5: 50.094    Loss: 2.308

2022-11-25 11:09:24,966 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:09:26,402 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:09:29,327 - INFO  - Validation [3][   20/   40]   Loss 99.394653   Top1 10.253906   Top5 50.214844   BatchTime 0.146132   
2022-11-25 11:09:30,364 - INFO  - Validation [3][   40/   40]   Loss 99.808261   Top1 10.000000   Top5 50.000000   BatchTime 0.098995   
2022-11-25 11:09:30,618 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 99.808

2022-11-25 11:09:30,618 - INFO  - ==> Sparsity : 0.284

2022-11-25 11:09:30,618 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 82.560   Top5: 99.060]
2022-11-25 11:09:30,618 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
2022-11-25 11:09:30,619 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
2022-11-25 11:09:30,791 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/88hard_pruning_checkpoint.pth.tar

2022-11-25 11:09:30,793 - INFO  - >>>>>> Epoch   4
2022-11-25 11:09:30,795 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:09:39,478 - INFO  - Training [4][   20/  196]   Loss 2.305957   Top1 10.703125   Top5 49.121094   BatchTime 0.434053   LR 0.003200   
2022-11-25 11:09:46,383 - INFO  - Training [4][   40/  196]   Loss 2.306490   Top1 10.146484   Top5 49.726562   BatchTime 0.389627   LR 0.003122   
2022-11-25 11:09:53,228 - INFO  - Training [4][   60/  196]   Loss 2.305708   Top1 10.026042   Top5 49.876302   BatchTime 0.373845   LR 0.003044   
2022-11-25 11:09:59,573 - INFO  - Training [4][   80/  196]   Loss 2.305504   Top1 10.004883   Top5 49.921875   BatchTime 0.359688   LR 0.002965   
2022-11-25 11:10:05,313 - INFO  - Training [4][  100/  196]   Loss 2.305389   Top1 10.007812   Top5 49.816406   BatchTime 0.345156   LR 0.002886   
2022-11-25 11:10:12,438 - INFO  - Training [4][  120/  196]   Loss 2.305311   Top1 10.019531   Top5 49.837240   BatchTime 0.347002   LR 0.002806   
2022-11-25 11:10:19,570 - INFO  - Training [4][  140/  196]   Loss 2.305398   Top1 9.988839   Top5 49.796317   BatchTime 0.348370   LR 0.002726   
2022-11-25 11:10:26,590 - INFO  - Training [4][  160/  196]   Loss 2.305252   Top1 9.990234   Top5 49.855957   BatchTime 0.348699   LR 0.002646   
2022-11-25 11:10:33,407 - INFO  - Training [4][  180/  196]   Loss 2.305266   Top1 9.937066   Top5 49.841580   BatchTime 0.347826   LR 0.002566   
2022-11-25 11:10:38,887 - INFO  - ==> Top1: 9.934    Top5: 49.938    Loss: 2.305

2022-11-25 11:10:39,136 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:10:40,889 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:10:43,633 - INFO  - Validation [4][   20/   40]   Loss 85.017147   Top1 10.253906   Top5 50.214844   BatchTime 0.137099   
2022-11-25 11:10:44,758 - INFO  - Validation [4][   40/   40]   Loss 85.379832   Top1 10.000000   Top5 50.000000   BatchTime 0.096686   
2022-11-25 11:10:44,998 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 85.380

2022-11-25 11:10:44,998 - INFO  - ==> Sparsity : 0.285

2022-11-25 11:10:44,998 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 82.560   Top5: 99.060]
2022-11-25 11:10:44,998 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
2022-11-25 11:10:44,998 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
2022-11-25 11:10:45,131 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/88hard_pruning_checkpoint.pth.tar

2022-11-25 11:10:45,133 - INFO  - >>>>>> Epoch   5
2022-11-25 11:10:45,135 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:10:53,565 - INFO  - Training [5][   20/  196]   Loss 2.303798   Top1 9.921875   Top5 50.429688   BatchTime 0.421362   LR 0.002424   
2022-11-25 11:11:00,407 - INFO  - Training [5][   40/  196]   Loss 2.304775   Top1 9.423828   Top5 49.726562   BatchTime 0.381748   LR 0.002343   
2022-11-25 11:11:07,253 - INFO  - Training [5][   60/  196]   Loss 2.304328   Top1 9.720052   Top5 49.804688   BatchTime 0.368584   LR 0.002263   
2022-11-25 11:11:13,936 - INFO  - Training [5][   80/  196]   Loss 2.303952   Top1 9.960938   Top5 50.058594   BatchTime 0.359972   LR 0.002183   
2022-11-25 11:11:20,025 - INFO  - Training [5][  100/  196]   Loss 2.304436   Top1 9.832031   Top5 49.750000   BatchTime 0.348868   LR 0.002104   
2022-11-25 11:11:26,722 - INFO  - Training [5][  120/  196]   Loss 2.304633   Top1 9.889323   Top5 49.628906   BatchTime 0.346531   LR 0.002024   
2022-11-25 11:11:33,548 - INFO  - Training [5][  140/  196]   Loss 2.304491   Top1 9.907924   Top5 49.743304   BatchTime 0.345783   LR 0.001946   
2022-11-25 11:11:40,684 - INFO  - Training [5][  160/  196]   Loss 2.304476   Top1 9.794922   Top5 49.641113   BatchTime 0.347160   LR 0.001868   
2022-11-25 11:11:47,725 - INFO  - Training [5][  180/  196]   Loss 2.304421   Top1 9.819878   Top5 49.737413   BatchTime 0.347703   LR 0.001790   
2022-11-25 11:11:53,203 - INFO  - ==> Top1: 9.814    Top5: 49.648    Loss: 2.304

2022-11-25 11:11:53,467 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:11:54,986 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:11:57,729 - INFO  - Validation [5][   20/   40]   Loss 79.298018   Top1 10.253906   Top5 50.214844   BatchTime 0.137076   
2022-11-25 11:11:58,809 - INFO  - Validation [5][   40/   40]   Loss 79.649358   Top1 10.000000   Top5 50.000000   BatchTime 0.095544   
2022-11-25 11:11:59,036 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 79.649

2022-11-25 11:11:59,037 - INFO  - ==> Sparsity : 0.285

2022-11-25 11:11:59,037 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 82.560   Top5: 99.060]
2022-11-25 11:11:59,037 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
2022-11-25 11:11:59,037 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
2022-11-25 11:11:59,200 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/88hard_pruning_checkpoint.pth.tar

2022-11-25 11:11:59,202 - INFO  - >>>>>> Epoch   6
2022-11-25 11:11:59,204 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:12:08,106 - INFO  - Training [6][   20/  196]   Loss 2.304530   Top1 9.765625   Top5 49.960938   BatchTime 0.444959   LR 0.001655   
2022-11-25 11:12:15,049 - INFO  - Training [6][   40/  196]   Loss 2.303916   Top1 10.156250   Top5 50.400391   BatchTime 0.396076   LR 0.001580   
2022-11-25 11:12:21,768 - INFO  - Training [6][   60/  196]   Loss 2.303623   Top1 9.986979   Top5 50.462240   BatchTime 0.376024   LR 0.001506   
2022-11-25 11:12:28,401 - INFO  - Training [6][   80/  196]   Loss 2.303325   Top1 10.136719   Top5 50.708008   BatchTime 0.364929   LR 0.001432   
2022-11-25 11:12:35,054 - INFO  - Training [6][  100/  196]   Loss 2.303240   Top1 10.121094   Top5 50.636719   BatchTime 0.358472   LR 0.001360   
2022-11-25 11:12:40,300 - INFO  - Training [6][  120/  196]   Loss 2.303246   Top1 10.208333   Top5 50.439453   BatchTime 0.342443   LR 0.001289   
2022-11-25 11:12:46,548 - INFO  - Training [6][  140/  196]   Loss 2.303210   Top1 10.164621   Top5 50.571987   BatchTime 0.338152   LR 0.001220   
2022-11-25 11:12:53,436 - INFO  - Training [6][  160/  196]   Loss 2.303300   Top1 10.109863   Top5 50.563965   BatchTime 0.338930   LR 0.001151   
2022-11-25 11:13:00,072 - INFO  - Training [6][  180/  196]   Loss 2.303230   Top1 10.112847   Top5 50.523003   BatchTime 0.338136   LR 0.001084   
2022-11-25 11:13:05,480 - INFO  - ==> Top1: 10.124    Top5: 50.532    Loss: 2.303

2022-11-25 11:13:06,059 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:13:07,659 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:13:10,318 - INFO  - Validation [6][   20/   40]   Loss 76.739457   Top1 10.253906   Top5 50.214844   BatchTime 0.132859   
2022-11-25 11:13:11,397 - INFO  - Validation [6][   40/   40]   Loss 77.073659   Top1 10.000000   Top5 50.000000   BatchTime 0.093398   
2022-11-25 11:13:11,615 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 77.074

2022-11-25 11:13:11,615 - INFO  - ==> Sparsity : 0.285

2022-11-25 11:13:11,616 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 82.560   Top5: 99.060]
2022-11-25 11:13:11,616 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
2022-11-25 11:13:11,616 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
2022-11-25 11:13:11,766 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-092958/88hard_pruning_checkpoint.pth.tar

2022-11-25 11:13:11,768 - INFO  - >>>>>> Epoch   7
2022-11-25 11:13:11,769 - INFO  - Training: 50000 samples (256 per mini-batch)
