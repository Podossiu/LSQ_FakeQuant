2022-10-28 07:58:33,186 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-075833/88_20221028-075833.log
2022-10-28 07:58:34,925 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 07:58:34,958 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-28 07:58:35,124 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 07:58:35,124 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 07:58:36,367 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 07:58:36,367 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 07:58:39,251 - INFO  - Validation [   20/   40]   Loss 3047.717822   Top1 12.753906   Top5 57.070312   BatchTime 0.144147   
2022-10-28 07:58:40,986 - INFO  - Validation [   40/   40]   Loss 3031.409704   Top1 12.670000   Top5 56.460000   BatchTime 0.115446   
2022-10-28 07:58:41,047 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-28 07:58:41,047 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 07:58:41,047 - INFO  - >>>>>> Epoch   0
2022-10-28 07:58:41,047 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 07:58:43,321 - INFO  - Training [0][   20/  196]   Loss 1.111732   Top1 70.175781   Top5 97.519531   BatchTime 0.113650   LR 0.001000   
2022-10-28 07:58:45,025 - INFO  - Training [0][   40/  196]   Loss 0.860091   Top1 75.615234   Top5 98.310547   BatchTime 0.099440   LR 0.001000   
2022-10-28 07:58:46,731 - INFO  - Training [0][   60/  196]   Loss 0.734230   Top1 78.684896   Top5 98.606771   BatchTime 0.094711   LR 0.001000   
2022-10-28 07:58:48,435 - INFO  - Training [0][   80/  196]   Loss 0.663459   Top1 80.385742   Top5 98.769531   BatchTime 0.092342   LR 0.001000   
2022-10-28 07:58:50,140 - INFO  - Training [0][  100/  196]   Loss 0.610135   Top1 81.687500   Top5 98.906250   BatchTime 0.090920   LR 0.001000   
2022-10-28 07:58:51,844 - INFO  - Training [0][  120/  196]   Loss 0.574572   Top1 82.649740   Top5 99.003906   BatchTime 0.089964   LR 0.001000   
2022-10-28 07:58:53,549 - INFO  - Training [0][  140/  196]   Loss 0.541158   Top1 83.459821   Top5 99.084821   BatchTime 0.089291   LR 0.001000   
2022-10-28 07:58:55,254 - INFO  - Training [0][  160/  196]   Loss 0.515742   Top1 84.118652   Top5 99.140625   BatchTime 0.088785   LR 0.001000   
2022-10-28 07:58:56,940 - INFO  - Training [0][  180/  196]   Loss 0.496040   Top1 84.615885   Top5 99.197049   BatchTime 0.088289   LR 0.001000   
2022-10-28 07:58:58,320 - INFO  - ==> Top1: 85.010    Top5: 99.252    Loss: 0.481

