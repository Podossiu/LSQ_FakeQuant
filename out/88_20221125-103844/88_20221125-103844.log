2022-11-25 10:38:44,840 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88_20221125-103844.log
2022-11-25 10:38:49,293 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-25 10:38:51,296 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-25 10:38:52,014 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
2022-11-25 10:38:52,014 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005

2022-11-25 10:38:52,297 - INFO  - >>>>>> Epoch   0
2022-11-25 10:38:52,300 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:39:01,892 - INFO  - Training [0][   20/  196]   Loss 1.577210   Top1 53.574219   Top5 89.453125   BatchTime 0.479493   LR 0.004999   
2022-11-25 10:39:08,456 - INFO  - Training [0][   40/  196]   Loss 1.482339   Top1 52.714844   Top5 89.892578   BatchTime 0.403854   LR 0.004995   
2022-11-25 10:39:16,324 - INFO  - Training [0][   60/  196]   Loss 1.381680   Top1 54.739583   Top5 90.989583   BatchTime 0.400370   LR 0.004989   
2022-11-25 10:39:24,324 - INFO  - Training [0][   80/  196]   Loss 1.310006   Top1 56.733398   Top5 91.875000   BatchTime 0.400276   LR 0.004980   
2022-11-25 10:39:32,413 - INFO  - Training [0][  100/  196]   Loss 1.249231   Top1 58.441406   Top5 92.589844   BatchTime 0.401104   LR 0.004968   
2022-11-25 10:39:40,632 - INFO  - Training [0][  120/  196]   Loss 1.201458   Top1 60.022786   Top5 93.050130   BatchTime 0.402742   LR 0.004954   
2022-11-25 10:39:48,660 - INFO  - Training [0][  140/  196]   Loss 1.167408   Top1 61.057478   Top5 93.434710   BatchTime 0.402552   LR 0.004938   
2022-11-25 10:39:56,958 - INFO  - Training [0][  160/  196]   Loss 1.144688   Top1 61.733398   Top5 93.618164   BatchTime 0.404096   LR 0.004919   
2022-11-25 10:40:04,854 - INFO  - Training [0][  180/  196]   Loss 1.121922   Top1 62.378472   Top5 93.808594   BatchTime 0.403060   LR 0.004897   
2022-11-25 10:40:11,233 - INFO  - ==> Top1: 62.978    Top5: 93.954    Loss: 1.104

2022-11-25 10:40:11,479 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:40:12,860 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:40:15,142 - INFO  - Validation [0][   20/   40]   Loss 0.830979   Top1 73.652344   Top5 97.382812   BatchTime 0.114022   
2022-11-25 10:40:16,340 - INFO  - Validation [0][   40/   40]   Loss 0.836001   Top1 73.270000   Top5 97.400000   BatchTime 0.086958   
2022-11-25 10:40:16,536 - INFO  - ==> Top1: 73.270    Top5: 97.400    Loss: 0.836

2022-11-25 10:40:16,537 - INFO  - ==> Sparsity : 0.118

2022-11-25 10:40:16,537 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 73.270   Top5: 97.400]
2022-11-25 10:40:24,291 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 10:40:24,295 - INFO  - >>>>>> Epoch   1
2022-11-25 10:40:24,299 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:40:33,484 - INFO  - Training [1][   20/  196]   Loss 0.930904   Top1 68.359375   Top5 95.605469   BatchTime 0.458939   LR 0.004853   
2022-11-25 10:40:40,848 - INFO  - Training [1][   40/  196]   Loss 0.923264   Top1 68.359375   Top5 95.732422   BatchTime 0.413581   LR 0.004825   
2022-11-25 10:40:47,939 - INFO  - Training [1][   60/  196]   Loss 0.913641   Top1 68.548177   Top5 95.794271   BatchTime 0.393899   LR 0.004794   
2022-11-25 10:40:55,291 - INFO  - Training [1][   80/  196]   Loss 0.898872   Top1 69.155273   Top5 96.044922   BatchTime 0.387329   LR 0.004761   
2022-11-25 10:41:02,333 - INFO  - Training [1][  100/  196]   Loss 0.884910   Top1 69.695312   Top5 96.113281   BatchTime 0.380284   LR 0.004725   
2022-11-25 10:41:09,550 - INFO  - Training [1][  120/  196]   Loss 0.875385   Top1 70.107422   Top5 96.207682   BatchTime 0.377045   LR 0.004687   
2022-11-25 10:41:16,865 - INFO  - Training [1][  140/  196]   Loss 0.864513   Top1 70.571987   Top5 96.350446   BatchTime 0.375431   LR 0.004647   
2022-11-25 10:41:24,187 - INFO  - Training [1][  160/  196]   Loss 0.861409   Top1 70.617676   Top5 96.354980   BatchTime 0.374263   LR 0.004605   
2022-11-25 10:41:31,187 - INFO  - Training [1][  180/  196]   Loss 0.852758   Top1 70.898438   Top5 96.356337   BatchTime 0.371566   LR 0.004560   
2022-11-25 10:41:36,928 - INFO  - ==> Top1: 71.036    Top5: 96.364    Loss: 0.849

2022-11-25 10:41:37,152 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:41:38,912 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:41:41,680 - INFO  - Validation [1][   20/   40]   Loss 0.614453   Top1 79.355469   Top5 98.496094   BatchTime 0.138294   
2022-11-25 10:41:42,943 - INFO  - Validation [1][   40/   40]   Loss 0.620314   Top1 78.990000   Top5 98.510000   BatchTime 0.100725   
2022-11-25 10:41:43,172 - INFO  - ==> Top1: 78.990    Top5: 98.510    Loss: 0.620

2022-11-25 10:41:43,172 - INFO  - ==> Sparsity : 0.126

2022-11-25 10:41:43,172 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 78.990   Top5: 98.510]
2022-11-25 10:41:43,172 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 73.270   Top5: 97.400]
2022-11-25 10:41:49,912 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 10:41:49,916 - INFO  - >>>>>> Epoch   2
2022-11-25 10:41:49,919 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:41:58,766 - INFO  - Training [2][   20/  196]   Loss 0.837033   Top1 71.972656   Top5 95.664062   BatchTime 0.442204   LR 0.004477   
2022-11-25 10:42:06,103 - INFO  - Training [2][   40/  196]   Loss 0.819110   Top1 72.773438   Top5 95.947266   BatchTime 0.404531   LR 0.004426   
2022-11-25 10:42:13,221 - INFO  - Training [2][   60/  196]   Loss 0.805805   Top1 72.962240   Top5 96.217448   BatchTime 0.388331   LR 0.004374   
2022-11-25 10:42:20,553 - INFO  - Training [2][   80/  196]   Loss 0.793803   Top1 73.364258   Top5 96.459961   BatchTime 0.382892   LR 0.004320   
2022-11-25 10:42:27,826 - INFO  - Training [2][  100/  196]   Loss 0.778424   Top1 73.726562   Top5 96.550781   BatchTime 0.379046   LR 0.004264   
2022-11-25 10:42:35,208 - INFO  - Training [2][  120/  196]   Loss 0.771053   Top1 73.945312   Top5 96.676432   BatchTime 0.377387   LR 0.004206   
2022-11-25 10:42:42,504 - INFO  - Training [2][  140/  196]   Loss 0.769257   Top1 73.998326   Top5 96.721540   BatchTime 0.375588   LR 0.004146   
2022-11-25 10:42:49,757 - INFO  - Training [2][  160/  196]   Loss 0.769434   Top1 74.038086   Top5 96.716309   BatchTime 0.373971   LR 0.004085   
2022-11-25 10:42:57,046 - INFO  - Training [2][  180/  196]   Loss 0.765029   Top1 74.160156   Top5 96.673177   BatchTime 0.372913   LR 0.004022   
2022-11-25 10:43:02,407 - INFO  - ==> Top1: 74.288    Top5: 96.680    Loss: 0.761

2022-11-25 10:43:02,613 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:43:04,900 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:43:07,866 - INFO  - Validation [2][   20/   40]   Loss 0.631960   Top1 79.687500   Top5 98.652344   BatchTime 0.148175   
2022-11-25 10:43:09,026 - INFO  - Validation [2][   40/   40]   Loss 0.623956   Top1 79.370000   Top5 98.660000   BatchTime 0.103097   
2022-11-25 10:43:09,234 - INFO  - ==> Top1: 79.370    Top5: 98.660    Loss: 0.624

2022-11-25 10:43:09,235 - INFO  - ==> Sparsity : 0.144

2022-11-25 10:43:09,235 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 79.370   Top5: 98.660]
2022-11-25 10:43:09,235 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 78.990   Top5: 98.510]
2022-11-25 10:43:09,235 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 73.270   Top5: 97.400]
2022-11-25 10:43:16,568 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 10:43:16,571 - INFO  - >>>>>> Epoch   3
2022-11-25 10:43:16,573 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:43:25,429 - INFO  - Training [3][   20/  196]   Loss 0.721567   Top1 75.136719   Top5 96.796875   BatchTime 0.442659   LR 0.003907   
2022-11-25 10:43:32,506 - INFO  - Training [3][   40/  196]   Loss 0.725366   Top1 75.068359   Top5 96.894531   BatchTime 0.398245   LR 0.003840   
2022-11-25 10:43:39,988 - INFO  - Training [3][   60/  196]   Loss 0.721218   Top1 75.136719   Top5 97.011719   BatchTime 0.390208   LR 0.003771   
2022-11-25 10:43:47,184 - INFO  - Training [3][   80/  196]   Loss 0.709942   Top1 75.717773   Top5 97.114258   BatchTime 0.382606   LR 0.003701   
2022-11-25 10:43:54,336 - INFO  - Training [3][  100/  196]   Loss 0.699132   Top1 76.144531   Top5 97.175781   BatchTime 0.377601   LR 0.003630   
2022-11-25 10:44:01,445 - INFO  - Training [3][  120/  196]   Loss 0.695024   Top1 76.344401   Top5 97.226562   BatchTime 0.373911   LR 0.003558   
2022-11-25 10:44:08,692 - INFO  - Training [3][  140/  196]   Loss 0.689027   Top1 76.515067   Top5 97.307478   BatchTime 0.372252   LR 0.003484   
2022-11-25 10:44:16,048 - INFO  - Training [3][  160/  196]   Loss 0.689855   Top1 76.425781   Top5 97.319336   BatchTime 0.371699   LR 0.003410   
2022-11-25 10:44:22,465 - INFO  - Training [3][  180/  196]   Loss 0.687436   Top1 76.438802   Top5 97.261285   BatchTime 0.366048   LR 0.003335   
2022-11-25 10:44:27,548 - INFO  - ==> Top1: 76.570    Top5: 97.250    Loss: 0.684

2022-11-25 10:44:27,819 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:44:29,433 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:44:32,047 - INFO  - Validation [3][   20/   40]   Loss 0.468931   Top1 84.082031   Top5 99.101562   BatchTime 0.130585   
2022-11-25 10:44:33,207 - INFO  - Validation [3][   40/   40]   Loss 0.460253   Top1 84.290000   Top5 99.290000   BatchTime 0.094297   
2022-11-25 10:44:33,441 - INFO  - ==> Top1: 84.290    Top5: 99.290    Loss: 0.460

2022-11-25 10:44:33,441 - INFO  - ==> Sparsity : 0.208

2022-11-25 10:44:33,441 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 84.290   Top5: 99.290]
2022-11-25 10:44:33,441 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 79.370   Top5: 98.660]
2022-11-25 10:44:33,442 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 78.990   Top5: 98.510]
2022-11-25 10:44:40,138 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 10:44:40,142 - INFO  - >>>>>> Epoch   4
2022-11-25 10:44:40,144 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:44:48,960 - INFO  - Training [4][   20/  196]   Loss 0.678999   Top1 76.699219   Top5 96.738281   BatchTime 0.440634   LR 0.003200   
2022-11-25 10:44:56,303 - INFO  - Training [4][   40/  196]   Loss 0.658223   Top1 77.695312   Top5 97.197266   BatchTime 0.403893   LR 0.003122   
2022-11-25 10:45:03,751 - INFO  - Training [4][   60/  196]   Loss 0.657304   Top1 77.591146   Top5 97.298177   BatchTime 0.393397   LR 0.003044   
2022-11-25 10:45:10,931 - INFO  - Training [4][   80/  196]   Loss 0.656273   Top1 77.495117   Top5 97.377930   BatchTime 0.384802   LR 0.002965   
2022-11-25 10:45:18,337 - INFO  - Training [4][  100/  196]   Loss 0.645450   Top1 77.964844   Top5 97.468750   BatchTime 0.381899   LR 0.002886   
2022-11-25 10:45:25,682 - INFO  - Training [4][  120/  196]   Loss 0.636178   Top1 78.294271   Top5 97.565104   BatchTime 0.379455   LR 0.002806   
2022-11-25 10:45:32,863 - INFO  - Training [4][  140/  196]   Loss 0.633765   Top1 78.417969   Top5 97.617188   BatchTime 0.376543   LR 0.002726   
2022-11-25 10:45:39,276 - INFO  - Training [4][  160/  196]   Loss 0.634230   Top1 78.430176   Top5 97.634277   BatchTime 0.369556   LR 0.002646   
2022-11-25 10:45:45,846 - INFO  - Training [4][  180/  196]   Loss 0.631057   Top1 78.532986   Top5 97.586806   BatchTime 0.364989   LR 0.002566   
2022-11-25 10:45:51,836 - INFO  - ==> Top1: 78.636    Top5: 97.586    Loss: 0.628

2022-11-25 10:45:52,102 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:45:53,640 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:45:56,283 - INFO  - Validation [4][   20/   40]   Loss 0.476248   Top1 84.355469   Top5 99.199219   BatchTime 0.132013   
2022-11-25 10:45:57,375 - INFO  - Validation [4][   40/   40]   Loss 0.469229   Top1 84.300000   Top5 99.250000   BatchTime 0.093329   
2022-11-25 10:45:57,610 - INFO  - ==> Top1: 84.300    Top5: 99.250    Loss: 0.469

2022-11-25 10:45:57,610 - INFO  - ==> Sparsity : 0.247

2022-11-25 10:45:57,610 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 84.300   Top5: 99.250]
2022-11-25 10:45:57,610 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 84.290   Top5: 99.290]
2022-11-25 10:45:57,611 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 79.370   Top5: 98.660]
2022-11-25 10:46:03,702 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 10:46:03,706 - INFO  - >>>>>> Epoch   5
2022-11-25 10:46:03,708 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:46:12,267 - INFO  - Training [5][   20/  196]   Loss 0.609030   Top1 79.082031   Top5 97.402344   BatchTime 0.427857   LR 0.002424   
2022-11-25 10:46:19,448 - INFO  - Training [5][   40/  196]   Loss 0.626178   Top1 78.408203   Top5 97.460938   BatchTime 0.393448   LR 0.002343   
2022-11-25 10:46:26,740 - INFO  - Training [5][   60/  196]   Loss 0.614611   Top1 78.906250   Top5 97.428385   BatchTime 0.383825   LR 0.002263   
2022-11-25 10:46:34,040 - INFO  - Training [5][   80/  196]   Loss 0.599136   Top1 79.345703   Top5 97.578125   BatchTime 0.379119   LR 0.002183   
2022-11-25 10:46:41,058 - INFO  - Training [5][  100/  196]   Loss 0.588920   Top1 79.652344   Top5 97.703125   BatchTime 0.373474   LR 0.002104   
2022-11-25 10:46:48,267 - INFO  - Training [5][  120/  196]   Loss 0.582263   Top1 79.905599   Top5 97.760417   BatchTime 0.371305   LR 0.002024   
2022-11-25 10:46:54,526 - INFO  - Training [5][  140/  196]   Loss 0.579856   Top1 79.969308   Top5 97.815290   BatchTime 0.362962   LR 0.001946   
2022-11-25 10:47:01,304 - INFO  - Training [5][  160/  196]   Loss 0.582266   Top1 79.873047   Top5 97.800293   BatchTime 0.359957   LR 0.001868   
2022-11-25 10:47:08,888 - INFO  - Training [5][  180/  196]   Loss 0.581190   Top1 79.943576   Top5 97.773438   BatchTime 0.362096   LR 0.001790   
2022-11-25 10:47:14,739 - INFO  - ==> Top1: 80.056    Top5: 97.782    Loss: 0.578

2022-11-25 10:47:14,976 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:47:16,453 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:47:19,055 - INFO  - Validation [5][   20/   40]   Loss 0.431183   Top1 85.839844   Top5 99.277344   BatchTime 0.129994   
2022-11-25 10:47:20,260 - INFO  - Validation [5][   40/   40]   Loss 0.418805   Top1 85.960000   Top5 99.410000   BatchTime 0.095139   
2022-11-25 10:47:20,482 - INFO  - ==> Top1: 85.960    Top5: 99.410    Loss: 0.419

2022-11-25 10:47:20,482 - INFO  - ==> Sparsity : 0.258

2022-11-25 10:47:20,483 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 85.960   Top5: 99.410]
2022-11-25 10:47:20,483 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 84.300   Top5: 99.250]
2022-11-25 10:47:20,483 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 84.290   Top5: 99.290]
2022-11-25 10:47:27,547 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 10:47:27,550 - INFO  - >>>>>> Epoch   6
2022-11-25 10:47:27,552 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:47:36,482 - INFO  - Training [6][   20/  196]   Loss 0.575530   Top1 79.941406   Top5 97.734375   BatchTime 0.446368   LR 0.001655   
2022-11-25 10:47:43,848 - INFO  - Training [6][   40/  196]   Loss 0.565765   Top1 80.283203   Top5 97.705078   BatchTime 0.407334   LR 0.001580   
2022-11-25 10:47:51,191 - INFO  - Training [6][   60/  196]   Loss 0.549803   Top1 81.041667   Top5 97.819010   BatchTime 0.393933   LR 0.001506   
2022-11-25 10:47:58,280 - INFO  - Training [6][   80/  196]   Loss 0.541856   Top1 81.313477   Top5 97.949219   BatchTime 0.384068   LR 0.001432   
2022-11-25 10:48:05,424 - INFO  - Training [6][  100/  196]   Loss 0.533934   Top1 81.507812   Top5 97.996094   BatchTime 0.378692   LR 0.001360   
2022-11-25 10:48:11,824 - INFO  - Training [6][  120/  196]   Loss 0.529074   Top1 81.653646   Top5 98.095703   BatchTime 0.368911   LR 0.001289   
2022-11-25 10:48:18,969 - INFO  - Training [6][  140/  196]   Loss 0.528702   Top1 81.690848   Top5 98.113839   BatchTime 0.367241   LR 0.001220   
2022-11-25 10:48:26,437 - INFO  - Training [6][  160/  196]   Loss 0.530189   Top1 81.628418   Top5 98.093262   BatchTime 0.368014   LR 0.001151   
2022-11-25 10:48:33,768 - INFO  - Training [6][  180/  196]   Loss 0.527854   Top1 81.684028   Top5 98.029514   BatchTime 0.367846   LR 0.001084   
2022-11-25 10:48:40,018 - INFO  - ==> Top1: 81.682    Top5: 98.048    Loss: 0.527

2022-11-25 10:48:40,253 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:48:41,660 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:48:44,381 - INFO  - Validation [6][   20/   40]   Loss 0.427126   Top1 85.761719   Top5 99.335938   BatchTime 0.135945   
2022-11-25 10:48:45,484 - INFO  - Validation [6][   40/   40]   Loss 0.409635   Top1 86.090000   Top5 99.520000   BatchTime 0.095558   
2022-11-25 10:48:45,869 - INFO  - ==> Top1: 86.090    Top5: 99.520    Loss: 0.410

2022-11-25 10:48:45,870 - INFO  - ==> Sparsity : 0.299

2022-11-25 10:48:45,870 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 86.090   Top5: 99.520]
2022-11-25 10:48:45,870 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 85.960   Top5: 99.410]
2022-11-25 10:48:45,870 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 84.300   Top5: 99.250]
2022-11-25 10:48:52,951 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 10:48:52,953 - INFO  - >>>>>> Epoch   7
2022-11-25 10:48:52,955 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:49:02,124 - INFO  - Training [7][   20/  196]   Loss 0.520515   Top1 81.992188   Top5 97.441406   BatchTime 0.458327   LR 0.000969   
2022-11-25 10:49:09,266 - INFO  - Training [7][   40/  196]   Loss 0.515368   Top1 82.236328   Top5 97.939453   BatchTime 0.407723   LR 0.000907   
2022-11-25 10:49:16,574 - INFO  - Training [7][   60/  196]   Loss 0.506499   Top1 82.714844   Top5 97.897135   BatchTime 0.393617   LR 0.000845   
2022-11-25 10:49:23,707 - INFO  - Training [7][   80/  196]   Loss 0.506454   Top1 82.558594   Top5 98.022461   BatchTime 0.384369   LR 0.000786   
2022-11-25 10:49:29,909 - INFO  - Training [7][  100/  196]   Loss 0.496697   Top1 82.835938   Top5 98.125000   BatchTime 0.369521   LR 0.000728   
2022-11-25 10:49:36,529 - INFO  - Training [7][  120/  196]   Loss 0.494644   Top1 82.910156   Top5 98.212891   BatchTime 0.363096   LR 0.000673   
2022-11-25 10:49:43,810 - INFO  - Training [7][  140/  196]   Loss 0.495345   Top1 82.918527   Top5 98.253348   BatchTime 0.363230   LR 0.000619   
2022-11-25 10:49:51,204 - INFO  - Training [7][  160/  196]   Loss 0.496424   Top1 82.856445   Top5 98.261719   BatchTime 0.364042   LR 0.000567   
2022-11-25 10:49:58,434 - INFO  - Training [7][  180/  196]   Loss 0.497916   Top1 82.825521   Top5 98.200955   BatchTime 0.363757   LR 0.000517   
2022-11-25 10:50:04,499 - INFO  - ==> Top1: 82.904    Top5: 98.204    Loss: 0.495

2022-11-25 10:50:04,763 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:50:06,300 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:50:08,694 - INFO  - Validation [7][   20/   40]   Loss 0.403423   Top1 86.640625   Top5 99.355469   BatchTime 0.119604   
2022-11-25 10:50:09,801 - INFO  - Validation [7][   40/   40]   Loss 0.391681   Top1 86.700000   Top5 99.540000   BatchTime 0.087482   
2022-11-25 10:50:10,053 - INFO  - ==> Top1: 86.700    Top5: 99.540    Loss: 0.392

2022-11-25 10:50:10,054 - INFO  - ==> Sparsity : 0.319

2022-11-25 10:50:10,054 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 86.700   Top5: 99.540]
2022-11-25 10:50:10,054 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 86.090   Top5: 99.520]
2022-11-25 10:50:10,054 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 85.960   Top5: 99.410]
2022-11-25 10:50:17,454 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 10:50:17,456 - INFO  - >>>>>> Epoch   8
2022-11-25 10:50:17,458 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:50:26,063 - INFO  - Training [8][   20/  196]   Loss 0.448987   Top1 84.199219   Top5 97.675781   BatchTime 0.430127   LR 0.000434   
2022-11-25 10:50:33,355 - INFO  - Training [8][   40/  196]   Loss 0.482763   Top1 82.910156   Top5 97.773438   BatchTime 0.397357   LR 0.000389   
2022-11-25 10:50:40,456 - INFO  - Training [8][   60/  196]   Loss 0.480544   Top1 83.118490   Top5 97.890625   BatchTime 0.383256   LR 0.000347   
2022-11-25 10:50:46,648 - INFO  - Training [8][   80/  196]   Loss 0.484665   Top1 83.125000   Top5 97.983398   BatchTime 0.364838   LR 0.000308   
2022-11-25 10:50:54,066 - INFO  - Training [8][  100/  196]   Loss 0.480768   Top1 83.242188   Top5 98.085938   BatchTime 0.366050   LR 0.000270   
2022-11-25 10:51:01,417 - INFO  - Training [8][  120/  196]   Loss 0.472707   Top1 83.548177   Top5 98.186849   BatchTime 0.366297   LR 0.000235   
2022-11-25 10:51:08,725 - INFO  - Training [8][  140/  196]   Loss 0.469353   Top1 83.643973   Top5 98.219866   BatchTime 0.366173   LR 0.000202   
2022-11-25 10:51:16,001 - INFO  - Training [8][  160/  196]   Loss 0.470575   Top1 83.615723   Top5 98.244629   BatchTime 0.365872   LR 0.000172   
2022-11-25 10:51:23,161 - INFO  - Training [8][  180/  196]   Loss 0.468093   Top1 83.665365   Top5 98.203125   BatchTime 0.364996   LR 0.000143   
2022-11-25 10:51:28,965 - INFO  - ==> Top1: 83.718    Top5: 98.220    Loss: 0.466

2022-11-25 10:51:29,215 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:51:30,585 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:51:33,071 - INFO  - Validation [8][   20/   40]   Loss 0.377211   Top1 87.421875   Top5 99.414062   BatchTime 0.124248   
2022-11-25 10:51:34,248 - INFO  - Validation [8][   40/   40]   Loss 0.367104   Top1 87.680000   Top5 99.530000   BatchTime 0.091538   
2022-11-25 10:51:34,499 - INFO  - ==> Top1: 87.680    Top5: 99.530    Loss: 0.367

2022-11-25 10:51:34,499 - INFO  - ==> Sparsity : 0.328

2022-11-25 10:51:34,499 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 10:51:34,499 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 86.700   Top5: 99.540]
2022-11-25 10:51:34,500 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 86.090   Top5: 99.520]
2022-11-25 10:51:41,267 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 10:51:41,269 - INFO  - >>>>>> Epoch   9
2022-11-25 10:51:41,271 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:51:49,752 - INFO  - Training [9][   20/  196]   Loss 0.465137   Top1 83.632812   Top5 97.753906   BatchTime 0.423940   LR 0.000100   
2022-11-25 10:51:56,759 - INFO  - Training [9][   40/  196]   Loss 0.477232   Top1 83.447266   Top5 97.998047   BatchTime 0.387144   LR 0.000079   
2022-11-25 10:52:02,952 - INFO  - Training [9][   60/  196]   Loss 0.465247   Top1 84.010417   Top5 98.151042   BatchTime 0.361305   LR 0.000060   
2022-11-25 10:52:10,319 - INFO  - Training [9][   80/  196]   Loss 0.467496   Top1 83.867188   Top5 98.251953   BatchTime 0.363065   LR 0.000044   
2022-11-25 10:52:17,859 - INFO  - Training [9][  100/  196]   Loss 0.460076   Top1 84.117188   Top5 98.300781   BatchTime 0.365851   LR 0.000030   
2022-11-25 10:52:24,916 - INFO  - Training [9][  120/  196]   Loss 0.453955   Top1 84.348958   Top5 98.346354   BatchTime 0.363681   LR 0.000019   
2022-11-25 10:52:32,186 - INFO  - Training [9][  140/  196]   Loss 0.454214   Top1 84.355469   Top5 98.384487   BatchTime 0.363654   LR 0.000010   
2022-11-25 10:52:39,420 - INFO  - Training [9][  160/  196]   Loss 0.459892   Top1 84.155273   Top5 98.378906   BatchTime 0.363410   LR 0.000004   
2022-11-25 10:52:46,587 - INFO  - Training [9][  180/  196]   Loss 0.457644   Top1 84.216580   Top5 98.339844   BatchTime 0.362851   LR 0.000001   
2022-11-25 10:52:52,612 - INFO  - ==> Top1: 84.258    Top5: 98.330    Loss: 0.457

2022-11-25 10:52:52,887 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:52:54,328 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:52:58,147 - INFO  - Validation [9][   20/   40]   Loss 0.358934   Top1 87.578125   Top5 99.550781   BatchTime 0.190842   
2022-11-25 10:52:59,211 - INFO  - Validation [9][   40/   40]   Loss 0.348532   Top1 88.080000   Top5 99.600000   BatchTime 0.122031   
2022-11-25 10:52:59,778 - INFO  - ==> Top1: 88.080    Top5: 99.600    Loss: 0.349

2022-11-25 10:52:59,778 - INFO  - ==> Sparsity : 0.329

2022-11-25 10:52:59,779 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 10:52:59,779 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 10:52:59,779 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.700   Top5: 99.540]
2022-11-25 10:53:05,761 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 10:53:05,763 - INFO  - >>>>>> Epoch  10
2022-11-25 10:53:05,765 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:53:13,883 - INFO  - Training [10][   20/  196]   Loss 0.538582   Top1 81.308594   Top5 97.500000   BatchTime 0.405743   LR 0.002500   
2022-11-25 10:53:20,042 - INFO  - Training [10][   40/  196]   Loss 0.550342   Top1 81.015625   Top5 97.578125   BatchTime 0.356839   LR 0.002499   
2022-11-25 10:53:27,316 - INFO  - Training [10][   60/  196]   Loss 0.551809   Top1 80.904948   Top5 97.819010   BatchTime 0.359121   LR 0.002499   
2022-11-25 10:53:35,009 - INFO  - Training [10][   80/  196]   Loss 0.555540   Top1 80.820312   Top5 97.944336   BatchTime 0.365498   LR 0.002497   
2022-11-25 10:53:42,377 - INFO  - Training [10][  100/  196]   Loss 0.552760   Top1 80.945312   Top5 97.988281   BatchTime 0.366079   LR 0.002496   
2022-11-25 10:53:49,659 - INFO  - Training [10][  120/  196]   Loss 0.542319   Top1 81.285807   Top5 98.095703   BatchTime 0.365748   LR 0.002494   
2022-11-25 10:53:56,988 - INFO  - Training [10][  140/  196]   Loss 0.542556   Top1 81.392299   Top5 98.158482   BatchTime 0.365851   LR 0.002492   
2022-11-25 10:54:04,127 - INFO  - Training [10][  160/  196]   Loss 0.546699   Top1 81.252441   Top5 98.098145   BatchTime 0.364737   LR 0.002490   
2022-11-25 10:54:11,478 - INFO  - Training [10][  180/  196]   Loss 0.547316   Top1 81.221788   Top5 98.023003   BatchTime 0.365048   LR 0.002487   
2022-11-25 10:54:17,566 - INFO  - ==> Top1: 81.326    Top5: 98.042    Loss: 0.546

2022-11-25 10:54:17,824 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:54:19,245 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:54:21,564 - INFO  - Validation [10][   20/   40]   Loss 0.597752   Top1 81.269531   Top5 98.281250   BatchTime 0.115859   
2022-11-25 10:54:22,574 - INFO  - Validation [10][   40/   40]   Loss 0.593479   Top1 81.170000   Top5 98.490000   BatchTime 0.083197   
2022-11-25 10:54:22,853 - INFO  - ==> Top1: 81.170    Top5: 98.490    Loss: 0.593

2022-11-25 10:54:22,853 - INFO  - ==> Sparsity : 0.291

2022-11-25 10:54:22,854 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 10:54:22,854 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 10:54:22,854 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.700   Top5: 99.540]
2022-11-25 10:54:23,000 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 10:54:23,002 - INFO  - >>>>>> Epoch  11
2022-11-25 10:54:23,004 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:54:31,288 - INFO  - Training [11][   20/  196]   Loss 0.557013   Top1 80.605469   Top5 97.578125   BatchTime 0.414028   LR 0.002481   
2022-11-25 10:54:37,886 - INFO  - Training [11][   40/  196]   Loss 0.562924   Top1 80.400391   Top5 97.675781   BatchTime 0.371959   LR 0.002478   
2022-11-25 10:54:44,998 - INFO  - Training [11][   60/  196]   Loss 0.557830   Top1 80.820312   Top5 97.786458   BatchTime 0.366508   LR 0.002474   
2022-11-25 10:54:52,167 - INFO  - Training [11][   80/  196]   Loss 0.553715   Top1 80.864258   Top5 97.861328   BatchTime 0.364496   LR 0.002470   
2022-11-25 10:54:59,652 - INFO  - Training [11][  100/  196]   Loss 0.545515   Top1 81.234375   Top5 97.929688   BatchTime 0.366441   LR 0.002465   
2022-11-25 10:55:06,938 - INFO  - Training [11][  120/  196]   Loss 0.540499   Top1 81.396484   Top5 98.059896   BatchTime 0.366086   LR 0.002460   
2022-11-25 10:55:14,200 - INFO  - Training [11][  140/  196]   Loss 0.542250   Top1 81.330915   Top5 98.080357   BatchTime 0.365659   LR 0.002455   
2022-11-25 10:55:21,426 - INFO  - Training [11][  160/  196]   Loss 0.547651   Top1 81.191406   Top5 98.034668   BatchTime 0.365114   LR 0.002450   
2022-11-25 10:55:28,481 - INFO  - Training [11][  180/  196]   Loss 0.548108   Top1 81.132812   Top5 97.970920   BatchTime 0.363739   LR 0.002444   
2022-11-25 10:55:34,707 - INFO  - ==> Top1: 81.154    Top5: 97.950    Loss: 0.547

2022-11-25 10:55:34,989 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:55:36,354 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:55:38,829 - INFO  - Validation [11][   20/   40]   Loss 0.803923   Top1 72.792969   Top5 98.183594   BatchTime 0.123624   
2022-11-25 10:55:39,925 - INFO  - Validation [11][   40/   40]   Loss 0.802323   Top1 72.820000   Top5 98.240000   BatchTime 0.089227   
2022-11-25 10:55:40,183 - INFO  - ==> Top1: 72.820    Top5: 98.240    Loss: 0.802

2022-11-25 10:55:40,183 - INFO  - ==> Sparsity : 0.303

2022-11-25 10:55:40,183 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 10:55:40,184 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 10:55:40,184 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.700   Top5: 99.540]
2022-11-25 10:55:40,304 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 10:55:40,305 - INFO  - >>>>>> Epoch  12
2022-11-25 10:55:40,307 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:55:48,676 - INFO  - Training [12][   20/  196]   Loss 0.565908   Top1 80.996094   Top5 97.558594   BatchTime 0.418313   LR 0.002433   
2022-11-25 10:55:54,815 - INFO  - Training [12][   40/  196]   Loss 0.564411   Top1 80.888672   Top5 97.607422   BatchTime 0.362650   LR 0.002426   
2022-11-25 10:56:01,854 - INFO  - Training [12][   60/  196]   Loss 0.553201   Top1 81.152344   Top5 97.662760   BatchTime 0.359067   LR 0.002419   
2022-11-25 10:56:08,983 - INFO  - Training [12][   80/  196]   Loss 0.555958   Top1 81.171875   Top5 97.778320   BatchTime 0.358417   LR 0.002412   
2022-11-25 10:56:16,386 - INFO  - Training [12][  100/  196]   Loss 0.548522   Top1 81.433594   Top5 97.781250   BatchTime 0.360763   LR 0.002404   
2022-11-25 10:56:23,876 - INFO  - Training [12][  120/  196]   Loss 0.542688   Top1 81.624349   Top5 97.903646   BatchTime 0.363054   LR 0.002396   
2022-11-25 10:56:31,227 - INFO  - Training [12][  140/  196]   Loss 0.538637   Top1 81.771763   Top5 97.946429   BatchTime 0.363695   LR 0.002388   
2022-11-25 10:56:38,491 - INFO  - Training [12][  160/  196]   Loss 0.543543   Top1 81.599121   Top5 97.919922   BatchTime 0.363629   LR 0.002380   
2022-11-25 10:56:45,703 - INFO  - Training [12][  180/  196]   Loss 0.540740   Top1 81.673177   Top5 97.903646   BatchTime 0.363293   LR 0.002371   
2022-11-25 10:56:51,836 - INFO  - ==> Top1: 81.732    Top5: 97.924    Loss: 0.538

2022-11-25 10:56:52,104 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:56:53,890 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:56:56,634 - INFO  - Validation [12][   20/   40]   Loss 0.412507   Top1 86.523438   Top5 99.335938   BatchTime 0.137081   
2022-11-25 10:56:57,751 - INFO  - Validation [12][   40/   40]   Loss 0.408460   Top1 86.540000   Top5 99.360000   BatchTime 0.096481   
2022-11-25 10:56:57,996 - INFO  - ==> Top1: 86.540    Top5: 99.360    Loss: 0.408

2022-11-25 10:56:57,996 - INFO  - ==> Sparsity : 0.303

2022-11-25 10:56:57,996 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 10:56:57,997 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 10:56:57,997 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.700   Top5: 99.540]
2022-11-25 10:56:58,132 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 10:56:58,134 - INFO  - >>>>>> Epoch  13
2022-11-25 10:56:58,136 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:57:06,877 - INFO  - Training [13][   20/  196]   Loss 0.544387   Top1 81.445312   Top5 97.421875   BatchTime 0.436887   LR 0.002355   
2022-11-25 10:57:13,329 - INFO  - Training [13][   40/  196]   Loss 0.550529   Top1 81.318359   Top5 97.597656   BatchTime 0.379754   LR 0.002345   
2022-11-25 10:57:20,744 - INFO  - Training [13][   60/  196]   Loss 0.538209   Top1 81.679688   Top5 97.786458   BatchTime 0.376753   LR 0.002336   
2022-11-25 10:57:27,891 - INFO  - Training [13][   80/  196]   Loss 0.535909   Top1 81.621094   Top5 97.934570   BatchTime 0.371899   LR 0.002325   
2022-11-25 10:57:34,974 - INFO  - Training [13][  100/  196]   Loss 0.538374   Top1 81.519531   Top5 97.906250   BatchTime 0.368349   LR 0.002315   
2022-11-25 10:57:42,293 - INFO  - Training [13][  120/  196]   Loss 0.543524   Top1 81.383464   Top5 97.952474   BatchTime 0.367945   LR 0.002304   
2022-11-25 10:57:49,565 - INFO  - Training [13][  140/  196]   Loss 0.543708   Top1 81.328125   Top5 97.996652   BatchTime 0.367327   LR 0.002293   
2022-11-25 10:57:57,100 - INFO  - Training [13][  160/  196]   Loss 0.547117   Top1 81.215820   Top5 97.988281   BatchTime 0.368507   LR 0.002282   
2022-11-25 10:58:04,226 - INFO  - Training [13][  180/  196]   Loss 0.546308   Top1 81.230469   Top5 97.940538   BatchTime 0.367146   LR 0.002271   
2022-11-25 10:58:10,250 - INFO  - ==> Top1: 81.340    Top5: 97.928    Loss: 0.544

2022-11-25 10:58:10,482 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:58:11,940 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:58:14,454 - INFO  - Validation [13][   20/   40]   Loss 0.387133   Top1 86.992188   Top5 99.296875   BatchTime 0.125594   
2022-11-25 10:58:15,542 - INFO  - Validation [13][   40/   40]   Loss 0.378183   Top1 86.980000   Top5 99.480000   BatchTime 0.090011   
2022-11-25 10:58:15,757 - INFO  - ==> Top1: 86.980    Top5: 99.480    Loss: 0.378

2022-11-25 10:58:15,757 - INFO  - ==> Sparsity : 0.308

2022-11-25 10:58:15,757 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 10:58:15,758 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 10:58:15,758 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 86.980   Top5: 99.480]
2022-11-25 10:58:15,880 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 10:58:15,881 - INFO  - >>>>>> Epoch  14
2022-11-25 10:58:15,883 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:58:24,303 - INFO  - Training [14][   20/  196]   Loss 0.534391   Top1 81.230469   Top5 97.773438   BatchTime 0.420871   LR 0.002250   
2022-11-25 10:58:30,639 - INFO  - Training [14][   40/  196]   Loss 0.546893   Top1 80.966797   Top5 97.812500   BatchTime 0.368842   LR 0.002238   
2022-11-25 10:58:37,603 - INFO  - Training [14][   60/  196]   Loss 0.541016   Top1 81.126302   Top5 97.851562   BatchTime 0.361949   LR 0.002225   
2022-11-25 10:58:44,534 - INFO  - Training [14][   80/  196]   Loss 0.532643   Top1 81.333008   Top5 97.993164   BatchTime 0.358106   LR 0.002213   
2022-11-25 10:58:51,988 - INFO  - Training [14][  100/  196]   Loss 0.524292   Top1 81.578125   Top5 98.062500   BatchTime 0.361015   LR 0.002200   
2022-11-25 10:58:59,596 - INFO  - Training [14][  120/  196]   Loss 0.520157   Top1 81.878255   Top5 98.125000   BatchTime 0.364249   LR 0.002186   
2022-11-25 10:59:06,880 - INFO  - Training [14][  140/  196]   Loss 0.516011   Top1 82.092634   Top5 98.208705   BatchTime 0.364242   LR 0.002173   
2022-11-25 10:59:14,271 - INFO  - Training [14][  160/  196]   Loss 0.515371   Top1 82.058105   Top5 98.217773   BatchTime 0.364907   LR 0.002159   
2022-11-25 10:59:21,458 - INFO  - Training [14][  180/  196]   Loss 0.513777   Top1 82.087674   Top5 98.148872   BatchTime 0.364288   LR 0.002145   
2022-11-25 10:59:27,499 - INFO  - ==> Top1: 82.190    Top5: 98.176    Loss: 0.511

2022-11-25 10:59:27,894 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:59:31,436 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:59:34,424 - INFO  - Validation [14][   20/   40]   Loss 0.431327   Top1 85.781250   Top5 99.335938   BatchTime 0.149309   
2022-11-25 10:59:35,442 - INFO  - Validation [14][   40/   40]   Loss 0.417994   Top1 86.200000   Top5 99.530000   BatchTime 0.100096   
2022-11-25 10:59:35,668 - INFO  - ==> Top1: 86.200    Top5: 99.530    Loss: 0.418

2022-11-25 10:59:35,668 - INFO  - ==> Sparsity : 0.322

2022-11-25 10:59:35,668 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 10:59:35,668 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 10:59:35,669 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 86.980   Top5: 99.480]
2022-11-25 10:59:35,816 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 10:59:35,817 - INFO  - >>>>>> Epoch  15
2022-11-25 10:59:35,819 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:59:43,779 - INFO  - Training [15][   20/  196]   Loss 0.536312   Top1 81.699219   Top5 97.382812   BatchTime 0.397853   LR 0.002120   
2022-11-25 10:59:50,193 - INFO  - Training [15][   40/  196]   Loss 0.517680   Top1 82.197266   Top5 97.666016   BatchTime 0.359290   LR 0.002106   
2022-11-25 10:59:57,194 - INFO  - Training [15][   60/  196]   Loss 0.511565   Top1 82.506510   Top5 97.825521   BatchTime 0.356207   LR 0.002091   
2022-11-25 11:00:03,955 - INFO  - Training [15][   80/  196]   Loss 0.508394   Top1 82.587891   Top5 97.978516   BatchTime 0.351662   LR 0.002076   
2022-11-25 11:00:10,861 - INFO  - Training [15][  100/  196]   Loss 0.501694   Top1 82.824219   Top5 98.054688   BatchTime 0.350391   LR 0.002061   
2022-11-25 11:00:18,664 - INFO  - Training [15][  120/  196]   Loss 0.491975   Top1 83.134766   Top5 98.193359   BatchTime 0.357015   LR 0.002045   
2022-11-25 11:00:26,151 - INFO  - Training [15][  140/  196]   Loss 0.493701   Top1 83.113839   Top5 98.239397   BatchTime 0.359490   LR 0.002030   
2022-11-25 11:00:33,612 - INFO  - Training [15][  160/  196]   Loss 0.495259   Top1 83.100586   Top5 98.208008   BatchTime 0.361188   LR 0.002014   
2022-11-25 11:00:40,990 - INFO  - Training [15][  180/  196]   Loss 0.496148   Top1 83.012153   Top5 98.155382   BatchTime 0.362045   LR 0.001998   
2022-11-25 11:00:47,029 - INFO  - ==> Top1: 83.058    Top5: 98.168    Loss: 0.494

2022-11-25 11:00:47,269 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:00:48,993 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:00:51,953 - INFO  - Validation [15][   20/   40]   Loss 0.400690   Top1 86.484375   Top5 99.296875   BatchTime 0.147950   
2022-11-25 11:00:53,501 - INFO  - Validation [15][   40/   40]   Loss 0.396730   Top1 86.530000   Top5 99.460000   BatchTime 0.112657   
2022-11-25 11:00:53,718 - INFO  - ==> Top1: 86.530    Top5: 99.460    Loss: 0.397

2022-11-25 11:00:53,718 - INFO  - ==> Sparsity : 0.356

2022-11-25 11:00:53,718 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 11:00:53,718 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 11:00:53,719 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 86.980   Top5: 99.480]
2022-11-25 11:00:54,032 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:00:54,033 - INFO  - >>>>>> Epoch  16
2022-11-25 11:00:54,035 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:01:02,038 - INFO  - Training [16][   20/  196]   Loss 0.487281   Top1 82.792969   Top5 97.929688   BatchTime 0.400006   LR 0.001969   
2022-11-25 11:01:08,389 - INFO  - Training [16][   40/  196]   Loss 0.489877   Top1 82.919922   Top5 98.017578   BatchTime 0.358788   LR 0.001953   
2022-11-25 11:01:15,459 - INFO  - Training [16][   60/  196]   Loss 0.481508   Top1 83.346354   Top5 98.105469   BatchTime 0.357030   LR 0.001936   
2022-11-25 11:01:22,656 - INFO  - Training [16][   80/  196]   Loss 0.480596   Top1 83.540039   Top5 98.203125   BatchTime 0.357727   LR 0.001919   
2022-11-25 11:01:29,866 - INFO  - Training [16][  100/  196]   Loss 0.477263   Top1 83.652344   Top5 98.187500   BatchTime 0.358285   LR 0.001902   
2022-11-25 11:01:36,973 - INFO  - Training [16][  120/  196]   Loss 0.476021   Top1 83.740234   Top5 98.255208   BatchTime 0.357797   LR 0.001885   
2022-11-25 11:01:44,268 - INFO  - Training [16][  140/  196]   Loss 0.473126   Top1 83.864397   Top5 98.311942   BatchTime 0.358787   LR 0.001867   
2022-11-25 11:01:51,468 - INFO  - Training [16][  160/  196]   Loss 0.477531   Top1 83.696289   Top5 98.254395   BatchTime 0.358934   LR 0.001850   
2022-11-25 11:01:58,855 - INFO  - Training [16][  180/  196]   Loss 0.477336   Top1 83.691406   Top5 98.209635   BatchTime 0.360094   LR 0.001832   
2022-11-25 11:02:04,710 - INFO  - ==> Top1: 83.760    Top5: 98.228    Loss: 0.474

2022-11-25 11:02:04,954 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:02:06,520 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:02:09,228 - INFO  - Validation [16][   20/   40]   Loss 0.433025   Top1 85.195312   Top5 99.218750   BatchTime 0.135339   
2022-11-25 11:02:11,258 - INFO  - Validation [16][   40/   40]   Loss 0.422035   Top1 85.460000   Top5 99.340000   BatchTime 0.118411   
2022-11-25 11:02:11,661 - INFO  - ==> Top1: 85.460    Top5: 99.340    Loss: 0.422

2022-11-25 11:02:11,661 - INFO  - ==> Sparsity : 0.366

2022-11-25 11:02:11,661 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 11:02:11,661 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 11:02:11,661 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 86.980   Top5: 99.480]
2022-11-25 11:02:11,819 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:02:11,820 - INFO  - >>>>>> Epoch  17
2022-11-25 11:02:11,822 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:02:20,378 - INFO  - Training [17][   20/  196]   Loss 0.481383   Top1 83.359375   Top5 97.832031   BatchTime 0.427642   LR 0.001800   
2022-11-25 11:02:26,371 - INFO  - Training [17][   40/  196]   Loss 0.478360   Top1 83.769531   Top5 98.017578   BatchTime 0.363652   LR 0.001782   
2022-11-25 11:02:33,571 - INFO  - Training [17][   60/  196]   Loss 0.476554   Top1 83.730469   Top5 98.059896   BatchTime 0.362426   LR 0.001764   
2022-11-25 11:02:40,835 - INFO  - Training [17][   80/  196]   Loss 0.469652   Top1 83.828125   Top5 98.232422   BatchTime 0.362619   LR 0.001746   
2022-11-25 11:02:48,116 - INFO  - Training [17][  100/  196]   Loss 0.466944   Top1 83.937500   Top5 98.261719   BatchTime 0.362904   LR 0.001727   
2022-11-25 11:02:55,835 - INFO  - Training [17][  120/  196]   Loss 0.461034   Top1 84.088542   Top5 98.369141   BatchTime 0.366748   LR 0.001708   
2022-11-25 11:03:03,273 - INFO  - Training [17][  140/  196]   Loss 0.462921   Top1 83.992746   Top5 98.381696   BatchTime 0.367484   LR 0.001690   
2022-11-25 11:03:10,650 - INFO  - Training [17][  160/  196]   Loss 0.465081   Top1 83.945312   Top5 98.342285   BatchTime 0.367651   LR 0.001671   
2022-11-25 11:03:17,844 - INFO  - Training [17][  180/  196]   Loss 0.463513   Top1 83.973524   Top5 98.279080   BatchTime 0.366768   LR 0.001652   
2022-11-25 11:03:23,719 - INFO  - ==> Top1: 84.104    Top5: 98.288    Loss: 0.460

2022-11-25 11:03:23,970 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:03:25,644 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:03:28,819 - INFO  - Validation [17][   20/   40]   Loss 0.368755   Top1 87.851562   Top5 99.433594   BatchTime 0.158627   
2022-11-25 11:03:30,636 - INFO  - Validation [17][   40/   40]   Loss 0.361171   Top1 88.160000   Top5 99.550000   BatchTime 0.124747   
2022-11-25 11:03:30,864 - INFO  - ==> Top1: 88.160    Top5: 99.550    Loss: 0.361

2022-11-25 11:03:30,864 - INFO  - ==> Sparsity : 0.427

2022-11-25 11:03:30,864 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 88.160   Top5: 99.550]
2022-11-25 11:03:30,865 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 11:03:30,865 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 11:03:36,467 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:03:36,469 - INFO  - >>>>>> Epoch  18
2022-11-25 11:03:36,472 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:03:44,368 - INFO  - Training [18][   20/  196]   Loss 0.468149   Top1 83.203125   Top5 97.968750   BatchTime 0.394667   LR 0.001618   
2022-11-25 11:03:51,533 - INFO  - Training [18][   40/  196]   Loss 0.447201   Top1 84.179688   Top5 98.242188   BatchTime 0.376462   LR 0.001599   
2022-11-25 11:03:58,704 - INFO  - Training [18][   60/  196]   Loss 0.451095   Top1 84.166667   Top5 98.281250   BatchTime 0.370488   LR 0.001579   
2022-11-25 11:04:06,081 - INFO  - Training [18][   80/  196]   Loss 0.449842   Top1 84.243164   Top5 98.339844   BatchTime 0.370072   LR 0.001560   
2022-11-25 11:04:12,995 - INFO  - Training [18][  100/  196]   Loss 0.445164   Top1 84.464844   Top5 98.351562   BatchTime 0.365200   LR 0.001540   
2022-11-25 11:04:20,114 - INFO  - Training [18][  120/  196]   Loss 0.440509   Top1 84.654948   Top5 98.421224   BatchTime 0.363659   LR 0.001521   
2022-11-25 11:04:27,495 - INFO  - Training [18][  140/  196]   Loss 0.437943   Top1 84.790737   Top5 98.496094   BatchTime 0.364430   LR 0.001501   
2022-11-25 11:04:34,206 - INFO  - Training [18][  160/  196]   Loss 0.442738   Top1 84.572754   Top5 98.486328   BatchTime 0.360820   LR 0.001482   
2022-11-25 11:04:40,984 - INFO  - Training [18][  180/  196]   Loss 0.444502   Top1 84.492188   Top5 98.409288   BatchTime 0.358384   LR 0.001462   
2022-11-25 11:04:46,937 - INFO  - ==> Top1: 84.458    Top5: 98.398    Loss: 0.444

2022-11-25 11:04:47,173 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:04:50,056 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:04:52,980 - INFO  - Validation [18][   20/   40]   Loss 0.387756   Top1 87.343750   Top5 99.394531   BatchTime 0.146078   
2022-11-25 11:04:54,025 - INFO  - Validation [18][   40/   40]   Loss 0.382255   Top1 87.190000   Top5 99.550000   BatchTime 0.099177   
2022-11-25 11:04:54,247 - INFO  - ==> Top1: 87.190    Top5: 99.550    Loss: 0.382

2022-11-25 11:04:54,248 - INFO  - ==> Sparsity : 0.371

2022-11-25 11:04:54,248 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 88.160   Top5: 99.550]
2022-11-25 11:04:54,248 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 11:04:54,249 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 11:04:54,387 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:04:54,389 - INFO  - >>>>>> Epoch  19
2022-11-25 11:04:54,392 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:05:02,267 - INFO  - Training [19][   20/  196]   Loss 0.453529   Top1 84.082031   Top5 97.929688   BatchTime 0.393550   LR 0.001427   
2022-11-25 11:05:09,483 - INFO  - Training [19][   40/  196]   Loss 0.449876   Top1 84.355469   Top5 98.046875   BatchTime 0.377175   LR 0.001407   
2022-11-25 11:05:16,380 - INFO  - Training [19][   60/  196]   Loss 0.441564   Top1 84.576823   Top5 98.216146   BatchTime 0.366403   LR 0.001387   
2022-11-25 11:05:23,478 - INFO  - Training [19][   80/  196]   Loss 0.439745   Top1 84.663086   Top5 98.334961   BatchTime 0.363525   LR 0.001367   
2022-11-25 11:05:30,697 - INFO  - Training [19][  100/  196]   Loss 0.434966   Top1 84.777344   Top5 98.394531   BatchTime 0.363010   LR 0.001347   
2022-11-25 11:05:37,959 - INFO  - Training [19][  120/  196]   Loss 0.430702   Top1 85.009766   Top5 98.486328   BatchTime 0.363024   LR 0.001327   
2022-11-25 11:05:45,362 - INFO  - Training [19][  140/  196]   Loss 0.428410   Top1 85.128348   Top5 98.526786   BatchTime 0.364036   LR 0.001307   
2022-11-25 11:05:52,654 - INFO  - Training [19][  160/  196]   Loss 0.431624   Top1 85.097656   Top5 98.491211   BatchTime 0.364109   LR 0.001287   
2022-11-25 11:05:59,919 - INFO  - Training [19][  180/  196]   Loss 0.432241   Top1 85.084635   Top5 98.465712   BatchTime 0.364011   LR 0.001266   
2022-11-25 11:06:06,084 - INFO  - ==> Top1: 85.106    Top5: 98.464    Loss: 0.432

2022-11-25 11:06:06,340 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:06:08,127 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:06:10,748 - INFO  - Validation [19][   20/   40]   Loss 0.729318   Top1 76.171875   Top5 98.105469   BatchTime 0.130958   
2022-11-25 11:06:11,761 - INFO  - Validation [19][   40/   40]   Loss 0.723332   Top1 76.170000   Top5 98.260000   BatchTime 0.090826   
2022-11-25 11:06:11,964 - INFO  - ==> Top1: 76.170    Top5: 98.260    Loss: 0.723

2022-11-25 11:06:11,964 - INFO  - ==> Sparsity : 0.370

2022-11-25 11:06:11,964 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 88.160   Top5: 99.550]
2022-11-25 11:06:11,964 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 11:06:11,965 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 87.680   Top5: 99.530]
2022-11-25 11:06:12,115 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:06:12,117 - INFO  - >>>>>> Epoch  20
2022-11-25 11:06:12,120 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:06:19,708 - INFO  - Training [20][   20/  196]   Loss 0.419560   Top1 84.960938   Top5 97.871094   BatchTime 0.379197   LR 0.001231   
2022-11-25 11:06:27,150 - INFO  - Training [20][   40/  196]   Loss 0.430816   Top1 84.794922   Top5 98.222656   BatchTime 0.375649   LR 0.001211   
2022-11-25 11:06:34,462 - INFO  - Training [20][   60/  196]   Loss 0.426828   Top1 85.006510   Top5 98.287760   BatchTime 0.372301   LR 0.001191   
2022-11-25 11:06:41,707 - INFO  - Training [20][   80/  196]   Loss 0.422515   Top1 85.224609   Top5 98.378906   BatchTime 0.369786   LR 0.001171   
2022-11-25 11:06:48,531 - INFO  - Training [20][  100/  196]   Loss 0.417485   Top1 85.386719   Top5 98.453125   BatchTime 0.364071   LR 0.001151   
2022-11-25 11:06:55,972 - INFO  - Training [20][  120/  196]   Loss 0.412537   Top1 85.566406   Top5 98.535156   BatchTime 0.365399   LR 0.001131   
2022-11-25 11:07:03,693 - INFO  - Training [20][  140/  196]   Loss 0.409740   Top1 85.728237   Top5 98.579799   BatchTime 0.368342   LR 0.001111   
2022-11-25 11:07:10,774 - INFO  - Training [20][  160/  196]   Loss 0.413436   Top1 85.615234   Top5 98.571777   BatchTime 0.366556   LR 0.001091   
2022-11-25 11:07:17,938 - INFO  - Training [20][  180/  196]   Loss 0.415315   Top1 85.603299   Top5 98.504774   BatchTime 0.365629   LR 0.001071   
2022-11-25 11:07:24,020 - INFO  - ==> Top1: 85.652    Top5: 98.514    Loss: 0.414

2022-11-25 11:07:24,382 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:07:26,903 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:07:29,490 - INFO  - Validation [20][   20/   40]   Loss 0.360866   Top1 88.144531   Top5 99.433594   BatchTime 0.129250   
2022-11-25 11:07:30,578 - INFO  - Validation [20][   40/   40]   Loss 0.343296   Top1 88.330000   Top5 99.600000   BatchTime 0.091836   
2022-11-25 11:07:30,796 - INFO  - ==> Top1: 88.330    Top5: 99.600    Loss: 0.343

2022-11-25 11:07:30,796 - INFO  - ==> Sparsity : 0.376

2022-11-25 11:07:30,796 - INFO  - Scoreboard best 1 ==> Epoch [20][Top1: 88.330   Top5: 99.600]
2022-11-25 11:07:30,796 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 88.160   Top5: 99.550]
2022-11-25 11:07:30,796 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 88.080   Top5: 99.600]
2022-11-25 11:07:37,477 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:07:37,481 - INFO  - >>>>>> Epoch  21
2022-11-25 11:07:37,484 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:07:46,519 - INFO  - Training [21][   20/  196]   Loss 0.439609   Top1 84.882812   Top5 97.558594   BatchTime 0.451613   LR 0.001036   
2022-11-25 11:07:53,814 - INFO  - Training [21][   40/  196]   Loss 0.433289   Top1 84.970703   Top5 97.949219   BatchTime 0.408190   LR 0.001016   
2022-11-25 11:08:00,989 - INFO  - Training [21][   60/  196]   Loss 0.424481   Top1 85.240885   Top5 98.170573   BatchTime 0.391711   LR 0.000996   
2022-11-25 11:08:08,359 - INFO  - Training [21][   80/  196]   Loss 0.423387   Top1 85.112305   Top5 98.305664   BatchTime 0.385904   LR 0.000976   
2022-11-25 11:08:16,120 - INFO  - Training [21][  100/  196]   Loss 0.419813   Top1 85.257812   Top5 98.359375   BatchTime 0.386330   LR 0.000957   
2022-11-25 11:08:23,520 - INFO  - Training [21][  120/  196]   Loss 0.412930   Top1 85.576172   Top5 98.447266   BatchTime 0.383605   LR 0.000937   
2022-11-25 11:08:30,742 - INFO  - Training [21][  140/  196]   Loss 0.410670   Top1 85.672433   Top5 98.498884   BatchTime 0.380393   LR 0.000918   
2022-11-25 11:08:38,035 - INFO  - Training [21][  160/  196]   Loss 0.412544   Top1 85.686035   Top5 98.479004   BatchTime 0.378425   LR 0.000899   
2022-11-25 11:08:45,477 - INFO  - Training [21][  180/  196]   Loss 0.413713   Top1 85.627170   Top5 98.396267   BatchTime 0.377721   LR 0.000879   
2022-11-25 11:08:51,308 - INFO  - ==> Top1: 85.682    Top5: 98.408    Loss: 0.411

2022-11-25 11:08:51,557 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:08:53,032 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:08:56,071 - INFO  - Validation [21][   20/   40]   Loss 0.355128   Top1 88.222656   Top5 99.511719   BatchTime 0.151849   
2022-11-25 11:08:58,501 - INFO  - Validation [21][   40/   40]   Loss 0.339659   Top1 88.440000   Top5 99.650000   BatchTime 0.136682   
2022-11-25 11:08:58,912 - INFO  - ==> Top1: 88.440    Top5: 99.650    Loss: 0.340

2022-11-25 11:08:58,912 - INFO  - ==> Sparsity : 0.370

2022-11-25 11:08:58,913 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 88.440   Top5: 99.650]
2022-11-25 11:08:58,913 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 88.330   Top5: 99.600]
2022-11-25 11:08:58,913 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 88.160   Top5: 99.550]
2022-11-25 11:09:04,487 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:09:04,491 - INFO  - >>>>>> Epoch  22
2022-11-25 11:09:04,493 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:09:13,273 - INFO  - Training [22][   20/  196]   Loss 0.386756   Top1 86.523438   Top5 98.046875   BatchTime 0.438824   LR 0.000846   
2022-11-25 11:09:20,762 - INFO  - Training [22][   40/  196]   Loss 0.403310   Top1 86.054688   Top5 98.281250   BatchTime 0.406636   LR 0.000827   
2022-11-25 11:09:27,927 - INFO  - Training [22][   60/  196]   Loss 0.404460   Top1 86.093750   Top5 98.359375   BatchTime 0.390520   LR 0.000808   
2022-11-25 11:09:35,203 - INFO  - Training [22][   80/  196]   Loss 0.399819   Top1 86.049805   Top5 98.437500   BatchTime 0.383836   LR 0.000789   
2022-11-25 11:09:42,579 - INFO  - Training [22][  100/  196]   Loss 0.391904   Top1 86.281250   Top5 98.441406   BatchTime 0.380829   LR 0.000770   
2022-11-25 11:09:49,858 - INFO  - Training [22][  120/  196]   Loss 0.389092   Top1 86.468099   Top5 98.502604   BatchTime 0.378012   LR 0.000752   
2022-11-25 11:09:57,125 - INFO  - Training [22][  140/  196]   Loss 0.389828   Top1 86.411830   Top5 98.554688   BatchTime 0.375915   LR 0.000734   
2022-11-25 11:10:04,594 - INFO  - Training [22][  160/  196]   Loss 0.392752   Top1 86.291504   Top5 98.535156   BatchTime 0.375610   LR 0.000715   
2022-11-25 11:10:11,823 - INFO  - Training [22][  180/  196]   Loss 0.393992   Top1 86.197917   Top5 98.487413   BatchTime 0.374036   LR 0.000697   
2022-11-25 11:10:16,726 - INFO  - ==> Top1: 86.254    Top5: 98.494    Loss: 0.392

2022-11-25 11:10:17,004 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:10:18,213 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:10:20,877 - INFO  - Validation [22][   20/   40]   Loss 0.341324   Top1 88.593750   Top5 99.472656   BatchTime 0.133099   
2022-11-25 11:10:21,987 - INFO  - Validation [22][   40/   40]   Loss 0.337688   Top1 88.530000   Top5 99.610000   BatchTime 0.094312   
2022-11-25 11:10:22,217 - INFO  - ==> Top1: 88.530    Top5: 99.610    Loss: 0.338

2022-11-25 11:10:22,218 - INFO  - ==> Sparsity : 0.372

2022-11-25 11:10:22,218 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 88.530   Top5: 99.610]
2022-11-25 11:10:22,218 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 88.440   Top5: 99.650]
2022-11-25 11:10:22,218 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 88.330   Top5: 99.600]
2022-11-25 11:10:27,758 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:10:27,764 - INFO  - >>>>>> Epoch  23
2022-11-25 11:10:27,766 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:10:36,296 - INFO  - Training [23][   20/  196]   Loss 0.388090   Top1 86.152344   Top5 98.085938   BatchTime 0.426394   LR 0.000666   
2022-11-25 11:10:43,504 - INFO  - Training [23][   40/  196]   Loss 0.396151   Top1 85.957031   Top5 98.251953   BatchTime 0.393405   LR 0.000648   
2022-11-25 11:10:50,933 - INFO  - Training [23][   60/  196]   Loss 0.395622   Top1 85.944010   Top5 98.326823   BatchTime 0.386079   LR 0.000630   
2022-11-25 11:10:58,377 - INFO  - Training [23][   80/  196]   Loss 0.396576   Top1 85.976562   Top5 98.461914   BatchTime 0.382601   LR 0.000613   
2022-11-25 11:11:05,713 - INFO  - Training [23][  100/  196]   Loss 0.388403   Top1 86.347656   Top5 98.484375   BatchTime 0.379439   LR 0.000596   
2022-11-25 11:11:13,246 - INFO  - Training [23][  120/  196]   Loss 0.381170   Top1 86.585286   Top5 98.554688   BatchTime 0.378980   LR 0.000579   
2022-11-25 11:11:20,953 - INFO  - Training [23][  140/  196]   Loss 0.379496   Top1 86.668527   Top5 98.590960   BatchTime 0.379885   LR 0.000562   
2022-11-25 11:11:28,347 - INFO  - Training [23][  160/  196]   Loss 0.381140   Top1 86.643066   Top5 98.588867   BatchTime 0.378612   LR 0.000545   
2022-11-25 11:11:34,767 - INFO  - Training [23][  180/  196]   Loss 0.380262   Top1 86.642795   Top5 98.522135   BatchTime 0.372211   LR 0.000529   
2022-11-25 11:11:40,458 - INFO  - ==> Top1: 86.648    Top5: 98.544    Loss: 0.380

2022-11-25 11:11:40,735 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:11:42,223 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:11:44,729 - INFO  - Validation [23][   20/   40]   Loss 0.354676   Top1 88.242188   Top5 99.355469   BatchTime 0.125198   
2022-11-25 11:11:45,859 - INFO  - Validation [23][   40/   40]   Loss 0.345709   Top1 88.310000   Top5 99.540000   BatchTime 0.090846   
2022-11-25 11:11:46,119 - INFO  - ==> Top1: 88.310    Top5: 99.540    Loss: 0.346

2022-11-25 11:11:46,120 - INFO  - ==> Sparsity : 0.381

2022-11-25 11:11:46,120 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 88.530   Top5: 99.610]
2022-11-25 11:11:46,120 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 88.440   Top5: 99.650]
2022-11-25 11:11:46,120 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 88.330   Top5: 99.600]
2022-11-25 11:11:46,243 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:11:46,245 - INFO  - >>>>>> Epoch  24
2022-11-25 11:11:46,247 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:11:54,869 - INFO  - Training [24][   20/  196]   Loss 0.405363   Top1 85.039062   Top5 98.183594   BatchTime 0.430996   LR 0.000500   
2022-11-25 11:12:01,892 - INFO  - Training [24][   40/  196]   Loss 0.392016   Top1 86.005859   Top5 98.369141   BatchTime 0.391070   LR 0.000484   
2022-11-25 11:12:09,180 - INFO  - Training [24][   60/  196]   Loss 0.386965   Top1 86.315104   Top5 98.483073   BatchTime 0.382178   LR 0.000468   
2022-11-25 11:12:14,713 - INFO  - Training [24][   80/  196]   Loss 0.381138   Top1 86.630859   Top5 98.603516   BatchTime 0.355791   LR 0.000453   
2022-11-25 11:12:20,008 - INFO  - Training [24][  100/  196]   Loss 0.373592   Top1 86.886719   Top5 98.601562   BatchTime 0.337578   LR 0.000437   
2022-11-25 11:12:25,177 - INFO  - Training [24][  120/  196]   Loss 0.369690   Top1 87.021484   Top5 98.681641   BatchTime 0.324394   LR 0.000422   
2022-11-25 11:12:30,077 - INFO  - Training [24][  140/  196]   Loss 0.368419   Top1 87.039621   Top5 98.727679   BatchTime 0.313055   LR 0.000407   
2022-11-25 11:12:35,276 - INFO  - Training [24][  160/  196]   Loss 0.371188   Top1 87.006836   Top5 98.720703   BatchTime 0.306416   LR 0.000392   
2022-11-25 11:12:40,725 - INFO  - Training [24][  180/  196]   Loss 0.371741   Top1 86.957465   Top5 98.663194   BatchTime 0.302640   LR 0.000378   
2022-11-25 11:12:45,154 - INFO  - ==> Top1: 87.028    Top5: 98.646    Loss: 0.370

2022-11-25 11:12:45,355 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:12:46,521 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:12:48,922 - INFO  - Validation [24][   20/   40]   Loss 0.320141   Top1 89.765625   Top5 99.550781   BatchTime 0.119954   
2022-11-25 11:12:50,013 - INFO  - Validation [24][   40/   40]   Loss 0.308053   Top1 89.680000   Top5 99.670000   BatchTime 0.087255   
2022-11-25 11:12:50,260 - INFO  - ==> Top1: 89.680    Top5: 99.670    Loss: 0.308

2022-11-25 11:12:50,260 - INFO  - ==> Sparsity : 0.375

2022-11-25 11:12:50,261 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:12:50,261 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 88.530   Top5: 99.610]
2022-11-25 11:12:50,261 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 88.440   Top5: 99.650]
2022-11-25 11:12:55,015 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:12:55,017 - INFO  - >>>>>> Epoch  25
2022-11-25 11:12:55,020 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:13:01,666 - INFO  - Training [25][   20/  196]   Loss 0.377966   Top1 86.660156   Top5 98.339844   BatchTime 0.332189   LR 0.000353   
2022-11-25 11:13:06,744 - INFO  - Training [25][   40/  196]   Loss 0.379185   Top1 86.826172   Top5 98.447266   BatchTime 0.293038   LR 0.000339   
2022-11-25 11:13:12,572 - INFO  - Training [25][   60/  196]   Loss 0.378469   Top1 86.842448   Top5 98.515625   BatchTime 0.292491   LR 0.000325   
2022-11-25 11:13:18,082 - INFO  - Training [25][   80/  196]   Loss 0.376691   Top1 86.982422   Top5 98.535156   BatchTime 0.288250   LR 0.000312   
2022-11-25 11:13:23,491 - INFO  - Training [25][  100/  196]   Loss 0.372639   Top1 87.046875   Top5 98.582031   BatchTime 0.284688   LR 0.000299   
2022-11-25 11:13:28,692 - INFO  - Training [25][  120/  196]   Loss 0.368548   Top1 87.174479   Top5 98.645833   BatchTime 0.280581   LR 0.000286   
2022-11-25 11:13:34,020 - INFO  - Training [25][  140/  196]   Loss 0.366172   Top1 87.282366   Top5 98.710938   BatchTime 0.278552   LR 0.000273   
2022-11-25 11:13:39,603 - INFO  - Training [25][  160/  196]   Loss 0.371358   Top1 87.163086   Top5 98.674316   BatchTime 0.278629   LR 0.000261   
2022-11-25 11:13:45,222 - INFO  - Training [25][  180/  196]   Loss 0.370649   Top1 87.198351   Top5 98.606771   BatchTime 0.278886   LR 0.000248   
2022-11-25 11:13:49,851 - INFO  - ==> Top1: 87.286    Top5: 98.618    Loss: 0.369

2022-11-25 11:13:50,067 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:13:51,770 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:13:54,227 - INFO  - Validation [25][   20/   40]   Loss 0.342894   Top1 88.339844   Top5 99.492188   BatchTime 0.122769   
2022-11-25 11:13:55,237 - INFO  - Validation [25][   40/   40]   Loss 0.331209   Top1 88.470000   Top5 99.640000   BatchTime 0.086645   
2022-11-25 11:13:55,455 - INFO  - ==> Top1: 88.470    Top5: 99.640    Loss: 0.331

2022-11-25 11:13:55,455 - INFO  - ==> Sparsity : 0.376

2022-11-25 11:13:55,455 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:13:55,455 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 88.530   Top5: 99.610]
2022-11-25 11:13:55,455 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 88.470   Top5: 99.640]
2022-11-25 11:13:55,574 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:13:55,575 - INFO  - >>>>>> Epoch  26
2022-11-25 11:13:55,577 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:14:01,945 - INFO  - Training [26][   20/  196]   Loss 0.386907   Top1 86.210938   Top5 97.929688   BatchTime 0.318265   LR 0.000228   
2022-11-25 11:14:07,339 - INFO  - Training [26][   40/  196]   Loss 0.387868   Top1 86.337891   Top5 98.144531   BatchTime 0.293993   LR 0.000216   
2022-11-25 11:14:12,682 - INFO  - Training [26][   60/  196]   Loss 0.373112   Top1 87.083333   Top5 98.255208   BatchTime 0.285036   LR 0.000205   
2022-11-25 11:14:17,788 - INFO  - Training [26][   80/  196]   Loss 0.371600   Top1 87.138672   Top5 98.422852   BatchTime 0.277598   LR 0.000194   
2022-11-25 11:14:23,398 - INFO  - Training [26][  100/  196]   Loss 0.366254   Top1 87.328125   Top5 98.472656   BatchTime 0.278180   LR 0.000183   
2022-11-25 11:14:28,441 - INFO  - Training [26][  120/  196]   Loss 0.362351   Top1 87.460938   Top5 98.561198   BatchTime 0.273841   LR 0.000173   
2022-11-25 11:14:33,437 - INFO  - Training [26][  140/  196]   Loss 0.361438   Top1 87.497210   Top5 98.607701   BatchTime 0.270407   LR 0.000163   
2022-11-25 11:14:38,437 - INFO  - Training [26][  160/  196]   Loss 0.361595   Top1 87.500000   Top5 98.608398   BatchTime 0.267855   LR 0.000153   
2022-11-25 11:14:43,917 - INFO  - Training [26][  180/  196]   Loss 0.359704   Top1 87.532552   Top5 98.556858   BatchTime 0.268539   LR 0.000144   
2022-11-25 11:14:48,015 - INFO  - ==> Top1: 87.500    Top5: 98.584    Loss: 0.360

2022-11-25 11:14:48,377 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:14:49,774 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:14:52,284 - INFO  - Validation [26][   20/   40]   Loss 0.377604   Top1 88.417969   Top5 99.433594   BatchTime 0.125322   
2022-11-25 11:14:53,376 - INFO  - Validation [26][   40/   40]   Loss 0.363915   Top1 88.240000   Top5 99.570000   BatchTime 0.089973   
2022-11-25 11:14:53,869 - INFO  - ==> Top1: 88.240    Top5: 99.570    Loss: 0.364

2022-11-25 11:14:53,870 - INFO  - ==> Sparsity : 0.378

2022-11-25 11:14:53,870 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:14:53,870 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 88.530   Top5: 99.610]
2022-11-25 11:14:53,870 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 88.470   Top5: 99.640]
2022-11-25 11:14:53,999 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:14:54,001 - INFO  - >>>>>> Epoch  27
2022-11-25 11:14:54,003 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:15:00,353 - INFO  - Training [27][   20/  196]   Loss 0.375832   Top1 87.187500   Top5 98.203125   BatchTime 0.317379   LR 0.000128   
2022-11-25 11:15:05,088 - INFO  - Training [27][   40/  196]   Loss 0.363379   Top1 87.548828   Top5 98.427734   BatchTime 0.277078   LR 0.000119   
2022-11-25 11:15:10,086 - INFO  - Training [27][   60/  196]   Loss 0.365244   Top1 87.428385   Top5 98.470052   BatchTime 0.268002   LR 0.000111   
2022-11-25 11:15:14,769 - INFO  - Training [27][   80/  196]   Loss 0.364601   Top1 87.465820   Top5 98.535156   BatchTime 0.259543   LR 0.000102   
2022-11-25 11:15:19,610 - INFO  - Training [27][  100/  196]   Loss 0.357178   Top1 87.640625   Top5 98.562500   BatchTime 0.256040   LR 0.000095   
2022-11-25 11:15:24,576 - INFO  - Training [27][  120/  196]   Loss 0.349300   Top1 87.958984   Top5 98.681641   BatchTime 0.254755   LR 0.000087   
2022-11-25 11:15:29,359 - INFO  - Training [27][  140/  196]   Loss 0.347277   Top1 88.027344   Top5 98.744420   BatchTime 0.252525   LR 0.000080   
2022-11-25 11:15:34,338 - INFO  - Training [27][  160/  196]   Loss 0.350465   Top1 87.905273   Top5 98.713379   BatchTime 0.252075   LR 0.000073   
2022-11-25 11:15:39,278 - INFO  - Training [27][  180/  196]   Loss 0.351468   Top1 87.797309   Top5 98.658854   BatchTime 0.251513   LR 0.000066   
2022-11-25 11:15:42,926 - INFO  - ==> Top1: 87.814    Top5: 98.668    Loss: 0.351

2022-11-25 11:15:43,110 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:15:44,355 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:15:46,988 - INFO  - Validation [27][   20/   40]   Loss 0.373578   Top1 87.890625   Top5 99.511719   BatchTime 0.131551   
2022-11-25 11:15:48,098 - INFO  - Validation [27][   40/   40]   Loss 0.363984   Top1 87.830000   Top5 99.570000   BatchTime 0.093539   
2022-11-25 11:15:48,323 - INFO  - ==> Top1: 87.830    Top5: 99.570    Loss: 0.364

2022-11-25 11:15:48,323 - INFO  - ==> Sparsity : 0.381

2022-11-25 11:15:48,324 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:15:48,324 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 88.530   Top5: 99.610]
2022-11-25 11:15:48,324 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 88.470   Top5: 99.640]
2022-11-25 11:15:48,473 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:15:48,475 - INFO  - >>>>>> Epoch  28
2022-11-25 11:15:48,477 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:15:55,468 - INFO  - Training [28][   20/  196]   Loss 0.381211   Top1 86.933594   Top5 97.968750   BatchTime 0.349424   LR 0.000055   
2022-11-25 11:16:00,580 - INFO  - Training [28][   40/  196]   Loss 0.377512   Top1 87.167969   Top5 98.310547   BatchTime 0.302516   LR 0.000050   
2022-11-25 11:16:05,826 - INFO  - Training [28][   60/  196]   Loss 0.367982   Top1 87.337240   Top5 98.411458   BatchTime 0.289118   LR 0.000044   
2022-11-25 11:16:11,037 - INFO  - Training [28][   80/  196]   Loss 0.367087   Top1 87.333984   Top5 98.481445   BatchTime 0.281976   LR 0.000039   
2022-11-25 11:16:16,172 - INFO  - Training [28][  100/  196]   Loss 0.357831   Top1 87.636719   Top5 98.531250   BatchTime 0.276929   LR 0.000034   
2022-11-25 11:16:21,572 - INFO  - Training [28][  120/  196]   Loss 0.352515   Top1 87.809245   Top5 98.649089   BatchTime 0.275767   LR 0.000030   
2022-11-25 11:16:26,945 - INFO  - Training [28][  140/  196]   Loss 0.350665   Top1 87.929688   Top5 98.716518   BatchTime 0.274752   LR 0.000026   
2022-11-25 11:16:31,917 - INFO  - Training [28][  160/  196]   Loss 0.353362   Top1 87.807617   Top5 98.713379   BatchTime 0.271484   LR 0.000022   
2022-11-25 11:16:36,945 - INFO  - Training [28][  180/  196]   Loss 0.352864   Top1 87.799479   Top5 98.697917   BatchTime 0.269249   LR 0.000018   
2022-11-25 11:16:41,075 - INFO  - ==> Top1: 87.930    Top5: 98.712    Loss: 0.350

2022-11-25 11:16:41,258 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:16:42,188 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:16:44,613 - INFO  - Validation [28][   20/   40]   Loss 0.329045   Top1 89.140625   Top5 99.550781   BatchTime 0.121142   
2022-11-25 11:16:45,576 - INFO  - Validation [28][   40/   40]   Loss 0.317728   Top1 89.200000   Top5 99.620000   BatchTime 0.084655   
2022-11-25 11:16:45,780 - INFO  - ==> Top1: 89.200    Top5: 99.620    Loss: 0.318

2022-11-25 11:16:45,780 - INFO  - ==> Sparsity : 0.382

2022-11-25 11:16:45,780 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:16:45,780 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:16:45,781 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 88.530   Top5: 99.610]
2022-11-25 11:16:45,895 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:16:45,896 - INFO  - >>>>>> Epoch  29
2022-11-25 11:16:45,898 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:16:52,936 - INFO  - Training [29][   20/  196]   Loss 0.367271   Top1 86.933594   Top5 98.476562   BatchTime 0.351765   LR 0.000013   
2022-11-25 11:16:58,470 - INFO  - Training [29][   40/  196]   Loss 0.366435   Top1 86.972656   Top5 98.623047   BatchTime 0.314235   LR 0.000010   
2022-11-25 11:17:03,703 - INFO  - Training [29][   60/  196]   Loss 0.367362   Top1 87.005208   Top5 98.593750   BatchTime 0.296716   LR 0.000008   
2022-11-25 11:17:08,965 - INFO  - Training [29][   80/  196]   Loss 0.361715   Top1 87.333984   Top5 98.696289   BatchTime 0.288308   LR 0.000005   
2022-11-25 11:17:13,944 - INFO  - Training [29][  100/  196]   Loss 0.356399   Top1 87.570312   Top5 98.671875   BatchTime 0.280436   LR 0.000004   
2022-11-25 11:17:18,912 - INFO  - Training [29][  120/  196]   Loss 0.350776   Top1 87.783203   Top5 98.727214   BatchTime 0.275098   LR 0.000002   
2022-11-25 11:17:23,925 - INFO  - Training [29][  140/  196]   Loss 0.349660   Top1 87.865513   Top5 98.777902   BatchTime 0.271600   LR 0.000001   
2022-11-25 11:17:29,196 - INFO  - Training [29][  160/  196]   Loss 0.351604   Top1 87.854004   Top5 98.769531   BatchTime 0.270595   LR 0.000001   
2022-11-25 11:17:34,784 - INFO  - Training [29][  180/  196]   Loss 0.350809   Top1 87.877604   Top5 98.719618   BatchTime 0.271572   LR 0.000000   
2022-11-25 11:17:39,350 - INFO  - ==> Top1: 87.966    Top5: 98.730    Loss: 0.348

2022-11-25 11:17:39,563 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:17:40,968 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:17:43,431 - INFO  - Validation [29][   20/   40]   Loss 0.367573   Top1 88.261719   Top5 99.414062   BatchTime 0.123070   
2022-11-25 11:17:44,509 - INFO  - Validation [29][   40/   40]   Loss 0.352828   Top1 88.450000   Top5 99.520000   BatchTime 0.088480   
2022-11-25 11:17:44,764 - INFO  - ==> Top1: 88.450    Top5: 99.520    Loss: 0.353

2022-11-25 11:17:44,764 - INFO  - ==> Sparsity : 0.382

2022-11-25 11:17:44,764 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:17:44,765 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:17:44,765 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 88.530   Top5: 99.610]
2022-11-25 11:17:44,879 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:17:44,881 - INFO  - >>>>>> Epoch  30
2022-11-25 11:17:44,882 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:17:51,227 - INFO  - Training [30][   20/  196]   Loss 0.369553   Top1 87.050781   Top5 98.125000   BatchTime 0.317113   LR 0.001250   
2022-11-25 11:17:56,343 - INFO  - Training [30][   40/  196]   Loss 0.392826   Top1 86.250000   Top5 98.339844   BatchTime 0.286467   LR 0.001250   
2022-11-25 11:18:02,009 - INFO  - Training [30][   60/  196]   Loss 0.397574   Top1 86.028646   Top5 98.359375   BatchTime 0.285404   LR 0.001250   
2022-11-25 11:18:07,345 - INFO  - Training [30][   80/  196]   Loss 0.401936   Top1 85.947266   Top5 98.432617   BatchTime 0.280752   LR 0.001250   
2022-11-25 11:18:12,358 - INFO  - Training [30][  100/  196]   Loss 0.397512   Top1 86.136719   Top5 98.472656   BatchTime 0.274725   LR 0.001250   
2022-11-25 11:18:17,295 - INFO  - Training [30][  120/  196]   Loss 0.391793   Top1 86.396484   Top5 98.554688   BatchTime 0.270087   LR 0.001249   
2022-11-25 11:18:22,437 - INFO  - Training [30][  140/  196]   Loss 0.390486   Top1 86.523438   Top5 98.610491   BatchTime 0.268231   LR 0.001249   
2022-11-25 11:18:27,849 - INFO  - Training [30][  160/  196]   Loss 0.393091   Top1 86.423340   Top5 98.603516   BatchTime 0.268523   LR 0.001249   
2022-11-25 11:18:33,220 - INFO  - Training [30][  180/  196]   Loss 0.395780   Top1 86.308594   Top5 98.528646   BatchTime 0.268526   LR 0.001248   
2022-11-25 11:18:37,532 - INFO  - ==> Top1: 86.376    Top5: 98.540    Loss: 0.396

2022-11-25 11:18:37,815 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:18:39,074 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:18:41,601 - INFO  - Validation [30][   20/   40]   Loss 0.429918   Top1 85.859375   Top5 99.160156   BatchTime 0.126243   
2022-11-25 11:18:42,806 - INFO  - Validation [30][   40/   40]   Loss 0.422768   Top1 85.810000   Top5 99.370000   BatchTime 0.093259   
2022-11-25 11:18:43,067 - INFO  - ==> Top1: 85.810    Top5: 99.370    Loss: 0.423

2022-11-25 11:18:43,068 - INFO  - ==> Sparsity : 0.373

2022-11-25 11:18:43,068 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:18:43,068 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:18:43,068 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 88.530   Top5: 99.610]
2022-11-25 11:18:43,212 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:18:43,214 - INFO  - >>>>>> Epoch  31
2022-11-25 11:18:43,216 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:18:50,231 - INFO  - Training [31][   20/  196]   Loss 0.401685   Top1 85.839844   Top5 98.300781   BatchTime 0.350638   LR 0.001248   
2022-11-25 11:18:55,982 - INFO  - Training [31][   40/  196]   Loss 0.409970   Top1 85.605469   Top5 98.320312   BatchTime 0.319085   LR 0.001247   
2022-11-25 11:19:01,310 - INFO  - Training [31][   60/  196]   Loss 0.408807   Top1 85.709635   Top5 98.378906   BatchTime 0.301528   LR 0.001247   
2022-11-25 11:19:06,649 - INFO  - Training [31][   80/  196]   Loss 0.407884   Top1 85.820312   Top5 98.466797   BatchTime 0.292886   LR 0.001246   
2022-11-25 11:19:12,011 - INFO  - Training [31][  100/  196]   Loss 0.407557   Top1 85.781250   Top5 98.511719   BatchTime 0.287927   LR 0.001246   
2022-11-25 11:19:17,595 - INFO  - Training [31][  120/  196]   Loss 0.402004   Top1 85.963542   Top5 98.541667   BatchTime 0.286471   LR 0.001245   
2022-11-25 11:19:23,579 - INFO  - Training [31][  140/  196]   Loss 0.399657   Top1 86.032366   Top5 98.613281   BatchTime 0.288287   LR 0.001244   
2022-11-25 11:19:29,386 - INFO  - Training [31][  160/  196]   Loss 0.403894   Top1 85.981445   Top5 98.593750   BatchTime 0.288545   LR 0.001244   
2022-11-25 11:19:35,219 - INFO  - Training [31][  180/  196]   Loss 0.404658   Top1 85.996094   Top5 98.561198   BatchTime 0.288890   LR 0.001243   
2022-11-25 11:19:39,915 - INFO  - ==> Top1: 86.038    Top5: 98.556    Loss: 0.404

2022-11-25 11:19:40,183 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:19:41,981 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:19:44,553 - INFO  - Validation [31][   20/   40]   Loss 0.368368   Top1 88.359375   Top5 99.589844   BatchTime 0.128537   
2022-11-25 11:19:45,576 - INFO  - Validation [31][   40/   40]   Loss 0.356529   Top1 88.280000   Top5 99.630000   BatchTime 0.089829   
2022-11-25 11:19:45,829 - INFO  - ==> Top1: 88.280    Top5: 99.630    Loss: 0.357

2022-11-25 11:19:45,829 - INFO  - ==> Sparsity : 0.338

2022-11-25 11:19:45,829 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:19:45,829 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:19:45,830 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 88.530   Top5: 99.610]
2022-11-25 11:19:45,953 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:19:45,955 - INFO  - >>>>>> Epoch  32
2022-11-25 11:19:45,957 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:19:54,429 - INFO  - Training [32][   20/  196]   Loss 0.413571   Top1 85.371094   Top5 97.949219   BatchTime 0.423497   LR 0.001242   
2022-11-25 11:20:01,646 - INFO  - Training [32][   40/  196]   Loss 0.422680   Top1 85.273438   Top5 98.105469   BatchTime 0.392177   LR 0.001241   
2022-11-25 11:20:08,806 - INFO  - Training [32][   60/  196]   Loss 0.414855   Top1 85.514323   Top5 98.170573   BatchTime 0.380780   LR 0.001240   
2022-11-25 11:20:15,932 - INFO  - Training [32][   80/  196]   Loss 0.413071   Top1 85.595703   Top5 98.310547   BatchTime 0.374663   LR 0.001239   
2022-11-25 11:20:23,169 - INFO  - Training [32][  100/  196]   Loss 0.403117   Top1 86.011719   Top5 98.355469   BatchTime 0.372096   LR 0.001238   
2022-11-25 11:20:30,465 - INFO  - Training [32][  120/  196]   Loss 0.397157   Top1 86.302083   Top5 98.434245   BatchTime 0.370875   LR 0.001237   
2022-11-25 11:20:37,528 - INFO  - Training [32][  140/  196]   Loss 0.398047   Top1 86.266741   Top5 98.515625   BatchTime 0.368347   LR 0.001236   
2022-11-25 11:20:44,995 - INFO  - Training [32][  160/  196]   Loss 0.398288   Top1 86.225586   Top5 98.520508   BatchTime 0.368971   LR 0.001235   
2022-11-25 11:20:51,759 - INFO  - Training [32][  180/  196]   Loss 0.397173   Top1 86.276042   Top5 98.465712   BatchTime 0.365552   LR 0.001234   
2022-11-25 11:20:57,708 - INFO  - ==> Top1: 86.268    Top5: 98.460    Loss: 0.397

2022-11-25 11:20:57,939 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:21:00,331 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:21:03,052 - INFO  - Validation [32][   20/   40]   Loss 0.364934   Top1 88.691406   Top5 99.511719   BatchTime 0.135919   
2022-11-25 11:21:04,226 - INFO  - Validation [32][   40/   40]   Loss 0.346096   Top1 88.660000   Top5 99.600000   BatchTime 0.097341   
2022-11-25 11:21:04,483 - INFO  - ==> Top1: 88.660    Top5: 99.600    Loss: 0.346

2022-11-25 11:21:04,483 - INFO  - ==> Sparsity : 0.372

2022-11-25 11:21:04,484 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:21:04,484 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:21:04,484 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 88.660   Top5: 99.600]
2022-11-25 11:21:04,814 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:21:04,815 - INFO  - >>>>>> Epoch  33
2022-11-25 11:21:04,817 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:21:12,721 - INFO  - Training [33][   20/  196]   Loss 0.402046   Top1 85.898438   Top5 98.046875   BatchTime 0.395102   LR 0.001232   
2022-11-25 11:21:19,864 - INFO  - Training [33][   40/  196]   Loss 0.407398   Top1 85.830078   Top5 98.076172   BatchTime 0.376114   LR 0.001230   
2022-11-25 11:21:27,216 - INFO  - Training [33][   60/  196]   Loss 0.403045   Top1 86.100260   Top5 98.177083   BatchTime 0.373272   LR 0.001229   
2022-11-25 11:21:34,109 - INFO  - Training [33][   80/  196]   Loss 0.402587   Top1 86.088867   Top5 98.300781   BatchTime 0.366119   LR 0.001228   
2022-11-25 11:21:41,121 - INFO  - Training [33][  100/  196]   Loss 0.399713   Top1 86.210938   Top5 98.332031   BatchTime 0.363015   LR 0.001226   
2022-11-25 11:21:48,544 - INFO  - Training [33][  120/  196]   Loss 0.393446   Top1 86.529948   Top5 98.460286   BatchTime 0.364374   LR 0.001225   
2022-11-25 11:21:55,787 - INFO  - Training [33][  140/  196]   Loss 0.391049   Top1 86.612723   Top5 98.532366   BatchTime 0.364055   LR 0.001224   
2022-11-25 11:22:03,204 - INFO  - Training [33][  160/  196]   Loss 0.393424   Top1 86.530762   Top5 98.530273   BatchTime 0.364899   LR 0.001222   
2022-11-25 11:22:10,696 - INFO  - Training [33][  180/  196]   Loss 0.394453   Top1 86.451823   Top5 98.480903   BatchTime 0.365978   LR 0.001221   
2022-11-25 11:22:16,569 - INFO  - ==> Top1: 86.462    Top5: 98.496    Loss: 0.395

2022-11-25 11:22:16,782 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:22:18,143 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:22:20,926 - INFO  - Validation [33][   20/   40]   Loss 0.348119   Top1 88.750000   Top5 99.609375   BatchTime 0.139078   
2022-11-25 11:22:22,885 - INFO  - Validation [33][   40/   40]   Loss 0.338657   Top1 88.590000   Top5 99.640000   BatchTime 0.118526   
2022-11-25 11:22:23,289 - INFO  - ==> Top1: 88.590    Top5: 99.640    Loss: 0.339

2022-11-25 11:22:23,289 - INFO  - ==> Sparsity : 0.368

2022-11-25 11:22:23,289 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:22:23,290 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:22:23,290 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 88.660   Top5: 99.600]
2022-11-25 11:22:23,498 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:22:23,501 - INFO  - >>>>>> Epoch  34
2022-11-25 11:22:23,504 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:22:31,273 - INFO  - Training [34][   20/  196]   Loss 0.399549   Top1 85.390625   Top5 98.183594   BatchTime 0.388171   LR 0.001218   
2022-11-25 11:22:37,470 - INFO  - Training [34][   40/  196]   Loss 0.403616   Top1 85.556641   Top5 98.417969   BatchTime 0.349022   LR 0.001216   
2022-11-25 11:22:44,738 - INFO  - Training [34][   60/  196]   Loss 0.402575   Top1 85.833333   Top5 98.496094   BatchTime 0.353814   LR 0.001215   
2022-11-25 11:22:52,056 - INFO  - Training [34][   80/  196]   Loss 0.406363   Top1 85.830078   Top5 98.525391   BatchTime 0.356832   LR 0.001213   
2022-11-25 11:22:59,392 - INFO  - Training [34][  100/  196]   Loss 0.411210   Top1 85.625000   Top5 98.496094   BatchTime 0.358826   LR 0.001211   
2022-11-25 11:23:06,543 - INFO  - Training [34][  120/  196]   Loss 0.411381   Top1 85.703125   Top5 98.538411   BatchTime 0.358610   LR 0.001209   
2022-11-25 11:23:13,798 - INFO  - Training [34][  140/  196]   Loss 0.412245   Top1 85.658482   Top5 98.588170   BatchTime 0.359204   LR 0.001208   
2022-11-25 11:23:21,044 - INFO  - Training [34][  160/  196]   Loss 0.413464   Top1 85.656738   Top5 98.566895   BatchTime 0.359590   LR 0.001206   
2022-11-25 11:23:28,265 - INFO  - Training [34][  180/  196]   Loss 0.413330   Top1 85.611979   Top5 98.493924   BatchTime 0.359752   LR 0.001204   
2022-11-25 11:23:33,713 - INFO  - ==> Top1: 85.680    Top5: 98.480    Loss: 0.412

2022-11-25 11:23:33,962 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:23:35,580 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:23:37,991 - INFO  - Validation [34][   20/   40]   Loss 0.372942   Top1 87.734375   Top5 99.375000   BatchTime 0.120474   
2022-11-25 11:23:39,082 - INFO  - Validation [34][   40/   40]   Loss 0.360539   Top1 87.810000   Top5 99.560000   BatchTime 0.087519   
2022-11-25 11:23:39,290 - INFO  - ==> Top1: 87.810    Top5: 99.560    Loss: 0.361

2022-11-25 11:23:39,291 - INFO  - ==> Sparsity : 0.379

2022-11-25 11:23:39,291 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:23:39,291 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:23:39,291 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 88.660   Top5: 99.600]
2022-11-25 11:23:39,414 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:23:39,415 - INFO  - >>>>>> Epoch  35
2022-11-25 11:23:39,417 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:23:47,419 - INFO  - Training [35][   20/  196]   Loss 0.417832   Top1 85.332031   Top5 98.242188   BatchTime 0.399951   LR 0.001201   
2022-11-25 11:23:53,486 - INFO  - Training [35][   40/  196]   Loss 0.420306   Top1 85.390625   Top5 98.291016   BatchTime 0.351661   LR 0.001199   
2022-11-25 11:23:59,683 - INFO  - Training [35][   60/  196]   Loss 0.416171   Top1 85.390625   Top5 98.378906   BatchTime 0.337717   LR 0.001197   
2022-11-25 11:24:06,730 - INFO  - Training [35][   80/  196]   Loss 0.409423   Top1 85.810547   Top5 98.457031   BatchTime 0.341387   LR 0.001195   
2022-11-25 11:24:13,967 - INFO  - Training [35][  100/  196]   Loss 0.401049   Top1 86.089844   Top5 98.531250   BatchTime 0.345470   LR 0.001192   
2022-11-25 11:24:21,256 - INFO  - Training [35][  120/  196]   Loss 0.395299   Top1 86.279297   Top5 98.606771   BatchTime 0.348637   LR 0.001190   
2022-11-25 11:24:28,703 - INFO  - Training [35][  140/  196]   Loss 0.393022   Top1 86.445312   Top5 98.660714   BatchTime 0.352025   LR 0.001188   
2022-11-25 11:24:35,934 - INFO  - Training [35][  160/  196]   Loss 0.396165   Top1 86.352539   Top5 98.623047   BatchTime 0.353214   LR 0.001186   
2022-11-25 11:24:43,213 - INFO  - Training [35][  180/  196]   Loss 0.395087   Top1 86.365017   Top5 98.569878   BatchTime 0.354406   LR 0.001184   
2022-11-25 11:24:48,905 - INFO  - ==> Top1: 86.398    Top5: 98.588    Loss: 0.394

2022-11-25 11:24:49,169 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:24:50,744 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:24:53,239 - INFO  - Validation [35][   20/   40]   Loss 0.377389   Top1 87.675781   Top5 99.296875   BatchTime 0.124645   
2022-11-25 11:24:54,263 - INFO  - Validation [35][   40/   40]   Loss 0.375293   Top1 87.540000   Top5 99.420000   BatchTime 0.087930   
2022-11-25 11:24:54,488 - INFO  - ==> Top1: 87.540    Top5: 99.420    Loss: 0.375

2022-11-25 11:24:54,489 - INFO  - ==> Sparsity : 0.372

2022-11-25 11:24:54,489 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:24:54,489 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:24:54,489 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 88.660   Top5: 99.600]
2022-11-25 11:24:54,625 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:24:54,626 - INFO  - >>>>>> Epoch  36
2022-11-25 11:24:54,628 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:25:03,122 - INFO  - Training [36][   20/  196]   Loss 0.420979   Top1 85.468750   Top5 97.851562   BatchTime 0.424563   LR 0.001180   
2022-11-25 11:25:10,174 - INFO  - Training [36][   40/  196]   Loss 0.407000   Top1 86.113281   Top5 98.076172   BatchTime 0.388575   LR 0.001177   
2022-11-25 11:25:17,089 - INFO  - Training [36][   60/  196]   Loss 0.397099   Top1 86.425781   Top5 98.216146   BatchTime 0.374303   LR 0.001175   
2022-11-25 11:25:22,609 - INFO  - Training [36][   80/  196]   Loss 0.393759   Top1 86.523438   Top5 98.349609   BatchTime 0.349729   LR 0.001173   
2022-11-25 11:25:29,762 - INFO  - Training [36][  100/  196]   Loss 0.385271   Top1 86.832031   Top5 98.398438   BatchTime 0.351310   LR 0.001170   
2022-11-25 11:25:36,791 - INFO  - Training [36][  120/  196]   Loss 0.380487   Top1 86.998698   Top5 98.525391   BatchTime 0.351330   LR 0.001168   
2022-11-25 11:25:44,649 - INFO  - Training [36][  140/  196]   Loss 0.377623   Top1 87.064732   Top5 98.571429   BatchTime 0.357267   LR 0.001165   
2022-11-25 11:25:52,016 - INFO  - Training [36][  160/  196]   Loss 0.377935   Top1 86.994629   Top5 98.576660   BatchTime 0.358650   LR 0.001163   
2022-11-25 11:25:59,545 - INFO  - Training [36][  180/  196]   Loss 0.380090   Top1 86.896701   Top5 98.509115   BatchTime 0.360628   LR 0.001160   
2022-11-25 11:26:05,489 - INFO  - ==> Top1: 86.980    Top5: 98.536    Loss: 0.378

2022-11-25 11:26:05,767 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:26:07,404 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:26:09,981 - INFO  - Validation [36][   20/   40]   Loss 0.353628   Top1 88.320312   Top5 99.472656   BatchTime 0.128746   
2022-11-25 11:26:11,042 - INFO  - Validation [36][   40/   40]   Loss 0.340029   Top1 88.830000   Top5 99.570000   BatchTime 0.090906   
2022-11-25 11:26:11,270 - INFO  - ==> Top1: 88.830    Top5: 99.570    Loss: 0.340

2022-11-25 11:26:11,270 - INFO  - ==> Sparsity : 0.364

2022-11-25 11:26:11,270 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:26:11,270 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:26:11,270 - INFO  - Scoreboard best 3 ==> Epoch [36][Top1: 88.830   Top5: 99.570]
2022-11-25 11:26:11,395 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:26:11,397 - INFO  - >>>>>> Epoch  37
2022-11-25 11:26:11,399 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:26:19,787 - INFO  - Training [37][   20/  196]   Loss 0.395506   Top1 86.191406   Top5 97.910156   BatchTime 0.419303   LR 0.001155   
2022-11-25 11:26:26,845 - INFO  - Training [37][   40/  196]   Loss 0.396470   Top1 86.328125   Top5 98.164062   BatchTime 0.386099   LR 0.001153   
2022-11-25 11:26:34,280 - INFO  - Training [37][   60/  196]   Loss 0.390601   Top1 86.406250   Top5 98.281250   BatchTime 0.381318   LR 0.001150   
2022-11-25 11:26:40,593 - INFO  - Training [37][   80/  196]   Loss 0.386073   Top1 86.577148   Top5 98.408203   BatchTime 0.364896   LR 0.001147   
2022-11-25 11:26:45,979 - INFO  - Training [37][  100/  196]   Loss 0.382257   Top1 86.628906   Top5 98.472656   BatchTime 0.345771   LR 0.001144   
2022-11-25 11:26:52,916 - INFO  - Training [37][  120/  196]   Loss 0.380017   Top1 86.806641   Top5 98.538411   BatchTime 0.345954   LR 0.001142   
2022-11-25 11:27:00,175 - INFO  - Training [37][  140/  196]   Loss 0.378233   Top1 86.947545   Top5 98.593750   BatchTime 0.348379   LR 0.001139   
2022-11-25 11:27:07,484 - INFO  - Training [37][  160/  196]   Loss 0.378473   Top1 86.896973   Top5 98.610840   BatchTime 0.350512   LR 0.001136   
2022-11-25 11:27:14,810 - INFO  - Training [37][  180/  196]   Loss 0.379548   Top1 86.805556   Top5 98.559028   BatchTime 0.352269   LR 0.001133   
2022-11-25 11:27:21,329 - INFO  - ==> Top1: 86.836    Top5: 98.568    Loss: 0.380

2022-11-25 11:27:21,576 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:27:23,012 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:27:25,604 - INFO  - Validation [37][   20/   40]   Loss 0.348568   Top1 88.515625   Top5 99.511719   BatchTime 0.129474   
2022-11-25 11:27:26,737 - INFO  - Validation [37][   40/   40]   Loss 0.334193   Top1 88.830000   Top5 99.640000   BatchTime 0.093071   
2022-11-25 11:27:26,976 - INFO  - ==> Top1: 88.830    Top5: 99.640    Loss: 0.334

2022-11-25 11:27:26,976 - INFO  - ==> Sparsity : 0.364

2022-11-25 11:27:26,976 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:27:26,977 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:27:26,977 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 88.830   Top5: 99.640]
2022-11-25 11:27:27,354 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:27:27,356 - INFO  - >>>>>> Epoch  38
2022-11-25 11:27:27,358 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:27:36,109 - INFO  - Training [38][   20/  196]   Loss 0.390046   Top1 86.035156   Top5 98.242188   BatchTime 0.437433   LR 0.001128   
2022-11-25 11:27:43,546 - INFO  - Training [38][   40/  196]   Loss 0.387382   Top1 86.533203   Top5 98.447266   BatchTime 0.404651   LR 0.001125   
2022-11-25 11:27:50,830 - INFO  - Training [38][   60/  196]   Loss 0.383548   Top1 86.582031   Top5 98.561198   BatchTime 0.391159   LR 0.001122   
2022-11-25 11:27:57,908 - INFO  - Training [38][   80/  196]   Loss 0.383493   Top1 86.591797   Top5 98.613281   BatchTime 0.381842   LR 0.001119   
2022-11-25 11:28:04,325 - INFO  - Training [38][  100/  196]   Loss 0.378842   Top1 86.824219   Top5 98.671875   BatchTime 0.369640   LR 0.001116   
2022-11-25 11:28:09,972 - INFO  - Training [38][  120/  196]   Loss 0.372640   Top1 87.067057   Top5 98.750000   BatchTime 0.355099   LR 0.001112   
2022-11-25 11:28:17,138 - INFO  - Training [38][  140/  196]   Loss 0.368530   Top1 87.223772   Top5 98.814174   BatchTime 0.355553   LR 0.001109   
2022-11-25 11:28:24,426 - INFO  - Training [38][  160/  196]   Loss 0.372796   Top1 87.036133   Top5 98.769531   BatchTime 0.356657   LR 0.001106   
2022-11-25 11:28:31,691 - INFO  - Training [38][  180/  196]   Loss 0.375821   Top1 86.946615   Top5 98.704427   BatchTime 0.357391   LR 0.001103   
2022-11-25 11:28:37,782 - INFO  - ==> Top1: 86.940    Top5: 98.706    Loss: 0.375

2022-11-25 11:28:38,035 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:28:39,470 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:28:42,109 - INFO  - Validation [38][   20/   40]   Loss 0.334242   Top1 89.570312   Top5 99.589844   BatchTime 0.131847   
2022-11-25 11:28:43,195 - INFO  - Validation [38][   40/   40]   Loss 0.316463   Top1 89.780000   Top5 99.690000   BatchTime 0.093076   
2022-11-25 11:28:43,463 - INFO  - ==> Top1: 89.780    Top5: 99.690    Loss: 0.316

2022-11-25 11:28:43,463 - INFO  - ==> Sparsity : 0.371

2022-11-25 11:28:43,463 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:28:43,464 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:28:43,464 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:28:49,636 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:28:49,640 - INFO  - >>>>>> Epoch  39
2022-11-25 11:28:49,642 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:28:58,433 - INFO  - Training [39][   20/  196]   Loss 0.391395   Top1 86.367188   Top5 98.183594   BatchTime 0.439408   LR 0.001097   
2022-11-25 11:29:05,629 - INFO  - Training [39][   40/  196]   Loss 0.389032   Top1 86.542969   Top5 98.437500   BatchTime 0.399623   LR 0.001094   
2022-11-25 11:29:12,416 - INFO  - Training [39][   60/  196]   Loss 0.381958   Top1 86.783854   Top5 98.496094   BatchTime 0.379521   LR 0.001090   
2022-11-25 11:29:19,125 - INFO  - Training [39][   80/  196]   Loss 0.381906   Top1 86.699219   Top5 98.569336   BatchTime 0.368509   LR 0.001087   
2022-11-25 11:29:25,789 - INFO  - Training [39][  100/  196]   Loss 0.378683   Top1 86.832031   Top5 98.535156   BatchTime 0.361441   LR 0.001084   
2022-11-25 11:29:31,474 - INFO  - Training [39][  120/  196]   Loss 0.371183   Top1 87.089844   Top5 98.678385   BatchTime 0.348574   LR 0.001080   
2022-11-25 11:29:38,291 - INFO  - Training [39][  140/  196]   Loss 0.371620   Top1 87.042411   Top5 98.730469   BatchTime 0.347471   LR 0.001077   
2022-11-25 11:29:45,601 - INFO  - Training [39][  160/  196]   Loss 0.371322   Top1 87.031250   Top5 98.737793   BatchTime 0.349724   LR 0.001073   
2022-11-25 11:29:52,902 - INFO  - Training [39][  180/  196]   Loss 0.373330   Top1 87.000868   Top5 98.682726   BatchTime 0.351426   LR 0.001070   
2022-11-25 11:29:58,657 - INFO  - ==> Top1: 87.070    Top5: 98.686    Loss: 0.372

2022-11-25 11:29:58,939 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:30:00,401 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:30:02,921 - INFO  - Validation [39][   20/   40]   Loss 0.344059   Top1 88.886719   Top5 99.550781   BatchTime 0.125909   
2022-11-25 11:30:04,036 - INFO  - Validation [39][   40/   40]   Loss 0.345242   Top1 88.820000   Top5 99.630000   BatchTime 0.090836   
2022-11-25 11:30:04,275 - INFO  - ==> Top1: 88.820    Top5: 99.630    Loss: 0.345

2022-11-25 11:30:04,276 - INFO  - ==> Sparsity : 0.365

2022-11-25 11:30:04,276 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:30:04,276 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:30:04,276 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:30:04,400 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:30:04,402 - INFO  - >>>>>> Epoch  40
2022-11-25 11:30:04,404 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:30:13,434 - INFO  - Training [40][   20/  196]   Loss 0.390836   Top1 86.347656   Top5 98.300781   BatchTime 0.451397   LR 0.001064   
2022-11-25 11:30:20,576 - INFO  - Training [40][   40/  196]   Loss 0.380096   Top1 86.787109   Top5 98.251953   BatchTime 0.404233   LR 0.001060   
2022-11-25 11:30:27,877 - INFO  - Training [40][   60/  196]   Loss 0.380988   Top1 86.634115   Top5 98.417969   BatchTime 0.391169   LR 0.001056   
2022-11-25 11:30:34,823 - INFO  - Training [40][   80/  196]   Loss 0.376293   Top1 86.840820   Top5 98.544922   BatchTime 0.380202   LR 0.001053   
2022-11-25 11:30:42,128 - INFO  - Training [40][  100/  196]   Loss 0.370669   Top1 86.941406   Top5 98.597656   BatchTime 0.377208   LR 0.001049   
2022-11-25 11:30:48,851 - INFO  - Training [40][  120/  196]   Loss 0.364251   Top1 87.190755   Top5 98.701172   BatchTime 0.370368   LR 0.001045   
2022-11-25 11:30:55,333 - INFO  - Training [40][  140/  196]   Loss 0.363173   Top1 87.282366   Top5 98.744420   BatchTime 0.363756   LR 0.001042   
2022-11-25 11:31:02,332 - INFO  - Training [40][  160/  196]   Loss 0.365617   Top1 87.216797   Top5 98.723145   BatchTime 0.362033   LR 0.001038   
2022-11-25 11:31:09,463 - INFO  - Training [40][  180/  196]   Loss 0.367189   Top1 87.157118   Top5 98.667535   BatchTime 0.361422   LR 0.001034   
2022-11-25 11:31:15,282 - INFO  - ==> Top1: 87.164    Top5: 98.666    Loss: 0.367

2022-11-25 11:31:15,538 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:31:17,176 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:31:19,699 - INFO  - Validation [40][   20/   40]   Loss 0.470795   Top1 86.933594   Top5 99.472656   BatchTime 0.126046   
2022-11-25 11:31:20,828 - INFO  - Validation [40][   40/   40]   Loss 0.468884   Top1 86.980000   Top5 99.530000   BatchTime 0.091265   
2022-11-25 11:31:21,037 - INFO  - ==> Top1: 86.980    Top5: 99.530    Loss: 0.469

2022-11-25 11:31:21,038 - INFO  - ==> Sparsity : 0.356

2022-11-25 11:31:21,038 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:31:21,039 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:31:21,039 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 89.200   Top5: 99.620]
2022-11-25 11:31:21,171 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:31:21,173 - INFO  - >>>>>> Epoch  41
2022-11-25 11:31:21,175 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:31:29,759 - INFO  - Training [41][   20/  196]   Loss 0.380695   Top1 86.914062   Top5 98.125000   BatchTime 0.429111   LR 0.001027   
2022-11-25 11:31:36,951 - INFO  - Training [41][   40/  196]   Loss 0.376210   Top1 86.894531   Top5 98.173828   BatchTime 0.394360   LR 0.001023   
2022-11-25 11:31:43,970 - INFO  - Training [41][   60/  196]   Loss 0.368071   Top1 87.154948   Top5 98.307292   BatchTime 0.379883   LR 0.001020   
2022-11-25 11:31:51,108 - INFO  - Training [41][   80/  196]   Loss 0.366549   Top1 87.148438   Top5 98.486328   BatchTime 0.374128   LR 0.001016   
2022-11-25 11:31:58,297 - INFO  - Training [41][  100/  196]   Loss 0.360218   Top1 87.441406   Top5 98.566406   BatchTime 0.371196   LR 0.001012   
2022-11-25 11:32:05,908 - INFO  - Training [41][  120/  196]   Loss 0.357596   Top1 87.633464   Top5 98.652344   BatchTime 0.372756   LR 0.001008   
2022-11-25 11:32:12,048 - INFO  - Training [41][  140/  196]   Loss 0.354609   Top1 87.734375   Top5 98.713728   BatchTime 0.363358   LR 0.001004   
2022-11-25 11:32:17,687 - INFO  - Training [41][  160/  196]   Loss 0.358218   Top1 87.617188   Top5 98.688965   BatchTime 0.353186   LR 0.001000   
2022-11-25 11:32:24,951 - INFO  - Training [41][  180/  196]   Loss 0.358373   Top1 87.580295   Top5 98.619792   BatchTime 0.354295   LR 0.000996   
2022-11-25 11:32:31,136 - INFO  - ==> Top1: 87.674    Top5: 98.608    Loss: 0.356

2022-11-25 11:32:31,377 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:32:32,743 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:32:35,212 - INFO  - Validation [41][   20/   40]   Loss 0.326311   Top1 90.039062   Top5 99.609375   BatchTime 0.123342   
2022-11-25 11:32:36,296 - INFO  - Validation [41][   40/   40]   Loss 0.311341   Top1 90.320000   Top5 99.670000   BatchTime 0.088780   
2022-11-25 11:32:36,484 - INFO  - ==> Top1: 90.320    Top5: 99.670    Loss: 0.311

2022-11-25 11:32:36,484 - INFO  - ==> Sparsity : 0.363

2022-11-25 11:32:36,484 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:32:36,484 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:32:36,485 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 89.680   Top5: 99.670]
2022-11-25 11:32:42,230 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:32:42,233 - INFO  - >>>>>> Epoch  42
2022-11-25 11:32:42,237 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:32:51,439 - INFO  - Training [42][   20/  196]   Loss 0.362366   Top1 87.167969   Top5 97.890625   BatchTime 0.459864   LR 0.000988   
2022-11-25 11:32:58,539 - INFO  - Training [42][   40/  196]   Loss 0.363698   Top1 87.314453   Top5 98.222656   BatchTime 0.407442   LR 0.000984   
2022-11-25 11:33:05,629 - INFO  - Training [42][   60/  196]   Loss 0.361471   Top1 87.473958   Top5 98.398438   BatchTime 0.389790   LR 0.000980   
2022-11-25 11:33:12,784 - INFO  - Training [42][   80/  196]   Loss 0.362119   Top1 87.500000   Top5 98.486328   BatchTime 0.381776   LR 0.000976   
2022-11-25 11:33:19,946 - INFO  - Training [42][  100/  196]   Loss 0.357129   Top1 87.691406   Top5 98.566406   BatchTime 0.377049   LR 0.000972   
2022-11-25 11:33:27,436 - INFO  - Training [42][  120/  196]   Loss 0.351823   Top1 87.792969   Top5 98.652344   BatchTime 0.376618   LR 0.000968   
2022-11-25 11:33:33,603 - INFO  - Training [42][  140/  196]   Loss 0.355164   Top1 87.703683   Top5 98.738839   BatchTime 0.366866   LR 0.000964   
2022-11-25 11:33:40,131 - INFO  - Training [42][  160/  196]   Loss 0.355964   Top1 87.597656   Top5 98.713379   BatchTime 0.361805   LR 0.000959   
2022-11-25 11:33:47,369 - INFO  - Training [42][  180/  196]   Loss 0.356554   Top1 87.586806   Top5 98.691406   BatchTime 0.361815   LR 0.000955   
2022-11-25 11:33:53,302 - INFO  - ==> Top1: 87.604    Top5: 98.700    Loss: 0.356

2022-11-25 11:33:53,571 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:33:55,061 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:33:57,579 - INFO  - Validation [42][   20/   40]   Loss 0.302757   Top1 90.136719   Top5 99.550781   BatchTime 0.125819   
2022-11-25 11:33:58,659 - INFO  - Validation [42][   40/   40]   Loss 0.293029   Top1 90.480000   Top5 99.650000   BatchTime 0.089924   
2022-11-25 11:33:58,880 - INFO  - ==> Top1: 90.480    Top5: 99.650    Loss: 0.293

2022-11-25 11:33:58,881 - INFO  - ==> Sparsity : 0.367

2022-11-25 11:33:58,881 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:33:58,881 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:33:58,881 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:34:04,044 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:34:04,047 - INFO  - >>>>>> Epoch  43
2022-11-25 11:34:04,048 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:34:12,885 - INFO  - Training [43][   20/  196]   Loss 0.375865   Top1 86.816406   Top5 98.281250   BatchTime 0.441715   LR 0.000947   
2022-11-25 11:34:20,010 - INFO  - Training [43][   40/  196]   Loss 0.373912   Top1 86.748047   Top5 98.486328   BatchTime 0.398961   LR 0.000943   
2022-11-25 11:34:27,389 - INFO  - Training [43][   60/  196]   Loss 0.364100   Top1 87.070312   Top5 98.600260   BatchTime 0.388968   LR 0.000939   
2022-11-25 11:34:34,448 - INFO  - Training [43][   80/  196]   Loss 0.361068   Top1 87.314453   Top5 98.706055   BatchTime 0.379961   LR 0.000934   
2022-11-25 11:34:41,644 - INFO  - Training [43][  100/  196]   Loss 0.357343   Top1 87.390625   Top5 98.734375   BatchTime 0.375931   LR 0.000930   
2022-11-25 11:34:48,675 - INFO  - Training [43][  120/  196]   Loss 0.351338   Top1 87.652995   Top5 98.789062   BatchTime 0.371865   LR 0.000926   
2022-11-25 11:34:55,616 - INFO  - Training [43][  140/  196]   Loss 0.351770   Top1 87.636719   Top5 98.861607   BatchTime 0.368321   LR 0.000921   
2022-11-25 11:35:02,908 - INFO  - Training [43][  160/  196]   Loss 0.355469   Top1 87.509766   Top5 98.842773   BatchTime 0.367854   LR 0.000917   
2022-11-25 11:35:10,037 - INFO  - Training [43][  180/  196]   Loss 0.354962   Top1 87.578125   Top5 98.786892   BatchTime 0.366584   LR 0.000912   
2022-11-25 11:35:15,936 - INFO  - ==> Top1: 87.604    Top5: 98.788    Loss: 0.354

2022-11-25 11:35:16,190 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:35:17,659 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:35:20,238 - INFO  - Validation [43][   20/   40]   Loss 0.342044   Top1 89.687500   Top5 99.550781   BatchTime 0.128875   
2022-11-25 11:35:21,295 - INFO  - Validation [43][   40/   40]   Loss 0.332322   Top1 89.620000   Top5 99.640000   BatchTime 0.090854   
2022-11-25 11:35:21,574 - INFO  - ==> Top1: 89.620    Top5: 99.640    Loss: 0.332

2022-11-25 11:35:21,574 - INFO  - ==> Sparsity : 0.371

2022-11-25 11:35:21,574 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:35:21,575 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:35:21,575 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:35:21,720 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:35:21,722 - INFO  - >>>>>> Epoch  44
2022-11-25 11:35:21,724 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:35:30,308 - INFO  - Training [44][   20/  196]   Loss 0.360992   Top1 87.109375   Top5 98.242188   BatchTime 0.429090   LR 0.000904   
2022-11-25 11:35:37,467 - INFO  - Training [44][   40/  196]   Loss 0.358162   Top1 87.382812   Top5 98.388672   BatchTime 0.393523   LR 0.000900   
2022-11-25 11:35:44,771 - INFO  - Training [44][   60/  196]   Loss 0.356625   Top1 87.532552   Top5 98.476562   BatchTime 0.384069   LR 0.000895   
2022-11-25 11:35:51,965 - INFO  - Training [44][   80/  196]   Loss 0.359286   Top1 87.490234   Top5 98.603516   BatchTime 0.377986   LR 0.000891   
2022-11-25 11:35:59,140 - INFO  - Training [44][  100/  196]   Loss 0.352947   Top1 87.816406   Top5 98.621094   BatchTime 0.374127   LR 0.000886   
2022-11-25 11:36:06,261 - INFO  - Training [44][  120/  196]   Loss 0.348082   Top1 87.975260   Top5 98.688151   BatchTime 0.371116   LR 0.000882   
2022-11-25 11:36:12,468 - INFO  - Training [44][  140/  196]   Loss 0.347025   Top1 88.041295   Top5 98.741629   BatchTime 0.362436   LR 0.000877   
2022-11-25 11:36:19,771 - INFO  - Training [44][  160/  196]   Loss 0.349616   Top1 87.951660   Top5 98.723145   BatchTime 0.362775   LR 0.000873   
2022-11-25 11:36:26,875 - INFO  - Training [44][  180/  196]   Loss 0.351428   Top1 87.905816   Top5 98.639323   BatchTime 0.361935   LR 0.000868   
2022-11-25 11:36:32,997 - INFO  - ==> Top1: 87.916    Top5: 98.648    Loss: 0.351

2022-11-25 11:36:33,246 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:36:34,764 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:36:37,565 - INFO  - Validation [44][   20/   40]   Loss 0.345861   Top1 89.218750   Top5 99.453125   BatchTime 0.139908   
2022-11-25 11:36:39,160 - INFO  - Validation [44][   40/   40]   Loss 0.339046   Top1 89.200000   Top5 99.560000   BatchTime 0.109848   
2022-11-25 11:36:39,412 - INFO  - ==> Top1: 89.200    Top5: 99.560    Loss: 0.339

2022-11-25 11:36:39,412 - INFO  - ==> Sparsity : 0.368

2022-11-25 11:36:39,412 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:36:39,412 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:36:39,413 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:36:39,788 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:36:39,790 - INFO  - >>>>>> Epoch  45
2022-11-25 11:36:39,792 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:36:48,405 - INFO  - Training [45][   20/  196]   Loss 0.351594   Top1 87.968750   Top5 98.242188   BatchTime 0.430497   LR 0.000860   
2022-11-25 11:36:55,619 - INFO  - Training [45][   40/  196]   Loss 0.362762   Top1 87.705078   Top5 98.398438   BatchTime 0.395624   LR 0.000855   
2022-11-25 11:37:02,786 - INFO  - Training [45][   60/  196]   Loss 0.360474   Top1 87.558594   Top5 98.476562   BatchTime 0.383188   LR 0.000850   
2022-11-25 11:37:09,827 - INFO  - Training [45][   80/  196]   Loss 0.357601   Top1 87.680664   Top5 98.637695   BatchTime 0.375408   LR 0.000846   
2022-11-25 11:37:16,844 - INFO  - Training [45][  100/  196]   Loss 0.349870   Top1 87.968750   Top5 98.707031   BatchTime 0.370496   LR 0.000841   
2022-11-25 11:37:24,115 - INFO  - Training [45][  120/  196]   Loss 0.346620   Top1 88.066406   Top5 98.769531   BatchTime 0.369337   LR 0.000836   
2022-11-25 11:37:30,353 - INFO  - Training [45][  140/  196]   Loss 0.345968   Top1 88.099888   Top5 98.819754   BatchTime 0.361133   LR 0.000832   
2022-11-25 11:37:37,541 - INFO  - Training [45][  160/  196]   Loss 0.349496   Top1 87.900391   Top5 98.811035   BatchTime 0.360915   LR 0.000827   
2022-11-25 11:37:44,792 - INFO  - Training [45][  180/  196]   Loss 0.349525   Top1 87.914497   Top5 98.747830   BatchTime 0.361095   LR 0.000822   
2022-11-25 11:37:50,692 - INFO  - ==> Top1: 87.928    Top5: 98.756    Loss: 0.350

2022-11-25 11:37:50,974 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:37:52,479 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:37:55,437 - INFO  - Validation [45][   20/   40]   Loss 0.338131   Top1 89.433594   Top5 99.589844   BatchTime 0.147749   
2022-11-25 11:37:57,245 - INFO  - Validation [45][   40/   40]   Loss 0.325086   Top1 89.480000   Top5 99.660000   BatchTime 0.119098   
2022-11-25 11:37:57,653 - INFO  - ==> Top1: 89.480    Top5: 99.660    Loss: 0.325

2022-11-25 11:37:57,653 - INFO  - ==> Sparsity : 0.382

2022-11-25 11:37:57,653 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:37:57,654 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:37:57,654 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:37:57,789 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:37:57,791 - INFO  - >>>>>> Epoch  46
2022-11-25 11:37:57,793 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:38:06,785 - INFO  - Training [46][   20/  196]   Loss 0.347049   Top1 87.421875   Top5 98.300781   BatchTime 0.449466   LR 0.000814   
2022-11-25 11:38:14,129 - INFO  - Training [46][   40/  196]   Loss 0.347273   Top1 87.519531   Top5 98.515625   BatchTime 0.408355   LR 0.000809   
2022-11-25 11:38:21,455 - INFO  - Training [46][   60/  196]   Loss 0.353941   Top1 87.434896   Top5 98.613281   BatchTime 0.394326   LR 0.000804   
2022-11-25 11:38:28,446 - INFO  - Training [46][   80/  196]   Loss 0.351276   Top1 87.656250   Top5 98.715820   BatchTime 0.383128   LR 0.000799   
2022-11-25 11:38:35,454 - INFO  - Training [46][  100/  196]   Loss 0.343557   Top1 88.011719   Top5 98.753906   BatchTime 0.376584   LR 0.000794   
2022-11-25 11:38:42,500 - INFO  - Training [46][  120/  196]   Loss 0.338765   Top1 88.193359   Top5 98.802083   BatchTime 0.372534   LR 0.000789   
2022-11-25 11:38:48,867 - INFO  - Training [46][  140/  196]   Loss 0.338311   Top1 88.250558   Top5 98.878348   BatchTime 0.364798   LR 0.000785   
2022-11-25 11:38:55,845 - INFO  - Training [46][  160/  196]   Loss 0.339652   Top1 88.168945   Top5 98.854980   BatchTime 0.362810   LR 0.000780   
2022-11-25 11:39:03,131 - INFO  - Training [46][  180/  196]   Loss 0.339186   Top1 88.192274   Top5 98.780382   BatchTime 0.362974   LR 0.000775   
2022-11-25 11:39:08,923 - INFO  - ==> Top1: 88.226    Top5: 98.776    Loss: 0.338

2022-11-25 11:39:09,185 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:39:10,971 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:39:13,516 - INFO  - Validation [46][   20/   40]   Loss 0.339279   Top1 89.335938   Top5 99.453125   BatchTime 0.127166   
2022-11-25 11:39:14,616 - INFO  - Validation [46][   40/   40]   Loss 0.335033   Top1 89.210000   Top5 99.550000   BatchTime 0.091085   
2022-11-25 11:39:14,872 - INFO  - ==> Top1: 89.210    Top5: 99.550    Loss: 0.335

2022-11-25 11:39:14,872 - INFO  - ==> Sparsity : 0.379

2022-11-25 11:39:14,872 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:39:14,872 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:39:14,872 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:39:14,999 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:39:15,001 - INFO  - >>>>>> Epoch  47
2022-11-25 11:39:15,003 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:39:23,802 - INFO  - Training [47][   20/  196]   Loss 0.359875   Top1 87.382812   Top5 98.125000   BatchTime 0.439835   LR 0.000766   
2022-11-25 11:39:30,878 - INFO  - Training [47][   40/  196]   Loss 0.351884   Top1 87.685547   Top5 98.300781   BatchTime 0.396818   LR 0.000761   
2022-11-25 11:39:38,070 - INFO  - Training [47][   60/  196]   Loss 0.342886   Top1 88.138021   Top5 98.541667   BatchTime 0.384407   LR 0.000756   
2022-11-25 11:39:45,464 - INFO  - Training [47][   80/  196]   Loss 0.345562   Top1 88.076172   Top5 98.632812   BatchTime 0.380730   LR 0.000752   
2022-11-25 11:39:52,678 - INFO  - Training [47][  100/  196]   Loss 0.339511   Top1 88.273438   Top5 98.675781   BatchTime 0.376725   LR 0.000747   
2022-11-25 11:39:59,699 - INFO  - Training [47][  120/  196]   Loss 0.334341   Top1 88.457031   Top5 98.743490   BatchTime 0.372447   LR 0.000742   
2022-11-25 11:40:05,966 - INFO  - Training [47][  140/  196]   Loss 0.332239   Top1 88.512835   Top5 98.800223   BatchTime 0.364003   LR 0.000737   
2022-11-25 11:40:13,023 - INFO  - Training [47][  160/  196]   Loss 0.335688   Top1 88.369141   Top5 98.806152   BatchTime 0.362610   LR 0.000732   
2022-11-25 11:40:20,251 - INFO  - Training [47][  180/  196]   Loss 0.334817   Top1 88.368056   Top5 98.747830   BatchTime 0.362476   LR 0.000727   
2022-11-25 11:40:26,194 - INFO  - ==> Top1: 88.414    Top5: 98.748    Loss: 0.333

2022-11-25 11:40:26,471 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:40:27,894 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:40:30,442 - INFO  - Validation [47][   20/   40]   Loss 0.336039   Top1 89.218750   Top5 99.492188   BatchTime 0.127279   
2022-11-25 11:40:31,578 - INFO  - Validation [47][   40/   40]   Loss 0.326589   Top1 89.540000   Top5 99.610000   BatchTime 0.092059   
2022-11-25 11:40:31,806 - INFO  - ==> Top1: 89.540    Top5: 99.610    Loss: 0.327

2022-11-25 11:40:31,807 - INFO  - ==> Sparsity : 0.376

2022-11-25 11:40:31,807 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:40:31,807 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:40:31,808 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:40:31,965 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:40:31,966 - INFO  - >>>>>> Epoch  48
2022-11-25 11:40:31,968 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:40:40,643 - INFO  - Training [48][   20/  196]   Loss 0.348828   Top1 88.066406   Top5 98.242188   BatchTime 0.433631   LR 0.000718   
2022-11-25 11:40:47,969 - INFO  - Training [48][   40/  196]   Loss 0.347693   Top1 87.900391   Top5 98.320312   BatchTime 0.399963   LR 0.000713   
2022-11-25 11:40:55,133 - INFO  - Training [48][   60/  196]   Loss 0.349903   Top1 87.734375   Top5 98.437500   BatchTime 0.386032   LR 0.000708   
2022-11-25 11:41:02,387 - INFO  - Training [48][   80/  196]   Loss 0.345456   Top1 88.022461   Top5 98.608398   BatchTime 0.380197   LR 0.000703   
2022-11-25 11:41:09,424 - INFO  - Training [48][  100/  196]   Loss 0.334215   Top1 88.351562   Top5 98.730469   BatchTime 0.374527   LR 0.000698   
2022-11-25 11:41:16,505 - INFO  - Training [48][  120/  196]   Loss 0.331251   Top1 88.476562   Top5 98.785807   BatchTime 0.371114   LR 0.000693   
2022-11-25 11:41:22,386 - INFO  - Training [48][  140/  196]   Loss 0.328178   Top1 88.579799   Top5 98.842076   BatchTime 0.360108   LR 0.000688   
2022-11-25 11:41:29,677 - INFO  - Training [48][  160/  196]   Loss 0.332622   Top1 88.400879   Top5 98.840332   BatchTime 0.360660   LR 0.000683   
2022-11-25 11:41:37,052 - INFO  - Training [48][  180/  196]   Loss 0.332224   Top1 88.372396   Top5 98.791233   BatchTime 0.361561   LR 0.000678   
2022-11-25 11:41:43,079 - INFO  - ==> Top1: 88.330    Top5: 98.788    Loss: 0.333

2022-11-25 11:41:43,319 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:41:44,873 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:41:47,693 - INFO  - Validation [48][   20/   40]   Loss 0.422451   Top1 86.738281   Top5 99.277344   BatchTime 0.140934   
2022-11-25 11:41:48,800 - INFO  - Validation [48][   40/   40]   Loss 0.415302   Top1 86.950000   Top5 99.380000   BatchTime 0.098147   
2022-11-25 11:41:49,023 - INFO  - ==> Top1: 86.950    Top5: 99.380    Loss: 0.415

2022-11-25 11:41:49,023 - INFO  - ==> Sparsity : 0.377

2022-11-25 11:41:49,023 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:41:49,023 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:41:49,023 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:41:49,157 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:41:49,158 - INFO  - >>>>>> Epoch  49
2022-11-25 11:41:49,160 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:41:58,142 - INFO  - Training [49][   20/  196]   Loss 0.330176   Top1 88.359375   Top5 98.085938   BatchTime 0.448927   LR 0.000669   
2022-11-25 11:42:05,815 - INFO  - Training [49][   40/  196]   Loss 0.329747   Top1 88.330078   Top5 98.388672   BatchTime 0.416303   LR 0.000664   
2022-11-25 11:42:13,078 - INFO  - Training [49][   60/  196]   Loss 0.323964   Top1 88.600260   Top5 98.561198   BatchTime 0.398589   LR 0.000659   
2022-11-25 11:42:20,524 - INFO  - Training [49][   80/  196]   Loss 0.326773   Top1 88.525391   Top5 98.647461   BatchTime 0.392010   LR 0.000654   
2022-11-25 11:42:27,443 - INFO  - Training [49][  100/  196]   Loss 0.326616   Top1 88.531250   Top5 98.699219   BatchTime 0.382799   LR 0.000649   
2022-11-25 11:42:34,443 - INFO  - Training [49][  120/  196]   Loss 0.323824   Top1 88.606771   Top5 98.798828   BatchTime 0.377330   LR 0.000644   
2022-11-25 11:42:40,102 - INFO  - Training [49][  140/  196]   Loss 0.321378   Top1 88.738839   Top5 98.853237   BatchTime 0.363847   LR 0.000639   
2022-11-25 11:42:47,335 - INFO  - Training [49][  160/  196]   Loss 0.322883   Top1 88.693848   Top5 98.828125   BatchTime 0.363570   LR 0.000634   
2022-11-25 11:42:54,433 - INFO  - Training [49][  180/  196]   Loss 0.322361   Top1 88.689236   Top5 98.782552   BatchTime 0.362608   LR 0.000629   
2022-11-25 11:43:00,415 - INFO  - ==> Top1: 88.734    Top5: 98.770    Loss: 0.322

2022-11-25 11:43:00,635 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:43:02,073 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:43:04,780 - INFO  - Validation [49][   20/   40]   Loss 0.370886   Top1 88.476562   Top5 99.355469   BatchTime 0.135255   
2022-11-25 11:43:05,837 - INFO  - Validation [49][   40/   40]   Loss 0.360953   Top1 88.400000   Top5 99.480000   BatchTime 0.094058   
2022-11-25 11:43:06,075 - INFO  - ==> Top1: 88.400    Top5: 99.480    Loss: 0.361

2022-11-25 11:43:06,076 - INFO  - ==> Sparsity : 0.376

2022-11-25 11:43:06,076 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:43:06,076 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:43:06,076 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:43:06,216 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:43:06,219 - INFO  - >>>>>> Epoch  50
2022-11-25 11:43:06,222 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:43:15,162 - INFO  - Training [50][   20/  196]   Loss 0.322344   Top1 88.417969   Top5 98.417969   BatchTime 0.446810   LR 0.000620   
2022-11-25 11:43:22,728 - INFO  - Training [50][   40/  196]   Loss 0.328150   Top1 88.281250   Top5 98.486328   BatchTime 0.412531   LR 0.000615   
2022-11-25 11:43:30,434 - INFO  - Training [50][   60/  196]   Loss 0.328015   Top1 88.424479   Top5 98.515625   BatchTime 0.403464   LR 0.000610   
2022-11-25 11:43:37,827 - INFO  - Training [50][   80/  196]   Loss 0.327807   Top1 88.491211   Top5 98.666992   BatchTime 0.395010   LR 0.000605   
2022-11-25 11:43:45,090 - INFO  - Training [50][  100/  196]   Loss 0.323600   Top1 88.613281   Top5 98.730469   BatchTime 0.388634   LR 0.000600   
2022-11-25 11:43:51,894 - INFO  - Training [50][  120/  196]   Loss 0.319216   Top1 88.753255   Top5 98.828125   BatchTime 0.380559   LR 0.000595   
2022-11-25 11:43:58,289 - INFO  - Training [50][  140/  196]   Loss 0.315718   Top1 88.844866   Top5 98.909040   BatchTime 0.371874   LR 0.000590   
2022-11-25 11:44:05,962 - INFO  - Training [50][  160/  196]   Loss 0.317948   Top1 88.774414   Top5 98.886719   BatchTime 0.373346   LR 0.000585   
2022-11-25 11:44:13,124 - INFO  - Training [50][  180/  196]   Loss 0.319743   Top1 88.756510   Top5 98.808594   BatchTime 0.371651   LR 0.000580   
2022-11-25 11:44:18,874 - INFO  - ==> Top1: 88.798    Top5: 98.828    Loss: 0.318

2022-11-25 11:44:19,150 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:44:20,832 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:44:23,436 - INFO  - Validation [50][   20/   40]   Loss 0.547320   Top1 83.261719   Top5 98.964844   BatchTime 0.130113   
2022-11-25 11:44:24,431 - INFO  - Validation [50][   40/   40]   Loss 0.539249   Top1 83.390000   Top5 99.040000   BatchTime 0.089922   
2022-11-25 11:44:24,674 - INFO  - ==> Top1: 83.390    Top5: 99.040    Loss: 0.539

2022-11-25 11:44:24,674 - INFO  - ==> Sparsity : 0.384

2022-11-25 11:44:24,675 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:44:24,675 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:44:24,675 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:44:24,800 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:44:24,802 - INFO  - >>>>>> Epoch  51
2022-11-25 11:44:24,804 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:44:33,485 - INFO  - Training [51][   20/  196]   Loss 0.320512   Top1 88.671875   Top5 98.261719   BatchTime 0.433961   LR 0.000571   
2022-11-25 11:44:40,889 - INFO  - Training [51][   40/  196]   Loss 0.329012   Top1 88.544922   Top5 98.457031   BatchTime 0.402053   LR 0.000566   
2022-11-25 11:44:48,362 - INFO  - Training [51][   60/  196]   Loss 0.325733   Top1 88.756510   Top5 98.580729   BatchTime 0.392590   LR 0.000561   
2022-11-25 11:44:55,628 - INFO  - Training [51][   80/  196]   Loss 0.323941   Top1 88.828125   Top5 98.701172   BatchTime 0.385273   LR 0.000556   
2022-11-25 11:45:03,085 - INFO  - Training [51][  100/  196]   Loss 0.318773   Top1 89.003906   Top5 98.742188   BatchTime 0.382782   LR 0.000551   
2022-11-25 11:45:09,449 - INFO  - Training [51][  120/  196]   Loss 0.312361   Top1 89.176432   Top5 98.831380   BatchTime 0.372016   LR 0.000546   
2022-11-25 11:45:15,634 - INFO  - Training [51][  140/  196]   Loss 0.310231   Top1 89.257812   Top5 98.900670   BatchTime 0.363050   LR 0.000541   
2022-11-25 11:45:23,080 - INFO  - Training [51][  160/  196]   Loss 0.312965   Top1 89.135742   Top5 98.911133   BatchTime 0.364210   LR 0.000536   
2022-11-25 11:45:30,116 - INFO  - Training [51][  180/  196]   Loss 0.312370   Top1 89.140625   Top5 98.845486   BatchTime 0.362830   LR 0.000531   
2022-11-25 11:45:35,887 - INFO  - ==> Top1: 89.172    Top5: 98.854    Loss: 0.312

2022-11-25 11:45:36,178 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:45:37,694 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:45:40,150 - INFO  - Validation [51][   20/   40]   Loss 0.573324   Top1 82.871094   Top5 99.121094   BatchTime 0.122681   
2022-11-25 11:45:41,262 - INFO  - Validation [51][   40/   40]   Loss 0.567064   Top1 82.490000   Top5 99.140000   BatchTime 0.089166   
2022-11-25 11:45:41,491 - INFO  - ==> Top1: 82.490    Top5: 99.140    Loss: 0.567

2022-11-25 11:45:41,491 - INFO  - ==> Sparsity : 0.376

2022-11-25 11:45:41,491 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:45:41,492 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:45:41,492 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:45:41,863 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:45:41,865 - INFO  - >>>>>> Epoch  52
2022-11-25 11:45:41,866 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:45:51,096 - INFO  - Training [52][   20/  196]   Loss 0.305939   Top1 89.062500   Top5 98.593750   BatchTime 0.461357   LR 0.000523   
2022-11-25 11:45:58,652 - INFO  - Training [52][   40/  196]   Loss 0.308330   Top1 89.287109   Top5 98.574219   BatchTime 0.419586   LR 0.000518   
2022-11-25 11:46:06,139 - INFO  - Training [52][   60/  196]   Loss 0.311165   Top1 89.114583   Top5 98.645833   BatchTime 0.404509   LR 0.000513   
2022-11-25 11:46:13,361 - INFO  - Training [52][   80/  196]   Loss 0.312828   Top1 88.974609   Top5 98.813477   BatchTime 0.393655   LR 0.000508   
2022-11-25 11:46:20,744 - INFO  - Training [52][  100/  196]   Loss 0.311184   Top1 89.027344   Top5 98.839844   BatchTime 0.388753   LR 0.000503   
2022-11-25 11:46:27,039 - INFO  - Training [52][  120/  196]   Loss 0.310417   Top1 89.124349   Top5 98.867188   BatchTime 0.376412   LR 0.000498   
2022-11-25 11:46:32,338 - INFO  - Training [52][  140/  196]   Loss 0.307934   Top1 89.190848   Top5 98.936942   BatchTime 0.360492   LR 0.000493   
2022-11-25 11:46:38,303 - INFO  - Training [52][  160/  196]   Loss 0.309018   Top1 89.160156   Top5 98.940430   BatchTime 0.352713   LR 0.000488   
2022-11-25 11:46:45,754 - INFO  - Training [52][  180/  196]   Loss 0.310318   Top1 89.116753   Top5 98.878038   BatchTime 0.354915   LR 0.000483   
2022-11-25 11:46:51,433 - INFO  - ==> Top1: 89.086    Top5: 98.884    Loss: 0.311

2022-11-25 11:46:51,665 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:46:53,149 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:46:55,712 - INFO  - Validation [52][   20/   40]   Loss 0.447171   Top1 86.367188   Top5 99.238281   BatchTime 0.128059   
2022-11-25 11:46:56,815 - INFO  - Validation [52][   40/   40]   Loss 0.451661   Top1 85.950000   Top5 99.330000   BatchTime 0.091605   
2022-11-25 11:46:57,035 - INFO  - ==> Top1: 85.950    Top5: 99.330    Loss: 0.452

2022-11-25 11:46:57,035 - INFO  - ==> Sparsity : 0.377

2022-11-25 11:46:57,036 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:46:57,036 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:46:57,036 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 89.780   Top5: 99.690]
2022-11-25 11:46:57,172 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:46:57,174 - INFO  - >>>>>> Epoch  53
2022-11-25 11:46:57,176 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:47:06,105 - INFO  - Training [53][   20/  196]   Loss 0.324713   Top1 88.261719   Top5 98.144531   BatchTime 0.446271   LR 0.000474   
2022-11-25 11:47:13,479 - INFO  - Training [53][   40/  196]   Loss 0.319823   Top1 88.789062   Top5 98.281250   BatchTime 0.407499   LR 0.000470   
2022-11-25 11:47:20,810 - INFO  - Training [53][   60/  196]   Loss 0.316371   Top1 89.010417   Top5 98.476562   BatchTime 0.393852   LR 0.000465   
2022-11-25 11:47:28,228 - INFO  - Training [53][   80/  196]   Loss 0.311329   Top1 89.140625   Top5 98.691406   BatchTime 0.388114   LR 0.000460   
2022-11-25 11:47:35,375 - INFO  - Training [53][  100/  196]   Loss 0.303768   Top1 89.386719   Top5 98.789062   BatchTime 0.381964   LR 0.000455   
2022-11-25 11:47:42,779 - INFO  - Training [53][  120/  196]   Loss 0.297105   Top1 89.635417   Top5 98.902995   BatchTime 0.380001   LR 0.000450   
2022-11-25 11:47:49,458 - INFO  - Training [53][  140/  196]   Loss 0.297641   Top1 89.659598   Top5 98.942522   BatchTime 0.373418   LR 0.000445   
2022-11-25 11:47:55,752 - INFO  - Training [53][  160/  196]   Loss 0.300576   Top1 89.558105   Top5 98.906250   BatchTime 0.366082   LR 0.000441   
2022-11-25 11:48:03,275 - INFO  - Training [53][  180/  196]   Loss 0.302919   Top1 89.505208   Top5 98.849826   BatchTime 0.367198   LR 0.000436   
2022-11-25 11:48:08,958 - INFO  - ==> Top1: 89.520    Top5: 98.844    Loss: 0.303

2022-11-25 11:48:09,220 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:48:10,685 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:48:13,359 - INFO  - Validation [53][   20/   40]   Loss 0.341248   Top1 89.589844   Top5 99.453125   BatchTime 0.133562   
2022-11-25 11:48:14,492 - INFO  - Validation [53][   40/   40]   Loss 0.325677   Top1 89.850000   Top5 99.570000   BatchTime 0.095123   
2022-11-25 11:48:14,780 - INFO  - ==> Top1: 89.850    Top5: 99.570    Loss: 0.326

2022-11-25 11:48:14,780 - INFO  - ==> Sparsity : 0.383

2022-11-25 11:48:14,781 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:48:14,781 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:48:14,781 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 89.850   Top5: 99.570]
2022-11-25 11:48:15,173 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:48:15,175 - INFO  - >>>>>> Epoch  54
2022-11-25 11:48:15,177 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:48:24,198 - INFO  - Training [54][   20/  196]   Loss 0.328287   Top1 88.417969   Top5 98.300781   BatchTime 0.450914   LR 0.000427   
2022-11-25 11:48:31,485 - INFO  - Training [54][   40/  196]   Loss 0.318954   Top1 88.798828   Top5 98.564453   BatchTime 0.407645   LR 0.000423   
2022-11-25 11:48:39,155 - INFO  - Training [54][   60/  196]   Loss 0.310836   Top1 89.042969   Top5 98.645833   BatchTime 0.399591   LR 0.000418   
2022-11-25 11:48:46,433 - INFO  - Training [54][   80/  196]   Loss 0.308883   Top1 89.189453   Top5 98.759766   BatchTime 0.390667   LR 0.000413   
2022-11-25 11:48:53,756 - INFO  - Training [54][  100/  196]   Loss 0.301859   Top1 89.410156   Top5 98.773438   BatchTime 0.385766   LR 0.000408   
2022-11-25 11:49:00,874 - INFO  - Training [54][  120/  196]   Loss 0.295986   Top1 89.664714   Top5 98.873698   BatchTime 0.380782   LR 0.000404   
2022-11-25 11:49:07,214 - INFO  - Training [54][  140/  196]   Loss 0.297056   Top1 89.665179   Top5 98.928571   BatchTime 0.371671   LR 0.000399   
2022-11-25 11:49:13,129 - INFO  - Training [54][  160/  196]   Loss 0.299739   Top1 89.572754   Top5 98.955078   BatchTime 0.362182   LR 0.000394   
2022-11-25 11:49:19,687 - INFO  - Training [54][  180/  196]   Loss 0.300935   Top1 89.537760   Top5 98.908420   BatchTime 0.358373   LR 0.000390   
2022-11-25 11:49:25,461 - INFO  - ==> Top1: 89.500    Top5: 98.912    Loss: 0.301

2022-11-25 11:49:25,751 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:49:27,206 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:49:29,784 - INFO  - Validation [54][   20/   40]   Loss 0.321526   Top1 90.097656   Top5 99.570312   BatchTime 0.128814   
2022-11-25 11:49:30,927 - INFO  - Validation [54][   40/   40]   Loss 0.307577   Top1 90.430000   Top5 99.640000   BatchTime 0.092971   
2022-11-25 11:49:31,168 - INFO  - ==> Top1: 90.430    Top5: 99.640    Loss: 0.308

2022-11-25 11:49:31,169 - INFO  - ==> Sparsity : 0.380

2022-11-25 11:49:31,169 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:49:31,169 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 90.430   Top5: 99.640]
2022-11-25 11:49:31,169 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 90.320   Top5: 99.670]
2022-11-25 11:49:31,328 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:49:31,330 - INFO  - >>>>>> Epoch  55
2022-11-25 11:49:31,332 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:49:40,346 - INFO  - Training [55][   20/  196]   Loss 0.327173   Top1 88.613281   Top5 98.417969   BatchTime 0.450575   LR 0.000381   
2022-11-25 11:49:47,655 - INFO  - Training [55][   40/  196]   Loss 0.329051   Top1 88.505859   Top5 98.486328   BatchTime 0.407996   LR 0.000377   
2022-11-25 11:49:55,234 - INFO  - Training [55][   60/  196]   Loss 0.319185   Top1 88.828125   Top5 98.684896   BatchTime 0.398312   LR 0.000372   
2022-11-25 11:50:02,598 - INFO  - Training [55][   80/  196]   Loss 0.313953   Top1 88.994141   Top5 98.808594   BatchTime 0.390784   LR 0.000368   
2022-11-25 11:50:09,820 - INFO  - Training [55][  100/  196]   Loss 0.304911   Top1 89.343750   Top5 98.867188   BatchTime 0.384852   LR 0.000363   
2022-11-25 11:50:17,143 - INFO  - Training [55][  120/  196]   Loss 0.299918   Top1 89.459635   Top5 98.955078   BatchTime 0.381732   LR 0.000358   
2022-11-25 11:50:24,196 - INFO  - Training [55][  140/  196]   Loss 0.295585   Top1 89.662388   Top5 99.026228   BatchTime 0.377575   LR 0.000354   
2022-11-25 11:50:31,080 - INFO  - Training [55][  160/  196]   Loss 0.297570   Top1 89.628906   Top5 98.991699   BatchTime 0.373402   LR 0.000349   
2022-11-25 11:50:37,594 - INFO  - Training [55][  180/  196]   Loss 0.299146   Top1 89.613715   Top5 98.865017   BatchTime 0.368104   LR 0.000345   
2022-11-25 11:50:41,647 - INFO  - ==> Top1: 89.662    Top5: 98.858    Loss: 0.297

2022-11-25 11:50:41,824 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:50:43,089 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:50:45,863 - INFO  - Validation [55][   20/   40]   Loss 0.301556   Top1 90.703125   Top5 99.531250   BatchTime 0.138569   
2022-11-25 11:50:47,020 - INFO  - Validation [55][   40/   40]   Loss 0.288396   Top1 91.080000   Top5 99.720000   BatchTime 0.098204   
2022-11-25 11:50:47,245 - INFO  - ==> Top1: 91.080    Top5: 99.720    Loss: 0.288

2022-11-25 11:50:47,246 - INFO  - ==> Sparsity : 0.376

2022-11-25 11:50:47,246 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 91.080   Top5: 99.720]
2022-11-25 11:50:47,246 - INFO  - Scoreboard best 2 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:50:47,246 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 90.430   Top5: 99.640]
2022-11-25 11:50:52,630 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:50:52,632 - INFO  - >>>>>> Epoch  56
2022-11-25 11:50:52,634 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:51:01,468 - INFO  - Training [56][   20/  196]   Loss 0.321561   Top1 88.496094   Top5 98.476562   BatchTime 0.441555   LR 0.000337   
2022-11-25 11:51:08,907 - INFO  - Training [56][   40/  196]   Loss 0.318746   Top1 88.535156   Top5 98.574219   BatchTime 0.406769   LR 0.000333   
2022-11-25 11:51:16,365 - INFO  - Training [56][   60/  196]   Loss 0.311371   Top1 89.036458   Top5 98.828125   BatchTime 0.395471   LR 0.000328   
2022-11-25 11:51:23,747 - INFO  - Training [56][   80/  196]   Loss 0.306706   Top1 89.287109   Top5 98.950195   BatchTime 0.388884   LR 0.000324   
2022-11-25 11:51:30,976 - INFO  - Training [56][  100/  196]   Loss 0.301265   Top1 89.441406   Top5 98.953125   BatchTime 0.383395   LR 0.000319   
2022-11-25 11:51:38,221 - INFO  - Training [56][  120/  196]   Loss 0.296632   Top1 89.563802   Top5 99.013672   BatchTime 0.379872   LR 0.000315   
2022-11-25 11:51:45,373 - INFO  - Training [56][  140/  196]   Loss 0.295293   Top1 89.598214   Top5 99.045759   BatchTime 0.376686   LR 0.000311   
2022-11-25 11:51:52,970 - INFO  - Training [56][  160/  196]   Loss 0.297714   Top1 89.567871   Top5 99.055176   BatchTime 0.377083   LR 0.000306   
2022-11-25 11:51:59,248 - INFO  - Training [56][  180/  196]   Loss 0.298135   Top1 89.583333   Top5 98.995226   BatchTime 0.370061   LR 0.000302   
2022-11-25 11:52:04,575 - INFO  - ==> Top1: 89.630    Top5: 98.980    Loss: 0.297

2022-11-25 11:52:04,838 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:52:06,408 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:52:08,996 - INFO  - Validation [56][   20/   40]   Loss 0.315003   Top1 90.253906   Top5 99.570312   BatchTime 0.129299   
2022-11-25 11:52:10,050 - INFO  - Validation [56][   40/   40]   Loss 0.294919   Top1 90.800000   Top5 99.710000   BatchTime 0.090995   
2022-11-25 11:52:10,312 - INFO  - ==> Top1: 90.800    Top5: 99.710    Loss: 0.295

2022-11-25 11:52:10,312 - INFO  - ==> Sparsity : 0.378

2022-11-25 11:52:10,312 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 91.080   Top5: 99.720]
2022-11-25 11:52:10,312 - INFO  - Scoreboard best 2 ==> Epoch [56][Top1: 90.800   Top5: 99.710]
2022-11-25 11:52:10,313 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:52:10,670 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:52:10,672 - INFO  - >>>>>> Epoch  57
2022-11-25 11:52:10,673 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:52:19,730 - INFO  - Training [57][   20/  196]   Loss 0.325340   Top1 88.808594   Top5 98.339844   BatchTime 0.452686   LR 0.000294   
2022-11-25 11:52:27,048 - INFO  - Training [57][   40/  196]   Loss 0.307926   Top1 89.570312   Top5 98.593750   BatchTime 0.409285   LR 0.000290   
2022-11-25 11:52:34,453 - INFO  - Training [57][   60/  196]   Loss 0.300689   Top1 89.824219   Top5 98.710938   BatchTime 0.396279   LR 0.000286   
2022-11-25 11:52:41,817 - INFO  - Training [57][   80/  196]   Loss 0.296510   Top1 89.765625   Top5 98.852539   BatchTime 0.389255   LR 0.000282   
2022-11-25 11:52:49,243 - INFO  - Training [57][  100/  196]   Loss 0.290771   Top1 89.914062   Top5 98.910156   BatchTime 0.385663   LR 0.000277   
2022-11-25 11:52:56,481 - INFO  - Training [57][  120/  196]   Loss 0.287171   Top1 90.032552   Top5 98.961589   BatchTime 0.381705   LR 0.000273   
2022-11-25 11:53:03,607 - INFO  - Training [57][  140/  196]   Loss 0.287986   Top1 90.058594   Top5 99.009487   BatchTime 0.378074   LR 0.000269   
2022-11-25 11:53:10,993 - INFO  - Training [57][  160/  196]   Loss 0.289587   Top1 90.039062   Top5 98.972168   BatchTime 0.376980   LR 0.000265   
2022-11-25 11:53:17,369 - INFO  - Training [57][  180/  196]   Loss 0.291689   Top1 89.976128   Top5 98.917101   BatchTime 0.370512   LR 0.000261   
2022-11-25 11:53:22,728 - INFO  - ==> Top1: 90.022    Top5: 98.920    Loss: 0.291

2022-11-25 11:53:23,018 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:53:24,540 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:53:27,141 - INFO  - Validation [57][   20/   40]   Loss 0.308139   Top1 90.351562   Top5 99.550781   BatchTime 0.129975   
2022-11-25 11:53:28,308 - INFO  - Validation [57][   40/   40]   Loss 0.309631   Top1 90.120000   Top5 99.650000   BatchTime 0.094161   
2022-11-25 11:53:28,578 - INFO  - ==> Top1: 90.120    Top5: 99.650    Loss: 0.310

2022-11-25 11:53:28,578 - INFO  - ==> Sparsity : 0.407

2022-11-25 11:53:28,579 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 91.080   Top5: 99.720]
2022-11-25 11:53:28,579 - INFO  - Scoreboard best 2 ==> Epoch [56][Top1: 90.800   Top5: 99.710]
2022-11-25 11:53:28,579 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 90.480   Top5: 99.650]
2022-11-25 11:53:28,718 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:53:28,719 - INFO  - >>>>>> Epoch  58
2022-11-25 11:53:28,721 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:53:37,386 - INFO  - Training [58][   20/  196]   Loss 0.309365   Top1 88.828125   Top5 98.515625   BatchTime 0.433089   LR 0.000254   
2022-11-25 11:53:44,888 - INFO  - Training [58][   40/  196]   Loss 0.307951   Top1 88.876953   Top5 98.652344   BatchTime 0.404109   LR 0.000250   
2022-11-25 11:53:52,224 - INFO  - Training [58][   60/  196]   Loss 0.301898   Top1 89.173177   Top5 98.763021   BatchTime 0.391671   LR 0.000246   
2022-11-25 11:53:59,532 - INFO  - Training [58][   80/  196]   Loss 0.299035   Top1 89.365234   Top5 98.901367   BatchTime 0.385098   LR 0.000242   
2022-11-25 11:54:07,132 - INFO  - Training [58][  100/  196]   Loss 0.294336   Top1 89.578125   Top5 98.933594   BatchTime 0.384075   LR 0.000238   
2022-11-25 11:54:14,466 - INFO  - Training [58][  120/  196]   Loss 0.290246   Top1 89.703776   Top5 98.997396   BatchTime 0.381176   LR 0.000234   
2022-11-25 11:54:21,510 - INFO  - Training [58][  140/  196]   Loss 0.287991   Top1 89.785156   Top5 99.029018   BatchTime 0.377038   LR 0.000230   
2022-11-25 11:54:28,829 - INFO  - Training [58][  160/  196]   Loss 0.290442   Top1 89.768066   Top5 98.989258   BatchTime 0.375654   LR 0.000226   
2022-11-25 11:54:35,285 - INFO  - Training [58][  180/  196]   Loss 0.291189   Top1 89.726562   Top5 98.938802   BatchTime 0.369781   LR 0.000222   
2022-11-25 11:54:39,980 - INFO  - ==> Top1: 89.790    Top5: 98.958    Loss: 0.289

2022-11-25 11:54:40,273 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:54:41,395 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:54:44,708 - INFO  - Validation [58][   20/   40]   Loss 0.292050   Top1 91.074219   Top5 99.609375   BatchTime 0.165531   
2022-11-25 11:54:45,705 - INFO  - Validation [58][   40/   40]   Loss 0.277944   Top1 91.280000   Top5 99.660000   BatchTime 0.107721   
2022-11-25 11:54:45,973 - INFO  - ==> Top1: 91.280    Top5: 99.660    Loss: 0.278

2022-11-25 11:54:45,973 - INFO  - ==> Sparsity : 0.427

2022-11-25 11:54:45,974 - INFO  - Scoreboard best 1 ==> Epoch [58][Top1: 91.280   Top5: 99.660]
2022-11-25 11:54:45,974 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 91.080   Top5: 99.720]
2022-11-25 11:54:45,974 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 90.800   Top5: 99.710]
2022-11-25 11:54:51,438 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:54:51,440 - INFO  - >>>>>> Epoch  59
2022-11-25 11:54:51,442 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:55:00,516 - INFO  - Training [59][   20/  196]   Loss 0.302464   Top1 89.511719   Top5 98.554688   BatchTime 0.453525   LR 0.000215   
2022-11-25 11:55:07,837 - INFO  - Training [59][   40/  196]   Loss 0.301784   Top1 89.628906   Top5 98.593750   BatchTime 0.409803   LR 0.000212   
2022-11-25 11:55:15,278 - INFO  - Training [59][   60/  196]   Loss 0.301642   Top1 89.726562   Top5 98.691406   BatchTime 0.397205   LR 0.000208   
2022-11-25 11:55:22,747 - INFO  - Training [59][   80/  196]   Loss 0.298159   Top1 89.819336   Top5 98.818359   BatchTime 0.391265   LR 0.000204   
2022-11-25 11:55:30,120 - INFO  - Training [59][  100/  196]   Loss 0.291154   Top1 90.015625   Top5 98.878906   BatchTime 0.386742   LR 0.000201   
2022-11-25 11:55:37,230 - INFO  - Training [59][  120/  196]   Loss 0.284680   Top1 90.208333   Top5 98.964844   BatchTime 0.381533   LR 0.000197   
2022-11-25 11:55:44,318 - INFO  - Training [59][  140/  196]   Loss 0.285767   Top1 90.234375   Top5 99.001116   BatchTime 0.377661   LR 0.000193   
2022-11-25 11:55:51,489 - INFO  - Training [59][  160/  196]   Loss 0.289663   Top1 90.065918   Top5 98.986816   BatchTime 0.375268   LR 0.000190   
2022-11-25 11:55:58,322 - INFO  - Training [59][  180/  196]   Loss 0.291688   Top1 90.015191   Top5 98.919271   BatchTime 0.371535   LR 0.000186   
2022-11-25 11:56:02,962 - INFO  - ==> Top1: 89.968    Top5: 98.906    Loss: 0.292

2022-11-25 11:56:03,261 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:56:04,670 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:56:07,687 - INFO  - Validation [59][   20/   40]   Loss 0.380791   Top1 88.300781   Top5 99.375000   BatchTime 0.150775   
2022-11-25 11:56:08,798 - INFO  - Validation [59][   40/   40]   Loss 0.373716   Top1 88.620000   Top5 99.540000   BatchTime 0.103175   
2022-11-25 11:56:09,065 - INFO  - ==> Top1: 88.620    Top5: 99.540    Loss: 0.374

2022-11-25 11:56:09,065 - INFO  - ==> Sparsity : 0.410

2022-11-25 11:56:09,066 - INFO  - Scoreboard best 1 ==> Epoch [58][Top1: 91.280   Top5: 99.660]
2022-11-25 11:56:09,066 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 91.080   Top5: 99.720]
2022-11-25 11:56:09,066 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 90.800   Top5: 99.710]
2022-11-25 11:56:09,426 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:56:09,428 - INFO  - >>>>>> Epoch  60
2022-11-25 11:56:09,430 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:56:18,421 - INFO  - Training [60][   20/  196]   Loss 0.294379   Top1 89.609375   Top5 98.281250   BatchTime 0.449397   LR 0.000180   
2022-11-25 11:56:25,914 - INFO  - Training [60][   40/  196]   Loss 0.310859   Top1 89.296875   Top5 98.408203   BatchTime 0.412018   LR 0.000176   
2022-11-25 11:56:33,577 - INFO  - Training [60][   60/  196]   Loss 0.306068   Top1 89.394531   Top5 98.606771   BatchTime 0.402408   LR 0.000173   
2022-11-25 11:56:40,693 - INFO  - Training [60][   80/  196]   Loss 0.298114   Top1 89.711914   Top5 98.852539   BatchTime 0.390756   LR 0.000169   
2022-11-25 11:56:47,871 - INFO  - Training [60][  100/  196]   Loss 0.293406   Top1 89.898438   Top5 98.906250   BatchTime 0.384382   LR 0.000166   
2022-11-25 11:56:55,059 - INFO  - Training [60][  120/  196]   Loss 0.285248   Top1 90.185547   Top5 98.964844   BatchTime 0.380213   LR 0.000162   
2022-11-25 11:57:02,411 - INFO  - Training [60][  140/  196]   Loss 0.283100   Top1 90.273438   Top5 99.009487   BatchTime 0.378415   LR 0.000159   
2022-11-25 11:57:09,583 - INFO  - Training [60][  160/  196]   Loss 0.286525   Top1 90.114746   Top5 98.996582   BatchTime 0.375937   LR 0.000156   
2022-11-25 11:57:17,131 - INFO  - Training [60][  180/  196]   Loss 0.286147   Top1 90.147569   Top5 98.956163   BatchTime 0.376098   LR 0.000152   
2022-11-25 11:57:21,871 - INFO  - ==> Top1: 90.168    Top5: 98.938    Loss: 0.286

2022-11-25 11:57:22,084 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:57:23,940 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:57:26,650 - INFO  - Validation [60][   20/   40]   Loss 0.291558   Top1 91.230469   Top5 99.628906   BatchTime 0.135400   
2022-11-25 11:57:27,802 - INFO  - Validation [60][   40/   40]   Loss 0.280580   Top1 91.500000   Top5 99.760000   BatchTime 0.096499   
2022-11-25 11:57:28,098 - INFO  - ==> Top1: 91.500    Top5: 99.760    Loss: 0.281

2022-11-25 11:57:28,098 - INFO  - ==> Sparsity : 0.398

2022-11-25 11:57:28,099 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.500   Top5: 99.760]
2022-11-25 11:57:28,099 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 91.280   Top5: 99.660]
2022-11-25 11:57:28,099 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 91.080   Top5: 99.720]
2022-11-25 11:57:34,134 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_best.pth.tar
save quantized models...
2022-11-25 11:57:34,141 - INFO  - >>>>>> Epoch  61
2022-11-25 11:57:34,143 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:57:43,125 - INFO  - Training [61][   20/  196]   Loss 0.284840   Top1 89.804688   Top5 98.457031   BatchTime 0.448960   LR 0.000147   
2022-11-25 11:57:50,434 - INFO  - Training [61][   40/  196]   Loss 0.302066   Top1 89.394531   Top5 98.564453   BatchTime 0.407201   LR 0.000143   
2022-11-25 11:57:57,800 - INFO  - Training [61][   60/  196]   Loss 0.294844   Top1 89.772135   Top5 98.717448   BatchTime 0.394235   LR 0.000140   
2022-11-25 11:58:05,129 - INFO  - Training [61][   80/  196]   Loss 0.293033   Top1 89.936523   Top5 98.828125   BatchTime 0.387281   LR 0.000137   
2022-11-25 11:58:12,199 - INFO  - Training [61][  100/  196]   Loss 0.286403   Top1 90.117188   Top5 98.882812   BatchTime 0.380524   LR 0.000134   
2022-11-25 11:58:19,631 - INFO  - Training [61][  120/  196]   Loss 0.282070   Top1 90.292969   Top5 98.948568   BatchTime 0.379041   LR 0.000131   
2022-11-25 11:58:26,741 - INFO  - Training [61][  140/  196]   Loss 0.284062   Top1 90.276228   Top5 98.978795   BatchTime 0.375677   LR 0.000128   
2022-11-25 11:58:34,127 - INFO  - Training [61][  160/  196]   Loss 0.284514   Top1 90.263672   Top5 98.942871   BatchTime 0.374878   LR 0.000125   
2022-11-25 11:58:42,233 - INFO  - Training [61][  180/  196]   Loss 0.284241   Top1 90.271267   Top5 98.867188   BatchTime 0.378257   LR 0.000122   
2022-11-25 11:58:47,236 - INFO  - ==> Top1: 90.326    Top5: 98.874    Loss: 0.283

2022-11-25 11:58:47,516 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:58:49,709 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:58:52,745 - INFO  - Validation [61][   20/   40]   Loss 0.296369   Top1 91.132812   Top5 99.667969   BatchTime 0.151731   
2022-11-25 11:58:53,846 - INFO  - Validation [61][   40/   40]   Loss 0.283709   Top1 91.280000   Top5 99.780000   BatchTime 0.103394   
2022-11-25 11:58:54,112 - INFO  - ==> Top1: 91.280    Top5: 99.780    Loss: 0.284

2022-11-25 11:58:54,113 - INFO  - ==> Sparsity : 0.397

2022-11-25 11:58:54,113 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.500   Top5: 99.760]
2022-11-25 11:58:54,113 - INFO  - Scoreboard best 2 ==> Epoch [61][Top1: 91.280   Top5: 99.780]
2022-11-25 11:58:54,114 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 91.280   Top5: 99.660]
2022-11-25 11:58:54,271 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 11:58:54,273 - INFO  - >>>>>> Epoch  62
2022-11-25 11:58:54,275 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:59:03,585 - INFO  - Training [62][   20/  196]   Loss 0.298284   Top1 89.609375   Top5 98.554688   BatchTime 0.465341   LR 0.000117   
2022-11-25 11:59:10,880 - INFO  - Training [62][   40/  196]   Loss 0.298298   Top1 89.580078   Top5 98.701172   BatchTime 0.415069   LR 0.000114   
2022-11-25 11:59:18,150 - INFO  - Training [62][   60/  196]   Loss 0.290873   Top1 89.895833   Top5 98.821615   BatchTime 0.397881   LR 0.000111   
2022-11-25 11:59:25,578 - INFO  - Training [62][   80/  196]   Loss 0.288105   Top1 89.975586   Top5 98.979492   BatchTime 0.391254   LR 0.000108   
2022-11-25 11:59:32,828 - INFO  - Training [62][  100/  196]   Loss 0.280588   Top1 90.234375   Top5 99.027344   BatchTime 0.385504   LR 0.000105   
2022-11-25 11:59:40,249 - INFO  - Training [62][  120/  196]   Loss 0.277021   Top1 90.416667   Top5 99.065755   BatchTime 0.383090   LR 0.000102   
2022-11-25 11:59:47,561 - INFO  - Training [62][  140/  196]   Loss 0.275724   Top1 90.532924   Top5 99.098772   BatchTime 0.380592   LR 0.000100   
2022-11-25 11:59:54,898 - INFO  - Training [62][  160/  196]   Loss 0.277692   Top1 90.437012   Top5 99.084473   BatchTime 0.378872   LR 0.000097   
2022-11-25 12:00:02,197 - INFO  - Training [62][  180/  196]   Loss 0.277535   Top1 90.427517   Top5 99.012587   BatchTime 0.377330   LR 0.000094   
2022-11-25 12:00:07,241 - INFO  - ==> Top1: 90.464    Top5: 99.008    Loss: 0.276

2022-11-25 12:00:07,469 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:00:09,014 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:00:12,994 - INFO  - Validation [62][   20/   40]   Loss 1.169516   Top1 67.460938   Top5 96.054688   BatchTime 0.198886   
2022-11-25 12:00:14,101 - INFO  - Validation [62][   40/   40]   Loss 1.150657   Top1 67.500000   Top5 96.430000   BatchTime 0.127141   
2022-11-25 12:00:14,407 - INFO  - ==> Top1: 67.500    Top5: 96.430    Loss: 1.151

2022-11-25 12:00:14,407 - INFO  - ==> Sparsity : 0.406

2022-11-25 12:00:14,408 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.500   Top5: 99.760]
2022-11-25 12:00:14,408 - INFO  - Scoreboard best 2 ==> Epoch [61][Top1: 91.280   Top5: 99.780]
2022-11-25 12:00:14,408 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 91.280   Top5: 99.660]
2022-11-25 12:00:14,551 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 12:00:14,553 - INFO  - >>>>>> Epoch  63
2022-11-25 12:00:14,555 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:00:24,077 - INFO  - Training [63][   20/  196]   Loss 0.301117   Top1 89.433594   Top5 98.242188   BatchTime 0.475964   LR 0.000090   
2022-11-25 12:00:31,195 - INFO  - Training [63][   40/  196]   Loss 0.301221   Top1 89.404297   Top5 98.417969   BatchTime 0.415952   LR 0.000087   
2022-11-25 12:00:38,438 - INFO  - Training [63][   60/  196]   Loss 0.294820   Top1 89.641927   Top5 98.645833   BatchTime 0.398004   LR 0.000085   
2022-11-25 12:00:45,603 - INFO  - Training [63][   80/  196]   Loss 0.290892   Top1 89.809570   Top5 98.823242   BatchTime 0.388072   LR 0.000082   
2022-11-25 12:00:52,980 - INFO  - Training [63][  100/  196]   Loss 0.284325   Top1 90.042969   Top5 98.878906   BatchTime 0.384226   LR 0.000080   
2022-11-25 12:01:00,299 - INFO  - Training [63][  120/  196]   Loss 0.276433   Top1 90.361328   Top5 98.961589   BatchTime 0.381177   LR 0.000077   
2022-11-25 12:01:07,515 - INFO  - Training [63][  140/  196]   Loss 0.274788   Top1 90.379464   Top5 99.009487   BatchTime 0.378270   LR 0.000075   
2022-11-25 12:01:14,757 - INFO  - Training [63][  160/  196]   Loss 0.278146   Top1 90.244141   Top5 98.994141   BatchTime 0.376244   LR 0.000072   
2022-11-25 12:01:21,984 - INFO  - Training [63][  180/  196]   Loss 0.279963   Top1 90.162760   Top5 98.921441   BatchTime 0.374588   LR 0.000070   
2022-11-25 12:01:28,037 - INFO  - ==> Top1: 90.192    Top5: 98.922    Loss: 0.280

2022-11-25 12:01:28,277 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:01:29,701 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:01:33,587 - INFO  - Validation [63][   20/   40]   Loss 0.310123   Top1 90.390625   Top5 99.472656   BatchTime 0.194173   
2022-11-25 12:01:34,946 - INFO  - Validation [63][   40/   40]   Loss 0.310589   Top1 90.400000   Top5 99.620000   BatchTime 0.131066   
2022-11-25 12:01:35,500 - INFO  - ==> Top1: 90.400    Top5: 99.620    Loss: 0.311

2022-11-25 12:01:35,501 - INFO  - ==> Sparsity : 0.415

2022-11-25 12:01:35,501 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.500   Top5: 99.760]
2022-11-25 12:01:35,501 - INFO  - Scoreboard best 2 ==> Epoch [61][Top1: 91.280   Top5: 99.780]
2022-11-25 12:01:35,501 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 91.280   Top5: 99.660]
2022-11-25 12:01:35,647 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 12:01:35,648 - INFO  - >>>>>> Epoch  64
2022-11-25 12:01:35,650 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:01:44,226 - INFO  - Training [64][   20/  196]   Loss 0.290699   Top1 89.550781   Top5 98.378906   BatchTime 0.428646   LR 0.000066   
2022-11-25 12:01:51,350 - INFO  - Training [64][   40/  196]   Loss 0.291675   Top1 89.541016   Top5 98.593750   BatchTime 0.392423   LR 0.000064   
2022-11-25 12:01:58,674 - INFO  - Training [64][   60/  196]   Loss 0.290992   Top1 89.622396   Top5 98.671875   BatchTime 0.383682   LR 0.000062   
2022-11-25 12:02:05,773 - INFO  - Training [64][   80/  196]   Loss 0.287825   Top1 89.824219   Top5 98.837891   BatchTime 0.376498   LR 0.000059   
2022-11-25 12:02:13,091 - INFO  - Training [64][  100/  196]   Loss 0.280045   Top1 90.125000   Top5 98.910156   BatchTime 0.374378   LR 0.000057   
2022-11-25 12:02:20,341 - INFO  - Training [64][  120/  196]   Loss 0.276864   Top1 90.263672   Top5 98.974609   BatchTime 0.372396   LR 0.000055   
2022-11-25 12:02:27,531 - INFO  - Training [64][  140/  196]   Loss 0.274456   Top1 90.357143   Top5 99.029018   BatchTime 0.370555   LR 0.000053   
2022-11-25 12:02:35,176 - INFO  - Training [64][  160/  196]   Loss 0.275937   Top1 90.310059   Top5 99.045410   BatchTime 0.372012   LR 0.000051   
2022-11-25 12:02:42,601 - INFO  - Training [64][  180/  196]   Loss 0.275981   Top1 90.319010   Top5 98.999566   BatchTime 0.371932   LR 0.000049   
2022-11-25 12:02:48,419 - INFO  - ==> Top1: 90.372    Top5: 99.012    Loss: 0.274

2022-11-25 12:02:48,685 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:02:49,922 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:02:52,699 - INFO  - Validation [64][   20/   40]   Loss 0.333263   Top1 89.765625   Top5 99.570312   BatchTime 0.138728   
2022-11-25 12:02:54,655 - INFO  - Validation [64][   40/   40]   Loss 0.336191   Top1 89.700000   Top5 99.620000   BatchTime 0.118269   
2022-11-25 12:02:55,036 - INFO  - ==> Top1: 89.700    Top5: 99.620    Loss: 0.336

2022-11-25 12:02:55,036 - INFO  - ==> Sparsity : 0.418

2022-11-25 12:02:55,036 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.500   Top5: 99.760]
2022-11-25 12:02:55,037 - INFO  - Scoreboard best 2 ==> Epoch [61][Top1: 91.280   Top5: 99.780]
2022-11-25 12:02:55,037 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 91.280   Top5: 99.660]
2022-11-25 12:02:55,460 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 12:02:55,463 - INFO  - >>>>>> Epoch  65
2022-11-25 12:02:55,466 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:03:04,257 - INFO  - Training [65][   20/  196]   Loss 0.292446   Top1 90.273438   Top5 98.203125   BatchTime 0.439345   LR 0.000046   
2022-11-25 12:03:11,569 - INFO  - Training [65][   40/  196]   Loss 0.278789   Top1 90.468750   Top5 98.613281   BatchTime 0.402473   LR 0.000044   
2022-11-25 12:03:18,755 - INFO  - Training [65][   60/  196]   Loss 0.280846   Top1 90.436198   Top5 98.678385   BatchTime 0.388084   LR 0.000042   
2022-11-25 12:03:26,002 - INFO  - Training [65][   80/  196]   Loss 0.277214   Top1 90.590820   Top5 98.842773   BatchTime 0.381650   LR 0.000040   
2022-11-25 12:03:33,345 - INFO  - Training [65][  100/  196]   Loss 0.271268   Top1 90.730469   Top5 98.914062   BatchTime 0.378752   LR 0.000039   
2022-11-25 12:03:40,605 - INFO  - Training [65][  120/  196]   Loss 0.270602   Top1 90.742188   Top5 98.958333   BatchTime 0.376120   LR 0.000037   
2022-11-25 12:03:47,704 - INFO  - Training [65][  140/  196]   Loss 0.267917   Top1 90.831473   Top5 99.020647   BatchTime 0.373100   LR 0.000035   
2022-11-25 12:03:55,364 - INFO  - Training [65][  160/  196]   Loss 0.271440   Top1 90.717773   Top5 99.028320   BatchTime 0.374334   LR 0.000033   
2022-11-25 12:04:02,830 - INFO  - Training [65][  180/  196]   Loss 0.271253   Top1 90.670573   Top5 98.995226   BatchTime 0.374219   LR 0.000032   
2022-11-25 12:04:08,494 - INFO  - ==> Top1: 90.610    Top5: 98.986    Loss: 0.272

2022-11-25 12:04:08,777 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:04:10,050 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:04:13,018 - INFO  - Validation [65][   20/   40]   Loss 0.342043   Top1 90.097656   Top5 99.414062   BatchTime 0.148277   
2022-11-25 12:04:14,575 - INFO  - Validation [65][   40/   40]   Loss 0.337883   Top1 90.020000   Top5 99.580000   BatchTime 0.113078   
2022-11-25 12:04:15,135 - INFO  - ==> Top1: 90.020    Top5: 99.580    Loss: 0.338

2022-11-25 12:04:15,136 - INFO  - ==> Sparsity : 0.418

2022-11-25 12:04:15,136 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.500   Top5: 99.760]
2022-11-25 12:04:15,136 - INFO  - Scoreboard best 2 ==> Epoch [61][Top1: 91.280   Top5: 99.780]
2022-11-25 12:04:15,137 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 91.280   Top5: 99.660]
2022-11-25 12:04:15,278 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 12:04:15,280 - INFO  - >>>>>> Epoch  66
2022-11-25 12:04:15,282 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:04:24,085 - INFO  - Training [66][   20/  196]   Loss 0.295948   Top1 89.609375   Top5 98.593750   BatchTime 0.440020   LR 0.000029   
2022-11-25 12:04:31,213 - INFO  - Training [66][   40/  196]   Loss 0.296432   Top1 89.335938   Top5 98.691406   BatchTime 0.398215   LR 0.000028   
2022-11-25 12:04:38,559 - INFO  - Training [66][   60/  196]   Loss 0.296150   Top1 89.459635   Top5 98.834635   BatchTime 0.387915   LR 0.000026   
2022-11-25 12:04:45,962 - INFO  - Training [66][   80/  196]   Loss 0.288072   Top1 89.721680   Top5 99.003906   BatchTime 0.383475   LR 0.000025   
2022-11-25 12:04:53,100 - INFO  - Training [66][  100/  196]   Loss 0.285841   Top1 89.878906   Top5 99.015625   BatchTime 0.378160   LR 0.000023   
2022-11-25 12:05:00,289 - INFO  - Training [66][  120/  196]   Loss 0.277491   Top1 90.185547   Top5 99.082031   BatchTime 0.375037   LR 0.000022   
2022-11-25 12:05:07,598 - INFO  - Training [66][  140/  196]   Loss 0.275294   Top1 90.309710   Top5 99.109933   BatchTime 0.373671   LR 0.000021   
2022-11-25 12:05:15,455 - INFO  - Training [66][  160/  196]   Loss 0.276605   Top1 90.266113   Top5 99.108887   BatchTime 0.376067   LR 0.000019   
2022-11-25 12:05:22,936 - INFO  - Training [66][  180/  196]   Loss 0.277456   Top1 90.249566   Top5 99.053819   BatchTime 0.375838   LR 0.000018   
2022-11-25 12:05:28,631 - INFO  - ==> Top1: 90.314    Top5: 99.046    Loss: 0.276

2022-11-25 12:05:28,905 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:05:30,351 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:05:33,266 - INFO  - Validation [66][   20/   40]   Loss 0.319129   Top1 90.097656   Top5 99.550781   BatchTime 0.145571   
2022-11-25 12:05:34,458 - INFO  - Validation [66][   40/   40]   Loss 0.317744   Top1 90.130000   Top5 99.640000   BatchTime 0.102603   
2022-11-25 12:05:34,821 - INFO  - ==> Top1: 90.130    Top5: 99.640    Loss: 0.318

2022-11-25 12:05:34,821 - INFO  - ==> Sparsity : 0.425

2022-11-25 12:05:34,822 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.500   Top5: 99.760]
2022-11-25 12:05:34,822 - INFO  - Scoreboard best 2 ==> Epoch [61][Top1: 91.280   Top5: 99.780]
2022-11-25 12:05:34,822 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 91.280   Top5: 99.660]
2022-11-25 12:05:35,170 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 12:05:35,171 - INFO  - >>>>>> Epoch  67
2022-11-25 12:05:35,173 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:05:43,393 - INFO  - Training [67][   20/  196]   Loss 0.299862   Top1 89.628906   Top5 98.535156   BatchTime 0.410861   LR 0.000016   
2022-11-25 12:05:50,667 - INFO  - Training [67][   40/  196]   Loss 0.294204   Top1 89.892578   Top5 98.681641   BatchTime 0.387272   LR 0.000015   
2022-11-25 12:05:57,863 - INFO  - Training [67][   60/  196]   Loss 0.290756   Top1 89.973958   Top5 98.743490   BatchTime 0.378111   LR 0.000014   
2022-11-25 12:06:04,881 - INFO  - Training [67][   80/  196]   Loss 0.283535   Top1 90.205078   Top5 98.906250   BatchTime 0.371308   LR 0.000013   
2022-11-25 12:06:12,183 - INFO  - Training [67][  100/  196]   Loss 0.277419   Top1 90.371094   Top5 98.917969   BatchTime 0.370069   LR 0.000012   
2022-11-25 12:06:19,513 - INFO  - Training [67][  120/  196]   Loss 0.272983   Top1 90.511068   Top5 98.974609   BatchTime 0.369473   LR 0.000011   
2022-11-25 12:06:26,880 - INFO  - Training [67][  140/  196]   Loss 0.270540   Top1 90.658482   Top5 99.040179   BatchTime 0.369309   LR 0.000010   
2022-11-25 12:06:34,388 - INFO  - Training [67][  160/  196]   Loss 0.272483   Top1 90.627441   Top5 99.050293   BatchTime 0.370073   LR 0.000009   
2022-11-25 12:06:42,018 - INFO  - Training [67][  180/  196]   Loss 0.273959   Top1 90.577257   Top5 98.999566   BatchTime 0.371341   LR 0.000008   
2022-11-25 12:06:48,119 - INFO  - ==> Top1: 90.642    Top5: 99.002    Loss: 0.273

2022-11-25 12:06:48,362 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:06:49,809 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:06:52,387 - INFO  - Validation [67][   20/   40]   Loss 0.296358   Top1 90.917969   Top5 99.609375   BatchTime 0.128831   
2022-11-25 12:06:53,485 - INFO  - Validation [67][   40/   40]   Loss 0.284815   Top1 91.380000   Top5 99.710000   BatchTime 0.091861   
2022-11-25 12:06:53,755 - INFO  - ==> Top1: 91.380    Top5: 99.710    Loss: 0.285

2022-11-25 12:06:53,755 - INFO  - ==> Sparsity : 0.428

2022-11-25 12:06:53,755 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.500   Top5: 99.760]
2022-11-25 12:06:53,755 - INFO  - Scoreboard best 2 ==> Epoch [67][Top1: 91.380   Top5: 99.710]
2022-11-25 12:06:53,756 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 91.280   Top5: 99.780]
2022-11-25 12:06:53,877 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 12:06:53,879 - INFO  - >>>>>> Epoch  68
2022-11-25 12:06:53,880 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:07:01,683 - INFO  - Training [68][   20/  196]   Loss 0.287315   Top1 89.941406   Top5 98.300781   BatchTime 0.390002   LR 0.000007   
2022-11-25 12:07:08,732 - INFO  - Training [68][   40/  196]   Loss 0.279487   Top1 90.273438   Top5 98.564453   BatchTime 0.371215   LR 0.000006   
2022-11-25 12:07:15,902 - INFO  - Training [68][   60/  196]   Loss 0.279267   Top1 90.488281   Top5 98.632812   BatchTime 0.366976   LR 0.000006   
2022-11-25 12:07:23,147 - INFO  - Training [68][   80/  196]   Loss 0.278309   Top1 90.561523   Top5 98.754883   BatchTime 0.365798   LR 0.000005   
2022-11-25 12:07:30,275 - INFO  - Training [68][  100/  196]   Loss 0.272501   Top1 90.691406   Top5 98.804688   BatchTime 0.363920   LR 0.000004   
2022-11-25 12:07:37,468 - INFO  - Training [68][  120/  196]   Loss 0.270447   Top1 90.810547   Top5 98.870443   BatchTime 0.363208   LR 0.000004   
2022-11-25 12:07:44,823 - INFO  - Training [68][  140/  196]   Loss 0.269054   Top1 90.848214   Top5 98.942522   BatchTime 0.363856   LR 0.000003   
2022-11-25 12:07:52,403 - INFO  - Training [68][  160/  196]   Loss 0.272626   Top1 90.683594   Top5 98.930664   BatchTime 0.365747   LR 0.000003   
2022-11-25 12:08:00,449 - INFO  - Training [68][  180/  196]   Loss 0.272916   Top1 90.648872   Top5 98.895399   BatchTime 0.369810   LR 0.000002   
2022-11-25 12:08:06,319 - INFO  - ==> Top1: 90.668    Top5: 98.904    Loss: 0.272

2022-11-25 12:08:06,567 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:08:08,257 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:08:10,817 - INFO  - Validation [68][   20/   40]   Loss 0.303033   Top1 90.976562   Top5 99.609375   BatchTime 0.127898   
2022-11-25 12:08:11,934 - INFO  - Validation [68][   40/   40]   Loss 0.289669   Top1 91.280000   Top5 99.740000   BatchTime 0.091883   
2022-11-25 12:08:12,167 - INFO  - ==> Top1: 91.280    Top5: 99.740    Loss: 0.290

2022-11-25 12:08:12,167 - INFO  - ==> Sparsity : 0.429

2022-11-25 12:08:12,168 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.500   Top5: 99.760]
2022-11-25 12:08:12,168 - INFO  - Scoreboard best 2 ==> Epoch [67][Top1: 91.380   Top5: 99.710]
2022-11-25 12:08:12,168 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 91.280   Top5: 99.780]
2022-11-25 12:08:12,297 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 12:08:12,299 - INFO  - >>>>>> Epoch  69
2022-11-25 12:08:12,301 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:08:19,745 - INFO  - Training [69][   20/  196]   Loss 0.288990   Top1 89.863281   Top5 98.750000   BatchTime 0.372102   LR 0.000002   
2022-11-25 12:08:26,864 - INFO  - Training [69][   40/  196]   Loss 0.293953   Top1 89.736328   Top5 98.808594   BatchTime 0.364016   LR 0.000001   
2022-11-25 12:08:34,376 - INFO  - Training [69][   60/  196]   Loss 0.296309   Top1 89.687500   Top5 98.873698   BatchTime 0.367878   LR 0.000001   
2022-11-25 12:08:41,771 - INFO  - Training [69][   80/  196]   Loss 0.294026   Top1 89.770508   Top5 98.930664   BatchTime 0.368344   LR 0.000001   
2022-11-25 12:08:49,041 - INFO  - Training [69][  100/  196]   Loss 0.284325   Top1 90.109375   Top5 98.960938   BatchTime 0.367373   LR 0.000000   
2022-11-25 12:08:56,407 - INFO  - Training [69][  120/  196]   Loss 0.280290   Top1 90.341797   Top5 99.016927   BatchTime 0.367530   LR 0.000000   
2022-11-25 12:09:03,672 - INFO  - Training [69][  140/  196]   Loss 0.278130   Top1 90.362723   Top5 99.040179   BatchTime 0.366918   LR 0.000000   
2022-11-25 12:09:11,196 - INFO  - Training [69][  160/  196]   Loss 0.281549   Top1 90.234375   Top5 99.008789   BatchTime 0.368074   LR 0.000000   
2022-11-25 12:09:18,581 - INFO  - Training [69][  180/  196]   Loss 0.282780   Top1 90.188802   Top5 98.971354   BatchTime 0.368206   LR 0.000000   
2022-11-25 12:09:24,445 - INFO  - ==> Top1: 90.192    Top5: 98.980    Loss: 0.282

2022-11-25 12:09:24,675 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:09:26,078 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:09:28,578 - INFO  - Validation [69][   20/   40]   Loss 0.331882   Top1 89.824219   Top5 99.453125   BatchTime 0.124894   
2022-11-25 12:09:29,644 - INFO  - Validation [69][   40/   40]   Loss 0.332634   Top1 89.870000   Top5 99.600000   BatchTime 0.089092   
2022-11-25 12:09:29,921 - INFO  - ==> Top1: 89.870    Top5: 99.600    Loss: 0.333

2022-11-25 12:09:29,921 - INFO  - ==> Sparsity : 0.429

2022-11-25 12:09:29,922 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 91.500   Top5: 99.760]
2022-11-25 12:09:29,922 - INFO  - Scoreboard best 2 ==> Epoch [67][Top1: 91.380   Top5: 99.710]
2022-11-25 12:09:29,922 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 91.280   Top5: 99.780]
2022-11-25 12:09:30,086 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/_checkpoint.pth.tar

2022-11-25 12:09:30,088 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 12:09:30,088 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:09:32,837 - INFO  - Validation [   20/   40]   Loss 0.331882   Top1 89.824219   Top5 99.453125   BatchTime 0.137348   
2022-11-25 12:09:33,992 - INFO  - Validation [   40/   40]   Loss 0.332634   Top1 89.870000   Top5 99.600000   BatchTime 0.097573   
2022-11-25 12:09:34,152 - INFO  - ==> Top1: 89.870    Top5: 99.600    Loss: 0.333

2022-11-25 12:09:34,153 - INFO  - ==> Sparsity : 0.000

2022-11-25 12:09:34,153 - INFO  - Program completed sucessfully ... exiting ...
2022-11-25 12:09:34,174 - INFO  - >>>>>> Epoch   0
2022-11-25 12:09:34,176 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:09:41,142 - INFO  - Training [0][   20/  196]   Loss 0.553685   Top1 81.035156   Top5 97.480469   BatchTime 0.348189   LR 0.004999   
2022-11-25 12:09:47,880 - INFO  - Training [0][   40/  196]   Loss 0.545831   Top1 81.093750   Top5 97.695312   BatchTime 0.342538   LR 0.004995   
2022-11-25 12:09:54,631 - INFO  - Training [0][   60/  196]   Loss 0.534478   Top1 81.412760   Top5 97.871094   BatchTime 0.340876   LR 0.004989   
2022-11-25 12:10:01,483 - INFO  - Training [0][   80/  196]   Loss 0.526307   Top1 81.782227   Top5 97.963867   BatchTime 0.341312   LR 0.004980   
2022-11-25 12:10:08,454 - INFO  - Training [0][  100/  196]   Loss 0.515178   Top1 82.042969   Top5 98.089844   BatchTime 0.342757   LR 0.004968   
2022-11-25 12:10:15,383 - INFO  - Training [0][  120/  196]   Loss 0.509037   Top1 82.236328   Top5 98.177083   BatchTime 0.343368   LR 0.004954   
2022-11-25 12:10:22,134 - INFO  - Training [0][  140/  196]   Loss 0.510495   Top1 82.290737   Top5 98.189174   BatchTime 0.342533   LR 0.004938   
2022-11-25 12:10:28,922 - INFO  - Training [0][  160/  196]   Loss 0.514425   Top1 82.182617   Top5 98.132324   BatchTime 0.342142   LR 0.004919   
2022-11-25 12:10:36,266 - INFO  - Training [0][  180/  196]   Loss 0.514558   Top1 82.222222   Top5 98.109809   BatchTime 0.344930   LR 0.004897   
2022-11-25 12:10:41,689 - INFO  - ==> Top1: 82.212    Top5: 98.126    Loss: 0.515

2022-11-25 12:10:41,950 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:10:43,474 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:10:46,074 - INFO  - Validation [0][   20/   40]   Loss 0.456011   Top1 85.097656   Top5 99.179688   BatchTime 0.129922   
2022-11-25 12:10:47,163 - INFO  - Validation [0][   40/   40]   Loss 0.448178   Top1 85.080000   Top5 99.300000   BatchTime 0.092192   
2022-11-25 12:10:47,452 - INFO  - ==> Top1: 85.080    Top5: 99.300    Loss: 0.448

2022-11-25 12:10:47,452 - INFO  - ==> Sparsity : 0.487

2022-11-25 12:10:47,452 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 85.080   Top5: 99.300]
2022-11-25 12:10:53,095 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:10:53,097 - INFO  - >>>>>> Epoch   1
2022-11-25 12:10:53,099 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:11:01,172 - INFO  - Training [1][   20/  196]   Loss 0.523037   Top1 81.855469   Top5 97.675781   BatchTime 0.403531   LR 0.004853   
2022-11-25 12:11:07,800 - INFO  - Training [1][   40/  196]   Loss 0.526947   Top1 82.041016   Top5 97.910156   BatchTime 0.367446   LR 0.004825   
2022-11-25 12:11:14,334 - INFO  - Training [1][   60/  196]   Loss 0.529521   Top1 81.842448   Top5 98.033854   BatchTime 0.353872   LR 0.004794   
2022-11-25 12:11:21,393 - INFO  - Training [1][   80/  196]   Loss 0.528598   Top1 81.914062   Top5 98.105469   BatchTime 0.353637   LR 0.004761   
2022-11-25 12:11:28,195 - INFO  - Training [1][  100/  196]   Loss 0.525088   Top1 82.050781   Top5 98.140625   BatchTime 0.350926   LR 0.004725   
2022-11-25 12:11:35,023 - INFO  - Training [1][  120/  196]   Loss 0.520186   Top1 82.141927   Top5 98.225911   BatchTime 0.349337   LR 0.004687   
2022-11-25 12:11:41,763 - INFO  - Training [1][  140/  196]   Loss 0.518188   Top1 82.193080   Top5 98.270089   BatchTime 0.347579   LR 0.004647   
2022-11-25 12:11:48,534 - INFO  - Training [1][  160/  196]   Loss 0.520242   Top1 82.155762   Top5 98.259277   BatchTime 0.346448   LR 0.004605   
2022-11-25 12:11:55,559 - INFO  - Training [1][  180/  196]   Loss 0.519092   Top1 82.187500   Top5 98.209635   BatchTime 0.346979   LR 0.004560   
2022-11-25 12:12:01,042 - INFO  - ==> Top1: 82.162    Top5: 98.204    Loss: 0.519

2022-11-25 12:12:01,296 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:12:02,604 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:12:05,106 - INFO  - Validation [1][   20/   40]   Loss 0.499055   Top1 83.867188   Top5 99.082031   BatchTime 0.125021   
2022-11-25 12:12:06,212 - INFO  - Validation [1][   40/   40]   Loss 0.506704   Top1 83.560000   Top5 99.150000   BatchTime 0.090157   
2022-11-25 12:12:06,447 - INFO  - ==> Top1: 83.560    Top5: 99.150    Loss: 0.507

2022-11-25 12:12:06,447 - INFO  - ==> Sparsity : 0.509

2022-11-25 12:12:06,448 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 85.080   Top5: 99.300]
2022-11-25 12:12:06,448 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 83.560   Top5: 99.150]
2022-11-25 12:12:06,815 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:12:06,816 - INFO  - >>>>>> Epoch   2
2022-11-25 12:12:06,818 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:12:14,003 - INFO  - Training [2][   20/  196]   Loss 0.530772   Top1 81.660156   Top5 97.558594   BatchTime 0.359103   LR 0.004477   
2022-11-25 12:12:20,274 - INFO  - Training [2][   40/  196]   Loss 0.536683   Top1 81.435547   Top5 97.705078   BatchTime 0.336316   LR 0.004426   
2022-11-25 12:12:27,099 - INFO  - Training [2][   60/  196]   Loss 0.528316   Top1 81.718750   Top5 97.792969   BatchTime 0.337956   LR 0.004374   
2022-11-25 12:12:33,642 - INFO  - Training [2][   80/  196]   Loss 0.518833   Top1 82.031250   Top5 97.915039   BatchTime 0.335263   LR 0.004320   
2022-11-25 12:12:40,241 - INFO  - Training [2][  100/  196]   Loss 0.510877   Top1 82.316406   Top5 97.996094   BatchTime 0.334193   LR 0.004264   
2022-11-25 12:12:47,326 - INFO  - Training [2][  120/  196]   Loss 0.507994   Top1 82.386068   Top5 98.082682   BatchTime 0.337540   LR 0.004206   
2022-11-25 12:12:53,988 - INFO  - Training [2][  140/  196]   Loss 0.507448   Top1 82.441406   Top5 98.127790   BatchTime 0.336905   LR 0.004146   
2022-11-25 12:13:00,707 - INFO  - Training [2][  160/  196]   Loss 0.509630   Top1 82.380371   Top5 98.103027   BatchTime 0.336783   LR 0.004085   
2022-11-25 12:13:07,666 - INFO  - Training [2][  180/  196]   Loss 0.508300   Top1 82.402344   Top5 98.083767   BatchTime 0.338024   LR 0.004022   
2022-11-25 12:13:13,460 - INFO  - ==> Top1: 82.520    Top5: 98.128    Loss: 0.505

2022-11-25 12:13:13,730 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:13:15,139 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:13:17,681 - INFO  - Validation [2][   20/   40]   Loss 0.503066   Top1 84.511719   Top5 99.316406   BatchTime 0.126987   
2022-11-25 12:13:18,827 - INFO  - Validation [2][   40/   40]   Loss 0.510246   Top1 84.140000   Top5 99.310000   BatchTime 0.092153   
2022-11-25 12:13:19,043 - INFO  - ==> Top1: 84.140    Top5: 99.310    Loss: 0.510

2022-11-25 12:13:19,044 - INFO  - ==> Sparsity : 0.524

2022-11-25 12:13:19,044 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 85.080   Top5: 99.300]
2022-11-25 12:13:19,044 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 84.140   Top5: 99.310]
2022-11-25 12:13:19,044 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 83.560   Top5: 99.150]
2022-11-25 12:13:19,183 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:13:19,185 - INFO  - >>>>>> Epoch   3
2022-11-25 12:13:19,187 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:13:27,311 - INFO  - Training [3][   20/  196]   Loss 0.532209   Top1 81.308594   Top5 97.871094   BatchTime 0.406073   LR 0.003907   
2022-11-25 12:13:32,796 - INFO  - Training [3][   40/  196]   Loss 0.516122   Top1 82.148438   Top5 97.998047   BatchTime 0.340154   LR 0.003840   
2022-11-25 12:13:38,947 - INFO  - Training [3][   60/  196]   Loss 0.507735   Top1 82.480469   Top5 98.111979   BatchTime 0.329292   LR 0.003771   
2022-11-25 12:13:45,929 - INFO  - Training [3][   80/  196]   Loss 0.503746   Top1 82.744141   Top5 98.300781   BatchTime 0.334238   LR 0.003701   
2022-11-25 12:13:52,733 - INFO  - Training [3][  100/  196]   Loss 0.496669   Top1 82.976562   Top5 98.281250   BatchTime 0.335439   LR 0.003630   
2022-11-25 12:13:59,525 - INFO  - Training [3][  120/  196]   Loss 0.488545   Top1 83.304036   Top5 98.352865   BatchTime 0.336126   LR 0.003558   
2022-11-25 12:14:06,224 - INFO  - Training [3][  140/  196]   Loss 0.484601   Top1 83.470982   Top5 98.406808   BatchTime 0.335957   LR 0.003484   
2022-11-25 12:14:12,544 - INFO  - Training [3][  160/  196]   Loss 0.486732   Top1 83.344727   Top5 98.400879   BatchTime 0.333461   LR 0.003410   
2022-11-25 12:14:19,304 - INFO  - Training [3][  180/  196]   Loss 0.481988   Top1 83.424479   Top5 98.324653   BatchTime 0.333966   LR 0.003335   
2022-11-25 12:14:24,677 - INFO  - ==> Top1: 83.534    Top5: 98.350    Loss: 0.478

2022-11-25 12:14:25,033 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:14:28,118 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:14:30,866 - INFO  - Validation [3][   20/   40]   Loss 0.421142   Top1 86.484375   Top5 99.375000   BatchTime 0.137279   
2022-11-25 12:14:32,012 - INFO  - Validation [3][   40/   40]   Loss 0.417999   Top1 86.410000   Top5 99.430000   BatchTime 0.097286   
2022-11-25 12:14:32,248 - INFO  - ==> Top1: 86.410    Top5: 99.430    Loss: 0.418

2022-11-25 12:14:32,248 - INFO  - ==> Sparsity : 0.531

2022-11-25 12:14:32,249 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 86.410   Top5: 99.430]
2022-11-25 12:14:32,249 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 85.080   Top5: 99.300]
2022-11-25 12:14:32,249 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 84.140   Top5: 99.310]
2022-11-25 12:14:37,423 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:14:37,427 - INFO  - >>>>>> Epoch   4
2022-11-25 12:14:37,430 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:14:45,154 - INFO  - Training [4][   20/  196]   Loss 0.467086   Top1 84.355469   Top5 97.734375   BatchTime 0.386073   LR 0.003200   
2022-11-25 12:14:50,607 - INFO  - Training [4][   40/  196]   Loss 0.462195   Top1 84.238281   Top5 98.154297   BatchTime 0.329378   LR 0.003122   
2022-11-25 12:14:57,103 - INFO  - Training [4][   60/  196]   Loss 0.457657   Top1 84.212240   Top5 98.229167   BatchTime 0.327842   LR 0.003044   
2022-11-25 12:15:04,020 - INFO  - Training [4][   80/  196]   Loss 0.451696   Top1 84.311523   Top5 98.378906   BatchTime 0.332347   LR 0.002965   
2022-11-25 12:15:10,862 - INFO  - Training [4][  100/  196]   Loss 0.447569   Top1 84.527344   Top5 98.375000   BatchTime 0.334299   LR 0.002886   
2022-11-25 12:15:17,913 - INFO  - Training [4][  120/  196]   Loss 0.444704   Top1 84.570312   Top5 98.476562   BatchTime 0.337335   LR 0.002806   
2022-11-25 12:15:24,635 - INFO  - Training [4][  140/  196]   Loss 0.444052   Top1 84.595424   Top5 98.512835   BatchTime 0.337159   LR 0.002726   
2022-11-25 12:15:31,454 - INFO  - Training [4][  160/  196]   Loss 0.444310   Top1 84.619141   Top5 98.505859   BatchTime 0.337630   LR 0.002646   
2022-11-25 12:15:38,256 - INFO  - Training [4][  180/  196]   Loss 0.442415   Top1 84.633247   Top5 98.467882   BatchTime 0.337905   LR 0.002566   
2022-11-25 12:15:44,079 - INFO  - ==> Top1: 84.662    Top5: 98.486    Loss: 0.441

2022-11-25 12:15:44,402 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:15:46,135 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:15:49,020 - INFO  - Validation [4][   20/   40]   Loss 0.370535   Top1 87.832031   Top5 99.570312   BatchTime 0.144138   
2022-11-25 12:15:50,099 - INFO  - Validation [4][   40/   40]   Loss 0.366862   Top1 87.740000   Top5 99.640000   BatchTime 0.099066   
2022-11-25 12:15:50,363 - INFO  - ==> Top1: 87.740    Top5: 99.640    Loss: 0.367

2022-11-25 12:15:50,364 - INFO  - ==> Sparsity : 0.536

2022-11-25 12:15:50,364 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 87.740   Top5: 99.640]
2022-11-25 12:15:50,364 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 86.410   Top5: 99.430]
2022-11-25 12:15:50,364 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 85.080   Top5: 99.300]
2022-11-25 12:15:56,209 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:15:56,211 - INFO  - >>>>>> Epoch   5
2022-11-25 12:15:56,213 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:16:03,341 - INFO  - Training [5][   20/  196]   Loss 0.415988   Top1 85.527344   Top5 98.222656   BatchTime 0.356289   LR 0.002424   
2022-11-25 12:16:09,236 - INFO  - Training [5][   40/  196]   Loss 0.422089   Top1 85.615234   Top5 98.330078   BatchTime 0.325521   LR 0.002343   
2022-11-25 12:16:15,978 - INFO  - Training [5][   60/  196]   Loss 0.414117   Top1 85.657552   Top5 98.424479   BatchTime 0.329384   LR 0.002263   
2022-11-25 12:16:22,819 - INFO  - Training [5][   80/  196]   Loss 0.406903   Top1 85.991211   Top5 98.505859   BatchTime 0.332549   LR 0.002183   
2022-11-25 12:16:29,393 - INFO  - Training [5][  100/  196]   Loss 0.404480   Top1 85.980469   Top5 98.535156   BatchTime 0.331776   LR 0.002104   
2022-11-25 12:16:36,530 - INFO  - Training [5][  120/  196]   Loss 0.399163   Top1 86.162109   Top5 98.626302   BatchTime 0.335956   LR 0.002024   
2022-11-25 12:16:43,444 - INFO  - Training [5][  140/  196]   Loss 0.399728   Top1 86.171875   Top5 98.635603   BatchTime 0.337345   LR 0.001946   
2022-11-25 12:16:50,039 - INFO  - Training [5][  160/  196]   Loss 0.402704   Top1 86.066895   Top5 98.635254   BatchTime 0.336394   LR 0.001868   
2022-11-25 12:16:56,736 - INFO  - Training [5][  180/  196]   Loss 0.403620   Top1 85.985243   Top5 98.580729   BatchTime 0.336225   LR 0.001790   
2022-11-25 12:17:02,339 - INFO  - ==> Top1: 85.998    Top5: 98.578    Loss: 0.403

2022-11-25 12:17:02,668 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:17:04,782 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:17:07,661 - INFO  - Validation [5][   20/   40]   Loss 0.335831   Top1 89.179688   Top5 99.648438   BatchTime 0.143883   
2022-11-25 12:17:08,764 - INFO  - Validation [5][   40/   40]   Loss 0.327505   Top1 89.420000   Top5 99.700000   BatchTime 0.099513   
2022-11-25 12:17:09,024 - INFO  - ==> Top1: 89.420    Top5: 99.700    Loss: 0.328

2022-11-25 12:17:09,024 - INFO  - ==> Sparsity : 0.537

2022-11-25 12:17:09,025 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 89.420   Top5: 99.700]
2022-11-25 12:17:09,025 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 87.740   Top5: 99.640]
2022-11-25 12:17:09,025 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 86.410   Top5: 99.430]
2022-11-25 12:17:14,200 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:17:14,202 - INFO  - >>>>>> Epoch   6
2022-11-25 12:17:14,204 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:17:21,117 - INFO  - Training [6][   20/  196]   Loss 0.396924   Top1 86.542969   Top5 98.105469   BatchTime 0.345513   LR 0.001655   
2022-11-25 12:17:26,934 - INFO  - Training [6][   40/  196]   Loss 0.388839   Top1 86.503906   Top5 98.398438   BatchTime 0.318207   LR 0.001580   
2022-11-25 12:17:33,951 - INFO  - Training [6][   60/  196]   Loss 0.382393   Top1 86.660156   Top5 98.509115   BatchTime 0.329074   LR 0.001506   
2022-11-25 12:17:40,615 - INFO  - Training [6][   80/  196]   Loss 0.376102   Top1 86.918945   Top5 98.598633   BatchTime 0.330108   LR 0.001432   
2022-11-25 12:17:47,475 - INFO  - Training [6][  100/  196]   Loss 0.374070   Top1 86.949219   Top5 98.664062   BatchTime 0.332690   LR 0.001360   
2022-11-25 12:17:54,195 - INFO  - Training [6][  120/  196]   Loss 0.369493   Top1 87.154948   Top5 98.714193   BatchTime 0.333239   LR 0.001289   
2022-11-25 12:18:00,947 - INFO  - Training [6][  140/  196]   Loss 0.370660   Top1 87.087054   Top5 98.752790   BatchTime 0.333859   LR 0.001220   
2022-11-25 12:18:07,591 - INFO  - Training [6][  160/  196]   Loss 0.371245   Top1 87.055664   Top5 98.742676   BatchTime 0.333652   LR 0.001151   
2022-11-25 12:18:14,364 - INFO  - Training [6][  180/  196]   Loss 0.369981   Top1 87.098524   Top5 98.695747   BatchTime 0.334208   LR 0.001084   
2022-11-25 12:18:19,948 - INFO  - ==> Top1: 87.120    Top5: 98.688    Loss: 0.370

2022-11-25 12:18:20,250 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:18:22,579 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:18:25,729 - INFO  - Validation [6][   20/   40]   Loss 0.299636   Top1 90.605469   Top5 99.609375   BatchTime 0.157376   
2022-11-25 12:18:27,324 - INFO  - Validation [6][   40/   40]   Loss 0.289932   Top1 90.570000   Top5 99.720000   BatchTime 0.118560   
2022-11-25 12:18:27,604 - INFO  - ==> Top1: 90.570    Top5: 99.720    Loss: 0.290

2022-11-25 12:18:27,605 - INFO  - ==> Sparsity : 0.539

2022-11-25 12:18:27,605 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:18:27,605 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.420   Top5: 99.700]
2022-11-25 12:18:27,605 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 87.740   Top5: 99.640]
2022-11-25 12:18:32,976 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:18:32,978 - INFO  - >>>>>> Epoch   7
2022-11-25 12:18:32,980 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:18:40,122 - INFO  - Training [7][   20/  196]   Loss 0.394794   Top1 86.132812   Top5 97.695312   BatchTime 0.356950   LR 0.000969   
2022-11-25 12:18:45,874 - INFO  - Training [7][   40/  196]   Loss 0.381416   Top1 86.650391   Top5 98.164062   BatchTime 0.322284   LR 0.000907   
2022-11-25 12:18:52,890 - INFO  - Training [7][   60/  196]   Loss 0.375449   Top1 86.783854   Top5 98.313802   BatchTime 0.331780   LR 0.000845   
2022-11-25 12:18:59,558 - INFO  - Training [7][   80/  196]   Loss 0.366861   Top1 87.045898   Top5 98.549805   BatchTime 0.332185   LR 0.000786   
2022-11-25 12:19:06,563 - INFO  - Training [7][  100/  196]   Loss 0.359906   Top1 87.316406   Top5 98.574219   BatchTime 0.335797   LR 0.000728   
2022-11-25 12:19:13,425 - INFO  - Training [7][  120/  196]   Loss 0.352536   Top1 87.584635   Top5 98.681641   BatchTime 0.337014   LR 0.000673   
2022-11-25 12:19:20,429 - INFO  - Training [7][  140/  196]   Loss 0.349400   Top1 87.712054   Top5 98.758371   BatchTime 0.338895   LR 0.000619   
2022-11-25 12:19:27,219 - INFO  - Training [7][  160/  196]   Loss 0.349862   Top1 87.666016   Top5 98.779297   BatchTime 0.338974   LR 0.000567   
2022-11-25 12:19:33,862 - INFO  - Training [7][  180/  196]   Loss 0.350244   Top1 87.647569   Top5 98.719618   BatchTime 0.338214   LR 0.000517   
2022-11-25 12:19:39,486 - INFO  - ==> Top1: 87.732    Top5: 98.728    Loss: 0.348

2022-11-25 12:19:39,778 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:19:42,316 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:19:45,211 - INFO  - Validation [7][   20/   40]   Loss 0.299245   Top1 90.253906   Top5 99.589844   BatchTime 0.144705   
2022-11-25 12:19:46,325 - INFO  - Validation [7][   40/   40]   Loss 0.283881   Top1 90.530000   Top5 99.700000   BatchTime 0.100190   
2022-11-25 12:19:46,609 - INFO  - ==> Top1: 90.530    Top5: 99.700    Loss: 0.284

2022-11-25 12:19:46,609 - INFO  - ==> Sparsity : 0.538

2022-11-25 12:19:46,609 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:19:46,609 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:19:46,609 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 89.420   Top5: 99.700]
2022-11-25 12:19:46,751 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:19:46,753 - INFO  - >>>>>> Epoch   8
2022-11-25 12:19:46,755 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:19:55,042 - INFO  - Training [8][   20/  196]   Loss 0.330756   Top1 87.792969   Top5 98.417969   BatchTime 0.414227   LR 0.000434   
2022-11-25 12:20:00,771 - INFO  - Training [8][   40/  196]   Loss 0.335301   Top1 87.666016   Top5 98.593750   BatchTime 0.350347   LR 0.000389   
2022-11-25 12:20:07,368 - INFO  - Training [8][   60/  196]   Loss 0.334777   Top1 88.014323   Top5 98.697917   BatchTime 0.343510   LR 0.000347   
2022-11-25 12:20:14,209 - INFO  - Training [8][   80/  196]   Loss 0.331427   Top1 88.286133   Top5 98.833008   BatchTime 0.343142   LR 0.000308   
2022-11-25 12:20:20,969 - INFO  - Training [8][  100/  196]   Loss 0.328101   Top1 88.394531   Top5 98.832031   BatchTime 0.342108   LR 0.000270   
2022-11-25 12:20:27,809 - INFO  - Training [8][  120/  196]   Loss 0.323147   Top1 88.583984   Top5 98.873698   BatchTime 0.342090   LR 0.000235   
2022-11-25 12:20:34,570 - INFO  - Training [8][  140/  196]   Loss 0.324069   Top1 88.621652   Top5 98.897879   BatchTime 0.341513   LR 0.000202   
2022-11-25 12:20:41,306 - INFO  - Training [8][  160/  196]   Loss 0.326969   Top1 88.510742   Top5 98.864746   BatchTime 0.340924   LR 0.000172   
2022-11-25 12:20:48,121 - INFO  - Training [8][  180/  196]   Loss 0.326818   Top1 88.506944   Top5 98.830295   BatchTime 0.340903   LR 0.000143   
2022-11-25 12:20:53,512 - INFO  - ==> Top1: 88.640    Top5: 98.838    Loss: 0.323

2022-11-25 12:20:53,919 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:20:55,639 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:20:58,261 - INFO  - Validation [8][   20/   40]   Loss 0.301667   Top1 90.390625   Top5 99.609375   BatchTime 0.131012   
2022-11-25 12:21:00,005 - INFO  - Validation [8][   40/   40]   Loss 0.287463   Top1 90.520000   Top5 99.710000   BatchTime 0.109104   
2022-11-25 12:21:00,649 - INFO  - ==> Top1: 90.520    Top5: 99.710    Loss: 0.287

2022-11-25 12:21:00,649 - INFO  - ==> Sparsity : 0.538

2022-11-25 12:21:00,650 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:21:00,650 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:21:00,650 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 90.520   Top5: 99.710]
2022-11-25 12:21:00,804 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:21:00,806 - INFO  - >>>>>> Epoch   9
2022-11-25 12:21:00,807 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:21:09,613 - INFO  - Training [9][   20/  196]   Loss 0.322914   Top1 88.632812   Top5 98.457031   BatchTime 0.440139   LR 0.000100   
2022-11-25 12:21:15,603 - INFO  - Training [9][   40/  196]   Loss 0.333758   Top1 88.261719   Top5 98.535156   BatchTime 0.369832   LR 0.000079   
2022-11-25 12:21:21,066 - INFO  - Training [9][   60/  196]   Loss 0.334300   Top1 88.131510   Top5 98.580729   BatchTime 0.337593   LR 0.000060   
2022-11-25 12:21:27,954 - INFO  - Training [9][   80/  196]   Loss 0.331584   Top1 88.339844   Top5 98.701172   BatchTime 0.339294   LR 0.000044   
2022-11-25 12:21:34,755 - INFO  - Training [9][  100/  196]   Loss 0.327360   Top1 88.570312   Top5 98.777344   BatchTime 0.339448   LR 0.000030   
2022-11-25 12:21:41,463 - INFO  - Training [9][  120/  196]   Loss 0.318705   Top1 88.922526   Top5 98.870443   BatchTime 0.338768   LR 0.000019   
2022-11-25 12:21:48,061 - INFO  - Training [9][  140/  196]   Loss 0.316545   Top1 88.962054   Top5 98.928571   BatchTime 0.337497   LR 0.000010   
2022-11-25 12:21:54,639 - INFO  - Training [9][  160/  196]   Loss 0.317503   Top1 88.896484   Top5 98.920898   BatchTime 0.336427   LR 0.000004   
2022-11-25 12:22:01,346 - INFO  - Training [9][  180/  196]   Loss 0.319366   Top1 88.789062   Top5 98.847656   BatchTime 0.336306   LR 0.000001   
2022-11-25 12:22:06,714 - INFO  - ==> Top1: 88.818    Top5: 98.848    Loss: 0.319

2022-11-25 12:22:06,960 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:22:08,726 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:22:11,427 - INFO  - Validation [9][   20/   40]   Loss 0.300845   Top1 90.351562   Top5 99.667969   BatchTime 0.134937   
2022-11-25 12:22:12,536 - INFO  - Validation [9][   40/   40]   Loss 0.288270   Top1 90.410000   Top5 99.750000   BatchTime 0.095189   
2022-11-25 12:22:12,758 - INFO  - ==> Top1: 90.410    Top5: 99.750    Loss: 0.288

2022-11-25 12:22:12,758 - INFO  - ==> Sparsity : 0.538

2022-11-25 12:22:12,758 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:22:12,758 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:22:12,758 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 90.520   Top5: 99.710]
2022-11-25 12:22:12,887 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:22:12,889 - INFO  - >>>>>> Epoch  10
2022-11-25 12:22:12,891 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:22:21,965 - INFO  - Training [10][   20/  196]   Loss 0.362598   Top1 86.953125   Top5 98.222656   BatchTime 0.453577   LR 0.002500   
2022-11-25 12:22:28,468 - INFO  - Training [10][   40/  196]   Loss 0.378485   Top1 86.718750   Top5 98.359375   BatchTime 0.389361   LR 0.002499   
2022-11-25 12:22:34,098 - INFO  - Training [10][   60/  196]   Loss 0.377172   Top1 86.829427   Top5 98.515625   BatchTime 0.353408   LR 0.002499   
2022-11-25 12:22:40,344 - INFO  - Training [10][   80/  196]   Loss 0.379096   Top1 86.821289   Top5 98.623047   BatchTime 0.343126   LR 0.002497   
2022-11-25 12:22:47,340 - INFO  - Training [10][  100/  196]   Loss 0.379461   Top1 86.761719   Top5 98.589844   BatchTime 0.344466   LR 0.002496   
2022-11-25 12:22:54,585 - INFO  - Training [10][  120/  196]   Loss 0.375686   Top1 86.878255   Top5 98.694661   BatchTime 0.347429   LR 0.002494   
2022-11-25 12:23:01,504 - INFO  - Training [10][  140/  196]   Loss 0.376234   Top1 86.863839   Top5 98.738839   BatchTime 0.347217   LR 0.002492   
2022-11-25 12:23:08,242 - INFO  - Training [10][  160/  196]   Loss 0.381578   Top1 86.694336   Top5 98.715820   BatchTime 0.345927   LR 0.002490   
2022-11-25 12:23:14,996 - INFO  - Training [10][  180/  196]   Loss 0.384740   Top1 86.542969   Top5 98.632812   BatchTime 0.345012   LR 0.002487   
2022-11-25 12:23:20,395 - INFO  - ==> Top1: 86.514    Top5: 98.632    Loss: 0.385

2022-11-25 12:23:20,650 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:23:22,212 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:23:24,896 - INFO  - Validation [10][   20/   40]   Loss 0.408409   Top1 87.421875   Top5 99.375000   BatchTime 0.134074   
2022-11-25 12:23:25,983 - INFO  - Validation [10][   40/   40]   Loss 0.394246   Top1 87.180000   Top5 99.440000   BatchTime 0.094227   
2022-11-25 12:23:26,258 - INFO  - ==> Top1: 87.180    Top5: 99.440    Loss: 0.394

2022-11-25 12:23:26,259 - INFO  - ==> Sparsity : 0.543

2022-11-25 12:23:26,259 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:23:26,259 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:23:26,259 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 90.520   Top5: 99.710]
2022-11-25 12:23:26,416 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:23:26,417 - INFO  - >>>>>> Epoch  11
2022-11-25 12:23:26,419 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:23:35,091 - INFO  - Training [11][   20/  196]   Loss 0.400450   Top1 86.113281   Top5 98.222656   BatchTime 0.433460   LR 0.002481   
2022-11-25 12:23:42,420 - INFO  - Training [11][   40/  196]   Loss 0.418118   Top1 85.283203   Top5 98.427734   BatchTime 0.399959   LR 0.002478   
2022-11-25 12:23:48,578 - INFO  - Training [11][   60/  196]   Loss 0.419486   Top1 85.260417   Top5 98.489583   BatchTime 0.369274   LR 0.002474   
2022-11-25 12:23:54,426 - INFO  - Training [11][   80/  196]   Loss 0.412874   Top1 85.576172   Top5 98.613281   BatchTime 0.350055   LR 0.002470   
2022-11-25 12:24:01,455 - INFO  - Training [11][  100/  196]   Loss 0.404325   Top1 85.886719   Top5 98.593750   BatchTime 0.350326   LR 0.002465   
2022-11-25 12:24:08,378 - INFO  - Training [11][  120/  196]   Loss 0.397089   Top1 86.207682   Top5 98.671875   BatchTime 0.349628   LR 0.002460   
2022-11-25 12:24:15,110 - INFO  - Training [11][  140/  196]   Loss 0.396449   Top1 86.275112   Top5 98.702567   BatchTime 0.347770   LR 0.002455   
2022-11-25 12:24:22,015 - INFO  - Training [11][  160/  196]   Loss 0.399858   Top1 86.188965   Top5 98.688965   BatchTime 0.347455   LR 0.002450   
2022-11-25 12:24:28,731 - INFO  - Training [11][  180/  196]   Loss 0.398670   Top1 86.208767   Top5 98.639323   BatchTime 0.346162   LR 0.002444   
2022-11-25 12:24:34,334 - INFO  - ==> Top1: 86.238    Top5: 98.646    Loss: 0.398

2022-11-25 12:24:34,553 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:24:36,164 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:24:38,867 - INFO  - Validation [11][   20/   40]   Loss 0.340187   Top1 89.082031   Top5 99.550781   BatchTime 0.135042   
2022-11-25 12:24:39,966 - INFO  - Validation [11][   40/   40]   Loss 0.333463   Top1 89.120000   Top5 99.540000   BatchTime 0.095004   
2022-11-25 12:24:40,244 - INFO  - ==> Top1: 89.120    Top5: 99.540    Loss: 0.333

2022-11-25 12:24:40,244 - INFO  - ==> Sparsity : 0.546

2022-11-25 12:24:40,245 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:24:40,245 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:24:40,245 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 90.520   Top5: 99.710]
2022-11-25 12:24:40,373 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:24:40,374 - INFO  - >>>>>> Epoch  12
2022-11-25 12:24:40,376 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:24:48,724 - INFO  - Training [12][   20/  196]   Loss 0.414129   Top1 85.429688   Top5 98.085938   BatchTime 0.417278   LR 0.002433   
2022-11-25 12:24:55,757 - INFO  - Training [12][   40/  196]   Loss 0.418007   Top1 85.283203   Top5 98.193359   BatchTime 0.384457   LR 0.002426   
2022-11-25 12:25:02,732 - INFO  - Training [12][   60/  196]   Loss 0.405701   Top1 85.722656   Top5 98.404948   BatchTime 0.372549   LR 0.002419   
2022-11-25 12:25:08,380 - INFO  - Training [12][   80/  196]   Loss 0.401847   Top1 85.976562   Top5 98.540039   BatchTime 0.350016   LR 0.002412   
2022-11-25 12:25:13,452 - INFO  - Training [12][  100/  196]   Loss 0.391790   Top1 86.328125   Top5 98.593750   BatchTime 0.330725   LR 0.002404   
2022-11-25 12:25:19,358 - INFO  - Training [12][  120/  196]   Loss 0.389831   Top1 86.445312   Top5 98.645833   BatchTime 0.324827   LR 0.002396   
2022-11-25 12:25:26,296 - INFO  - Training [12][  140/  196]   Loss 0.389688   Top1 86.453683   Top5 98.719308   BatchTime 0.327975   LR 0.002388   
2022-11-25 12:25:33,158 - INFO  - Training [12][  160/  196]   Loss 0.393771   Top1 86.271973   Top5 98.688965   BatchTime 0.329867   LR 0.002380   
2022-11-25 12:25:40,106 - INFO  - Training [12][  180/  196]   Loss 0.392195   Top1 86.338976   Top5 98.654514   BatchTime 0.331812   LR 0.002371   
2022-11-25 12:25:45,795 - INFO  - ==> Top1: 86.312    Top5: 98.660    Loss: 0.392

2022-11-25 12:25:46,088 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:25:47,579 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:25:50,288 - INFO  - Validation [12][   20/   40]   Loss 0.368141   Top1 88.222656   Top5 99.414062   BatchTime 0.135362   
2022-11-25 12:25:51,322 - INFO  - Validation [12][   40/   40]   Loss 0.346644   Top1 88.650000   Top5 99.550000   BatchTime 0.093520   
2022-11-25 12:25:51,546 - INFO  - ==> Top1: 88.650    Top5: 99.550    Loss: 0.347

2022-11-25 12:25:51,546 - INFO  - ==> Sparsity : 0.551

2022-11-25 12:25:51,547 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:25:51,547 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:25:51,547 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 90.520   Top5: 99.710]
2022-11-25 12:25:51,686 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:25:51,687 - INFO  - >>>>>> Epoch  13
2022-11-25 12:25:51,689 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:26:00,019 - INFO  - Training [13][   20/  196]   Loss 0.387426   Top1 86.601562   Top5 98.339844   BatchTime 0.416365   LR 0.002355   
2022-11-25 12:26:06,818 - INFO  - Training [13][   40/  196]   Loss 0.391755   Top1 86.445312   Top5 98.378906   BatchTime 0.378146   LR 0.002345   
2022-11-25 12:26:14,070 - INFO  - Training [13][   60/  196]   Loss 0.389549   Top1 86.588542   Top5 98.561198   BatchTime 0.372965   LR 0.002336   
2022-11-25 12:26:20,914 - INFO  - Training [13][   80/  196]   Loss 0.389948   Top1 86.425781   Top5 98.676758   BatchTime 0.365267   LR 0.002325   
2022-11-25 12:26:27,536 - INFO  - Training [13][  100/  196]   Loss 0.389015   Top1 86.503906   Top5 98.738281   BatchTime 0.358436   LR 0.002315   
2022-11-25 12:26:33,134 - INFO  - Training [13][  120/  196]   Loss 0.384263   Top1 86.686198   Top5 98.789062   BatchTime 0.345350   LR 0.002304   
2022-11-25 12:26:39,298 - INFO  - Training [13][  140/  196]   Loss 0.387028   Top1 86.682478   Top5 98.819754   BatchTime 0.340041   LR 0.002293   
2022-11-25 12:26:46,069 - INFO  - Training [13][  160/  196]   Loss 0.388083   Top1 86.596680   Top5 98.796387   BatchTime 0.339853   LR 0.002282   
2022-11-25 12:26:53,040 - INFO  - Training [13][  180/  196]   Loss 0.388919   Top1 86.540799   Top5 98.736979   BatchTime 0.340820   LR 0.002271   
2022-11-25 12:26:58,556 - INFO  - ==> Top1: 86.490    Top5: 98.720    Loss: 0.391

2022-11-25 12:26:58,788 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:27:00,412 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:27:03,157 - INFO  - Validation [13][   20/   40]   Loss 0.321876   Top1 89.550781   Top5 99.511719   BatchTime 0.137144   
2022-11-25 12:27:04,218 - INFO  - Validation [13][   40/   40]   Loss 0.316162   Top1 89.580000   Top5 99.570000   BatchTime 0.095093   
2022-11-25 12:27:04,515 - INFO  - ==> Top1: 89.580    Top5: 99.570    Loss: 0.316

2022-11-25 12:27:04,515 - INFO  - ==> Sparsity : 0.555

2022-11-25 12:27:04,515 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:27:04,515 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:27:04,516 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 90.520   Top5: 99.710]
2022-11-25 12:27:04,650 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:27:04,652 - INFO  - >>>>>> Epoch  14
2022-11-25 12:27:04,654 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:27:13,192 - INFO  - Training [14][   20/  196]   Loss 0.394942   Top1 86.074219   Top5 98.359375   BatchTime 0.426755   LR 0.002250   
2022-11-25 12:27:20,208 - INFO  - Training [14][   40/  196]   Loss 0.393403   Top1 86.347656   Top5 98.398438   BatchTime 0.388795   LR 0.002238   
2022-11-25 12:27:27,313 - INFO  - Training [14][   60/  196]   Loss 0.395701   Top1 86.347656   Top5 98.528646   BatchTime 0.377609   LR 0.002225   
2022-11-25 12:27:34,035 - INFO  - Training [14][   80/  196]   Loss 0.391271   Top1 86.391602   Top5 98.662109   BatchTime 0.367232   LR 0.002213   
2022-11-25 12:27:41,456 - INFO  - Training [14][  100/  196]   Loss 0.386072   Top1 86.523438   Top5 98.687500   BatchTime 0.367989   LR 0.002200   
2022-11-25 12:27:47,526 - INFO  - Training [14][  120/  196]   Loss 0.378274   Top1 86.803385   Top5 98.779297   BatchTime 0.357246   LR 0.002186   
2022-11-25 12:27:53,632 - INFO  - Training [14][  140/  196]   Loss 0.376519   Top1 86.833147   Top5 98.830915   BatchTime 0.349819   LR 0.002173   
2022-11-25 12:28:00,662 - INFO  - Training [14][  160/  196]   Loss 0.380886   Top1 86.599121   Top5 98.820801   BatchTime 0.350027   LR 0.002159   
2022-11-25 12:28:07,553 - INFO  - Training [14][  180/  196]   Loss 0.380623   Top1 86.595052   Top5 98.778212   BatchTime 0.349423   LR 0.002145   
2022-11-25 12:28:13,025 - INFO  - ==> Top1: 86.662    Top5: 98.770    Loss: 0.380

2022-11-25 12:28:13,293 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:28:14,844 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:28:17,783 - INFO  - Validation [14][   20/   40]   Loss 0.325123   Top1 89.355469   Top5 99.570312   BatchTime 0.146795   
2022-11-25 12:28:18,971 - INFO  - Validation [14][   40/   40]   Loss 0.309931   Top1 89.750000   Top5 99.630000   BatchTime 0.103103   
2022-11-25 12:28:19,231 - INFO  - ==> Top1: 89.750    Top5: 99.630    Loss: 0.310

2022-11-25 12:28:19,231 - INFO  - ==> Sparsity : 0.557

2022-11-25 12:28:19,231 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:28:19,232 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:28:19,232 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 90.520   Top5: 99.710]
2022-11-25 12:28:19,358 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:28:19,359 - INFO  - >>>>>> Epoch  15
2022-11-25 12:28:19,361 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:28:27,861 - INFO  - Training [15][   20/  196]   Loss 0.399073   Top1 85.566406   Top5 98.320312   BatchTime 0.424839   LR 0.002120   
2022-11-25 12:28:34,625 - INFO  - Training [15][   40/  196]   Loss 0.387026   Top1 86.357422   Top5 98.544922   BatchTime 0.381535   LR 0.002106   
2022-11-25 12:28:41,747 - INFO  - Training [15][   60/  196]   Loss 0.385024   Top1 86.386719   Top5 98.587240   BatchTime 0.373052   LR 0.002091   
2022-11-25 12:28:48,433 - INFO  - Training [15][   80/  196]   Loss 0.380904   Top1 86.596680   Top5 98.676758   BatchTime 0.363360   LR 0.002076   
2022-11-25 12:28:55,447 - INFO  - Training [15][  100/  196]   Loss 0.372814   Top1 86.851562   Top5 98.738281   BatchTime 0.360825   LR 0.002061   
2022-11-25 12:29:02,455 - INFO  - Training [15][  120/  196]   Loss 0.367916   Top1 87.119141   Top5 98.802083   BatchTime 0.359093   LR 0.002045   
2022-11-25 12:29:08,461 - INFO  - Training [15][  140/  196]   Loss 0.366995   Top1 87.151228   Top5 98.825335   BatchTime 0.350689   LR 0.002030   
2022-11-25 12:29:13,917 - INFO  - Training [15][  160/  196]   Loss 0.370839   Top1 87.011719   Top5 98.818359   BatchTime 0.340951   LR 0.002014   
2022-11-25 12:29:18,919 - INFO  - Training [15][  180/  196]   Loss 0.371403   Top1 87.005208   Top5 98.780382   BatchTime 0.330860   LR 0.001998   
2022-11-25 12:29:24,676 - INFO  - ==> Top1: 87.052    Top5: 98.764    Loss: 0.371

2022-11-25 12:29:24,933 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:29:26,699 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:29:29,381 - INFO  - Validation [15][   20/   40]   Loss 0.338073   Top1 89.277344   Top5 99.531250   BatchTime 0.134015   
2022-11-25 12:29:30,534 - INFO  - Validation [15][   40/   40]   Loss 0.325362   Top1 89.420000   Top5 99.670000   BatchTime 0.095850   
2022-11-25 12:29:30,832 - INFO  - ==> Top1: 89.420    Top5: 99.670    Loss: 0.325

2022-11-25 12:29:30,832 - INFO  - ==> Sparsity : 0.558

2022-11-25 12:29:30,832 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:29:30,832 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:29:30,833 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 90.520   Top5: 99.710]
2022-11-25 12:29:30,965 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:29:30,967 - INFO  - >>>>>> Epoch  16
2022-11-25 12:29:30,970 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:29:39,513 - INFO  - Training [16][   20/  196]   Loss 0.392315   Top1 86.640625   Top5 98.222656   BatchTime 0.427047   LR 0.001969   
2022-11-25 12:29:46,325 - INFO  - Training [16][   40/  196]   Loss 0.378204   Top1 86.943359   Top5 98.388672   BatchTime 0.383816   LR 0.001953   
2022-11-25 12:29:52,974 - INFO  - Training [16][   60/  196]   Loss 0.371003   Top1 87.063802   Top5 98.483073   BatchTime 0.366694   LR 0.001936   
2022-11-25 12:29:59,744 - INFO  - Training [16][   80/  196]   Loss 0.367623   Top1 87.241211   Top5 98.642578   BatchTime 0.359645   LR 0.001919   
2022-11-25 12:30:06,447 - INFO  - Training [16][  100/  196]   Loss 0.362760   Top1 87.468750   Top5 98.718750   BatchTime 0.354747   LR 0.001902   
2022-11-25 12:30:13,065 - INFO  - Training [16][  120/  196]   Loss 0.354536   Top1 87.760417   Top5 98.802083   BatchTime 0.350766   LR 0.001885   
2022-11-25 12:30:20,251 - INFO  - Training [16][  140/  196]   Loss 0.352566   Top1 87.776228   Top5 98.869978   BatchTime 0.351991   LR 0.001867   
2022-11-25 12:30:27,257 - INFO  - Training [16][  160/  196]   Loss 0.356722   Top1 87.631836   Top5 98.854980   BatchTime 0.351776   LR 0.001850   
2022-11-25 12:30:33,087 - INFO  - Training [16][  180/  196]   Loss 0.357164   Top1 87.641059   Top5 98.817274   BatchTime 0.345075   LR 0.001832   
2022-11-25 12:30:37,253 - INFO  - ==> Top1: 87.672    Top5: 98.810    Loss: 0.357

2022-11-25 12:30:37,453 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:30:38,798 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:30:41,560 - INFO  - Validation [16][   20/   40]   Loss 0.317365   Top1 90.136719   Top5 99.589844   BatchTime 0.138016   
2022-11-25 12:30:42,692 - INFO  - Validation [16][   40/   40]   Loss 0.304218   Top1 90.340000   Top5 99.650000   BatchTime 0.097319   
2022-11-25 12:30:42,948 - INFO  - ==> Top1: 90.340    Top5: 99.650    Loss: 0.304

2022-11-25 12:30:42,948 - INFO  - ==> Sparsity : 0.559

2022-11-25 12:30:42,949 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:30:42,949 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:30:42,949 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 90.520   Top5: 99.710]
2022-11-25 12:30:43,085 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:30:43,087 - INFO  - >>>>>> Epoch  17
2022-11-25 12:30:43,089 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:30:51,418 - INFO  - Training [17][   20/  196]   Loss 0.362242   Top1 87.050781   Top5 98.222656   BatchTime 0.416332   LR 0.001800   
2022-11-25 12:30:58,076 - INFO  - Training [17][   40/  196]   Loss 0.360536   Top1 87.128906   Top5 98.496094   BatchTime 0.374623   LR 0.001782   
2022-11-25 12:31:04,753 - INFO  - Training [17][   60/  196]   Loss 0.361546   Top1 87.076823   Top5 98.593750   BatchTime 0.361019   LR 0.001764   
2022-11-25 12:31:11,492 - INFO  - Training [17][   80/  196]   Loss 0.358455   Top1 87.260742   Top5 98.691406   BatchTime 0.355006   LR 0.001746   
2022-11-25 12:31:18,518 - INFO  - Training [17][  100/  196]   Loss 0.353760   Top1 87.363281   Top5 98.769531   BatchTime 0.354262   LR 0.001727   
2022-11-25 12:31:25,279 - INFO  - Training [17][  120/  196]   Loss 0.352534   Top1 87.464193   Top5 98.795573   BatchTime 0.351557   LR 0.001708   
2022-11-25 12:31:31,890 - INFO  - Training [17][  140/  196]   Loss 0.352421   Top1 87.505580   Top5 98.850446   BatchTime 0.348553   LR 0.001690   
2022-11-25 12:31:38,754 - INFO  - Training [17][  160/  196]   Loss 0.352679   Top1 87.480469   Top5 98.852539   BatchTime 0.347889   LR 0.001671   
2022-11-25 12:31:45,765 - INFO  - Training [17][  180/  196]   Loss 0.349448   Top1 87.612847   Top5 98.843316   BatchTime 0.348183   LR 0.001652   
2022-11-25 12:31:51,145 - INFO  - ==> Top1: 87.620    Top5: 98.842    Loss: 0.349

2022-11-25 12:31:51,327 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:31:52,511 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:31:55,912 - INFO  - Validation [17][   20/   40]   Loss 0.303853   Top1 90.507812   Top5 99.609375   BatchTime 0.169957   
2022-11-25 12:31:58,134 - INFO  - Validation [17][   40/   40]   Loss 0.296640   Top1 90.700000   Top5 99.620000   BatchTime 0.140525   
2022-11-25 12:31:58,435 - INFO  - ==> Top1: 90.700    Top5: 99.620    Loss: 0.297

2022-11-25 12:31:58,436 - INFO  - ==> Sparsity : 0.561

2022-11-25 12:31:58,436 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 90.700   Top5: 99.620]
2022-11-25 12:31:58,436 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:31:58,436 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:32:04,503 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:32:04,505 - INFO  - >>>>>> Epoch  18
2022-11-25 12:32:04,508 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:32:13,214 - INFO  - Training [18][   20/  196]   Loss 0.355544   Top1 87.421875   Top5 98.496094   BatchTime 0.435166   LR 0.001618   
2022-11-25 12:32:20,067 - INFO  - Training [18][   40/  196]   Loss 0.361515   Top1 87.246094   Top5 98.583984   BatchTime 0.388903   LR 0.001599   
2022-11-25 12:32:26,760 - INFO  - Training [18][   60/  196]   Loss 0.356241   Top1 87.441406   Top5 98.619792   BatchTime 0.370816   LR 0.001579   
2022-11-25 12:32:33,847 - INFO  - Training [18][   80/  196]   Loss 0.355980   Top1 87.553711   Top5 98.735352   BatchTime 0.366707   LR 0.001560   
2022-11-25 12:32:40,799 - INFO  - Training [18][  100/  196]   Loss 0.345500   Top1 87.902344   Top5 98.796875   BatchTime 0.362883   LR 0.001540   
2022-11-25 12:32:47,578 - INFO  - Training [18][  120/  196]   Loss 0.338241   Top1 88.212891   Top5 98.850911   BatchTime 0.358891   LR 0.001521   
2022-11-25 12:32:54,700 - INFO  - Training [18][  140/  196]   Loss 0.336484   Top1 88.297991   Top5 98.909040   BatchTime 0.358489   LR 0.001501   
2022-11-25 12:33:01,322 - INFO  - Training [18][  160/  196]   Loss 0.337692   Top1 88.261719   Top5 98.896484   BatchTime 0.355066   LR 0.001482   
2022-11-25 12:33:08,428 - INFO  - Training [18][  180/  196]   Loss 0.335760   Top1 88.318142   Top5 98.904080   BatchTime 0.355093   LR 0.001462   
2022-11-25 12:33:12,853 - INFO  - ==> Top1: 88.350    Top5: 98.912    Loss: 0.335

2022-11-25 12:33:13,069 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:33:14,991 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:33:17,822 - INFO  - Validation [18][   20/   40]   Loss 0.312658   Top1 90.234375   Top5 99.609375   BatchTime 0.141433   
2022-11-25 12:33:19,375 - INFO  - Validation [18][   40/   40]   Loss 0.304452   Top1 90.360000   Top5 99.710000   BatchTime 0.109562   
2022-11-25 12:33:19,607 - INFO  - ==> Top1: 90.360    Top5: 99.710    Loss: 0.304

2022-11-25 12:33:19,607 - INFO  - ==> Sparsity : 0.561

2022-11-25 12:33:19,608 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 90.700   Top5: 99.620]
2022-11-25 12:33:19,608 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:33:19,608 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:33:19,749 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:33:19,751 - INFO  - >>>>>> Epoch  19
2022-11-25 12:33:19,753 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:33:28,310 - INFO  - Training [19][   20/  196]   Loss 0.348751   Top1 88.046875   Top5 98.437500   BatchTime 0.427738   LR 0.001427   
2022-11-25 12:33:34,921 - INFO  - Training [19][   40/  196]   Loss 0.348656   Top1 88.076172   Top5 98.564453   BatchTime 0.379131   LR 0.001407   
2022-11-25 12:33:41,565 - INFO  - Training [19][   60/  196]   Loss 0.346713   Top1 88.027344   Top5 98.613281   BatchTime 0.363486   LR 0.001387   
2022-11-25 12:33:48,354 - INFO  - Training [19][   80/  196]   Loss 0.343732   Top1 88.139648   Top5 98.720703   BatchTime 0.357484   LR 0.001367   
2022-11-25 12:33:55,237 - INFO  - Training [19][  100/  196]   Loss 0.337788   Top1 88.292969   Top5 98.781250   BatchTime 0.354810   LR 0.001347   
2022-11-25 12:34:01,944 - INFO  - Training [19][  120/  196]   Loss 0.330144   Top1 88.496094   Top5 98.880208   BatchTime 0.351569   LR 0.001327   
2022-11-25 12:34:08,706 - INFO  - Training [19][  140/  196]   Loss 0.328433   Top1 88.557478   Top5 98.948103   BatchTime 0.349644   LR 0.001307   
2022-11-25 12:34:15,396 - INFO  - Training [19][  160/  196]   Loss 0.332637   Top1 88.366699   Top5 98.945312   BatchTime 0.347748   LR 0.001287   
2022-11-25 12:34:22,243 - INFO  - Training [19][  180/  196]   Loss 0.332752   Top1 88.313802   Top5 98.921441   BatchTime 0.347149   LR 0.001266   
2022-11-25 12:34:27,930 - INFO  - ==> Top1: 88.312    Top5: 98.912    Loss: 0.333

2022-11-25 12:34:28,495 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:34:29,719 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:34:32,615 - INFO  - Validation [19][   20/   40]   Loss 0.319874   Top1 89.824219   Top5 99.687500   BatchTime 0.144729   
2022-11-25 12:34:33,919 - INFO  - Validation [19][   40/   40]   Loss 0.304810   Top1 90.300000   Top5 99.730000   BatchTime 0.104958   
2022-11-25 12:34:34,449 - INFO  - ==> Top1: 90.300    Top5: 99.730    Loss: 0.305

2022-11-25 12:34:34,449 - INFO  - ==> Sparsity : 0.563

2022-11-25 12:34:34,449 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 90.700   Top5: 99.620]
2022-11-25 12:34:34,450 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:34:34,450 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 90.530   Top5: 99.700]
2022-11-25 12:34:34,596 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:34:34,598 - INFO  - >>>>>> Epoch  20
2022-11-25 12:34:34,600 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:34:42,489 - INFO  - Training [20][   20/  196]   Loss 0.330168   Top1 88.105469   Top5 98.710938   BatchTime 0.394328   LR 0.001231   
2022-11-25 12:34:49,289 - INFO  - Training [20][   40/  196]   Loss 0.328988   Top1 88.310547   Top5 98.759766   BatchTime 0.367147   LR 0.001211   
2022-11-25 12:34:55,902 - INFO  - Training [20][   60/  196]   Loss 0.327878   Top1 88.424479   Top5 98.776042   BatchTime 0.354993   LR 0.001191   
2022-11-25 12:35:02,759 - INFO  - Training [20][   80/  196]   Loss 0.326791   Top1 88.442383   Top5 98.935547   BatchTime 0.351947   LR 0.001171   
2022-11-25 12:35:09,510 - INFO  - Training [20][  100/  196]   Loss 0.320623   Top1 88.656250   Top5 98.964844   BatchTime 0.349066   LR 0.001151   
2022-11-25 12:35:16,571 - INFO  - Training [20][  120/  196]   Loss 0.316476   Top1 88.782552   Top5 99.029948   BatchTime 0.349733   LR 0.001131   
2022-11-25 12:35:23,598 - INFO  - Training [20][  140/  196]   Loss 0.318744   Top1 88.699777   Top5 99.068080   BatchTime 0.349960   LR 0.001111   
2022-11-25 12:35:30,215 - INFO  - Training [20][  160/  196]   Loss 0.323950   Top1 88.535156   Top5 99.040527   BatchTime 0.347575   LR 0.001091   
2022-11-25 12:35:36,918 - INFO  - Training [20][  180/  196]   Loss 0.323611   Top1 88.537326   Top5 98.999566   BatchTime 0.346194   LR 0.001071   
2022-11-25 12:35:42,777 - INFO  - ==> Top1: 88.578    Top5: 98.994    Loss: 0.322

2022-11-25 12:35:43,114 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:35:44,787 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:35:47,668 - INFO  - Validation [20][   20/   40]   Loss 0.304687   Top1 90.429688   Top5 99.531250   BatchTime 0.143977   
2022-11-25 12:35:48,740 - INFO  - Validation [20][   40/   40]   Loss 0.290904   Top1 90.690000   Top5 99.680000   BatchTime 0.098784   
2022-11-25 12:35:48,988 - INFO  - ==> Top1: 90.690    Top5: 99.680    Loss: 0.291

2022-11-25 12:35:48,988 - INFO  - ==> Sparsity : 0.563

2022-11-25 12:35:48,988 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 90.700   Top5: 99.620]
2022-11-25 12:35:48,988 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 90.690   Top5: 99.680]
2022-11-25 12:35:48,989 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.570   Top5: 99.720]
2022-11-25 12:35:49,124 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:35:49,126 - INFO  - >>>>>> Epoch  21
2022-11-25 12:35:49,128 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:35:56,495 - INFO  - Training [21][   20/  196]   Loss 0.326150   Top1 88.476562   Top5 98.574219   BatchTime 0.368221   LR 0.001036   
2022-11-25 12:36:01,693 - INFO  - Training [21][   40/  196]   Loss 0.335098   Top1 88.134766   Top5 98.447266   BatchTime 0.314055   LR 0.001016   
2022-11-25 12:36:07,354 - INFO  - Training [21][   60/  196]   Loss 0.327878   Top1 88.463542   Top5 98.593750   BatchTime 0.303720   LR 0.000996   
2022-11-25 12:36:14,111 - INFO  - Training [21][   80/  196]   Loss 0.328587   Top1 88.437500   Top5 98.715820   BatchTime 0.312255   LR 0.000976   
2022-11-25 12:36:20,728 - INFO  - Training [21][  100/  196]   Loss 0.319027   Top1 88.765625   Top5 98.800781   BatchTime 0.315975   LR 0.000957   
2022-11-25 12:36:27,485 - INFO  - Training [21][  120/  196]   Loss 0.311647   Top1 89.023438   Top5 98.873698   BatchTime 0.319619   LR 0.000937   
2022-11-25 12:36:34,276 - INFO  - Training [21][  140/  196]   Loss 0.307223   Top1 89.215960   Top5 98.934152   BatchTime 0.322460   LR 0.000918   
2022-11-25 12:36:41,110 - INFO  - Training [21][  160/  196]   Loss 0.311155   Top1 89.133301   Top5 98.911133   BatchTime 0.324868   LR 0.000899   
2022-11-25 12:36:47,748 - INFO  - Training [21][  180/  196]   Loss 0.311426   Top1 89.105903   Top5 98.891059   BatchTime 0.325650   LR 0.000879   
2022-11-25 12:36:53,136 - INFO  - ==> Top1: 89.156    Top5: 98.878    Loss: 0.310

2022-11-25 12:36:53,675 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:36:55,132 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:36:57,851 - INFO  - Validation [21][   20/   40]   Loss 0.302973   Top1 90.839844   Top5 99.589844   BatchTime 0.135883   
2022-11-25 12:36:58,976 - INFO  - Validation [21][   40/   40]   Loss 0.289777   Top1 90.790000   Top5 99.690000   BatchTime 0.096057   
2022-11-25 12:36:59,242 - INFO  - ==> Top1: 90.790    Top5: 99.690    Loss: 0.290

2022-11-25 12:36:59,242 - INFO  - ==> Sparsity : 0.563

2022-11-25 12:36:59,242 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 90.790   Top5: 99.690]
2022-11-25 12:36:59,242 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 90.700   Top5: 99.620]
2022-11-25 12:36:59,242 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.690   Top5: 99.680]
2022-11-25 12:37:06,068 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:37:06,074 - INFO  - >>>>>> Epoch  22
2022-11-25 12:37:06,077 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:37:14,060 - INFO  - Training [22][   20/  196]   Loss 0.317324   Top1 89.003906   Top5 98.554688   BatchTime 0.399020   LR 0.000846   
2022-11-25 12:37:19,276 - INFO  - Training [22][   40/  196]   Loss 0.318478   Top1 88.916016   Top5 98.710938   BatchTime 0.329911   LR 0.000827   
2022-11-25 12:37:25,230 - INFO  - Training [22][   60/  196]   Loss 0.315733   Top1 88.945312   Top5 98.828125   BatchTime 0.319163   LR 0.000808   
2022-11-25 12:37:31,852 - INFO  - Training [22][   80/  196]   Loss 0.314123   Top1 89.028320   Top5 98.964844   BatchTime 0.322152   LR 0.000789   
2022-11-25 12:37:38,819 - INFO  - Training [22][  100/  196]   Loss 0.307565   Top1 89.203125   Top5 99.019531   BatchTime 0.327387   LR 0.000770   
2022-11-25 12:37:45,602 - INFO  - Training [22][  120/  196]   Loss 0.302264   Top1 89.459635   Top5 99.078776   BatchTime 0.329346   LR 0.000752   
2022-11-25 12:37:52,911 - INFO  - Training [22][  140/  196]   Loss 0.300734   Top1 89.497768   Top5 99.126674   BatchTime 0.334502   LR 0.000734   
2022-11-25 12:37:59,823 - INFO  - Training [22][  160/  196]   Loss 0.302081   Top1 89.475098   Top5 99.155273   BatchTime 0.335892   LR 0.000715   
2022-11-25 12:38:06,569 - INFO  - Training [22][  180/  196]   Loss 0.304143   Top1 89.394531   Top5 99.092882   BatchTime 0.336048   LR 0.000697   
2022-11-25 12:38:12,034 - INFO  - ==> Top1: 89.436    Top5: 99.076    Loss: 0.302

2022-11-25 12:38:12,338 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:38:14,106 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:38:16,692 - INFO  - Validation [22][   20/   40]   Loss 0.316053   Top1 90.351562   Top5 99.648438   BatchTime 0.129195   
2022-11-25 12:38:17,875 - INFO  - Validation [22][   40/   40]   Loss 0.305085   Top1 90.510000   Top5 99.700000   BatchTime 0.094181   
2022-11-25 12:38:18,152 - INFO  - ==> Top1: 90.510    Top5: 99.700    Loss: 0.305

2022-11-25 12:38:18,152 - INFO  - ==> Sparsity : 0.563

2022-11-25 12:38:18,153 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 90.790   Top5: 99.690]
2022-11-25 12:38:18,153 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 90.700   Top5: 99.620]
2022-11-25 12:38:18,153 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 90.690   Top5: 99.680]
2022-11-25 12:38:18,286 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:38:18,288 - INFO  - >>>>>> Epoch  23
2022-11-25 12:38:18,290 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:38:27,244 - INFO  - Training [23][   20/  196]   Loss 0.325187   Top1 88.828125   Top5 98.691406   BatchTime 0.447581   LR 0.000666   
2022-11-25 12:38:33,089 - INFO  - Training [23][   40/  196]   Loss 0.321544   Top1 88.613281   Top5 98.769531   BatchTime 0.369925   LR 0.000648   
2022-11-25 12:38:38,394 - INFO  - Training [23][   60/  196]   Loss 0.313215   Top1 88.919271   Top5 98.886719   BatchTime 0.335020   LR 0.000630   
2022-11-25 12:38:45,065 - INFO  - Training [23][   80/  196]   Loss 0.306612   Top1 89.184570   Top5 99.038086   BatchTime 0.334656   LR 0.000613   
2022-11-25 12:38:51,864 - INFO  - Training [23][  100/  196]   Loss 0.299396   Top1 89.457031   Top5 99.062500   BatchTime 0.335718   LR 0.000596   
2022-11-25 12:38:58,770 - INFO  - Training [23][  120/  196]   Loss 0.293948   Top1 89.615885   Top5 99.098307   BatchTime 0.337313   LR 0.000579   
2022-11-25 12:39:05,717 - INFO  - Training [23][  140/  196]   Loss 0.292786   Top1 89.718192   Top5 99.129464   BatchTime 0.338744   LR 0.000562   
2022-11-25 12:39:12,624 - INFO  - Training [23][  160/  196]   Loss 0.294229   Top1 89.658203   Top5 99.106445   BatchTime 0.339569   LR 0.000545   
2022-11-25 12:39:19,205 - INFO  - Training [23][  180/  196]   Loss 0.295826   Top1 89.578993   Top5 99.084201   BatchTime 0.338399   LR 0.000529   
2022-11-25 12:39:24,752 - INFO  - ==> Top1: 89.656    Top5: 99.090    Loss: 0.294

2022-11-25 12:39:25,000 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:39:26,420 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:39:29,020 - INFO  - Validation [23][   20/   40]   Loss 0.283952   Top1 91.093750   Top5 99.726562   BatchTime 0.129913   
2022-11-25 12:39:30,073 - INFO  - Validation [23][   40/   40]   Loss 0.273815   Top1 91.250000   Top5 99.750000   BatchTime 0.091274   
2022-11-25 12:39:30,353 - INFO  - ==> Top1: 91.250    Top5: 99.750    Loss: 0.274

2022-11-25 12:39:30,354 - INFO  - ==> Sparsity : 0.563

2022-11-25 12:39:30,354 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 91.250   Top5: 99.750]
2022-11-25 12:39:30,354 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 90.790   Top5: 99.690]
2022-11-25 12:39:30,354 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.700   Top5: 99.620]
2022-11-25 12:39:35,431 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:39:35,435 - INFO  - >>>>>> Epoch  24
2022-11-25 12:39:35,437 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:39:44,014 - INFO  - Training [24][   20/  196]   Loss 0.318093   Top1 88.964844   Top5 98.613281   BatchTime 0.428731   LR 0.000500   
2022-11-25 12:39:49,908 - INFO  - Training [24][   40/  196]   Loss 0.314463   Top1 89.111328   Top5 98.720703   BatchTime 0.361728   LR 0.000484   
2022-11-25 12:39:55,839 - INFO  - Training [24][   60/  196]   Loss 0.302892   Top1 89.518229   Top5 98.769531   BatchTime 0.339986   LR 0.000468   
2022-11-25 12:40:02,664 - INFO  - Training [24][   80/  196]   Loss 0.302943   Top1 89.526367   Top5 98.881836   BatchTime 0.340310   LR 0.000453   
2022-11-25 12:40:09,614 - INFO  - Training [24][  100/  196]   Loss 0.295683   Top1 89.777344   Top5 98.910156   BatchTime 0.341743   LR 0.000437   
2022-11-25 12:40:16,218 - INFO  - Training [24][  120/  196]   Loss 0.291982   Top1 89.879557   Top5 98.994141   BatchTime 0.339818   LR 0.000422   
2022-11-25 12:40:23,422 - INFO  - Training [24][  140/  196]   Loss 0.288290   Top1 90.002790   Top5 99.051339   BatchTime 0.342733   LR 0.000407   
2022-11-25 12:40:30,544 - INFO  - Training [24][  160/  196]   Loss 0.291501   Top1 89.877930   Top5 99.035645   BatchTime 0.344398   LR 0.000392   
2022-11-25 12:40:37,237 - INFO  - Training [24][  180/  196]   Loss 0.290505   Top1 89.889323   Top5 99.023438   BatchTime 0.343319   LR 0.000378   
2022-11-25 12:40:42,812 - INFO  - ==> Top1: 89.902    Top5: 99.008    Loss: 0.290

2022-11-25 12:40:43,081 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:40:44,564 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:40:47,367 - INFO  - Validation [24][   20/   40]   Loss 0.282023   Top1 91.093750   Top5 99.648438   BatchTime 0.140104   
2022-11-25 12:40:48,487 - INFO  - Validation [24][   40/   40]   Loss 0.269213   Top1 91.570000   Top5 99.730000   BatchTime 0.098033   
2022-11-25 12:40:48,735 - INFO  - ==> Top1: 91.570    Top5: 99.730    Loss: 0.269

2022-11-25 12:40:48,735 - INFO  - ==> Sparsity : 0.563

2022-11-25 12:40:48,736 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:40:48,736 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 91.250   Top5: 99.750]
2022-11-25 12:40:48,736 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 90.790   Top5: 99.690]
2022-11-25 12:40:54,409 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:40:54,415 - INFO  - >>>>>> Epoch  25
2022-11-25 12:40:54,417 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:41:02,729 - INFO  - Training [25][   20/  196]   Loss 0.300837   Top1 89.140625   Top5 98.613281   BatchTime 0.415439   LR 0.000353   
2022-11-25 12:41:08,703 - INFO  - Training [25][   40/  196]   Loss 0.298194   Top1 89.199219   Top5 98.681641   BatchTime 0.357067   LR 0.000339   
2022-11-25 12:41:14,380 - INFO  - Training [25][   60/  196]   Loss 0.290753   Top1 89.557292   Top5 98.795573   BatchTime 0.332662   LR 0.000325   
2022-11-25 12:41:21,274 - INFO  - Training [25][   80/  196]   Loss 0.295770   Top1 89.497070   Top5 98.950195   BatchTime 0.335672   LR 0.000312   
2022-11-25 12:41:28,140 - INFO  - Training [25][  100/  196]   Loss 0.287824   Top1 89.804688   Top5 98.984375   BatchTime 0.337194   LR 0.000299   
2022-11-25 12:41:34,945 - INFO  - Training [25][  120/  196]   Loss 0.281821   Top1 90.084635   Top5 99.069010   BatchTime 0.337703   LR 0.000286   
2022-11-25 12:41:41,543 - INFO  - Training [25][  140/  196]   Loss 0.280276   Top1 90.164621   Top5 99.140625   BatchTime 0.336590   LR 0.000273   
2022-11-25 12:41:48,416 - INFO  - Training [25][  160/  196]   Loss 0.282899   Top1 90.102539   Top5 99.099121   BatchTime 0.337469   LR 0.000261   
2022-11-25 12:41:55,276 - INFO  - Training [25][  180/  196]   Loss 0.283002   Top1 90.112847   Top5 99.066840   BatchTime 0.338087   LR 0.000248   
2022-11-25 12:42:00,880 - INFO  - ==> Top1: 90.116    Top5: 99.066    Loss: 0.282

2022-11-25 12:42:01,121 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:42:02,544 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:42:05,296 - INFO  - Validation [25][   20/   40]   Loss 0.280793   Top1 91.093750   Top5 99.609375   BatchTime 0.137537   
2022-11-25 12:42:06,421 - INFO  - Validation [25][   40/   40]   Loss 0.265257   Top1 91.550000   Top5 99.620000   BatchTime 0.096905   
2022-11-25 12:42:06,659 - INFO  - ==> Top1: 91.550    Top5: 99.620    Loss: 0.265

2022-11-25 12:42:06,659 - INFO  - ==> Sparsity : 0.563

2022-11-25 12:42:06,660 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:42:06,660 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:42:06,660 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 91.250   Top5: 99.750]
2022-11-25 12:42:07,055 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:42:07,057 - INFO  - >>>>>> Epoch  26
2022-11-25 12:42:07,059 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:42:15,182 - INFO  - Training [26][   20/  196]   Loss 0.292384   Top1 89.882812   Top5 98.613281   BatchTime 0.406036   LR 0.000228   
2022-11-25 12:42:21,904 - INFO  - Training [26][   40/  196]   Loss 0.291630   Top1 89.765625   Top5 98.730469   BatchTime 0.371066   LR 0.000216   
2022-11-25 12:42:27,661 - INFO  - Training [26][   60/  196]   Loss 0.287724   Top1 89.759115   Top5 98.776042   BatchTime 0.343322   LR 0.000205   
2022-11-25 12:42:34,184 - INFO  - Training [26][   80/  196]   Loss 0.283118   Top1 89.921875   Top5 98.935547   BatchTime 0.339027   LR 0.000194   
2022-11-25 12:42:41,044 - INFO  - Training [26][  100/  196]   Loss 0.276784   Top1 90.160156   Top5 98.980469   BatchTime 0.339824   LR 0.000183   
2022-11-25 12:42:48,058 - INFO  - Training [26][  120/  196]   Loss 0.273328   Top1 90.305990   Top5 99.036458   BatchTime 0.341630   LR 0.000173   
2022-11-25 12:42:54,987 - INFO  - Training [26][  140/  196]   Loss 0.270600   Top1 90.440848   Top5 99.079241   BatchTime 0.342323   LR 0.000163   
2022-11-25 12:43:01,724 - INFO  - Training [26][  160/  196]   Loss 0.272211   Top1 90.368652   Top5 99.089355   BatchTime 0.341636   LR 0.000153   
2022-11-25 12:43:08,762 - INFO  - Training [26][  180/  196]   Loss 0.271827   Top1 90.434028   Top5 99.090712   BatchTime 0.342777   LR 0.000144   
2022-11-25 12:43:14,252 - INFO  - ==> Top1: 90.446    Top5: 99.086    Loss: 0.271

2022-11-25 12:43:14,529 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:43:15,967 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:43:18,712 - INFO  - Validation [26][   20/   40]   Loss 0.291800   Top1 91.074219   Top5 99.589844   BatchTime 0.137175   
2022-11-25 12:43:19,806 - INFO  - Validation [26][   40/   40]   Loss 0.273662   Top1 91.450000   Top5 99.710000   BatchTime 0.095951   
2022-11-25 12:43:20,093 - INFO  - ==> Top1: 91.450    Top5: 99.710    Loss: 0.274

2022-11-25 12:43:20,094 - INFO  - ==> Sparsity : 0.562

2022-11-25 12:43:20,094 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:43:20,094 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:43:20,095 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 91.450   Top5: 99.710]
2022-11-25 12:43:20,246 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:43:20,248 - INFO  - >>>>>> Epoch  27
2022-11-25 12:43:20,250 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:43:28,729 - INFO  - Training [27][   20/  196]   Loss 0.292989   Top1 89.589844   Top5 98.476562   BatchTime 0.423825   LR 0.000128   
2022-11-25 12:43:35,464 - INFO  - Training [27][   40/  196]   Loss 0.286183   Top1 89.960938   Top5 98.662109   BatchTime 0.380287   LR 0.000119   
2022-11-25 12:43:41,989 - INFO  - Training [27][   60/  196]   Loss 0.281381   Top1 90.169271   Top5 98.802083   BatchTime 0.362270   LR 0.000111   
2022-11-25 12:43:47,095 - INFO  - Training [27][   80/  196]   Loss 0.278852   Top1 90.336914   Top5 98.916016   BatchTime 0.335528   LR 0.000102   
2022-11-25 12:43:53,985 - INFO  - Training [27][  100/  196]   Loss 0.271268   Top1 90.585938   Top5 98.992188   BatchTime 0.337324   LR 0.000095   
2022-11-25 12:44:00,765 - INFO  - Training [27][  120/  196]   Loss 0.267889   Top1 90.686849   Top5 99.078776   BatchTime 0.337601   LR 0.000087   
2022-11-25 12:44:07,636 - INFO  - Training [27][  140/  196]   Loss 0.267611   Top1 90.714286   Top5 99.123884   BatchTime 0.338453   LR 0.000080   
2022-11-25 12:44:14,312 - INFO  - Training [27][  160/  196]   Loss 0.270333   Top1 90.642090   Top5 99.074707   BatchTime 0.337865   LR 0.000073   
2022-11-25 12:44:21,262 - INFO  - Training [27][  180/  196]   Loss 0.270912   Top1 90.594618   Top5 99.055990   BatchTime 0.338939   LR 0.000066   
2022-11-25 12:44:26,942 - INFO  - ==> Top1: 90.654    Top5: 99.058    Loss: 0.270

2022-11-25 12:44:27,184 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:44:28,699 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:44:31,500 - INFO  - Validation [27][   20/   40]   Loss 0.301091   Top1 90.800781   Top5 99.589844   BatchTime 0.139952   
2022-11-25 12:44:32,638 - INFO  - Validation [27][   40/   40]   Loss 0.283924   Top1 91.110000   Top5 99.680000   BatchTime 0.098421   
2022-11-25 12:44:32,854 - INFO  - ==> Top1: 91.110    Top5: 99.680    Loss: 0.284

2022-11-25 12:44:32,854 - INFO  - ==> Sparsity : 0.562

2022-11-25 12:44:32,854 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:44:32,855 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:44:32,855 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 91.450   Top5: 99.710]
2022-11-25 12:44:33,247 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:44:33,248 - INFO  - >>>>>> Epoch  28
2022-11-25 12:44:33,250 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:44:41,819 - INFO  - Training [28][   20/  196]   Loss 0.283556   Top1 90.058594   Top5 98.691406   BatchTime 0.428244   LR 0.000055   
2022-11-25 12:44:48,550 - INFO  - Training [28][   40/  196]   Loss 0.293876   Top1 89.746094   Top5 98.857422   BatchTime 0.382423   LR 0.000050   
2022-11-25 12:44:55,406 - INFO  - Training [28][   60/  196]   Loss 0.286722   Top1 90.019531   Top5 98.938802   BatchTime 0.369219   LR 0.000044   
2022-11-25 12:45:01,552 - INFO  - Training [28][   80/  196]   Loss 0.277898   Top1 90.341797   Top5 99.067383   BatchTime 0.353728   LR 0.000039   
2022-11-25 12:45:06,968 - INFO  - Training [28][  100/  196]   Loss 0.273531   Top1 90.468750   Top5 99.093750   BatchTime 0.337146   LR 0.000034   
2022-11-25 12:45:14,569 - INFO  - Training [28][  120/  196]   Loss 0.268496   Top1 90.608724   Top5 99.134115   BatchTime 0.344292   LR 0.000030   
2022-11-25 12:45:21,446 - INFO  - Training [28][  140/  196]   Loss 0.266618   Top1 90.705915   Top5 99.174107   BatchTime 0.344231   LR 0.000026   
2022-11-25 12:45:28,213 - INFO  - Training [28][  160/  196]   Loss 0.269478   Top1 90.605469   Top5 99.167480   BatchTime 0.343495   LR 0.000022   
2022-11-25 12:45:35,077 - INFO  - Training [28][  180/  196]   Loss 0.270896   Top1 90.555556   Top5 99.138455   BatchTime 0.343464   LR 0.000018   
2022-11-25 12:45:40,557 - INFO  - ==> Top1: 90.578    Top5: 99.114    Loss: 0.270

2022-11-25 12:45:40,833 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:45:42,285 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:45:45,187 - INFO  - Validation [28][   20/   40]   Loss 0.286300   Top1 90.996094   Top5 99.609375   BatchTime 0.145009   
2022-11-25 12:45:46,381 - INFO  - Validation [28][   40/   40]   Loss 0.268916   Top1 91.370000   Top5 99.710000   BatchTime 0.102348   
2022-11-25 12:45:46,692 - INFO  - ==> Top1: 91.370    Top5: 99.710    Loss: 0.269

2022-11-25 12:45:46,692 - INFO  - ==> Sparsity : 0.562

2022-11-25 12:45:46,692 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:45:46,693 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:45:46,693 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 91.450   Top5: 99.710]
2022-11-25 12:45:46,853 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:45:46,855 - INFO  - >>>>>> Epoch  29
2022-11-25 12:45:46,856 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:45:55,117 - INFO  - Training [29][   20/  196]   Loss 0.268942   Top1 90.273438   Top5 98.671875   BatchTime 0.412908   LR 0.000013   
2022-11-25 12:46:01,769 - INFO  - Training [29][   40/  196]   Loss 0.285278   Top1 90.146484   Top5 98.750000   BatchTime 0.372738   LR 0.000010   
2022-11-25 12:46:08,535 - INFO  - Training [29][   60/  196]   Loss 0.282979   Top1 90.221354   Top5 98.880208   BatchTime 0.361256   LR 0.000008   
2022-11-25 12:46:15,421 - INFO  - Training [29][   80/  196]   Loss 0.279742   Top1 90.405273   Top5 99.013672   BatchTime 0.357017   LR 0.000005   
2022-11-25 12:46:20,985 - INFO  - Training [29][  100/  196]   Loss 0.271868   Top1 90.582031   Top5 99.062500   BatchTime 0.341251   LR 0.000004   
2022-11-25 12:46:26,778 - INFO  - Training [29][  120/  196]   Loss 0.268479   Top1 90.751953   Top5 99.111328   BatchTime 0.332655   LR 0.000002   
2022-11-25 12:46:34,109 - INFO  - Training [29][  140/  196]   Loss 0.268233   Top1 90.784040   Top5 99.165737   BatchTime 0.337497   LR 0.000001   
2022-11-25 12:46:40,962 - INFO  - Training [29][  160/  196]   Loss 0.271500   Top1 90.681152   Top5 99.130859   BatchTime 0.338137   LR 0.000001   
2022-11-25 12:46:47,659 - INFO  - Training [29][  180/  196]   Loss 0.272338   Top1 90.603299   Top5 99.092882   BatchTime 0.337773   LR 0.000000   
2022-11-25 12:46:53,123 - INFO  - ==> Top1: 90.644    Top5: 99.074    Loss: 0.272

2022-11-25 12:46:53,408 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:46:54,922 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:46:57,642 - INFO  - Validation [29][   20/   40]   Loss 0.289948   Top1 91.210938   Top5 99.628906   BatchTime 0.135893   
2022-11-25 12:46:58,734 - INFO  - Validation [29][   40/   40]   Loss 0.273547   Top1 91.560000   Top5 99.720000   BatchTime 0.095258   
2022-11-25 12:46:58,989 - INFO  - ==> Top1: 91.560    Top5: 99.720    Loss: 0.274

2022-11-25 12:46:58,989 - INFO  - ==> Sparsity : 0.562

2022-11-25 12:46:58,989 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:46:58,989 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:46:58,989 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:46:59,118 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:46:59,120 - INFO  - >>>>>> Epoch  30
2022-11-25 12:46:59,122 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:47:07,764 - INFO  - Training [30][   20/  196]   Loss 0.300730   Top1 89.082031   Top5 98.476562   BatchTime 0.431912   LR 0.001250   
2022-11-25 12:47:14,492 - INFO  - Training [30][   40/  196]   Loss 0.303096   Top1 89.140625   Top5 98.662109   BatchTime 0.384164   LR 0.001250   
2022-11-25 12:47:21,920 - INFO  - Training [30][   60/  196]   Loss 0.300888   Top1 89.270833   Top5 98.756510   BatchTime 0.379915   LR 0.001250   
2022-11-25 12:47:28,748 - INFO  - Training [30][   80/  196]   Loss 0.302952   Top1 89.233398   Top5 98.891602   BatchTime 0.370280   LR 0.001250   
2022-11-25 12:47:35,420 - INFO  - Training [30][  100/  196]   Loss 0.303044   Top1 89.285156   Top5 98.910156   BatchTime 0.362947   LR 0.001250   
2022-11-25 12:47:40,828 - INFO  - Training [30][  120/  196]   Loss 0.299147   Top1 89.492188   Top5 98.984375   BatchTime 0.347522   LR 0.001249   
2022-11-25 12:47:47,116 - INFO  - Training [30][  140/  196]   Loss 0.295874   Top1 89.598214   Top5 99.068080   BatchTime 0.342788   LR 0.001249   
2022-11-25 12:47:54,830 - INFO  - Training [30][  160/  196]   Loss 0.301196   Top1 89.421387   Top5 99.025879   BatchTime 0.348152   LR 0.001249   
2022-11-25 12:48:01,747 - INFO  - Training [30][  180/  196]   Loss 0.300021   Top1 89.470486   Top5 99.001736   BatchTime 0.347896   LR 0.001248   
2022-11-25 12:48:07,220 - INFO  - ==> Top1: 89.462    Top5: 98.998    Loss: 0.300

2022-11-25 12:48:07,466 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:48:09,030 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:48:11,774 - INFO  - Validation [30][   20/   40]   Loss 0.311933   Top1 90.449219   Top5 99.589844   BatchTime 0.137111   
2022-11-25 12:48:12,928 - INFO  - Validation [30][   40/   40]   Loss 0.298788   Top1 90.590000   Top5 99.640000   BatchTime 0.097418   
2022-11-25 12:48:13,196 - INFO  - ==> Top1: 90.590    Top5: 99.640    Loss: 0.299

2022-11-25 12:48:13,197 - INFO  - ==> Sparsity : 0.563

2022-11-25 12:48:13,197 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:48:13,197 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:48:13,197 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:48:13,343 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:48:13,344 - INFO  - >>>>>> Epoch  31
2022-11-25 12:48:13,346 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:48:21,794 - INFO  - Training [31][   20/  196]   Loss 0.310403   Top1 89.101562   Top5 98.457031   BatchTime 0.422257   LR 0.001248   
2022-11-25 12:48:28,548 - INFO  - Training [31][   40/  196]   Loss 0.307181   Top1 89.072266   Top5 98.779297   BatchTime 0.379976   LR 0.001247   
2022-11-25 12:48:35,649 - INFO  - Training [31][   60/  196]   Loss 0.307749   Top1 88.984375   Top5 98.815104   BatchTime 0.371664   LR 0.001247   
2022-11-25 12:48:42,496 - INFO  - Training [31][   80/  196]   Loss 0.312078   Top1 88.793945   Top5 98.935547   BatchTime 0.364334   LR 0.001246   
2022-11-25 12:48:49,499 - INFO  - Training [31][  100/  196]   Loss 0.306623   Top1 89.070312   Top5 98.976562   BatchTime 0.361494   LR 0.001246   
2022-11-25 12:48:55,845 - INFO  - Training [31][  120/  196]   Loss 0.302374   Top1 89.231771   Top5 99.042969   BatchTime 0.354127   LR 0.001245   
2022-11-25 12:49:00,849 - INFO  - Training [31][  140/  196]   Loss 0.303210   Top1 89.268973   Top5 99.065290   BatchTime 0.339285   LR 0.001244   
2022-11-25 12:49:06,185 - INFO  - Training [31][  160/  196]   Loss 0.306545   Top1 89.165039   Top5 99.028320   BatchTime 0.330222   LR 0.001244   
2022-11-25 12:49:13,345 - INFO  - Training [31][  180/  196]   Loss 0.307750   Top1 89.114583   Top5 98.999566   BatchTime 0.333308   LR 0.001243   
2022-11-25 12:49:18,697 - INFO  - ==> Top1: 89.170    Top5: 98.984    Loss: 0.306

2022-11-25 12:49:18,951 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:49:20,342 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:49:23,086 - INFO  - Validation [31][   20/   40]   Loss 0.294555   Top1 90.976562   Top5 99.687500   BatchTime 0.137075   
2022-11-25 12:49:24,148 - INFO  - Validation [31][   40/   40]   Loss 0.290809   Top1 90.740000   Top5 99.740000   BatchTime 0.095113   
2022-11-25 12:49:24,382 - INFO  - ==> Top1: 90.740    Top5: 99.740    Loss: 0.291

2022-11-25 12:49:24,383 - INFO  - ==> Sparsity : 0.563

2022-11-25 12:49:24,383 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:49:24,383 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:49:24,383 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:49:24,518 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:49:24,520 - INFO  - >>>>>> Epoch  32
2022-11-25 12:49:24,522 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:49:32,933 - INFO  - Training [32][   20/  196]   Loss 0.309225   Top1 88.593750   Top5 98.574219   BatchTime 0.420445   LR 0.001242   
2022-11-25 12:49:39,726 - INFO  - Training [32][   40/  196]   Loss 0.306908   Top1 89.150391   Top5 98.691406   BatchTime 0.380037   LR 0.001241   
2022-11-25 12:49:46,450 - INFO  - Training [32][   60/  196]   Loss 0.307995   Top1 89.186198   Top5 98.710938   BatchTime 0.365429   LR 0.001240   
2022-11-25 12:49:53,765 - INFO  - Training [32][   80/  196]   Loss 0.306934   Top1 89.311523   Top5 98.828125   BatchTime 0.365504   LR 0.001239   
2022-11-25 12:50:00,469 - INFO  - Training [32][  100/  196]   Loss 0.304561   Top1 89.441406   Top5 98.867188   BatchTime 0.359449   LR 0.001238   
2022-11-25 12:50:07,646 - INFO  - Training [32][  120/  196]   Loss 0.296548   Top1 89.684245   Top5 98.961589   BatchTime 0.359350   LR 0.001237   
2022-11-25 12:50:14,545 - INFO  - Training [32][  140/  196]   Loss 0.296938   Top1 89.729353   Top5 99.029018   BatchTime 0.357291   LR 0.001236   
2022-11-25 12:50:20,639 - INFO  - Training [32][  160/  196]   Loss 0.298584   Top1 89.648438   Top5 99.023438   BatchTime 0.350715   LR 0.001235   
2022-11-25 12:50:26,083 - INFO  - Training [32][  180/  196]   Loss 0.300494   Top1 89.555122   Top5 98.956163   BatchTime 0.341989   LR 0.001234   
2022-11-25 12:50:30,432 - INFO  - ==> Top1: 89.552    Top5: 98.934    Loss: 0.300

2022-11-25 12:50:30,713 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:50:32,899 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:50:36,185 - INFO  - Validation [32][   20/   40]   Loss 0.324642   Top1 90.156250   Top5 99.628906   BatchTime 0.164176   
2022-11-25 12:50:37,280 - INFO  - Validation [32][   40/   40]   Loss 0.316818   Top1 90.160000   Top5 99.680000   BatchTime 0.109473   
2022-11-25 12:50:37,573 - INFO  - ==> Top1: 90.160    Top5: 99.680    Loss: 0.317

2022-11-25 12:50:37,574 - INFO  - ==> Sparsity : 0.563

2022-11-25 12:50:37,574 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:50:37,574 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:50:37,574 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:50:37,718 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:50:37,720 - INFO  - >>>>>> Epoch  33
2022-11-25 12:50:37,722 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:50:46,098 - INFO  - Training [33][   20/  196]   Loss 0.324046   Top1 88.378906   Top5 98.613281   BatchTime 0.418644   LR 0.001232   
2022-11-25 12:50:52,768 - INFO  - Training [33][   40/  196]   Loss 0.324977   Top1 88.408203   Top5 98.691406   BatchTime 0.376082   LR 0.001230   
2022-11-25 12:50:59,609 - INFO  - Training [33][   60/  196]   Loss 0.317161   Top1 88.723958   Top5 98.756510   BatchTime 0.364733   LR 0.001229   
2022-11-25 12:51:06,277 - INFO  - Training [33][   80/  196]   Loss 0.311118   Top1 88.984375   Top5 98.857422   BatchTime 0.356902   LR 0.001228   
2022-11-25 12:51:12,867 - INFO  - Training [33][  100/  196]   Loss 0.302390   Top1 89.250000   Top5 98.941406   BatchTime 0.351416   LR 0.001226   
2022-11-25 12:51:19,544 - INFO  - Training [33][  120/  196]   Loss 0.301539   Top1 89.329427   Top5 98.987630   BatchTime 0.348485   LR 0.001225   
2022-11-25 12:51:26,425 - INFO  - Training [33][  140/  196]   Loss 0.300098   Top1 89.425223   Top5 99.029018   BatchTime 0.347855   LR 0.001224   
2022-11-25 12:51:33,311 - INFO  - Training [33][  160/  196]   Loss 0.301598   Top1 89.362793   Top5 99.023438   BatchTime 0.347409   LR 0.001222   
2022-11-25 12:51:40,223 - INFO  - Training [33][  180/  196]   Loss 0.303874   Top1 89.318576   Top5 98.975694   BatchTime 0.347206   LR 0.001221   
2022-11-25 12:51:45,527 - INFO  - ==> Top1: 89.286    Top5: 98.964    Loss: 0.304

2022-11-25 12:51:45,736 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:51:46,928 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:51:51,561 - INFO  - Validation [33][   20/   40]   Loss 0.377517   Top1 89.218750   Top5 99.531250   BatchTime 0.231588   
2022-11-25 12:51:54,398 - INFO  - Validation [33][   40/   40]   Loss 0.372696   Top1 88.830000   Top5 99.600000   BatchTime 0.186714   
2022-11-25 12:51:55,045 - INFO  - ==> Top1: 88.830    Top5: 99.600    Loss: 0.373

2022-11-25 12:51:55,045 - INFO  - ==> Sparsity : 0.564

2022-11-25 12:51:55,045 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:51:55,046 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:51:55,046 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:51:55,231 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:51:55,234 - INFO  - >>>>>> Epoch  34
2022-11-25 12:51:55,237 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:52:04,276 - INFO  - Training [34][   20/  196]   Loss 0.320275   Top1 88.945312   Top5 98.378906   BatchTime 0.451661   LR 0.001218   
2022-11-25 12:52:10,990 - INFO  - Training [34][   40/  196]   Loss 0.315969   Top1 88.925781   Top5 98.681641   BatchTime 0.393698   LR 0.001216   
2022-11-25 12:52:17,667 - INFO  - Training [34][   60/  196]   Loss 0.317134   Top1 89.055990   Top5 98.717448   BatchTime 0.373739   LR 0.001215   
2022-11-25 12:52:24,552 - INFO  - Training [34][   80/  196]   Loss 0.313496   Top1 89.238281   Top5 98.867188   BatchTime 0.366372   LR 0.001213   
2022-11-25 12:52:31,812 - INFO  - Training [34][  100/  196]   Loss 0.308710   Top1 89.335938   Top5 98.917969   BatchTime 0.365690   LR 0.001211   
2022-11-25 12:52:38,420 - INFO  - Training [34][  120/  196]   Loss 0.300968   Top1 89.557292   Top5 99.003906   BatchTime 0.359809   LR 0.001209   
2022-11-25 12:52:44,932 - INFO  - Training [34][  140/  196]   Loss 0.299467   Top1 89.598214   Top5 99.082031   BatchTime 0.354926   LR 0.001208   
2022-11-25 12:52:51,757 - INFO  - Training [34][  160/  196]   Loss 0.301364   Top1 89.521484   Top5 99.079590   BatchTime 0.353213   LR 0.001206   
2022-11-25 12:52:58,602 - INFO  - Training [34][  180/  196]   Loss 0.301484   Top1 89.498698   Top5 99.023438   BatchTime 0.351994   LR 0.001204   
2022-11-25 12:53:04,049 - INFO  - ==> Top1: 89.548    Top5: 99.028    Loss: 0.299

2022-11-25 12:53:04,374 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:53:05,954 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:53:08,665 - INFO  - Validation [34][   20/   40]   Loss 0.332281   Top1 90.019531   Top5 99.570312   BatchTime 0.135475   
2022-11-25 12:53:09,700 - INFO  - Validation [34][   40/   40]   Loss 0.323838   Top1 89.860000   Top5 99.690000   BatchTime 0.093617   
2022-11-25 12:53:09,951 - INFO  - ==> Top1: 89.860    Top5: 99.690    Loss: 0.324

2022-11-25 12:53:09,952 - INFO  - ==> Sparsity : 0.565

2022-11-25 12:53:09,952 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:53:09,952 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:53:09,952 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:53:10,084 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:53:10,086 - INFO  - >>>>>> Epoch  35
2022-11-25 12:53:10,088 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:53:17,946 - INFO  - Training [35][   20/  196]   Loss 0.323783   Top1 88.671875   Top5 98.457031   BatchTime 0.392769   LR 0.001201   
2022-11-25 12:53:24,556 - INFO  - Training [35][   40/  196]   Loss 0.323800   Top1 88.574219   Top5 98.652344   BatchTime 0.361623   LR 0.001199   
2022-11-25 12:53:31,417 - INFO  - Training [35][   60/  196]   Loss 0.314253   Top1 88.867188   Top5 98.743490   BatchTime 0.355438   LR 0.001197   
2022-11-25 12:53:38,131 - INFO  - Training [35][   80/  196]   Loss 0.311210   Top1 89.062500   Top5 98.881836   BatchTime 0.350505   LR 0.001195   
2022-11-25 12:53:44,788 - INFO  - Training [35][  100/  196]   Loss 0.305121   Top1 89.296875   Top5 98.945312   BatchTime 0.346966   LR 0.001192   
2022-11-25 12:53:51,448 - INFO  - Training [35][  120/  196]   Loss 0.297919   Top1 89.531250   Top5 98.994141   BatchTime 0.344642   LR 0.001190   
2022-11-25 12:53:58,253 - INFO  - Training [35][  140/  196]   Loss 0.299266   Top1 89.511719   Top5 99.062500   BatchTime 0.344013   LR 0.001188   
2022-11-25 12:54:05,328 - INFO  - Training [35][  160/  196]   Loss 0.301468   Top1 89.477539   Top5 99.060059   BatchTime 0.345225   LR 0.001186   
2022-11-25 12:54:12,116 - INFO  - Training [35][  180/  196]   Loss 0.300605   Top1 89.494358   Top5 99.036458   BatchTime 0.344582   LR 0.001184   
2022-11-25 12:54:17,644 - INFO  - ==> Top1: 89.422    Top5: 99.022    Loss: 0.302

2022-11-25 12:54:17,891 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:54:19,353 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:54:22,083 - INFO  - Validation [35][   20/   40]   Loss 0.372785   Top1 89.570312   Top5 99.511719   BatchTime 0.136414   
2022-11-25 12:54:23,221 - INFO  - Validation [35][   40/   40]   Loss 0.361641   Top1 89.400000   Top5 99.610000   BatchTime 0.096659   
2022-11-25 12:54:23,496 - INFO  - ==> Top1: 89.400    Top5: 99.610    Loss: 0.362

2022-11-25 12:54:23,496 - INFO  - ==> Sparsity : 0.566

2022-11-25 12:54:23,496 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:54:23,497 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:54:23,497 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:54:23,628 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:54:23,630 - INFO  - >>>>>> Epoch  36
2022-11-25 12:54:23,632 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:54:30,698 - INFO  - Training [36][   20/  196]   Loss 0.306138   Top1 89.433594   Top5 98.671875   BatchTime 0.353151   LR 0.001180   
2022-11-25 12:54:36,247 - INFO  - Training [36][   40/  196]   Loss 0.308310   Top1 89.316406   Top5 98.730469   BatchTime 0.315303   LR 0.001177   
2022-11-25 12:54:41,399 - INFO  - Training [36][   60/  196]   Loss 0.308000   Top1 89.355469   Top5 98.867188   BatchTime 0.296080   LR 0.001175   
2022-11-25 12:54:48,251 - INFO  - Training [36][   80/  196]   Loss 0.305209   Top1 89.389648   Top5 98.950195   BatchTime 0.307709   LR 0.001173   
2022-11-25 12:54:54,947 - INFO  - Training [36][  100/  196]   Loss 0.301750   Top1 89.554688   Top5 98.949219   BatchTime 0.313127   LR 0.001170   
2022-11-25 12:55:01,692 - INFO  - Training [36][  120/  196]   Loss 0.295102   Top1 89.798177   Top5 99.016927   BatchTime 0.317145   LR 0.001168   
2022-11-25 12:55:08,813 - INFO  - Training [36][  140/  196]   Loss 0.294277   Top1 89.818638   Top5 99.073661   BatchTime 0.322698   LR 0.001165   
2022-11-25 12:55:15,806 - INFO  - Training [36][  160/  196]   Loss 0.295866   Top1 89.733887   Top5 99.057617   BatchTime 0.326070   LR 0.001163   
2022-11-25 12:55:22,634 - INFO  - Training [36][  180/  196]   Loss 0.297836   Top1 89.665799   Top5 99.025608   BatchTime 0.327772   LR 0.001160   
2022-11-25 12:55:28,304 - INFO  - ==> Top1: 89.748    Top5: 99.018    Loss: 0.296

2022-11-25 12:55:28,550 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:55:30,068 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:55:33,087 - INFO  - Validation [36][   20/   40]   Loss 0.326282   Top1 90.175781   Top5 99.570312   BatchTime 0.150843   
2022-11-25 12:55:34,212 - INFO  - Validation [36][   40/   40]   Loss 0.323947   Top1 90.330000   Top5 99.670000   BatchTime 0.103579   
2022-11-25 12:55:34,543 - INFO  - ==> Top1: 90.330    Top5: 99.670    Loss: 0.324

2022-11-25 12:55:34,543 - INFO  - ==> Sparsity : 0.566

2022-11-25 12:55:34,544 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:55:34,544 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:55:34,544 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:55:34,704 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:55:34,706 - INFO  - >>>>>> Epoch  37
2022-11-25 12:55:34,708 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:55:43,287 - INFO  - Training [37][   20/  196]   Loss 0.317916   Top1 89.277344   Top5 98.457031   BatchTime 0.428783   LR 0.001155   
2022-11-25 12:55:49,027 - INFO  - Training [37][   40/  196]   Loss 0.314660   Top1 89.316406   Top5 98.632812   BatchTime 0.357874   LR 0.001153   
2022-11-25 12:55:54,951 - INFO  - Training [37][   60/  196]   Loss 0.306970   Top1 89.498698   Top5 98.750000   BatchTime 0.337328   LR 0.001150   
2022-11-25 12:55:59,838 - INFO  - Training [37][   80/  196]   Loss 0.303088   Top1 89.555664   Top5 98.891602   BatchTime 0.314075   LR 0.001147   
2022-11-25 12:56:06,469 - INFO  - Training [37][  100/  196]   Loss 0.298783   Top1 89.652344   Top5 98.972656   BatchTime 0.317568   LR 0.001144   
2022-11-25 12:56:13,155 - INFO  - Training [37][  120/  196]   Loss 0.292692   Top1 89.843750   Top5 99.026693   BatchTime 0.320362   LR 0.001142   
2022-11-25 12:56:19,779 - INFO  - Training [37][  140/  196]   Loss 0.292277   Top1 89.832589   Top5 99.073661   BatchTime 0.321907   LR 0.001139   
2022-11-25 12:56:26,788 - INFO  - Training [37][  160/  196]   Loss 0.294923   Top1 89.797363   Top5 99.072266   BatchTime 0.325471   LR 0.001136   
2022-11-25 12:56:33,612 - INFO  - Training [37][  180/  196]   Loss 0.297190   Top1 89.722222   Top5 99.027778   BatchTime 0.327223   LR 0.001133   
2022-11-25 12:56:39,075 - INFO  - ==> Top1: 89.720    Top5: 99.046    Loss: 0.296

2022-11-25 12:56:39,322 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:56:40,829 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:56:45,595 - INFO  - Validation [37][   20/   40]   Loss 0.324796   Top1 90.058594   Top5 99.609375   BatchTime 0.238224   
2022-11-25 12:56:46,735 - INFO  - Validation [37][   40/   40]   Loss 0.316744   Top1 90.130000   Top5 99.710000   BatchTime 0.147606   
2022-11-25 12:56:46,987 - INFO  - ==> Top1: 90.130    Top5: 99.710    Loss: 0.317

2022-11-25 12:56:46,988 - INFO  - ==> Sparsity : 0.567

2022-11-25 12:56:46,988 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:56:46,988 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:56:46,988 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:56:47,121 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:56:47,122 - INFO  - >>>>>> Epoch  38
2022-11-25 12:56:47,124 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:56:55,743 - INFO  - Training [38][   20/  196]   Loss 0.307303   Top1 89.394531   Top5 98.789062   BatchTime 0.430826   LR 0.001128   
2022-11-25 12:57:02,469 - INFO  - Training [38][   40/  196]   Loss 0.305526   Top1 89.404297   Top5 99.023438   BatchTime 0.383563   LR 0.001125   
2022-11-25 12:57:08,095 - INFO  - Training [38][   60/  196]   Loss 0.299715   Top1 89.433594   Top5 99.029948   BatchTime 0.349471   LR 0.001122   
2022-11-25 12:57:14,423 - INFO  - Training [38][   80/  196]   Loss 0.299827   Top1 89.404297   Top5 99.077148   BatchTime 0.341195   LR 0.001119   
2022-11-25 12:57:21,503 - INFO  - Training [38][  100/  196]   Loss 0.294245   Top1 89.589844   Top5 99.085938   BatchTime 0.343758   LR 0.001116   
2022-11-25 12:57:28,378 - INFO  - Training [38][  120/  196]   Loss 0.292932   Top1 89.700521   Top5 99.111328   BatchTime 0.343754   LR 0.001112   
2022-11-25 12:57:35,126 - INFO  - Training [38][  140/  196]   Loss 0.291919   Top1 89.701451   Top5 99.143415   BatchTime 0.342846   LR 0.001109   
2022-11-25 12:57:41,747 - INFO  - Training [38][  160/  196]   Loss 0.294257   Top1 89.719238   Top5 99.106445   BatchTime 0.341374   LR 0.001106   
2022-11-25 12:57:48,611 - INFO  - Training [38][  180/  196]   Loss 0.296799   Top1 89.667969   Top5 99.069010   BatchTime 0.341576   LR 0.001103   
2022-11-25 12:57:54,187 - INFO  - ==> Top1: 89.696    Top5: 99.034    Loss: 0.296

2022-11-25 12:57:54,435 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:57:55,928 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:57:58,736 - INFO  - Validation [38][   20/   40]   Loss 0.305963   Top1 90.039062   Top5 99.707031   BatchTime 0.140326   
2022-11-25 12:57:59,905 - INFO  - Validation [38][   40/   40]   Loss 0.294342   Top1 90.610000   Top5 99.780000   BatchTime 0.099388   
2022-11-25 12:58:00,150 - INFO  - ==> Top1: 90.610    Top5: 99.780    Loss: 0.294

2022-11-25 12:58:00,150 - INFO  - ==> Sparsity : 0.567

2022-11-25 12:58:00,151 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:58:00,151 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:58:00,151 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:58:00,282 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:58:00,283 - INFO  - >>>>>> Epoch  39
2022-11-25 12:58:00,285 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:58:08,876 - INFO  - Training [39][   20/  196]   Loss 0.305595   Top1 89.101562   Top5 98.847656   BatchTime 0.429424   LR 0.001097   
2022-11-25 12:58:15,641 - INFO  - Training [39][   40/  196]   Loss 0.310769   Top1 89.042969   Top5 98.906250   BatchTime 0.383822   LR 0.001094   
2022-11-25 12:58:21,864 - INFO  - Training [39][   60/  196]   Loss 0.308230   Top1 89.218750   Top5 98.932292   BatchTime 0.359597   LR 0.001090   
2022-11-25 12:58:27,153 - INFO  - Training [39][   80/  196]   Loss 0.309704   Top1 89.062500   Top5 98.989258   BatchTime 0.335808   LR 0.001087   
2022-11-25 12:58:33,621 - INFO  - Training [39][  100/  196]   Loss 0.300668   Top1 89.410156   Top5 98.984375   BatchTime 0.333327   LR 0.001084   
2022-11-25 12:58:40,444 - INFO  - Training [39][  120/  196]   Loss 0.296563   Top1 89.567057   Top5 99.049479   BatchTime 0.334634   LR 0.001080   
2022-11-25 12:58:47,187 - INFO  - Training [39][  140/  196]   Loss 0.296394   Top1 89.592634   Top5 99.076451   BatchTime 0.334992   LR 0.001077   
2022-11-25 12:58:53,985 - INFO  - Training [39][  160/  196]   Loss 0.296426   Top1 89.619141   Top5 99.074707   BatchTime 0.335603   LR 0.001073   
2022-11-25 12:59:00,807 - INFO  - Training [39][  180/  196]   Loss 0.294811   Top1 89.676649   Top5 99.032118   BatchTime 0.336215   LR 0.001070   
2022-11-25 12:59:06,221 - INFO  - ==> Top1: 89.690    Top5: 99.016    Loss: 0.294

2022-11-25 12:59:06,500 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:59:08,017 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:59:10,703 - INFO  - Validation [39][   20/   40]   Loss 0.301817   Top1 90.644531   Top5 99.726562   BatchTime 0.134209   
2022-11-25 12:59:11,832 - INFO  - Validation [39][   40/   40]   Loss 0.289664   Top1 91.040000   Top5 99.790000   BatchTime 0.095332   
2022-11-25 12:59:12,101 - INFO  - ==> Top1: 91.040    Top5: 99.790    Loss: 0.290

2022-11-25 12:59:12,102 - INFO  - ==> Sparsity : 0.567

2022-11-25 12:59:12,102 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 12:59:12,102 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 12:59:12,102 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 12:59:12,244 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:59:12,246 - INFO  - >>>>>> Epoch  40
2022-11-25 12:59:12,249 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:59:21,075 - INFO  - Training [40][   20/  196]   Loss 0.313153   Top1 88.847656   Top5 98.339844   BatchTime 0.441098   LR 0.001064   
2022-11-25 12:59:27,790 - INFO  - Training [40][   40/  196]   Loss 0.304492   Top1 89.160156   Top5 98.671875   BatchTime 0.388450   LR 0.001060   
2022-11-25 12:59:34,642 - INFO  - Training [40][   60/  196]   Loss 0.301678   Top1 89.348958   Top5 98.723958   BatchTime 0.373163   LR 0.001056   
2022-11-25 12:59:39,942 - INFO  - Training [40][   80/  196]   Loss 0.295688   Top1 89.580078   Top5 98.881836   BatchTime 0.346119   LR 0.001053   
2022-11-25 12:59:45,807 - INFO  - Training [40][  100/  196]   Loss 0.289082   Top1 89.789062   Top5 98.933594   BatchTime 0.335543   LR 0.001049   
2022-11-25 12:59:53,114 - INFO  - Training [40][  120/  196]   Loss 0.284763   Top1 89.931641   Top5 99.013672   BatchTime 0.340512   LR 0.001045   
2022-11-25 12:59:59,832 - INFO  - Training [40][  140/  196]   Loss 0.280937   Top1 90.027902   Top5 99.082031   BatchTime 0.339852   LR 0.001042   
2022-11-25 13:00:06,632 - INFO  - Training [40][  160/  196]   Loss 0.284771   Top1 89.924316   Top5 99.072266   BatchTime 0.339866   LR 0.001038   
2022-11-25 13:00:13,510 - INFO  - Training [40][  180/  196]   Loss 0.287441   Top1 89.865451   Top5 99.038628   BatchTime 0.340316   LR 0.001034   
2022-11-25 13:00:19,115 - INFO  - ==> Top1: 89.890    Top5: 99.036    Loss: 0.288

2022-11-25 13:00:19,346 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:00:20,768 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:00:23,698 - INFO  - Validation [40][   20/   40]   Loss 0.297091   Top1 90.859375   Top5 99.648438   BatchTime 0.146406   
2022-11-25 13:00:24,808 - INFO  - Validation [40][   40/   40]   Loss 0.285325   Top1 91.160000   Top5 99.720000   BatchTime 0.100970   
2022-11-25 13:00:25,142 - INFO  - ==> Top1: 91.160    Top5: 99.720    Loss: 0.285

2022-11-25 13:00:25,142 - INFO  - ==> Sparsity : 0.567

2022-11-25 13:00:25,143 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:00:25,143 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:00:25,143 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 13:00:25,276 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:00:25,278 - INFO  - >>>>>> Epoch  41
2022-11-25 13:00:25,280 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:00:33,935 - INFO  - Training [41][   20/  196]   Loss 0.313998   Top1 88.750000   Top5 98.515625   BatchTime 0.432628   LR 0.001027   
2022-11-25 13:00:40,637 - INFO  - Training [41][   40/  196]   Loss 0.306522   Top1 88.994141   Top5 98.847656   BatchTime 0.383861   LR 0.001023   
2022-11-25 13:00:47,312 - INFO  - Training [41][   60/  196]   Loss 0.301766   Top1 89.244792   Top5 98.886719   BatchTime 0.367158   LR 0.001020   
2022-11-25 13:00:52,702 - INFO  - Training [41][   80/  196]   Loss 0.295174   Top1 89.565430   Top5 99.018555   BatchTime 0.342739   LR 0.001016   
2022-11-25 13:00:58,728 - INFO  - Training [41][  100/  196]   Loss 0.287279   Top1 89.929688   Top5 99.089844   BatchTime 0.334451   LR 0.001012   
2022-11-25 13:01:05,389 - INFO  - Training [41][  120/  196]   Loss 0.283079   Top1 90.126953   Top5 99.117839   BatchTime 0.334217   LR 0.001008   
2022-11-25 13:01:12,619 - INFO  - Training [41][  140/  196]   Loss 0.282271   Top1 90.167411   Top5 99.174107   BatchTime 0.338112   LR 0.001004   
2022-11-25 13:01:19,265 - INFO  - Training [41][  160/  196]   Loss 0.287574   Top1 89.970703   Top5 99.140625   BatchTime 0.337385   LR 0.001000   
2022-11-25 13:01:26,008 - INFO  - Training [41][  180/  196]   Loss 0.288060   Top1 89.969618   Top5 99.114583   BatchTime 0.337358   LR 0.000996   
2022-11-25 13:01:31,607 - INFO  - ==> Top1: 89.978    Top5: 99.106    Loss: 0.288

2022-11-25 13:01:31,858 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:01:33,219 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:01:36,180 - INFO  - Validation [41][   20/   40]   Loss 0.309785   Top1 90.488281   Top5 99.609375   BatchTime 0.147977   
2022-11-25 13:01:37,289 - INFO  - Validation [41][   40/   40]   Loss 0.293482   Top1 90.920000   Top5 99.720000   BatchTime 0.101707   
2022-11-25 13:01:37,579 - INFO  - ==> Top1: 90.920    Top5: 99.720    Loss: 0.293

2022-11-25 13:01:37,580 - INFO  - ==> Sparsity : 0.568

2022-11-25 13:01:37,580 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:01:37,580 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:01:37,580 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 13:01:37,723 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:01:37,725 - INFO  - >>>>>> Epoch  42
2022-11-25 13:01:37,727 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:01:46,579 - INFO  - Training [42][   20/  196]   Loss 0.308764   Top1 88.867188   Top5 98.691406   BatchTime 0.442459   LR 0.000988   
2022-11-25 13:01:53,633 - INFO  - Training [42][   40/  196]   Loss 0.308008   Top1 89.062500   Top5 98.701172   BatchTime 0.397600   LR 0.000984   
2022-11-25 13:02:00,132 - INFO  - Training [42][   60/  196]   Loss 0.302466   Top1 89.381510   Top5 98.789062   BatchTime 0.373371   LR 0.000980   
2022-11-25 13:02:05,622 - INFO  - Training [42][   80/  196]   Loss 0.298030   Top1 89.536133   Top5 98.920898   BatchTime 0.348655   LR 0.000976   
2022-11-25 13:02:11,264 - INFO  - Training [42][  100/  196]   Loss 0.293632   Top1 89.765625   Top5 98.898438   BatchTime 0.335341   LR 0.000972   
2022-11-25 13:02:17,824 - INFO  - Training [42][  120/  196]   Loss 0.288129   Top1 89.928385   Top5 99.003906   BatchTime 0.334121   LR 0.000968   
2022-11-25 13:02:24,471 - INFO  - Training [42][  140/  196]   Loss 0.283260   Top1 90.083705   Top5 99.076451   BatchTime 0.333864   LR 0.000964   
2022-11-25 13:02:31,836 - INFO  - Training [42][  160/  196]   Loss 0.284530   Top1 90.031738   Top5 99.057617   BatchTime 0.338162   LR 0.000959   
2022-11-25 13:02:38,476 - INFO  - Training [42][  180/  196]   Loss 0.283765   Top1 90.056424   Top5 99.008247   BatchTime 0.337479   LR 0.000955   
2022-11-25 13:02:44,140 - INFO  - ==> Top1: 90.130    Top5: 99.002    Loss: 0.281

2022-11-25 13:02:44,388 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:02:45,756 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:02:48,634 - INFO  - Validation [42][   20/   40]   Loss 0.286513   Top1 91.171875   Top5 99.628906   BatchTime 0.143783   
2022-11-25 13:02:49,754 - INFO  - Validation [42][   40/   40]   Loss 0.280739   Top1 91.400000   Top5 99.730000   BatchTime 0.099896   
2022-11-25 13:02:50,039 - INFO  - ==> Top1: 91.400    Top5: 99.730    Loss: 0.281

2022-11-25 13:02:50,040 - INFO  - ==> Sparsity : 0.568

2022-11-25 13:02:50,040 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:02:50,040 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:02:50,040 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 13:02:50,187 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:02:50,189 - INFO  - >>>>>> Epoch  43
2022-11-25 13:02:50,191 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:02:59,139 - INFO  - Training [43][   20/  196]   Loss 0.292900   Top1 89.238281   Top5 98.554688   BatchTime 0.447265   LR 0.000947   
2022-11-25 13:03:06,047 - INFO  - Training [43][   40/  196]   Loss 0.292475   Top1 89.384766   Top5 98.779297   BatchTime 0.396344   LR 0.000943   
2022-11-25 13:03:12,811 - INFO  - Training [43][   60/  196]   Loss 0.290152   Top1 89.537760   Top5 98.873698   BatchTime 0.376964   LR 0.000939   
2022-11-25 13:03:18,689 - INFO  - Training [43][   80/  196]   Loss 0.285407   Top1 89.672852   Top5 99.038086   BatchTime 0.356201   LR 0.000934   
2022-11-25 13:03:24,541 - INFO  - Training [43][  100/  196]   Loss 0.279108   Top1 89.933594   Top5 99.093750   BatchTime 0.343472   LR 0.000930   
2022-11-25 13:03:31,302 - INFO  - Training [43][  120/  196]   Loss 0.273609   Top1 90.139974   Top5 99.147135   BatchTime 0.342570   LR 0.000926   
2022-11-25 13:03:38,121 - INFO  - Training [43][  140/  196]   Loss 0.274010   Top1 90.170201   Top5 99.168527   BatchTime 0.342342   LR 0.000921   
2022-11-25 13:03:44,970 - INFO  - Training [43][  160/  196]   Loss 0.276391   Top1 90.144043   Top5 99.160156   BatchTime 0.342349   LR 0.000917   
2022-11-25 13:03:52,116 - INFO  - Training [43][  180/  196]   Loss 0.276502   Top1 90.164931   Top5 99.108073   BatchTime 0.344010   LR 0.000912   
2022-11-25 13:03:57,740 - INFO  - ==> Top1: 90.170    Top5: 99.098    Loss: 0.276

2022-11-25 13:03:58,034 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:03:59,556 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:04:02,635 - INFO  - Validation [43][   20/   40]   Loss 0.288585   Top1 91.367188   Top5 99.726562   BatchTime 0.153824   
2022-11-25 13:04:03,784 - INFO  - Validation [43][   40/   40]   Loss 0.277477   Top1 91.440000   Top5 99.740000   BatchTime 0.105649   
2022-11-25 13:04:04,046 - INFO  - ==> Top1: 91.440    Top5: 99.740    Loss: 0.277

2022-11-25 13:04:04,046 - INFO  - ==> Sparsity : 0.568

2022-11-25 13:04:04,047 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:04:04,047 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:04:04,047 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 13:04:04,195 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:04:04,197 - INFO  - >>>>>> Epoch  44
2022-11-25 13:04:04,199 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:04:13,065 - INFO  - Training [44][   20/  196]   Loss 0.292202   Top1 89.199219   Top5 98.613281   BatchTime 0.443186   LR 0.000904   
2022-11-25 13:04:20,108 - INFO  - Training [44][   40/  196]   Loss 0.292041   Top1 89.599609   Top5 98.974609   BatchTime 0.397650   LR 0.000900   
2022-11-25 13:04:26,870 - INFO  - Training [44][   60/  196]   Loss 0.291762   Top1 89.759115   Top5 98.938802   BatchTime 0.377798   LR 0.000895   
2022-11-25 13:04:32,244 - INFO  - Training [44][   80/  196]   Loss 0.286632   Top1 89.838867   Top5 99.047852   BatchTime 0.350521   LR 0.000891   
2022-11-25 13:04:38,062 - INFO  - Training [44][  100/  196]   Loss 0.280060   Top1 90.082031   Top5 99.101562   BatchTime 0.338598   LR 0.000886   
2022-11-25 13:04:44,903 - INFO  - Training [44][  120/  196]   Loss 0.273602   Top1 90.325521   Top5 99.179688   BatchTime 0.339175   LR 0.000882   
2022-11-25 13:04:51,725 - INFO  - Training [44][  140/  196]   Loss 0.269788   Top1 90.452009   Top5 99.224330   BatchTime 0.339446   LR 0.000877   
2022-11-25 13:04:58,417 - INFO  - Training [44][  160/  196]   Loss 0.271321   Top1 90.415039   Top5 99.196777   BatchTime 0.338842   LR 0.000873   
2022-11-25 13:05:05,075 - INFO  - Training [44][  180/  196]   Loss 0.272962   Top1 90.310330   Top5 99.160156   BatchTime 0.338179   LR 0.000868   
2022-11-25 13:05:11,250 - INFO  - ==> Top1: 90.324    Top5: 99.148    Loss: 0.273

2022-11-25 13:05:11,524 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:05:13,076 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:05:16,281 - INFO  - Validation [44][   20/   40]   Loss 0.297759   Top1 90.898438   Top5 99.765625   BatchTime 0.160176   
2022-11-25 13:05:17,414 - INFO  - Validation [44][   40/   40]   Loss 0.289424   Top1 90.940000   Top5 99.810000   BatchTime 0.108411   
2022-11-25 13:05:17,674 - INFO  - ==> Top1: 90.940    Top5: 99.810    Loss: 0.289

2022-11-25 13:05:17,674 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:05:17,675 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:05:17,675 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:05:17,675 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 13:05:17,803 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:05:17,805 - INFO  - >>>>>> Epoch  45
2022-11-25 13:05:17,807 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:05:27,053 - INFO  - Training [45][   20/  196]   Loss 0.281103   Top1 89.941406   Top5 98.789062   BatchTime 0.462208   LR 0.000860   
2022-11-25 13:05:34,050 - INFO  - Training [45][   40/  196]   Loss 0.286010   Top1 90.146484   Top5 98.818359   BatchTime 0.406013   LR 0.000855   
2022-11-25 13:05:40,666 - INFO  - Training [45][   60/  196]   Loss 0.286305   Top1 90.136719   Top5 98.815104   BatchTime 0.380953   LR 0.000850   
2022-11-25 13:05:46,284 - INFO  - Training [45][   80/  196]   Loss 0.283910   Top1 90.209961   Top5 98.989258   BatchTime 0.355927   LR 0.000846   
2022-11-25 13:05:52,525 - INFO  - Training [45][  100/  196]   Loss 0.277666   Top1 90.421875   Top5 99.070312   BatchTime 0.347151   LR 0.000841   
2022-11-25 13:05:59,283 - INFO  - Training [45][  120/  196]   Loss 0.271497   Top1 90.566406   Top5 99.121094   BatchTime 0.345604   LR 0.000836   
2022-11-25 13:06:06,024 - INFO  - Training [45][  140/  196]   Loss 0.270358   Top1 90.638951   Top5 99.151786   BatchTime 0.344389   LR 0.000832   
2022-11-25 13:06:12,651 - INFO  - Training [45][  160/  196]   Loss 0.272297   Top1 90.573730   Top5 99.138184   BatchTime 0.342757   LR 0.000827   
2022-11-25 13:06:19,527 - INFO  - Training [45][  180/  196]   Loss 0.271457   Top1 90.542535   Top5 99.129774   BatchTime 0.342871   LR 0.000822   
2022-11-25 13:06:25,544 - INFO  - ==> Top1: 90.528    Top5: 99.128    Loss: 0.272

2022-11-25 13:06:25,794 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:06:27,263 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:06:30,365 - INFO  - Validation [45][   20/   40]   Loss 0.302261   Top1 90.859375   Top5 99.589844   BatchTime 0.155012   
2022-11-25 13:06:31,442 - INFO  - Validation [45][   40/   40]   Loss 0.293105   Top1 91.060000   Top5 99.690000   BatchTime 0.104428   
2022-11-25 13:06:31,670 - INFO  - ==> Top1: 91.060    Top5: 99.690    Loss: 0.293

2022-11-25 13:06:31,671 - INFO  - ==> Sparsity : 0.568

2022-11-25 13:06:31,671 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:06:31,671 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:06:31,671 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 91.550   Top5: 99.620]
2022-11-25 13:06:31,798 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:06:31,799 - INFO  - >>>>>> Epoch  46
2022-11-25 13:06:31,801 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:06:40,910 - INFO  - Training [46][   20/  196]   Loss 0.271058   Top1 90.214844   Top5 98.808594   BatchTime 0.455302   LR 0.000814   
2022-11-25 13:06:47,734 - INFO  - Training [46][   40/  196]   Loss 0.278608   Top1 90.107422   Top5 98.876953   BatchTime 0.398253   LR 0.000809   
2022-11-25 13:06:54,596 - INFO  - Training [46][   60/  196]   Loss 0.278238   Top1 90.117188   Top5 98.997396   BatchTime 0.379877   LR 0.000804   
2022-11-25 13:07:00,010 - INFO  - Training [46][   80/  196]   Loss 0.274427   Top1 90.229492   Top5 99.106445   BatchTime 0.352583   LR 0.000799   
2022-11-25 13:07:06,204 - INFO  - Training [46][  100/  196]   Loss 0.272540   Top1 90.328125   Top5 99.128906   BatchTime 0.343998   LR 0.000794   
2022-11-25 13:07:13,058 - INFO  - Training [46][  120/  196]   Loss 0.267333   Top1 90.579427   Top5 99.176432   BatchTime 0.343783   LR 0.000789   
2022-11-25 13:07:19,930 - INFO  - Training [46][  140/  196]   Loss 0.265046   Top1 90.680804   Top5 99.227121   BatchTime 0.343758   LR 0.000785   
2022-11-25 13:07:26,646 - INFO  - Training [46][  160/  196]   Loss 0.268221   Top1 90.566406   Top5 99.216309   BatchTime 0.342758   LR 0.000780   
2022-11-25 13:07:33,340 - INFO  - Training [46][  180/  196]   Loss 0.270212   Top1 90.549045   Top5 99.168837   BatchTime 0.341865   LR 0.000775   
2022-11-25 13:07:39,357 - INFO  - ==> Top1: 90.550    Top5: 99.156    Loss: 0.271

2022-11-25 13:07:39,595 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:07:41,117 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:07:44,047 - INFO  - Validation [46][   20/   40]   Loss 0.291489   Top1 91.640625   Top5 99.707031   BatchTime 0.146394   
2022-11-25 13:07:45,148 - INFO  - Validation [46][   40/   40]   Loss 0.273650   Top1 91.770000   Top5 99.800000   BatchTime 0.100739   
2022-11-25 13:07:45,433 - INFO  - ==> Top1: 91.770    Top5: 99.800    Loss: 0.274

2022-11-25 13:07:45,433 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:07:45,433 - INFO  - Scoreboard best 1 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:07:45,434 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:07:45,434 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:07:51,319 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 13:07:51,324 - INFO  - >>>>>> Epoch  47
2022-11-25 13:07:51,327 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:07:59,859 - INFO  - Training [47][   20/  196]   Loss 0.282997   Top1 90.156250   Top5 98.554688   BatchTime 0.426464   LR 0.000766   
2022-11-25 13:08:06,515 - INFO  - Training [47][   40/  196]   Loss 0.285497   Top1 89.873047   Top5 98.691406   BatchTime 0.379635   LR 0.000761   
2022-11-25 13:08:11,955 - INFO  - Training [47][   60/  196]   Loss 0.284141   Top1 89.856771   Top5 98.789062   BatchTime 0.343765   LR 0.000756   
2022-11-25 13:08:17,794 - INFO  - Training [47][   80/  196]   Loss 0.281802   Top1 90.009766   Top5 98.930664   BatchTime 0.330804   LR 0.000752   
2022-11-25 13:08:24,726 - INFO  - Training [47][  100/  196]   Loss 0.277189   Top1 90.199219   Top5 98.992188   BatchTime 0.333963   LR 0.000747   
2022-11-25 13:08:31,615 - INFO  - Training [47][  120/  196]   Loss 0.270589   Top1 90.514323   Top5 99.055990   BatchTime 0.335712   LR 0.000742   
2022-11-25 13:08:38,253 - INFO  - Training [47][  140/  196]   Loss 0.267569   Top1 90.597098   Top5 99.123884   BatchTime 0.335167   LR 0.000737   
2022-11-25 13:08:44,931 - INFO  - Training [47][  160/  196]   Loss 0.269811   Top1 90.522461   Top5 99.101562   BatchTime 0.335006   LR 0.000732   
2022-11-25 13:08:51,970 - INFO  - Training [47][  180/  196]   Loss 0.269737   Top1 90.514323   Top5 99.086372   BatchTime 0.336891   LR 0.000727   
2022-11-25 13:08:57,402 - INFO  - ==> Top1: 90.534    Top5: 99.096    Loss: 0.268

2022-11-25 13:08:57,674 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:08:59,379 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:09:02,179 - INFO  - Validation [47][   20/   40]   Loss 0.289126   Top1 91.367188   Top5 99.707031   BatchTime 0.139885   
2022-11-25 13:09:03,389 - INFO  - Validation [47][   40/   40]   Loss 0.277715   Top1 91.420000   Top5 99.780000   BatchTime 0.100191   
2022-11-25 13:09:03,647 - INFO  - ==> Top1: 91.420    Top5: 99.780    Loss: 0.278

2022-11-25 13:09:03,647 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:09:03,647 - INFO  - Scoreboard best 1 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:09:03,647 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:09:03,648 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:09:03,785 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:09:03,787 - INFO  - >>>>>> Epoch  48
2022-11-25 13:09:03,788 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:09:12,265 - INFO  - Training [48][   20/  196]   Loss 0.267078   Top1 90.507812   Top5 98.710938   BatchTime 0.423681   LR 0.000718   
2022-11-25 13:09:19,287 - INFO  - Training [48][   40/  196]   Loss 0.277201   Top1 90.214844   Top5 98.769531   BatchTime 0.387407   LR 0.000713   
2022-11-25 13:09:24,862 - INFO  - Training [48][   60/  196]   Loss 0.273457   Top1 90.358073   Top5 98.919271   BatchTime 0.351185   LR 0.000708   
2022-11-25 13:09:30,961 - INFO  - Training [48][   80/  196]   Loss 0.275672   Top1 90.302734   Top5 98.994141   BatchTime 0.339617   LR 0.000703   
2022-11-25 13:09:37,767 - INFO  - Training [48][  100/  196]   Loss 0.269898   Top1 90.500000   Top5 99.046875   BatchTime 0.339752   LR 0.000698   
2022-11-25 13:09:44,474 - INFO  - Training [48][  120/  196]   Loss 0.264619   Top1 90.683594   Top5 99.111328   BatchTime 0.339025   LR 0.000693   
2022-11-25 13:09:51,107 - INFO  - Training [48][  140/  196]   Loss 0.262991   Top1 90.792411   Top5 99.151786   BatchTime 0.337966   LR 0.000688   
2022-11-25 13:09:57,903 - INFO  - Training [48][  160/  196]   Loss 0.264080   Top1 90.727539   Top5 99.162598   BatchTime 0.338196   LR 0.000683   
2022-11-25 13:10:05,073 - INFO  - Training [48][  180/  196]   Loss 0.264259   Top1 90.674913   Top5 99.127604   BatchTime 0.340452   LR 0.000678   
2022-11-25 13:10:10,587 - INFO  - ==> Top1: 90.730    Top5: 99.124    Loss: 0.263

2022-11-25 13:10:10,868 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:10:12,265 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:10:15,304 - INFO  - Validation [48][   20/   40]   Loss 0.304248   Top1 91.308594   Top5 99.648438   BatchTime 0.151889   
2022-11-25 13:10:16,486 - INFO  - Validation [48][   40/   40]   Loss 0.294209   Top1 91.340000   Top5 99.760000   BatchTime 0.105496   
2022-11-25 13:10:16,761 - INFO  - ==> Top1: 91.340    Top5: 99.760    Loss: 0.294

2022-11-25 13:10:16,762 - INFO  - ==> Sparsity : 0.570

2022-11-25 13:10:16,762 - INFO  - Scoreboard best 1 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:10:16,762 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:10:16,762 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:10:16,896 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:10:16,898 - INFO  - >>>>>> Epoch  49
2022-11-25 13:10:16,900 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:10:25,334 - INFO  - Training [49][   20/  196]   Loss 0.279429   Top1 90.000000   Top5 98.437500   BatchTime 0.421545   LR 0.000669   
2022-11-25 13:10:32,193 - INFO  - Training [49][   40/  196]   Loss 0.275169   Top1 90.263672   Top5 98.671875   BatchTime 0.382265   LR 0.000664   
2022-11-25 13:10:37,955 - INFO  - Training [49][   60/  196]   Loss 0.276806   Top1 90.266927   Top5 98.828125   BatchTime 0.350863   LR 0.000659   
2022-11-25 13:10:43,656 - INFO  - Training [49][   80/  196]   Loss 0.275066   Top1 90.327148   Top5 98.916016   BatchTime 0.334420   LR 0.000654   
2022-11-25 13:10:50,266 - INFO  - Training [49][  100/  196]   Loss 0.267567   Top1 90.625000   Top5 98.976562   BatchTime 0.333635   LR 0.000649   
2022-11-25 13:10:56,998 - INFO  - Training [49][  120/  196]   Loss 0.261471   Top1 90.908203   Top5 99.055990   BatchTime 0.334118   LR 0.000644   
2022-11-25 13:11:03,627 - INFO  - Training [49][  140/  196]   Loss 0.259145   Top1 90.970982   Top5 99.135045   BatchTime 0.333741   LR 0.000639   
2022-11-25 13:11:10,239 - INFO  - Training [49][  160/  196]   Loss 0.260512   Top1 90.905762   Top5 99.099121   BatchTime 0.333351   LR 0.000634   
2022-11-25 13:11:17,368 - INFO  - Training [49][  180/  196]   Loss 0.260870   Top1 90.876736   Top5 99.110243   BatchTime 0.335913   LR 0.000629   
2022-11-25 13:11:22,943 - INFO  - ==> Top1: 90.870    Top5: 99.124    Loss: 0.261

2022-11-25 13:11:23,206 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:11:25,056 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:11:27,847 - INFO  - Validation [49][   20/   40]   Loss 0.288499   Top1 91.367188   Top5 99.667969   BatchTime 0.139478   
2022-11-25 13:11:28,982 - INFO  - Validation [49][   40/   40]   Loss 0.281484   Top1 91.360000   Top5 99.770000   BatchTime 0.098106   
2022-11-25 13:11:29,265 - INFO  - ==> Top1: 91.360    Top5: 99.770    Loss: 0.281

2022-11-25 13:11:29,266 - INFO  - ==> Sparsity : 0.570

2022-11-25 13:11:29,266 - INFO  - Scoreboard best 1 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:11:29,266 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:11:29,266 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:11:29,403 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:11:29,404 - INFO  - >>>>>> Epoch  50
2022-11-25 13:11:29,406 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:11:38,161 - INFO  - Training [50][   20/  196]   Loss 0.296796   Top1 89.941406   Top5 98.535156   BatchTime 0.437616   LR 0.000620   
2022-11-25 13:11:45,240 - INFO  - Training [50][   40/  196]   Loss 0.287388   Top1 89.931641   Top5 98.779297   BatchTime 0.395796   LR 0.000615   
2022-11-25 13:11:51,228 - INFO  - Training [50][   60/  196]   Loss 0.283115   Top1 89.947917   Top5 98.912760   BatchTime 0.363654   LR 0.000610   
2022-11-25 13:11:56,901 - INFO  - Training [50][   80/  196]   Loss 0.278377   Top1 90.205078   Top5 99.047852   BatchTime 0.343658   LR 0.000605   
2022-11-25 13:12:03,603 - INFO  - Training [50][  100/  196]   Loss 0.272375   Top1 90.406250   Top5 99.089844   BatchTime 0.341941   LR 0.000600   
2022-11-25 13:12:10,615 - INFO  - Training [50][  120/  196]   Loss 0.264964   Top1 90.638021   Top5 99.160156   BatchTime 0.343382   LR 0.000595   
2022-11-25 13:12:17,398 - INFO  - Training [50][  140/  196]   Loss 0.261075   Top1 90.753348   Top5 99.213170   BatchTime 0.342780   LR 0.000590   
2022-11-25 13:12:24,133 - INFO  - Training [50][  160/  196]   Loss 0.260619   Top1 90.742188   Top5 99.204102   BatchTime 0.342022   LR 0.000585   
2022-11-25 13:12:31,222 - INFO  - Training [50][  180/  196]   Loss 0.259643   Top1 90.759549   Top5 99.171007   BatchTime 0.343405   LR 0.000580   
2022-11-25 13:12:36,690 - INFO  - ==> Top1: 90.806    Top5: 99.170    Loss: 0.260

2022-11-25 13:12:36,966 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:12:38,391 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:12:41,256 - INFO  - Validation [50][   20/   40]   Loss 0.305357   Top1 90.742188   Top5 99.746094   BatchTime 0.143189   
2022-11-25 13:12:42,407 - INFO  - Validation [50][   40/   40]   Loss 0.292480   Top1 91.010000   Top5 99.800000   BatchTime 0.100372   
2022-11-25 13:12:42,677 - INFO  - ==> Top1: 91.010    Top5: 99.800    Loss: 0.292

2022-11-25 13:12:42,677 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:12:42,677 - INFO  - Scoreboard best 1 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:12:42,678 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:12:42,678 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:12:42,865 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:12:42,867 - INFO  - >>>>>> Epoch  51
2022-11-25 13:12:42,869 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:12:51,781 - INFO  - Training [51][   20/  196]   Loss 0.281872   Top1 90.507812   Top5 98.417969   BatchTime 0.445468   LR 0.000571   
2022-11-25 13:12:58,926 - INFO  - Training [51][   40/  196]   Loss 0.272388   Top1 90.849609   Top5 98.701172   BatchTime 0.401349   LR 0.000566   
2022-11-25 13:13:05,097 - INFO  - Training [51][   60/  196]   Loss 0.272894   Top1 90.618490   Top5 98.841146   BatchTime 0.370422   LR 0.000561   
2022-11-25 13:13:11,103 - INFO  - Training [51][   80/  196]   Loss 0.267582   Top1 90.795898   Top5 98.945312   BatchTime 0.352888   LR 0.000556   
2022-11-25 13:13:17,884 - INFO  - Training [51][  100/  196]   Loss 0.261253   Top1 90.972656   Top5 99.000000   BatchTime 0.350117   LR 0.000551   
2022-11-25 13:13:24,710 - INFO  - Training [51][  120/  196]   Loss 0.257582   Top1 91.025391   Top5 99.062500   BatchTime 0.348647   LR 0.000546   
2022-11-25 13:13:31,551 - INFO  - Training [51][  140/  196]   Loss 0.256110   Top1 91.021205   Top5 99.112723   BatchTime 0.347705   LR 0.000541   
2022-11-25 13:13:38,456 - INFO  - Training [51][  160/  196]   Loss 0.259264   Top1 90.944824   Top5 99.116211   BatchTime 0.347400   LR 0.000536   
2022-11-25 13:13:45,556 - INFO  - Training [51][  180/  196]   Loss 0.261456   Top1 90.848524   Top5 99.099392   BatchTime 0.348243   LR 0.000531   
2022-11-25 13:13:51,136 - INFO  - ==> Top1: 90.970    Top5: 99.096    Loss: 0.259

2022-11-25 13:13:51,385 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:13:53,099 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:13:56,058 - INFO  - Validation [51][   20/   40]   Loss 0.286849   Top1 91.328125   Top5 99.707031   BatchTime 0.147856   
2022-11-25 13:13:57,205 - INFO  - Validation [51][   40/   40]   Loss 0.275729   Top1 91.510000   Top5 99.800000   BatchTime 0.102618   
2022-11-25 13:13:57,477 - INFO  - ==> Top1: 91.510    Top5: 99.800    Loss: 0.276

2022-11-25 13:13:57,477 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:13:57,477 - INFO  - Scoreboard best 1 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:13:57,477 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:13:57,478 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:13:57,618 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:13:57,620 - INFO  - >>>>>> Epoch  52
2022-11-25 13:13:57,622 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:14:06,531 - INFO  - Training [52][   20/  196]   Loss 0.266188   Top1 90.781250   Top5 98.769531   BatchTime 0.445340   LR 0.000523   
2022-11-25 13:14:13,263 - INFO  - Training [52][   40/  196]   Loss 0.266009   Top1 90.742188   Top5 98.837891   BatchTime 0.390974   LR 0.000518   
2022-11-25 13:14:19,062 - INFO  - Training [52][   60/  196]   Loss 0.263867   Top1 90.820312   Top5 98.932292   BatchTime 0.357292   LR 0.000513   
2022-11-25 13:14:25,492 - INFO  - Training [52][   80/  196]   Loss 0.261624   Top1 90.834961   Top5 99.052734   BatchTime 0.348341   LR 0.000508   
2022-11-25 13:14:32,329 - INFO  - Training [52][  100/  196]   Loss 0.253954   Top1 91.132812   Top5 99.121094   BatchTime 0.347042   LR 0.000503   
2022-11-25 13:14:39,448 - INFO  - Training [52][  120/  196]   Loss 0.249614   Top1 91.272786   Top5 99.182943   BatchTime 0.348526   LR 0.000498   
2022-11-25 13:14:46,694 - INFO  - Training [52][  140/  196]   Loss 0.246876   Top1 91.358817   Top5 99.221540   BatchTime 0.350491   LR 0.000493   
2022-11-25 13:14:54,044 - INFO  - Training [52][  160/  196]   Loss 0.251087   Top1 91.188965   Top5 99.221191   BatchTime 0.352620   LR 0.000488   
2022-11-25 13:15:00,960 - INFO  - Training [52][  180/  196]   Loss 0.251946   Top1 91.193576   Top5 99.175347   BatchTime 0.351861   LR 0.000483   
2022-11-25 13:15:06,556 - INFO  - ==> Top1: 91.218    Top5: 99.158    Loss: 0.252

2022-11-25 13:15:06,868 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:15:08,302 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:15:11,398 - INFO  - Validation [52][   20/   40]   Loss 0.289674   Top1 91.250000   Top5 99.648438   BatchTime 0.154706   
2022-11-25 13:15:12,509 - INFO  - Validation [52][   40/   40]   Loss 0.283158   Top1 91.400000   Top5 99.770000   BatchTime 0.105137   
2022-11-25 13:15:12,754 - INFO  - ==> Top1: 91.400    Top5: 99.770    Loss: 0.283

2022-11-25 13:15:12,755 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:15:12,755 - INFO  - Scoreboard best 1 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:15:12,755 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:15:12,755 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 91.560   Top5: 99.720]
2022-11-25 13:15:12,881 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:15:12,883 - INFO  - >>>>>> Epoch  53
2022-11-25 13:15:12,885 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:15:22,356 - INFO  - Training [53][   20/  196]   Loss 0.269525   Top1 90.390625   Top5 98.515625   BatchTime 0.473423   LR 0.000474   
2022-11-25 13:15:29,059 - INFO  - Training [53][   40/  196]   Loss 0.271284   Top1 90.419922   Top5 98.857422   BatchTime 0.404297   LR 0.000470   
2022-11-25 13:15:34,429 - INFO  - Training [53][   60/  196]   Loss 0.264473   Top1 90.742188   Top5 98.958333   BatchTime 0.359035   LR 0.000465   
2022-11-25 13:15:41,212 - INFO  - Training [53][   80/  196]   Loss 0.256304   Top1 91.030273   Top5 99.082031   BatchTime 0.354055   LR 0.000460   
2022-11-25 13:15:48,656 - INFO  - Training [53][  100/  196]   Loss 0.252562   Top1 91.191406   Top5 99.117188   BatchTime 0.357692   LR 0.000455   
2022-11-25 13:15:55,598 - INFO  - Training [53][  120/  196]   Loss 0.246439   Top1 91.389974   Top5 99.176432   BatchTime 0.355914   LR 0.000450   
2022-11-25 13:16:02,676 - INFO  - Training [53][  140/  196]   Loss 0.245652   Top1 91.406250   Top5 99.218750   BatchTime 0.355633   LR 0.000445   
2022-11-25 13:16:09,484 - INFO  - Training [53][  160/  196]   Loss 0.249428   Top1 91.315918   Top5 99.194336   BatchTime 0.353729   LR 0.000441   
2022-11-25 13:16:16,292 - INFO  - Training [53][  180/  196]   Loss 0.249756   Top1 91.317274   Top5 99.168837   BatchTime 0.352245   LR 0.000436   
2022-11-25 13:16:22,068 - INFO  - ==> Top1: 91.242    Top5: 99.176    Loss: 0.250

2022-11-25 13:16:22,362 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:16:23,755 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:16:26,772 - INFO  - Validation [53][   20/   40]   Loss 0.279578   Top1 91.875000   Top5 99.746094   BatchTime 0.150762   
2022-11-25 13:16:27,853 - INFO  - Validation [53][   40/   40]   Loss 0.270076   Top1 92.040000   Top5 99.800000   BatchTime 0.102397   
2022-11-25 13:16:28,123 - INFO  - ==> Top1: 92.040    Top5: 99.800    Loss: 0.270

2022-11-25 13:16:28,123 - INFO  - ==> Sparsity : 0.570

2022-11-25 13:16:28,124 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:16:28,124 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:16:28,124 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:16:34,718 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 13:16:34,722 - INFO  - >>>>>> Epoch  54
2022-11-25 13:16:34,723 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:16:41,863 - INFO  - Training [54][   20/  196]   Loss 0.273036   Top1 90.195312   Top5 98.554688   BatchTime 0.356839   LR 0.000427   
2022-11-25 13:16:48,587 - INFO  - Training [54][   40/  196]   Loss 0.268544   Top1 90.449219   Top5 98.720703   BatchTime 0.346520   LR 0.000423   
2022-11-25 13:16:55,486 - INFO  - Training [54][   60/  196]   Loss 0.263525   Top1 90.839844   Top5 98.867188   BatchTime 0.346000   LR 0.000418   
2022-11-25 13:17:02,387 - INFO  - Training [54][   80/  196]   Loss 0.259068   Top1 90.976562   Top5 98.989258   BatchTime 0.345763   LR 0.000413   
2022-11-25 13:17:09,565 - INFO  - Training [54][  100/  196]   Loss 0.253148   Top1 91.164062   Top5 99.050781   BatchTime 0.348385   LR 0.000408   
2022-11-25 13:17:16,472 - INFO  - Training [54][  120/  196]   Loss 0.248651   Top1 91.347656   Top5 99.150391   BatchTime 0.347876   LR 0.000404   
2022-11-25 13:17:23,306 - INFO  - Training [54][  140/  196]   Loss 0.249326   Top1 91.344866   Top5 99.162946   BatchTime 0.347001   LR 0.000399   
2022-11-25 13:17:29,953 - INFO  - Training [54][  160/  196]   Loss 0.251339   Top1 91.242676   Top5 99.145508   BatchTime 0.345165   LR 0.000394   
2022-11-25 13:17:36,583 - INFO  - Training [54][  180/  196]   Loss 0.251326   Top1 91.284722   Top5 99.125434   BatchTime 0.343646   LR 0.000390   
2022-11-25 13:17:41,891 - INFO  - ==> Top1: 91.348    Top5: 99.128    Loss: 0.249

2022-11-25 13:17:42,231 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:17:44,117 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:17:46,753 - INFO  - Validation [54][   20/   40]   Loss 0.304126   Top1 91.328125   Top5 99.589844   BatchTime 0.131713   
2022-11-25 13:17:48,222 - INFO  - Validation [54][   40/   40]   Loss 0.297979   Top1 91.070000   Top5 99.680000   BatchTime 0.102593   
2022-11-25 13:17:48,487 - INFO  - ==> Top1: 91.070    Top5: 99.680    Loss: 0.298

2022-11-25 13:17:48,487 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:17:48,487 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:17:48,487 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:17:48,487 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:17:48,618 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:17:48,620 - INFO  - >>>>>> Epoch  55
2022-11-25 13:17:48,622 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:17:55,677 - INFO  - Training [55][   20/  196]   Loss 0.260893   Top1 90.527344   Top5 98.632812   BatchTime 0.352646   LR 0.000381   
2022-11-25 13:18:02,114 - INFO  - Training [55][   40/  196]   Loss 0.270853   Top1 90.429688   Top5 98.710938   BatchTime 0.337241   LR 0.000377   
2022-11-25 13:18:08,818 - INFO  - Training [55][   60/  196]   Loss 0.266645   Top1 90.683594   Top5 98.873698   BatchTime 0.336561   LR 0.000372   
2022-11-25 13:18:15,877 - INFO  - Training [55][   80/  196]   Loss 0.258840   Top1 91.035156   Top5 99.033203   BatchTime 0.340651   LR 0.000368   
2022-11-25 13:18:22,944 - INFO  - Training [55][  100/  196]   Loss 0.251543   Top1 91.304688   Top5 99.062500   BatchTime 0.343197   LR 0.000363   
2022-11-25 13:18:29,799 - INFO  - Training [55][  120/  196]   Loss 0.247218   Top1 91.455078   Top5 99.124349   BatchTime 0.343121   LR 0.000358   
2022-11-25 13:18:36,687 - INFO  - Training [55][  140/  196]   Loss 0.244709   Top1 91.492746   Top5 99.162946   BatchTime 0.343302   LR 0.000354   
2022-11-25 13:18:43,585 - INFO  - Training [55][  160/  196]   Loss 0.246889   Top1 91.391602   Top5 99.157715   BatchTime 0.343501   LR 0.000349   
2022-11-25 13:18:50,417 - INFO  - Training [55][  180/  196]   Loss 0.246758   Top1 91.391059   Top5 99.112413   BatchTime 0.343290   LR 0.000345   
2022-11-25 13:18:55,978 - INFO  - ==> Top1: 91.430    Top5: 99.114    Loss: 0.246

2022-11-25 13:18:56,258 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:18:58,082 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:19:00,982 - INFO  - Validation [55][   20/   40]   Loss 0.331683   Top1 90.273438   Top5 99.648438   BatchTime 0.144936   
2022-11-25 13:19:02,221 - INFO  - Validation [55][   40/   40]   Loss 0.312540   Top1 90.580000   Top5 99.720000   BatchTime 0.103450   
2022-11-25 13:19:02,485 - INFO  - ==> Top1: 90.580    Top5: 99.720    Loss: 0.313

2022-11-25 13:19:02,485 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:19:02,485 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:19:02,485 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:19:02,486 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:19:02,635 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:19:02,636 - INFO  - >>>>>> Epoch  56
2022-11-25 13:19:02,638 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:19:09,615 - INFO  - Training [56][   20/  196]   Loss 0.267751   Top1 90.859375   Top5 98.828125   BatchTime 0.348685   LR 0.000337   
2022-11-25 13:19:16,516 - INFO  - Training [56][   40/  196]   Loss 0.265079   Top1 90.869141   Top5 98.876953   BatchTime 0.346874   LR 0.000333   
2022-11-25 13:19:23,359 - INFO  - Training [56][   60/  196]   Loss 0.259105   Top1 91.074219   Top5 98.964844   BatchTime 0.345304   LR 0.000328   
2022-11-25 13:19:30,312 - INFO  - Training [56][   80/  196]   Loss 0.257283   Top1 90.986328   Top5 99.062500   BatchTime 0.345889   LR 0.000324   
2022-11-25 13:19:36,821 - INFO  - Training [56][  100/  196]   Loss 0.247970   Top1 91.320312   Top5 99.136719   BatchTime 0.341798   LR 0.000319   
2022-11-25 13:19:44,025 - INFO  - Training [56][  120/  196]   Loss 0.243948   Top1 91.432292   Top5 99.153646   BatchTime 0.344858   LR 0.000315   
2022-11-25 13:19:50,982 - INFO  - Training [56][  140/  196]   Loss 0.242619   Top1 91.470424   Top5 99.213170   BatchTime 0.345293   LR 0.000311   
2022-11-25 13:19:57,676 - INFO  - Training [56][  160/  196]   Loss 0.245516   Top1 91.350098   Top5 99.194336   BatchTime 0.343967   LR 0.000306   
2022-11-25 13:20:04,542 - INFO  - Training [56][  180/  196]   Loss 0.244582   Top1 91.347656   Top5 99.166667   BatchTime 0.343889   LR 0.000302   
2022-11-25 13:20:10,311 - INFO  - ==> Top1: 91.366    Top5: 99.146    Loss: 0.244

2022-11-25 13:20:10,609 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:20:12,040 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:20:15,182 - INFO  - Validation [56][   20/   40]   Loss 0.310181   Top1 90.820312   Top5 99.726562   BatchTime 0.157024   
2022-11-25 13:20:16,342 - INFO  - Validation [56][   40/   40]   Loss 0.291732   Top1 91.290000   Top5 99.790000   BatchTime 0.107513   
2022-11-25 13:20:16,531 - INFO  - ==> Top1: 91.290    Top5: 99.790    Loss: 0.292

2022-11-25 13:20:16,531 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:20:16,532 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:20:16,532 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:20:16,532 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:20:16,668 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:20:16,670 - INFO  - >>>>>> Epoch  57
2022-11-25 13:20:16,672 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:20:23,989 - INFO  - Training [57][   20/  196]   Loss 0.261273   Top1 90.976562   Top5 98.750000   BatchTime 0.365719   LR 0.000294   
2022-11-25 13:20:30,814 - INFO  - Training [57][   40/  196]   Loss 0.250839   Top1 91.142578   Top5 98.896484   BatchTime 0.353490   LR 0.000290   
2022-11-25 13:20:37,566 - INFO  - Training [57][   60/  196]   Loss 0.244908   Top1 91.445312   Top5 98.971354   BatchTime 0.348191   LR 0.000286   
2022-11-25 13:20:44,821 - INFO  - Training [57][   80/  196]   Loss 0.246261   Top1 91.425781   Top5 99.125977   BatchTime 0.351826   LR 0.000282   
2022-11-25 13:20:51,674 - INFO  - Training [57][  100/  196]   Loss 0.241812   Top1 91.656250   Top5 99.140625   BatchTime 0.349988   LR 0.000277   
2022-11-25 13:20:58,396 - INFO  - Training [57][  120/  196]   Loss 0.238670   Top1 91.822917   Top5 99.176432   BatchTime 0.347676   LR 0.000273   
2022-11-25 13:21:05,085 - INFO  - Training [57][  140/  196]   Loss 0.237751   Top1 91.833147   Top5 99.218750   BatchTime 0.345785   LR 0.000269   
2022-11-25 13:21:11,911 - INFO  - Training [57][  160/  196]   Loss 0.240359   Top1 91.711426   Top5 99.211426   BatchTime 0.345223   LR 0.000265   
2022-11-25 13:21:18,745 - INFO  - Training [57][  180/  196]   Loss 0.243799   Top1 91.603733   Top5 99.168837   BatchTime 0.344833   LR 0.000261   
2022-11-25 13:21:24,300 - INFO  - ==> Top1: 91.608    Top5: 99.164    Loss: 0.243

2022-11-25 13:21:24,593 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:21:26,195 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:21:29,076 - INFO  - Validation [57][   20/   40]   Loss 0.293011   Top1 91.347656   Top5 99.726562   BatchTime 0.143929   
2022-11-25 13:21:30,213 - INFO  - Validation [57][   40/   40]   Loss 0.281505   Top1 91.450000   Top5 99.790000   BatchTime 0.100413   
2022-11-25 13:21:30,486 - INFO  - ==> Top1: 91.450    Top5: 99.790    Loss: 0.282

2022-11-25 13:21:30,486 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:21:30,486 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:21:30,486 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:21:30,486 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:21:30,608 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:21:30,610 - INFO  - >>>>>> Epoch  58
2022-11-25 13:21:30,612 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:21:37,977 - INFO  - Training [58][   20/  196]   Loss 0.258446   Top1 90.703125   Top5 98.691406   BatchTime 0.368115   LR 0.000254   
2022-11-25 13:21:45,288 - INFO  - Training [58][   40/  196]   Loss 0.273015   Top1 90.488281   Top5 98.818359   BatchTime 0.366853   LR 0.000250   
2022-11-25 13:21:52,182 - INFO  - Training [58][   60/  196]   Loss 0.262638   Top1 90.930990   Top5 98.873698   BatchTime 0.359455   LR 0.000246   
2022-11-25 13:21:58,992 - INFO  - Training [58][   80/  196]   Loss 0.257404   Top1 91.059570   Top5 99.047852   BatchTime 0.354718   LR 0.000242   
2022-11-25 13:22:05,946 - INFO  - Training [58][  100/  196]   Loss 0.249532   Top1 91.308594   Top5 99.097656   BatchTime 0.353313   LR 0.000238   
2022-11-25 13:22:12,736 - INFO  - Training [58][  120/  196]   Loss 0.244785   Top1 91.484375   Top5 99.163411   BatchTime 0.351011   LR 0.000234   
2022-11-25 13:22:19,487 - INFO  - Training [58][  140/  196]   Loss 0.242302   Top1 91.587612   Top5 99.227121   BatchTime 0.349088   LR 0.000230   
2022-11-25 13:22:26,286 - INFO  - Training [58][  160/  196]   Loss 0.242070   Top1 91.601562   Top5 99.206543   BatchTime 0.347944   LR 0.000226   
2022-11-25 13:22:33,131 - INFO  - Training [58][  180/  196]   Loss 0.243094   Top1 91.558160   Top5 99.190538   BatchTime 0.347313   LR 0.000222   
2022-11-25 13:22:38,588 - INFO  - ==> Top1: 91.564    Top5: 99.168    Loss: 0.242

2022-11-25 13:22:38,822 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:22:40,341 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:22:43,786 - INFO  - Validation [58][   20/   40]   Loss 0.326967   Top1 90.429688   Top5 99.648438   BatchTime 0.172125   
2022-11-25 13:22:44,797 - INFO  - Validation [58][   40/   40]   Loss 0.315623   Top1 90.610000   Top5 99.730000   BatchTime 0.111336   
2022-11-25 13:22:45,145 - INFO  - ==> Top1: 90.610    Top5: 99.730    Loss: 0.316

2022-11-25 13:22:45,146 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:22:45,146 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:22:45,146 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:22:45,146 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 91.570   Top5: 99.730]
2022-11-25 13:22:45,272 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:22:45,274 - INFO  - >>>>>> Epoch  59
2022-11-25 13:22:45,275 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:22:53,133 - INFO  - Training [59][   20/  196]   Loss 0.273748   Top1 90.488281   Top5 98.593750   BatchTime 0.392767   LR 0.000215   
2022-11-25 13:22:59,906 - INFO  - Training [59][   40/  196]   Loss 0.261264   Top1 90.947266   Top5 98.818359   BatchTime 0.365701   LR 0.000212   
2022-11-25 13:23:06,471 - INFO  - Training [59][   60/  196]   Loss 0.252846   Top1 91.132812   Top5 98.912760   BatchTime 0.353224   LR 0.000208   
2022-11-25 13:23:13,410 - INFO  - Training [59][   80/  196]   Loss 0.248053   Top1 91.279297   Top5 99.101562   BatchTime 0.351650   LR 0.000204   
2022-11-25 13:23:20,120 - INFO  - Training [59][  100/  196]   Loss 0.244671   Top1 91.449219   Top5 99.109375   BatchTime 0.348420   LR 0.000201   
2022-11-25 13:23:27,005 - INFO  - Training [59][  120/  196]   Loss 0.239717   Top1 91.650391   Top5 99.156901   BatchTime 0.347720   LR 0.000197   
2022-11-25 13:23:33,955 - INFO  - Training [59][  140/  196]   Loss 0.238872   Top1 91.699219   Top5 99.188058   BatchTime 0.347693   LR 0.000193   
2022-11-25 13:23:40,718 - INFO  - Training [59][  160/  196]   Loss 0.239593   Top1 91.647949   Top5 99.199219   BatchTime 0.346496   LR 0.000190   
2022-11-25 13:23:47,990 - INFO  - Training [59][  180/  196]   Loss 0.238638   Top1 91.697049   Top5 99.197049   BatchTime 0.348397   LR 0.000186   
2022-11-25 13:23:53,556 - INFO  - ==> Top1: 91.710    Top5: 99.196    Loss: 0.238

2022-11-25 13:23:53,816 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:23:55,178 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:23:58,245 - INFO  - Validation [59][   20/   40]   Loss 0.286536   Top1 91.816406   Top5 99.726562   BatchTime 0.153195   
2022-11-25 13:23:59,344 - INFO  - Validation [59][   40/   40]   Loss 0.272076   Top1 91.920000   Top5 99.810000   BatchTime 0.104102   
2022-11-25 13:23:59,664 - INFO  - ==> Top1: 91.920    Top5: 99.810    Loss: 0.272

2022-11-25 13:23:59,664 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:23:59,664 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:23:59,665 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:23:59,665 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:24:00,125 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:24:00,127 - INFO  - >>>>>> Epoch  60
2022-11-25 13:24:00,129 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:24:08,087 - INFO  - Training [60][   20/  196]   Loss 0.262916   Top1 90.527344   Top5 98.769531   BatchTime 0.397784   LR 0.000180   
2022-11-25 13:24:14,828 - INFO  - Training [60][   40/  196]   Loss 0.262245   Top1 90.693359   Top5 98.798828   BatchTime 0.367412   LR 0.000176   
2022-11-25 13:24:21,714 - INFO  - Training [60][   60/  196]   Loss 0.247280   Top1 91.269531   Top5 98.951823   BatchTime 0.359707   LR 0.000173   
2022-11-25 13:24:28,733 - INFO  - Training [60][   80/  196]   Loss 0.245688   Top1 91.381836   Top5 99.077148   BatchTime 0.357515   LR 0.000169   
2022-11-25 13:24:35,674 - INFO  - Training [60][  100/  196]   Loss 0.239758   Top1 91.570312   Top5 99.140625   BatchTime 0.355418   LR 0.000166   
2022-11-25 13:24:42,768 - INFO  - Training [60][  120/  196]   Loss 0.235554   Top1 91.751302   Top5 99.215495   BatchTime 0.355304   LR 0.000162   
2022-11-25 13:24:49,647 - INFO  - Training [60][  140/  196]   Loss 0.234866   Top1 91.813616   Top5 99.268973   BatchTime 0.353678   LR 0.000159   
2022-11-25 13:24:56,392 - INFO  - Training [60][  160/  196]   Loss 0.238965   Top1 91.704102   Top5 99.252930   BatchTime 0.351621   LR 0.000156   
2022-11-25 13:25:03,087 - INFO  - Training [60][  180/  196]   Loss 0.238405   Top1 91.720920   Top5 99.238281   BatchTime 0.349750   LR 0.000152   
2022-11-25 13:25:08,711 - INFO  - ==> Top1: 91.798    Top5: 99.230    Loss: 0.236

2022-11-25 13:25:08,987 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:25:10,500 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:25:13,446 - INFO  - Validation [60][   20/   40]   Loss 0.284669   Top1 91.718750   Top5 99.726562   BatchTime 0.147212   
2022-11-25 13:25:14,614 - INFO  - Validation [60][   40/   40]   Loss 0.276729   Top1 91.610000   Top5 99.790000   BatchTime 0.102814   
2022-11-25 13:25:14,918 - INFO  - ==> Top1: 91.610    Top5: 99.790    Loss: 0.277

2022-11-25 13:25:14,918 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:25:14,918 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:25:14,918 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:25:14,918 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:25:15,074 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:25:15,076 - INFO  - >>>>>> Epoch  61
2022-11-25 13:25:15,078 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:25:22,593 - INFO  - Training [61][   20/  196]   Loss 0.249769   Top1 91.035156   Top5 98.789062   BatchTime 0.375657   LR 0.000147   
2022-11-25 13:25:29,606 - INFO  - Training [61][   40/  196]   Loss 0.246295   Top1 91.181641   Top5 98.916016   BatchTime 0.363156   LR 0.000143   
2022-11-25 13:25:36,472 - INFO  - Training [61][   60/  196]   Loss 0.244836   Top1 91.373698   Top5 98.990885   BatchTime 0.356521   LR 0.000140   
2022-11-25 13:25:43,657 - INFO  - Training [61][   80/  196]   Loss 0.244026   Top1 91.440430   Top5 99.101562   BatchTime 0.357210   LR 0.000137   
2022-11-25 13:25:50,565 - INFO  - Training [61][  100/  196]   Loss 0.237766   Top1 91.652344   Top5 99.128906   BatchTime 0.354842   LR 0.000134   
2022-11-25 13:25:57,401 - INFO  - Training [61][  120/  196]   Loss 0.233147   Top1 91.868490   Top5 99.176432   BatchTime 0.352673   LR 0.000131   
2022-11-25 13:26:04,331 - INFO  - Training [61][  140/  196]   Loss 0.231467   Top1 91.933594   Top5 99.218750   BatchTime 0.351789   LR 0.000128   
2022-11-25 13:26:11,288 - INFO  - Training [61][  160/  196]   Loss 0.233595   Top1 91.848145   Top5 99.191895   BatchTime 0.351293   LR 0.000125   
2022-11-25 13:26:18,191 - INFO  - Training [61][  180/  196]   Loss 0.233124   Top1 91.866319   Top5 99.171007   BatchTime 0.350614   LR 0.000122   
2022-11-25 13:26:23,757 - INFO  - ==> Top1: 91.830    Top5: 99.174    Loss: 0.233

2022-11-25 13:26:24,014 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:26:25,398 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:26:28,549 - INFO  - Validation [61][   20/   40]   Loss 0.288450   Top1 91.445312   Top5 99.648438   BatchTime 0.157444   
2022-11-25 13:26:29,628 - INFO  - Validation [61][   40/   40]   Loss 0.278455   Top1 91.550000   Top5 99.780000   BatchTime 0.105713   
2022-11-25 13:26:29,862 - INFO  - ==> Top1: 91.550    Top5: 99.780    Loss: 0.278

2022-11-25 13:26:29,862 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:26:29,862 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:26:29,862 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:26:29,863 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:26:30,013 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:26:30,015 - INFO  - >>>>>> Epoch  62
2022-11-25 13:26:30,017 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:26:38,617 - INFO  - Training [62][   20/  196]   Loss 0.246571   Top1 91.445312   Top5 98.867188   BatchTime 0.429886   LR 0.000117   
2022-11-25 13:26:45,810 - INFO  - Training [62][   40/  196]   Loss 0.247754   Top1 91.445312   Top5 98.896484   BatchTime 0.394770   LR 0.000114   
2022-11-25 13:26:52,418 - INFO  - Training [62][   60/  196]   Loss 0.245178   Top1 91.562500   Top5 98.932292   BatchTime 0.373302   LR 0.000111   
2022-11-25 13:26:59,321 - INFO  - Training [62][   80/  196]   Loss 0.244611   Top1 91.567383   Top5 99.057617   BatchTime 0.366268   LR 0.000108   
2022-11-25 13:27:06,106 - INFO  - Training [62][  100/  196]   Loss 0.233048   Top1 91.964844   Top5 99.152344   BatchTime 0.360864   LR 0.000105   
2022-11-25 13:27:13,042 - INFO  - Training [62][  120/  196]   Loss 0.228757   Top1 92.106120   Top5 99.195964   BatchTime 0.358517   LR 0.000102   
2022-11-25 13:27:19,878 - INFO  - Training [62][  140/  196]   Loss 0.226208   Top1 92.170759   Top5 99.255022   BatchTime 0.356128   LR 0.000100   
2022-11-25 13:27:26,883 - INFO  - Training [62][  160/  196]   Loss 0.230348   Top1 91.994629   Top5 99.223633   BatchTime 0.355394   LR 0.000097   
2022-11-25 13:27:33,821 - INFO  - Training [62][  180/  196]   Loss 0.230590   Top1 92.003038   Top5 99.218750   BatchTime 0.354450   LR 0.000094   
2022-11-25 13:27:39,707 - INFO  - ==> Top1: 92.002    Top5: 99.206    Loss: 0.230

2022-11-25 13:27:39,971 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:27:41,382 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:27:44,483 - INFO  - Validation [62][   20/   40]   Loss 0.344696   Top1 89.980469   Top5 99.589844   BatchTime 0.154970   
2022-11-25 13:27:45,829 - INFO  - Validation [62][   40/   40]   Loss 0.333738   Top1 90.180000   Top5 99.680000   BatchTime 0.111152   
2022-11-25 13:27:46,371 - INFO  - ==> Top1: 90.180    Top5: 99.680    Loss: 0.334

2022-11-25 13:27:46,372 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:27:46,372 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:27:46,372 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:27:46,372 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:27:46,507 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:27:46,508 - INFO  - >>>>>> Epoch  63
2022-11-25 13:27:46,510 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:27:54,790 - INFO  - Training [63][   20/  196]   Loss 0.246199   Top1 91.132812   Top5 98.554688   BatchTime 0.413850   LR 0.000090   
2022-11-25 13:28:01,745 - INFO  - Training [63][   40/  196]   Loss 0.250698   Top1 91.054688   Top5 98.808594   BatchTime 0.380793   LR 0.000087   
2022-11-25 13:28:08,784 - INFO  - Training [63][   60/  196]   Loss 0.247089   Top1 91.158854   Top5 98.932292   BatchTime 0.371182   LR 0.000085   
2022-11-25 13:28:15,888 - INFO  - Training [63][   80/  196]   Loss 0.243140   Top1 91.362305   Top5 99.023438   BatchTime 0.367185   LR 0.000082   
2022-11-25 13:28:22,740 - INFO  - Training [63][  100/  196]   Loss 0.233096   Top1 91.714844   Top5 99.082031   BatchTime 0.362268   LR 0.000080   
2022-11-25 13:28:29,688 - INFO  - Training [63][  120/  196]   Loss 0.226181   Top1 91.995443   Top5 99.156901   BatchTime 0.359793   LR 0.000077   
2022-11-25 13:28:36,503 - INFO  - Training [63][  140/  196]   Loss 0.223973   Top1 92.073103   Top5 99.218750   BatchTime 0.357064   LR 0.000075   
2022-11-25 13:28:43,745 - INFO  - Training [63][  160/  196]   Loss 0.226972   Top1 92.006836   Top5 99.211426   BatchTime 0.357699   LR 0.000072   
2022-11-25 13:28:50,699 - INFO  - Training [63][  180/  196]   Loss 0.227151   Top1 92.018229   Top5 99.184028   BatchTime 0.356584   LR 0.000070   
2022-11-25 13:28:56,509 - INFO  - ==> Top1: 92.068    Top5: 99.182    Loss: 0.226

2022-11-25 13:28:56,755 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:28:57,989 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:29:01,985 - INFO  - Validation [63][   20/   40]   Loss 0.294981   Top1 91.367188   Top5 99.707031   BatchTime 0.199707   
2022-11-25 13:29:03,537 - INFO  - Validation [63][   40/   40]   Loss 0.286536   Top1 91.540000   Top5 99.760000   BatchTime 0.138653   
2022-11-25 13:29:03,790 - INFO  - ==> Top1: 91.540    Top5: 99.760    Loss: 0.287

2022-11-25 13:29:03,790 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:29:03,790 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:29:03,790 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:29:03,791 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:29:03,936 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:29:03,937 - INFO  - >>>>>> Epoch  64
2022-11-25 13:29:03,939 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:29:13,191 - INFO  - Training [64][   20/  196]   Loss 0.245485   Top1 91.210938   Top5 98.515625   BatchTime 0.462448   LR 0.000066   
2022-11-25 13:29:19,945 - INFO  - Training [64][   40/  196]   Loss 0.239046   Top1 91.494141   Top5 98.740234   BatchTime 0.400082   LR 0.000064   
2022-11-25 13:29:26,588 - INFO  - Training [64][   60/  196]   Loss 0.236312   Top1 91.582031   Top5 98.938802   BatchTime 0.377426   LR 0.000062   
2022-11-25 13:29:33,681 - INFO  - Training [64][   80/  196]   Loss 0.234293   Top1 91.694336   Top5 99.072266   BatchTime 0.371735   LR 0.000059   
2022-11-25 13:29:40,776 - INFO  - Training [64][  100/  196]   Loss 0.227945   Top1 91.859375   Top5 99.136719   BatchTime 0.368341   LR 0.000057   
2022-11-25 13:29:47,768 - INFO  - Training [64][  120/  196]   Loss 0.226073   Top1 91.985677   Top5 99.202474   BatchTime 0.365217   LR 0.000055   
2022-11-25 13:29:54,802 - INFO  - Training [64][  140/  196]   Loss 0.224547   Top1 92.061942   Top5 99.277344   BatchTime 0.363287   LR 0.000053   
2022-11-25 13:30:01,840 - INFO  - Training [64][  160/  196]   Loss 0.226921   Top1 91.992188   Top5 99.265137   BatchTime 0.361859   LR 0.000051   
2022-11-25 13:30:08,798 - INFO  - Training [64][  180/  196]   Loss 0.227428   Top1 91.979167   Top5 99.253472   BatchTime 0.360310   LR 0.000049   
2022-11-25 13:30:13,247 - INFO  - ==> Top1: 92.016    Top5: 99.234    Loss: 0.227

2022-11-25 13:30:13,447 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:30:15,044 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:30:18,192 - INFO  - Validation [64][   20/   40]   Loss 0.309422   Top1 90.937500   Top5 99.648438   BatchTime 0.157311   
2022-11-25 13:30:19,752 - INFO  - Validation [64][   40/   40]   Loss 0.302381   Top1 91.020000   Top5 99.730000   BatchTime 0.117663   
2022-11-25 13:30:20,028 - INFO  - ==> Top1: 91.020    Top5: 99.730    Loss: 0.302

2022-11-25 13:30:20,028 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:30:20,029 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:30:20,029 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:30:20,029 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:30:20,167 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:30:20,169 - INFO  - >>>>>> Epoch  65
2022-11-25 13:30:20,171 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:30:28,884 - INFO  - Training [65][   20/  196]   Loss 0.250752   Top1 91.191406   Top5 98.535156   BatchTime 0.435496   LR 0.000046   
2022-11-25 13:30:35,935 - INFO  - Training [65][   40/  196]   Loss 0.249092   Top1 91.435547   Top5 98.730469   BatchTime 0.394032   LR 0.000044   
2022-11-25 13:30:42,778 - INFO  - Training [65][   60/  196]   Loss 0.240009   Top1 91.608073   Top5 98.880208   BatchTime 0.376745   LR 0.000042   
2022-11-25 13:30:49,511 - INFO  - Training [65][   80/  196]   Loss 0.240184   Top1 91.655273   Top5 99.028320   BatchTime 0.366721   LR 0.000040   
2022-11-25 13:30:56,192 - INFO  - Training [65][  100/  196]   Loss 0.232809   Top1 91.843750   Top5 99.105469   BatchTime 0.360184   LR 0.000039   
2022-11-25 13:31:03,289 - INFO  - Training [65][  120/  196]   Loss 0.227857   Top1 92.018229   Top5 99.166667   BatchTime 0.359289   LR 0.000037   
2022-11-25 13:31:10,080 - INFO  - Training [65][  140/  196]   Loss 0.227553   Top1 92.061942   Top5 99.210379   BatchTime 0.356473   LR 0.000035   
2022-11-25 13:31:16,778 - INFO  - Training [65][  160/  196]   Loss 0.229037   Top1 92.048340   Top5 99.208984   BatchTime 0.353770   LR 0.000033   
2022-11-25 13:31:23,578 - INFO  - Training [65][  180/  196]   Loss 0.229031   Top1 92.016059   Top5 99.177517   BatchTime 0.352244   LR 0.000032   
2022-11-25 13:31:27,901 - INFO  - ==> Top1: 92.038    Top5: 99.174    Loss: 0.229

2022-11-25 13:31:28,112 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:31:30,291 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:31:33,867 - INFO  - Validation [65][   20/   40]   Loss 0.288225   Top1 91.660156   Top5 99.667969   BatchTime 0.178680   
2022-11-25 13:31:36,341 - INFO  - Validation [65][   40/   40]   Loss 0.274153   Top1 91.770000   Top5 99.730000   BatchTime 0.151210   
2022-11-25 13:31:36,732 - INFO  - ==> Top1: 91.770    Top5: 99.730    Loss: 0.274

2022-11-25 13:31:36,732 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:31:36,733 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:31:36,733 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:31:36,733 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:31:36,866 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:31:36,867 - INFO  - >>>>>> Epoch  66
2022-11-25 13:31:36,869 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:31:46,342 - INFO  - Training [66][   20/  196]   Loss 0.250464   Top1 91.250000   Top5 98.769531   BatchTime 0.473535   LR 0.000029   
2022-11-25 13:31:52,981 - INFO  - Training [66][   40/  196]   Loss 0.249428   Top1 91.250000   Top5 98.847656   BatchTime 0.402733   LR 0.000028   
2022-11-25 13:31:59,742 - INFO  - Training [66][   60/  196]   Loss 0.245639   Top1 91.419271   Top5 98.971354   BatchTime 0.381171   LR 0.000026   
2022-11-25 13:32:06,426 - INFO  - Training [66][   80/  196]   Loss 0.238584   Top1 91.606445   Top5 99.121094   BatchTime 0.369426   LR 0.000025   
2022-11-25 13:32:13,585 - INFO  - Training [66][  100/  196]   Loss 0.232186   Top1 91.929688   Top5 99.179688   BatchTime 0.367130   LR 0.000023   
2022-11-25 13:32:20,505 - INFO  - Training [66][  120/  196]   Loss 0.226905   Top1 92.154948   Top5 99.225260   BatchTime 0.363612   LR 0.000022   
2022-11-25 13:32:27,114 - INFO  - Training [66][  140/  196]   Loss 0.226756   Top1 92.176339   Top5 99.268973   BatchTime 0.358874   LR 0.000021   
2022-11-25 13:32:34,058 - INFO  - Training [66][  160/  196]   Loss 0.228060   Top1 92.084961   Top5 99.252930   BatchTime 0.357410   LR 0.000019   
2022-11-25 13:32:40,212 - INFO  - Training [66][  180/  196]   Loss 0.228805   Top1 92.035590   Top5 99.251302   BatchTime 0.351886   LR 0.000018   
2022-11-25 13:32:44,607 - INFO  - ==> Top1: 92.040    Top5: 99.252    Loss: 0.227

2022-11-25 13:32:44,827 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:32:46,365 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:32:49,090 - INFO  - Validation [66][   20/   40]   Loss 0.293746   Top1 91.796875   Top5 99.628906   BatchTime 0.136200   
2022-11-25 13:32:50,171 - INFO  - Validation [66][   40/   40]   Loss 0.284201   Top1 91.660000   Top5 99.720000   BatchTime 0.095125   
2022-11-25 13:32:50,463 - INFO  - ==> Top1: 91.660    Top5: 99.720    Loss: 0.284

2022-11-25 13:32:50,464 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:32:50,464 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:32:50,465 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:32:50,465 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:32:50,611 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:32:50,613 - INFO  - >>>>>> Epoch  67
2022-11-25 13:32:50,615 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:32:59,285 - INFO  - Training [67][   20/  196]   Loss 0.245847   Top1 91.113281   Top5 98.710938   BatchTime 0.433356   LR 0.000016   
2022-11-25 13:33:05,873 - INFO  - Training [67][   40/  196]   Loss 0.248298   Top1 91.162109   Top5 98.828125   BatchTime 0.381384   LR 0.000015   
2022-11-25 13:33:12,573 - INFO  - Training [67][   60/  196]   Loss 0.243553   Top1 91.549479   Top5 98.873698   BatchTime 0.365925   LR 0.000014   
2022-11-25 13:33:19,504 - INFO  - Training [67][   80/  196]   Loss 0.241344   Top1 91.547852   Top5 99.013672   BatchTime 0.361076   LR 0.000013   
2022-11-25 13:33:26,169 - INFO  - Training [67][  100/  196]   Loss 0.234500   Top1 91.804688   Top5 99.082031   BatchTime 0.355515   LR 0.000012   
2022-11-25 13:33:33,060 - INFO  - Training [67][  120/  196]   Loss 0.226953   Top1 92.044271   Top5 99.147135   BatchTime 0.353686   LR 0.000011   
2022-11-25 13:33:39,967 - INFO  - Training [67][  140/  196]   Loss 0.224698   Top1 92.176339   Top5 99.190848   BatchTime 0.352494   LR 0.000010   
2022-11-25 13:33:46,802 - INFO  - Training [67][  160/  196]   Loss 0.225073   Top1 92.106934   Top5 99.184570   BatchTime 0.351147   LR 0.000009   
2022-11-25 13:33:52,556 - INFO  - Training [67][  180/  196]   Loss 0.225456   Top1 92.107205   Top5 99.153646   BatchTime 0.344097   LR 0.000008   
2022-11-25 13:33:56,808 - INFO  - ==> Top1: 92.116    Top5: 99.150    Loss: 0.225

2022-11-25 13:33:57,008 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:33:58,687 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:34:01,600 - INFO  - Validation [67][   20/   40]   Loss 0.345864   Top1 89.882812   Top5 99.511719   BatchTime 0.145554   
2022-11-25 13:34:02,752 - INFO  - Validation [67][   40/   40]   Loss 0.336730   Top1 89.860000   Top5 99.620000   BatchTime 0.101574   
2022-11-25 13:34:03,005 - INFO  - ==> Top1: 89.860    Top5: 99.620    Loss: 0.337

2022-11-25 13:34:03,005 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:34:03,006 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:34:03,006 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:34:03,006 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:34:03,178 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:34:03,180 - INFO  - >>>>>> Epoch  68
2022-11-25 13:34:03,181 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:34:12,404 - INFO  - Training [68][   20/  196]   Loss 0.237456   Top1 91.171875   Top5 99.101562   BatchTime 0.460966   LR 0.000007   
2022-11-25 13:34:19,140 - INFO  - Training [68][   40/  196]   Loss 0.237626   Top1 91.357422   Top5 99.091797   BatchTime 0.398908   LR 0.000006   
2022-11-25 13:34:25,727 - INFO  - Training [68][   60/  196]   Loss 0.231117   Top1 91.705729   Top5 99.153646   BatchTime 0.375721   LR 0.000006   
2022-11-25 13:34:32,638 - INFO  - Training [68][   80/  196]   Loss 0.232315   Top1 91.689453   Top5 99.218750   BatchTime 0.368176   LR 0.000005   
2022-11-25 13:34:39,653 - INFO  - Training [68][  100/  196]   Loss 0.227303   Top1 91.878906   Top5 99.218750   BatchTime 0.364687   LR 0.000004   
2022-11-25 13:34:46,426 - INFO  - Training [68][  120/  196]   Loss 0.224722   Top1 92.027995   Top5 99.254557   BatchTime 0.360349   LR 0.000004   
2022-11-25 13:34:53,313 - INFO  - Training [68][  140/  196]   Loss 0.223292   Top1 92.151228   Top5 99.296875   BatchTime 0.358063   LR 0.000003   
2022-11-25 13:34:59,985 - INFO  - Training [68][  160/  196]   Loss 0.224551   Top1 92.128906   Top5 99.299316   BatchTime 0.355000   LR 0.000003   
2022-11-25 13:35:05,975 - INFO  - Training [68][  180/  196]   Loss 0.224498   Top1 92.148438   Top5 99.262153   BatchTime 0.348835   LR 0.000002   
2022-11-25 13:35:10,420 - INFO  - ==> Top1: 92.172    Top5: 99.242    Loss: 0.224

2022-11-25 13:35:10,674 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:35:12,144 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:35:15,155 - INFO  - Validation [68][   20/   40]   Loss 0.458188   Top1 86.777344   Top5 99.394531   BatchTime 0.150465   
2022-11-25 13:35:16,281 - INFO  - Validation [68][   40/   40]   Loss 0.446593   Top1 86.940000   Top5 99.490000   BatchTime 0.103403   
2022-11-25 13:35:16,566 - INFO  - ==> Top1: 86.940    Top5: 99.490    Loss: 0.447

2022-11-25 13:35:16,566 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:35:16,566 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:35:16,566 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:35:16,567 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:35:16,716 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:35:16,717 - INFO  - >>>>>> Epoch  69
2022-11-25 13:35:16,719 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:35:25,282 - INFO  - Training [69][   20/  196]   Loss 0.244078   Top1 91.191406   Top5 98.652344   BatchTime 0.427978   LR 0.000002   
2022-11-25 13:35:32,342 - INFO  - Training [69][   40/  196]   Loss 0.250525   Top1 91.064453   Top5 98.769531   BatchTime 0.390511   LR 0.000001   
2022-11-25 13:35:39,316 - INFO  - Training [69][   60/  196]   Loss 0.243051   Top1 91.354167   Top5 98.925781   BatchTime 0.376570   LR 0.000001   
2022-11-25 13:35:46,400 - INFO  - Training [69][   80/  196]   Loss 0.241242   Top1 91.459961   Top5 99.082031   BatchTime 0.370970   LR 0.000001   
2022-11-25 13:35:53,269 - INFO  - Training [69][  100/  196]   Loss 0.234740   Top1 91.730469   Top5 99.121094   BatchTime 0.365463   LR 0.000000   
2022-11-25 13:35:59,985 - INFO  - Training [69][  120/  196]   Loss 0.227237   Top1 92.057292   Top5 99.173177   BatchTime 0.360524   LR 0.000000   
2022-11-25 13:36:06,707 - INFO  - Training [69][  140/  196]   Loss 0.225908   Top1 92.117746   Top5 99.215960   BatchTime 0.357032   LR 0.000000   
2022-11-25 13:36:13,389 - INFO  - Training [69][  160/  196]   Loss 0.227539   Top1 92.036133   Top5 99.218750   BatchTime 0.354163   LR 0.000000   
2022-11-25 13:36:18,899 - INFO  - Training [69][  180/  196]   Loss 0.227729   Top1 92.033420   Top5 99.220920   BatchTime 0.345422   LR 0.000000   
2022-11-25 13:36:23,783 - INFO  - ==> Top1: 92.032    Top5: 99.236    Loss: 0.227

2022-11-25 13:36:24,050 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:36:25,619 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:36:29,722 - INFO  - Validation [69][   20/   40]   Loss 0.308643   Top1 91.171875   Top5 99.589844   BatchTime 0.205046   
2022-11-25 13:36:31,083 - INFO  - Validation [69][   40/   40]   Loss 0.298489   Top1 91.410000   Top5 99.700000   BatchTime 0.136545   
2022-11-25 13:36:31,377 - INFO  - ==> Top1: 91.410    Top5: 99.700    Loss: 0.298

2022-11-25 13:36:31,378 - INFO  - ==> Sparsity : 0.569

2022-11-25 13:36:31,378 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 92.040   Top5: 99.800]
2022-11-25 13:36:31,378 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 91.920   Top5: 99.810]
2022-11-25 13:36:31,378 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 91.770   Top5: 99.800]
2022-11-25 13:36:31,505 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103844/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:36:31,506 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 13:36:31,507 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:36:34,348 - INFO  - Validation [   20/   40]   Loss 0.308643   Top1 91.171875   Top5 99.589844   BatchTime 0.141965   
2022-11-25 13:36:35,438 - INFO  - Validation [   40/   40]   Loss 0.298489   Top1 91.410000   Top5 99.700000   BatchTime 0.098250   
2022-11-25 13:36:35,603 - INFO  - ==> Top1: 91.410    Top5: 99.700    Loss: 0.298

2022-11-25 13:36:35,604 - INFO  - ==> Sparsity : 0.000

2022-11-25 13:36:35,604 - INFO  - Program completed sucessfully ... exiting ...
