2022-10-28 08:28:08,812 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-082808/88_20221028-082808.log
2022-10-28 08:28:10,552 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 08:28:10,586 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-28 08:28:10,752 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 08:28:10,752 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 08:28:12,021 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 08:28:12,021 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:28:14,959 - INFO  - Validation [   20/   40]   Loss 3047.717822   Top1 12.753906   Top5 57.070312   BatchTime 0.146837   
2022-10-28 08:28:16,665 - INFO  - Validation [   40/   40]   Loss 3031.409704   Top1 12.670000   Top5 56.460000   BatchTime 0.116091   
2022-10-28 08:28:16,744 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-28 08:28:16,744 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 08:28:16,744 - INFO  - >>>>>> Epoch   0
2022-10-28 08:28:16,744 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 08:28:19,020 - INFO  - Training [0][   20/  196]   Loss 1.141794   Top1 69.843750   Top5 97.265625   BatchTime 0.113713   LR 0.001000   
2022-10-28 08:28:20,723 - INFO  - Training [0][   40/  196]   Loss 0.887083   Top1 75.595703   Top5 98.056641   BatchTime 0.099453   LR 0.001000   
2022-10-28 08:28:22,423 - INFO  - Training [0][   60/  196]   Loss 0.748270   Top1 78.639323   Top5 98.489583   BatchTime 0.094634   LR 0.001000   
2022-10-28 08:28:24,123 - INFO  - Training [0][   80/  196]   Loss 0.671700   Top1 80.390625   Top5 98.715820   BatchTime 0.092220   LR 0.001000   
2022-10-28 08:28:25,823 - INFO  - Training [0][  100/  196]   Loss 0.616460   Top1 81.656250   Top5 98.898438   BatchTime 0.090774   LR 0.001000   
2022-10-28 08:28:27,523 - INFO  - Training [0][  120/  196]   Loss 0.576433   Top1 82.688802   Top5 99.003906   BatchTime 0.089810   LR 0.001000   
2022-10-28 08:28:29,223 - INFO  - Training [0][  140/  196]   Loss 0.542614   Top1 83.496094   Top5 99.101562   BatchTime 0.089123   LR 0.001000   
2022-10-28 08:28:30,921 - INFO  - Training [0][  160/  196]   Loss 0.518249   Top1 84.108887   Top5 99.155273   BatchTime 0.088599   LR 0.001000   
2022-10-28 08:28:32,603 - INFO  - Training [0][  180/  196]   Loss 0.497523   Top1 84.607205   Top5 99.192708   BatchTime 0.088099   LR 0.001000   
2022-10-28 08:28:34,008 - INFO  - ==> Top1: 84.988    Top5: 99.224    Loss: 0.484

