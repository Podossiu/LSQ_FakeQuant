2022-10-20 18:29:01,505 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221020-182901/88_20221020-182901.log
2022-10-20 18:29:02,692 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-20 18:29:02,725 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-20 18:29:02,770 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-20 18:29:02,771 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-20 18:29:03,909 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-20 18:29:03,910 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:29:04,759 - INFO  - Validation [   20/   40]   Loss 3047.717615   Top1 12.753906   Top5 57.070312   BatchTime 0.042465   
2022-10-20 18:29:04,900 - INFO  - Validation [   40/   40]   Loss 3031.409504   Top1 12.670000   Top5 56.460000   BatchTime 0.024744   
2022-10-20 18:29:04,970 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-20 18:29:04,971 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-20 18:29:04,971 - INFO  - >>>>>> Epoch   0
2022-10-20 18:29:04,971 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:29:06,055 - INFO  - Training [0][   20/  196]   Loss 1.065406   Top1 71.406250   Top5 97.519531   BatchTime 0.054209   LR 0.001000   
2022-10-20 18:29:06,568 - INFO  - Training [0][   40/  196]   Loss 0.840642   Top1 76.455078   Top5 98.164062   BatchTime 0.039913   LR 0.001000   
2022-10-20 18:29:07,082 - INFO  - Training [0][   60/  196]   Loss 0.725722   Top1 78.873698   Top5 98.502604   BatchTime 0.035174   LR 0.001000   
2022-10-20 18:29:07,594 - INFO  - Training [0][   80/  196]   Loss 0.654162   Top1 80.537109   Top5 98.745117   BatchTime 0.032782   LR 0.001000   
