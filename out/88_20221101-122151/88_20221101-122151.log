2022-11-01 12:21:51,088 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221101-122151/88_20221101-122151.log
2022-11-01 12:21:52,320 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-01 12:21:52,413 - INFO  - Created `mobilenetv2` model
          Use pre-trained model = True
2022-11-01 12:21:53,088 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-11-01 12:21:53,088 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-11-01 12:21:54,269 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-01 12:21:54,269 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-01 12:21:57,948 - INFO  - Validation [   20/   40]   Loss nan   Top1 10.078125   Top5 50.019531   BatchTime 0.182110   
2022-11-01 12:21:59,288 - INFO  - Validation [   40/   40]   Loss nan   Top1 10.000000   Top5 50.000000   BatchTime 0.124555   
2022-11-01 12:21:59,385 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: nan

2022-11-01 12:21:59,385 - INFO  - ==> Sparsity : 0.059

2022-11-01 12:21:59,385 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 50.000]
2022-11-01 12:21:59,385 - INFO  - >>>>>> Epoch   0
2022-11-01 12:21:59,386 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-01 12:22:03,137 - INFO  - Training [0][   20/  196]   Loss 20.311611   Top1 0.214844   Top5 1.152344   BatchTime 0.187411   LR 0.001000   
2022-11-01 12:22:06,050 - INFO  - Training [0][   40/  196]   Loss 18.808511   Top1 0.654297   Top5 2.968750   BatchTime 0.166531   LR 0.001000   
2022-11-01 12:22:08,985 - INFO  - Training [0][   60/  196]   Loss 17.949870   Top1 1.542969   Top5 7.089844   BatchTime 0.159930   LR 0.001000   
2022-11-01 12:22:11,866 - INFO  - Training [0][   80/  196]   Loss 17.355677   Top1 2.729492   Top5 11.865234   BatchTime 0.155960   LR 0.001000   
2022-11-01 12:22:14,688 - INFO  - Training [0][  100/  196]   Loss 16.899815   Top1 4.050781   Top5 16.886719   BatchTime 0.152993   LR 0.001000   
2022-11-01 12:22:17,490 - INFO  - Training [0][  120/  196]   Loss 16.502160   Top1 5.253906   Top5 21.901042   BatchTime 0.150837   LR 0.001000   
2022-11-01 12:22:20,339 - INFO  - Training [0][  140/  196]   Loss 16.154996   Top1 6.495536   Top5 26.615513   BatchTime 0.149644   LR 0.001000   
2022-11-01 12:22:23,196 - INFO  - Training [0][  160/  196]   Loss 15.849555   Top1 7.541504   Top5 30.693359   BatchTime 0.148794   LR 0.001000   
2022-11-01 12:22:25,979 - INFO  - Training [0][  180/  196]   Loss 15.576734   Top1 8.563368   Top5 34.401042   BatchTime 0.147721   LR 0.001000   
2022-11-01 12:22:28,319 - INFO  - ==> Top1: 9.220    Top5: 36.900    Loss: 15.394

2022-11-01 12:22:28,415 - INFO  - Created `mobilenetv2` model
          Use pre-trained model = False
2022-11-01 12:22:29,332 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-01 12:22:33,081 - INFO  - Validation [0][   20/   40]   Loss 3.269605   Top1 16.972656   Top5 66.816406   BatchTime 0.187393   
2022-11-01 12:22:35,888 - INFO  - Validation [0][   40/   40]   Loss 3.253660   Top1 17.300000   Top5 67.550000   BatchTime 0.163874   
2022-11-01 12:22:36,024 - INFO  - ==> Top1: 17.300    Top5: 67.550    Loss: 3.254

2022-11-01 12:22:36,024 - INFO  - ==> Sparsity : 0.107

2022-11-01 12:22:36,059 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-01 12:22:37,364 - INFO  - Validation [0][   20/   40]   Loss 3.541002   Top1 16.757812   Top5 64.453125   BatchTime 0.065185   
2022-11-01 12:22:37,778 - INFO  - Validation [0][   40/   40]   Loss 3.499859   Top1 16.920000   Top5 64.830000   BatchTime 0.042956   
