2022-10-20 17:35:04,671 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221020-173504/88_20221020-173504.log
2022-10-20 17:35:05,858 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-20 17:35:05,894 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-20 17:35:06,020 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.1
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-20 17:35:06,021 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.1

2022-10-20 17:35:07,169 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-20 17:35:07,169 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:35:08,615 - INFO  - Validation [   20/   40]   Loss 4.050640   Top1 15.332031   Top5 67.363281   BatchTime 0.072283   
2022-10-20 17:35:09,264 - INFO  - Validation [   40/   40]   Loss 4.047568   Top1 15.560000   Top5 67.030000   BatchTime 0.052365   
2022-10-20 17:35:09,339 - INFO  - ==> Top1: 15.560    Top5: 67.030    Loss: 4.048

2022-10-20 17:35:09,339 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 15.560   Top5: 67.030]
2022-10-20 17:35:09,339 - INFO  - >>>>>> Epoch   0
2022-10-20 17:35:09,339 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:35:11,446 - INFO  - Training [0][   20/  196]   Loss 2.212336   Top1 24.570312   Top5 66.757812   BatchTime 0.105270   LR 0.100000   
2022-10-20 17:35:13,000 - INFO  - Training [0][   40/  196]   Loss 2.147134   Top1 23.125000   Top5 66.923828   BatchTime 0.091488   LR 0.100000   
2022-10-20 17:35:14,555 - INFO  - Training [0][   60/  196]   Loss 2.105369   Top1 23.307292   Top5 67.076823   BatchTime 0.086912   LR 0.100000   
2022-10-20 17:35:16,107 - INFO  - Training [0][   80/  196]   Loss 2.069435   Top1 24.189453   Top5 67.480469   BatchTime 0.084580   LR 0.100000   
2022-10-20 17:35:17,660 - INFO  - Training [0][  100/  196]   Loss 2.040523   Top1 25.097656   Top5 67.828125   BatchTime 0.083200   LR 0.100000   
2022-10-20 17:35:19,211 - INFO  - Training [0][  120/  196]   Loss 2.015518   Top1 26.074219   Top5 68.183594   BatchTime 0.082257   LR 0.100000   
2022-10-20 17:35:20,766 - INFO  - Training [0][  140/  196]   Loss 1.989223   Top1 27.218192   Top5 68.744420   BatchTime 0.081614   LR 0.100000   
2022-10-20 17:35:22,318 - INFO  - Training [0][  160/  196]   Loss 1.965779   Top1 28.149414   Top5 69.155273   BatchTime 0.081107   LR 0.100000   
2022-10-20 17:35:23,865 - INFO  - Training [0][  180/  196]   Loss 1.945280   Top1 29.199219   Top5 69.453125   BatchTime 0.080690   LR 0.100000   
2022-10-20 17:35:25,158 - INFO  - ==> Top1: 29.772    Top5: 69.708    Loss: 1.932

2022-10-20 17:35:25,229 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:35:26,303 - INFO  - Validation [0][   20/   40]   Loss 1.829843   Top1 37.929688   Top5 74.375000   BatchTime 0.053642   
2022-10-20 17:35:26,837 - INFO  - Validation [0][   40/   40]   Loss 1.844316   Top1 37.260000   Top5 74.170000   BatchTime 0.040189   
2022-10-20 17:35:26,915 - INFO  - ==> Top1: 37.260    Top5: 74.170    Loss: 1.844

2022-10-20 17:35:26,916 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:35:28,516 - INFO  - Validation [0][   20/   40]   Loss 2.106654   Top1 32.187500   Top5 77.187500   BatchTime 0.079986   
2022-10-20 17:35:29,319 - INFO  - Validation [0][   40/   40]   Loss 2.107962   Top1 31.680000   Top5 77.470000   BatchTime 0.060065   
2022-10-20 17:35:29,403 - INFO  - ==> Top1: 31.680    Top5: 77.470    Loss: 2.108

2022-10-20 17:35:29,403 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 31.680   Top5: 77.470]
2022-10-20 17:35:29,403 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 15.560   Top5: 67.030]
2022-10-20 17:35:31,149 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-173504/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-173504/88_best.pth.tar
save quantized models...
2022-10-20 17:35:31,149 - INFO  - >>>>>> Epoch   1
2022-10-20 17:35:31,149 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:35:33,296 - INFO  - Training [1][   20/  196]   Loss 1.736985   Top1 38.378906   Top5 73.300781   BatchTime 0.107291   LR 0.100000   
2022-10-20 17:35:34,858 - INFO  - Training [1][   40/  196]   Loss 1.720177   Top1 39.560547   Top5 73.642578   BatchTime 0.092700   LR 0.100000   
2022-10-20 17:35:36,429 - INFO  - Training [1][   60/  196]   Loss 1.711560   Top1 40.045573   Top5 73.684896   BatchTime 0.087984   LR 0.100000   
2022-10-20 17:35:37,987 - INFO  - Training [1][   80/  196]   Loss 1.697274   Top1 40.693359   Top5 74.116211   BatchTime 0.085461   LR 0.100000   
2022-10-20 17:35:39,547 - INFO  - Training [1][  100/  196]   Loss 1.683317   Top1 41.417969   Top5 74.089844   BatchTime 0.083966   LR 0.100000   
2022-10-20 17:35:41,107 - INFO  - Training [1][  120/  196]   Loss 1.674656   Top1 41.712240   Top5 74.313151   BatchTime 0.082975   LR 0.100000   
2022-10-20 17:35:42,671 - INFO  - Training [1][  140/  196]   Loss 1.663713   Top1 42.167969   Top5 74.534040   BatchTime 0.082287   LR 0.100000   
2022-10-20 17:35:44,228 - INFO  - Training [1][  160/  196]   Loss 1.654116   Top1 42.573242   Top5 74.641113   BatchTime 0.081733   LR 0.100000   
2022-10-20 17:35:45,780 - INFO  - Training [1][  180/  196]   Loss 1.645330   Top1 42.836372   Top5 74.858941   BatchTime 0.081274   LR 0.100000   
2022-10-20 17:35:47,072 - INFO  - ==> Top1: 43.000    Top5: 75.016    Loss: 1.641

2022-10-20 17:35:47,144 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:35:48,239 - INFO  - Validation [1][   20/   40]   Loss 1.854540   Top1 43.300781   Top5 74.902344   BatchTime 0.054734   
2022-10-20 17:35:48,777 - INFO  - Validation [1][   40/   40]   Loss 1.852200   Top1 42.730000   Top5 75.000000   BatchTime 0.040813   
2022-10-20 17:35:48,849 - INFO  - ==> Top1: 42.730    Top5: 75.000    Loss: 1.852

2022-10-20 17:35:48,849 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:35:50,407 - INFO  - Validation [1][   20/   40]   Loss 5.556462   Top1 22.382812   Top5 62.421875   BatchTime 0.077899   
2022-10-20 17:35:51,197 - INFO  - Validation [1][   40/   40]   Loss 5.549132   Top1 22.440000   Top5 62.230000   BatchTime 0.058693   
2022-10-20 17:35:51,290 - INFO  - ==> Top1: 22.440    Top5: 62.230    Loss: 5.549

2022-10-20 17:35:51,290 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 31.680   Top5: 77.470]
2022-10-20 17:35:51,290 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 22.440   Top5: 62.230]
2022-10-20 17:35:51,290 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 15.560   Top5: 67.030]
2022-10-20 17:35:51,363 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-173504/88_checkpoint.pth.tar

2022-10-20 17:35:51,364 - INFO  - >>>>>> Epoch   2
2022-10-20 17:35:51,364 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:35:53,553 - INFO  - Training [2][   20/  196]   Loss 1.539163   Top1 46.796875   Top5 76.445312   BatchTime 0.109442   LR 0.100000   
2022-10-20 17:35:55,118 - INFO  - Training [2][   40/  196]   Loss 1.504629   Top1 48.154297   Top5 79.863281   BatchTime 0.093830   LR 0.100000   
2022-10-20 17:35:56,674 - INFO  - Training [2][   60/  196]   Loss 1.481973   Top1 48.736979   Top5 81.464844   BatchTime 0.088484   LR 0.100000   
2022-10-20 17:35:58,234 - INFO  - Training [2][   80/  196]   Loss 1.468050   Top1 49.101562   Top5 82.348633   BatchTime 0.085867   LR 0.100000   
2022-10-20 17:35:59,795 - INFO  - Training [2][  100/  196]   Loss 1.446302   Top1 49.894531   Top5 83.003906   BatchTime 0.084300   LR 0.100000   
