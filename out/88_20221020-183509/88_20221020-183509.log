2022-10-20 18:35:09,800 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221020-183509/88_20221020-183509.log
2022-10-20 18:35:10,989 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-20 18:35:11,022 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-20 18:35:11,026 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-20 18:35:11,026 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-20 18:35:12,199 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-20 18:35:12,199 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:35:13,045 - INFO  - Validation [   20/   40]   Loss 3047.717615   Top1 12.753906   Top5 57.070312   BatchTime 0.042313   
2022-10-20 18:35:13,182 - INFO  - Validation [   40/   40]   Loss 3031.409504   Top1 12.670000   Top5 56.460000   BatchTime 0.024572   
2022-10-20 18:35:13,239 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-20 18:35:13,239 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-20 18:35:13,239 - INFO  - >>>>>> Epoch   0
2022-10-20 18:35:13,239 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:35:14,319 - INFO  - Training [0][   20/  196]   Loss 1.053250   Top1 71.289062   Top5 97.656250   BatchTime 0.053955   LR 0.001000   
2022-10-20 18:35:14,834 - INFO  - Training [0][   40/  196]   Loss 0.838544   Top1 76.132812   Top5 98.417969   BatchTime 0.039847   LR 0.001000   
2022-10-20 18:35:15,349 - INFO  - Training [0][   60/  196]   Loss 0.724287   Top1 78.808594   Top5 98.626302   BatchTime 0.035157   LR 0.001000   
2022-10-20 18:35:15,863 - INFO  - Training [0][   80/  196]   Loss 0.653088   Top1 80.610352   Top5 98.833008   BatchTime 0.032791   LR 0.001000   
2022-10-20 18:35:16,379 - INFO  - Training [0][  100/  196]   Loss 0.604728   Top1 81.746094   Top5 98.937500   BatchTime 0.031392   LR 0.001000   
2022-10-20 18:35:16,896 - INFO  - Training [0][  120/  196]   Loss 0.562871   Top1 82.815755   Top5 99.059245   BatchTime 0.030469   LR 0.001000   
2022-10-20 18:35:17,409 - INFO  - Training [0][  140/  196]   Loss 0.533363   Top1 83.457031   Top5 99.148996   BatchTime 0.029778   LR 0.001000   
2022-10-20 18:35:17,923 - INFO  - Training [0][  160/  196]   Loss 0.509189   Top1 84.089355   Top5 99.208984   BatchTime 0.029267   LR 0.001000   
2022-10-20 18:35:18,433 - INFO  - Training [0][  180/  196]   Loss 0.489678   Top1 84.594184   Top5 99.251302   BatchTime 0.028849   LR 0.001000   
2022-10-20 18:35:18,900 - INFO  - ==> Top1: 84.894    Top5: 99.284    Loss: 0.478

2022-10-20 18:35:18,922 - INFO  - Validation: 10000 samples (256 per mini-batch)
