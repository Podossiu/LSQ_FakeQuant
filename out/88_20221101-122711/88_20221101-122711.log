2022-11-01 12:27:11,535 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221101-122711/88_20221101-122711.log
2022-11-01 12:27:12,772 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-01 12:27:12,865 - INFO  - Created `mobilenetv2` model
          Use pre-trained model = True
2022-11-01 12:27:13,526 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-11-01 12:27:13,526 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-11-01 12:27:14,594 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-11-01 12:27:14,594 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-01 12:27:18,185 - INFO  - Validation [   20/   40]   Loss nan   Top1 10.078125   Top5 50.019531   BatchTime 0.179427   
2022-11-01 12:27:19,555 - INFO  - Validation [   40/   40]   Loss nan   Top1 10.000000   Top5 50.000000   BatchTime 0.123973   
2022-11-01 12:27:19,644 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: nan

2022-11-01 12:27:19,644 - INFO  - ==> Sparsity : 0.059

2022-11-01 12:27:19,644 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 10.000   Top5: 50.000]
2022-11-01 12:27:19,644 - INFO  - >>>>>> Epoch   0
2022-11-01 12:27:19,645 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-01 12:27:23,419 - INFO  - Training [0][   20/  196]   Loss 20.478684   Top1 0.156250   Top5 0.820312   BatchTime 0.188522   LR 0.001000   
2022-11-01 12:27:26,250 - INFO  - Training [0][   40/  196]   Loss 18.932515   Top1 0.566406   Top5 3.027344   BatchTime 0.165033   LR 0.001000   
2022-11-01 12:27:29,175 - INFO  - Training [0][   60/  196]   Loss 18.079574   Top1 1.393229   Top5 6.627604   BatchTime 0.158770   LR 0.001000   
2022-11-01 12:27:32,037 - INFO  - Training [0][   80/  196]   Loss 17.489400   Top1 2.451172   Top5 11.000977   BatchTime 0.154861   LR 0.001000   
2022-11-01 12:27:34,922 - INFO  - Training [0][  100/  196]   Loss 17.036260   Top1 3.515625   Top5 15.570312   BatchTime 0.152731   LR 0.001000   
2022-11-01 12:27:37,816 - INFO  - Training [0][  120/  196]   Loss 16.633612   Top1 5.000000   Top5 20.647786   BatchTime 0.151393   LR 0.001000   
2022-11-01 12:27:40,700 - INFO  - Training [0][  140/  196]   Loss 16.280373   Top1 6.325335   Top5 25.340402   BatchTime 0.150368   LR 0.001000   
2022-11-01 12:27:43,594 - INFO  - Training [0][  160/  196]   Loss 15.969596   Top1 7.514648   Top5 29.741211   BatchTime 0.149656   LR 0.001000   
2022-11-01 12:27:46,403 - INFO  - Training [0][  180/  196]   Loss 15.690143   Top1 8.734809   Top5 33.793403   BatchTime 0.148632   LR 0.001000   
2022-11-01 12:27:48,728 - INFO  - ==> Top1: 9.474    Top5: 36.248    Loss: 15.507

2022-11-01 12:27:48,826 - INFO  - Created `mobilenetv2` model
          Use pre-trained model = False
2022-11-01 12:27:49,719 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-01 12:27:53,528 - INFO  - Validation [0][   20/   40]   Loss 3.207553   Top1 20.156250   Top5 69.433594   BatchTime 0.190393   
2022-11-01 12:27:56,305 - INFO  - Validation [0][   40/   40]   Loss 3.206598   Top1 20.390000   Top5 69.070000   BatchTime 0.164623   
2022-11-01 12:27:56,448 - INFO  - ==> Top1: 20.390    Top5: 69.070    Loss: 3.207

2022-11-01 12:27:56,448 - INFO  - ==> Sparsity : 0.107

2022-11-01 12:27:56,484 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-01 12:27:57,818 - INFO  - Validation [0][   20/   40]   Loss 3.511102   Top1 18.515625   Top5 66.914062   BatchTime 0.066661   
2022-11-01 12:27:58,181 - INFO  - Validation [0][   40/   40]   Loss 3.479146   Top1 18.430000   Top5 66.860000   BatchTime 0.042401   
