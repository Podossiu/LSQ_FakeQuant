2022-10-28 08:36:53,025 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-083653/88_20221028-083653.log
2022-10-28 08:36:54,773 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 08:36:54,806 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-28 08:36:54,984 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 08:36:54,984 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 08:36:56,248 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 08:36:56,248 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:36:59,264 - INFO  - Validation [   20/   40]   Loss 3047.717822   Top1 12.753906   Top5 57.070312   BatchTime 0.150742   
2022-10-28 08:37:00,778 - INFO  - Validation [   40/   40]   Loss 3031.409704   Top1 12.670000   Top5 56.460000   BatchTime 0.113238   
2022-10-28 08:37:00,847 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-28 08:37:00,847 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 08:37:00,847 - INFO  - >>>>>> Epoch   0
2022-10-28 08:37:00,847 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 08:37:03,102 - INFO  - Training [0][   20/  196]   Loss 1.132054   Top1 70.742188   Top5 97.226562   BatchTime 0.112688   LR 0.001000   
2022-10-28 08:37:04,803 - INFO  - Training [0][   40/  196]   Loss 0.871179   Top1 75.703125   Top5 98.037109   BatchTime 0.098886   LR 0.001000   
2022-10-28 08:37:06,505 - INFO  - Training [0][   60/  196]   Loss 0.749066   Top1 78.587240   Top5 98.489583   BatchTime 0.094277   LR 0.001000   
2022-10-28 08:37:08,205 - INFO  - Training [0][   80/  196]   Loss 0.669373   Top1 80.585938   Top5 98.681641   BatchTime 0.091968   LR 0.001000   
2022-10-28 08:37:09,907 - INFO  - Training [0][  100/  196]   Loss 0.610547   Top1 81.863281   Top5 98.871094   BatchTime 0.090591   LR 0.001000   
2022-10-28 08:37:11,609 - INFO  - Training [0][  120/  196]   Loss 0.573099   Top1 82.708333   Top5 98.994141   BatchTime 0.089672   LR 0.001000   
2022-10-28 08:37:13,310 - INFO  - Training [0][  140/  196]   Loss 0.539046   Top1 83.568638   Top5 99.090402   BatchTime 0.089011   LR 0.001000   
2022-10-28 08:37:15,012 - INFO  - Training [0][  160/  196]   Loss 0.516757   Top1 84.143066   Top5 99.152832   BatchTime 0.088523   LR 0.001000   
2022-10-28 08:37:16,697 - INFO  - Training [0][  180/  196]   Loss 0.499374   Top1 84.548611   Top5 99.201389   BatchTime 0.088050   LR 0.001000   
2022-10-28 08:37:18,102 - INFO  - ==> Top1: 84.866    Top5: 99.238    Loss: 0.486

