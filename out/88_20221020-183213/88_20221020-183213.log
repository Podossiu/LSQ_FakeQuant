2022-10-20 18:32:14,003 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221020-183213/88_20221020-183213.log
2022-10-20 18:32:15,189 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-20 18:32:15,222 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-20 18:32:15,268 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-20 18:32:15,268 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-20 18:32:16,456 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-20 18:32:16,456 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:32:17,336 - INFO  - Validation [   20/   40]   Loss 3047.717615   Top1 12.753906   Top5 57.070312   BatchTime 0.043962   
2022-10-20 18:32:17,475 - INFO  - Validation [   40/   40]   Loss 3031.409504   Top1 12.670000   Top5 56.460000   BatchTime 0.025446   
2022-10-20 18:32:17,532 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-20 18:32:17,532 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-20 18:32:17,533 - INFO  - >>>>>> Epoch   0
2022-10-20 18:32:17,533 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:32:18,611 - INFO  - Training [0][   20/  196]   Loss 1.154690   Top1 69.433594   Top5 96.933594   BatchTime 0.053880   LR 0.001000   
2022-10-20 18:32:19,124 - INFO  - Training [0][   40/  196]   Loss 0.892593   Top1 75.283203   Top5 97.949219   BatchTime 0.039783   LR 0.001000   
2022-10-20 18:32:19,641 - INFO  - Training [0][   60/  196]   Loss 0.749731   Top1 78.463542   Top5 98.385417   BatchTime 0.035130   LR 0.001000   
2022-10-20 18:32:20,154 - INFO  - Training [0][   80/  196]   Loss 0.665593   Top1 80.468750   Top5 98.666992   BatchTime 0.032762   LR 0.001000   
2022-10-20 18:32:20,668 - INFO  - Training [0][  100/  196]   Loss 0.611609   Top1 81.707031   Top5 98.839844   BatchTime 0.031346   LR 0.001000   
2022-10-20 18:32:21,182 - INFO  - Training [0][  120/  196]   Loss 0.572533   Top1 82.594401   Top5 98.984375   BatchTime 0.030405   LR 0.001000   
2022-10-20 18:32:21,696 - INFO  - Training [0][  140/  196]   Loss 0.543278   Top1 83.356585   Top5 99.045759   BatchTime 0.029730   LR 0.001000   
2022-10-20 18:32:22,212 - INFO  - Training [0][  160/  196]   Loss 0.516667   Top1 84.013672   Top5 99.111328   BatchTime 0.029239   LR 0.001000   
2022-10-20 18:32:22,720 - INFO  - Training [0][  180/  196]   Loss 0.495311   Top1 84.578993   Top5 99.179688   BatchTime 0.028817   LR 0.001000   
2022-10-20 18:32:23,190 - INFO  - ==> Top1: 84.972    Top5: 99.216    Loss: 0.481

2022-10-20 18:32:23,212 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:32:23,851 - INFO  - Validation [0][   20/   40]   Loss 0.446639   Top1 86.757812   Top5 99.355469   BatchTime 0.031913   
2022-10-20 18:32:23,979 - INFO  - Validation [0][   40/   40]   Loss 0.435763   Top1 86.740000   Top5 99.400000   BatchTime 0.019163   
2022-10-20 18:32:24,049 - INFO  - ==> Top1: 86.740    Top5: 99.400    Loss: 0.436

2022-10-20 18:32:24,049 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:32:26,974 - INFO  - Validation [0][   20/   40]   Loss 0.446638   Top1 86.757812   Top5 99.355469   BatchTime 0.146212   
2022-10-20 18:32:29,193 - INFO  - Validation [0][   40/   40]   Loss 0.435763   Top1 86.740000   Top5 99.400000   BatchTime 0.128580   
2022-10-20 18:32:29,260 - INFO  - ==> Top1: 86.740    Top5: 99.400    Loss: 0.436

2022-10-20 18:32:29,260 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 86.740   Top5: 99.400]
2022-10-20 18:32:29,260 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-20 18:32:30,900 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-183213/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-183213/88_best.pth.tar
save quantized models...
2022-10-20 18:32:30,900 - INFO  - >>>>>> Epoch   1
2022-10-20 18:32:30,900 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:32:31,996 - INFO  - Training [1][   20/  196]   Loss 0.309220   Top1 88.964844   Top5 99.765625   BatchTime 0.054759   LR 0.001000   
2022-10-20 18:32:32,509 - INFO  - Training [1][   40/  196]   Loss 0.302416   Top1 89.306641   Top5 99.775391   BatchTime 0.040220   LR 0.001000   
