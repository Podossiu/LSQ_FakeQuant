2022-10-20 16:51:23,794 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_20221020-165123.log
2022-10-20 16:51:24,980 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-20 16:51:25,014 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-20 16:51:25,138 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.01
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-20 16:51:25,138 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.01

2022-10-20 16:51:26,288 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-20 16:51:26,288 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:51:27,693 - INFO  - Validation [   20/   40]   Loss 4.050640   Top1 15.332031   Top5 67.363281   BatchTime 0.070202   
2022-10-20 16:51:28,343 - INFO  - Validation [   40/   40]   Loss 4.047568   Top1 15.560000   Top5 67.030000   BatchTime 0.051342   
2022-10-20 16:51:28,406 - INFO  - ==> Top1: 15.560    Top5: 67.030    Loss: 4.048

2022-10-20 16:51:28,406 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 15.560   Top5: 67.030]
2022-10-20 16:51:28,406 - INFO  - >>>>>> Epoch   0
2022-10-20 16:51:28,406 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:51:30,518 - INFO  - Training [0][   20/  196]   Loss 1.094194   Top1 67.968750   Top5 94.648438   BatchTime 0.105548   LR 0.010000   
2022-10-20 16:51:32,072 - INFO  - Training [0][   40/  196]   Loss 0.950720   Top1 70.527344   Top5 95.742188   BatchTime 0.091628   LR 0.010000   
2022-10-20 16:51:33,628 - INFO  - Training [0][   60/  196]   Loss 0.875562   Top1 72.265625   Top5 96.308594   BatchTime 0.087009   LR 0.010000   
2022-10-20 16:51:35,182 - INFO  - Training [0][   80/  196]   Loss 0.817793   Top1 73.715820   Top5 96.762695   BatchTime 0.084689   LR 0.010000   
2022-10-20 16:51:36,737 - INFO  - Training [0][  100/  196]   Loss 0.774345   Top1 74.785156   Top5 97.035156   BatchTime 0.083295   LR 0.010000   
2022-10-20 16:51:38,294 - INFO  - Training [0][  120/  196]   Loss 0.743742   Top1 75.543620   Top5 97.304688   BatchTime 0.082390   LR 0.010000   
2022-10-20 16:51:39,850 - INFO  - Training [0][  140/  196]   Loss 0.721918   Top1 76.093750   Top5 97.463728   BatchTime 0.081729   LR 0.010000   
2022-10-20 16:51:41,405 - INFO  - Training [0][  160/  196]   Loss 0.704135   Top1 76.608887   Top5 97.636719   BatchTime 0.081233   LR 0.010000   
2022-10-20 16:51:42,953 - INFO  - Training [0][  180/  196]   Loss 0.686588   Top1 77.128906   Top5 97.771267   BatchTime 0.080809   LR 0.010000   
2022-10-20 16:51:44,238 - INFO  - ==> Top1: 77.502    Top5: 97.848    Loss: 0.674

2022-10-20 16:51:44,303 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:51:45,367 - INFO  - Validation [0][   20/   40]   Loss 0.720802   Top1 75.722656   Top5 98.066406   BatchTime 0.053129   
2022-10-20 16:51:45,900 - INFO  - Validation [0][   40/   40]   Loss 0.732732   Top1 75.390000   Top5 98.100000   BatchTime 0.039912   
2022-10-20 16:51:45,963 - INFO  - ==> Top1: 75.390    Top5: 98.100    Loss: 0.733

2022-10-20 16:51:45,963 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:51:47,530 - INFO  - Validation [0][   20/   40]   Loss 0.724285   Top1 76.113281   Top5 98.164062   BatchTime 0.078337   
2022-10-20 16:51:48,402 - INFO  - Validation [0][   40/   40]   Loss 0.739764   Top1 75.530000   Top5 98.150000   BatchTime 0.060977   
2022-10-20 16:51:48,481 - INFO  - ==> Top1: 75.530    Top5: 98.150    Loss: 0.740

2022-10-20 16:51:48,481 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 75.530   Top5: 98.150]
2022-10-20 16:51:48,481 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 15.560   Top5: 67.030]
2022-10-20 16:51:50,172 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 16:51:50,172 - INFO  - >>>>>> Epoch   1
2022-10-20 16:51:50,172 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:51:52,322 - INFO  - Training [1][   20/  196]   Loss 0.483459   Top1 83.066406   Top5 98.945312   BatchTime 0.107439   LR 0.010000   
2022-10-20 16:51:53,873 - INFO  - Training [1][   40/  196]   Loss 0.496624   Top1 82.685547   Top5 98.837891   BatchTime 0.092504   LR 0.010000   
2022-10-20 16:51:55,433 - INFO  - Training [1][   60/  196]   Loss 0.497172   Top1 82.819010   Top5 98.821615   BatchTime 0.087669   LR 0.010000   
2022-10-20 16:51:56,986 - INFO  - Training [1][   80/  196]   Loss 0.500886   Top1 82.749023   Top5 98.842773   BatchTime 0.085157   LR 0.010000   
2022-10-20 16:51:58,546 - INFO  - Training [1][  100/  196]   Loss 0.499343   Top1 82.687500   Top5 98.851562   BatchTime 0.083723   LR 0.010000   
2022-10-20 16:52:00,098 - INFO  - Training [1][  120/  196]   Loss 0.498411   Top1 82.669271   Top5 98.867188   BatchTime 0.082706   LR 0.010000   
2022-10-20 16:52:01,658 - INFO  - Training [1][  140/  196]   Loss 0.498587   Top1 82.633929   Top5 98.856027   BatchTime 0.082034   LR 0.010000   
2022-10-20 16:52:03,211 - INFO  - Training [1][  160/  196]   Loss 0.493760   Top1 82.800293   Top5 98.876953   BatchTime 0.081481   LR 0.010000   
2022-10-20 16:52:04,758 - INFO  - Training [1][  180/  196]   Loss 0.492388   Top1 82.905816   Top5 98.904080   BatchTime 0.081024   LR 0.010000   
2022-10-20 16:52:06,050 - INFO  - ==> Top1: 82.886    Top5: 98.920    Loss: 0.492

2022-10-20 16:52:06,119 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:52:07,204 - INFO  - Validation [1][   20/   40]   Loss 0.805701   Top1 75.390625   Top5 97.929688   BatchTime 0.054219   
2022-10-20 16:52:07,736 - INFO  - Validation [1][   40/   40]   Loss 0.806127   Top1 75.540000   Top5 98.090000   BatchTime 0.040414   
2022-10-20 16:52:07,806 - INFO  - ==> Top1: 75.540    Top5: 98.090    Loss: 0.806

2022-10-20 16:52:07,807 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:52:09,359 - INFO  - Validation [1][   20/   40]   Loss 0.809259   Top1 75.312500   Top5 97.792969   BatchTime 0.077610   
2022-10-20 16:52:10,152 - INFO  - Validation [1][   40/   40]   Loss 0.809980   Top1 75.600000   Top5 97.900000   BatchTime 0.058617   
2022-10-20 16:52:10,239 - INFO  - ==> Top1: 75.600    Top5: 97.900    Loss: 0.810

2022-10-20 16:52:10,239 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 75.600   Top5: 97.900]
2022-10-20 16:52:10,239 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 75.530   Top5: 98.150]
2022-10-20 16:52:10,239 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 15.560   Top5: 67.030]
2022-10-20 16:52:12,225 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 16:52:12,225 - INFO  - >>>>>> Epoch   2
2022-10-20 16:52:12,225 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:52:14,416 - INFO  - Training [2][   20/  196]   Loss 0.449433   Top1 83.769531   Top5 99.218750   BatchTime 0.109501   LR 0.010000   
2022-10-20 16:52:15,978 - INFO  - Training [2][   40/  196]   Loss 0.453001   Top1 84.013672   Top5 99.179688   BatchTime 0.093782   LR 0.010000   
2022-10-20 16:52:17,542 - INFO  - Training [2][   60/  196]   Loss 0.449827   Top1 84.121094   Top5 99.108073   BatchTime 0.088585   LR 0.010000   
2022-10-20 16:52:19,101 - INFO  - Training [2][   80/  196]   Loss 0.447301   Top1 84.238281   Top5 99.082031   BatchTime 0.085925   LR 0.010000   
2022-10-20 16:52:20,657 - INFO  - Training [2][  100/  196]   Loss 0.447941   Top1 84.300781   Top5 99.109375   BatchTime 0.084303   LR 0.010000   
2022-10-20 16:52:22,213 - INFO  - Training [2][  120/  196]   Loss 0.448778   Top1 84.293620   Top5 99.091797   BatchTime 0.083220   LR 0.010000   
2022-10-20 16:52:23,769 - INFO  - Training [2][  140/  196]   Loss 0.446270   Top1 84.391741   Top5 99.123884   BatchTime 0.082446   LR 0.010000   
2022-10-20 16:52:25,325 - INFO  - Training [2][  160/  196]   Loss 0.448323   Top1 84.345703   Top5 99.118652   BatchTime 0.081865   LR 0.010000   
2022-10-20 16:52:26,873 - INFO  - Training [2][  180/  196]   Loss 0.448123   Top1 84.329427   Top5 99.129774   BatchTime 0.081369   LR 0.010000   
2022-10-20 16:52:28,165 - INFO  - ==> Top1: 84.320    Top5: 99.148    Loss: 0.448

2022-10-20 16:52:28,236 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:52:29,325 - INFO  - Validation [2][   20/   40]   Loss 0.774538   Top1 75.839844   Top5 98.222656   BatchTime 0.054394   
2022-10-20 16:52:29,865 - INFO  - Validation [2][   40/   40]   Loss 0.777083   Top1 75.650000   Top5 98.410000   BatchTime 0.040714   
2022-10-20 16:52:29,939 - INFO  - ==> Top1: 75.650    Top5: 98.410    Loss: 0.777

2022-10-20 16:52:29,939 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:52:31,509 - INFO  - Validation [2][   20/   40]   Loss 0.780940   Top1 76.210938   Top5 98.554688   BatchTime 0.078448   
2022-10-20 16:52:32,302 - INFO  - Validation [2][   40/   40]   Loss 0.782779   Top1 76.030000   Top5 98.600000   BatchTime 0.059070   
2022-10-20 16:52:32,387 - INFO  - ==> Top1: 76.030    Top5: 98.600    Loss: 0.783

2022-10-20 16:52:32,387 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 76.030   Top5: 98.600]
2022-10-20 16:52:32,387 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 75.600   Top5: 97.900]
2022-10-20 16:52:32,387 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 75.530   Top5: 98.150]
2022-10-20 16:52:34,378 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 16:52:34,379 - INFO  - >>>>>> Epoch   3
2022-10-20 16:52:34,380 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:52:36,546 - INFO  - Training [3][   20/  196]   Loss 0.422935   Top1 85.507812   Top5 99.316406   BatchTime 0.108146   LR 0.010000   
2022-10-20 16:52:38,106 - INFO  - Training [3][   40/  196]   Loss 0.419272   Top1 85.458984   Top5 99.248047   BatchTime 0.093078   LR 0.010000   
2022-10-20 16:52:39,659 - INFO  - Training [3][   60/  196]   Loss 0.415285   Top1 85.403646   Top5 99.231771   BatchTime 0.087941   LR 0.010000   
2022-10-20 16:52:41,210 - INFO  - Training [3][   80/  196]   Loss 0.419901   Top1 85.283203   Top5 99.218750   BatchTime 0.085334   LR 0.010000   
2022-10-20 16:52:42,764 - INFO  - Training [3][  100/  196]   Loss 0.424229   Top1 85.050781   Top5 99.210938   BatchTime 0.083807   LR 0.010000   
2022-10-20 16:52:44,322 - INFO  - Training [3][  120/  196]   Loss 0.422693   Top1 85.133464   Top5 99.218750   BatchTime 0.082827   LR 0.010000   
2022-10-20 16:52:45,877 - INFO  - Training [3][  140/  196]   Loss 0.422654   Top1 85.136719   Top5 99.193638   BatchTime 0.082098   LR 0.010000   
2022-10-20 16:52:47,427 - INFO  - Training [3][  160/  196]   Loss 0.423921   Top1 85.109863   Top5 99.194336   BatchTime 0.081526   LR 0.010000   
2022-10-20 16:52:48,972 - INFO  - Training [3][  180/  196]   Loss 0.424163   Top1 85.101997   Top5 99.201389   BatchTime 0.081049   LR 0.010000   
2022-10-20 16:52:50,260 - INFO  - ==> Top1: 85.168    Top5: 99.210    Loss: 0.423

2022-10-20 16:52:50,368 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:52:51,465 - INFO  - Validation [3][   20/   40]   Loss 0.561480   Top1 80.722656   Top5 98.984375   BatchTime 0.054825   
2022-10-20 16:52:52,000 - INFO  - Validation [3][   40/   40]   Loss 0.565141   Top1 80.660000   Top5 98.920000   BatchTime 0.040779   
2022-10-20 16:52:52,067 - INFO  - ==> Top1: 80.660    Top5: 98.920    Loss: 0.565

2022-10-20 16:52:52,067 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:52:53,654 - INFO  - Validation [3][   20/   40]   Loss 0.562664   Top1 81.230469   Top5 99.082031   BatchTime 0.079294   
2022-10-20 16:52:54,450 - INFO  - Validation [3][   40/   40]   Loss 0.567841   Top1 81.150000   Top5 98.970000   BatchTime 0.059547   
2022-10-20 16:52:54,534 - INFO  - ==> Top1: 81.150    Top5: 98.970    Loss: 0.568

2022-10-20 16:52:54,534 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 81.150   Top5: 98.970]
2022-10-20 16:52:54,534 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 76.030   Top5: 98.600]
2022-10-20 16:52:54,534 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 75.600   Top5: 97.900]
2022-10-20 16:52:56,488 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 16:52:56,490 - INFO  - >>>>>> Epoch   4
2022-10-20 16:52:56,490 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:52:58,731 - INFO  - Training [4][   20/  196]   Loss 0.395452   Top1 86.445312   Top5 99.296875   BatchTime 0.111895   LR 0.010000   
2022-10-20 16:53:00,291 - INFO  - Training [4][   40/  196]   Loss 0.400405   Top1 86.191406   Top5 99.335938   BatchTime 0.094956   LR 0.010000   
2022-10-20 16:53:01,851 - INFO  - Training [4][   60/  196]   Loss 0.397105   Top1 86.250000   Top5 99.322917   BatchTime 0.089301   LR 0.010000   
2022-10-20 16:53:03,413 - INFO  - Training [4][   80/  196]   Loss 0.399038   Top1 86.137695   Top5 99.301758   BatchTime 0.086507   LR 0.010000   
2022-10-20 16:53:04,970 - INFO  - Training [4][  100/  196]   Loss 0.405344   Top1 85.917969   Top5 99.289062   BatchTime 0.084768   LR 0.010000   
2022-10-20 16:53:06,529 - INFO  - Training [4][  120/  196]   Loss 0.408164   Top1 85.807292   Top5 99.283854   BatchTime 0.083632   LR 0.010000   
2022-10-20 16:53:08,088 - INFO  - Training [4][  140/  196]   Loss 0.409752   Top1 85.691964   Top5 99.229911   BatchTime 0.082820   LR 0.010000   
2022-10-20 16:53:09,649 - INFO  - Training [4][  160/  196]   Loss 0.411097   Top1 85.654297   Top5 99.243164   BatchTime 0.082224   LR 0.010000   
2022-10-20 16:53:11,198 - INFO  - Training [4][  180/  196]   Loss 0.410061   Top1 85.692274   Top5 99.253472   BatchTime 0.081691   LR 0.010000   
2022-10-20 16:53:12,503 - INFO  - ==> Top1: 85.698    Top5: 99.258    Loss: 0.410

2022-10-20 16:53:12,575 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:53:13,717 - INFO  - Validation [4][   20/   40]   Loss 0.878929   Top1 74.453125   Top5 97.324219   BatchTime 0.057102   
2022-10-20 16:53:14,254 - INFO  - Validation [4][   40/   40]   Loss 0.886101   Top1 74.120000   Top5 97.460000   BatchTime 0.041978   
2022-10-20 16:53:14,342 - INFO  - ==> Top1: 74.120    Top5: 97.460    Loss: 0.886

2022-10-20 16:53:14,342 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:53:16,054 - INFO  - Validation [4][   20/   40]   Loss 0.881899   Top1 75.058594   Top5 97.519531   BatchTime 0.085595   
2022-10-20 16:53:16,947 - INFO  - Validation [4][   40/   40]   Loss 0.887452   Top1 74.580000   Top5 97.680000   BatchTime 0.065123   
2022-10-20 16:53:17,035 - INFO  - ==> Top1: 74.580    Top5: 97.680    Loss: 0.887

2022-10-20 16:53:17,036 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 81.150   Top5: 98.970]
2022-10-20 16:53:17,036 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 76.030   Top5: 98.600]
2022-10-20 16:53:17,036 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 75.600   Top5: 97.900]
2022-10-20 16:53:17,126 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:53:17,127 - INFO  - >>>>>> Epoch   5
2022-10-20 16:53:17,127 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:53:19,342 - INFO  - Training [5][   20/  196]   Loss 0.389224   Top1 86.152344   Top5 99.355469   BatchTime 0.110731   LR 0.010000   
2022-10-20 16:53:20,899 - INFO  - Training [5][   40/  196]   Loss 0.386894   Top1 86.416016   Top5 99.404297   BatchTime 0.094292   LR 0.010000   
2022-10-20 16:53:22,456 - INFO  - Training [5][   60/  196]   Loss 0.389078   Top1 86.406250   Top5 99.316406   BatchTime 0.088800   LR 0.010000   
2022-10-20 16:53:24,011 - INFO  - Training [5][   80/  196]   Loss 0.395246   Top1 86.196289   Top5 99.262695   BatchTime 0.086047   LR 0.010000   
2022-10-20 16:53:25,567 - INFO  - Training [5][  100/  196]   Loss 0.394605   Top1 86.183594   Top5 99.257812   BatchTime 0.084397   LR 0.010000   
2022-10-20 16:53:27,124 - INFO  - Training [5][  120/  196]   Loss 0.391744   Top1 86.210938   Top5 99.264323   BatchTime 0.083299   LR 0.010000   
2022-10-20 16:53:28,678 - INFO  - Training [5][  140/  196]   Loss 0.390678   Top1 86.238839   Top5 99.282924   BatchTime 0.082504   LR 0.010000   
2022-10-20 16:53:30,232 - INFO  - Training [5][  160/  196]   Loss 0.389708   Top1 86.252441   Top5 99.284668   BatchTime 0.081897   LR 0.010000   
2022-10-20 16:53:31,777 - INFO  - Training [5][  180/  196]   Loss 0.388958   Top1 86.252170   Top5 99.294705   BatchTime 0.081381   LR 0.010000   
2022-10-20 16:53:33,070 - INFO  - ==> Top1: 86.180    Top5: 99.282    Loss: 0.392

2022-10-20 16:53:33,167 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:53:34,298 - INFO  - Validation [5][   20/   40]   Loss 0.655118   Top1 79.824219   Top5 98.671875   BatchTime 0.056495   
2022-10-20 16:53:34,830 - INFO  - Validation [5][   40/   40]   Loss 0.659026   Top1 79.620000   Top5 98.640000   BatchTime 0.041550   
2022-10-20 16:53:34,911 - INFO  - ==> Top1: 79.620    Top5: 98.640    Loss: 0.659

2022-10-20 16:53:34,911 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:53:36,510 - INFO  - Validation [5][   20/   40]   Loss 0.656731   Top1 79.531250   Top5 98.593750   BatchTime 0.079896   
2022-10-20 16:53:37,307 - INFO  - Validation [5][   40/   40]   Loss 0.661522   Top1 79.290000   Top5 98.570000   BatchTime 0.059878   
2022-10-20 16:53:37,401 - INFO  - ==> Top1: 79.290    Top5: 98.570    Loss: 0.662

2022-10-20 16:53:37,401 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 81.150   Top5: 98.970]
2022-10-20 16:53:37,401 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 79.290   Top5: 98.570]
2022-10-20 16:53:37,401 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 76.030   Top5: 98.600]
2022-10-20 16:53:37,495 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:53:37,495 - INFO  - >>>>>> Epoch   6
2022-10-20 16:53:37,495 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:53:39,700 - INFO  - Training [6][   20/  196]   Loss 0.383140   Top1 86.582031   Top5 99.316406   BatchTime 0.110154   LR 0.010000   
2022-10-20 16:53:41,259 - INFO  - Training [6][   40/  196]   Loss 0.393833   Top1 86.289062   Top5 99.267578   BatchTime 0.094073   LR 0.010000   
2022-10-20 16:53:42,819 - INFO  - Training [6][   60/  196]   Loss 0.381371   Top1 86.621094   Top5 99.309896   BatchTime 0.088700   LR 0.010000   
2022-10-20 16:53:44,377 - INFO  - Training [6][   80/  196]   Loss 0.377819   Top1 86.718750   Top5 99.335938   BatchTime 0.086008   LR 0.010000   
2022-10-20 16:53:45,936 - INFO  - Training [6][  100/  196]   Loss 0.377618   Top1 86.796875   Top5 99.339844   BatchTime 0.084395   LR 0.010000   
2022-10-20 16:53:47,495 - INFO  - Training [6][  120/  196]   Loss 0.377738   Top1 86.757812   Top5 99.348958   BatchTime 0.083318   LR 0.010000   
2022-10-20 16:53:49,054 - INFO  - Training [6][  140/  196]   Loss 0.377860   Top1 86.766183   Top5 99.361049   BatchTime 0.082553   LR 0.010000   
2022-10-20 16:53:50,614 - INFO  - Training [6][  160/  196]   Loss 0.377538   Top1 86.726074   Top5 99.357910   BatchTime 0.081981   LR 0.010000   
2022-10-20 16:53:52,164 - INFO  - Training [6][  180/  196]   Loss 0.376834   Top1 86.736111   Top5 99.346788   BatchTime 0.081485   LR 0.010000   
2022-10-20 16:53:53,464 - INFO  - ==> Top1: 86.730    Top5: 99.336    Loss: 0.377

2022-10-20 16:53:53,535 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:53:54,668 - INFO  - Validation [6][   20/   40]   Loss 0.588967   Top1 81.796875   Top5 98.632812   BatchTime 0.056592   
2022-10-20 16:53:55,202 - INFO  - Validation [6][   40/   40]   Loss 0.583990   Top1 81.600000   Top5 98.730000   BatchTime 0.041649   
2022-10-20 16:53:55,281 - INFO  - ==> Top1: 81.600    Top5: 98.730    Loss: 0.584

2022-10-20 16:53:55,281 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:53:56,893 - INFO  - Validation [6][   20/   40]   Loss 0.592813   Top1 81.425781   Top5 98.593750   BatchTime 0.080583   
2022-10-20 16:53:57,692 - INFO  - Validation [6][   40/   40]   Loss 0.587489   Top1 81.450000   Top5 98.680000   BatchTime 0.060262   
2022-10-20 16:53:57,783 - INFO  - ==> Top1: 81.450    Top5: 98.680    Loss: 0.587

2022-10-20 16:53:57,783 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 81.450   Top5: 98.680]
2022-10-20 16:53:57,783 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 81.150   Top5: 98.970]
2022-10-20 16:53:57,783 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 79.290   Top5: 98.570]
2022-10-20 16:53:59,661 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 16:53:59,662 - INFO  - >>>>>> Epoch   7
2022-10-20 16:53:59,662 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:54:01,902 - INFO  - Training [7][   20/  196]   Loss 0.351715   Top1 88.242188   Top5 99.375000   BatchTime 0.111859   LR 0.010000   
2022-10-20 16:54:03,459 - INFO  - Training [7][   40/  196]   Loss 0.354354   Top1 87.900391   Top5 99.394531   BatchTime 0.094853   LR 0.010000   
2022-10-20 16:54:05,016 - INFO  - Training [7][   60/  196]   Loss 0.356234   Top1 87.740885   Top5 99.375000   BatchTime 0.089185   LR 0.010000   
2022-10-20 16:54:06,571 - INFO  - Training [7][   80/  196]   Loss 0.359774   Top1 87.666016   Top5 99.365234   BatchTime 0.086326   LR 0.010000   
2022-10-20 16:54:08,125 - INFO  - Training [7][  100/  196]   Loss 0.363597   Top1 87.492188   Top5 99.355469   BatchTime 0.084600   LR 0.010000   
2022-10-20 16:54:09,682 - INFO  - Training [7][  120/  196]   Loss 0.366840   Top1 87.337240   Top5 99.342448   BatchTime 0.083470   LR 0.010000   
2022-10-20 16:54:11,233 - INFO  - Training [7][  140/  196]   Loss 0.366092   Top1 87.268415   Top5 99.372210   BatchTime 0.082625   LR 0.010000   
2022-10-20 16:54:12,786 - INFO  - Training [7][  160/  196]   Loss 0.365469   Top1 87.297363   Top5 99.353027   BatchTime 0.082005   LR 0.010000   
2022-10-20 16:54:14,331 - INFO  - Training [7][  180/  196]   Loss 0.365375   Top1 87.230903   Top5 99.377170   BatchTime 0.081475   LR 0.010000   
2022-10-20 16:54:15,634 - INFO  - ==> Top1: 87.156    Top5: 99.374    Loss: 0.367

2022-10-20 16:54:15,706 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:54:16,868 - INFO  - Validation [7][   20/   40]   Loss 0.554399   Top1 81.992188   Top5 98.867188   BatchTime 0.058048   
2022-10-20 16:54:17,407 - INFO  - Validation [7][   40/   40]   Loss 0.549305   Top1 82.210000   Top5 99.020000   BatchTime 0.042509   
2022-10-20 16:54:17,488 - INFO  - ==> Top1: 82.210    Top5: 99.020    Loss: 0.549

2022-10-20 16:54:17,488 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:54:19,086 - INFO  - Validation [7][   20/   40]   Loss 0.559813   Top1 82.089844   Top5 98.964844   BatchTime 0.079860   
2022-10-20 16:54:19,881 - INFO  - Validation [7][   40/   40]   Loss 0.555583   Top1 82.410000   Top5 99.030000   BatchTime 0.059818   
2022-10-20 16:54:19,966 - INFO  - ==> Top1: 82.410    Top5: 99.030    Loss: 0.556

2022-10-20 16:54:19,966 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 82.410   Top5: 99.030]
2022-10-20 16:54:19,966 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 81.450   Top5: 98.680]
2022-10-20 16:54:19,967 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 81.150   Top5: 98.970]
2022-10-20 16:54:22,136 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 16:54:22,137 - INFO  - >>>>>> Epoch   8
2022-10-20 16:54:22,137 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:54:24,304 - INFO  - Training [8][   20/  196]   Loss 0.345890   Top1 87.695312   Top5 99.453125   BatchTime 0.108311   LR 0.010000   
2022-10-20 16:54:25,866 - INFO  - Training [8][   40/  196]   Loss 0.351192   Top1 87.841797   Top5 99.375000   BatchTime 0.093184   LR 0.010000   
2022-10-20 16:54:27,426 - INFO  - Training [8][   60/  196]   Loss 0.352738   Top1 87.591146   Top5 99.414062   BatchTime 0.088131   LR 0.010000   
2022-10-20 16:54:28,985 - INFO  - Training [8][   80/  196]   Loss 0.354696   Top1 87.573242   Top5 99.394531   BatchTime 0.085583   LR 0.010000   
2022-10-20 16:54:30,544 - INFO  - Training [8][  100/  196]   Loss 0.354631   Top1 87.621094   Top5 99.394531   BatchTime 0.084055   LR 0.010000   
2022-10-20 16:54:32,103 - INFO  - Training [8][  120/  196]   Loss 0.355386   Top1 87.604167   Top5 99.391276   BatchTime 0.083037   LR 0.010000   
2022-10-20 16:54:33,662 - INFO  - Training [8][  140/  196]   Loss 0.353933   Top1 87.566964   Top5 99.414062   BatchTime 0.082310   LR 0.010000   
2022-10-20 16:54:35,221 - INFO  - Training [8][  160/  196]   Loss 0.354710   Top1 87.541504   Top5 99.426270   BatchTime 0.081765   LR 0.010000   
2022-10-20 16:54:36,771 - INFO  - Training [8][  180/  196]   Loss 0.357062   Top1 87.486979   Top5 99.398872   BatchTime 0.081294   LR 0.010000   
2022-10-20 16:54:38,082 - INFO  - ==> Top1: 87.414    Top5: 99.386    Loss: 0.359

2022-10-20 16:54:38,193 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:54:39,328 - INFO  - Validation [8][   20/   40]   Loss 0.605410   Top1 81.210938   Top5 98.769531   BatchTime 0.056707   
2022-10-20 16:54:39,862 - INFO  - Validation [8][   40/   40]   Loss 0.610269   Top1 81.150000   Top5 98.810000   BatchTime 0.041714   
2022-10-20 16:54:39,947 - INFO  - ==> Top1: 81.150    Top5: 98.810    Loss: 0.610

2022-10-20 16:54:39,947 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:54:41,570 - INFO  - Validation [8][   20/   40]   Loss 0.615562   Top1 81.113281   Top5 98.710938   BatchTime 0.081100   
2022-10-20 16:54:42,365 - INFO  - Validation [8][   40/   40]   Loss 0.617161   Top1 81.320000   Top5 98.760000   BatchTime 0.060437   
2022-10-20 16:54:42,458 - INFO  - ==> Top1: 81.320    Top5: 98.760    Loss: 0.617

2022-10-20 16:54:42,458 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 82.410   Top5: 99.030]
2022-10-20 16:54:42,459 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 81.450   Top5: 98.680]
2022-10-20 16:54:42,459 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 81.320   Top5: 98.760]
2022-10-20 16:54:42,551 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:54:42,551 - INFO  - >>>>>> Epoch   9
2022-10-20 16:54:42,551 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:54:44,769 - INFO  - Training [9][   20/  196]   Loss 0.328162   Top1 88.359375   Top5 99.609375   BatchTime 0.110847   LR 0.010000   
2022-10-20 16:54:46,330 - INFO  - Training [9][   40/  196]   Loss 0.337830   Top1 87.988281   Top5 99.570312   BatchTime 0.094443   LR 0.010000   
2022-10-20 16:54:47,891 - INFO  - Training [9][   60/  196]   Loss 0.339709   Top1 87.968750   Top5 99.511719   BatchTime 0.088969   LR 0.010000   
2022-10-20 16:54:49,451 - INFO  - Training [9][   80/  196]   Loss 0.342997   Top1 87.954102   Top5 99.448242   BatchTime 0.086225   LR 0.010000   
2022-10-20 16:54:51,011 - INFO  - Training [9][  100/  196]   Loss 0.343890   Top1 87.937500   Top5 99.414062   BatchTime 0.084582   LR 0.010000   
2022-10-20 16:54:52,571 - INFO  - Training [9][  120/  196]   Loss 0.345857   Top1 87.923177   Top5 99.404297   BatchTime 0.083487   LR 0.010000   
2022-10-20 16:54:54,132 - INFO  - Training [9][  140/  196]   Loss 0.346871   Top1 87.893415   Top5 99.411272   BatchTime 0.082706   LR 0.010000   
2022-10-20 16:54:55,692 - INFO  - Training [9][  160/  196]   Loss 0.346147   Top1 87.895508   Top5 99.418945   BatchTime 0.082120   LR 0.010000   
2022-10-20 16:54:57,243 - INFO  - Training [9][  180/  196]   Loss 0.348841   Top1 87.764757   Top5 99.429253   BatchTime 0.081610   LR 0.010000   
2022-10-20 16:54:58,549 - INFO  - ==> Top1: 87.838    Top5: 99.414    Loss: 0.348

2022-10-20 16:54:58,616 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:54:59,757 - INFO  - Validation [9][   20/   40]   Loss 0.552883   Top1 81.484375   Top5 98.789062   BatchTime 0.057010   
2022-10-20 16:55:00,293 - INFO  - Validation [9][   40/   40]   Loss 0.560822   Top1 81.420000   Top5 98.920000   BatchTime 0.041918   
2022-10-20 16:55:00,384 - INFO  - ==> Top1: 81.420    Top5: 98.920    Loss: 0.561

2022-10-20 16:55:00,384 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:55:01,996 - INFO  - Validation [9][   20/   40]   Loss 0.560082   Top1 81.582031   Top5 98.847656   BatchTime 0.080559   
2022-10-20 16:55:02,794 - INFO  - Validation [9][   40/   40]   Loss 0.566542   Top1 81.570000   Top5 98.970000   BatchTime 0.060235   
2022-10-20 16:55:02,885 - INFO  - ==> Top1: 81.570    Top5: 98.970    Loss: 0.567

2022-10-20 16:55:02,885 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 82.410   Top5: 99.030]
2022-10-20 16:55:02,885 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 81.570   Top5: 98.970]
2022-10-20 16:55:02,885 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 81.450   Top5: 98.680]
2022-10-20 16:55:03,003 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:55:03,004 - INFO  - >>>>>> Epoch  10
2022-10-20 16:55:03,004 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:55:05,284 - INFO  - Training [10][   20/  196]   Loss 0.321852   Top1 88.183594   Top5 99.531250   BatchTime 0.113822   LR 0.010000   
2022-10-20 16:55:06,846 - INFO  - Training [10][   40/  196]   Loss 0.321928   Top1 88.564453   Top5 99.482422   BatchTime 0.095967   LR 0.010000   
2022-10-20 16:55:08,408 - INFO  - Training [10][   60/  196]   Loss 0.325314   Top1 88.593750   Top5 99.479167   BatchTime 0.090017   LR 0.010000   
2022-10-20 16:55:09,970 - INFO  - Training [10][   80/  196]   Loss 0.332471   Top1 88.364258   Top5 99.423828   BatchTime 0.087033   LR 0.010000   
2022-10-20 16:55:11,535 - INFO  - Training [10][  100/  196]   Loss 0.329776   Top1 88.527344   Top5 99.453125   BatchTime 0.085274   LR 0.010000   
2022-10-20 16:55:13,094 - INFO  - Training [10][  120/  196]   Loss 0.331520   Top1 88.460286   Top5 99.436849   BatchTime 0.084054   LR 0.010000   
2022-10-20 16:55:14,655 - INFO  - Training [10][  140/  196]   Loss 0.332887   Top1 88.404018   Top5 99.450335   BatchTime 0.083199   LR 0.010000   
2022-10-20 16:55:16,220 - INFO  - Training [10][  160/  196]   Loss 0.333046   Top1 88.322754   Top5 99.472656   BatchTime 0.082576   LR 0.010000   
2022-10-20 16:55:17,778 - INFO  - Training [10][  180/  196]   Loss 0.332642   Top1 88.324653   Top5 99.483507   BatchTime 0.082057   LR 0.010000   
2022-10-20 16:55:19,085 - INFO  - ==> Top1: 88.278    Top5: 99.486    Loss: 0.335

2022-10-20 16:55:19,157 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:55:20,315 - INFO  - Validation [10][   20/   40]   Loss 0.538571   Top1 83.066406   Top5 98.867188   BatchTime 0.057868   
2022-10-20 16:55:20,847 - INFO  - Validation [10][   40/   40]   Loss 0.526391   Top1 83.270000   Top5 99.020000   BatchTime 0.042236   
2022-10-20 16:55:20,937 - INFO  - ==> Top1: 83.270    Top5: 99.020    Loss: 0.526

2022-10-20 16:55:20,937 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:55:22,544 - INFO  - Validation [10][   20/   40]   Loss 0.543247   Top1 82.871094   Top5 98.925781   BatchTime 0.080341   
2022-10-20 16:55:23,342 - INFO  - Validation [10][   40/   40]   Loss 0.533923   Top1 83.280000   Top5 99.030000   BatchTime 0.060131   
2022-10-20 16:55:23,426 - INFO  - ==> Top1: 83.280    Top5: 99.030    Loss: 0.534

2022-10-20 16:55:23,426 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:55:23,426 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 82.410   Top5: 99.030]
2022-10-20 16:55:23,426 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 81.570   Top5: 98.970]
2022-10-20 16:55:25,325 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 16:55:25,326 - INFO  - >>>>>> Epoch  11
2022-10-20 16:55:25,326 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:55:27,527 - INFO  - Training [11][   20/  196]   Loss 0.307654   Top1 89.492188   Top5 99.570312   BatchTime 0.110006   LR 0.010000   
2022-10-20 16:55:29,088 - INFO  - Training [11][   40/  196]   Loss 0.319382   Top1 88.974609   Top5 99.492188   BatchTime 0.094023   LR 0.010000   
2022-10-20 16:55:30,648 - INFO  - Training [11][   60/  196]   Loss 0.321402   Top1 88.906250   Top5 99.498698   BatchTime 0.088679   LR 0.010000   
2022-10-20 16:55:32,208 - INFO  - Training [11][   80/  196]   Loss 0.324544   Top1 88.745117   Top5 99.536133   BatchTime 0.086010   LR 0.010000   
2022-10-20 16:55:33,768 - INFO  - Training [11][  100/  196]   Loss 0.325833   Top1 88.769531   Top5 99.507812   BatchTime 0.084407   LR 0.010000   
2022-10-20 16:55:35,327 - INFO  - Training [11][  120/  196]   Loss 0.326515   Top1 88.772786   Top5 99.501953   BatchTime 0.083337   LR 0.010000   
2022-10-20 16:55:36,887 - INFO  - Training [11][  140/  196]   Loss 0.327012   Top1 88.685826   Top5 99.517299   BatchTime 0.082571   LR 0.010000   
2022-10-20 16:55:38,449 - INFO  - Training [11][  160/  196]   Loss 0.327158   Top1 88.688965   Top5 99.523926   BatchTime 0.082009   LR 0.010000   
2022-10-20 16:55:40,000 - INFO  - Training [11][  180/  196]   Loss 0.329321   Top1 88.626302   Top5 99.505208   BatchTime 0.081514   LR 0.010000   
2022-10-20 16:55:41,299 - INFO  - ==> Top1: 88.552    Top5: 99.502    Loss: 0.330

2022-10-20 16:55:41,365 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:55:42,515 - INFO  - Validation [11][   20/   40]   Loss 0.613046   Top1 80.683594   Top5 98.457031   BatchTime 0.057458   
2022-10-20 16:55:43,051 - INFO  - Validation [11][   40/   40]   Loss 0.622432   Top1 80.310000   Top5 98.610000   BatchTime 0.042153   
2022-10-20 16:55:43,127 - INFO  - ==> Top1: 80.310    Top5: 98.610    Loss: 0.622

2022-10-20 16:55:43,127 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:55:44,729 - INFO  - Validation [11][   20/   40]   Loss 0.621491   Top1 80.546875   Top5 98.535156   BatchTime 0.080092   
2022-10-20 16:55:45,529 - INFO  - Validation [11][   40/   40]   Loss 0.632258   Top1 80.200000   Top5 98.680000   BatchTime 0.060053   
2022-10-20 16:55:45,625 - INFO  - ==> Top1: 80.200    Top5: 98.680    Loss: 0.632

2022-10-20 16:55:45,625 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:55:45,626 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 82.410   Top5: 99.030]
2022-10-20 16:55:45,626 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 81.570   Top5: 98.970]
2022-10-20 16:55:45,714 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:55:45,714 - INFO  - >>>>>> Epoch  12
2022-10-20 16:55:45,714 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:55:47,915 - INFO  - Training [12][   20/  196]   Loss 0.322409   Top1 88.730469   Top5 99.218750   BatchTime 0.109999   LR 0.010000   
2022-10-20 16:55:49,470 - INFO  - Training [12][   40/  196]   Loss 0.308604   Top1 89.140625   Top5 99.404297   BatchTime 0.093869   LR 0.010000   
2022-10-20 16:55:51,026 - INFO  - Training [12][   60/  196]   Loss 0.310181   Top1 89.075521   Top5 99.479167   BatchTime 0.088503   LR 0.010000   
2022-10-20 16:55:52,581 - INFO  - Training [12][   80/  196]   Loss 0.308329   Top1 89.213867   Top5 99.501953   BatchTime 0.085817   LR 0.010000   
2022-10-20 16:55:54,136 - INFO  - Training [12][  100/  196]   Loss 0.314325   Top1 89.089844   Top5 99.457031   BatchTime 0.084200   LR 0.010000   
2022-10-20 16:55:55,691 - INFO  - Training [12][  120/  196]   Loss 0.315588   Top1 89.069010   Top5 99.459635   BatchTime 0.083130   LR 0.010000   
2022-10-20 16:55:57,247 - INFO  - Training [12][  140/  196]   Loss 0.317318   Top1 88.931362   Top5 99.447545   BatchTime 0.082364   LR 0.010000   
2022-10-20 16:55:58,802 - INFO  - Training [12][  160/  196]   Loss 0.318892   Top1 88.840332   Top5 99.445801   BatchTime 0.081789   LR 0.010000   
2022-10-20 16:56:00,351 - INFO  - Training [12][  180/  196]   Loss 0.320251   Top1 88.817274   Top5 99.459635   BatchTime 0.081305   LR 0.010000   
2022-10-20 16:56:01,652 - INFO  - ==> Top1: 88.726    Top5: 99.458    Loss: 0.322

2022-10-20 16:56:01,724 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:56:02,858 - INFO  - Validation [12][   20/   40]   Loss 0.570097   Top1 82.109375   Top5 98.867188   BatchTime 0.056685   
2022-10-20 16:56:03,396 - INFO  - Validation [12][   40/   40]   Loss 0.562465   Top1 82.070000   Top5 99.000000   BatchTime 0.041798   
2022-10-20 16:56:03,485 - INFO  - ==> Top1: 82.070    Top5: 99.000    Loss: 0.562

2022-10-20 16:56:03,486 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:56:05,134 - INFO  - Validation [12][   20/   40]   Loss 0.573258   Top1 82.011719   Top5 98.867188   BatchTime 0.082369   
2022-10-20 16:56:05,940 - INFO  - Validation [12][   40/   40]   Loss 0.567445   Top1 82.050000   Top5 98.980000   BatchTime 0.061349   
2022-10-20 16:56:06,043 - INFO  - ==> Top1: 82.050    Top5: 98.980    Loss: 0.567

2022-10-20 16:56:06,043 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:56:06,043 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 82.410   Top5: 99.030]
2022-10-20 16:56:06,043 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 82.050   Top5: 98.980]
2022-10-20 16:56:06,069 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:56:06,069 - INFO  - >>>>>> Epoch  13
2022-10-20 16:56:06,069 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:56:08,327 - INFO  - Training [13][   20/  196]   Loss 0.292197   Top1 90.195312   Top5 99.492188   BatchTime 0.112839   LR 0.010000   
2022-10-20 16:56:09,892 - INFO  - Training [13][   40/  196]   Loss 0.296710   Top1 90.029297   Top5 99.560547   BatchTime 0.095540   LR 0.010000   
2022-10-20 16:56:11,455 - INFO  - Training [13][   60/  196]   Loss 0.298945   Top1 89.967448   Top5 99.537760   BatchTime 0.089753   LR 0.010000   
2022-10-20 16:56:13,019 - INFO  - Training [13][   80/  196]   Loss 0.307006   Top1 89.541016   Top5 99.492188   BatchTime 0.086866   LR 0.010000   
2022-10-20 16:56:14,583 - INFO  - Training [13][  100/  196]   Loss 0.307633   Top1 89.515625   Top5 99.464844   BatchTime 0.085129   LR 0.010000   
2022-10-20 16:56:16,149 - INFO  - Training [13][  120/  196]   Loss 0.307823   Top1 89.391276   Top5 99.462891   BatchTime 0.083988   LR 0.010000   
2022-10-20 16:56:17,717 - INFO  - Training [13][  140/  196]   Loss 0.306440   Top1 89.455915   Top5 99.455915   BatchTime 0.083190   LR 0.010000   
2022-10-20 16:56:19,280 - INFO  - Training [13][  160/  196]   Loss 0.308212   Top1 89.338379   Top5 99.458008   BatchTime 0.082562   LR 0.010000   
2022-10-20 16:56:20,834 - INFO  - Training [13][  180/  196]   Loss 0.311354   Top1 89.207899   Top5 99.481337   BatchTime 0.082018   LR 0.010000   
2022-10-20 16:56:22,159 - INFO  - ==> Top1: 89.176    Top5: 99.480    Loss: 0.312

2022-10-20 16:56:22,226 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:56:23,371 - INFO  - Validation [13][   20/   40]   Loss 0.713565   Top1 79.316406   Top5 97.695312   BatchTime 0.057201   
2022-10-20 16:56:23,904 - INFO  - Validation [13][   40/   40]   Loss 0.703877   Top1 79.470000   Top5 97.740000   BatchTime 0.041922   
2022-10-20 16:56:23,979 - INFO  - ==> Top1: 79.470    Top5: 97.740    Loss: 0.704

2022-10-20 16:56:23,980 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:56:25,618 - INFO  - Validation [13][   20/   40]   Loss 0.720470   Top1 79.238281   Top5 97.597656   BatchTime 0.081873   
2022-10-20 16:56:26,424 - INFO  - Validation [13][   40/   40]   Loss 0.710572   Top1 79.310000   Top5 97.760000   BatchTime 0.061091   
2022-10-20 16:56:26,525 - INFO  - ==> Top1: 79.310    Top5: 97.760    Loss: 0.711

2022-10-20 16:56:26,525 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:56:26,525 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 82.410   Top5: 99.030]
2022-10-20 16:56:26,525 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 82.050   Top5: 98.980]
2022-10-20 16:56:26,585 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:56:26,585 - INFO  - >>>>>> Epoch  14
2022-10-20 16:56:26,586 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:56:28,808 - INFO  - Training [14][   20/  196]   Loss 0.297281   Top1 89.199219   Top5 99.628906   BatchTime 0.111057   LR 0.010000   
2022-10-20 16:56:30,371 - INFO  - Training [14][   40/  196]   Loss 0.304205   Top1 88.857422   Top5 99.628906   BatchTime 0.094609   LR 0.010000   
2022-10-20 16:56:31,934 - INFO  - Training [14][   60/  196]   Loss 0.303012   Top1 89.205729   Top5 99.602865   BatchTime 0.089119   LR 0.010000   
2022-10-20 16:56:33,496 - INFO  - Training [14][   80/  196]   Loss 0.300240   Top1 89.335938   Top5 99.614258   BatchTime 0.086365   LR 0.010000   
2022-10-20 16:56:35,058 - INFO  - Training [14][  100/  196]   Loss 0.301156   Top1 89.343750   Top5 99.597656   BatchTime 0.084715   LR 0.010000   
2022-10-20 16:56:36,621 - INFO  - Training [14][  120/  196]   Loss 0.304196   Top1 89.303385   Top5 99.583333   BatchTime 0.083617   LR 0.010000   
2022-10-20 16:56:38,184 - INFO  - Training [14][  140/  196]   Loss 0.305194   Top1 89.246652   Top5 99.575893   BatchTime 0.082838   LR 0.010000   
2022-10-20 16:56:39,746 - INFO  - Training [14][  160/  196]   Loss 0.307010   Top1 89.174805   Top5 99.577637   BatchTime 0.082245   LR 0.010000   
2022-10-20 16:56:41,301 - INFO  - Training [14][  180/  196]   Loss 0.308630   Top1 89.140625   Top5 99.583333   BatchTime 0.081744   LR 0.010000   
2022-10-20 16:56:42,611 - INFO  - ==> Top1: 89.120    Top5: 99.568    Loss: 0.309

2022-10-20 16:56:42,678 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:56:43,819 - INFO  - Validation [14][   20/   40]   Loss 0.562806   Top1 82.597656   Top5 98.886719   BatchTime 0.057015   
2022-10-20 16:56:44,359 - INFO  - Validation [14][   40/   40]   Loss 0.561479   Top1 82.450000   Top5 98.990000   BatchTime 0.042004   
2022-10-20 16:56:44,442 - INFO  - ==> Top1: 82.450    Top5: 98.990    Loss: 0.561

2022-10-20 16:56:44,443 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:56:46,065 - INFO  - Validation [14][   20/   40]   Loss 0.570889   Top1 82.675781   Top5 98.984375   BatchTime 0.081096   
2022-10-20 16:56:46,870 - INFO  - Validation [14][   40/   40]   Loss 0.566867   Top1 82.680000   Top5 99.070000   BatchTime 0.060663   
2022-10-20 16:56:46,971 - INFO  - ==> Top1: 82.680    Top5: 99.070    Loss: 0.567

2022-10-20 16:56:46,971 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:56:46,971 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 82.680   Top5: 99.070]
2022-10-20 16:56:46,971 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 82.410   Top5: 99.030]
2022-10-20 16:56:47,022 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:56:47,022 - INFO  - >>>>>> Epoch  15
2022-10-20 16:56:47,022 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:56:49,209 - INFO  - Training [15][   20/  196]   Loss 0.302622   Top1 88.964844   Top5 99.687500   BatchTime 0.109301   LR 0.010000   
2022-10-20 16:56:50,769 - INFO  - Training [15][   40/  196]   Loss 0.301720   Top1 89.169922   Top5 99.638672   BatchTime 0.093635   LR 0.010000   
2022-10-20 16:56:52,328 - INFO  - Training [15][   60/  196]   Loss 0.308701   Top1 88.997396   Top5 99.583333   BatchTime 0.088413   LR 0.010000   
2022-10-20 16:56:53,887 - INFO  - Training [15][   80/  196]   Loss 0.312234   Top1 88.916016   Top5 99.555664   BatchTime 0.085801   LR 0.010000   
2022-10-20 16:56:55,448 - INFO  - Training [15][  100/  196]   Loss 0.314696   Top1 88.863281   Top5 99.554688   BatchTime 0.084244   LR 0.010000   
2022-10-20 16:56:57,008 - INFO  - Training [15][  120/  196]   Loss 0.313199   Top1 88.961589   Top5 99.534505   BatchTime 0.083202   LR 0.010000   
2022-10-20 16:56:58,568 - INFO  - Training [15][  140/  196]   Loss 0.311134   Top1 89.017857   Top5 99.539621   BatchTime 0.082460   LR 0.010000   
2022-10-20 16:57:00,128 - INFO  - Training [15][  160/  196]   Loss 0.309921   Top1 89.067383   Top5 99.523926   BatchTime 0.081903   LR 0.010000   
2022-10-20 16:57:01,678 - INFO  - Training [15][  180/  196]   Loss 0.310286   Top1 89.019097   Top5 99.529080   BatchTime 0.081415   LR 0.010000   
2022-10-20 16:57:02,986 - INFO  - ==> Top1: 88.988    Top5: 99.534    Loss: 0.311

2022-10-20 16:57:03,052 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:57:04,195 - INFO  - Validation [15][   20/   40]   Loss 0.564457   Top1 82.851562   Top5 98.925781   BatchTime 0.057122   
2022-10-20 16:57:04,727 - INFO  - Validation [15][   40/   40]   Loss 0.558858   Top1 82.770000   Top5 99.080000   BatchTime 0.041869   
2022-10-20 16:57:04,815 - INFO  - ==> Top1: 82.770    Top5: 99.080    Loss: 0.559

2022-10-20 16:57:04,815 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:57:06,431 - INFO  - Validation [15][   20/   40]   Loss 0.570727   Top1 83.105469   Top5 98.769531   BatchTime 0.080782   
2022-10-20 16:57:07,229 - INFO  - Validation [15][   40/   40]   Loss 0.563320   Top1 82.810000   Top5 98.900000   BatchTime 0.060344   
2022-10-20 16:57:07,329 - INFO  - ==> Top1: 82.810    Top5: 98.900    Loss: 0.563

2022-10-20 16:57:07,329 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:57:07,330 - INFO  - Scoreboard best 2 ==> Epoch [15][Top1: 82.810   Top5: 98.900]
2022-10-20 16:57:07,330 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 82.680   Top5: 99.070]
2022-10-20 16:57:07,401 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:57:07,401 - INFO  - >>>>>> Epoch  16
2022-10-20 16:57:07,401 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:57:09,628 - INFO  - Training [16][   20/  196]   Loss 0.288832   Top1 90.097656   Top5 99.531250   BatchTime 0.111286   LR 0.010000   
2022-10-20 16:57:11,190 - INFO  - Training [16][   40/  196]   Loss 0.289132   Top1 90.058594   Top5 99.541016   BatchTime 0.094704   LR 0.010000   
2022-10-20 16:57:12,753 - INFO  - Training [16][   60/  196]   Loss 0.287844   Top1 90.013021   Top5 99.583333   BatchTime 0.089180   LR 0.010000   
2022-10-20 16:57:14,316 - INFO  - Training [16][   80/  196]   Loss 0.287376   Top1 90.083008   Top5 99.589844   BatchTime 0.086421   LR 0.010000   
2022-10-20 16:57:15,881 - INFO  - Training [16][  100/  196]   Loss 0.285892   Top1 90.089844   Top5 99.597656   BatchTime 0.084783   LR 0.010000   
2022-10-20 16:57:17,452 - INFO  - Training [16][  120/  196]   Loss 0.284588   Top1 90.055339   Top5 99.619141   BatchTime 0.083749   LR 0.010000   
2022-10-20 16:57:19,014 - INFO  - Training [16][  140/  196]   Loss 0.286591   Top1 89.952567   Top5 99.606585   BatchTime 0.082941   LR 0.010000   
2022-10-20 16:57:20,574 - INFO  - Training [16][  160/  196]   Loss 0.291932   Top1 89.733887   Top5 99.594727   BatchTime 0.082321   LR 0.010000   
2022-10-20 16:57:22,125 - INFO  - Training [16][  180/  196]   Loss 0.293984   Top1 89.704861   Top5 99.592014   BatchTime 0.081791   LR 0.010000   
2022-10-20 16:57:23,437 - INFO  - ==> Top1: 89.626    Top5: 99.584    Loss: 0.296

2022-10-20 16:57:23,509 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:57:24,648 - INFO  - Validation [16][   20/   40]   Loss 0.569864   Top1 82.890625   Top5 98.847656   BatchTime 0.056919   
2022-10-20 16:57:25,181 - INFO  - Validation [16][   40/   40]   Loss 0.565425   Top1 82.600000   Top5 99.040000   BatchTime 0.041780   
2022-10-20 16:57:25,273 - INFO  - ==> Top1: 82.600    Top5: 99.040    Loss: 0.565

2022-10-20 16:57:25,274 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:57:26,936 - INFO  - Validation [16][   20/   40]   Loss 0.581856   Top1 82.636719   Top5 98.925781   BatchTime 0.083088   
2022-10-20 16:57:27,733 - INFO  - Validation [16][   40/   40]   Loss 0.575683   Top1 82.570000   Top5 99.080000   BatchTime 0.061479   
2022-10-20 16:57:27,831 - INFO  - ==> Top1: 82.570    Top5: 99.080    Loss: 0.576

2022-10-20 16:57:27,831 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:57:27,831 - INFO  - Scoreboard best 2 ==> Epoch [15][Top1: 82.810   Top5: 98.900]
2022-10-20 16:57:27,831 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 82.680   Top5: 99.070]
2022-10-20 16:57:27,858 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:57:27,858 - INFO  - >>>>>> Epoch  17
2022-10-20 16:57:27,858 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:57:30,139 - INFO  - Training [17][   20/  196]   Loss 0.301628   Top1 89.160156   Top5 99.667969   BatchTime 0.113991   LR 0.010000   
2022-10-20 16:57:31,702 - INFO  - Training [17][   40/  196]   Loss 0.294950   Top1 89.580078   Top5 99.677734   BatchTime 0.096071   LR 0.010000   
2022-10-20 16:57:33,264 - INFO  - Training [17][   60/  196]   Loss 0.289121   Top1 89.843750   Top5 99.687500   BatchTime 0.090094   LR 0.010000   
2022-10-20 16:57:34,827 - INFO  - Training [17][   80/  196]   Loss 0.288019   Top1 89.877930   Top5 99.643555   BatchTime 0.087107   LR 0.010000   
2022-10-20 16:57:36,390 - INFO  - Training [17][  100/  196]   Loss 0.288421   Top1 89.898438   Top5 99.628906   BatchTime 0.085314   LR 0.010000   
2022-10-20 16:57:37,955 - INFO  - Training [17][  120/  196]   Loss 0.290139   Top1 89.772135   Top5 99.609375   BatchTime 0.084130   LR 0.010000   
2022-10-20 16:57:39,517 - INFO  - Training [17][  140/  196]   Loss 0.289931   Top1 89.760045   Top5 99.601004   BatchTime 0.083274   LR 0.010000   
2022-10-20 16:57:41,080 - INFO  - Training [17][  160/  196]   Loss 0.288797   Top1 89.824219   Top5 99.589844   BatchTime 0.082633   LR 0.010000   
2022-10-20 16:57:42,634 - INFO  - Training [17][  180/  196]   Loss 0.291755   Top1 89.709201   Top5 99.587674   BatchTime 0.082082   LR 0.010000   
2022-10-20 16:57:43,951 - INFO  - ==> Top1: 89.644    Top5: 99.580    Loss: 0.293

2022-10-20 16:57:44,017 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:57:45,160 - INFO  - Validation [17][   20/   40]   Loss 0.521796   Top1 83.632812   Top5 99.101562   BatchTime 0.057127   
2022-10-20 16:57:45,696 - INFO  - Validation [17][   40/   40]   Loss 0.511731   Top1 83.430000   Top5 99.170000   BatchTime 0.041951   
2022-10-20 16:57:45,779 - INFO  - ==> Top1: 83.430    Top5: 99.170    Loss: 0.512

2022-10-20 16:57:45,779 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:57:47,387 - INFO  - Validation [17][   20/   40]   Loss 0.528450   Top1 83.652344   Top5 99.121094   BatchTime 0.080345   
2022-10-20 16:57:48,186 - INFO  - Validation [17][   40/   40]   Loss 0.517948   Top1 83.820000   Top5 99.190000   BatchTime 0.060163   
2022-10-20 16:57:48,284 - INFO  - ==> Top1: 83.820    Top5: 99.190    Loss: 0.518

2022-10-20 16:57:48,284 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 16:57:48,285 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:57:48,285 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 82.810   Top5: 98.900]
2022-10-20 16:57:50,064 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 16:57:50,064 - INFO  - >>>>>> Epoch  18
2022-10-20 16:57:50,064 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:57:52,267 - INFO  - Training [18][   20/  196]   Loss 0.277138   Top1 90.273438   Top5 99.492188   BatchTime 0.110077   LR 0.010000   
2022-10-20 16:57:53,833 - INFO  - Training [18][   40/  196]   Loss 0.279714   Top1 89.951172   Top5 99.550781   BatchTime 0.094188   LR 0.010000   
2022-10-20 16:57:55,395 - INFO  - Training [18][   60/  196]   Loss 0.282835   Top1 90.058594   Top5 99.557292   BatchTime 0.088827   LR 0.010000   
2022-10-20 16:57:56,956 - INFO  - Training [18][   80/  196]   Loss 0.282726   Top1 90.068359   Top5 99.575195   BatchTime 0.086139   LR 0.010000   
2022-10-20 16:57:58,518 - INFO  - Training [18][  100/  196]   Loss 0.285490   Top1 89.898438   Top5 99.593750   BatchTime 0.084531   LR 0.010000   
2022-10-20 16:58:00,080 - INFO  - Training [18][  120/  196]   Loss 0.286827   Top1 89.977214   Top5 99.550781   BatchTime 0.083460   LR 0.010000   
2022-10-20 16:58:01,642 - INFO  - Training [18][  140/  196]   Loss 0.286545   Top1 90.000000   Top5 99.564732   BatchTime 0.082693   LR 0.010000   
2022-10-20 16:58:03,204 - INFO  - Training [18][  160/  196]   Loss 0.289366   Top1 89.885254   Top5 99.562988   BatchTime 0.082118   LR 0.010000   
2022-10-20 16:58:04,758 - INFO  - Training [18][  180/  196]   Loss 0.291023   Top1 89.789497   Top5 99.559462   BatchTime 0.081626   LR 0.010000   
2022-10-20 16:58:06,068 - INFO  - ==> Top1: 89.818    Top5: 99.566    Loss: 0.290

2022-10-20 16:58:06,134 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:58:07,272 - INFO  - Validation [18][   20/   40]   Loss 0.580459   Top1 82.363281   Top5 98.828125   BatchTime 0.056870   
2022-10-20 16:58:07,810 - INFO  - Validation [18][   40/   40]   Loss 0.572081   Top1 82.180000   Top5 99.060000   BatchTime 0.041876   
2022-10-20 16:58:07,900 - INFO  - ==> Top1: 82.180    Top5: 99.060    Loss: 0.572

2022-10-20 16:58:07,900 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:58:09,523 - INFO  - Validation [18][   20/   40]   Loss 0.592069   Top1 82.792969   Top5 98.906250   BatchTime 0.081125   
2022-10-20 16:58:10,322 - INFO  - Validation [18][   40/   40]   Loss 0.582728   Top1 82.590000   Top5 99.060000   BatchTime 0.060532   
2022-10-20 16:58:10,423 - INFO  - ==> Top1: 82.590    Top5: 99.060    Loss: 0.583

2022-10-20 16:58:10,423 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 16:58:10,423 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:58:10,423 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 82.810   Top5: 98.900]
2022-10-20 16:58:10,449 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:58:10,450 - INFO  - >>>>>> Epoch  19
2022-10-20 16:58:10,450 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:58:12,684 - INFO  - Training [19][   20/  196]   Loss 0.265731   Top1 90.820312   Top5 99.667969   BatchTime 0.111692   LR 0.010000   
2022-10-20 16:58:14,245 - INFO  - Training [19][   40/  196]   Loss 0.269927   Top1 90.576172   Top5 99.609375   BatchTime 0.094868   LR 0.010000   
2022-10-20 16:58:15,806 - INFO  - Training [19][   60/  196]   Loss 0.278877   Top1 90.214844   Top5 99.589844   BatchTime 0.089264   LR 0.010000   
2022-10-20 16:58:17,371 - INFO  - Training [19][   80/  196]   Loss 0.282369   Top1 90.029297   Top5 99.575195   BatchTime 0.086502   LR 0.010000   
2022-10-20 16:58:18,930 - INFO  - Training [19][  100/  196]   Loss 0.279722   Top1 90.152344   Top5 99.589844   BatchTime 0.084792   LR 0.010000   
2022-10-20 16:58:20,489 - INFO  - Training [19][  120/  196]   Loss 0.281654   Top1 90.039062   Top5 99.580078   BatchTime 0.083652   LR 0.010000   
2022-10-20 16:58:22,049 - INFO  - Training [19][  140/  196]   Loss 0.284106   Top1 89.949777   Top5 99.581473   BatchTime 0.082840   LR 0.010000   
2022-10-20 16:58:23,608 - INFO  - Training [19][  160/  196]   Loss 0.283662   Top1 89.958496   Top5 99.592285   BatchTime 0.082230   LR 0.010000   
2022-10-20 16:58:25,158 - INFO  - Training [19][  180/  196]   Loss 0.283671   Top1 89.997830   Top5 99.568142   BatchTime 0.081705   LR 0.010000   
2022-10-20 16:58:26,469 - INFO  - ==> Top1: 89.980    Top5: 99.570    Loss: 0.284

2022-10-20 16:58:26,541 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:58:27,692 - INFO  - Validation [19][   20/   40]   Loss 0.568980   Top1 82.656250   Top5 98.847656   BatchTime 0.057528   
2022-10-20 16:58:28,229 - INFO  - Validation [19][   40/   40]   Loss 0.563261   Top1 82.390000   Top5 99.010000   BatchTime 0.042209   
2022-10-20 16:58:28,315 - INFO  - ==> Top1: 82.390    Top5: 99.010    Loss: 0.563

2022-10-20 16:58:28,315 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:58:29,973 - INFO  - Validation [19][   20/   40]   Loss 0.573920   Top1 83.007812   Top5 98.789062   BatchTime 0.082874   
2022-10-20 16:58:30,774 - INFO  - Validation [19][   40/   40]   Loss 0.569221   Top1 82.830000   Top5 98.970000   BatchTime 0.061441   
2022-10-20 16:58:30,870 - INFO  - ==> Top1: 82.830    Top5: 98.970    Loss: 0.569

2022-10-20 16:58:30,870 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 16:58:30,870 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:58:30,870 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 82.830   Top5: 98.970]
2022-10-20 16:58:30,932 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:58:30,932 - INFO  - >>>>>> Epoch  20
2022-10-20 16:58:30,932 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:58:33,145 - INFO  - Training [20][   20/  196]   Loss 0.271758   Top1 90.449219   Top5 99.550781   BatchTime 0.110608   LR 0.010000   
2022-10-20 16:58:34,706 - INFO  - Training [20][   40/  196]   Loss 0.270574   Top1 90.468750   Top5 99.570312   BatchTime 0.094318   LR 0.010000   
2022-10-20 16:58:36,266 - INFO  - Training [20][   60/  196]   Loss 0.273106   Top1 90.442708   Top5 99.589844   BatchTime 0.088874   LR 0.010000   
2022-10-20 16:58:37,831 - INFO  - Training [20][   80/  196]   Loss 0.275206   Top1 90.385742   Top5 99.604492   BatchTime 0.086222   LR 0.010000   
2022-10-20 16:58:39,387 - INFO  - Training [20][  100/  196]   Loss 0.273138   Top1 90.464844   Top5 99.640625   BatchTime 0.084531   LR 0.010000   
2022-10-20 16:58:40,946 - INFO  - Training [20][  120/  196]   Loss 0.274239   Top1 90.374349   Top5 99.625651   BatchTime 0.083437   LR 0.010000   
2022-10-20 16:58:42,506 - INFO  - Training [20][  140/  196]   Loss 0.278041   Top1 90.226004   Top5 99.626116   BatchTime 0.082662   LR 0.010000   
2022-10-20 16:58:44,070 - INFO  - Training [20][  160/  196]   Loss 0.278900   Top1 90.183105   Top5 99.626465   BatchTime 0.082100   LR 0.010000   
2022-10-20 16:58:45,616 - INFO  - Training [20][  180/  196]   Loss 0.278616   Top1 90.149740   Top5 99.639757   BatchTime 0.081570   LR 0.010000   
2022-10-20 16:58:46,928 - INFO  - ==> Top1: 90.168    Top5: 99.648    Loss: 0.278

2022-10-20 16:58:46,994 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:58:48,138 - INFO  - Validation [20][   20/   40]   Loss 0.594682   Top1 82.753906   Top5 98.652344   BatchTime 0.057167   
2022-10-20 16:58:48,675 - INFO  - Validation [20][   40/   40]   Loss 0.578824   Top1 82.760000   Top5 98.930000   BatchTime 0.042012   
2022-10-20 16:58:48,761 - INFO  - ==> Top1: 82.760    Top5: 98.930    Loss: 0.579

2022-10-20 16:58:48,761 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:58:50,393 - INFO  - Validation [20][   20/   40]   Loss 0.607911   Top1 82.441406   Top5 98.652344   BatchTime 0.081560   
2022-10-20 16:58:51,199 - INFO  - Validation [20][   40/   40]   Loss 0.590914   Top1 82.600000   Top5 98.840000   BatchTime 0.060936   
2022-10-20 16:58:51,295 - INFO  - ==> Top1: 82.600    Top5: 98.840    Loss: 0.591

2022-10-20 16:58:51,296 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 16:58:51,296 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:58:51,296 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 82.830   Top5: 98.970]
2022-10-20 16:58:51,359 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:58:51,360 - INFO  - >>>>>> Epoch  21
2022-10-20 16:58:51,360 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:58:53,626 - INFO  - Training [21][   20/  196]   Loss 0.261032   Top1 90.605469   Top5 99.628906   BatchTime 0.113152   LR 0.010000   
2022-10-20 16:58:55,183 - INFO  - Training [21][   40/  196]   Loss 0.267561   Top1 90.419922   Top5 99.648438   BatchTime 0.095505   LR 0.010000   
2022-10-20 16:58:56,746 - INFO  - Training [21][   60/  196]   Loss 0.265021   Top1 90.625000   Top5 99.609375   BatchTime 0.089713   LR 0.010000   
2022-10-20 16:58:58,310 - INFO  - Training [21][   80/  196]   Loss 0.264852   Top1 90.551758   Top5 99.599609   BatchTime 0.086844   LR 0.010000   
2022-10-20 16:58:59,873 - INFO  - Training [21][  100/  196]   Loss 0.267869   Top1 90.488281   Top5 99.589844   BatchTime 0.085095   LR 0.010000   
2022-10-20 16:59:01,434 - INFO  - Training [21][  120/  196]   Loss 0.271663   Top1 90.397135   Top5 99.612630   BatchTime 0.083928   LR 0.010000   
2022-10-20 16:59:02,997 - INFO  - Training [21][  140/  196]   Loss 0.275268   Top1 90.298549   Top5 99.598214   BatchTime 0.083099   LR 0.010000   
2022-10-20 16:59:04,559 - INFO  - Training [21][  160/  196]   Loss 0.276289   Top1 90.246582   Top5 99.611816   BatchTime 0.082476   LR 0.010000   
2022-10-20 16:59:06,113 - INFO  - Training [21][  180/  196]   Loss 0.277217   Top1 90.223524   Top5 99.618056   BatchTime 0.081941   LR 0.010000   
2022-10-20 16:59:07,425 - INFO  - ==> Top1: 90.226    Top5: 99.628    Loss: 0.277

2022-10-20 16:59:07,490 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:59:08,638 - INFO  - Validation [21][   20/   40]   Loss 0.528043   Top1 83.867188   Top5 99.062500   BatchTime 0.057365   
2022-10-20 16:59:09,176 - INFO  - Validation [21][   40/   40]   Loss 0.526510   Top1 83.830000   Top5 99.040000   BatchTime 0.042131   
2022-10-20 16:59:09,263 - INFO  - ==> Top1: 83.830    Top5: 99.040    Loss: 0.527

2022-10-20 16:59:09,263 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:59:10,881 - INFO  - Validation [21][   20/   40]   Loss 0.535746   Top1 83.691406   Top5 98.945312   BatchTime 0.080901   
2022-10-20 16:59:11,680 - INFO  - Validation [21][   40/   40]   Loss 0.534177   Top1 83.610000   Top5 98.970000   BatchTime 0.060425   
2022-10-20 16:59:11,781 - INFO  - ==> Top1: 83.610    Top5: 98.970    Loss: 0.534

2022-10-20 16:59:11,781 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 16:59:11,781 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 83.610   Top5: 98.970]
2022-10-20 16:59:11,781 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:59:11,835 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:59:11,836 - INFO  - >>>>>> Epoch  22
2022-10-20 16:59:11,836 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:59:14,065 - INFO  - Training [22][   20/  196]   Loss 0.251063   Top1 91.015625   Top5 99.746094   BatchTime 0.111441   LR 0.010000   
2022-10-20 16:59:15,630 - INFO  - Training [22][   40/  196]   Loss 0.261700   Top1 90.703125   Top5 99.726562   BatchTime 0.094831   LR 0.010000   
2022-10-20 16:59:17,200 - INFO  - Training [22][   60/  196]   Loss 0.259749   Top1 90.839844   Top5 99.707031   BatchTime 0.089386   LR 0.010000   
2022-10-20 16:59:18,760 - INFO  - Training [22][   80/  196]   Loss 0.263708   Top1 90.717773   Top5 99.707031   BatchTime 0.086538   LR 0.010000   
2022-10-20 16:59:20,320 - INFO  - Training [22][  100/  196]   Loss 0.265301   Top1 90.632812   Top5 99.679688   BatchTime 0.084836   LR 0.010000   
2022-10-20 16:59:21,879 - INFO  - Training [22][  120/  196]   Loss 0.267012   Top1 90.582682   Top5 99.645182   BatchTime 0.083690   LR 0.010000   
2022-10-20 16:59:23,442 - INFO  - Training [22][  140/  196]   Loss 0.269039   Top1 90.538504   Top5 99.637277   BatchTime 0.082897   LR 0.010000   
2022-10-20 16:59:25,000 - INFO  - Training [22][  160/  196]   Loss 0.270419   Top1 90.437012   Top5 99.655762   BatchTime 0.082273   LR 0.010000   
2022-10-20 16:59:26,554 - INFO  - Training [22][  180/  196]   Loss 0.270084   Top1 90.462240   Top5 99.650608   BatchTime 0.081763   LR 0.010000   
2022-10-20 16:59:27,859 - INFO  - ==> Top1: 90.328    Top5: 99.644    Loss: 0.273

2022-10-20 16:59:27,930 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:59:29,068 - INFO  - Validation [22][   20/   40]   Loss 0.671395   Top1 80.722656   Top5 98.320312   BatchTime 0.056891   
2022-10-20 16:59:29,602 - INFO  - Validation [22][   40/   40]   Loss 0.654893   Top1 80.920000   Top5 98.440000   BatchTime 0.041779   
2022-10-20 16:59:29,687 - INFO  - ==> Top1: 80.920    Top5: 98.440    Loss: 0.655

2022-10-20 16:59:29,687 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:59:31,309 - INFO  - Validation [22][   20/   40]   Loss 0.695743   Top1 80.644531   Top5 98.183594   BatchTime 0.081075   
2022-10-20 16:59:32,109 - INFO  - Validation [22][   40/   40]   Loss 0.679367   Top1 80.530000   Top5 98.380000   BatchTime 0.060550   
2022-10-20 16:59:32,213 - INFO  - ==> Top1: 80.530    Top5: 98.380    Loss: 0.679

2022-10-20 16:59:32,213 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 16:59:32,214 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 83.610   Top5: 98.970]
2022-10-20 16:59:32,214 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:59:32,239 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:59:32,239 - INFO  - >>>>>> Epoch  23
2022-10-20 16:59:32,239 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:59:34,461 - INFO  - Training [23][   20/  196]   Loss 0.270793   Top1 90.527344   Top5 99.648438   BatchTime 0.111046   LR 0.010000   
2022-10-20 16:59:36,029 - INFO  - Training [23][   40/  196]   Loss 0.264489   Top1 90.693359   Top5 99.697266   BatchTime 0.094716   LR 0.010000   
2022-10-20 16:59:37,589 - INFO  - Training [23][   60/  196]   Loss 0.262400   Top1 90.729167   Top5 99.694010   BatchTime 0.089142   LR 0.010000   
2022-10-20 16:59:39,149 - INFO  - Training [23][   80/  196]   Loss 0.260270   Top1 90.830078   Top5 99.702148   BatchTime 0.086354   LR 0.010000   
2022-10-20 16:59:40,708 - INFO  - Training [23][  100/  196]   Loss 0.264951   Top1 90.574219   Top5 99.675781   BatchTime 0.084677   LR 0.010000   
2022-10-20 16:59:42,267 - INFO  - Training [23][  120/  196]   Loss 0.264598   Top1 90.585938   Top5 99.677734   BatchTime 0.083559   LR 0.010000   
2022-10-20 16:59:43,827 - INFO  - Training [23][  140/  196]   Loss 0.268531   Top1 90.493862   Top5 99.654018   BatchTime 0.082762   LR 0.010000   
2022-10-20 16:59:45,386 - INFO  - Training [23][  160/  196]   Loss 0.267790   Top1 90.527344   Top5 99.667969   BatchTime 0.082160   LR 0.010000   
2022-10-20 16:59:46,937 - INFO  - Training [23][  180/  196]   Loss 0.270080   Top1 90.453559   Top5 99.670139   BatchTime 0.081646   LR 0.010000   
2022-10-20 16:59:48,251 - INFO  - ==> Top1: 90.422    Top5: 99.672    Loss: 0.271

2022-10-20 16:59:48,317 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:59:49,472 - INFO  - Validation [23][   20/   40]   Loss 0.593992   Top1 82.148438   Top5 98.789062   BatchTime 0.057724   
2022-10-20 16:59:50,010 - INFO  - Validation [23][   40/   40]   Loss 0.571156   Top1 82.720000   Top5 98.840000   BatchTime 0.042310   
2022-10-20 16:59:50,102 - INFO  - ==> Top1: 82.720    Top5: 98.840    Loss: 0.571

2022-10-20 16:59:50,102 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 16:59:51,719 - INFO  - Validation [23][   20/   40]   Loss 0.606164   Top1 82.500000   Top5 98.808594   BatchTime 0.080819   
2022-10-20 16:59:52,518 - INFO  - Validation [23][   40/   40]   Loss 0.582724   Top1 82.870000   Top5 98.880000   BatchTime 0.060403   
2022-10-20 16:59:52,612 - INFO  - ==> Top1: 82.870    Top5: 98.880    Loss: 0.583

2022-10-20 16:59:52,612 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 16:59:52,612 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 83.610   Top5: 98.970]
2022-10-20 16:59:52,612 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 16:59:52,673 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 16:59:52,673 - INFO  - >>>>>> Epoch  24
2022-10-20 16:59:52,673 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 16:59:54,918 - INFO  - Training [24][   20/  196]   Loss 0.240783   Top1 91.406250   Top5 99.707031   BatchTime 0.112191   LR 0.010000   
2022-10-20 16:59:56,478 - INFO  - Training [24][   40/  196]   Loss 0.245308   Top1 91.308594   Top5 99.677734   BatchTime 0.095101   LR 0.010000   
2022-10-20 16:59:58,038 - INFO  - Training [24][   60/  196]   Loss 0.252573   Top1 91.087240   Top5 99.654948   BatchTime 0.089399   LR 0.010000   
2022-10-20 16:59:59,598 - INFO  - Training [24][   80/  196]   Loss 0.254899   Top1 90.942383   Top5 99.682617   BatchTime 0.086551   LR 0.010000   
2022-10-20 17:00:01,159 - INFO  - Training [24][  100/  196]   Loss 0.255893   Top1 90.914062   Top5 99.687500   BatchTime 0.084853   LR 0.010000   
2022-10-20 17:00:02,725 - INFO  - Training [24][  120/  196]   Loss 0.258536   Top1 90.797526   Top5 99.700521   BatchTime 0.083755   LR 0.010000   
2022-10-20 17:00:04,285 - INFO  - Training [24][  140/  196]   Loss 0.259839   Top1 90.761719   Top5 99.695871   BatchTime 0.082933   LR 0.010000   
2022-10-20 17:00:05,845 - INFO  - Training [24][  160/  196]   Loss 0.260978   Top1 90.742188   Top5 99.685059   BatchTime 0.082314   LR 0.010000   
2022-10-20 17:00:07,395 - INFO  - Training [24][  180/  196]   Loss 0.262791   Top1 90.687934   Top5 99.678819   BatchTime 0.081781   LR 0.010000   
2022-10-20 17:00:08,698 - INFO  - ==> Top1: 90.686    Top5: 99.680    Loss: 0.263

2022-10-20 17:00:08,763 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:00:09,928 - INFO  - Validation [24][   20/   40]   Loss 0.569592   Top1 82.871094   Top5 98.789062   BatchTime 0.058207   
2022-10-20 17:00:10,462 - INFO  - Validation [24][   40/   40]   Loss 0.552677   Top1 83.170000   Top5 99.030000   BatchTime 0.042439   
2022-10-20 17:00:10,553 - INFO  - ==> Top1: 83.170    Top5: 99.030    Loss: 0.553

2022-10-20 17:00:10,553 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:00:12,183 - INFO  - Validation [24][   20/   40]   Loss 0.575470   Top1 82.792969   Top5 98.691406   BatchTime 0.081427   
2022-10-20 17:00:12,986 - INFO  - Validation [24][   40/   40]   Loss 0.559054   Top1 83.090000   Top5 98.960000   BatchTime 0.060791   
2022-10-20 17:00:13,081 - INFO  - ==> Top1: 83.090    Top5: 98.960    Loss: 0.559

2022-10-20 17:00:13,082 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 17:00:13,082 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 83.610   Top5: 98.970]
2022-10-20 17:00:13,082 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 83.280   Top5: 99.030]
2022-10-20 17:00:13,133 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:00:13,134 - INFO  - >>>>>> Epoch  25
2022-10-20 17:00:13,134 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:00:15,361 - INFO  - Training [25][   20/  196]   Loss 0.249823   Top1 91.367188   Top5 99.628906   BatchTime 0.111314   LR 0.010000   
2022-10-20 17:00:16,941 - INFO  - Training [25][   40/  196]   Loss 0.252473   Top1 91.191406   Top5 99.619141   BatchTime 0.095171   LR 0.010000   
2022-10-20 17:00:18,500 - INFO  - Training [25][   60/  196]   Loss 0.250873   Top1 91.276042   Top5 99.654948   BatchTime 0.089429   LR 0.010000   
2022-10-20 17:00:20,063 - INFO  - Training [25][   80/  196]   Loss 0.249579   Top1 91.420898   Top5 99.677734   BatchTime 0.086606   LR 0.010000   
2022-10-20 17:00:21,626 - INFO  - Training [25][  100/  196]   Loss 0.252733   Top1 91.320312   Top5 99.675781   BatchTime 0.084909   LR 0.010000   
2022-10-20 17:00:23,188 - INFO  - Training [25][  120/  196]   Loss 0.253572   Top1 91.276042   Top5 99.664714   BatchTime 0.083778   LR 0.010000   
2022-10-20 17:00:24,751 - INFO  - Training [25][  140/  196]   Loss 0.256214   Top1 91.121652   Top5 99.670759   BatchTime 0.082971   LR 0.010000   
2022-10-20 17:00:26,313 - INFO  - Training [25][  160/  196]   Loss 0.256509   Top1 91.115723   Top5 99.665527   BatchTime 0.082366   LR 0.010000   
2022-10-20 17:00:27,868 - INFO  - Training [25][  180/  196]   Loss 0.257305   Top1 91.067708   Top5 99.663628   BatchTime 0.081852   LR 0.010000   
2022-10-20 17:00:29,196 - INFO  - ==> Top1: 90.992    Top5: 99.668    Loss: 0.260

2022-10-20 17:00:29,262 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:00:30,426 - INFO  - Validation [25][   20/   40]   Loss 0.530349   Top1 83.300781   Top5 99.140625   BatchTime 0.058155   
2022-10-20 17:00:30,965 - INFO  - Validation [25][   40/   40]   Loss 0.524904   Top1 83.610000   Top5 99.180000   BatchTime 0.042565   
2022-10-20 17:00:31,055 - INFO  - ==> Top1: 83.610    Top5: 99.180    Loss: 0.525

2022-10-20 17:00:31,055 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:00:32,699 - INFO  - Validation [25][   20/   40]   Loss 0.537795   Top1 83.359375   Top5 99.121094   BatchTime 0.082193   
2022-10-20 17:00:33,507 - INFO  - Validation [25][   40/   40]   Loss 0.531428   Top1 83.490000   Top5 99.150000   BatchTime 0.061299   
2022-10-20 17:00:33,610 - INFO  - ==> Top1: 83.490    Top5: 99.150    Loss: 0.531

2022-10-20 17:00:33,610 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 17:00:33,610 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 83.610   Top5: 98.970]
2022-10-20 17:00:33,610 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 83.490   Top5: 99.150]
2022-10-20 17:00:33,670 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:00:33,671 - INFO  - >>>>>> Epoch  26
2022-10-20 17:00:33,671 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:00:35,880 - INFO  - Training [26][   20/  196]   Loss 0.261046   Top1 90.820312   Top5 99.589844   BatchTime 0.110409   LR 0.010000   
2022-10-20 17:00:37,444 - INFO  - Training [26][   40/  196]   Loss 0.251261   Top1 91.064453   Top5 99.658203   BatchTime 0.094309   LR 0.010000   
2022-10-20 17:00:39,009 - INFO  - Training [26][   60/  196]   Loss 0.255255   Top1 90.983073   Top5 99.648438   BatchTime 0.088957   LR 0.010000   
2022-10-20 17:00:40,573 - INFO  - Training [26][   80/  196]   Loss 0.257852   Top1 90.981445   Top5 99.648438   BatchTime 0.086268   LR 0.010000   
2022-10-20 17:00:42,137 - INFO  - Training [26][  100/  196]   Loss 0.255678   Top1 91.019531   Top5 99.652344   BatchTime 0.084655   LR 0.010000   
2022-10-20 17:00:43,701 - INFO  - Training [26][  120/  196]   Loss 0.255332   Top1 90.989583   Top5 99.671224   BatchTime 0.083581   LR 0.010000   
2022-10-20 17:00:45,266 - INFO  - Training [26][  140/  196]   Loss 0.255105   Top1 91.001674   Top5 99.673549   BatchTime 0.082813   LR 0.010000   
2022-10-20 17:00:46,830 - INFO  - Training [26][  160/  196]   Loss 0.258730   Top1 90.888672   Top5 99.650879   BatchTime 0.082238   LR 0.010000   
2022-10-20 17:00:48,384 - INFO  - Training [26][  180/  196]   Loss 0.258771   Top1 90.907118   Top5 99.650608   BatchTime 0.081736   LR 0.010000   
2022-10-20 17:00:49,702 - INFO  - ==> Top1: 90.828    Top5: 99.636    Loss: 0.261

2022-10-20 17:00:49,808 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:00:50,980 - INFO  - Validation [26][   20/   40]   Loss 0.572861   Top1 83.437500   Top5 99.062500   BatchTime 0.058560   
2022-10-20 17:00:51,517 - INFO  - Validation [26][   40/   40]   Loss 0.576331   Top1 83.530000   Top5 99.110000   BatchTime 0.042722   
2022-10-20 17:00:51,606 - INFO  - ==> Top1: 83.530    Top5: 99.110    Loss: 0.576

2022-10-20 17:00:51,606 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:00:53,290 - INFO  - Validation [26][   20/   40]   Loss 0.574479   Top1 83.437500   Top5 99.082031   BatchTime 0.084132   
2022-10-20 17:00:54,095 - INFO  - Validation [26][   40/   40]   Loss 0.579062   Top1 83.460000   Top5 99.090000   BatchTime 0.062194   
2022-10-20 17:00:54,191 - INFO  - ==> Top1: 83.460    Top5: 99.090    Loss: 0.579

2022-10-20 17:00:54,191 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 17:00:54,191 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 83.610   Top5: 98.970]
2022-10-20 17:00:54,191 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 83.490   Top5: 99.150]
2022-10-20 17:00:54,218 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:00:54,218 - INFO  - >>>>>> Epoch  27
2022-10-20 17:00:54,218 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:00:56,423 - INFO  - Training [27][   20/  196]   Loss 0.244876   Top1 91.054688   Top5 99.726562   BatchTime 0.110220   LR 0.010000   
2022-10-20 17:00:57,991 - INFO  - Training [27][   40/  196]   Loss 0.242140   Top1 91.220703   Top5 99.755859   BatchTime 0.094306   LR 0.010000   
2022-10-20 17:00:59,551 - INFO  - Training [27][   60/  196]   Loss 0.247068   Top1 91.119792   Top5 99.726562   BatchTime 0.088875   LR 0.010000   
2022-10-20 17:01:01,114 - INFO  - Training [27][   80/  196]   Loss 0.248121   Top1 91.181641   Top5 99.711914   BatchTime 0.086194   LR 0.010000   
2022-10-20 17:01:02,677 - INFO  - Training [27][  100/  196]   Loss 0.248965   Top1 91.164062   Top5 99.699219   BatchTime 0.084582   LR 0.010000   
2022-10-20 17:01:04,242 - INFO  - Training [27][  120/  196]   Loss 0.251257   Top1 91.129557   Top5 99.703776   BatchTime 0.083522   LR 0.010000   
2022-10-20 17:01:05,802 - INFO  - Training [27][  140/  196]   Loss 0.249655   Top1 91.163504   Top5 99.676339   BatchTime 0.082738   LR 0.010000   
2022-10-20 17:01:07,365 - INFO  - Training [27][  160/  196]   Loss 0.249457   Top1 91.184082   Top5 99.682617   BatchTime 0.082163   LR 0.010000   
2022-10-20 17:01:08,919 - INFO  - Training [27][  180/  196]   Loss 0.251180   Top1 91.087240   Top5 99.680990   BatchTime 0.081664   LR 0.010000   
2022-10-20 17:01:10,227 - INFO  - ==> Top1: 91.056    Top5: 99.686    Loss: 0.253

2022-10-20 17:01:10,293 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:01:11,455 - INFO  - Validation [27][   20/   40]   Loss 0.554099   Top1 83.554688   Top5 98.867188   BatchTime 0.058021   
2022-10-20 17:01:11,992 - INFO  - Validation [27][   40/   40]   Loss 0.540989   Top1 83.830000   Top5 99.040000   BatchTime 0.042459   
2022-10-20 17:01:12,078 - INFO  - ==> Top1: 83.830    Top5: 99.040    Loss: 0.541

2022-10-20 17:01:12,078 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:01:13,719 - INFO  - Validation [27][   20/   40]   Loss 0.564822   Top1 83.417969   Top5 98.847656   BatchTime 0.082044   
2022-10-20 17:01:14,526 - INFO  - Validation [27][   40/   40]   Loss 0.551991   Top1 83.690000   Top5 98.980000   BatchTime 0.061200   
2022-10-20 17:01:14,634 - INFO  - ==> Top1: 83.690    Top5: 98.980    Loss: 0.552

2022-10-20 17:01:14,634 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 17:01:14,634 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 83.690   Top5: 98.980]
2022-10-20 17:01:14,634 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 83.610   Top5: 98.970]
2022-10-20 17:01:14,698 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:01:14,698 - INFO  - >>>>>> Epoch  28
2022-10-20 17:01:14,698 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:01:16,971 - INFO  - Training [28][   20/  196]   Loss 0.247682   Top1 91.289062   Top5 99.628906   BatchTime 0.113582   LR 0.010000   
2022-10-20 17:01:18,535 - INFO  - Training [28][   40/  196]   Loss 0.243695   Top1 91.435547   Top5 99.619141   BatchTime 0.095905   LR 0.010000   
2022-10-20 17:01:20,099 - INFO  - Training [28][   60/  196]   Loss 0.241578   Top1 91.471354   Top5 99.615885   BatchTime 0.089993   LR 0.010000   
2022-10-20 17:01:21,662 - INFO  - Training [28][   80/  196]   Loss 0.238967   Top1 91.523438   Top5 99.653320   BatchTime 0.087040   LR 0.010000   
2022-10-20 17:01:23,227 - INFO  - Training [28][  100/  196]   Loss 0.240409   Top1 91.425781   Top5 99.652344   BatchTime 0.085274   LR 0.010000   
2022-10-20 17:01:24,789 - INFO  - Training [28][  120/  196]   Loss 0.244433   Top1 91.282552   Top5 99.661458   BatchTime 0.084083   LR 0.010000   
2022-10-20 17:01:26,352 - INFO  - Training [28][  140/  196]   Loss 0.244177   Top1 91.272321   Top5 99.665179   BatchTime 0.083234   LR 0.010000   
2022-10-20 17:01:27,916 - INFO  - Training [28][  160/  196]   Loss 0.245459   Top1 91.232910   Top5 99.665527   BatchTime 0.082603   LR 0.010000   
2022-10-20 17:01:29,470 - INFO  - Training [28][  180/  196]   Loss 0.245273   Top1 91.265191   Top5 99.663628   BatchTime 0.082059   LR 0.010000   
2022-10-20 17:01:30,775 - INFO  - ==> Top1: 91.194    Top5: 99.666    Loss: 0.247

2022-10-20 17:01:30,855 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:01:32,041 - INFO  - Validation [28][   20/   40]   Loss 0.599209   Top1 83.125000   Top5 98.730469   BatchTime 0.059290   
2022-10-20 17:01:32,579 - INFO  - Validation [28][   40/   40]   Loss 0.580704   Top1 82.950000   Top5 98.920000   BatchTime 0.043100   
2022-10-20 17:01:32,669 - INFO  - ==> Top1: 82.950    Top5: 98.920    Loss: 0.581

2022-10-20 17:01:32,669 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:01:34,308 - INFO  - Validation [28][   20/   40]   Loss 0.611829   Top1 82.890625   Top5 98.652344   BatchTime 0.081947   
2022-10-20 17:01:35,110 - INFO  - Validation [28][   40/   40]   Loss 0.594834   Top1 83.030000   Top5 98.860000   BatchTime 0.061024   
2022-10-20 17:01:35,203 - INFO  - ==> Top1: 83.030    Top5: 98.860    Loss: 0.595

2022-10-20 17:01:35,203 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 17:01:35,203 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 83.690   Top5: 98.980]
2022-10-20 17:01:35,203 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 83.610   Top5: 98.970]
2022-10-20 17:01:35,258 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:01:35,258 - INFO  - >>>>>> Epoch  29
2022-10-20 17:01:35,258 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:01:37,476 - INFO  - Training [29][   20/  196]   Loss 0.243533   Top1 91.035156   Top5 99.687500   BatchTime 0.110849   LR 0.010000   
2022-10-20 17:01:39,038 - INFO  - Training [29][   40/  196]   Loss 0.245154   Top1 91.201172   Top5 99.687500   BatchTime 0.094469   LR 0.010000   
2022-10-20 17:01:40,599 - INFO  - Training [29][   60/  196]   Loss 0.247385   Top1 90.983073   Top5 99.707031   BatchTime 0.088989   LR 0.010000   
2022-10-20 17:01:42,159 - INFO  - Training [29][   80/  196]   Loss 0.252038   Top1 90.991211   Top5 99.697266   BatchTime 0.086250   LR 0.010000   
2022-10-20 17:01:43,720 - INFO  - Training [29][  100/  196]   Loss 0.251624   Top1 91.015625   Top5 99.707031   BatchTime 0.084610   LR 0.010000   
2022-10-20 17:01:45,281 - INFO  - Training [29][  120/  196]   Loss 0.251411   Top1 91.048177   Top5 99.710286   BatchTime 0.083516   LR 0.010000   
2022-10-20 17:01:46,843 - INFO  - Training [29][  140/  196]   Loss 0.252687   Top1 90.968192   Top5 99.715402   BatchTime 0.082736   LR 0.010000   
2022-10-20 17:01:48,403 - INFO  - Training [29][  160/  196]   Loss 0.253672   Top1 90.942383   Top5 99.709473   BatchTime 0.082148   LR 0.010000   
2022-10-20 17:01:49,955 - INFO  - Training [29][  180/  196]   Loss 0.252669   Top1 90.965712   Top5 99.702691   BatchTime 0.081639   LR 0.010000   
2022-10-20 17:01:51,255 - INFO  - ==> Top1: 90.992    Top5: 99.706    Loss: 0.252

2022-10-20 17:01:51,321 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:01:52,469 - INFO  - Validation [29][   20/   40]   Loss 0.554258   Top1 83.691406   Top5 99.140625   BatchTime 0.057402   
2022-10-20 17:01:53,005 - INFO  - Validation [29][   40/   40]   Loss 0.536478   Top1 83.950000   Top5 99.230000   BatchTime 0.042095   
2022-10-20 17:01:53,090 - INFO  - ==> Top1: 83.950    Top5: 99.230    Loss: 0.536

2022-10-20 17:01:53,090 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:01:54,707 - INFO  - Validation [29][   20/   40]   Loss 0.565440   Top1 83.867188   Top5 99.082031   BatchTime 0.080853   
2022-10-20 17:01:55,508 - INFO  - Validation [29][   40/   40]   Loss 0.546767   Top1 84.080000   Top5 99.110000   BatchTime 0.060439   
2022-10-20 17:01:55,608 - INFO  - ==> Top1: 84.080    Top5: 99.110    Loss: 0.547

2022-10-20 17:01:55,608 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 84.080   Top5: 99.110]
2022-10-20 17:01:55,608 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 17:01:55,608 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 83.690   Top5: 98.980]
2022-10-20 17:01:57,326 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 17:01:57,327 - INFO  - >>>>>> Epoch  30
2022-10-20 17:01:57,327 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:01:59,521 - INFO  - Training [30][   20/  196]   Loss 0.221959   Top1 92.187500   Top5 99.824219   BatchTime 0.109656   LR 0.001000   
2022-10-20 17:02:01,089 - INFO  - Training [30][   40/  196]   Loss 0.214908   Top1 92.333984   Top5 99.794922   BatchTime 0.094025   LR 0.001000   
2022-10-20 17:02:02,647 - INFO  - Training [30][   60/  196]   Loss 0.208861   Top1 92.617188   Top5 99.791667   BatchTime 0.088662   LR 0.001000   
2022-10-20 17:02:04,210 - INFO  - Training [30][   80/  196]   Loss 0.203714   Top1 92.866211   Top5 99.785156   BatchTime 0.086034   LR 0.001000   
2022-10-20 17:02:05,774 - INFO  - Training [30][  100/  196]   Loss 0.201262   Top1 93.003906   Top5 99.796875   BatchTime 0.084463   LR 0.001000   
2022-10-20 17:02:07,342 - INFO  - Training [30][  120/  196]   Loss 0.196015   Top1 93.193359   Top5 99.794922   BatchTime 0.083452   LR 0.001000   
2022-10-20 17:02:08,901 - INFO  - Training [30][  140/  196]   Loss 0.195902   Top1 93.205915   Top5 99.787946   BatchTime 0.082662   LR 0.001000   
2022-10-20 17:02:10,462 - INFO  - Training [30][  160/  196]   Loss 0.195512   Top1 93.225098   Top5 99.787598   BatchTime 0.082091   LR 0.001000   
2022-10-20 17:02:12,015 - INFO  - Training [30][  180/  196]   Loss 0.195045   Top1 93.244358   Top5 99.789497   BatchTime 0.081596   LR 0.001000   
2022-10-20 17:02:13,326 - INFO  - ==> Top1: 93.248    Top5: 99.790    Loss: 0.195

2022-10-20 17:02:13,398 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:02:14,552 - INFO  - Validation [30][   20/   40]   Loss 0.470346   Top1 85.917969   Top5 99.218750   BatchTime 0.057695   
2022-10-20 17:02:15,087 - INFO  - Validation [30][   40/   40]   Loss 0.455295   Top1 86.080000   Top5 99.340000   BatchTime 0.042215   
2022-10-20 17:02:15,170 - INFO  - ==> Top1: 86.080    Top5: 99.340    Loss: 0.455

2022-10-20 17:02:15,170 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:02:16,849 - INFO  - Validation [30][   20/   40]   Loss 0.483803   Top1 85.449219   Top5 99.160156   BatchTime 0.083940   
2022-10-20 17:02:17,728 - INFO  - Validation [30][   40/   40]   Loss 0.466937   Top1 85.960000   Top5 99.270000   BatchTime 0.063959   
2022-10-20 17:02:17,831 - INFO  - ==> Top1: 85.960    Top5: 99.270    Loss: 0.467

2022-10-20 17:02:17,831 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 85.960   Top5: 99.270]
2022-10-20 17:02:17,831 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 84.080   Top5: 99.110]
2022-10-20 17:02:17,831 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 83.820   Top5: 99.190]
2022-10-20 17:02:19,600 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 17:02:19,601 - INFO  - >>>>>> Epoch  31
2022-10-20 17:02:19,601 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:02:21,815 - INFO  - Training [31][   20/  196]   Loss 0.176342   Top1 94.023438   Top5 99.804688   BatchTime 0.110681   LR 0.001000   
2022-10-20 17:02:23,374 - INFO  - Training [31][   40/  196]   Loss 0.177419   Top1 94.082031   Top5 99.785156   BatchTime 0.094321   LR 0.001000   
2022-10-20 17:02:24,935 - INFO  - Training [31][   60/  196]   Loss 0.176881   Top1 94.114583   Top5 99.798177   BatchTime 0.088887   LR 0.001000   
2022-10-20 17:02:26,495 - INFO  - Training [31][   80/  196]   Loss 0.178575   Top1 93.964844   Top5 99.790039   BatchTime 0.086162   LR 0.001000   
2022-10-20 17:02:28,055 - INFO  - Training [31][  100/  196]   Loss 0.177484   Top1 93.976562   Top5 99.800781   BatchTime 0.084530   LR 0.001000   
2022-10-20 17:02:29,615 - INFO  - Training [31][  120/  196]   Loss 0.175161   Top1 94.016927   Top5 99.814453   BatchTime 0.083440   LR 0.001000   
2022-10-20 17:02:31,175 - INFO  - Training [31][  140/  196]   Loss 0.175666   Top1 93.964844   Top5 99.829799   BatchTime 0.082663   LR 0.001000   
2022-10-20 17:02:32,734 - INFO  - Training [31][  160/  196]   Loss 0.176773   Top1 93.867188   Top5 99.826660   BatchTime 0.082078   LR 0.001000   
2022-10-20 17:02:34,280 - INFO  - Training [31][  180/  196]   Loss 0.176674   Top1 93.888889   Top5 99.806858   BatchTime 0.081546   LR 0.001000   
2022-10-20 17:02:35,587 - INFO  - ==> Top1: 93.888    Top5: 99.808    Loss: 0.177

2022-10-20 17:02:35,654 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:02:36,821 - INFO  - Validation [31][   20/   40]   Loss 0.463309   Top1 85.625000   Top5 99.218750   BatchTime 0.058312   
2022-10-20 17:02:37,353 - INFO  - Validation [31][   40/   40]   Loss 0.450474   Top1 85.880000   Top5 99.360000   BatchTime 0.042470   
2022-10-20 17:02:37,446 - INFO  - ==> Top1: 85.880    Top5: 99.360    Loss: 0.450

2022-10-20 17:02:37,447 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:02:39,086 - INFO  - Validation [31][   20/   40]   Loss 0.475118   Top1 85.781250   Top5 99.179688   BatchTime 0.081954   
2022-10-20 17:02:39,886 - INFO  - Validation [31][   40/   40]   Loss 0.462856   Top1 85.940000   Top5 99.340000   BatchTime 0.060982   
2022-10-20 17:02:39,993 - INFO  - ==> Top1: 85.940    Top5: 99.340    Loss: 0.463

2022-10-20 17:02:39,993 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 85.960   Top5: 99.270]
2022-10-20 17:02:39,993 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 85.940   Top5: 99.340]
2022-10-20 17:02:39,993 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 84.080   Top5: 99.110]
2022-10-20 17:02:40,053 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:02:40,054 - INFO  - >>>>>> Epoch  32
2022-10-20 17:02:40,054 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:02:42,329 - INFO  - Training [32][   20/  196]   Loss 0.167425   Top1 94.531250   Top5 99.804688   BatchTime 0.113595   LR 0.001000   
2022-10-20 17:02:43,890 - INFO  - Training [32][   40/  196]   Loss 0.165814   Top1 94.394531   Top5 99.824219   BatchTime 0.095807   LR 0.001000   
2022-10-20 17:02:45,450 - INFO  - Training [32][   60/  196]   Loss 0.169201   Top1 94.192708   Top5 99.830729   BatchTime 0.089881   LR 0.001000   
2022-10-20 17:02:47,013 - INFO  - Training [32][   80/  196]   Loss 0.168605   Top1 94.257812   Top5 99.819336   BatchTime 0.086942   LR 0.001000   
2022-10-20 17:02:48,570 - INFO  - Training [32][  100/  196]   Loss 0.169677   Top1 94.183594   Top5 99.812500   BatchTime 0.085128   LR 0.001000   
2022-10-20 17:02:50,131 - INFO  - Training [32][  120/  196]   Loss 0.168411   Top1 94.257812   Top5 99.811198   BatchTime 0.083942   LR 0.001000   
2022-10-20 17:02:51,691 - INFO  - Training [32][  140/  196]   Loss 0.168346   Top1 94.294085   Top5 99.799107   BatchTime 0.083092   LR 0.001000   
2022-10-20 17:02:53,254 - INFO  - Training [32][  160/  196]   Loss 0.166796   Top1 94.335938   Top5 99.802246   BatchTime 0.082474   LR 0.001000   
2022-10-20 17:02:54,802 - INFO  - Training [32][  180/  196]   Loss 0.166846   Top1 94.364149   Top5 99.800347   BatchTime 0.081912   LR 0.001000   
2022-10-20 17:02:56,118 - INFO  - ==> Top1: 94.360    Top5: 99.792    Loss: 0.167

2022-10-20 17:02:56,183 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:02:57,345 - INFO  - Validation [32][   20/   40]   Loss 0.467300   Top1 86.171875   Top5 99.160156   BatchTime 0.058051   
2022-10-20 17:02:57,885 - INFO  - Validation [32][   40/   40]   Loss 0.453453   Top1 86.280000   Top5 99.320000   BatchTime 0.042531   
2022-10-20 17:02:57,981 - INFO  - ==> Top1: 86.280    Top5: 99.320    Loss: 0.453

2022-10-20 17:02:57,981 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:02:59,649 - INFO  - Validation [32][   20/   40]   Loss 0.477494   Top1 86.347656   Top5 99.160156   BatchTime 0.083383   
2022-10-20 17:03:00,506 - INFO  - Validation [32][   40/   40]   Loss 0.464042   Top1 86.350000   Top5 99.300000   BatchTime 0.063113   
2022-10-20 17:03:00,605 - INFO  - ==> Top1: 86.350    Top5: 99.300    Loss: 0.464

2022-10-20 17:03:00,605 - INFO  - Scoreboard best 1 ==> Epoch [32][Top1: 86.350   Top5: 99.300]
2022-10-20 17:03:00,605 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 85.960   Top5: 99.270]
2022-10-20 17:03:00,605 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 85.940   Top5: 99.340]
2022-10-20 17:03:02,390 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 17:03:02,391 - INFO  - >>>>>> Epoch  33
2022-10-20 17:03:02,392 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:03:04,644 - INFO  - Training [33][   20/  196]   Loss 0.162157   Top1 94.570312   Top5 99.804688   BatchTime 0.112515   LR 0.001000   
2022-10-20 17:03:06,208 - INFO  - Training [33][   40/  196]   Loss 0.162451   Top1 94.501953   Top5 99.804688   BatchTime 0.095350   LR 0.001000   
2022-10-20 17:03:07,770 - INFO  - Training [33][   60/  196]   Loss 0.165418   Top1 94.348958   Top5 99.791667   BatchTime 0.089613   LR 0.001000   
2022-10-20 17:03:09,327 - INFO  - Training [33][   80/  196]   Loss 0.163864   Top1 94.375000   Top5 99.809570   BatchTime 0.086666   LR 0.001000   
2022-10-20 17:03:10,889 - INFO  - Training [33][  100/  196]   Loss 0.164011   Top1 94.414062   Top5 99.808594   BatchTime 0.084956   LR 0.001000   
2022-10-20 17:03:12,446 - INFO  - Training [33][  120/  196]   Loss 0.162503   Top1 94.492188   Top5 99.824219   BatchTime 0.083769   LR 0.001000   
2022-10-20 17:03:14,006 - INFO  - Training [33][  140/  196]   Loss 0.161793   Top1 94.525670   Top5 99.827009   BatchTime 0.082942   LR 0.001000   
2022-10-20 17:03:15,566 - INFO  - Training [33][  160/  196]   Loss 0.162154   Top1 94.504395   Top5 99.826660   BatchTime 0.082326   LR 0.001000   
2022-10-20 17:03:17,134 - INFO  - Training [33][  180/  196]   Loss 0.161551   Top1 94.552951   Top5 99.830729   BatchTime 0.081891   LR 0.001000   
2022-10-20 17:03:18,441 - INFO  - ==> Top1: 94.486    Top5: 99.834    Loss: 0.163

2022-10-20 17:03:18,508 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:03:19,696 - INFO  - Validation [33][   20/   40]   Loss 0.469889   Top1 86.191406   Top5 99.101562   BatchTime 0.059356   
2022-10-20 17:03:20,228 - INFO  - Validation [33][   40/   40]   Loss 0.451842   Top1 86.440000   Top5 99.220000   BatchTime 0.042973   
2022-10-20 17:03:20,315 - INFO  - ==> Top1: 86.440    Top5: 99.220    Loss: 0.452

2022-10-20 17:03:20,315 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:03:21,977 - INFO  - Validation [33][   20/   40]   Loss 0.479653   Top1 86.132812   Top5 99.082031   BatchTime 0.083082   
2022-10-20 17:03:22,773 - INFO  - Validation [33][   40/   40]   Loss 0.463286   Top1 86.390000   Top5 99.210000   BatchTime 0.061449   
2022-10-20 17:03:22,873 - INFO  - ==> Top1: 86.390    Top5: 99.210    Loss: 0.463

2022-10-20 17:03:22,873 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 86.390   Top5: 99.210]
2022-10-20 17:03:22,873 - INFO  - Scoreboard best 2 ==> Epoch [32][Top1: 86.350   Top5: 99.300]
2022-10-20 17:03:22,873 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 85.960   Top5: 99.270]
2022-10-20 17:03:24,665 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 17:03:24,665 - INFO  - >>>>>> Epoch  34
2022-10-20 17:03:24,665 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:03:26,895 - INFO  - Training [34][   20/  196]   Loss 0.149017   Top1 94.785156   Top5 99.824219   BatchTime 0.111465   LR 0.001000   
2022-10-20 17:03:28,453 - INFO  - Training [34][   40/  196]   Loss 0.151838   Top1 94.873047   Top5 99.814453   BatchTime 0.094666   LR 0.001000   
2022-10-20 17:03:30,010 - INFO  - Training [34][   60/  196]   Loss 0.152253   Top1 94.876302   Top5 99.817708   BatchTime 0.089066   LR 0.001000   
2022-10-20 17:03:31,568 - INFO  - Training [34][   80/  196]   Loss 0.149713   Top1 95.034180   Top5 99.838867   BatchTime 0.086265   LR 0.001000   
2022-10-20 17:03:33,127 - INFO  - Training [34][  100/  196]   Loss 0.153280   Top1 94.882812   Top5 99.808594   BatchTime 0.084602   LR 0.001000   
2022-10-20 17:03:34,684 - INFO  - Training [34][  120/  196]   Loss 0.153868   Top1 94.820964   Top5 99.811198   BatchTime 0.083480   LR 0.001000   
2022-10-20 17:03:36,241 - INFO  - Training [34][  140/  196]   Loss 0.154519   Top1 94.762835   Top5 99.810268   BatchTime 0.082676   LR 0.001000   
2022-10-20 17:03:37,800 - INFO  - Training [34][  160/  196]   Loss 0.154337   Top1 94.746094   Top5 99.819336   BatchTime 0.082083   LR 0.001000   
2022-10-20 17:03:39,348 - INFO  - Training [34][  180/  196]   Loss 0.155381   Top1 94.691840   Top5 99.822049   BatchTime 0.081562   LR 0.001000   
2022-10-20 17:03:40,651 - INFO  - ==> Top1: 94.718    Top5: 99.814    Loss: 0.155

2022-10-20 17:03:40,718 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:03:41,907 - INFO  - Validation [34][   20/   40]   Loss 0.462556   Top1 86.152344   Top5 99.160156   BatchTime 0.059401   
2022-10-20 17:03:42,444 - INFO  - Validation [34][   40/   40]   Loss 0.449489   Top1 86.370000   Top5 99.280000   BatchTime 0.043130   
2022-10-20 17:03:42,543 - INFO  - ==> Top1: 86.370    Top5: 99.280    Loss: 0.449

2022-10-20 17:03:42,543 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:03:44,233 - INFO  - Validation [34][   20/   40]   Loss 0.473478   Top1 86.210938   Top5 99.042969   BatchTime 0.084470   
2022-10-20 17:03:45,036 - INFO  - Validation [34][   40/   40]   Loss 0.461043   Top1 86.390000   Top5 99.190000   BatchTime 0.062304   
2022-10-20 17:03:45,132 - INFO  - ==> Top1: 86.390    Top5: 99.190    Loss: 0.461

2022-10-20 17:03:45,132 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 86.390   Top5: 99.210]
2022-10-20 17:03:45,132 - INFO  - Scoreboard best 2 ==> Epoch [34][Top1: 86.390   Top5: 99.190]
2022-10-20 17:03:45,132 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 86.350   Top5: 99.300]
2022-10-20 17:03:45,184 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:03:45,184 - INFO  - >>>>>> Epoch  35
2022-10-20 17:03:45,184 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:03:47,430 - INFO  - Training [35][   20/  196]   Loss 0.147606   Top1 94.804688   Top5 99.843750   BatchTime 0.112241   LR 0.001000   
2022-10-20 17:03:48,991 - INFO  - Training [35][   40/  196]   Loss 0.152007   Top1 94.824219   Top5 99.853516   BatchTime 0.095145   LR 0.001000   
2022-10-20 17:03:50,549 - INFO  - Training [35][   60/  196]   Loss 0.155377   Top1 94.602865   Top5 99.869792   BatchTime 0.089396   LR 0.001000   
2022-10-20 17:03:52,109 - INFO  - Training [35][   80/  196]   Loss 0.157369   Top1 94.594727   Top5 99.833984   BatchTime 0.086551   LR 0.001000   
2022-10-20 17:03:53,666 - INFO  - Training [35][  100/  196]   Loss 0.155996   Top1 94.632812   Top5 99.839844   BatchTime 0.084811   LR 0.001000   
2022-10-20 17:03:55,221 - INFO  - Training [35][  120/  196]   Loss 0.155847   Top1 94.654948   Top5 99.840495   BatchTime 0.083631   LR 0.001000   
2022-10-20 17:03:56,778 - INFO  - Training [35][  140/  196]   Loss 0.156432   Top1 94.662388   Top5 99.849330   BatchTime 0.082807   LR 0.001000   
2022-10-20 17:03:58,338 - INFO  - Training [35][  160/  196]   Loss 0.155768   Top1 94.675293   Top5 99.848633   BatchTime 0.082205   LR 0.001000   
2022-10-20 17:03:59,883 - INFO  - Training [35][  180/  196]   Loss 0.155381   Top1 94.733073   Top5 99.837240   BatchTime 0.081653   LR 0.001000   
2022-10-20 17:04:01,183 - INFO  - ==> Top1: 94.698    Top5: 99.840    Loss: 0.156

2022-10-20 17:04:01,250 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:04:02,429 - INFO  - Validation [35][   20/   40]   Loss 0.468861   Top1 86.425781   Top5 99.140625   BatchTime 0.058925   
2022-10-20 17:04:02,967 - INFO  - Validation [35][   40/   40]   Loss 0.452024   Top1 86.550000   Top5 99.310000   BatchTime 0.042896   
2022-10-20 17:04:03,068 - INFO  - ==> Top1: 86.550    Top5: 99.310    Loss: 0.452

2022-10-20 17:04:03,068 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:04:04,737 - INFO  - Validation [35][   20/   40]   Loss 0.479748   Top1 86.523438   Top5 99.101562   BatchTime 0.083415   
2022-10-20 17:04:05,544 - INFO  - Validation [35][   40/   40]   Loss 0.462981   Top1 86.590000   Top5 99.250000   BatchTime 0.061897   
2022-10-20 17:04:05,650 - INFO  - ==> Top1: 86.590    Top5: 99.250    Loss: 0.463

2022-10-20 17:04:05,650 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:04:05,651 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 86.390   Top5: 99.210]
2022-10-20 17:04:05,651 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 86.390   Top5: 99.190]
2022-10-20 17:04:07,422 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 17:04:07,423 - INFO  - >>>>>> Epoch  36
2022-10-20 17:04:07,423 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:04:09,652 - INFO  - Training [36][   20/  196]   Loss 0.162534   Top1 94.433594   Top5 99.726562   BatchTime 0.111411   LR 0.001000   
2022-10-20 17:04:11,213 - INFO  - Training [36][   40/  196]   Loss 0.157370   Top1 94.580078   Top5 99.775391   BatchTime 0.094727   LR 0.001000   
2022-10-20 17:04:12,774 - INFO  - Training [36][   60/  196]   Loss 0.157911   Top1 94.641927   Top5 99.791667   BatchTime 0.089169   LR 0.001000   
2022-10-20 17:04:14,335 - INFO  - Training [36][   80/  196]   Loss 0.154565   Top1 94.794922   Top5 99.809570   BatchTime 0.086387   LR 0.001000   
2022-10-20 17:04:15,900 - INFO  - Training [36][  100/  196]   Loss 0.153464   Top1 94.820312   Top5 99.812500   BatchTime 0.084765   LR 0.001000   
2022-10-20 17:04:17,465 - INFO  - Training [36][  120/  196]   Loss 0.152514   Top1 94.801432   Top5 99.811198   BatchTime 0.083676   LR 0.001000   
2022-10-20 17:04:19,028 - INFO  - Training [36][  140/  196]   Loss 0.153361   Top1 94.762835   Top5 99.810268   BatchTime 0.082890   LR 0.001000   
2022-10-20 17:04:20,587 - INFO  - Training [36][  160/  196]   Loss 0.153639   Top1 94.777832   Top5 99.809570   BatchTime 0.082270   LR 0.001000   
2022-10-20 17:04:22,139 - INFO  - Training [36][  180/  196]   Loss 0.155325   Top1 94.730903   Top5 99.802517   BatchTime 0.081752   LR 0.001000   
2022-10-20 17:04:23,454 - INFO  - ==> Top1: 94.722    Top5: 99.808    Loss: 0.155

2022-10-20 17:04:23,525 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:04:24,716 - INFO  - Validation [36][   20/   40]   Loss 0.463806   Top1 86.230469   Top5 99.199219   BatchTime 0.059510   
2022-10-20 17:04:25,249 - INFO  - Validation [36][   40/   40]   Loss 0.447599   Top1 86.430000   Top5 99.370000   BatchTime 0.043077   
2022-10-20 17:04:25,347 - INFO  - ==> Top1: 86.430    Top5: 99.370    Loss: 0.448

2022-10-20 17:04:25,347 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:04:26,994 - INFO  - Validation [36][   20/   40]   Loss 0.473822   Top1 86.269531   Top5 99.179688   BatchTime 0.082326   
2022-10-20 17:04:27,797 - INFO  - Validation [36][   40/   40]   Loss 0.458259   Top1 86.500000   Top5 99.280000   BatchTime 0.061226   
2022-10-20 17:04:27,903 - INFO  - ==> Top1: 86.500    Top5: 99.280    Loss: 0.458

2022-10-20 17:04:27,904 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:04:27,904 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:04:27,904 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 86.390   Top5: 99.210]
2022-10-20 17:04:27,970 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:04:27,970 - INFO  - >>>>>> Epoch  37
2022-10-20 17:04:27,971 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:04:30,219 - INFO  - Training [37][   20/  196]   Loss 0.139305   Top1 95.527344   Top5 99.804688   BatchTime 0.112379   LR 0.001000   
2022-10-20 17:04:31,778 - INFO  - Training [37][   40/  196]   Loss 0.151239   Top1 95.087891   Top5 99.804688   BatchTime 0.095173   LR 0.001000   
2022-10-20 17:04:33,338 - INFO  - Training [37][   60/  196]   Loss 0.151262   Top1 95.019531   Top5 99.837240   BatchTime 0.089443   LR 0.001000   
2022-10-20 17:04:34,898 - INFO  - Training [37][   80/  196]   Loss 0.152351   Top1 94.965820   Top5 99.829102   BatchTime 0.086579   LR 0.001000   
2022-10-20 17:04:36,457 - INFO  - Training [37][  100/  196]   Loss 0.151711   Top1 94.960938   Top5 99.839844   BatchTime 0.084856   LR 0.001000   
2022-10-20 17:04:38,018 - INFO  - Training [37][  120/  196]   Loss 0.151737   Top1 94.928385   Top5 99.833984   BatchTime 0.083721   LR 0.001000   
2022-10-20 17:04:39,578 - INFO  - Training [37][  140/  196]   Loss 0.150984   Top1 94.938616   Top5 99.835379   BatchTime 0.082900   LR 0.001000   
2022-10-20 17:04:41,138 - INFO  - Training [37][  160/  196]   Loss 0.150138   Top1 94.995117   Top5 99.836426   BatchTime 0.082287   LR 0.001000   
2022-10-20 17:04:42,689 - INFO  - Training [37][  180/  196]   Loss 0.150839   Top1 94.943576   Top5 99.841580   BatchTime 0.081764   LR 0.001000   
2022-10-20 17:04:44,014 - INFO  - ==> Top1: 94.990    Top5: 99.846    Loss: 0.150

2022-10-20 17:04:44,122 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:04:45,322 - INFO  - Validation [37][   20/   40]   Loss 0.465523   Top1 86.210938   Top5 99.082031   BatchTime 0.060017   
2022-10-20 17:04:45,857 - INFO  - Validation [37][   40/   40]   Loss 0.450161   Top1 86.280000   Top5 99.260000   BatchTime 0.043364   
2022-10-20 17:04:45,960 - INFO  - ==> Top1: 86.280    Top5: 99.260    Loss: 0.450

2022-10-20 17:04:45,960 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:04:47,655 - INFO  - Validation [37][   20/   40]   Loss 0.476319   Top1 86.230469   Top5 99.179688   BatchTime 0.084710   
2022-10-20 17:04:48,461 - INFO  - Validation [37][   40/   40]   Loss 0.460880   Top1 86.310000   Top5 99.250000   BatchTime 0.062508   
2022-10-20 17:04:48,569 - INFO  - ==> Top1: 86.310    Top5: 99.250    Loss: 0.461

2022-10-20 17:04:48,570 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:04:48,570 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:04:48,570 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 86.390   Top5: 99.210]
2022-10-20 17:04:48,641 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:04:48,641 - INFO  - >>>>>> Epoch  38
2022-10-20 17:04:48,641 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:04:51,098 - INFO  - Training [38][   20/  196]   Loss 0.145293   Top1 95.000000   Top5 99.941406   BatchTime 0.122810   LR 0.001000   
2022-10-20 17:04:52,662 - INFO  - Training [38][   40/  196]   Loss 0.142729   Top1 95.185547   Top5 99.941406   BatchTime 0.100517   LR 0.001000   
2022-10-20 17:04:54,224 - INFO  - Training [38][   60/  196]   Loss 0.146232   Top1 95.000000   Top5 99.889323   BatchTime 0.093039   LR 0.001000   
2022-10-20 17:04:55,786 - INFO  - Training [38][   80/  196]   Loss 0.148057   Top1 94.853516   Top5 99.882812   BatchTime 0.089297   LR 0.001000   
2022-10-20 17:04:57,347 - INFO  - Training [38][  100/  196]   Loss 0.147827   Top1 94.906250   Top5 99.855469   BatchTime 0.087052   LR 0.001000   
2022-10-20 17:04:58,908 - INFO  - Training [38][  120/  196]   Loss 0.147855   Top1 94.876302   Top5 99.847005   BatchTime 0.085551   LR 0.001000   
2022-10-20 17:05:00,469 - INFO  - Training [38][  140/  196]   Loss 0.148873   Top1 94.888393   Top5 99.824219   BatchTime 0.084479   LR 0.001000   
2022-10-20 17:05:02,030 - INFO  - Training [38][  160/  196]   Loss 0.150731   Top1 94.814453   Top5 99.814453   BatchTime 0.083678   LR 0.001000   
2022-10-20 17:05:03,582 - INFO  - Training [38][  180/  196]   Loss 0.150848   Top1 94.806858   Top5 99.826389   BatchTime 0.083000   LR 0.001000   
2022-10-20 17:05:04,914 - INFO  - ==> Top1: 94.842    Top5: 99.826    Loss: 0.150

2022-10-20 17:05:04,980 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:05:06,199 - INFO  - Validation [38][   20/   40]   Loss 0.478802   Top1 86.386719   Top5 99.121094   BatchTime 0.060904   
2022-10-20 17:05:06,739 - INFO  - Validation [38][   40/   40]   Loss 0.459237   Top1 86.500000   Top5 99.300000   BatchTime 0.043942   
2022-10-20 17:05:06,838 - INFO  - ==> Top1: 86.500    Top5: 99.300    Loss: 0.459

2022-10-20 17:05:06,839 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:05:08,524 - INFO  - Validation [38][   20/   40]   Loss 0.493759   Top1 86.308594   Top5 99.121094   BatchTime 0.084225   
2022-10-20 17:05:09,324 - INFO  - Validation [38][   40/   40]   Loss 0.472318   Top1 86.410000   Top5 99.270000   BatchTime 0.062116   
2022-10-20 17:05:09,434 - INFO  - ==> Top1: 86.410    Top5: 99.270    Loss: 0.472

2022-10-20 17:05:09,434 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:05:09,434 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:05:09,434 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 86.410   Top5: 99.270]
2022-10-20 17:05:09,460 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:05:09,460 - INFO  - >>>>>> Epoch  39
2022-10-20 17:05:09,460 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:05:11,718 - INFO  - Training [39][   20/  196]   Loss 0.130341   Top1 95.644531   Top5 99.843750   BatchTime 0.112857   LR 0.001000   
2022-10-20 17:05:13,277 - INFO  - Training [39][   40/  196]   Loss 0.140744   Top1 95.439453   Top5 99.804688   BatchTime 0.095412   LR 0.001000   
2022-10-20 17:05:14,836 - INFO  - Training [39][   60/  196]   Loss 0.140586   Top1 95.468750   Top5 99.817708   BatchTime 0.089586   LR 0.001000   
2022-10-20 17:05:16,405 - INFO  - Training [39][   80/  196]   Loss 0.141575   Top1 95.336914   Top5 99.843750   BatchTime 0.086796   LR 0.001000   
2022-10-20 17:05:17,973 - INFO  - Training [39][  100/  196]   Loss 0.142746   Top1 95.250000   Top5 99.832031   BatchTime 0.085115   LR 0.001000   
2022-10-20 17:05:19,534 - INFO  - Training [39][  120/  196]   Loss 0.144348   Top1 95.192057   Top5 99.827474   BatchTime 0.083943   LR 0.001000   
2022-10-20 17:05:21,095 - INFO  - Training [39][  140/  196]   Loss 0.144869   Top1 95.172991   Top5 99.824219   BatchTime 0.083101   LR 0.001000   
2022-10-20 17:05:22,657 - INFO  - Training [39][  160/  196]   Loss 0.142967   Top1 95.258789   Top5 99.819336   BatchTime 0.082473   LR 0.001000   
2022-10-20 17:05:24,208 - INFO  - Training [39][  180/  196]   Loss 0.142975   Top1 95.262587   Top5 99.819878   BatchTime 0.081926   LR 0.001000   
2022-10-20 17:05:25,523 - INFO  - ==> Top1: 95.200    Top5: 99.814    Loss: 0.144

2022-10-20 17:05:25,591 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:05:26,822 - INFO  - Validation [39][   20/   40]   Loss 0.474236   Top1 86.171875   Top5 99.101562   BatchTime 0.061514   
2022-10-20 17:05:27,354 - INFO  - Validation [39][   40/   40]   Loss 0.457724   Top1 86.370000   Top5 99.280000   BatchTime 0.044076   
2022-10-20 17:05:27,446 - INFO  - ==> Top1: 86.370    Top5: 99.280    Loss: 0.458

2022-10-20 17:05:27,446 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:05:29,119 - INFO  - Validation [39][   20/   40]   Loss 0.489983   Top1 86.074219   Top5 99.121094   BatchTime 0.083621   
2022-10-20 17:05:29,923 - INFO  - Validation [39][   40/   40]   Loss 0.472142   Top1 86.240000   Top5 99.260000   BatchTime 0.061913   
2022-10-20 17:05:30,027 - INFO  - ==> Top1: 86.240    Top5: 99.260    Loss: 0.472

2022-10-20 17:05:30,027 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:05:30,027 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:05:30,027 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 86.410   Top5: 99.270]
2022-10-20 17:05:30,083 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:05:30,083 - INFO  - >>>>>> Epoch  40
2022-10-20 17:05:30,083 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:05:32,351 - INFO  - Training [40][   20/  196]   Loss 0.132618   Top1 95.625000   Top5 99.843750   BatchTime 0.113343   LR 0.001000   
2022-10-20 17:05:33,915 - INFO  - Training [40][   40/  196]   Loss 0.137293   Top1 95.400391   Top5 99.892578   BatchTime 0.095763   LR 0.001000   
2022-10-20 17:05:35,481 - INFO  - Training [40][   60/  196]   Loss 0.142512   Top1 95.195312   Top5 99.876302   BatchTime 0.089951   LR 0.001000   
2022-10-20 17:05:37,042 - INFO  - Training [40][   80/  196]   Loss 0.144456   Top1 95.083008   Top5 99.848633   BatchTime 0.086968   LR 0.001000   
2022-10-20 17:05:38,606 - INFO  - Training [40][  100/  196]   Loss 0.145301   Top1 95.046875   Top5 99.832031   BatchTime 0.085222   LR 0.001000   
2022-10-20 17:05:40,168 - INFO  - Training [40][  120/  196]   Loss 0.145367   Top1 95.022786   Top5 99.847005   BatchTime 0.084033   LR 0.001000   
2022-10-20 17:05:41,731 - INFO  - Training [40][  140/  196]   Loss 0.144357   Top1 95.044643   Top5 99.852121   BatchTime 0.083187   LR 0.001000   
2022-10-20 17:05:43,292 - INFO  - Training [40][  160/  196]   Loss 0.145142   Top1 95.031738   Top5 99.851074   BatchTime 0.082548   LR 0.001000   
2022-10-20 17:05:44,846 - INFO  - Training [40][  180/  196]   Loss 0.145008   Top1 95.041233   Top5 99.852431   BatchTime 0.082006   LR 0.001000   
2022-10-20 17:05:46,170 - INFO  - ==> Top1: 95.028    Top5: 99.852    Loss: 0.146

2022-10-20 17:05:46,236 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:05:47,419 - INFO  - Validation [40][   20/   40]   Loss 0.477048   Top1 86.406250   Top5 99.160156   BatchTime 0.059105   
2022-10-20 17:05:47,952 - INFO  - Validation [40][   40/   40]   Loss 0.456821   Top1 86.520000   Top5 99.360000   BatchTime 0.042890   
2022-10-20 17:05:48,050 - INFO  - ==> Top1: 86.520    Top5: 99.360    Loss: 0.457

2022-10-20 17:05:48,051 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:05:49,741 - INFO  - Validation [40][   20/   40]   Loss 0.489620   Top1 86.152344   Top5 99.199219   BatchTime 0.084491   
2022-10-20 17:05:50,546 - INFO  - Validation [40][   40/   40]   Loss 0.470102   Top1 86.480000   Top5 99.300000   BatchTime 0.062363   
2022-10-20 17:05:50,648 - INFO  - ==> Top1: 86.480    Top5: 99.300    Loss: 0.470

2022-10-20 17:05:50,648 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:05:50,648 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:05:50,648 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 86.480   Top5: 99.300]
2022-10-20 17:05:50,713 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:05:50,714 - INFO  - >>>>>> Epoch  41
2022-10-20 17:05:50,714 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:05:53,035 - INFO  - Training [41][   20/  196]   Loss 0.145021   Top1 94.882812   Top5 99.843750   BatchTime 0.115886   LR 0.001000   
2022-10-20 17:05:54,599 - INFO  - Training [41][   40/  196]   Loss 0.142837   Top1 95.019531   Top5 99.843750   BatchTime 0.097054   LR 0.001000   
2022-10-20 17:05:56,164 - INFO  - Training [41][   60/  196]   Loss 0.139759   Top1 95.182292   Top5 99.863281   BatchTime 0.090780   LR 0.001000   
2022-10-20 17:05:57,728 - INFO  - Training [41][   80/  196]   Loss 0.140700   Top1 95.166016   Top5 99.853516   BatchTime 0.087636   LR 0.001000   
2022-10-20 17:05:59,292 - INFO  - Training [41][  100/  196]   Loss 0.142463   Top1 95.175781   Top5 99.851562   BatchTime 0.085746   LR 0.001000   
2022-10-20 17:06:00,856 - INFO  - Training [41][  120/  196]   Loss 0.142489   Top1 95.172526   Top5 99.853516   BatchTime 0.084491   LR 0.001000   
2022-10-20 17:06:02,423 - INFO  - Training [41][  140/  196]   Loss 0.142742   Top1 95.195312   Top5 99.846540   BatchTime 0.083613   LR 0.001000   
2022-10-20 17:06:03,985 - INFO  - Training [41][  160/  196]   Loss 0.144201   Top1 95.134277   Top5 99.841309   BatchTime 0.082922   LR 0.001000   
2022-10-20 17:06:05,540 - INFO  - Training [41][  180/  196]   Loss 0.144408   Top1 95.119358   Top5 99.837240   BatchTime 0.082347   LR 0.001000   
2022-10-20 17:06:06,848 - INFO  - ==> Top1: 95.064    Top5: 99.830    Loss: 0.145

2022-10-20 17:06:06,920 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:06:08,127 - INFO  - Validation [41][   20/   40]   Loss 0.483000   Top1 86.132812   Top5 99.218750   BatchTime 0.060338   
2022-10-20 17:06:08,667 - INFO  - Validation [41][   40/   40]   Loss 0.460608   Top1 86.450000   Top5 99.330000   BatchTime 0.043671   
2022-10-20 17:06:08,769 - INFO  - ==> Top1: 86.450    Top5: 99.330    Loss: 0.461

2022-10-20 17:06:08,769 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:06:10,446 - INFO  - Validation [41][   20/   40]   Loss 0.495681   Top1 86.054688   Top5 99.160156   BatchTime 0.083833   
2022-10-20 17:06:11,252 - INFO  - Validation [41][   40/   40]   Loss 0.474142   Top1 86.430000   Top5 99.300000   BatchTime 0.062056   
2022-10-20 17:06:11,365 - INFO  - ==> Top1: 86.430    Top5: 99.300    Loss: 0.474

2022-10-20 17:06:11,365 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:06:11,365 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:06:11,365 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 86.480   Top5: 99.300]
2022-10-20 17:06:11,422 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:06:11,423 - INFO  - >>>>>> Epoch  42
2022-10-20 17:06:11,423 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:06:13,680 - INFO  - Training [42][   20/  196]   Loss 0.142280   Top1 95.156250   Top5 99.765625   BatchTime 0.112835   LR 0.001000   
2022-10-20 17:06:15,246 - INFO  - Training [42][   40/  196]   Loss 0.144220   Top1 95.087891   Top5 99.794922   BatchTime 0.095560   LR 0.001000   
2022-10-20 17:06:16,815 - INFO  - Training [42][   60/  196]   Loss 0.144923   Top1 95.058594   Top5 99.804688   BatchTime 0.089849   LR 0.001000   
2022-10-20 17:06:18,378 - INFO  - Training [42][   80/  196]   Loss 0.147452   Top1 94.941406   Top5 99.819336   BatchTime 0.086931   LR 0.001000   
2022-10-20 17:06:19,941 - INFO  - Training [42][  100/  196]   Loss 0.146038   Top1 94.953125   Top5 99.804688   BatchTime 0.085173   LR 0.001000   
2022-10-20 17:06:21,504 - INFO  - Training [42][  120/  196]   Loss 0.146066   Top1 94.983724   Top5 99.814453   BatchTime 0.084002   LR 0.001000   
2022-10-20 17:06:23,067 - INFO  - Training [42][  140/  196]   Loss 0.146090   Top1 95.000000   Top5 99.801897   BatchTime 0.083164   LR 0.001000   
2022-10-20 17:06:24,630 - INFO  - Training [42][  160/  196]   Loss 0.143507   Top1 95.080566   Top5 99.804688   BatchTime 0.082537   LR 0.001000   
2022-10-20 17:06:26,185 - INFO  - Training [42][  180/  196]   Loss 0.143729   Top1 95.049913   Top5 99.811198   BatchTime 0.082004   LR 0.001000   
2022-10-20 17:06:27,513 - INFO  - ==> Top1: 95.054    Top5: 99.812    Loss: 0.144

2022-10-20 17:06:27,579 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:06:28,766 - INFO  - Validation [42][   20/   40]   Loss 0.479522   Top1 86.250000   Top5 99.101562   BatchTime 0.059314   
2022-10-20 17:06:29,302 - INFO  - Validation [42][   40/   40]   Loss 0.457612   Top1 86.570000   Top5 99.270000   BatchTime 0.043060   
2022-10-20 17:06:29,396 - INFO  - ==> Top1: 86.570    Top5: 99.270    Loss: 0.458

2022-10-20 17:06:29,396 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:06:31,099 - INFO  - Validation [42][   20/   40]   Loss 0.486659   Top1 86.093750   Top5 99.179688   BatchTime 0.085128   
2022-10-20 17:06:31,907 - INFO  - Validation [42][   40/   40]   Loss 0.468876   Top1 86.370000   Top5 99.290000   BatchTime 0.062757   
2022-10-20 17:06:32,024 - INFO  - ==> Top1: 86.370    Top5: 99.290    Loss: 0.469

2022-10-20 17:06:32,024 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:06:32,024 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:06:32,024 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 86.480   Top5: 99.300]
2022-10-20 17:06:32,050 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:06:32,050 - INFO  - >>>>>> Epoch  43
2022-10-20 17:06:32,050 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:06:34,319 - INFO  - Training [43][   20/  196]   Loss 0.149682   Top1 94.960938   Top5 99.785156   BatchTime 0.113381   LR 0.001000   
2022-10-20 17:06:35,885 - INFO  - Training [43][   40/  196]   Loss 0.144201   Top1 95.166016   Top5 99.814453   BatchTime 0.095861   LR 0.001000   
2022-10-20 17:06:37,450 - INFO  - Training [43][   60/  196]   Loss 0.139945   Top1 95.358073   Top5 99.804688   BatchTime 0.089980   LR 0.001000   
2022-10-20 17:06:39,016 - INFO  - Training [43][   80/  196]   Loss 0.141055   Top1 95.268555   Top5 99.780273   BatchTime 0.087065   LR 0.001000   
2022-10-20 17:06:40,578 - INFO  - Training [43][  100/  196]   Loss 0.140024   Top1 95.332031   Top5 99.804688   BatchTime 0.085267   LR 0.001000   
2022-10-20 17:06:42,142 - INFO  - Training [43][  120/  196]   Loss 0.139899   Top1 95.332031   Top5 99.827474   BatchTime 0.084090   LR 0.001000   
2022-10-20 17:06:43,706 - INFO  - Training [43][  140/  196]   Loss 0.140015   Top1 95.309710   Top5 99.824219   BatchTime 0.083246   LR 0.001000   
2022-10-20 17:06:45,272 - INFO  - Training [43][  160/  196]   Loss 0.139443   Top1 95.290527   Top5 99.831543   BatchTime 0.082630   LR 0.001000   
2022-10-20 17:06:46,824 - INFO  - Training [43][  180/  196]   Loss 0.139776   Top1 95.271267   Top5 99.835069   BatchTime 0.082071   LR 0.001000   
2022-10-20 17:06:48,135 - INFO  - ==> Top1: 95.264    Top5: 99.838    Loss: 0.140

2022-10-20 17:06:48,200 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:06:49,398 - INFO  - Validation [43][   20/   40]   Loss 0.489643   Top1 85.957031   Top5 99.140625   BatchTime 0.059824   
2022-10-20 17:06:49,936 - INFO  - Validation [43][   40/   40]   Loss 0.469506   Top1 86.340000   Top5 99.290000   BatchTime 0.043367   
2022-10-20 17:06:50,027 - INFO  - ==> Top1: 86.340    Top5: 99.290    Loss: 0.470

2022-10-20 17:06:50,027 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:06:51,695 - INFO  - Validation [43][   20/   40]   Loss 0.504716   Top1 86.171875   Top5 99.179688   BatchTime 0.083373   
2022-10-20 17:06:52,510 - INFO  - Validation [43][   40/   40]   Loss 0.483643   Top1 86.320000   Top5 99.300000   BatchTime 0.062054   
2022-10-20 17:06:52,613 - INFO  - ==> Top1: 86.320    Top5: 99.300    Loss: 0.484

2022-10-20 17:06:52,613 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:06:52,613 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:06:52,613 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 86.480   Top5: 99.300]
2022-10-20 17:06:52,668 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:06:52,668 - INFO  - >>>>>> Epoch  44
2022-10-20 17:06:52,668 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:06:54,945 - INFO  - Training [44][   20/  196]   Loss 0.134986   Top1 95.507812   Top5 99.843750   BatchTime 0.113774   LR 0.001000   
2022-10-20 17:06:56,510 - INFO  - Training [44][   40/  196]   Loss 0.135553   Top1 95.429688   Top5 99.833984   BatchTime 0.096009   LR 0.001000   
2022-10-20 17:06:58,075 - INFO  - Training [44][   60/  196]   Loss 0.135792   Top1 95.449219   Top5 99.843750   BatchTime 0.090089   LR 0.001000   
2022-10-20 17:06:59,645 - INFO  - Training [44][   80/  196]   Loss 0.138145   Top1 95.351562   Top5 99.843750   BatchTime 0.087193   LR 0.001000   
2022-10-20 17:07:01,205 - INFO  - Training [44][  100/  196]   Loss 0.138053   Top1 95.359375   Top5 99.832031   BatchTime 0.085352   LR 0.001000   
2022-10-20 17:07:02,769 - INFO  - Training [44][  120/  196]   Loss 0.137970   Top1 95.371094   Top5 99.843750   BatchTime 0.084166   LR 0.001000   
2022-10-20 17:07:04,334 - INFO  - Training [44][  140/  196]   Loss 0.138416   Top1 95.323661   Top5 99.843750   BatchTime 0.083319   LR 0.001000   
2022-10-20 17:07:05,904 - INFO  - Training [44][  160/  196]   Loss 0.138645   Top1 95.302734   Top5 99.841309   BatchTime 0.082713   LR 0.001000   
2022-10-20 17:07:07,453 - INFO  - Training [44][  180/  196]   Loss 0.138193   Top1 95.338542   Top5 99.830729   BatchTime 0.082129   LR 0.001000   
2022-10-20 17:07:08,774 - INFO  - ==> Top1: 95.308    Top5: 99.826    Loss: 0.139

2022-10-20 17:07:08,848 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:07:10,041 - INFO  - Validation [44][   20/   40]   Loss 0.486374   Top1 86.015625   Top5 99.101562   BatchTime 0.059650   
2022-10-20 17:07:10,576 - INFO  - Validation [44][   40/   40]   Loss 0.468275   Top1 86.360000   Top5 99.270000   BatchTime 0.043202   
2022-10-20 17:07:10,670 - INFO  - ==> Top1: 86.360    Top5: 99.270    Loss: 0.468

2022-10-20 17:07:10,670 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:07:12,347 - INFO  - Validation [44][   20/   40]   Loss 0.496741   Top1 86.230469   Top5 99.121094   BatchTime 0.083826   
2022-10-20 17:07:13,151 - INFO  - Validation [44][   40/   40]   Loss 0.481697   Top1 86.490000   Top5 99.310000   BatchTime 0.062008   
2022-10-20 17:07:13,256 - INFO  - ==> Top1: 86.490    Top5: 99.310    Loss: 0.482

2022-10-20 17:07:13,256 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:07:13,256 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:07:13,256 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 86.490   Top5: 99.310]
2022-10-20 17:07:13,312 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:07:13,312 - INFO  - >>>>>> Epoch  45
2022-10-20 17:07:13,312 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:07:15,600 - INFO  - Training [45][   20/  196]   Loss 0.138128   Top1 95.449219   Top5 99.824219   BatchTime 0.114382   LR 0.001000   
2022-10-20 17:07:17,178 - INFO  - Training [45][   40/  196]   Loss 0.139448   Top1 95.273438   Top5 99.843750   BatchTime 0.096626   LR 0.001000   
2022-10-20 17:07:18,742 - INFO  - Training [45][   60/  196]   Loss 0.137844   Top1 95.273438   Top5 99.863281   BatchTime 0.090488   LR 0.001000   
2022-10-20 17:07:20,306 - INFO  - Training [45][   80/  196]   Loss 0.138276   Top1 95.224609   Top5 99.868164   BatchTime 0.087413   LR 0.001000   
2022-10-20 17:07:21,870 - INFO  - Training [45][  100/  196]   Loss 0.139381   Top1 95.199219   Top5 99.871094   BatchTime 0.085573   LR 0.001000   
2022-10-20 17:07:23,434 - INFO  - Training [45][  120/  196]   Loss 0.137298   Top1 95.302734   Top5 99.869792   BatchTime 0.084346   LR 0.001000   
2022-10-20 17:07:24,998 - INFO  - Training [45][  140/  196]   Loss 0.139037   Top1 95.234375   Top5 99.860491   BatchTime 0.083467   LR 0.001000   
2022-10-20 17:07:26,562 - INFO  - Training [45][  160/  196]   Loss 0.139323   Top1 95.224609   Top5 99.838867   BatchTime 0.082810   LR 0.001000   
2022-10-20 17:07:28,118 - INFO  - Training [45][  180/  196]   Loss 0.139230   Top1 95.236545   Top5 99.839410   BatchTime 0.082251   LR 0.001000   
2022-10-20 17:07:29,437 - INFO  - ==> Top1: 95.206    Top5: 99.844    Loss: 0.140

2022-10-20 17:07:29,510 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:07:30,717 - INFO  - Validation [45][   20/   40]   Loss 0.482257   Top1 86.035156   Top5 99.160156   BatchTime 0.060317   
2022-10-20 17:07:31,255 - INFO  - Validation [45][   40/   40]   Loss 0.467531   Top1 86.290000   Top5 99.300000   BatchTime 0.043607   
2022-10-20 17:07:31,337 - INFO  - ==> Top1: 86.290    Top5: 99.300    Loss: 0.468

2022-10-20 17:07:31,337 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:07:33,021 - INFO  - Validation [45][   20/   40]   Loss 0.495342   Top1 85.996094   Top5 99.160156   BatchTime 0.084168   
2022-10-20 17:07:33,824 - INFO  - Validation [45][   40/   40]   Loss 0.481151   Top1 86.210000   Top5 99.290000   BatchTime 0.062151   
2022-10-20 17:07:33,928 - INFO  - ==> Top1: 86.210    Top5: 99.290    Loss: 0.481

2022-10-20 17:07:33,928 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:07:33,928 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:07:33,928 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 86.490   Top5: 99.310]
2022-10-20 17:07:33,954 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:07:33,954 - INFO  - >>>>>> Epoch  46
2022-10-20 17:07:33,954 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:07:36,224 - INFO  - Training [46][   20/  196]   Loss 0.134525   Top1 95.625000   Top5 99.824219   BatchTime 0.113427   LR 0.001000   
2022-10-20 17:07:37,784 - INFO  - Training [46][   40/  196]   Loss 0.143499   Top1 95.224609   Top5 99.804688   BatchTime 0.095718   LR 0.001000   
2022-10-20 17:07:39,343 - INFO  - Training [46][   60/  196]   Loss 0.139422   Top1 95.305990   Top5 99.837240   BatchTime 0.089798   LR 0.001000   
2022-10-20 17:07:40,902 - INFO  - Training [46][   80/  196]   Loss 0.140463   Top1 95.317383   Top5 99.819336   BatchTime 0.086831   LR 0.001000   
2022-10-20 17:07:42,461 - INFO  - Training [46][  100/  196]   Loss 0.138140   Top1 95.367188   Top5 99.832031   BatchTime 0.085051   LR 0.001000   
2022-10-20 17:07:44,019 - INFO  - Training [46][  120/  196]   Loss 0.138710   Top1 95.384115   Top5 99.837240   BatchTime 0.083865   LR 0.001000   
2022-10-20 17:07:45,578 - INFO  - Training [46][  140/  196]   Loss 0.138485   Top1 95.407366   Top5 99.838170   BatchTime 0.083018   LR 0.001000   
2022-10-20 17:07:47,137 - INFO  - Training [46][  160/  196]   Loss 0.138147   Top1 95.446777   Top5 99.838867   BatchTime 0.082381   LR 0.001000   
2022-10-20 17:07:48,685 - INFO  - Training [46][  180/  196]   Loss 0.138602   Top1 95.412326   Top5 99.837240   BatchTime 0.081830   LR 0.001000   
2022-10-20 17:07:50,002 - INFO  - ==> Top1: 95.436    Top5: 99.842    Loss: 0.138

2022-10-20 17:07:50,067 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:07:51,271 - INFO  - Validation [46][   20/   40]   Loss 0.480073   Top1 86.132812   Top5 99.101562   BatchTime 0.060131   
2022-10-20 17:07:51,806 - INFO  - Validation [46][   40/   40]   Loss 0.465044   Top1 86.570000   Top5 99.260000   BatchTime 0.043455   
2022-10-20 17:07:51,919 - INFO  - ==> Top1: 86.570    Top5: 99.260    Loss: 0.465

2022-10-20 17:07:51,919 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:07:53,589 - INFO  - Validation [46][   20/   40]   Loss 0.494362   Top1 85.976562   Top5 99.140625   BatchTime 0.083452   
2022-10-20 17:07:54,389 - INFO  - Validation [46][   40/   40]   Loss 0.478978   Top1 86.510000   Top5 99.280000   BatchTime 0.061737   
2022-10-20 17:07:54,491 - INFO  - ==> Top1: 86.510    Top5: 99.280    Loss: 0.479

2022-10-20 17:07:54,492 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:07:54,492 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 86.510   Top5: 99.280]
2022-10-20 17:07:54,492 - INFO  - Scoreboard best 3 ==> Epoch [36][Top1: 86.500   Top5: 99.280]
2022-10-20 17:07:54,557 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:07:54,557 - INFO  - >>>>>> Epoch  47
2022-10-20 17:07:54,557 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:07:56,797 - INFO  - Training [47][   20/  196]   Loss 0.129396   Top1 95.937500   Top5 99.863281   BatchTime 0.111934   LR 0.001000   
2022-10-20 17:07:58,369 - INFO  - Training [47][   40/  196]   Loss 0.130741   Top1 95.683594   Top5 99.902344   BatchTime 0.095276   LR 0.001000   
2022-10-20 17:07:59,934 - INFO  - Training [47][   60/  196]   Loss 0.132527   Top1 95.605469   Top5 99.908854   BatchTime 0.089598   LR 0.001000   
2022-10-20 17:08:01,502 - INFO  - Training [47][   80/  196]   Loss 0.136769   Top1 95.361328   Top5 99.887695   BatchTime 0.086797   LR 0.001000   
2022-10-20 17:08:03,063 - INFO  - Training [47][  100/  196]   Loss 0.137173   Top1 95.332031   Top5 99.878906   BatchTime 0.085046   LR 0.001000   
2022-10-20 17:08:04,628 - INFO  - Training [47][  120/  196]   Loss 0.136236   Top1 95.358073   Top5 99.869792   BatchTime 0.083911   LR 0.001000   
2022-10-20 17:08:06,192 - INFO  - Training [47][  140/  196]   Loss 0.136958   Top1 95.359933   Top5 99.860491   BatchTime 0.083096   LR 0.001000   
2022-10-20 17:08:07,757 - INFO  - Training [47][  160/  196]   Loss 0.137575   Top1 95.346680   Top5 99.851074   BatchTime 0.082489   LR 0.001000   
2022-10-20 17:08:09,311 - INFO  - Training [47][  180/  196]   Loss 0.136384   Top1 95.401476   Top5 99.850260   BatchTime 0.081960   LR 0.001000   
2022-10-20 17:08:10,631 - INFO  - ==> Top1: 95.402    Top5: 99.854    Loss: 0.136

2022-10-20 17:08:10,698 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:08:12,104 - INFO  - Validation [47][   20/   40]   Loss 0.484566   Top1 86.191406   Top5 99.082031   BatchTime 0.070256   
2022-10-20 17:08:12,642 - INFO  - Validation [47][   40/   40]   Loss 0.466163   Top1 86.630000   Top5 99.260000   BatchTime 0.048576   
2022-10-20 17:08:12,745 - INFO  - ==> Top1: 86.630    Top5: 99.260    Loss: 0.466

2022-10-20 17:08:12,745 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:08:14,414 - INFO  - Validation [47][   20/   40]   Loss 0.500151   Top1 86.191406   Top5 99.121094   BatchTime 0.083436   
2022-10-20 17:08:15,220 - INFO  - Validation [47][   40/   40]   Loss 0.480987   Top1 86.710000   Top5 99.210000   BatchTime 0.061862   
2022-10-20 17:08:15,331 - INFO  - ==> Top1: 86.710    Top5: 99.210    Loss: 0.481

2022-10-20 17:08:15,331 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:08:15,331 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:08:15,331 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 86.510   Top5: 99.280]
2022-10-20 17:08:17,200 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 17:08:17,201 - INFO  - >>>>>> Epoch  48
2022-10-20 17:08:17,201 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:08:19,465 - INFO  - Training [48][   20/  196]   Loss 0.133986   Top1 95.351562   Top5 99.902344   BatchTime 0.113025   LR 0.001000   
2022-10-20 17:08:21,029 - INFO  - Training [48][   40/  196]   Loss 0.134388   Top1 95.429688   Top5 99.873047   BatchTime 0.095608   LR 0.001000   
2022-10-20 17:08:22,586 - INFO  - Training [48][   60/  196]   Loss 0.133456   Top1 95.423177   Top5 99.843750   BatchTime 0.089699   LR 0.001000   
2022-10-20 17:08:24,144 - INFO  - Training [48][   80/  196]   Loss 0.133297   Top1 95.439453   Top5 99.829102   BatchTime 0.086745   LR 0.001000   
2022-10-20 17:08:25,706 - INFO  - Training [48][  100/  196]   Loss 0.132752   Top1 95.457031   Top5 99.835938   BatchTime 0.085014   LR 0.001000   
2022-10-20 17:08:27,259 - INFO  - Training [48][  120/  196]   Loss 0.133817   Top1 95.436198   Top5 99.850260   BatchTime 0.083786   LR 0.001000   
2022-10-20 17:08:28,816 - INFO  - Training [48][  140/  196]   Loss 0.133237   Top1 95.482701   Top5 99.857701   BatchTime 0.082938   LR 0.001000   
2022-10-20 17:08:30,373 - INFO  - Training [48][  160/  196]   Loss 0.133932   Top1 95.429688   Top5 99.863281   BatchTime 0.082303   LR 0.001000   
2022-10-20 17:08:31,921 - INFO  - Training [48][  180/  196]   Loss 0.134289   Top1 95.405816   Top5 99.861111   BatchTime 0.081756   LR 0.001000   
2022-10-20 17:08:33,235 - INFO  - ==> Top1: 95.428    Top5: 99.850    Loss: 0.134

2022-10-20 17:08:33,307 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:08:34,520 - INFO  - Validation [48][   20/   40]   Loss 0.490664   Top1 86.093750   Top5 99.023438   BatchTime 0.060597   
2022-10-20 17:08:35,057 - INFO  - Validation [48][   40/   40]   Loss 0.470537   Top1 86.360000   Top5 99.230000   BatchTime 0.043722   
2022-10-20 17:08:35,159 - INFO  - ==> Top1: 86.360    Top5: 99.230    Loss: 0.471

2022-10-20 17:08:35,159 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:08:36,813 - INFO  - Validation [48][   20/   40]   Loss 0.508729   Top1 86.035156   Top5 99.023438   BatchTime 0.082668   
2022-10-20 17:08:37,633 - INFO  - Validation [48][   40/   40]   Loss 0.486291   Top1 86.310000   Top5 99.220000   BatchTime 0.061839   
2022-10-20 17:08:37,747 - INFO  - ==> Top1: 86.310    Top5: 99.220    Loss: 0.486

2022-10-20 17:08:37,747 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:08:37,747 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:08:37,747 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 86.510   Top5: 99.280]
2022-10-20 17:08:37,803 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:08:37,803 - INFO  - >>>>>> Epoch  49
2022-10-20 17:08:37,803 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:08:40,065 - INFO  - Training [49][   20/  196]   Loss 0.140877   Top1 95.332031   Top5 99.765625   BatchTime 0.113060   LR 0.001000   
2022-10-20 17:08:41,629 - INFO  - Training [49][   40/  196]   Loss 0.131960   Top1 95.488281   Top5 99.804688   BatchTime 0.095632   LR 0.001000   
2022-10-20 17:08:43,188 - INFO  - Training [49][   60/  196]   Loss 0.134836   Top1 95.319010   Top5 99.811198   BatchTime 0.089739   LR 0.001000   
2022-10-20 17:08:44,746 - INFO  - Training [49][   80/  196]   Loss 0.133088   Top1 95.410156   Top5 99.824219   BatchTime 0.086781   LR 0.001000   
2022-10-20 17:08:46,304 - INFO  - Training [49][  100/  196]   Loss 0.132933   Top1 95.441406   Top5 99.824219   BatchTime 0.085002   LR 0.001000   
2022-10-20 17:08:47,866 - INFO  - Training [49][  120/  196]   Loss 0.133022   Top1 95.472005   Top5 99.817708   BatchTime 0.083849   LR 0.001000   
2022-10-20 17:08:49,426 - INFO  - Training [49][  140/  196]   Loss 0.131963   Top1 95.558036   Top5 99.829799   BatchTime 0.083014   LR 0.001000   
2022-10-20 17:08:50,986 - INFO  - Training [49][  160/  196]   Loss 0.133565   Top1 95.510254   Top5 99.824219   BatchTime 0.082387   LR 0.001000   
2022-10-20 17:08:52,537 - INFO  - Training [49][  180/  196]   Loss 0.133480   Top1 95.529514   Top5 99.813368   BatchTime 0.081847   LR 0.001000   
2022-10-20 17:08:53,859 - INFO  - ==> Top1: 95.548    Top5: 99.818    Loss: 0.133

2022-10-20 17:08:53,927 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:08:55,140 - INFO  - Validation [49][   20/   40]   Loss 0.490954   Top1 86.191406   Top5 99.082031   BatchTime 0.060637   
2022-10-20 17:08:55,675 - INFO  - Validation [49][   40/   40]   Loss 0.472976   Top1 86.280000   Top5 99.260000   BatchTime 0.043698   
2022-10-20 17:08:55,778 - INFO  - ==> Top1: 86.280    Top5: 99.260    Loss: 0.473

2022-10-20 17:08:55,778 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:08:57,460 - INFO  - Validation [49][   20/   40]   Loss 0.505498   Top1 85.976562   Top5 99.140625   BatchTime 0.084070   
2022-10-20 17:08:58,266 - INFO  - Validation [49][   40/   40]   Loss 0.487404   Top1 86.270000   Top5 99.300000   BatchTime 0.062175   
2022-10-20 17:08:58,376 - INFO  - ==> Top1: 86.270    Top5: 99.300    Loss: 0.487

2022-10-20 17:08:58,376 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:08:58,376 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:08:58,376 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 86.510   Top5: 99.280]
2022-10-20 17:08:58,455 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:08:58,455 - INFO  - >>>>>> Epoch  50
2022-10-20 17:08:58,455 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:09:00,742 - INFO  - Training [50][   20/  196]   Loss 0.122218   Top1 96.132812   Top5 99.785156   BatchTime 0.114299   LR 0.001000   
2022-10-20 17:09:02,302 - INFO  - Training [50][   40/  196]   Loss 0.130427   Top1 95.595703   Top5 99.833984   BatchTime 0.096142   LR 0.001000   
2022-10-20 17:09:03,862 - INFO  - Training [50][   60/  196]   Loss 0.132864   Top1 95.520833   Top5 99.863281   BatchTime 0.090094   LR 0.001000   
2022-10-20 17:09:05,422 - INFO  - Training [50][   80/  196]   Loss 0.134272   Top1 95.434570   Top5 99.873047   BatchTime 0.087071   LR 0.001000   
2022-10-20 17:09:06,982 - INFO  - Training [50][  100/  196]   Loss 0.132968   Top1 95.445312   Top5 99.875000   BatchTime 0.085257   LR 0.001000   
2022-10-20 17:09:08,543 - INFO  - Training [50][  120/  196]   Loss 0.132049   Top1 95.530599   Top5 99.876302   BatchTime 0.084051   LR 0.001000   
2022-10-20 17:09:10,103 - INFO  - Training [50][  140/  196]   Loss 0.132249   Top1 95.541295   Top5 99.877232   BatchTime 0.083185   LR 0.001000   
2022-10-20 17:09:11,663 - INFO  - Training [50][  160/  196]   Loss 0.131998   Top1 95.563965   Top5 99.873047   BatchTime 0.082537   LR 0.001000   
2022-10-20 17:09:13,215 - INFO  - Training [50][  180/  196]   Loss 0.133166   Top1 95.503472   Top5 99.874132   BatchTime 0.081988   LR 0.001000   
2022-10-20 17:09:14,531 - INFO  - ==> Top1: 95.512    Top5: 99.870    Loss: 0.133

2022-10-20 17:09:14,604 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:09:15,829 - INFO  - Validation [50][   20/   40]   Loss 0.486478   Top1 86.347656   Top5 99.023438   BatchTime 0.061231   
2022-10-20 17:09:16,369 - INFO  - Validation [50][   40/   40]   Loss 0.471596   Top1 86.450000   Top5 99.290000   BatchTime 0.044126   
2022-10-20 17:09:16,479 - INFO  - ==> Top1: 86.450    Top5: 99.290    Loss: 0.472

2022-10-20 17:09:16,480 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:09:18,190 - INFO  - Validation [50][   20/   40]   Loss 0.501618   Top1 86.074219   Top5 99.101562   BatchTime 0.085492   
2022-10-20 17:09:18,993 - INFO  - Validation [50][   40/   40]   Loss 0.488493   Top1 86.420000   Top5 99.250000   BatchTime 0.062828   
2022-10-20 17:09:19,103 - INFO  - ==> Top1: 86.420    Top5: 99.250    Loss: 0.488

2022-10-20 17:09:19,103 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:09:19,103 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:09:19,103 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 86.510   Top5: 99.280]
2022-10-20 17:09:19,157 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:09:19,157 - INFO  - >>>>>> Epoch  51
2022-10-20 17:09:19,157 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:09:21,457 - INFO  - Training [51][   20/  196]   Loss 0.120934   Top1 96.093750   Top5 99.941406   BatchTime 0.114920   LR 0.001000   
2022-10-20 17:09:23,025 - INFO  - Training [51][   40/  196]   Loss 0.125028   Top1 95.751953   Top5 99.921875   BatchTime 0.096683   LR 0.001000   
2022-10-20 17:09:24,589 - INFO  - Training [51][   60/  196]   Loss 0.128290   Top1 95.651042   Top5 99.895833   BatchTime 0.090508   LR 0.001000   
2022-10-20 17:09:26,153 - INFO  - Training [51][   80/  196]   Loss 0.127747   Top1 95.673828   Top5 99.887695   BatchTime 0.087428   LR 0.001000   
2022-10-20 17:09:27,716 - INFO  - Training [51][  100/  196]   Loss 0.129384   Top1 95.613281   Top5 99.890625   BatchTime 0.085574   LR 0.001000   
2022-10-20 17:09:29,280 - INFO  - Training [51][  120/  196]   Loss 0.130480   Top1 95.579427   Top5 99.879557   BatchTime 0.084345   LR 0.001000   
2022-10-20 17:09:30,843 - INFO  - Training [51][  140/  196]   Loss 0.129633   Top1 95.611049   Top5 99.877232   BatchTime 0.083462   LR 0.001000   
2022-10-20 17:09:32,406 - INFO  - Training [51][  160/  196]   Loss 0.129399   Top1 95.598145   Top5 99.875488   BatchTime 0.082797   LR 0.001000   
2022-10-20 17:09:33,961 - INFO  - Training [51][  180/  196]   Loss 0.129726   Top1 95.575087   Top5 99.874132   BatchTime 0.082237   LR 0.001000   
2022-10-20 17:09:35,286 - INFO  - ==> Top1: 95.598    Top5: 99.868    Loss: 0.129

2022-10-20 17:09:35,352 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:09:36,559 - INFO  - Validation [51][   20/   40]   Loss 0.487854   Top1 86.582031   Top5 99.062500   BatchTime 0.060323   
2022-10-20 17:09:37,094 - INFO  - Validation [51][   40/   40]   Loss 0.473215   Top1 86.730000   Top5 99.280000   BatchTime 0.043533   
2022-10-20 17:09:37,203 - INFO  - ==> Top1: 86.730    Top5: 99.280    Loss: 0.473

2022-10-20 17:09:37,203 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:09:38,918 - INFO  - Validation [51][   20/   40]   Loss 0.502730   Top1 86.289062   Top5 99.101562   BatchTime 0.085738   
2022-10-20 17:09:39,724 - INFO  - Validation [51][   40/   40]   Loss 0.487348   Top1 86.500000   Top5 99.260000   BatchTime 0.063026   
2022-10-20 17:09:39,835 - INFO  - ==> Top1: 86.500    Top5: 99.260    Loss: 0.487

2022-10-20 17:09:39,835 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:09:39,835 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:09:39,835 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 86.510   Top5: 99.280]
2022-10-20 17:09:39,884 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:09:39,884 - INFO  - >>>>>> Epoch  52
2022-10-20 17:09:39,885 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:09:42,135 - INFO  - Training [52][   20/  196]   Loss 0.133860   Top1 95.488281   Top5 99.843750   BatchTime 0.112479   LR 0.001000   
2022-10-20 17:09:43,692 - INFO  - Training [52][   40/  196]   Loss 0.132490   Top1 95.537109   Top5 99.804688   BatchTime 0.095176   LR 0.001000   
2022-10-20 17:09:45,250 - INFO  - Training [52][   60/  196]   Loss 0.131971   Top1 95.488281   Top5 99.837240   BatchTime 0.089403   LR 0.001000   
2022-10-20 17:09:46,810 - INFO  - Training [52][   80/  196]   Loss 0.129979   Top1 95.576172   Top5 99.838867   BatchTime 0.086558   LR 0.001000   
2022-10-20 17:09:48,368 - INFO  - Training [52][  100/  196]   Loss 0.132451   Top1 95.394531   Top5 99.855469   BatchTime 0.084823   LR 0.001000   
2022-10-20 17:09:49,924 - INFO  - Training [52][  120/  196]   Loss 0.132083   Top1 95.387370   Top5 99.863281   BatchTime 0.083649   LR 0.001000   
2022-10-20 17:09:51,478 - INFO  - Training [52][  140/  196]   Loss 0.132844   Top1 95.398996   Top5 99.860491   BatchTime 0.082805   LR 0.001000   
2022-10-20 17:09:53,036 - INFO  - Training [52][  160/  196]   Loss 0.132534   Top1 95.480957   Top5 99.858398   BatchTime 0.082187   LR 0.001000   
2022-10-20 17:09:54,583 - INFO  - Training [52][  180/  196]   Loss 0.132279   Top1 95.527344   Top5 99.858941   BatchTime 0.081653   LR 0.001000   
2022-10-20 17:09:55,899 - INFO  - ==> Top1: 95.522    Top5: 99.856    Loss: 0.132

2022-10-20 17:09:55,972 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:09:57,181 - INFO  - Validation [52][   20/   40]   Loss 0.500259   Top1 86.093750   Top5 99.062500   BatchTime 0.060416   
2022-10-20 17:09:57,714 - INFO  - Validation [52][   40/   40]   Loss 0.479458   Top1 86.330000   Top5 99.210000   BatchTime 0.043540   
2022-10-20 17:09:57,815 - INFO  - ==> Top1: 86.330    Top5: 99.210    Loss: 0.479

2022-10-20 17:09:57,815 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:09:59,495 - INFO  - Validation [52][   20/   40]   Loss 0.514110   Top1 85.820312   Top5 99.023438   BatchTime 0.083991   
2022-10-20 17:10:00,301 - INFO  - Validation [52][   40/   40]   Loss 0.494296   Top1 86.310000   Top5 99.230000   BatchTime 0.062131   
2022-10-20 17:10:00,413 - INFO  - ==> Top1: 86.310    Top5: 99.230    Loss: 0.494

2022-10-20 17:10:00,413 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:10:00,413 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:10:00,413 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 86.510   Top5: 99.280]
2022-10-20 17:10:00,439 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:10:00,439 - INFO  - >>>>>> Epoch  53
2022-10-20 17:10:00,439 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:10:02,732 - INFO  - Training [53][   20/  196]   Loss 0.138530   Top1 95.039062   Top5 99.843750   BatchTime 0.114592   LR 0.001000   
2022-10-20 17:10:04,300 - INFO  - Training [53][   40/  196]   Loss 0.127600   Top1 95.585938   Top5 99.843750   BatchTime 0.096483   LR 0.001000   
2022-10-20 17:10:05,860 - INFO  - Training [53][   60/  196]   Loss 0.129008   Top1 95.429688   Top5 99.850260   BatchTime 0.090322   LR 0.001000   
2022-10-20 17:10:07,424 - INFO  - Training [53][   80/  196]   Loss 0.127936   Top1 95.532227   Top5 99.838867   BatchTime 0.087291   LR 0.001000   
2022-10-20 17:10:08,987 - INFO  - Training [53][  100/  196]   Loss 0.131671   Top1 95.464844   Top5 99.839844   BatchTime 0.085469   LR 0.001000   
2022-10-20 17:10:10,551 - INFO  - Training [53][  120/  196]   Loss 0.132296   Top1 95.455729   Top5 99.853516   BatchTime 0.084257   LR 0.001000   
2022-10-20 17:10:12,115 - INFO  - Training [53][  140/  196]   Loss 0.131744   Top1 95.488281   Top5 99.849330   BatchTime 0.083392   LR 0.001000   
2022-10-20 17:10:13,679 - INFO  - Training [53][  160/  196]   Loss 0.131713   Top1 95.510254   Top5 99.836426   BatchTime 0.082740   LR 0.001000   
2022-10-20 17:10:15,235 - INFO  - Training [53][  180/  196]   Loss 0.131517   Top1 95.549045   Top5 99.843750   BatchTime 0.082188   LR 0.001000   
2022-10-20 17:10:16,571 - INFO  - ==> Top1: 95.550    Top5: 99.846    Loss: 0.132

2022-10-20 17:10:16,640 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:10:17,853 - INFO  - Validation [53][   20/   40]   Loss 0.489916   Top1 86.328125   Top5 99.062500   BatchTime 0.060615   
2022-10-20 17:10:18,386 - INFO  - Validation [53][   40/   40]   Loss 0.476928   Top1 86.410000   Top5 99.270000   BatchTime 0.043626   
2022-10-20 17:10:18,483 - INFO  - ==> Top1: 86.410    Top5: 99.270    Loss: 0.477

2022-10-20 17:10:18,483 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:10:20,182 - INFO  - Validation [53][   20/   40]   Loss 0.505008   Top1 86.289062   Top5 99.101562   BatchTime 0.084940   
2022-10-20 17:10:20,985 - INFO  - Validation [53][   40/   40]   Loss 0.491968   Top1 86.410000   Top5 99.260000   BatchTime 0.062531   
2022-10-20 17:10:21,091 - INFO  - ==> Top1: 86.410    Top5: 99.260    Loss: 0.492

2022-10-20 17:10:21,091 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:10:21,091 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:10:21,091 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 86.510   Top5: 99.280]
2022-10-20 17:10:21,141 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:10:21,142 - INFO  - >>>>>> Epoch  54
2022-10-20 17:10:21,142 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:10:23,452 - INFO  - Training [54][   20/  196]   Loss 0.123522   Top1 95.703125   Top5 99.843750   BatchTime 0.115463   LR 0.001000   
2022-10-20 17:10:25,015 - INFO  - Training [54][   40/  196]   Loss 0.127701   Top1 95.595703   Top5 99.814453   BatchTime 0.096814   LR 0.001000   
2022-10-20 17:10:26,580 - INFO  - Training [54][   60/  196]   Loss 0.124978   Top1 95.690104   Top5 99.824219   BatchTime 0.090619   LR 0.001000   
2022-10-20 17:10:28,138 - INFO  - Training [54][   80/  196]   Loss 0.125409   Top1 95.786133   Top5 99.814453   BatchTime 0.087441   LR 0.001000   
2022-10-20 17:10:29,698 - INFO  - Training [54][  100/  196]   Loss 0.125788   Top1 95.785156   Top5 99.824219   BatchTime 0.085557   LR 0.001000   
2022-10-20 17:10:31,258 - INFO  - Training [54][  120/  196]   Loss 0.128075   Top1 95.735677   Top5 99.814453   BatchTime 0.084297   LR 0.001000   
2022-10-20 17:10:32,818 - INFO  - Training [54][  140/  196]   Loss 0.127925   Top1 95.733817   Top5 99.815848   BatchTime 0.083397   LR 0.001000   
2022-10-20 17:10:34,379 - INFO  - Training [54][  160/  196]   Loss 0.128975   Top1 95.683594   Top5 99.819336   BatchTime 0.082724   LR 0.001000   
2022-10-20 17:10:35,930 - INFO  - Training [54][  180/  196]   Loss 0.128655   Top1 95.720486   Top5 99.828559   BatchTime 0.082148   LR 0.001000   
2022-10-20 17:10:37,250 - INFO  - ==> Top1: 95.684    Top5: 99.836    Loss: 0.129

2022-10-20 17:10:37,317 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:10:38,524 - INFO  - Validation [54][   20/   40]   Loss 0.494520   Top1 86.640625   Top5 99.121094   BatchTime 0.060324   
2022-10-20 17:10:39,062 - INFO  - Validation [54][   40/   40]   Loss 0.478187   Top1 86.730000   Top5 99.230000   BatchTime 0.043612   
2022-10-20 17:10:39,157 - INFO  - ==> Top1: 86.730    Top5: 99.230    Loss: 0.478

2022-10-20 17:10:39,157 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:10:40,828 - INFO  - Validation [54][   20/   40]   Loss 0.508999   Top1 86.093750   Top5 99.101562   BatchTime 0.083538   
2022-10-20 17:10:41,638 - INFO  - Validation [54][   40/   40]   Loss 0.491190   Top1 86.530000   Top5 99.260000   BatchTime 0.062012   
2022-10-20 17:10:41,751 - INFO  - ==> Top1: 86.530    Top5: 99.260    Loss: 0.491

2022-10-20 17:10:41,751 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:10:41,752 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:10:41,752 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 86.530   Top5: 99.260]
2022-10-20 17:10:41,806 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:10:41,806 - INFO  - >>>>>> Epoch  55
2022-10-20 17:10:41,806 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:10:44,092 - INFO  - Training [55][   20/  196]   Loss 0.132677   Top1 95.488281   Top5 99.882812   BatchTime 0.114230   LR 0.001000   
2022-10-20 17:10:45,656 - INFO  - Training [55][   40/  196]   Loss 0.131522   Top1 95.488281   Top5 99.902344   BatchTime 0.096209   LR 0.001000   
2022-10-20 17:10:47,219 - INFO  - Training [55][   60/  196]   Loss 0.130650   Top1 95.364583   Top5 99.915365   BatchTime 0.090195   LR 0.001000   
2022-10-20 17:10:48,782 - INFO  - Training [55][   80/  196]   Loss 0.129307   Top1 95.502930   Top5 99.907227   BatchTime 0.087183   LR 0.001000   
2022-10-20 17:10:50,345 - INFO  - Training [55][  100/  196]   Loss 0.130475   Top1 95.488281   Top5 99.867188   BatchTime 0.085373   LR 0.001000   
2022-10-20 17:10:51,907 - INFO  - Training [55][  120/  196]   Loss 0.130387   Top1 95.517578   Top5 99.869792   BatchTime 0.084167   LR 0.001000   
2022-10-20 17:10:53,470 - INFO  - Training [55][  140/  196]   Loss 0.130723   Top1 95.479911   Top5 99.863281   BatchTime 0.083306   LR 0.001000   
2022-10-20 17:10:55,033 - INFO  - Training [55][  160/  196]   Loss 0.130638   Top1 95.505371   Top5 99.858398   BatchTime 0.082661   LR 0.001000   
2022-10-20 17:10:56,587 - INFO  - Training [55][  180/  196]   Loss 0.128643   Top1 95.575087   Top5 99.863281   BatchTime 0.082109   LR 0.001000   
2022-10-20 17:10:57,905 - INFO  - ==> Top1: 95.574    Top5: 99.866    Loss: 0.129

2022-10-20 17:10:57,976 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:10:59,188 - INFO  - Validation [55][   20/   40]   Loss 0.485541   Top1 86.542969   Top5 99.082031   BatchTime 0.060560   
2022-10-20 17:10:59,724 - INFO  - Validation [55][   40/   40]   Loss 0.477588   Top1 86.750000   Top5 99.200000   BatchTime 0.043677   
2022-10-20 17:10:59,821 - INFO  - ==> Top1: 86.750    Top5: 99.200    Loss: 0.478

2022-10-20 17:10:59,821 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:11:01,501 - INFO  - Validation [55][   20/   40]   Loss 0.506576   Top1 86.445312   Top5 99.140625   BatchTime 0.083970   
2022-10-20 17:11:02,305 - INFO  - Validation [55][   40/   40]   Loss 0.494875   Top1 86.660000   Top5 99.200000   BatchTime 0.062070   
2022-10-20 17:11:02,414 - INFO  - ==> Top1: 86.660    Top5: 99.200    Loss: 0.495

2022-10-20 17:11:02,415 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:11:02,415 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:11:02,415 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:11:02,485 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:11:02,486 - INFO  - >>>>>> Epoch  56
2022-10-20 17:11:02,486 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:11:04,801 - INFO  - Training [56][   20/  196]   Loss 0.120871   Top1 95.742188   Top5 99.882812   BatchTime 0.115590   LR 0.001000   
2022-10-20 17:11:06,361 - INFO  - Training [56][   40/  196]   Loss 0.124689   Top1 95.673828   Top5 99.863281   BatchTime 0.096800   LR 0.001000   
2022-10-20 17:11:07,922 - INFO  - Training [56][   60/  196]   Loss 0.124717   Top1 95.690104   Top5 99.863281   BatchTime 0.090538   LR 0.001000   
2022-10-20 17:11:09,482 - INFO  - Training [56][   80/  196]   Loss 0.125772   Top1 95.610352   Top5 99.848633   BatchTime 0.087412   LR 0.001000   
2022-10-20 17:11:11,042 - INFO  - Training [56][  100/  196]   Loss 0.127549   Top1 95.625000   Top5 99.851562   BatchTime 0.085528   LR 0.001000   
2022-10-20 17:11:12,602 - INFO  - Training [56][  120/  196]   Loss 0.126543   Top1 95.664062   Top5 99.853516   BatchTime 0.084273   LR 0.001000   
2022-10-20 17:11:14,162 - INFO  - Training [56][  140/  196]   Loss 0.126219   Top1 95.719866   Top5 99.849330   BatchTime 0.083377   LR 0.001000   
2022-10-20 17:11:15,724 - INFO  - Training [56][  160/  196]   Loss 0.126530   Top1 95.671387   Top5 99.851074   BatchTime 0.082714   LR 0.001000   
2022-10-20 17:11:17,286 - INFO  - Training [56][  180/  196]   Loss 0.126806   Top1 95.659722   Top5 99.856771   BatchTime 0.082203   LR 0.001000   
2022-10-20 17:11:18,616 - INFO  - ==> Top1: 95.632    Top5: 99.858    Loss: 0.127

2022-10-20 17:11:18,689 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:11:19,890 - INFO  - Validation [56][   20/   40]   Loss 0.499333   Top1 86.464844   Top5 99.042969   BatchTime 0.060054   
2022-10-20 17:11:20,429 - INFO  - Validation [56][   40/   40]   Loss 0.481384   Top1 86.560000   Top5 99.260000   BatchTime 0.043491   
2022-10-20 17:11:20,539 - INFO  - ==> Top1: 86.560    Top5: 99.260    Loss: 0.481

2022-10-20 17:11:20,539 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:11:22,214 - INFO  - Validation [56][   20/   40]   Loss 0.510534   Top1 86.328125   Top5 99.023438   BatchTime 0.083720   
2022-10-20 17:11:23,020 - INFO  - Validation [56][   40/   40]   Loss 0.494132   Top1 86.490000   Top5 99.230000   BatchTime 0.062013   
2022-10-20 17:11:23,130 - INFO  - ==> Top1: 86.490    Top5: 99.230    Loss: 0.494

2022-10-20 17:11:23,130 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:11:23,130 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:11:23,130 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:11:23,179 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:11:23,180 - INFO  - >>>>>> Epoch  57
2022-10-20 17:11:23,180 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:11:25,669 - INFO  - Training [57][   20/  196]   Loss 0.118535   Top1 96.191406   Top5 99.863281   BatchTime 0.124293   LR 0.001000   
2022-10-20 17:11:27,228 - INFO  - Training [57][   40/  196]   Loss 0.118500   Top1 96.113281   Top5 99.863281   BatchTime 0.101119   LR 0.001000   
2022-10-20 17:11:28,786 - INFO  - Training [57][   60/  196]   Loss 0.120026   Top1 96.100260   Top5 99.850260   BatchTime 0.093391   LR 0.001000   
2022-10-20 17:11:30,345 - INFO  - Training [57][   80/  196]   Loss 0.122057   Top1 96.040039   Top5 99.843750   BatchTime 0.089521   LR 0.001000   
2022-10-20 17:11:31,903 - INFO  - Training [57][  100/  196]   Loss 0.122921   Top1 96.050781   Top5 99.847656   BatchTime 0.087199   LR 0.001000   
2022-10-20 17:11:33,465 - INFO  - Training [57][  120/  196]   Loss 0.123429   Top1 96.028646   Top5 99.853516   BatchTime 0.085683   LR 0.001000   
2022-10-20 17:11:35,025 - INFO  - Training [57][  140/  196]   Loss 0.123971   Top1 95.951451   Top5 99.857701   BatchTime 0.084585   LR 0.001000   
2022-10-20 17:11:36,579 - INFO  - Training [57][  160/  196]   Loss 0.124242   Top1 95.905762   Top5 99.848633   BatchTime 0.083721   LR 0.001000   
2022-10-20 17:11:38,134 - INFO  - Training [57][  180/  196]   Loss 0.124987   Top1 95.874566   Top5 99.839410   BatchTime 0.083058   LR 0.001000   
2022-10-20 17:11:39,461 - INFO  - ==> Top1: 95.822    Top5: 99.842    Loss: 0.126

2022-10-20 17:11:39,525 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:11:40,752 - INFO  - Validation [57][   20/   40]   Loss 0.495418   Top1 86.269531   Top5 99.082031   BatchTime 0.061316   
2022-10-20 17:11:41,288 - INFO  - Validation [57][   40/   40]   Loss 0.482663   Top1 86.480000   Top5 99.200000   BatchTime 0.044060   
2022-10-20 17:11:41,388 - INFO  - ==> Top1: 86.480    Top5: 99.200    Loss: 0.483

2022-10-20 17:11:41,388 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:11:43,138 - INFO  - Validation [57][   20/   40]   Loss 0.510580   Top1 86.367188   Top5 99.023438   BatchTime 0.087475   
2022-10-20 17:11:43,944 - INFO  - Validation [57][   40/   40]   Loss 0.495378   Top1 86.490000   Top5 99.160000   BatchTime 0.063892   
2022-10-20 17:11:44,066 - INFO  - ==> Top1: 86.490    Top5: 99.160    Loss: 0.495

2022-10-20 17:11:44,066 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:11:44,066 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:11:44,066 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:11:44,114 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:11:44,115 - INFO  - >>>>>> Epoch  58
2022-10-20 17:11:44,115 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:11:46,382 - INFO  - Training [58][   20/  196]   Loss 0.120381   Top1 95.839844   Top5 99.863281   BatchTime 0.113322   LR 0.001000   
2022-10-20 17:11:47,947 - INFO  - Training [58][   40/  196]   Loss 0.124565   Top1 95.673828   Top5 99.863281   BatchTime 0.095788   LR 0.001000   
2022-10-20 17:11:49,512 - INFO  - Training [58][   60/  196]   Loss 0.123773   Top1 95.677083   Top5 99.876302   BatchTime 0.089936   LR 0.001000   
2022-10-20 17:11:51,076 - INFO  - Training [58][   80/  196]   Loss 0.125711   Top1 95.581055   Top5 99.887695   BatchTime 0.087010   LR 0.001000   
2022-10-20 17:11:52,641 - INFO  - Training [58][  100/  196]   Loss 0.125841   Top1 95.597656   Top5 99.890625   BatchTime 0.085251   LR 0.001000   
2022-10-20 17:11:54,205 - INFO  - Training [58][  120/  196]   Loss 0.125670   Top1 95.628255   Top5 99.873047   BatchTime 0.084082   LR 0.001000   
2022-10-20 17:11:55,770 - INFO  - Training [58][  140/  196]   Loss 0.125896   Top1 95.669643   Top5 99.868862   BatchTime 0.083246   LR 0.001000   
2022-10-20 17:11:57,335 - INFO  - Training [58][  160/  196]   Loss 0.125459   Top1 95.676270   Top5 99.865723   BatchTime 0.082619   LR 0.001000   
2022-10-20 17:11:58,889 - INFO  - Training [58][  180/  196]   Loss 0.124496   Top1 95.757378   Top5 99.861111   BatchTime 0.082076   LR 0.001000   
2022-10-20 17:12:00,210 - INFO  - ==> Top1: 95.688    Top5: 99.868    Loss: 0.126

2022-10-20 17:12:00,277 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:12:01,508 - INFO  - Validation [58][   20/   40]   Loss 0.492473   Top1 86.621094   Top5 99.023438   BatchTime 0.061514   
2022-10-20 17:12:02,049 - INFO  - Validation [58][   40/   40]   Loss 0.479020   Top1 86.650000   Top5 99.290000   BatchTime 0.044295   
2022-10-20 17:12:02,143 - INFO  - ==> Top1: 86.650    Top5: 99.290    Loss: 0.479

2022-10-20 17:12:02,143 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:12:03,928 - INFO  - Validation [58][   20/   40]   Loss 0.510262   Top1 86.308594   Top5 99.023438   BatchTime 0.089252   
2022-10-20 17:12:04,732 - INFO  - Validation [58][   40/   40]   Loss 0.496937   Top1 86.590000   Top5 99.200000   BatchTime 0.064722   
2022-10-20 17:12:04,842 - INFO  - ==> Top1: 86.590    Top5: 99.200    Loss: 0.497

2022-10-20 17:12:04,842 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:12:04,842 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:12:04,842 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:12:04,918 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:12:04,918 - INFO  - >>>>>> Epoch  59
2022-10-20 17:12:04,919 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:12:07,205 - INFO  - Training [59][   20/  196]   Loss 0.115545   Top1 96.269531   Top5 99.863281   BatchTime 0.114297   LR 0.001000   
2022-10-20 17:12:08,770 - INFO  - Training [59][   40/  196]   Loss 0.115074   Top1 96.220703   Top5 99.873047   BatchTime 0.096254   LR 0.001000   
2022-10-20 17:12:10,331 - INFO  - Training [59][   60/  196]   Loss 0.116647   Top1 96.158854   Top5 99.863281   BatchTime 0.090192   LR 0.001000   
2022-10-20 17:12:11,897 - INFO  - Training [59][   80/  196]   Loss 0.119690   Top1 96.005859   Top5 99.863281   BatchTime 0.087213   LR 0.001000   
2022-10-20 17:12:13,453 - INFO  - Training [59][  100/  196]   Loss 0.120521   Top1 95.949219   Top5 99.847656   BatchTime 0.085336   LR 0.001000   
2022-10-20 17:12:15,014 - INFO  - Training [59][  120/  196]   Loss 0.120704   Top1 95.917969   Top5 99.853516   BatchTime 0.084123   LR 0.001000   
2022-10-20 17:12:16,580 - INFO  - Training [59][  140/  196]   Loss 0.121973   Top1 95.834263   Top5 99.857701   BatchTime 0.083291   LR 0.001000   
2022-10-20 17:12:18,143 - INFO  - Training [59][  160/  196]   Loss 0.121529   Top1 95.852051   Top5 99.855957   BatchTime 0.082643   LR 0.001000   
2022-10-20 17:12:19,695 - INFO  - Training [59][  180/  196]   Loss 0.122249   Top1 95.831163   Top5 99.852431   BatchTime 0.082083   LR 0.001000   
2022-10-20 17:12:21,003 - INFO  - ==> Top1: 95.764    Top5: 99.852    Loss: 0.124

2022-10-20 17:12:21,076 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:12:22,298 - INFO  - Validation [59][   20/   40]   Loss 0.503060   Top1 86.250000   Top5 99.140625   BatchTime 0.061088   
2022-10-20 17:12:22,834 - INFO  - Validation [59][   40/   40]   Loss 0.487760   Top1 86.410000   Top5 99.290000   BatchTime 0.043924   
2022-10-20 17:12:22,934 - INFO  - ==> Top1: 86.410    Top5: 99.290    Loss: 0.488

2022-10-20 17:12:22,934 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:12:24,617 - INFO  - Validation [59][   20/   40]   Loss 0.517040   Top1 85.761719   Top5 99.062500   BatchTime 0.084132   
2022-10-20 17:12:25,421 - INFO  - Validation [59][   40/   40]   Loss 0.505073   Top1 86.110000   Top5 99.250000   BatchTime 0.062158   
2022-10-20 17:12:25,533 - INFO  - ==> Top1: 86.110    Top5: 99.250    Loss: 0.505

2022-10-20 17:12:25,533 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:12:25,533 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:12:25,533 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:12:25,559 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:12:25,559 - INFO  - >>>>>> Epoch  60
2022-10-20 17:12:25,559 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:12:27,802 - INFO  - Training [60][   20/  196]   Loss 0.120440   Top1 96.074219   Top5 99.902344   BatchTime 0.112074   LR 0.000100   
2022-10-20 17:12:29,365 - INFO  - Training [60][   40/  196]   Loss 0.122022   Top1 95.937500   Top5 99.853516   BatchTime 0.095133   LR 0.000100   
2022-10-20 17:12:30,929 - INFO  - Training [60][   60/  196]   Loss 0.122819   Top1 95.937500   Top5 99.876302   BatchTime 0.089485   LR 0.000100   
2022-10-20 17:12:32,493 - INFO  - Training [60][   80/  196]   Loss 0.123138   Top1 95.937500   Top5 99.868164   BatchTime 0.086657   LR 0.000100   
2022-10-20 17:12:34,058 - INFO  - Training [60][  100/  196]   Loss 0.122614   Top1 95.984375   Top5 99.863281   BatchTime 0.084982   LR 0.000100   
2022-10-20 17:12:35,619 - INFO  - Training [60][  120/  196]   Loss 0.123468   Top1 95.960286   Top5 99.853516   BatchTime 0.083824   LR 0.000100   
2022-10-20 17:12:37,182 - INFO  - Training [60][  140/  196]   Loss 0.124637   Top1 95.867746   Top5 99.860491   BatchTime 0.083015   LR 0.000100   
2022-10-20 17:12:38,748 - INFO  - Training [60][  160/  196]   Loss 0.123590   Top1 95.905762   Top5 99.868164   BatchTime 0.082424   LR 0.000100   
2022-10-20 17:12:40,302 - INFO  - Training [60][  180/  196]   Loss 0.123536   Top1 95.894097   Top5 99.869792   BatchTime 0.081897   LR 0.000100   
2022-10-20 17:12:41,621 - INFO  - ==> Top1: 95.892    Top5: 99.866    Loss: 0.123

2022-10-20 17:12:41,694 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:12:42,896 - INFO  - Validation [60][   20/   40]   Loss 0.501178   Top1 86.074219   Top5 99.101562   BatchTime 0.060082   
2022-10-20 17:12:43,434 - INFO  - Validation [60][   40/   40]   Loss 0.488086   Top1 86.410000   Top5 99.250000   BatchTime 0.043498   
2022-10-20 17:12:43,520 - INFO  - ==> Top1: 86.410    Top5: 99.250    Loss: 0.488

2022-10-20 17:12:43,520 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:12:45,200 - INFO  - Validation [60][   20/   40]   Loss 0.513260   Top1 86.054688   Top5 99.062500   BatchTime 0.083954   
2022-10-20 17:12:46,005 - INFO  - Validation [60][   40/   40]   Loss 0.501092   Top1 86.400000   Top5 99.200000   BatchTime 0.062120   
2022-10-20 17:12:46,115 - INFO  - ==> Top1: 86.400    Top5: 99.200    Loss: 0.501

2022-10-20 17:12:46,115 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:12:46,115 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:12:46,115 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:12:46,179 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:12:46,179 - INFO  - >>>>>> Epoch  61
2022-10-20 17:12:46,179 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:12:48,485 - INFO  - Training [61][   20/  196]   Loss 0.117135   Top1 95.898438   Top5 99.882812   BatchTime 0.115226   LR 0.000100   
2022-10-20 17:12:50,048 - INFO  - Training [61][   40/  196]   Loss 0.117611   Top1 95.976562   Top5 99.873047   BatchTime 0.096702   LR 0.000100   
2022-10-20 17:12:51,612 - INFO  - Training [61][   60/  196]   Loss 0.114036   Top1 96.132812   Top5 99.869792   BatchTime 0.090527   LR 0.000100   
2022-10-20 17:12:53,177 - INFO  - Training [61][   80/  196]   Loss 0.114257   Top1 96.137695   Top5 99.877930   BatchTime 0.087462   LR 0.000100   
2022-10-20 17:12:54,738 - INFO  - Training [61][  100/  196]   Loss 0.116516   Top1 96.046875   Top5 99.867188   BatchTime 0.085579   LR 0.000100   
2022-10-20 17:12:56,301 - INFO  - Training [61][  120/  196]   Loss 0.118182   Top1 96.002604   Top5 99.873047   BatchTime 0.084341   LR 0.000100   
2022-10-20 17:12:57,865 - INFO  - Training [61][  140/  196]   Loss 0.117097   Top1 96.054688   Top5 99.874442   BatchTime 0.083459   LR 0.000100   
2022-10-20 17:12:59,430 - INFO  - Training [61][  160/  196]   Loss 0.117419   Top1 96.013184   Top5 99.875488   BatchTime 0.082813   LR 0.000100   
2022-10-20 17:13:00,983 - INFO  - Training [61][  180/  196]   Loss 0.117801   Top1 96.039497   Top5 99.882812   BatchTime 0.082237   LR 0.000100   
2022-10-20 17:13:02,303 - INFO  - ==> Top1: 96.066    Top5: 99.884    Loss: 0.117

2022-10-20 17:13:02,375 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:13:03,590 - INFO  - Validation [61][   20/   40]   Loss 0.493486   Top1 86.523438   Top5 99.082031   BatchTime 0.060727   
2022-10-20 17:13:04,125 - INFO  - Validation [61][   40/   40]   Loss 0.480258   Top1 86.580000   Top5 99.270000   BatchTime 0.043736   
2022-10-20 17:13:04,222 - INFO  - ==> Top1: 86.580    Top5: 99.270    Loss: 0.480

2022-10-20 17:13:04,222 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:13:05,905 - INFO  - Validation [61][   20/   40]   Loss 0.510771   Top1 86.230469   Top5 99.062500   BatchTime 0.084113   
2022-10-20 17:13:06,715 - INFO  - Validation [61][   40/   40]   Loss 0.499870   Top1 86.390000   Top5 99.180000   BatchTime 0.062325   
2022-10-20 17:13:06,811 - INFO  - ==> Top1: 86.390    Top5: 99.180    Loss: 0.500

2022-10-20 17:13:06,812 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:13:06,812 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:13:06,812 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:13:06,864 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:13:06,865 - INFO  - >>>>>> Epoch  62
2022-10-20 17:13:06,865 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:13:09,108 - INFO  - Training [62][   20/  196]   Loss 0.117744   Top1 96.054688   Top5 99.882812   BatchTime 0.112119   LR 0.000100   
2022-10-20 17:13:10,670 - INFO  - Training [62][   40/  196]   Loss 0.117070   Top1 95.996094   Top5 99.882812   BatchTime 0.095109   LR 0.000100   
2022-10-20 17:13:12,231 - INFO  - Training [62][   60/  196]   Loss 0.116546   Top1 96.067708   Top5 99.902344   BatchTime 0.089431   LR 0.000100   
2022-10-20 17:13:13,793 - INFO  - Training [62][   80/  196]   Loss 0.118438   Top1 96.059570   Top5 99.887695   BatchTime 0.086591   LR 0.000100   
2022-10-20 17:13:15,355 - INFO  - Training [62][  100/  196]   Loss 0.118585   Top1 96.027344   Top5 99.878906   BatchTime 0.084894   LR 0.000100   
2022-10-20 17:13:16,920 - INFO  - Training [62][  120/  196]   Loss 0.119859   Top1 95.973307   Top5 99.882812   BatchTime 0.083784   LR 0.000100   
2022-10-20 17:13:18,479 - INFO  - Training [62][  140/  196]   Loss 0.119414   Top1 95.998884   Top5 99.891183   BatchTime 0.082950   LR 0.000100   
2022-10-20 17:13:20,037 - INFO  - Training [62][  160/  196]   Loss 0.118664   Top1 96.030273   Top5 99.895020   BatchTime 0.082318   LR 0.000100   
2022-10-20 17:13:21,587 - INFO  - Training [62][  180/  196]   Loss 0.118139   Top1 96.065538   Top5 99.887153   BatchTime 0.081784   LR 0.000100   
2022-10-20 17:13:22,911 - INFO  - ==> Top1: 96.054    Top5: 99.884    Loss: 0.118

2022-10-20 17:13:22,976 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:13:24,174 - INFO  - Validation [62][   20/   40]   Loss 0.491655   Top1 86.250000   Top5 99.082031   BatchTime 0.059878   
2022-10-20 17:13:24,707 - INFO  - Validation [62][   40/   40]   Loss 0.477660   Top1 86.590000   Top5 99.240000   BatchTime 0.043251   
2022-10-20 17:13:24,804 - INFO  - ==> Top1: 86.590    Top5: 99.240    Loss: 0.478

2022-10-20 17:13:24,804 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:13:26,490 - INFO  - Validation [62][   20/   40]   Loss 0.509335   Top1 85.976562   Top5 99.101562   BatchTime 0.084281   
2022-10-20 17:13:27,295 - INFO  - Validation [62][   40/   40]   Loss 0.497879   Top1 86.320000   Top5 99.240000   BatchTime 0.062249   
2022-10-20 17:13:27,407 - INFO  - ==> Top1: 86.320    Top5: 99.240    Loss: 0.498

2022-10-20 17:13:27,407 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:13:27,407 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:13:27,407 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 86.590   Top5: 99.250]
2022-10-20 17:13:27,492 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:13:27,493 - INFO  - >>>>>> Epoch  63
2022-10-20 17:13:27,493 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:13:29,765 - INFO  - Training [63][   20/  196]   Loss 0.123369   Top1 95.761719   Top5 99.765625   BatchTime 0.113430   LR 0.000100   
2022-10-20 17:13:31,328 - INFO  - Training [63][   40/  196]   Loss 0.118241   Top1 96.044922   Top5 99.863281   BatchTime 0.095790   LR 0.000100   
2022-10-20 17:13:32,888 - INFO  - Training [63][   60/  196]   Loss 0.123488   Top1 95.898438   Top5 99.811198   BatchTime 0.089871   LR 0.000100   
2022-10-20 17:13:34,449 - INFO  - Training [63][   80/  196]   Loss 0.121228   Top1 95.937500   Top5 99.848633   BatchTime 0.086914   LR 0.000100   
2022-10-20 17:13:36,010 - INFO  - Training [63][  100/  196]   Loss 0.121142   Top1 95.878906   Top5 99.859375   BatchTime 0.085137   LR 0.000100   
2022-10-20 17:13:37,572 - INFO  - Training [63][  120/  196]   Loss 0.120069   Top1 95.895182   Top5 99.853516   BatchTime 0.083961   LR 0.000100   
2022-10-20 17:13:39,137 - INFO  - Training [63][  140/  196]   Loss 0.119520   Top1 95.943080   Top5 99.854911   BatchTime 0.083149   LR 0.000100   
2022-10-20 17:13:40,694 - INFO  - Training [63][  160/  196]   Loss 0.119001   Top1 95.983887   Top5 99.853516   BatchTime 0.082485   LR 0.000100   
2022-10-20 17:13:42,245 - INFO  - Training [63][  180/  196]   Loss 0.118981   Top1 95.965712   Top5 99.861111   BatchTime 0.081938   LR 0.000100   
2022-10-20 17:13:43,562 - INFO  - ==> Top1: 95.978    Top5: 99.860    Loss: 0.119

2022-10-20 17:13:43,635 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:13:44,825 - INFO  - Validation [63][   20/   40]   Loss 0.490044   Top1 86.542969   Top5 99.023438   BatchTime 0.059426   
2022-10-20 17:13:45,358 - INFO  - Validation [63][   40/   40]   Loss 0.477011   Top1 86.590000   Top5 99.220000   BatchTime 0.043042   
2022-10-20 17:13:45,445 - INFO  - ==> Top1: 86.590    Top5: 99.220    Loss: 0.477

2022-10-20 17:13:45,445 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:13:47,158 - INFO  - Validation [63][   20/   40]   Loss 0.506417   Top1 86.464844   Top5 99.042969   BatchTime 0.085627   
2022-10-20 17:13:47,962 - INFO  - Validation [63][   40/   40]   Loss 0.495330   Top1 86.720000   Top5 99.170000   BatchTime 0.062914   
2022-10-20 17:13:48,071 - INFO  - ==> Top1: 86.720    Top5: 99.170    Loss: 0.495

2022-10-20 17:13:48,071 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:13:48,071 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:13:48,071 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:13:49,854 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 17:13:49,854 - INFO  - >>>>>> Epoch  64
2022-10-20 17:13:49,854 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:13:52,119 - INFO  - Training [64][   20/  196]   Loss 0.109646   Top1 96.347656   Top5 99.882812   BatchTime 0.113202   LR 0.000100   
2022-10-20 17:13:53,682 - INFO  - Training [64][   40/  196]   Loss 0.120297   Top1 95.986328   Top5 99.882812   BatchTime 0.095667   LR 0.000100   
2022-10-20 17:13:55,244 - INFO  - Training [64][   60/  196]   Loss 0.119077   Top1 96.054688   Top5 99.895833   BatchTime 0.089817   LR 0.000100   
2022-10-20 17:13:56,810 - INFO  - Training [64][   80/  196]   Loss 0.119284   Top1 95.991211   Top5 99.902344   BatchTime 0.086938   LR 0.000100   
2022-10-20 17:13:58,369 - INFO  - Training [64][  100/  196]   Loss 0.118656   Top1 96.031250   Top5 99.882812   BatchTime 0.085134   LR 0.000100   
2022-10-20 17:13:59,931 - INFO  - Training [64][  120/  196]   Loss 0.118772   Top1 95.992839   Top5 99.882812   BatchTime 0.083967   LR 0.000100   
2022-10-20 17:14:01,494 - INFO  - Training [64][  140/  196]   Loss 0.119130   Top1 95.996094   Top5 99.888393   BatchTime 0.083131   LR 0.000100   
2022-10-20 17:14:03,060 - INFO  - Training [64][  160/  196]   Loss 0.119309   Top1 95.981445   Top5 99.868164   BatchTime 0.082528   LR 0.000100   
2022-10-20 17:14:04,609 - INFO  - Training [64][  180/  196]   Loss 0.119347   Top1 96.015625   Top5 99.869792   BatchTime 0.081965   LR 0.000100   
2022-10-20 17:14:05,929 - INFO  - ==> Top1: 96.016    Top5: 99.864    Loss: 0.119

2022-10-20 17:14:05,995 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:14:07,202 - INFO  - Validation [64][   20/   40]   Loss 0.493598   Top1 86.582031   Top5 99.062500   BatchTime 0.060314   
2022-10-20 17:14:07,740 - INFO  - Validation [64][   40/   40]   Loss 0.479248   Top1 86.740000   Top5 99.240000   BatchTime 0.043601   
2022-10-20 17:14:07,835 - INFO  - ==> Top1: 86.740    Top5: 99.240    Loss: 0.479

2022-10-20 17:14:07,835 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:14:09,521 - INFO  - Validation [64][   20/   40]   Loss 0.508454   Top1 86.308594   Top5 99.140625   BatchTime 0.084237   
2022-10-20 17:14:10,331 - INFO  - Validation [64][   40/   40]   Loss 0.496801   Top1 86.530000   Top5 99.210000   BatchTime 0.062378   
2022-10-20 17:14:10,443 - INFO  - ==> Top1: 86.530    Top5: 99.210    Loss: 0.497

2022-10-20 17:14:10,443 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:14:10,443 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:14:10,443 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:14:10,507 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:14:10,507 - INFO  - >>>>>> Epoch  65
2022-10-20 17:14:10,508 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:14:12,859 - INFO  - Training [65][   20/  196]   Loss 0.124888   Top1 95.683594   Top5 99.941406   BatchTime 0.117511   LR 0.000100   
2022-10-20 17:14:14,419 - INFO  - Training [65][   40/  196]   Loss 0.121046   Top1 95.849609   Top5 99.921875   BatchTime 0.097757   LR 0.000100   
2022-10-20 17:14:15,982 - INFO  - Training [65][   60/  196]   Loss 0.117287   Top1 96.002604   Top5 99.928385   BatchTime 0.091218   LR 0.000100   
2022-10-20 17:14:17,549 - INFO  - Training [65][   80/  196]   Loss 0.119271   Top1 95.966797   Top5 99.882812   BatchTime 0.088000   LR 0.000100   
2022-10-20 17:14:19,109 - INFO  - Training [65][  100/  196]   Loss 0.118803   Top1 96.023438   Top5 99.882812   BatchTime 0.086003   LR 0.000100   
2022-10-20 17:14:20,669 - INFO  - Training [65][  120/  196]   Loss 0.117761   Top1 96.067708   Top5 99.882812   BatchTime 0.084674   LR 0.000100   
2022-10-20 17:14:22,230 - INFO  - Training [65][  140/  196]   Loss 0.116919   Top1 96.113281   Top5 99.877232   BatchTime 0.083721   LR 0.000100   
2022-10-20 17:14:23,790 - INFO  - Training [65][  160/  196]   Loss 0.116867   Top1 96.127930   Top5 99.880371   BatchTime 0.083008   LR 0.000100   
2022-10-20 17:14:25,341 - INFO  - Training [65][  180/  196]   Loss 0.116154   Top1 96.156684   Top5 99.884983   BatchTime 0.082399   LR 0.000100   
2022-10-20 17:14:26,663 - INFO  - ==> Top1: 96.162    Top5: 99.878    Loss: 0.116

2022-10-20 17:14:26,729 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:14:27,943 - INFO  - Validation [65][   20/   40]   Loss 0.494158   Top1 86.523438   Top5 99.101562   BatchTime 0.060642   
2022-10-20 17:14:28,478 - INFO  - Validation [65][   40/   40]   Loss 0.479033   Top1 86.690000   Top5 99.270000   BatchTime 0.043693   
2022-10-20 17:14:28,579 - INFO  - ==> Top1: 86.690    Top5: 99.270    Loss: 0.479

2022-10-20 17:14:28,579 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:14:30,251 - INFO  - Validation [65][   20/   40]   Loss 0.511003   Top1 86.425781   Top5 99.023438   BatchTime 0.083561   
2022-10-20 17:14:31,062 - INFO  - Validation [65][   40/   40]   Loss 0.494947   Top1 86.510000   Top5 99.190000   BatchTime 0.062049   
2022-10-20 17:14:31,170 - INFO  - ==> Top1: 86.510    Top5: 99.190    Loss: 0.495

2022-10-20 17:14:31,170 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:14:31,170 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:14:31,170 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:14:31,196 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:14:31,197 - INFO  - >>>>>> Epoch  66
2022-10-20 17:14:31,197 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:14:33,445 - INFO  - Training [66][   20/  196]   Loss 0.109646   Top1 96.445312   Top5 99.863281   BatchTime 0.112381   LR 0.000100   
2022-10-20 17:14:35,008 - INFO  - Training [66][   40/  196]   Loss 0.114455   Top1 96.367188   Top5 99.902344   BatchTime 0.095253   LR 0.000100   
2022-10-20 17:14:36,570 - INFO  - Training [66][   60/  196]   Loss 0.113458   Top1 96.354167   Top5 99.921875   BatchTime 0.089539   LR 0.000100   
2022-10-20 17:14:38,135 - INFO  - Training [66][   80/  196]   Loss 0.113011   Top1 96.303711   Top5 99.926758   BatchTime 0.086711   LR 0.000100   
2022-10-20 17:14:39,697 - INFO  - Training [66][  100/  196]   Loss 0.114729   Top1 96.277344   Top5 99.910156   BatchTime 0.084998   LR 0.000100   
2022-10-20 17:14:41,260 - INFO  - Training [66][  120/  196]   Loss 0.115396   Top1 96.250000   Top5 99.895833   BatchTime 0.083852   LR 0.000100   
2022-10-20 17:14:42,823 - INFO  - Training [66][  140/  196]   Loss 0.118630   Top1 96.152344   Top5 99.874442   BatchTime 0.083035   LR 0.000100   
2022-10-20 17:14:44,390 - INFO  - Training [66][  160/  196]   Loss 0.118478   Top1 96.132812   Top5 99.882812   BatchTime 0.082451   LR 0.000100   
2022-10-20 17:14:45,943 - INFO  - Training [66][  180/  196]   Loss 0.117149   Top1 96.163194   Top5 99.889323   BatchTime 0.081920   LR 0.000100   
2022-10-20 17:14:47,264 - INFO  - ==> Top1: 96.140    Top5: 99.890    Loss: 0.117

2022-10-20 17:14:47,332 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:14:48,556 - INFO  - Validation [66][   20/   40]   Loss 0.493653   Top1 86.367188   Top5 99.082031   BatchTime 0.061182   
2022-10-20 17:14:49,089 - INFO  - Validation [66][   40/   40]   Loss 0.477109   Top1 86.480000   Top5 99.250000   BatchTime 0.043913   
2022-10-20 17:14:49,185 - INFO  - ==> Top1: 86.480    Top5: 99.250    Loss: 0.477

2022-10-20 17:14:49,186 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:14:50,873 - INFO  - Validation [66][   20/   40]   Loss 0.504906   Top1 86.171875   Top5 99.082031   BatchTime 0.084354   
2022-10-20 17:14:51,675 - INFO  - Validation [66][   40/   40]   Loss 0.491126   Top1 86.530000   Top5 99.220000   BatchTime 0.062220   
2022-10-20 17:14:51,774 - INFO  - ==> Top1: 86.530    Top5: 99.220    Loss: 0.491

2022-10-20 17:14:51,774 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:14:51,775 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:14:51,775 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 86.660   Top5: 99.200]
2022-10-20 17:14:51,840 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:14:51,841 - INFO  - >>>>>> Epoch  67
2022-10-20 17:14:51,841 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:14:54,188 - INFO  - Training [67][   20/  196]   Loss 0.114701   Top1 96.250000   Top5 99.863281   BatchTime 0.117160   LR 0.000100   
2022-10-20 17:14:55,753 - INFO  - Training [67][   40/  196]   Loss 0.116722   Top1 96.054688   Top5 99.853516   BatchTime 0.097724   LR 0.000100   
2022-10-20 17:14:57,317 - INFO  - Training [67][   60/  196]   Loss 0.117554   Top1 96.152344   Top5 99.843750   BatchTime 0.091208   LR 0.000100   
2022-10-20 17:14:58,884 - INFO  - Training [67][   80/  196]   Loss 0.116031   Top1 96.220703   Top5 99.829102   BatchTime 0.088000   LR 0.000100   
2022-10-20 17:15:00,445 - INFO  - Training [67][  100/  196]   Loss 0.116577   Top1 96.156250   Top5 99.835938   BatchTime 0.086001   LR 0.000100   
2022-10-20 17:15:02,011 - INFO  - Training [67][  120/  196]   Loss 0.117261   Top1 96.123047   Top5 99.843750   BatchTime 0.084718   LR 0.000100   
2022-10-20 17:15:03,575 - INFO  - Training [67][  140/  196]   Loss 0.117025   Top1 96.124442   Top5 99.854911   BatchTime 0.083789   LR 0.000100   
2022-10-20 17:15:05,145 - INFO  - Training [67][  160/  196]   Loss 0.117143   Top1 96.093750   Top5 99.863281   BatchTime 0.083125   LR 0.000100   
2022-10-20 17:15:06,706 - INFO  - Training [67][  180/  196]   Loss 0.117367   Top1 96.065538   Top5 99.865451   BatchTime 0.082561   LR 0.000100   
2022-10-20 17:15:08,037 - INFO  - ==> Top1: 96.062    Top5: 99.866    Loss: 0.117

2022-10-20 17:15:08,110 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:15:09,331 - INFO  - Validation [67][   20/   40]   Loss 0.497197   Top1 86.406250   Top5 99.023438   BatchTime 0.061042   
2022-10-20 17:15:09,870 - INFO  - Validation [67][   40/   40]   Loss 0.481293   Top1 86.570000   Top5 99.220000   BatchTime 0.044007   
2022-10-20 17:15:09,963 - INFO  - ==> Top1: 86.570    Top5: 99.220    Loss: 0.481

2022-10-20 17:15:09,963 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:15:11,824 - INFO  - Validation [67][   20/   40]   Loss 0.512295   Top1 86.542969   Top5 99.003906   BatchTime 0.093021   
2022-10-20 17:15:12,773 - INFO  - Validation [67][   40/   40]   Loss 0.499046   Top1 86.700000   Top5 99.160000   BatchTime 0.070239   
2022-10-20 17:15:12,887 - INFO  - ==> Top1: 86.700    Top5: 99.160    Loss: 0.499

2022-10-20 17:15:12,887 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:15:12,887 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:15:12,887 - INFO  - Scoreboard best 3 ==> Epoch [67][Top1: 86.700   Top5: 99.160]
2022-10-20 17:15:13,703 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:15:13,703 - INFO  - >>>>>> Epoch  68
2022-10-20 17:15:13,703 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:15:15,986 - INFO  - Training [68][   20/  196]   Loss 0.115635   Top1 96.308594   Top5 99.902344   BatchTime 0.114109   LR 0.000100   
2022-10-20 17:15:17,557 - INFO  - Training [68][   40/  196]   Loss 0.112912   Top1 96.396484   Top5 99.882812   BatchTime 0.096327   LR 0.000100   
2022-10-20 17:15:19,116 - INFO  - Training [68][   60/  196]   Loss 0.117390   Top1 96.165365   Top5 99.876302   BatchTime 0.090197   LR 0.000100   
2022-10-20 17:15:20,681 - INFO  - Training [68][   80/  196]   Loss 0.117831   Top1 96.113281   Top5 99.882812   BatchTime 0.087219   LR 0.000100   
2022-10-20 17:15:22,248 - INFO  - Training [68][  100/  196]   Loss 0.116299   Top1 96.191406   Top5 99.878906   BatchTime 0.085443   LR 0.000100   
2022-10-20 17:15:23,819 - INFO  - Training [68][  120/  196]   Loss 0.116542   Top1 96.165365   Top5 99.876302   BatchTime 0.084294   LR 0.000100   
2022-10-20 17:15:25,409 - INFO  - Training [68][  140/  196]   Loss 0.116347   Top1 96.163504   Top5 99.868862   BatchTime 0.083604   LR 0.000100   
2022-10-20 17:15:27,006 - INFO  - Training [68][  160/  196]   Loss 0.115890   Top1 96.154785   Top5 99.875488   BatchTime 0.083135   LR 0.000100   
2022-10-20 17:15:28,581 - INFO  - Training [68][  180/  196]   Loss 0.116444   Top1 96.152344   Top5 99.878472   BatchTime 0.082651   LR 0.000100   
2022-10-20 17:15:29,915 - INFO  - ==> Top1: 96.120    Top5: 99.882    Loss: 0.117

2022-10-20 17:15:29,982 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:15:31,228 - INFO  - Validation [68][   20/   40]   Loss 0.497957   Top1 86.093750   Top5 99.003906   BatchTime 0.062232   
2022-10-20 17:15:31,768 - INFO  - Validation [68][   40/   40]   Loss 0.481912   Top1 86.320000   Top5 99.190000   BatchTime 0.044629   
2022-10-20 17:15:31,870 - INFO  - ==> Top1: 86.320    Top5: 99.190    Loss: 0.482

2022-10-20 17:15:31,871 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:15:33,836 - INFO  - Validation [68][   20/   40]   Loss 0.512572   Top1 86.054688   Top5 99.062500   BatchTime 0.098269   
2022-10-20 17:15:34,853 - INFO  - Validation [68][   40/   40]   Loss 0.498846   Top1 86.250000   Top5 99.180000   BatchTime 0.074559   
2022-10-20 17:15:34,962 - INFO  - ==> Top1: 86.250    Top5: 99.180    Loss: 0.499

2022-10-20 17:15:34,962 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:15:34,962 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:15:34,962 - INFO  - Scoreboard best 3 ==> Epoch [67][Top1: 86.700   Top5: 99.160]
2022-10-20 17:15:34,988 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:15:34,988 - INFO  - >>>>>> Epoch  69
2022-10-20 17:15:34,988 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:15:37,265 - INFO  - Training [69][   20/  196]   Loss 0.117729   Top1 96.093750   Top5 99.921875   BatchTime 0.113801   LR 0.000100   
2022-10-20 17:15:38,835 - INFO  - Training [69][   40/  196]   Loss 0.114820   Top1 96.171875   Top5 99.921875   BatchTime 0.096164   LR 0.000100   
2022-10-20 17:15:40,402 - INFO  - Training [69][   60/  196]   Loss 0.115153   Top1 96.269531   Top5 99.876302   BatchTime 0.090226   LR 0.000100   
2022-10-20 17:15:41,978 - INFO  - Training [69][   80/  196]   Loss 0.116077   Top1 96.176758   Top5 99.882812   BatchTime 0.087363   LR 0.000100   
2022-10-20 17:15:43,576 - INFO  - Training [69][  100/  196]   Loss 0.115633   Top1 96.191406   Top5 99.886719   BatchTime 0.085870   LR 0.000100   
2022-10-20 17:15:45,149 - INFO  - Training [69][  120/  196]   Loss 0.115413   Top1 96.188151   Top5 99.882812   BatchTime 0.084669   LR 0.000100   
2022-10-20 17:15:46,722 - INFO  - Training [69][  140/  196]   Loss 0.113682   Top1 96.255580   Top5 99.880022   BatchTime 0.083805   LR 0.000100   
2022-10-20 17:15:48,293 - INFO  - Training [69][  160/  196]   Loss 0.114411   Top1 96.193848   Top5 99.870605   BatchTime 0.083149   LR 0.000100   
2022-10-20 17:15:49,862 - INFO  - Training [69][  180/  196]   Loss 0.114684   Top1 96.191406   Top5 99.874132   BatchTime 0.082628   LR 0.000100   
2022-10-20 17:15:51,341 - INFO  - ==> Top1: 96.152    Top5: 99.872    Loss: 0.116

2022-10-20 17:15:51,409 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:15:52,622 - INFO  - Validation [69][   20/   40]   Loss 0.497042   Top1 86.582031   Top5 99.082031   BatchTime 0.060630   
2022-10-20 17:15:53,162 - INFO  - Validation [69][   40/   40]   Loss 0.477996   Top1 86.820000   Top5 99.260000   BatchTime 0.043799   
2022-10-20 17:15:53,257 - INFO  - ==> Top1: 86.820    Top5: 99.260    Loss: 0.478

2022-10-20 17:15:53,258 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:15:54,980 - INFO  - Validation [69][   20/   40]   Loss 0.512491   Top1 86.367188   Top5 98.984375   BatchTime 0.086096   
2022-10-20 17:15:55,800 - INFO  - Validation [69][   40/   40]   Loss 0.494774   Top1 86.750000   Top5 99.170000   BatchTime 0.063547   
2022-10-20 17:15:55,918 - INFO  - ==> Top1: 86.750    Top5: 99.170    Loss: 0.495

2022-10-20 17:15:55,918 - INFO  - Scoreboard best 1 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:15:55,919 - INFO  - Scoreboard best 2 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:15:55,919 - INFO  - Scoreboard best 3 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:15:57,831 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 17:15:57,833 - INFO  - >>>>>> Epoch  70
2022-10-20 17:15:57,833 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:16:00,158 - INFO  - Training [70][   20/  196]   Loss 0.108868   Top1 96.503906   Top5 99.980469   BatchTime 0.116117   LR 0.000100   
2022-10-20 17:16:01,717 - INFO  - Training [70][   40/  196]   Loss 0.110452   Top1 96.455078   Top5 99.941406   BatchTime 0.097035   LR 0.000100   
2022-10-20 17:16:03,280 - INFO  - Training [70][   60/  196]   Loss 0.112970   Top1 96.386719   Top5 99.915365   BatchTime 0.090733   LR 0.000100   
2022-10-20 17:16:04,843 - INFO  - Training [70][   80/  196]   Loss 0.115578   Top1 96.284180   Top5 99.892578   BatchTime 0.087581   LR 0.000100   
2022-10-20 17:16:06,408 - INFO  - Training [70][  100/  196]   Loss 0.114812   Top1 96.308594   Top5 99.882812   BatchTime 0.085719   LR 0.000100   
2022-10-20 17:16:07,973 - INFO  - Training [70][  120/  196]   Loss 0.115716   Top1 96.253255   Top5 99.866536   BatchTime 0.084472   LR 0.000100   
2022-10-20 17:16:09,538 - INFO  - Training [70][  140/  196]   Loss 0.115617   Top1 96.222098   Top5 99.866071   BatchTime 0.083582   LR 0.000100   
2022-10-20 17:16:11,103 - INFO  - Training [70][  160/  196]   Loss 0.115588   Top1 96.203613   Top5 99.873047   BatchTime 0.082919   LR 0.000100   
2022-10-20 17:16:12,665 - INFO  - Training [70][  180/  196]   Loss 0.114962   Top1 96.221788   Top5 99.863281   BatchTime 0.082383   LR 0.000100   
2022-10-20 17:16:13,999 - INFO  - ==> Top1: 96.220    Top5: 99.864    Loss: 0.115

2022-10-20 17:16:14,067 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:16:15,300 - INFO  - Validation [70][   20/   40]   Loss 0.496916   Top1 86.464844   Top5 99.140625   BatchTime 0.061603   
2022-10-20 17:16:15,839 - INFO  - Validation [70][   40/   40]   Loss 0.483140   Top1 86.470000   Top5 99.300000   BatchTime 0.044269   
2022-10-20 17:16:15,941 - INFO  - ==> Top1: 86.470    Top5: 99.300    Loss: 0.483

2022-10-20 17:16:15,941 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:16:17,693 - INFO  - Validation [70][   20/   40]   Loss 0.506957   Top1 86.347656   Top5 99.121094   BatchTime 0.087595   
2022-10-20 17:16:18,507 - INFO  - Validation [70][   40/   40]   Loss 0.495627   Top1 86.490000   Top5 99.260000   BatchTime 0.064133   
2022-10-20 17:16:18,614 - INFO  - ==> Top1: 86.490    Top5: 99.260    Loss: 0.496

2022-10-20 17:16:18,615 - INFO  - Scoreboard best 1 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:16:18,615 - INFO  - Scoreboard best 2 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:16:18,615 - INFO  - Scoreboard best 3 ==> Epoch [47][Top1: 86.710   Top5: 99.210]
2022-10-20 17:16:18,668 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:16:18,668 - INFO  - >>>>>> Epoch  71
2022-10-20 17:16:18,668 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:16:20,978 - INFO  - Training [71][   20/  196]   Loss 0.101143   Top1 96.855469   Top5 99.921875   BatchTime 0.115468   LR 0.000100   
2022-10-20 17:16:22,545 - INFO  - Training [71][   40/  196]   Loss 0.112293   Top1 96.376953   Top5 99.863281   BatchTime 0.096888   LR 0.000100   
2022-10-20 17:16:24,102 - INFO  - Training [71][   60/  196]   Loss 0.110472   Top1 96.451823   Top5 99.882812   BatchTime 0.090550   LR 0.000100   
2022-10-20 17:16:25,659 - INFO  - Training [71][   80/  196]   Loss 0.113499   Top1 96.259766   Top5 99.873047   BatchTime 0.087377   LR 0.000100   
2022-10-20 17:16:27,217 - INFO  - Training [71][  100/  196]   Loss 0.113724   Top1 96.238281   Top5 99.875000   BatchTime 0.085476   LR 0.000100   
2022-10-20 17:16:28,775 - INFO  - Training [71][  120/  196]   Loss 0.114007   Top1 96.246745   Top5 99.866536   BatchTime 0.084215   LR 0.000100   
2022-10-20 17:16:30,333 - INFO  - Training [71][  140/  196]   Loss 0.113576   Top1 96.224888   Top5 99.863281   BatchTime 0.083311   LR 0.000100   
2022-10-20 17:16:31,890 - INFO  - Training [71][  160/  196]   Loss 0.112976   Top1 96.235352   Top5 99.873047   BatchTime 0.082630   LR 0.000100   
2022-10-20 17:16:33,438 - INFO  - Training [71][  180/  196]   Loss 0.113443   Top1 96.230469   Top5 99.876302   BatchTime 0.082050   LR 0.000100   
2022-10-20 17:16:34,751 - INFO  - ==> Top1: 96.208    Top5: 99.874    Loss: 0.114

2022-10-20 17:16:34,823 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:16:36,046 - INFO  - Validation [71][   20/   40]   Loss 0.493972   Top1 86.425781   Top5 99.082031   BatchTime 0.061159   
2022-10-20 17:16:36,585 - INFO  - Validation [71][   40/   40]   Loss 0.476479   Top1 86.670000   Top5 99.220000   BatchTime 0.044048   
2022-10-20 17:16:36,685 - INFO  - ==> Top1: 86.670    Top5: 99.220    Loss: 0.476

2022-10-20 17:16:36,685 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:16:38,397 - INFO  - Validation [71][   20/   40]   Loss 0.509020   Top1 86.367188   Top5 99.042969   BatchTime 0.085573   
2022-10-20 17:16:39,198 - INFO  - Validation [71][   40/   40]   Loss 0.492784   Top1 86.810000   Top5 99.190000   BatchTime 0.062807   
2022-10-20 17:16:39,302 - INFO  - ==> Top1: 86.810    Top5: 99.190    Loss: 0.493

2022-10-20 17:16:39,303 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:16:39,303 - INFO  - Scoreboard best 2 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:16:39,303 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:16:41,076 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 17:16:41,077 - INFO  - >>>>>> Epoch  72
2022-10-20 17:16:41,077 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:16:43,337 - INFO  - Training [72][   20/  196]   Loss 0.112488   Top1 96.015625   Top5 99.902344   BatchTime 0.112849   LR 0.000100   
2022-10-20 17:16:44,901 - INFO  - Training [72][   40/  196]   Loss 0.114236   Top1 95.966797   Top5 99.873047   BatchTime 0.095518   LR 0.000100   
2022-10-20 17:16:46,468 - INFO  - Training [72][   60/  196]   Loss 0.114300   Top1 96.087240   Top5 99.869792   BatchTime 0.089790   LR 0.000100   
2022-10-20 17:16:48,028 - INFO  - Training [72][   80/  196]   Loss 0.114908   Top1 96.147461   Top5 99.882812   BatchTime 0.086846   LR 0.000100   
2022-10-20 17:16:49,591 - INFO  - Training [72][  100/  196]   Loss 0.114466   Top1 96.132812   Top5 99.871094   BatchTime 0.085111   LR 0.000100   
2022-10-20 17:16:51,155 - INFO  - Training [72][  120/  196]   Loss 0.114285   Top1 96.162109   Top5 99.863281   BatchTime 0.083957   LR 0.000100   
2022-10-20 17:16:52,722 - INFO  - Training [72][  140/  196]   Loss 0.115487   Top1 96.127232   Top5 99.868862   BatchTime 0.083153   LR 0.000100   
2022-10-20 17:16:54,282 - INFO  - Training [72][  160/  196]   Loss 0.113896   Top1 96.213379   Top5 99.865723   BatchTime 0.082512   LR 0.000100   
2022-10-20 17:16:55,837 - INFO  - Training [72][  180/  196]   Loss 0.114169   Top1 96.217448   Top5 99.861111   BatchTime 0.081979   LR 0.000100   
2022-10-20 17:16:57,152 - INFO  - ==> Top1: 96.208    Top5: 99.856    Loss: 0.114

2022-10-20 17:16:57,265 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:16:58,497 - INFO  - Validation [72][   20/   40]   Loss 0.500708   Top1 86.250000   Top5 99.101562   BatchTime 0.061573   
2022-10-20 17:16:59,033 - INFO  - Validation [72][   40/   40]   Loss 0.486549   Top1 86.440000   Top5 99.230000   BatchTime 0.044180   
2022-10-20 17:16:59,129 - INFO  - ==> Top1: 86.440    Top5: 99.230    Loss: 0.487

2022-10-20 17:16:59,129 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:17:00,825 - INFO  - Validation [72][   20/   40]   Loss 0.514711   Top1 86.386719   Top5 99.023438   BatchTime 0.084793   
2022-10-20 17:17:01,635 - INFO  - Validation [72][   40/   40]   Loss 0.502652   Top1 86.450000   Top5 99.190000   BatchTime 0.062632   
2022-10-20 17:17:01,746 - INFO  - ==> Top1: 86.450    Top5: 99.190    Loss: 0.503

2022-10-20 17:17:01,747 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:17:01,747 - INFO  - Scoreboard best 2 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:17:01,747 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:17:01,808 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:17:01,809 - INFO  - >>>>>> Epoch  73
2022-10-20 17:17:01,809 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:17:04,075 - INFO  - Training [73][   20/  196]   Loss 0.120839   Top1 96.250000   Top5 99.863281   BatchTime 0.113294   LR 0.000100   
2022-10-20 17:17:05,636 - INFO  - Training [73][   40/  196]   Loss 0.114689   Top1 96.347656   Top5 99.863281   BatchTime 0.095672   LR 0.000100   
2022-10-20 17:17:07,197 - INFO  - Training [73][   60/  196]   Loss 0.117294   Top1 96.171875   Top5 99.856771   BatchTime 0.089794   LR 0.000100   
2022-10-20 17:17:08,758 - INFO  - Training [73][   80/  196]   Loss 0.118457   Top1 96.152344   Top5 99.848633   BatchTime 0.086857   LR 0.000100   
2022-10-20 17:17:10,318 - INFO  - Training [73][  100/  196]   Loss 0.117110   Top1 96.152344   Top5 99.863281   BatchTime 0.085089   LR 0.000100   
2022-10-20 17:17:11,879 - INFO  - Training [73][  120/  196]   Loss 0.116319   Top1 96.171875   Top5 99.873047   BatchTime 0.083912   LR 0.000100   
2022-10-20 17:17:13,440 - INFO  - Training [73][  140/  196]   Loss 0.117149   Top1 96.155134   Top5 99.871652   BatchTime 0.083071   LR 0.000100   
2022-10-20 17:17:15,000 - INFO  - Training [73][  160/  196]   Loss 0.116583   Top1 96.176758   Top5 99.870605   BatchTime 0.082442   LR 0.000100   
2022-10-20 17:17:16,562 - INFO  - Training [73][  180/  196]   Loss 0.116014   Top1 96.206597   Top5 99.867622   BatchTime 0.081957   LR 0.000100   
2022-10-20 17:17:17,894 - INFO  - ==> Top1: 96.178    Top5: 99.870    Loss: 0.116

2022-10-20 17:17:17,967 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:17:19,197 - INFO  - Validation [73][   20/   40]   Loss 0.491132   Top1 86.269531   Top5 98.964844   BatchTime 0.061429   
2022-10-20 17:17:19,730 - INFO  - Validation [73][   40/   40]   Loss 0.478267   Top1 86.480000   Top5 99.130000   BatchTime 0.044045   
2022-10-20 17:17:19,834 - INFO  - ==> Top1: 86.480    Top5: 99.130    Loss: 0.478

2022-10-20 17:17:19,834 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:17:21,559 - INFO  - Validation [73][   20/   40]   Loss 0.507424   Top1 86.386719   Top5 99.042969   BatchTime 0.086228   
2022-10-20 17:17:22,365 - INFO  - Validation [73][   40/   40]   Loss 0.496181   Top1 86.620000   Top5 99.180000   BatchTime 0.063261   
2022-10-20 17:17:22,474 - INFO  - ==> Top1: 86.620    Top5: 99.180    Loss: 0.496

2022-10-20 17:17:22,474 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:17:22,474 - INFO  - Scoreboard best 2 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:17:22,474 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:17:22,535 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:17:22,535 - INFO  - >>>>>> Epoch  74
2022-10-20 17:17:22,535 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:17:24,825 - INFO  - Training [74][   20/  196]   Loss 0.107361   Top1 96.210938   Top5 99.941406   BatchTime 0.114430   LR 0.000100   
2022-10-20 17:17:26,391 - INFO  - Training [74][   40/  196]   Loss 0.107288   Top1 96.464844   Top5 99.921875   BatchTime 0.096369   LR 0.000100   
2022-10-20 17:17:27,956 - INFO  - Training [74][   60/  196]   Loss 0.110530   Top1 96.334635   Top5 99.882812   BatchTime 0.090321   LR 0.000100   
2022-10-20 17:17:29,520 - INFO  - Training [74][   80/  196]   Loss 0.111334   Top1 96.342773   Top5 99.868164   BatchTime 0.087294   LR 0.000100   
2022-10-20 17:17:31,084 - INFO  - Training [74][  100/  196]   Loss 0.112593   Top1 96.210938   Top5 99.878906   BatchTime 0.085475   LR 0.000100   
2022-10-20 17:17:32,648 - INFO  - Training [74][  120/  196]   Loss 0.113686   Top1 96.214193   Top5 99.869792   BatchTime 0.084263   LR 0.000100   
2022-10-20 17:17:34,213 - INFO  - Training [74][  140/  196]   Loss 0.115057   Top1 96.143973   Top5 99.871652   BatchTime 0.083401   LR 0.000100   
2022-10-20 17:17:35,777 - INFO  - Training [74][  160/  196]   Loss 0.114848   Top1 96.171875   Top5 99.868164   BatchTime 0.082751   LR 0.000100   
2022-10-20 17:17:37,331 - INFO  - Training [74][  180/  196]   Loss 0.113637   Top1 96.234809   Top5 99.878472   BatchTime 0.082191   LR 0.000100   
2022-10-20 17:17:38,663 - INFO  - ==> Top1: 96.204    Top5: 99.874    Loss: 0.115

2022-10-20 17:17:38,731 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:17:39,993 - INFO  - Validation [74][   20/   40]   Loss 0.494641   Top1 86.406250   Top5 99.023438   BatchTime 0.063065   
2022-10-20 17:17:40,527 - INFO  - Validation [74][   40/   40]   Loss 0.482011   Top1 86.460000   Top5 99.230000   BatchTime 0.044868   
2022-10-20 17:17:40,632 - INFO  - ==> Top1: 86.460    Top5: 99.230    Loss: 0.482

2022-10-20 17:17:40,632 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:17:42,351 - INFO  - Validation [74][   20/   40]   Loss 0.507655   Top1 86.523438   Top5 99.121094   BatchTime 0.085942   
2022-10-20 17:17:43,153 - INFO  - Validation [74][   40/   40]   Loss 0.497953   Top1 86.590000   Top5 99.260000   BatchTime 0.063009   
2022-10-20 17:17:43,270 - INFO  - ==> Top1: 86.590    Top5: 99.260    Loss: 0.498

2022-10-20 17:17:43,270 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:17:43,270 - INFO  - Scoreboard best 2 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:17:43,270 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:17:43,354 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:17:43,354 - INFO  - >>>>>> Epoch  75
2022-10-20 17:17:43,354 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:17:45,643 - INFO  - Training [75][   20/  196]   Loss 0.111456   Top1 96.132812   Top5 99.902344   BatchTime 0.114403   LR 0.000100   
2022-10-20 17:17:47,205 - INFO  - Training [75][   40/  196]   Loss 0.108548   Top1 96.298828   Top5 99.912109   BatchTime 0.096243   LR 0.000100   
2022-10-20 17:17:48,766 - INFO  - Training [75][   60/  196]   Loss 0.106518   Top1 96.425781   Top5 99.895833   BatchTime 0.090185   LR 0.000100   
2022-10-20 17:17:50,331 - INFO  - Training [75][   80/  196]   Loss 0.110831   Top1 96.303711   Top5 99.887695   BatchTime 0.087199   LR 0.000100   
2022-10-20 17:17:51,889 - INFO  - Training [75][  100/  196]   Loss 0.112722   Top1 96.218750   Top5 99.886719   BatchTime 0.085339   LR 0.000100   
2022-10-20 17:17:53,450 - INFO  - Training [75][  120/  196]   Loss 0.112274   Top1 96.194661   Top5 99.892578   BatchTime 0.084128   LR 0.000100   
2022-10-20 17:17:55,011 - INFO  - Training [75][  140/  196]   Loss 0.112969   Top1 96.130022   Top5 99.888393   BatchTime 0.083257   LR 0.000100   
2022-10-20 17:17:56,576 - INFO  - Training [75][  160/  196]   Loss 0.114881   Top1 96.049805   Top5 99.865723   BatchTime 0.082628   LR 0.000100   
2022-10-20 17:17:58,123 - INFO  - Training [75][  180/  196]   Loss 0.114565   Top1 96.085069   Top5 99.861111   BatchTime 0.082045   LR 0.000100   
2022-10-20 17:17:59,443 - INFO  - ==> Top1: 96.012    Top5: 99.860    Loss: 0.116

2022-10-20 17:17:59,509 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:18:00,738 - INFO  - Validation [75][   20/   40]   Loss 0.496647   Top1 86.660156   Top5 99.160156   BatchTime 0.061461   
2022-10-20 17:18:01,275 - INFO  - Validation [75][   40/   40]   Loss 0.482771   Top1 86.790000   Top5 99.280000   BatchTime 0.044143   
2022-10-20 17:18:01,386 - INFO  - ==> Top1: 86.790    Top5: 99.280    Loss: 0.483

2022-10-20 17:18:01,386 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:18:03,096 - INFO  - Validation [75][   20/   40]   Loss 0.512571   Top1 86.484375   Top5 99.101562   BatchTime 0.085500   
2022-10-20 17:18:03,902 - INFO  - Validation [75][   40/   40]   Loss 0.500936   Top1 86.690000   Top5 99.240000   BatchTime 0.062889   
2022-10-20 17:18:04,009 - INFO  - ==> Top1: 86.690    Top5: 99.240    Loss: 0.501

2022-10-20 17:18:04,009 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:18:04,009 - INFO  - Scoreboard best 2 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:18:04,009 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:18:04,065 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:18:04,066 - INFO  - >>>>>> Epoch  76
2022-10-20 17:18:04,066 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:18:06,446 - INFO  - Training [76][   20/  196]   Loss 0.113524   Top1 96.406250   Top5 99.863281   BatchTime 0.118863   LR 0.000100   
2022-10-20 17:18:08,008 - INFO  - Training [76][   40/  196]   Loss 0.111432   Top1 96.435547   Top5 99.882812   BatchTime 0.098476   LR 0.000100   
2022-10-20 17:18:09,572 - INFO  - Training [76][   60/  196]   Loss 0.111629   Top1 96.406250   Top5 99.869792   BatchTime 0.091717   LR 0.000100   
2022-10-20 17:18:11,130 - INFO  - Training [76][   80/  196]   Loss 0.112264   Top1 96.357422   Top5 99.868164   BatchTime 0.088258   LR 0.000100   
2022-10-20 17:18:12,691 - INFO  - Training [76][  100/  196]   Loss 0.113864   Top1 96.253906   Top5 99.859375   BatchTime 0.086216   LR 0.000100   
2022-10-20 17:18:14,252 - INFO  - Training [76][  120/  196]   Loss 0.114152   Top1 96.230469   Top5 99.869792   BatchTime 0.084856   LR 0.000100   
2022-10-20 17:18:15,819 - INFO  - Training [76][  140/  196]   Loss 0.113735   Top1 96.255580   Top5 99.868862   BatchTime 0.083926   LR 0.000100   
2022-10-20 17:18:17,391 - INFO  - Training [76][  160/  196]   Loss 0.114454   Top1 96.213379   Top5 99.868164   BatchTime 0.083261   LR 0.000100   
2022-10-20 17:18:18,947 - INFO  - Training [76][  180/  196]   Loss 0.114389   Top1 96.226128   Top5 99.861111   BatchTime 0.082657   LR 0.000100   
2022-10-20 17:18:20,275 - INFO  - ==> Top1: 96.216    Top5: 99.860    Loss: 0.115

2022-10-20 17:18:20,343 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:18:21,555 - INFO  - Validation [76][   20/   40]   Loss 0.493009   Top1 86.425781   Top5 99.082031   BatchTime 0.060599   
2022-10-20 17:18:22,089 - INFO  - Validation [76][   40/   40]   Loss 0.479646   Top1 86.650000   Top5 99.280000   BatchTime 0.043629   
2022-10-20 17:18:22,198 - INFO  - ==> Top1: 86.650    Top5: 99.280    Loss: 0.480

2022-10-20 17:18:22,198 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:18:23,901 - INFO  - Validation [76][   20/   40]   Loss 0.507080   Top1 86.269531   Top5 99.003906   BatchTime 0.085102   
2022-10-20 17:18:24,707 - INFO  - Validation [76][   40/   40]   Loss 0.498019   Top1 86.440000   Top5 99.160000   BatchTime 0.062696   
2022-10-20 17:18:24,826 - INFO  - ==> Top1: 86.440    Top5: 99.160    Loss: 0.498

2022-10-20 17:18:24,826 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:18:24,826 - INFO  - Scoreboard best 2 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:18:24,826 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:18:24,852 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:18:24,852 - INFO  - >>>>>> Epoch  77
2022-10-20 17:18:24,852 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:18:27,133 - INFO  - Training [77][   20/  196]   Loss 0.113697   Top1 96.250000   Top5 99.921875   BatchTime 0.114001   LR 0.000100   
2022-10-20 17:18:28,692 - INFO  - Training [77][   40/  196]   Loss 0.114826   Top1 96.240234   Top5 99.882812   BatchTime 0.095976   LR 0.000100   
2022-10-20 17:18:30,250 - INFO  - Training [77][   60/  196]   Loss 0.112226   Top1 96.334635   Top5 99.889323   BatchTime 0.089954   LR 0.000100   
2022-10-20 17:18:31,808 - INFO  - Training [77][   80/  196]   Loss 0.112865   Top1 96.279297   Top5 99.873047   BatchTime 0.086937   LR 0.000100   
2022-10-20 17:18:33,366 - INFO  - Training [77][  100/  196]   Loss 0.112908   Top1 96.269531   Top5 99.871094   BatchTime 0.085135   LR 0.000100   
2022-10-20 17:18:34,925 - INFO  - Training [77][  120/  196]   Loss 0.113428   Top1 96.250000   Top5 99.873047   BatchTime 0.083930   LR 0.000100   
2022-10-20 17:18:36,483 - INFO  - Training [77][  140/  196]   Loss 0.112854   Top1 96.266741   Top5 99.882812   BatchTime 0.083071   LR 0.000100   
2022-10-20 17:18:38,042 - INFO  - Training [77][  160/  196]   Loss 0.113937   Top1 96.237793   Top5 99.880371   BatchTime 0.082432   LR 0.000100   
2022-10-20 17:18:39,591 - INFO  - Training [77][  180/  196]   Loss 0.114418   Top1 96.230469   Top5 99.876302   BatchTime 0.081876   LR 0.000100   
2022-10-20 17:18:40,919 - INFO  - ==> Top1: 96.196    Top5: 99.872    Loss: 0.115

2022-10-20 17:18:40,989 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:18:42,217 - INFO  - Validation [77][   20/   40]   Loss 0.498199   Top1 86.503906   Top5 99.062500   BatchTime 0.061337   
2022-10-20 17:18:42,755 - INFO  - Validation [77][   40/   40]   Loss 0.482293   Top1 86.570000   Top5 99.240000   BatchTime 0.044134   
2022-10-20 17:18:42,864 - INFO  - ==> Top1: 86.570    Top5: 99.240    Loss: 0.482

2022-10-20 17:18:42,864 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:18:44,621 - INFO  - Validation [77][   20/   40]   Loss 0.512554   Top1 86.210938   Top5 99.042969   BatchTime 0.087835   
2022-10-20 17:18:45,422 - INFO  - Validation [77][   40/   40]   Loss 0.497609   Top1 86.430000   Top5 99.210000   BatchTime 0.063941   
2022-10-20 17:18:45,547 - INFO  - ==> Top1: 86.430    Top5: 99.210    Loss: 0.498

2022-10-20 17:18:45,548 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:18:45,548 - INFO  - Scoreboard best 2 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:18:45,548 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 86.720   Top5: 99.170]
2022-10-20 17:18:45,610 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:18:45,610 - INFO  - >>>>>> Epoch  78
2022-10-20 17:18:45,610 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:18:47,870 - INFO  - Training [78][   20/  196]   Loss 0.107627   Top1 96.503906   Top5 99.902344   BatchTime 0.112990   LR 0.000100   
2022-10-20 17:18:49,430 - INFO  - Training [78][   40/  196]   Loss 0.109666   Top1 96.386719   Top5 99.882812   BatchTime 0.095474   LR 0.000100   
2022-10-20 17:18:50,989 - INFO  - Training [78][   60/  196]   Loss 0.108682   Top1 96.458333   Top5 99.876302   BatchTime 0.089632   LR 0.000100   
2022-10-20 17:18:52,547 - INFO  - Training [78][   80/  196]   Loss 0.112818   Top1 96.313477   Top5 99.877930   BatchTime 0.086700   LR 0.000100   
2022-10-20 17:18:54,105 - INFO  - Training [78][  100/  196]   Loss 0.113986   Top1 96.230469   Top5 99.867188   BatchTime 0.084943   LR 0.000100   
2022-10-20 17:18:55,663 - INFO  - Training [78][  120/  196]   Loss 0.114307   Top1 96.217448   Top5 99.873047   BatchTime 0.083769   LR 0.000100   
2022-10-20 17:18:57,222 - INFO  - Training [78][  140/  196]   Loss 0.116274   Top1 96.171875   Top5 99.863281   BatchTime 0.082933   LR 0.000100   
2022-10-20 17:18:58,781 - INFO  - Training [78][  160/  196]   Loss 0.114579   Top1 96.257324   Top5 99.865723   BatchTime 0.082311   LR 0.000100   
2022-10-20 17:19:00,329 - INFO  - Training [78][  180/  196]   Loss 0.114780   Top1 96.210938   Top5 99.871962   BatchTime 0.081766   LR 0.000100   
2022-10-20 17:19:01,662 - INFO  - ==> Top1: 96.206    Top5: 99.874    Loss: 0.115

2022-10-20 17:19:01,730 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:19:02,982 - INFO  - Validation [78][   20/   40]   Loss 0.495685   Top1 86.542969   Top5 99.082031   BatchTime 0.062566   
2022-10-20 17:19:03,515 - INFO  - Validation [78][   40/   40]   Loss 0.481244   Top1 86.690000   Top5 99.270000   BatchTime 0.044607   
2022-10-20 17:19:03,612 - INFO  - ==> Top1: 86.690    Top5: 99.270    Loss: 0.481

2022-10-20 17:19:03,612 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:19:05,341 - INFO  - Validation [78][   20/   40]   Loss 0.509008   Top1 86.484375   Top5 99.140625   BatchTime 0.086400   
2022-10-20 17:19:06,143 - INFO  - Validation [78][   40/   40]   Loss 0.497815   Top1 86.750000   Top5 99.240000   BatchTime 0.063262   
2022-10-20 17:19:06,249 - INFO  - ==> Top1: 86.750    Top5: 99.240    Loss: 0.498

2022-10-20 17:19:06,249 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:19:06,249 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:19:06,249 - INFO  - Scoreboard best 3 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:19:06,312 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:19:06,312 - INFO  - >>>>>> Epoch  79
2022-10-20 17:19:06,312 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:19:08,626 - INFO  - Training [79][   20/  196]   Loss 0.113364   Top1 96.230469   Top5 99.980469   BatchTime 0.115655   LR 0.000100   
2022-10-20 17:19:10,190 - INFO  - Training [79][   40/  196]   Loss 0.110066   Top1 96.289062   Top5 99.912109   BatchTime 0.096925   LR 0.000100   
2022-10-20 17:19:11,753 - INFO  - Training [79][   60/  196]   Loss 0.110755   Top1 96.302083   Top5 99.908854   BatchTime 0.090676   LR 0.000100   
2022-10-20 17:19:13,318 - INFO  - Training [79][   80/  196]   Loss 0.112493   Top1 96.196289   Top5 99.907227   BatchTime 0.087563   LR 0.000100   
2022-10-20 17:19:14,883 - INFO  - Training [79][  100/  196]   Loss 0.113742   Top1 96.128906   Top5 99.886719   BatchTime 0.085696   LR 0.000100   
2022-10-20 17:19:16,454 - INFO  - Training [79][  120/  196]   Loss 0.114130   Top1 96.136068   Top5 99.882812   BatchTime 0.084507   LR 0.000100   
2022-10-20 17:19:18,029 - INFO  - Training [79][  140/  196]   Loss 0.114594   Top1 96.127232   Top5 99.880022   BatchTime 0.083682   LR 0.000100   
2022-10-20 17:19:19,593 - INFO  - Training [79][  160/  196]   Loss 0.114357   Top1 96.181641   Top5 99.880371   BatchTime 0.082997   LR 0.000100   
2022-10-20 17:19:21,148 - INFO  - Training [79][  180/  196]   Loss 0.114800   Top1 96.174045   Top5 99.878472   BatchTime 0.082414   LR 0.000100   
2022-10-20 17:19:22,466 - INFO  - ==> Top1: 96.190    Top5: 99.888    Loss: 0.114

2022-10-20 17:19:22,534 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:19:23,769 - INFO  - Validation [79][   20/   40]   Loss 0.494103   Top1 86.484375   Top5 99.062500   BatchTime 0.061693   
2022-10-20 17:19:24,307 - INFO  - Validation [79][   40/   40]   Loss 0.480938   Top1 86.650000   Top5 99.230000   BatchTime 0.044313   
2022-10-20 17:19:24,414 - INFO  - ==> Top1: 86.650    Top5: 99.230    Loss: 0.481

2022-10-20 17:19:24,414 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:19:26,128 - INFO  - Validation [79][   20/   40]   Loss 0.509445   Top1 86.347656   Top5 99.101562   BatchTime 0.085675   
2022-10-20 17:19:26,933 - INFO  - Validation [79][   40/   40]   Loss 0.497537   Top1 86.560000   Top5 99.280000   BatchTime 0.062968   
2022-10-20 17:19:27,052 - INFO  - ==> Top1: 86.560    Top5: 99.280    Loss: 0.498

2022-10-20 17:19:27,052 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:19:27,052 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:19:27,052 - INFO  - Scoreboard best 3 ==> Epoch [69][Top1: 86.750   Top5: 99.170]
2022-10-20 17:19:27,114 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:19:27,114 - INFO  - >>>>>> Epoch  80
2022-10-20 17:19:27,114 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:19:29,446 - INFO  - Training [80][   20/  196]   Loss 0.111673   Top1 96.308594   Top5 99.902344   BatchTime 0.116550   LR 0.000100   
2022-10-20 17:19:31,013 - INFO  - Training [80][   40/  196]   Loss 0.113695   Top1 96.308594   Top5 99.892578   BatchTime 0.097455   LR 0.000100   
2022-10-20 17:19:32,579 - INFO  - Training [80][   60/  196]   Loss 0.115978   Top1 96.145833   Top5 99.882812   BatchTime 0.091064   LR 0.000100   
2022-10-20 17:19:34,144 - INFO  - Training [80][   80/  196]   Loss 0.115682   Top1 96.176758   Top5 99.877930   BatchTime 0.087865   LR 0.000100   
2022-10-20 17:19:35,709 - INFO  - Training [80][  100/  196]   Loss 0.113954   Top1 96.222656   Top5 99.878906   BatchTime 0.085944   LR 0.000100   
2022-10-20 17:19:37,275 - INFO  - Training [80][  120/  196]   Loss 0.114823   Top1 96.136068   Top5 99.873047   BatchTime 0.084663   LR 0.000100   
2022-10-20 17:19:38,839 - INFO  - Training [80][  140/  196]   Loss 0.116440   Top1 96.068638   Top5 99.866071   BatchTime 0.083744   LR 0.000100   
2022-10-20 17:19:40,408 - INFO  - Training [80][  160/  196]   Loss 0.116372   Top1 96.115723   Top5 99.877930   BatchTime 0.083077   LR 0.000100   
2022-10-20 17:19:41,960 - INFO  - Training [80][  180/  196]   Loss 0.115981   Top1 96.150174   Top5 99.878472   BatchTime 0.082469   LR 0.000100   
2022-10-20 17:19:43,266 - INFO  - ==> Top1: 96.126    Top5: 99.884    Loss: 0.116

2022-10-20 17:19:43,333 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:19:44,572 - INFO  - Validation [80][   20/   40]   Loss 0.491826   Top1 86.484375   Top5 99.140625   BatchTime 0.061930   
2022-10-20 17:19:45,110 - INFO  - Validation [80][   40/   40]   Loss 0.480279   Top1 86.670000   Top5 99.250000   BatchTime 0.044401   
2022-10-20 17:19:45,217 - INFO  - ==> Top1: 86.670    Top5: 99.250    Loss: 0.480

2022-10-20 17:19:45,217 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:19:46,955 - INFO  - Validation [80][   20/   40]   Loss 0.507562   Top1 86.542969   Top5 99.062500   BatchTime 0.086880   
2022-10-20 17:19:47,766 - INFO  - Validation [80][   40/   40]   Loss 0.496953   Top1 86.750000   Top5 99.180000   BatchTime 0.063715   
2022-10-20 17:19:47,878 - INFO  - ==> Top1: 86.750    Top5: 99.180    Loss: 0.497

2022-10-20 17:19:47,878 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:19:47,878 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:19:47,878 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:19:47,904 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:19:47,904 - INFO  - >>>>>> Epoch  81
2022-10-20 17:19:47,904 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:19:50,178 - INFO  - Training [81][   20/  196]   Loss 0.112760   Top1 96.347656   Top5 99.941406   BatchTime 0.113664   LR 0.000100   
2022-10-20 17:19:51,743 - INFO  - Training [81][   40/  196]   Loss 0.113464   Top1 96.240234   Top5 99.902344   BatchTime 0.095941   LR 0.000100   
2022-10-20 17:19:53,307 - INFO  - Training [81][   60/  196]   Loss 0.113025   Top1 96.230469   Top5 99.902344   BatchTime 0.090030   LR 0.000100   
2022-10-20 17:19:54,871 - INFO  - Training [81][   80/  196]   Loss 0.115002   Top1 96.162109   Top5 99.887695   BatchTime 0.087078   LR 0.000100   
2022-10-20 17:19:56,436 - INFO  - Training [81][  100/  196]   Loss 0.115369   Top1 96.132812   Top5 99.886719   BatchTime 0.085303   LR 0.000100   
2022-10-20 17:19:57,999 - INFO  - Training [81][  120/  196]   Loss 0.114284   Top1 96.210938   Top5 99.892578   BatchTime 0.084118   LR 0.000100   
2022-10-20 17:19:59,563 - INFO  - Training [81][  140/  196]   Loss 0.115696   Top1 96.166295   Top5 99.891183   BatchTime 0.083272   LR 0.000100   
2022-10-20 17:20:01,127 - INFO  - Training [81][  160/  196]   Loss 0.116038   Top1 96.174316   Top5 99.880371   BatchTime 0.082637   LR 0.000100   
2022-10-20 17:20:02,684 - INFO  - Training [81][  180/  196]   Loss 0.115285   Top1 96.217448   Top5 99.878472   BatchTime 0.082102   LR 0.000100   
2022-10-20 17:20:04,009 - INFO  - ==> Top1: 96.276    Top5: 99.884    Loss: 0.114

2022-10-20 17:20:04,078 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:20:05,307 - INFO  - Validation [81][   20/   40]   Loss 0.491837   Top1 86.464844   Top5 99.179688   BatchTime 0.061431   
2022-10-20 17:20:05,839 - INFO  - Validation [81][   40/   40]   Loss 0.478379   Top1 86.610000   Top5 99.290000   BatchTime 0.044029   
2022-10-20 17:20:05,945 - INFO  - ==> Top1: 86.610    Top5: 99.290    Loss: 0.478

2022-10-20 17:20:05,945 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:20:07,657 - INFO  - Validation [81][   20/   40]   Loss 0.507016   Top1 86.347656   Top5 99.062500   BatchTime 0.085572   
2022-10-20 17:20:08,460 - INFO  - Validation [81][   40/   40]   Loss 0.495080   Top1 86.550000   Top5 99.220000   BatchTime 0.062872   
2022-10-20 17:20:08,592 - INFO  - ==> Top1: 86.550    Top5: 99.220    Loss: 0.495

2022-10-20 17:20:08,593 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:20:08,593 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:20:08,593 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:20:08,660 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:20:08,661 - INFO  - >>>>>> Epoch  82
2022-10-20 17:20:08,662 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:20:11,042 - INFO  - Training [82][   20/  196]   Loss 0.116344   Top1 96.093750   Top5 99.863281   BatchTime 0.118864   LR 0.000100   
2022-10-20 17:20:12,602 - INFO  - Training [82][   40/  196]   Loss 0.115635   Top1 96.083984   Top5 99.843750   BatchTime 0.098432   LR 0.000100   
2022-10-20 17:20:14,160 - INFO  - Training [82][   60/  196]   Loss 0.115605   Top1 96.100260   Top5 99.882812   BatchTime 0.091584   LR 0.000100   
2022-10-20 17:20:15,719 - INFO  - Training [82][   80/  196]   Loss 0.114540   Top1 96.147461   Top5 99.887695   BatchTime 0.088174   LR 0.000100   
2022-10-20 17:20:17,281 - INFO  - Training [82][  100/  196]   Loss 0.114438   Top1 96.160156   Top5 99.906250   BatchTime 0.086164   LR 0.000100   
2022-10-20 17:20:18,839 - INFO  - Training [82][  120/  196]   Loss 0.114668   Top1 96.155599   Top5 99.895833   BatchTime 0.084785   LR 0.000100   
2022-10-20 17:20:20,397 - INFO  - Training [82][  140/  196]   Loss 0.113653   Top1 96.196987   Top5 99.893973   BatchTime 0.083800   LR 0.000100   
2022-10-20 17:20:21,955 - INFO  - Training [82][  160/  196]   Loss 0.113722   Top1 96.206055   Top5 99.887695   BatchTime 0.083061   LR 0.000100   
2022-10-20 17:20:23,503 - INFO  - Training [82][  180/  196]   Loss 0.113539   Top1 96.217448   Top5 99.893663   BatchTime 0.082431   LR 0.000100   
2022-10-20 17:20:24,830 - INFO  - ==> Top1: 96.210    Top5: 99.892    Loss: 0.114

2022-10-20 17:20:24,897 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:20:26,135 - INFO  - Validation [82][   20/   40]   Loss 0.494414   Top1 86.464844   Top5 99.101562   BatchTime 0.061855   
2022-10-20 17:20:26,668 - INFO  - Validation [82][   40/   40]   Loss 0.481221   Top1 86.710000   Top5 99.210000   BatchTime 0.044248   
2022-10-20 17:20:26,770 - INFO  - ==> Top1: 86.710    Top5: 99.210    Loss: 0.481

2022-10-20 17:20:26,771 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:20:28,504 - INFO  - Validation [82][   20/   40]   Loss 0.507435   Top1 86.484375   Top5 99.121094   BatchTime 0.086634   
2022-10-20 17:20:29,304 - INFO  - Validation [82][   40/   40]   Loss 0.495008   Top1 86.660000   Top5 99.250000   BatchTime 0.063313   
2022-10-20 17:20:29,410 - INFO  - ==> Top1: 86.660    Top5: 99.250    Loss: 0.495

2022-10-20 17:20:29,410 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:20:29,410 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:20:29,410 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:20:29,478 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:20:29,479 - INFO  - >>>>>> Epoch  83
2022-10-20 17:20:29,479 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:20:32,000 - INFO  - Training [83][   20/  196]   Loss 0.116533   Top1 95.996094   Top5 99.921875   BatchTime 0.126015   LR 0.000100   
2022-10-20 17:20:33,565 - INFO  - Training [83][   40/  196]   Loss 0.118125   Top1 95.771484   Top5 99.921875   BatchTime 0.102121   LR 0.000100   
2022-10-20 17:20:35,129 - INFO  - Training [83][   60/  196]   Loss 0.115506   Top1 95.911458   Top5 99.915365   BatchTime 0.094154   LR 0.000100   
2022-10-20 17:20:36,696 - INFO  - Training [83][   80/  196]   Loss 0.113556   Top1 96.074219   Top5 99.897461   BatchTime 0.090201   LR 0.000100   
2022-10-20 17:20:38,263 - INFO  - Training [83][  100/  196]   Loss 0.113931   Top1 96.105469   Top5 99.878906   BatchTime 0.087832   LR 0.000100   
2022-10-20 17:20:39,825 - INFO  - Training [83][  120/  196]   Loss 0.114862   Top1 96.080729   Top5 99.882812   BatchTime 0.086208   LR 0.000100   
2022-10-20 17:20:41,389 - INFO  - Training [83][  140/  196]   Loss 0.116051   Top1 96.040737   Top5 99.888393   BatchTime 0.085065   LR 0.000100   
2022-10-20 17:20:42,956 - INFO  - Training [83][  160/  196]   Loss 0.115072   Top1 96.098633   Top5 99.882812   BatchTime 0.084225   LR 0.000100   
2022-10-20 17:20:44,510 - INFO  - Training [83][  180/  196]   Loss 0.115715   Top1 96.100260   Top5 99.878472   BatchTime 0.083502   LR 0.000100   
2022-10-20 17:20:45,837 - INFO  - ==> Top1: 96.104    Top5: 99.876    Loss: 0.116

2022-10-20 17:20:45,904 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:20:47,131 - INFO  - Validation [83][   20/   40]   Loss 0.490244   Top1 86.347656   Top5 99.082031   BatchTime 0.061323   
2022-10-20 17:20:47,669 - INFO  - Validation [83][   40/   40]   Loss 0.477809   Top1 86.750000   Top5 99.260000   BatchTime 0.044116   
2022-10-20 17:20:47,779 - INFO  - ==> Top1: 86.750    Top5: 99.260    Loss: 0.478

2022-10-20 17:20:47,779 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:20:49,501 - INFO  - Validation [83][   20/   40]   Loss 0.511201   Top1 86.289062   Top5 99.062500   BatchTime 0.086047   
2022-10-20 17:20:50,304 - INFO  - Validation [83][   40/   40]   Loss 0.496945   Top1 86.600000   Top5 99.190000   BatchTime 0.063099   
2022-10-20 17:20:50,411 - INFO  - ==> Top1: 86.600    Top5: 99.190    Loss: 0.497

2022-10-20 17:20:50,411 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:20:50,411 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:20:50,411 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:20:50,437 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:20:50,437 - INFO  - >>>>>> Epoch  84
2022-10-20 17:20:50,437 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:20:52,731 - INFO  - Training [84][   20/  196]   Loss 0.118732   Top1 95.996094   Top5 99.804688   BatchTime 0.114631   LR 0.000100   
2022-10-20 17:20:54,297 - INFO  - Training [84][   40/  196]   Loss 0.116673   Top1 95.996094   Top5 99.853516   BatchTime 0.096457   LR 0.000100   
2022-10-20 17:20:55,861 - INFO  - Training [84][   60/  196]   Loss 0.115569   Top1 96.074219   Top5 99.850260   BatchTime 0.090381   LR 0.000100   
2022-10-20 17:20:57,426 - INFO  - Training [84][   80/  196]   Loss 0.116137   Top1 96.074219   Top5 99.863281   BatchTime 0.087339   LR 0.000100   
2022-10-20 17:20:58,990 - INFO  - Training [84][  100/  196]   Loss 0.116253   Top1 96.125000   Top5 99.871094   BatchTime 0.085511   LR 0.000100   
2022-10-20 17:21:00,554 - INFO  - Training [84][  120/  196]   Loss 0.115638   Top1 96.158854   Top5 99.869792   BatchTime 0.084296   LR 0.000100   
2022-10-20 17:21:02,119 - INFO  - Training [84][  140/  196]   Loss 0.114371   Top1 96.202567   Top5 99.871652   BatchTime 0.083431   LR 0.000100   
2022-10-20 17:21:03,683 - INFO  - Training [84][  160/  196]   Loss 0.114567   Top1 96.193848   Top5 99.868164   BatchTime 0.082778   LR 0.000100   
2022-10-20 17:21:05,238 - INFO  - Training [84][  180/  196]   Loss 0.115254   Top1 96.206597   Top5 99.878472   BatchTime 0.082216   LR 0.000100   
2022-10-20 17:21:06,569 - INFO  - ==> Top1: 96.232    Top5: 99.878    Loss: 0.114

2022-10-20 17:21:06,638 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:21:07,898 - INFO  - Validation [84][   20/   40]   Loss 0.499033   Top1 86.230469   Top5 99.179688   BatchTime 0.062976   
2022-10-20 17:21:08,437 - INFO  - Validation [84][   40/   40]   Loss 0.485507   Top1 86.500000   Top5 99.270000   BatchTime 0.044955   
2022-10-20 17:21:08,554 - INFO  - ==> Top1: 86.500    Top5: 99.270    Loss: 0.486

2022-10-20 17:21:08,555 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:21:10,271 - INFO  - Validation [84][   20/   40]   Loss 0.517075   Top1 86.132812   Top5 99.062500   BatchTime 0.085795   
2022-10-20 17:21:11,072 - INFO  - Validation [84][   40/   40]   Loss 0.505740   Top1 86.370000   Top5 99.190000   BatchTime 0.062914   
2022-10-20 17:21:11,193 - INFO  - ==> Top1: 86.370    Top5: 99.190    Loss: 0.506

2022-10-20 17:21:11,193 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:21:11,193 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:21:11,193 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:21:11,242 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:21:11,242 - INFO  - >>>>>> Epoch  85
2022-10-20 17:21:11,242 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:21:13,556 - INFO  - Training [85][   20/  196]   Loss 0.112039   Top1 96.015625   Top5 99.843750   BatchTime 0.115654   LR 0.000100   
2022-10-20 17:21:15,124 - INFO  - Training [85][   40/  196]   Loss 0.113845   Top1 96.113281   Top5 99.873047   BatchTime 0.097041   LR 0.000100   
2022-10-20 17:21:16,702 - INFO  - Training [85][   60/  196]   Loss 0.114762   Top1 96.191406   Top5 99.889323   BatchTime 0.090982   LR 0.000100   
2022-10-20 17:21:18,274 - INFO  - Training [85][   80/  196]   Loss 0.116703   Top1 96.127930   Top5 99.892578   BatchTime 0.087887   LR 0.000100   
2022-10-20 17:21:19,840 - INFO  - Training [85][  100/  196]   Loss 0.115796   Top1 96.167969   Top5 99.890625   BatchTime 0.085967   LR 0.000100   
2022-10-20 17:21:21,404 - INFO  - Training [85][  120/  196]   Loss 0.115215   Top1 96.139323   Top5 99.902344   BatchTime 0.084679   LR 0.000100   
2022-10-20 17:21:22,970 - INFO  - Training [85][  140/  196]   Loss 0.114678   Top1 96.174665   Top5 99.902344   BatchTime 0.083761   LR 0.000100   
2022-10-20 17:21:24,534 - INFO  - Training [85][  160/  196]   Loss 0.114363   Top1 96.201172   Top5 99.890137   BatchTime 0.083070   LR 0.000100   
2022-10-20 17:21:26,089 - INFO  - Training [85][  180/  196]   Loss 0.112832   Top1 96.265191   Top5 99.887153   BatchTime 0.082478   LR 0.000100   
2022-10-20 17:21:27,415 - INFO  - ==> Top1: 96.260    Top5: 99.890    Loss: 0.113

2022-10-20 17:21:27,481 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:21:28,732 - INFO  - Validation [85][   20/   40]   Loss 0.502172   Top1 86.562500   Top5 99.140625   BatchTime 0.062495   
2022-10-20 17:21:29,271 - INFO  - Validation [85][   40/   40]   Loss 0.485554   Top1 86.680000   Top5 99.250000   BatchTime 0.044725   
2022-10-20 17:21:29,375 - INFO  - ==> Top1: 86.680    Top5: 99.250    Loss: 0.486

2022-10-20 17:21:29,375 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:21:31,073 - INFO  - Validation [85][   20/   40]   Loss 0.517918   Top1 86.503906   Top5 99.042969   BatchTime 0.084857   
2022-10-20 17:21:31,877 - INFO  - Validation [85][   40/   40]   Loss 0.502142   Top1 86.600000   Top5 99.180000   BatchTime 0.062539   
2022-10-20 17:21:32,000 - INFO  - ==> Top1: 86.600    Top5: 99.180    Loss: 0.502

2022-10-20 17:21:32,000 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:21:32,000 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:21:32,000 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:21:32,069 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:21:32,069 - INFO  - >>>>>> Epoch  86
2022-10-20 17:21:32,069 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:21:34,406 - INFO  - Training [86][   20/  196]   Loss 0.114079   Top1 96.406250   Top5 99.863281   BatchTime 0.116781   LR 0.000100   
2022-10-20 17:21:35,972 - INFO  - Training [86][   40/  196]   Loss 0.118761   Top1 96.269531   Top5 99.833984   BatchTime 0.097555   LR 0.000100   
2022-10-20 17:21:37,537 - INFO  - Training [86][   60/  196]   Loss 0.116695   Top1 96.289062   Top5 99.850260   BatchTime 0.091115   LR 0.000100   
2022-10-20 17:21:39,102 - INFO  - Training [86][   80/  196]   Loss 0.115997   Top1 96.250000   Top5 99.863281   BatchTime 0.087896   LR 0.000100   
2022-10-20 17:21:40,665 - INFO  - Training [86][  100/  196]   Loss 0.114622   Top1 96.281250   Top5 99.867188   BatchTime 0.085949   LR 0.000100   
2022-10-20 17:21:42,228 - INFO  - Training [86][  120/  196]   Loss 0.113548   Top1 96.295573   Top5 99.876302   BatchTime 0.084651   LR 0.000100   
2022-10-20 17:21:43,792 - INFO  - Training [86][  140/  196]   Loss 0.115461   Top1 96.233259   Top5 99.860491   BatchTime 0.083724   LR 0.000100   
2022-10-20 17:21:45,355 - INFO  - Training [86][  160/  196]   Loss 0.114826   Top1 96.264648   Top5 99.863281   BatchTime 0.083030   LR 0.000100   
2022-10-20 17:21:46,914 - INFO  - Training [86][  180/  196]   Loss 0.114171   Top1 96.267361   Top5 99.867622   BatchTime 0.082464   LR 0.000100   
2022-10-20 17:21:48,245 - INFO  - ==> Top1: 96.304    Top5: 99.868    Loss: 0.113

2022-10-20 17:21:48,314 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:21:49,555 - INFO  - Validation [86][   20/   40]   Loss 0.494507   Top1 86.757812   Top5 99.218750   BatchTime 0.062018   
2022-10-20 17:21:50,091 - INFO  - Validation [86][   40/   40]   Loss 0.480827   Top1 86.790000   Top5 99.300000   BatchTime 0.044424   
2022-10-20 17:21:50,198 - INFO  - ==> Top1: 86.790    Top5: 99.300    Loss: 0.481

2022-10-20 17:21:50,199 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:21:51,907 - INFO  - Validation [86][   20/   40]   Loss 0.509788   Top1 86.523438   Top5 99.082031   BatchTime 0.085409   
2022-10-20 17:21:52,709 - INFO  - Validation [86][   40/   40]   Loss 0.499288   Top1 86.710000   Top5 99.170000   BatchTime 0.062745   
2022-10-20 17:21:52,822 - INFO  - ==> Top1: 86.710    Top5: 99.170    Loss: 0.499

2022-10-20 17:21:52,822 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:21:52,822 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:21:52,822 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:21:52,874 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:21:52,875 - INFO  - >>>>>> Epoch  87
2022-10-20 17:21:52,875 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:21:55,169 - INFO  - Training [87][   20/  196]   Loss 0.109477   Top1 96.601562   Top5 99.843750   BatchTime 0.114655   LR 0.000100   
2022-10-20 17:21:56,735 - INFO  - Training [87][   40/  196]   Loss 0.112557   Top1 96.455078   Top5 99.814453   BatchTime 0.096475   LR 0.000100   
2022-10-20 17:21:58,305 - INFO  - Training [87][   60/  196]   Loss 0.114281   Top1 96.321615   Top5 99.837240   BatchTime 0.090493   LR 0.000100   
2022-10-20 17:21:59,869 - INFO  - Training [87][   80/  196]   Loss 0.113556   Top1 96.284180   Top5 99.853516   BatchTime 0.087419   LR 0.000100   
2022-10-20 17:22:01,433 - INFO  - Training [87][  100/  196]   Loss 0.112422   Top1 96.363281   Top5 99.855469   BatchTime 0.085573   LR 0.000100   
2022-10-20 17:22:02,997 - INFO  - Training [87][  120/  196]   Loss 0.113769   Top1 96.318359   Top5 99.850260   BatchTime 0.084342   LR 0.000100   
2022-10-20 17:22:04,561 - INFO  - Training [87][  140/  196]   Loss 0.115054   Top1 96.238839   Top5 99.854911   BatchTime 0.083464   LR 0.000100   
2022-10-20 17:22:06,124 - INFO  - Training [87][  160/  196]   Loss 0.113915   Top1 96.262207   Top5 99.865723   BatchTime 0.082803   LR 0.000100   
2022-10-20 17:22:07,679 - INFO  - Training [87][  180/  196]   Loss 0.114189   Top1 96.269531   Top5 99.858941   BatchTime 0.082241   LR 0.000100   
2022-10-20 17:22:09,012 - INFO  - ==> Top1: 96.292    Top5: 99.862    Loss: 0.114

2022-10-20 17:22:09,078 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:22:10,311 - INFO  - Validation [87][   20/   40]   Loss 0.495974   Top1 86.464844   Top5 99.140625   BatchTime 0.061648   
2022-10-20 17:22:10,847 - INFO  - Validation [87][   40/   40]   Loss 0.479299   Top1 86.650000   Top5 99.300000   BatchTime 0.044212   
2022-10-20 17:22:10,949 - INFO  - ==> Top1: 86.650    Top5: 99.300    Loss: 0.479

2022-10-20 17:22:10,949 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:22:12,659 - INFO  - Validation [87][   20/   40]   Loss 0.512875   Top1 86.328125   Top5 99.140625   BatchTime 0.085457   
2022-10-20 17:22:13,461 - INFO  - Validation [87][   40/   40]   Loss 0.495521   Top1 86.730000   Top5 99.260000   BatchTime 0.062783   
2022-10-20 17:22:13,576 - INFO  - ==> Top1: 86.730    Top5: 99.260    Loss: 0.496

2022-10-20 17:22:13,576 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:22:13,576 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:22:13,576 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:22:13,640 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:22:13,641 - INFO  - >>>>>> Epoch  88
2022-10-20 17:22:13,641 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:22:15,944 - INFO  - Training [88][   20/  196]   Loss 0.110000   Top1 96.269531   Top5 99.921875   BatchTime 0.115101   LR 0.000100   
2022-10-20 17:22:17,517 - INFO  - Training [88][   40/  196]   Loss 0.108353   Top1 96.347656   Top5 99.902344   BatchTime 0.096891   LR 0.000100   
2022-10-20 17:22:19,084 - INFO  - Training [88][   60/  196]   Loss 0.112187   Top1 96.269531   Top5 99.876302   BatchTime 0.090706   LR 0.000100   
2022-10-20 17:22:20,648 - INFO  - Training [88][   80/  196]   Loss 0.114750   Top1 96.166992   Top5 99.873047   BatchTime 0.087580   LR 0.000100   
2022-10-20 17:22:22,212 - INFO  - Training [88][  100/  196]   Loss 0.115631   Top1 96.164062   Top5 99.871094   BatchTime 0.085708   LR 0.000100   
2022-10-20 17:22:23,777 - INFO  - Training [88][  120/  196]   Loss 0.114941   Top1 96.188151   Top5 99.876302   BatchTime 0.084460   LR 0.000100   
2022-10-20 17:22:25,341 - INFO  - Training [88][  140/  196]   Loss 0.115403   Top1 96.196987   Top5 99.877232   BatchTime 0.083567   LR 0.000100   
2022-10-20 17:22:26,905 - INFO  - Training [88][  160/  196]   Loss 0.114898   Top1 96.225586   Top5 99.868164   BatchTime 0.082896   LR 0.000100   
2022-10-20 17:22:28,460 - INFO  - Training [88][  180/  196]   Loss 0.114943   Top1 96.236979   Top5 99.876302   BatchTime 0.082323   LR 0.000100   
2022-10-20 17:22:29,789 - INFO  - ==> Top1: 96.284    Top5: 99.880    Loss: 0.114

2022-10-20 17:22:29,862 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:22:31,125 - INFO  - Validation [88][   20/   40]   Loss 0.495635   Top1 86.191406   Top5 99.042969   BatchTime 0.063142   
2022-10-20 17:22:31,663 - INFO  - Validation [88][   40/   40]   Loss 0.479911   Top1 86.490000   Top5 99.220000   BatchTime 0.045011   
2022-10-20 17:22:31,769 - INFO  - ==> Top1: 86.490    Top5: 99.220    Loss: 0.480

2022-10-20 17:22:31,769 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:22:33,485 - INFO  - Validation [88][   20/   40]   Loss 0.513973   Top1 85.996094   Top5 98.964844   BatchTime 0.085777   
2022-10-20 17:22:34,288 - INFO  - Validation [88][   40/   40]   Loss 0.498167   Top1 86.350000   Top5 99.180000   BatchTime 0.062954   
2022-10-20 17:22:34,399 - INFO  - ==> Top1: 86.350    Top5: 99.180    Loss: 0.498

2022-10-20 17:22:34,399 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:22:34,399 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:22:34,399 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:22:34,451 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:22:34,451 - INFO  - >>>>>> Epoch  89
2022-10-20 17:22:34,451 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:22:36,729 - INFO  - Training [89][   20/  196]   Loss 0.110395   Top1 96.113281   Top5 99.902344   BatchTime 0.113824   LR 0.000100   
2022-10-20 17:22:38,291 - INFO  - Training [89][   40/  196]   Loss 0.119128   Top1 95.976562   Top5 99.902344   BatchTime 0.095981   LR 0.000100   
2022-10-20 17:22:39,852 - INFO  - Training [89][   60/  196]   Loss 0.118590   Top1 96.028646   Top5 99.902344   BatchTime 0.089995   LR 0.000100   
2022-10-20 17:22:41,411 - INFO  - Training [89][   80/  196]   Loss 0.121028   Top1 95.922852   Top5 99.887695   BatchTime 0.086991   LR 0.000100   
2022-10-20 17:22:42,971 - INFO  - Training [89][  100/  196]   Loss 0.119043   Top1 96.035156   Top5 99.890625   BatchTime 0.085184   LR 0.000100   
2022-10-20 17:22:44,530 - INFO  - Training [89][  120/  196]   Loss 0.117010   Top1 96.136068   Top5 99.899089   BatchTime 0.083983   LR 0.000100   
2022-10-20 17:22:46,090 - INFO  - Training [89][  140/  196]   Loss 0.118316   Top1 96.054688   Top5 99.907924   BatchTime 0.083125   LR 0.000100   
2022-10-20 17:22:47,649 - INFO  - Training [89][  160/  196]   Loss 0.117086   Top1 96.123047   Top5 99.897461   BatchTime 0.082476   LR 0.000100   
2022-10-20 17:22:49,198 - INFO  - Training [89][  180/  196]   Loss 0.118133   Top1 96.085069   Top5 99.891493   BatchTime 0.081919   LR 0.000100   
2022-10-20 17:22:50,531 - INFO  - ==> Top1: 96.108    Top5: 99.892    Loss: 0.118

2022-10-20 17:22:50,597 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:22:51,830 - INFO  - Validation [89][   20/   40]   Loss 0.497295   Top1 86.289062   Top5 99.082031   BatchTime 0.061622   
2022-10-20 17:22:52,363 - INFO  - Validation [89][   40/   40]   Loss 0.482170   Top1 86.560000   Top5 99.250000   BatchTime 0.044130   
2022-10-20 17:22:52,467 - INFO  - ==> Top1: 86.560    Top5: 99.250    Loss: 0.482

2022-10-20 17:22:52,467 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:22:54,170 - INFO  - Validation [89][   20/   40]   Loss 0.516554   Top1 86.269531   Top5 99.062500   BatchTime 0.085137   
2022-10-20 17:22:54,970 - INFO  - Validation [89][   40/   40]   Loss 0.500158   Top1 86.460000   Top5 99.180000   BatchTime 0.062565   
2022-10-20 17:22:55,077 - INFO  - ==> Top1: 86.460    Top5: 99.180    Loss: 0.500

2022-10-20 17:22:55,077 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:22:55,077 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:22:55,077 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:22:55,128 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:22:55,129 - INFO  - >>>>>> Epoch  90
2022-10-20 17:22:55,129 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:22:57,415 - INFO  - Training [90][   20/  196]   Loss 0.117778   Top1 96.191406   Top5 99.804688   BatchTime 0.114266   LR 0.000010   
2022-10-20 17:22:58,974 - INFO  - Training [90][   40/  196]   Loss 0.116525   Top1 96.259766   Top5 99.843750   BatchTime 0.096103   LR 0.000010   
2022-10-20 17:23:00,533 - INFO  - Training [90][   60/  196]   Loss 0.116754   Top1 96.302083   Top5 99.824219   BatchTime 0.090058   LR 0.000010   
2022-10-20 17:23:02,091 - INFO  - Training [90][   80/  196]   Loss 0.115759   Top1 96.181641   Top5 99.843750   BatchTime 0.087020   LR 0.000010   
2022-10-20 17:23:03,650 - INFO  - Training [90][  100/  196]   Loss 0.115517   Top1 96.203125   Top5 99.835938   BatchTime 0.085201   LR 0.000010   
2022-10-20 17:23:05,208 - INFO  - Training [90][  120/  196]   Loss 0.114575   Top1 96.214193   Top5 99.853516   BatchTime 0.083989   LR 0.000010   
2022-10-20 17:23:06,766 - INFO  - Training [90][  140/  196]   Loss 0.113580   Top1 96.250000   Top5 99.863281   BatchTime 0.083119   LR 0.000010   
2022-10-20 17:23:08,325 - INFO  - Training [90][  160/  196]   Loss 0.112681   Top1 96.279297   Top5 99.870605   BatchTime 0.082469   LR 0.000010   
2022-10-20 17:23:09,873 - INFO  - Training [90][  180/  196]   Loss 0.111951   Top1 96.317274   Top5 99.874132   BatchTime 0.081906   LR 0.000010   
2022-10-20 17:23:11,187 - INFO  - ==> Top1: 96.300    Top5: 99.872    Loss: 0.112

2022-10-20 17:23:11,259 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:23:12,486 - INFO  - Validation [90][   20/   40]   Loss 0.494096   Top1 86.425781   Top5 99.082031   BatchTime 0.061345   
2022-10-20 17:23:13,025 - INFO  - Validation [90][   40/   40]   Loss 0.482954   Top1 86.540000   Top5 99.240000   BatchTime 0.044140   
2022-10-20 17:23:13,133 - INFO  - ==> Top1: 86.540    Top5: 99.240    Loss: 0.483

2022-10-20 17:23:13,133 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:23:14,850 - INFO  - Validation [90][   20/   40]   Loss 0.512894   Top1 86.191406   Top5 99.121094   BatchTime 0.085829   
2022-10-20 17:23:15,664 - INFO  - Validation [90][   40/   40]   Loss 0.501383   Top1 86.510000   Top5 99.220000   BatchTime 0.063255   
2022-10-20 17:23:15,787 - INFO  - ==> Top1: 86.510    Top5: 99.220    Loss: 0.501

2022-10-20 17:23:15,787 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:23:15,788 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:23:15,788 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:23:15,840 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:23:15,841 - INFO  - >>>>>> Epoch  91
2022-10-20 17:23:15,842 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:23:18,210 - INFO  - Training [91][   20/  196]   Loss 0.103165   Top1 96.679688   Top5 99.902344   BatchTime 0.118286   LR 0.000010   
2022-10-20 17:23:19,775 - INFO  - Training [91][   40/  196]   Loss 0.108519   Top1 96.591797   Top5 99.853516   BatchTime 0.098248   LR 0.000010   
2022-10-20 17:23:21,337 - INFO  - Training [91][   60/  196]   Loss 0.108892   Top1 96.510417   Top5 99.837240   BatchTime 0.091533   LR 0.000010   
2022-10-20 17:23:22,897 - INFO  - Training [91][   80/  196]   Loss 0.110014   Top1 96.420898   Top5 99.858398   BatchTime 0.088158   LR 0.000010   
2022-10-20 17:23:24,458 - INFO  - Training [91][  100/  196]   Loss 0.110231   Top1 96.398438   Top5 99.867188   BatchTime 0.086135   LR 0.000010   
2022-10-20 17:23:26,019 - INFO  - Training [91][  120/  196]   Loss 0.110808   Top1 96.344401   Top5 99.866536   BatchTime 0.084786   LR 0.000010   
2022-10-20 17:23:27,580 - INFO  - Training [91][  140/  196]   Loss 0.110920   Top1 96.325335   Top5 99.871652   BatchTime 0.083825   LR 0.000010   
2022-10-20 17:23:29,142 - INFO  - Training [91][  160/  196]   Loss 0.111026   Top1 96.315918   Top5 99.875488   BatchTime 0.083105   LR 0.000010   
2022-10-20 17:23:30,693 - INFO  - Training [91][  180/  196]   Loss 0.111069   Top1 96.330295   Top5 99.880642   BatchTime 0.082489   LR 0.000010   
2022-10-20 17:23:32,015 - INFO  - ==> Top1: 96.270    Top5: 99.876    Loss: 0.112

2022-10-20 17:23:32,081 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:23:33,316 - INFO  - Validation [91][   20/   40]   Loss 0.495377   Top1 86.679688   Top5 99.160156   BatchTime 0.061717   
2022-10-20 17:23:33,854 - INFO  - Validation [91][   40/   40]   Loss 0.484584   Top1 86.750000   Top5 99.320000   BatchTime 0.044309   
2022-10-20 17:23:33,956 - INFO  - ==> Top1: 86.750    Top5: 99.320    Loss: 0.485

2022-10-20 17:23:33,956 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:23:35,666 - INFO  - Validation [91][   20/   40]   Loss 0.514241   Top1 86.445312   Top5 99.062500   BatchTime 0.085448   
2022-10-20 17:23:36,474 - INFO  - Validation [91][   40/   40]   Loss 0.503406   Top1 86.600000   Top5 99.220000   BatchTime 0.062933   
2022-10-20 17:23:36,591 - INFO  - ==> Top1: 86.600    Top5: 99.220    Loss: 0.503

2022-10-20 17:23:36,591 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:23:36,591 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:23:36,591 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:23:36,644 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:23:36,644 - INFO  - >>>>>> Epoch  92
2022-10-20 17:23:36,644 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:23:38,934 - INFO  - Training [92][   20/  196]   Loss 0.109495   Top1 96.562500   Top5 99.824219   BatchTime 0.114475   LR 0.000010   
2022-10-20 17:23:40,499 - INFO  - Training [92][   40/  196]   Loss 0.109221   Top1 96.484375   Top5 99.882812   BatchTime 0.096346   LR 0.000010   
2022-10-20 17:23:42,063 - INFO  - Training [92][   60/  196]   Loss 0.109376   Top1 96.451823   Top5 99.876302   BatchTime 0.090297   LR 0.000010   
2022-10-20 17:23:43,627 - INFO  - Training [92][   80/  196]   Loss 0.110594   Top1 96.396484   Top5 99.892578   BatchTime 0.087277   LR 0.000010   
2022-10-20 17:23:45,191 - INFO  - Training [92][  100/  196]   Loss 0.112045   Top1 96.300781   Top5 99.898438   BatchTime 0.085465   LR 0.000010   
2022-10-20 17:23:46,756 - INFO  - Training [92][  120/  196]   Loss 0.112139   Top1 96.243490   Top5 99.902344   BatchTime 0.084257   LR 0.000010   
2022-10-20 17:23:48,320 - INFO  - Training [92][  140/  196]   Loss 0.114614   Top1 96.149554   Top5 99.877232   BatchTime 0.083394   LR 0.000010   
2022-10-20 17:23:49,885 - INFO  - Training [92][  160/  196]   Loss 0.115567   Top1 96.137695   Top5 99.868164   BatchTime 0.082748   LR 0.000010   
2022-10-20 17:23:51,440 - INFO  - Training [92][  180/  196]   Loss 0.115112   Top1 96.189236   Top5 99.869792   BatchTime 0.082191   LR 0.000010   
2022-10-20 17:23:52,764 - INFO  - ==> Top1: 96.182    Top5: 99.874    Loss: 0.115

2022-10-20 17:23:52,837 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:23:54,214 - INFO  - Validation [92][   20/   40]   Loss 0.501381   Top1 86.386719   Top5 99.062500   BatchTime 0.068774   
2022-10-20 17:23:54,750 - INFO  - Validation [92][   40/   40]   Loss 0.484123   Top1 86.570000   Top5 99.230000   BatchTime 0.047793   
2022-10-20 17:23:54,856 - INFO  - ==> Top1: 86.570    Top5: 99.230    Loss: 0.484

2022-10-20 17:23:54,856 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:23:56,566 - INFO  - Validation [92][   20/   40]   Loss 0.519865   Top1 86.445312   Top5 99.042969   BatchTime 0.085459   
2022-10-20 17:23:57,369 - INFO  - Validation [92][   40/   40]   Loss 0.505305   Top1 86.680000   Top5 99.190000   BatchTime 0.062810   
2022-10-20 17:23:57,482 - INFO  - ==> Top1: 86.680    Top5: 99.190    Loss: 0.505

2022-10-20 17:23:57,483 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:23:57,483 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:23:57,483 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:23:57,535 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:23:57,536 - INFO  - >>>>>> Epoch  93
2022-10-20 17:23:57,536 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:23:59,842 - INFO  - Training [93][   20/  196]   Loss 0.107492   Top1 96.699219   Top5 99.902344   BatchTime 0.115259   LR 0.000010   
2022-10-20 17:24:01,405 - INFO  - Training [93][   40/  196]   Loss 0.111016   Top1 96.542969   Top5 99.863281   BatchTime 0.096705   LR 0.000010   
2022-10-20 17:24:02,967 - INFO  - Training [93][   60/  196]   Loss 0.114676   Top1 96.315104   Top5 99.863281   BatchTime 0.090506   LR 0.000010   
2022-10-20 17:24:04,529 - INFO  - Training [93][   80/  196]   Loss 0.111946   Top1 96.386719   Top5 99.873047   BatchTime 0.087401   LR 0.000010   
2022-10-20 17:24:06,093 - INFO  - Training [93][  100/  196]   Loss 0.110909   Top1 96.417969   Top5 99.890625   BatchTime 0.085566   LR 0.000010   
2022-10-20 17:24:07,661 - INFO  - Training [93][  120/  196]   Loss 0.111014   Top1 96.386719   Top5 99.895833   BatchTime 0.084372   LR 0.000010   
2022-10-20 17:24:09,233 - INFO  - Training [93][  140/  196]   Loss 0.113038   Top1 96.319754   Top5 99.893973   BatchTime 0.083544   LR 0.000010   
2022-10-20 17:24:10,793 - INFO  - Training [93][  160/  196]   Loss 0.113518   Top1 96.293945   Top5 99.899902   BatchTime 0.082852   LR 0.000010   
2022-10-20 17:24:12,350 - INFO  - Training [93][  180/  196]   Loss 0.113844   Top1 96.263021   Top5 99.900174   BatchTime 0.082292   LR 0.000010   
2022-10-20 17:24:13,685 - INFO  - ==> Top1: 96.284    Top5: 99.902    Loss: 0.114

2022-10-20 17:24:13,752 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:24:14,999 - INFO  - Validation [93][   20/   40]   Loss 0.497306   Top1 86.347656   Top5 99.121094   BatchTime 0.062316   
2022-10-20 17:24:15,534 - INFO  - Validation [93][   40/   40]   Loss 0.481122   Top1 86.630000   Top5 99.230000   BatchTime 0.044519   
2022-10-20 17:24:15,646 - INFO  - ==> Top1: 86.630    Top5: 99.230    Loss: 0.481

2022-10-20 17:24:15,646 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:24:17,443 - INFO  - Validation [93][   20/   40]   Loss 0.515120   Top1 86.347656   Top5 99.082031   BatchTime 0.089811   
2022-10-20 17:24:18,258 - INFO  - Validation [93][   40/   40]   Loss 0.499770   Top1 86.530000   Top5 99.170000   BatchTime 0.065290   
2022-10-20 17:24:18,379 - INFO  - ==> Top1: 86.530    Top5: 99.170    Loss: 0.500

2022-10-20 17:24:18,379 - INFO  - Scoreboard best 1 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:24:18,379 - INFO  - Scoreboard best 2 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:24:18,379 - INFO  - Scoreboard best 3 ==> Epoch [80][Top1: 86.750   Top5: 99.180]
2022-10-20 17:24:18,429 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:24:18,429 - INFO  - >>>>>> Epoch  94
2022-10-20 17:24:18,429 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:24:20,735 - INFO  - Training [94][   20/  196]   Loss 0.113757   Top1 96.250000   Top5 99.921875   BatchTime 0.115254   LR 0.000010   
2022-10-20 17:24:22,300 - INFO  - Training [94][   40/  196]   Loss 0.113676   Top1 96.240234   Top5 99.902344   BatchTime 0.096746   LR 0.000010   
2022-10-20 17:24:23,865 - INFO  - Training [94][   60/  196]   Loss 0.114370   Top1 96.276042   Top5 99.889323   BatchTime 0.090574   LR 0.000010   
2022-10-20 17:24:25,429 - INFO  - Training [94][   80/  196]   Loss 0.112662   Top1 96.289062   Top5 99.877930   BatchTime 0.087480   LR 0.000010   
2022-10-20 17:24:26,993 - INFO  - Training [94][  100/  196]   Loss 0.112362   Top1 96.285156   Top5 99.890625   BatchTime 0.085630   LR 0.000010   
2022-10-20 17:24:28,558 - INFO  - Training [94][  120/  196]   Loss 0.112816   Top1 96.250000   Top5 99.882812   BatchTime 0.084394   LR 0.000010   
2022-10-20 17:24:30,122 - INFO  - Training [94][  140/  196]   Loss 0.113195   Top1 96.275112   Top5 99.885603   BatchTime 0.083511   LR 0.000010   
2022-10-20 17:24:31,687 - INFO  - Training [94][  160/  196]   Loss 0.112477   Top1 96.291504   Top5 99.885254   BatchTime 0.082850   LR 0.000010   
2022-10-20 17:24:33,241 - INFO  - Training [94][  180/  196]   Loss 0.111855   Top1 96.328125   Top5 99.884983   BatchTime 0.082281   LR 0.000010   
2022-10-20 17:24:34,562 - INFO  - ==> Top1: 96.288    Top5: 99.882    Loss: 0.113

2022-10-20 17:24:34,634 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:24:35,864 - INFO  - Validation [94][   20/   40]   Loss 0.499345   Top1 86.425781   Top5 99.062500   BatchTime 0.061483   
2022-10-20 17:24:36,402 - INFO  - Validation [94][   40/   40]   Loss 0.482758   Top1 86.760000   Top5 99.260000   BatchTime 0.044194   
2022-10-20 17:24:36,506 - INFO  - ==> Top1: 86.760    Top5: 99.260    Loss: 0.483

2022-10-20 17:24:36,506 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:24:38,246 - INFO  - Validation [94][   20/   40]   Loss 0.518045   Top1 86.542969   Top5 99.179688   BatchTime 0.087006   
2022-10-20 17:24:39,046 - INFO  - Validation [94][   40/   40]   Loss 0.498329   Top1 86.810000   Top5 99.290000   BatchTime 0.063496   
2022-10-20 17:24:39,168 - INFO  - ==> Top1: 86.810    Top5: 99.290    Loss: 0.498

2022-10-20 17:24:39,168 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:24:39,168 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:24:39,169 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:24:41,094 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_best.pth.tar
save quantized models...
2022-10-20 17:24:41,095 - INFO  - >>>>>> Epoch  95
2022-10-20 17:24:41,096 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:24:43,416 - INFO  - Training [95][   20/  196]   Loss 0.108814   Top1 96.347656   Top5 99.941406   BatchTime 0.115886   LR 0.000010   
2022-10-20 17:24:44,980 - INFO  - Training [95][   40/  196]   Loss 0.107810   Top1 96.455078   Top5 99.941406   BatchTime 0.097037   LR 0.000010   
2022-10-20 17:24:46,543 - INFO  - Training [95][   60/  196]   Loss 0.109910   Top1 96.432292   Top5 99.928385   BatchTime 0.090743   LR 0.000010   
2022-10-20 17:24:48,101 - INFO  - Training [95][   80/  196]   Loss 0.111808   Top1 96.298828   Top5 99.926758   BatchTime 0.087529   LR 0.000010   
2022-10-20 17:24:49,662 - INFO  - Training [95][  100/  196]   Loss 0.110877   Top1 96.343750   Top5 99.910156   BatchTime 0.085632   LR 0.000010   
2022-10-20 17:24:51,222 - INFO  - Training [95][  120/  196]   Loss 0.111458   Top1 96.292318   Top5 99.895833   BatchTime 0.084364   LR 0.000010   
2022-10-20 17:24:52,786 - INFO  - Training [95][  140/  196]   Loss 0.111682   Top1 96.314174   Top5 99.893973   BatchTime 0.083479   LR 0.000010   
2022-10-20 17:24:54,343 - INFO  - Training [95][  160/  196]   Loss 0.111800   Top1 96.267090   Top5 99.885254   BatchTime 0.082775   LR 0.000010   
2022-10-20 17:24:55,894 - INFO  - Training [95][  180/  196]   Loss 0.113128   Top1 96.174045   Top5 99.880642   BatchTime 0.082197   LR 0.000010   
2022-10-20 17:24:57,227 - INFO  - ==> Top1: 96.200    Top5: 99.876    Loss: 0.113

2022-10-20 17:24:57,294 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:24:58,517 - INFO  - Validation [95][   20/   40]   Loss 0.499337   Top1 86.445312   Top5 99.179688   BatchTime 0.061098   
2022-10-20 17:24:59,055 - INFO  - Validation [95][   40/   40]   Loss 0.483546   Top1 86.690000   Top5 99.270000   BatchTime 0.044001   
2022-10-20 17:24:59,153 - INFO  - ==> Top1: 86.690    Top5: 99.270    Loss: 0.484

2022-10-20 17:24:59,154 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:25:00,895 - INFO  - Validation [95][   20/   40]   Loss 0.515827   Top1 86.406250   Top5 99.042969   BatchTime 0.087027   
2022-10-20 17:25:01,700 - INFO  - Validation [95][   40/   40]   Loss 0.501133   Top1 86.610000   Top5 99.180000   BatchTime 0.063656   
2022-10-20 17:25:01,809 - INFO  - ==> Top1: 86.610    Top5: 99.180    Loss: 0.501

2022-10-20 17:25:01,810 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:25:01,810 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:25:01,810 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:25:01,868 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:25:01,868 - INFO  - >>>>>> Epoch  96
2022-10-20 17:25:01,868 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:25:04,149 - INFO  - Training [96][   20/  196]   Loss 0.120134   Top1 95.898438   Top5 99.843750   BatchTime 0.114007   LR 0.000010   
2022-10-20 17:25:05,712 - INFO  - Training [96][   40/  196]   Loss 0.114812   Top1 96.191406   Top5 99.853516   BatchTime 0.096087   LR 0.000010   
2022-10-20 17:25:07,279 - INFO  - Training [96][   60/  196]   Loss 0.117445   Top1 96.035156   Top5 99.869792   BatchTime 0.090173   LR 0.000010   
2022-10-20 17:25:08,838 - INFO  - Training [96][   80/  196]   Loss 0.118855   Top1 95.986328   Top5 99.863281   BatchTime 0.087114   LR 0.000010   
2022-10-20 17:25:10,401 - INFO  - Training [96][  100/  196]   Loss 0.116361   Top1 96.058594   Top5 99.871094   BatchTime 0.085321   LR 0.000010   
2022-10-20 17:25:11,964 - INFO  - Training [96][  120/  196]   Loss 0.115246   Top1 96.116536   Top5 99.873047   BatchTime 0.084125   LR 0.000010   
2022-10-20 17:25:13,531 - INFO  - Training [96][  140/  196]   Loss 0.115352   Top1 96.085379   Top5 99.868862   BatchTime 0.083300   LR 0.000010   
2022-10-20 17:25:15,090 - INFO  - Training [96][  160/  196]   Loss 0.114051   Top1 96.154785   Top5 99.875488   BatchTime 0.082629   LR 0.000010   
2022-10-20 17:25:16,658 - INFO  - Training [96][  180/  196]   Loss 0.114007   Top1 96.176215   Top5 99.878472   BatchTime 0.082158   LR 0.000010   
2022-10-20 17:25:17,984 - INFO  - ==> Top1: 96.178    Top5: 99.878    Loss: 0.114

2022-10-20 17:25:18,057 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:25:19,299 - INFO  - Validation [96][   20/   40]   Loss 0.499067   Top1 86.406250   Top5 99.082031   BatchTime 0.062059   
2022-10-20 17:25:19,837 - INFO  - Validation [96][   40/   40]   Loss 0.482436   Top1 86.580000   Top5 99.230000   BatchTime 0.044484   
2022-10-20 17:25:19,935 - INFO  - ==> Top1: 86.580    Top5: 99.230    Loss: 0.482

2022-10-20 17:25:19,935 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:25:21,657 - INFO  - Validation [96][   20/   40]   Loss 0.513110   Top1 86.230469   Top5 99.101562   BatchTime 0.086038   
2022-10-20 17:25:22,464 - INFO  - Validation [96][   40/   40]   Loss 0.497442   Top1 86.520000   Top5 99.260000   BatchTime 0.063196   
2022-10-20 17:25:22,593 - INFO  - ==> Top1: 86.520    Top5: 99.260    Loss: 0.497

2022-10-20 17:25:22,593 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:25:22,593 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:25:22,593 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:25:22,647 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:25:22,648 - INFO  - >>>>>> Epoch  97
2022-10-20 17:25:22,648 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:25:24,987 - INFO  - Training [97][   20/  196]   Loss 0.107435   Top1 96.425781   Top5 99.882812   BatchTime 0.116813   LR 0.000010   
2022-10-20 17:25:26,550 - INFO  - Training [97][   40/  196]   Loss 0.109503   Top1 96.367188   Top5 99.882812   BatchTime 0.097472   LR 0.000010   
2022-10-20 17:25:28,113 - INFO  - Training [97][   60/  196]   Loss 0.110497   Top1 96.328125   Top5 99.876302   BatchTime 0.091026   LR 0.000010   
2022-10-20 17:25:29,680 - INFO  - Training [97][   80/  196]   Loss 0.111880   Top1 96.240234   Top5 99.897461   BatchTime 0.087856   LR 0.000010   
2022-10-20 17:25:31,238 - INFO  - Training [97][  100/  196]   Loss 0.110610   Top1 96.285156   Top5 99.898438   BatchTime 0.085868   LR 0.000010   
2022-10-20 17:25:32,801 - INFO  - Training [97][  120/  196]   Loss 0.111756   Top1 96.285807   Top5 99.882812   BatchTime 0.084584   LR 0.000010   
2022-10-20 17:25:34,365 - INFO  - Training [97][  140/  196]   Loss 0.112169   Top1 96.266741   Top5 99.885603   BatchTime 0.083667   LR 0.000010   
2022-10-20 17:25:35,928 - INFO  - Training [97][  160/  196]   Loss 0.113117   Top1 96.210938   Top5 99.882812   BatchTime 0.082980   LR 0.000010   
2022-10-20 17:25:37,483 - INFO  - Training [97][  180/  196]   Loss 0.112697   Top1 96.250000   Top5 99.880642   BatchTime 0.082398   LR 0.000010   
2022-10-20 17:25:38,818 - INFO  - ==> Top1: 96.252    Top5: 99.880    Loss: 0.113

2022-10-20 17:25:38,884 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:25:40,148 - INFO  - Validation [97][   20/   40]   Loss 0.497358   Top1 86.484375   Top5 99.062500   BatchTime 0.063176   
2022-10-20 17:25:40,686 - INFO  - Validation [97][   40/   40]   Loss 0.482731   Top1 86.730000   Top5 99.240000   BatchTime 0.045053   
2022-10-20 17:25:40,785 - INFO  - ==> Top1: 86.730    Top5: 99.240    Loss: 0.483

2022-10-20 17:25:40,785 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:25:42,494 - INFO  - Validation [97][   20/   40]   Loss 0.513053   Top1 86.386719   Top5 99.101562   BatchTime 0.085406   
2022-10-20 17:25:43,294 - INFO  - Validation [97][   40/   40]   Loss 0.500144   Top1 86.540000   Top5 99.230000   BatchTime 0.062703   
2022-10-20 17:25:43,395 - INFO  - ==> Top1: 86.540    Top5: 99.230    Loss: 0.500

2022-10-20 17:25:43,395 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:25:43,395 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:25:43,395 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:25:43,447 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:25:43,447 - INFO  - >>>>>> Epoch  98
2022-10-20 17:25:43,447 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:25:45,753 - INFO  - Training [98][   20/  196]   Loss 0.118576   Top1 96.171875   Top5 99.843750   BatchTime 0.115258   LR 0.000010   
2022-10-20 17:25:47,317 - INFO  - Training [98][   40/  196]   Loss 0.117525   Top1 96.162109   Top5 99.873047   BatchTime 0.096719   LR 0.000010   
2022-10-20 17:25:48,880 - INFO  - Training [98][   60/  196]   Loss 0.119052   Top1 96.074219   Top5 99.882812   BatchTime 0.090538   LR 0.000010   
2022-10-20 17:25:50,444 - INFO  - Training [98][   80/  196]   Loss 0.115714   Top1 96.152344   Top5 99.887695   BatchTime 0.087448   LR 0.000010   
2022-10-20 17:25:52,008 - INFO  - Training [98][  100/  196]   Loss 0.113582   Top1 96.230469   Top5 99.898438   BatchTime 0.085592   LR 0.000010   
2022-10-20 17:25:53,571 - INFO  - Training [98][  120/  196]   Loss 0.114614   Top1 96.178385   Top5 99.873047   BatchTime 0.084357   LR 0.000010   
2022-10-20 17:25:55,135 - INFO  - Training [98][  140/  196]   Loss 0.114611   Top1 96.160714   Top5 99.868862   BatchTime 0.083474   LR 0.000010   
2022-10-20 17:25:56,698 - INFO  - Training [98][  160/  196]   Loss 0.113647   Top1 96.198730   Top5 99.865723   BatchTime 0.082811   LR 0.000010   
2022-10-20 17:25:58,254 - INFO  - Training [98][  180/  196]   Loss 0.113150   Top1 96.219618   Top5 99.874132   BatchTime 0.082253   LR 0.000010   
2022-10-20 17:25:59,579 - INFO  - ==> Top1: 96.224    Top5: 99.878    Loss: 0.113

2022-10-20 17:25:59,646 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:26:00,896 - INFO  - Validation [98][   20/   40]   Loss 0.497858   Top1 86.347656   Top5 99.160156   BatchTime 0.062502   
2022-10-20 17:26:01,434 - INFO  - Validation [98][   40/   40]   Loss 0.483207   Top1 86.580000   Top5 99.270000   BatchTime 0.044693   
2022-10-20 17:26:01,547 - INFO  - ==> Top1: 86.580    Top5: 99.270    Loss: 0.483

2022-10-20 17:26:01,547 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:26:03,265 - INFO  - Validation [98][   20/   40]   Loss 0.511820   Top1 86.328125   Top5 99.160156   BatchTime 0.085876   
2022-10-20 17:26:04,072 - INFO  - Validation [98][   40/   40]   Loss 0.499766   Top1 86.630000   Top5 99.300000   BatchTime 0.063104   
2022-10-20 17:26:04,187 - INFO  - ==> Top1: 86.630    Top5: 99.300    Loss: 0.500

2022-10-20 17:26:04,187 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:26:04,187 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:26:04,187 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:26:04,496 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:26:04,497 - INFO  - >>>>>> Epoch  99
2022-10-20 17:26:04,497 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:26:06,882 - INFO  - Training [99][   20/  196]   Loss 0.107379   Top1 96.406250   Top5 99.882812   BatchTime 0.119071   LR 0.000010   
2022-10-20 17:26:08,446 - INFO  - Training [99][   40/  196]   Loss 0.112561   Top1 96.289062   Top5 99.873047   BatchTime 0.098643   LR 0.000010   
2022-10-20 17:26:10,014 - INFO  - Training [99][   60/  196]   Loss 0.113509   Top1 96.217448   Top5 99.869792   BatchTime 0.091897   LR 0.000010   
2022-10-20 17:26:11,578 - INFO  - Training [99][   80/  196]   Loss 0.112484   Top1 96.206055   Top5 99.877930   BatchTime 0.088473   LR 0.000010   
2022-10-20 17:26:13,144 - INFO  - Training [99][  100/  196]   Loss 0.112670   Top1 96.195312   Top5 99.875000   BatchTime 0.086437   LR 0.000010   
2022-10-20 17:26:14,707 - INFO  - Training [99][  120/  196]   Loss 0.113592   Top1 96.171875   Top5 99.873047   BatchTime 0.085057   LR 0.000010   
2022-10-20 17:26:16,277 - INFO  - Training [99][  140/  196]   Loss 0.114002   Top1 96.138393   Top5 99.868862   BatchTime 0.084116   LR 0.000010   
2022-10-20 17:26:17,848 - INFO  - Training [99][  160/  196]   Loss 0.115057   Top1 96.083984   Top5 99.865723   BatchTime 0.083419   LR 0.000010   
2022-10-20 17:26:19,402 - INFO  - Training [99][  180/  196]   Loss 0.115025   Top1 96.085069   Top5 99.869792   BatchTime 0.082787   LR 0.000010   
2022-10-20 17:26:20,733 - INFO  - ==> Top1: 96.116    Top5: 99.876    Loss: 0.115

2022-10-20 17:26:20,799 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:26:22,038 - INFO  - Validation [99][   20/   40]   Loss 0.502228   Top1 86.406250   Top5 99.101562   BatchTime 0.061913   
2022-10-20 17:26:22,576 - INFO  - Validation [99][   40/   40]   Loss 0.489005   Top1 86.610000   Top5 99.220000   BatchTime 0.044431   
2022-10-20 17:26:22,681 - INFO  - ==> Top1: 86.610    Top5: 99.220    Loss: 0.489

2022-10-20 17:26:22,681 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:26:24,393 - INFO  - Validation [99][   20/   40]   Loss 0.515157   Top1 86.210938   Top5 99.062500   BatchTime 0.085563   
2022-10-20 17:26:25,195 - INFO  - Validation [99][   40/   40]   Loss 0.503556   Top1 86.510000   Top5 99.200000   BatchTime 0.062840   
2022-10-20 17:26:25,309 - INFO  - ==> Top1: 86.510    Top5: 99.200    Loss: 0.504

2022-10-20 17:26:25,310 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:26:25,310 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:26:25,310 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:26:25,336 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:26:25,336 - INFO  - >>>>>> Epoch 100
2022-10-20 17:26:25,336 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:26:27,657 - INFO  - Training [100][   20/  196]   Loss 0.112061   Top1 96.191406   Top5 99.882812   BatchTime 0.115989   LR 0.000010   
2022-10-20 17:26:29,223 - INFO  - Training [100][   40/  196]   Loss 0.112713   Top1 96.269531   Top5 99.843750   BatchTime 0.097145   LR 0.000010   
2022-10-20 17:26:30,786 - INFO  - Training [100][   60/  196]   Loss 0.112085   Top1 96.315104   Top5 99.850260   BatchTime 0.090822   LR 0.000010   
2022-10-20 17:26:32,350 - INFO  - Training [100][   80/  196]   Loss 0.113287   Top1 96.289062   Top5 99.868164   BatchTime 0.087661   LR 0.000010   
2022-10-20 17:26:33,913 - INFO  - Training [100][  100/  196]   Loss 0.114552   Top1 96.230469   Top5 99.871094   BatchTime 0.085761   LR 0.000010   
2022-10-20 17:26:35,477 - INFO  - Training [100][  120/  196]   Loss 0.113581   Top1 96.279297   Top5 99.873047   BatchTime 0.084499   LR 0.000010   
2022-10-20 17:26:37,041 - INFO  - Training [100][  140/  196]   Loss 0.112987   Top1 96.314174   Top5 99.871652   BatchTime 0.083596   LR 0.000010   
2022-10-20 17:26:38,605 - INFO  - Training [100][  160/  196]   Loss 0.113495   Top1 96.306152   Top5 99.863281   BatchTime 0.082924   LR 0.000010   
2022-10-20 17:26:40,160 - INFO  - Training [100][  180/  196]   Loss 0.113607   Top1 96.286892   Top5 99.865451   BatchTime 0.082347   LR 0.000010   
2022-10-20 17:26:41,490 - INFO  - ==> Top1: 96.304    Top5: 99.866    Loss: 0.113

2022-10-20 17:26:41,558 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:26:42,796 - INFO  - Validation [100][   20/   40]   Loss 0.497922   Top1 86.230469   Top5 99.140625   BatchTime 0.061872   
2022-10-20 17:26:43,332 - INFO  - Validation [100][   40/   40]   Loss 0.479558   Top1 86.500000   Top5 99.290000   BatchTime 0.044327   
2022-10-20 17:26:43,441 - INFO  - ==> Top1: 86.500    Top5: 99.290    Loss: 0.480

2022-10-20 17:26:43,441 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:26:45,143 - INFO  - Validation [100][   20/   40]   Loss 0.511793   Top1 86.347656   Top5 99.160156   BatchTime 0.085084   
2022-10-20 17:26:45,945 - INFO  - Validation [100][   40/   40]   Loss 0.495191   Top1 86.570000   Top5 99.280000   BatchTime 0.062590   
2022-10-20 17:26:46,060 - INFO  - ==> Top1: 86.570    Top5: 99.280    Loss: 0.495

2022-10-20 17:26:46,061 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:26:46,061 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:26:46,061 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:26:46,112 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:26:46,112 - INFO  - >>>>>> Epoch 101
2022-10-20 17:26:46,113 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:26:48,420 - INFO  - Training [101][   20/  196]   Loss 0.109936   Top1 96.347656   Top5 99.882812   BatchTime 0.115306   LR 0.000010   
2022-10-20 17:26:49,983 - INFO  - Training [101][   40/  196]   Loss 0.113896   Top1 96.181641   Top5 99.912109   BatchTime 0.096740   LR 0.000010   
2022-10-20 17:26:51,544 - INFO  - Training [101][   60/  196]   Loss 0.114700   Top1 96.145833   Top5 99.908854   BatchTime 0.090511   LR 0.000010   
2022-10-20 17:26:53,105 - INFO  - Training [101][   80/  196]   Loss 0.114085   Top1 96.132812   Top5 99.912109   BatchTime 0.087390   LR 0.000010   
2022-10-20 17:26:54,667 - INFO  - Training [101][  100/  196]   Loss 0.113373   Top1 96.210938   Top5 99.917969   BatchTime 0.085538   LR 0.000010   
2022-10-20 17:26:56,226 - INFO  - Training [101][  120/  196]   Loss 0.113543   Top1 96.220703   Top5 99.918620   BatchTime 0.084271   LR 0.000010   
2022-10-20 17:26:57,787 - INFO  - Training [101][  140/  196]   Loss 0.113761   Top1 96.180246   Top5 99.910714   BatchTime 0.083381   LR 0.000010   
2022-10-20 17:26:59,348 - INFO  - Training [101][  160/  196]   Loss 0.114804   Top1 96.142578   Top5 99.909668   BatchTime 0.082714   LR 0.000010   
2022-10-20 17:27:00,901 - INFO  - Training [101][  180/  196]   Loss 0.115089   Top1 96.154514   Top5 99.900174   BatchTime 0.082151   LR 0.000010   
2022-10-20 17:27:02,221 - INFO  - ==> Top1: 96.130    Top5: 99.902    Loss: 0.116

2022-10-20 17:27:02,339 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:27:03,585 - INFO  - Validation [101][   20/   40]   Loss 0.497198   Top1 86.582031   Top5 99.082031   BatchTime 0.062273   
2022-10-20 17:27:04,122 - INFO  - Validation [101][   40/   40]   Loss 0.479084   Top1 86.710000   Top5 99.210000   BatchTime 0.044544   
2022-10-20 17:27:04,234 - INFO  - ==> Top1: 86.710    Top5: 99.210    Loss: 0.479

2022-10-20 17:27:04,234 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:27:05,955 - INFO  - Validation [101][   20/   40]   Loss 0.511922   Top1 86.347656   Top5 99.023438   BatchTime 0.086013   
2022-10-20 17:27:06,753 - INFO  - Validation [101][   40/   40]   Loss 0.497074   Top1 86.560000   Top5 99.170000   BatchTime 0.062940   
2022-10-20 17:27:06,857 - INFO  - ==> Top1: 86.560    Top5: 99.170    Loss: 0.497

2022-10-20 17:27:06,857 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:27:06,857 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:27:06,857 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:27:06,913 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:27:06,913 - INFO  - >>>>>> Epoch 102
2022-10-20 17:27:06,913 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:27:09,200 - INFO  - Training [102][   20/  196]   Loss 0.120573   Top1 96.074219   Top5 99.843750   BatchTime 0.114290   LR 0.000010   
2022-10-20 17:27:10,758 - INFO  - Training [102][   40/  196]   Loss 0.115660   Top1 96.201172   Top5 99.892578   BatchTime 0.096114   LR 0.000010   
2022-10-20 17:27:12,317 - INFO  - Training [102][   60/  196]   Loss 0.112997   Top1 96.236979   Top5 99.908854   BatchTime 0.090046   LR 0.000010   
2022-10-20 17:27:13,875 - INFO  - Training [102][   80/  196]   Loss 0.114007   Top1 96.196289   Top5 99.892578   BatchTime 0.087014   LR 0.000010   
2022-10-20 17:27:15,434 - INFO  - Training [102][  100/  196]   Loss 0.114830   Top1 96.187500   Top5 99.890625   BatchTime 0.085196   LR 0.000010   
2022-10-20 17:27:16,997 - INFO  - Training [102][  120/  196]   Loss 0.116027   Top1 96.132812   Top5 99.879557   BatchTime 0.084029   LR 0.000010   
2022-10-20 17:27:18,557 - INFO  - Training [102][  140/  196]   Loss 0.114983   Top1 96.183036   Top5 99.885603   BatchTime 0.083162   LR 0.000010   
2022-10-20 17:27:20,115 - INFO  - Training [102][  160/  196]   Loss 0.114012   Top1 96.210938   Top5 99.890137   BatchTime 0.082507   LR 0.000010   
2022-10-20 17:27:21,664 - INFO  - Training [102][  180/  196]   Loss 0.113931   Top1 96.219618   Top5 99.889323   BatchTime 0.081945   LR 0.000010   
2022-10-20 17:27:22,993 - INFO  - ==> Top1: 96.188    Top5: 99.884    Loss: 0.114

2022-10-20 17:27:23,066 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:27:24,304 - INFO  - Validation [102][   20/   40]   Loss 0.498151   Top1 86.464844   Top5 99.121094   BatchTime 0.061864   
2022-10-20 17:27:24,837 - INFO  - Validation [102][   40/   40]   Loss 0.482842   Top1 86.750000   Top5 99.240000   BatchTime 0.044263   
2022-10-20 17:27:24,946 - INFO  - ==> Top1: 86.750    Top5: 99.240    Loss: 0.483

2022-10-20 17:27:24,946 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:27:26,645 - INFO  - Validation [102][   20/   40]   Loss 0.513848   Top1 86.406250   Top5 99.101562   BatchTime 0.084911   
2022-10-20 17:27:27,448 - INFO  - Validation [102][   40/   40]   Loss 0.499389   Top1 86.700000   Top5 99.210000   BatchTime 0.062537   
2022-10-20 17:27:27,575 - INFO  - ==> Top1: 86.700    Top5: 99.210    Loss: 0.499

2022-10-20 17:27:27,576 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:27:27,576 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:27:27,576 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:27:27,602 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:27:27,602 - INFO  - >>>>>> Epoch 103
2022-10-20 17:27:27,602 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:27:29,926 - INFO  - Training [103][   20/  196]   Loss 0.107285   Top1 96.464844   Top5 99.882812   BatchTime 0.116130   LR 0.000010   
2022-10-20 17:27:31,480 - INFO  - Training [103][   40/  196]   Loss 0.106568   Top1 96.435547   Top5 99.902344   BatchTime 0.096920   LR 0.000010   
2022-10-20 17:27:33,039 - INFO  - Training [103][   60/  196]   Loss 0.111948   Top1 96.250000   Top5 99.882812   BatchTime 0.090591   LR 0.000010   
2022-10-20 17:27:34,597 - INFO  - Training [103][   80/  196]   Loss 0.110484   Top1 96.313477   Top5 99.877930   BatchTime 0.087425   LR 0.000010   
2022-10-20 17:27:36,155 - INFO  - Training [103][  100/  196]   Loss 0.112226   Top1 96.285156   Top5 99.863281   BatchTime 0.085521   LR 0.000010   
2022-10-20 17:27:37,714 - INFO  - Training [103][  120/  196]   Loss 0.112760   Top1 96.250000   Top5 99.863281   BatchTime 0.084256   LR 0.000010   
2022-10-20 17:27:39,273 - INFO  - Training [103][  140/  196]   Loss 0.113393   Top1 96.222098   Top5 99.860491   BatchTime 0.083352   LR 0.000010   
2022-10-20 17:27:40,831 - INFO  - Training [103][  160/  196]   Loss 0.112336   Top1 96.267090   Top5 99.865723   BatchTime 0.082670   LR 0.000010   
2022-10-20 17:27:42,380 - INFO  - Training [103][  180/  196]   Loss 0.112904   Top1 96.228299   Top5 99.858941   BatchTime 0.082092   LR 0.000010   
2022-10-20 17:27:43,702 - INFO  - ==> Top1: 96.244    Top5: 99.864    Loss: 0.112

2022-10-20 17:27:43,768 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:27:45,006 - INFO  - Validation [103][   20/   40]   Loss 0.493489   Top1 86.484375   Top5 99.023438   BatchTime 0.061870   
2022-10-20 17:27:45,538 - INFO  - Validation [103][   40/   40]   Loss 0.479158   Top1 86.650000   Top5 99.220000   BatchTime 0.044251   
2022-10-20 17:27:45,638 - INFO  - ==> Top1: 86.650    Top5: 99.220    Loss: 0.479

2022-10-20 17:27:45,638 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:27:47,347 - INFO  - Validation [103][   20/   40]   Loss 0.509108   Top1 86.445312   Top5 99.042969   BatchTime 0.085421   
2022-10-20 17:27:48,146 - INFO  - Validation [103][   40/   40]   Loss 0.495301   Top1 86.720000   Top5 99.210000   BatchTime 0.062679   
2022-10-20 17:27:48,266 - INFO  - ==> Top1: 86.720    Top5: 99.210    Loss: 0.495

2022-10-20 17:27:48,267 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:27:48,267 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:27:48,267 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:27:48,319 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:27:48,319 - INFO  - >>>>>> Epoch 104
2022-10-20 17:27:48,319 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:27:50,620 - INFO  - Training [104][   20/  196]   Loss 0.108924   Top1 96.464844   Top5 99.902344   BatchTime 0.114974   LR 0.000010   
2022-10-20 17:27:52,183 - INFO  - Training [104][   40/  196]   Loss 0.107482   Top1 96.660156   Top5 99.882812   BatchTime 0.096573   LR 0.000010   
2022-10-20 17:27:53,747 - INFO  - Training [104][   60/  196]   Loss 0.106958   Top1 96.731771   Top5 99.889323   BatchTime 0.090444   LR 0.000010   
2022-10-20 17:27:55,316 - INFO  - Training [104][   80/  196]   Loss 0.109405   Top1 96.669922   Top5 99.892578   BatchTime 0.087441   LR 0.000010   
2022-10-20 17:27:56,880 - INFO  - Training [104][  100/  196]   Loss 0.110304   Top1 96.625000   Top5 99.906250   BatchTime 0.085592   LR 0.000010   
2022-10-20 17:27:58,444 - INFO  - Training [104][  120/  196]   Loss 0.112197   Top1 96.487630   Top5 99.899089   BatchTime 0.084364   LR 0.000010   
2022-10-20 17:28:00,008 - INFO  - Training [104][  140/  196]   Loss 0.111904   Top1 96.484375   Top5 99.896763   BatchTime 0.083483   LR 0.000010   
2022-10-20 17:28:01,572 - INFO  - Training [104][  160/  196]   Loss 0.112313   Top1 96.430664   Top5 99.892578   BatchTime 0.082822   LR 0.000010   
2022-10-20 17:28:03,126 - INFO  - Training [104][  180/  196]   Loss 0.112346   Top1 96.401910   Top5 99.891493   BatchTime 0.082253   LR 0.000010   
2022-10-20 17:28:04,462 - INFO  - ==> Top1: 96.380    Top5: 99.888    Loss: 0.113

2022-10-20 17:28:04,529 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:28:05,783 - INFO  - Validation [104][   20/   40]   Loss 0.496970   Top1 86.425781   Top5 99.121094   BatchTime 0.062671   
2022-10-20 17:28:06,317 - INFO  - Validation [104][   40/   40]   Loss 0.481896   Top1 86.690000   Top5 99.310000   BatchTime 0.044671   
2022-10-20 17:28:06,428 - INFO  - ==> Top1: 86.690    Top5: 99.310    Loss: 0.482

2022-10-20 17:28:06,428 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:28:08,143 - INFO  - Validation [104][   20/   40]   Loss 0.514524   Top1 86.445312   Top5 99.062500   BatchTime 0.085689   
2022-10-20 17:28:08,942 - INFO  - Validation [104][   40/   40]   Loss 0.500567   Top1 86.580000   Top5 99.220000   BatchTime 0.062837   
2022-10-20 17:28:09,057 - INFO  - ==> Top1: 86.580    Top5: 99.220    Loss: 0.501

2022-10-20 17:28:09,057 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:28:09,057 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:28:09,057 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:28:09,113 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:28:09,113 - INFO  - >>>>>> Epoch 105
2022-10-20 17:28:09,113 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:28:11,427 - INFO  - Training [105][   20/  196]   Loss 0.116067   Top1 95.878906   Top5 99.863281   BatchTime 0.115622   LR 0.000010   
2022-10-20 17:28:12,988 - INFO  - Training [105][   40/  196]   Loss 0.114352   Top1 96.064453   Top5 99.863281   BatchTime 0.096848   LR 0.000010   
2022-10-20 17:28:14,551 - INFO  - Training [105][   60/  196]   Loss 0.112434   Top1 96.132812   Top5 99.882812   BatchTime 0.090613   LR 0.000010   
2022-10-20 17:28:16,118 - INFO  - Training [105][   80/  196]   Loss 0.111117   Top1 96.152344   Top5 99.877930   BatchTime 0.087542   LR 0.000010   
2022-10-20 17:28:17,680 - INFO  - Training [105][  100/  196]   Loss 0.111013   Top1 96.207031   Top5 99.882812   BatchTime 0.085658   LR 0.000010   
2022-10-20 17:28:19,241 - INFO  - Training [105][  120/  196]   Loss 0.112417   Top1 96.184896   Top5 99.882812   BatchTime 0.084391   LR 0.000010   
2022-10-20 17:28:20,803 - INFO  - Training [105][  140/  196]   Loss 0.113005   Top1 96.132812   Top5 99.896763   BatchTime 0.083486   LR 0.000010   
2022-10-20 17:28:22,364 - INFO  - Training [105][  160/  196]   Loss 0.113629   Top1 96.125488   Top5 99.877930   BatchTime 0.082807   LR 0.000010   
2022-10-20 17:28:23,916 - INFO  - Training [105][  180/  196]   Loss 0.113287   Top1 96.174045   Top5 99.884983   BatchTime 0.082228   LR 0.000010   
2022-10-20 17:28:25,247 - INFO  - ==> Top1: 96.176    Top5: 99.886    Loss: 0.113

2022-10-20 17:28:25,315 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:28:26,561 - INFO  - Validation [105][   20/   40]   Loss 0.497203   Top1 86.601562   Top5 99.062500   BatchTime 0.062296   
2022-10-20 17:28:27,098 - INFO  - Validation [105][   40/   40]   Loss 0.480980   Top1 86.720000   Top5 99.230000   BatchTime 0.044564   
2022-10-20 17:28:27,198 - INFO  - ==> Top1: 86.720    Top5: 99.230    Loss: 0.481

2022-10-20 17:28:27,198 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:28:28,926 - INFO  - Validation [105][   20/   40]   Loss 0.511024   Top1 86.484375   Top5 99.199219   BatchTime 0.086330   
2022-10-20 17:28:29,732 - INFO  - Validation [105][   40/   40]   Loss 0.498670   Top1 86.610000   Top5 99.260000   BatchTime 0.063323   
2022-10-20 17:28:29,859 - INFO  - ==> Top1: 86.610    Top5: 99.260    Loss: 0.499

2022-10-20 17:28:29,859 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:28:29,859 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:28:29,859 - INFO  - Scoreboard best 3 ==> Epoch [78][Top1: 86.750   Top5: 99.240]
2022-10-20 17:28:29,918 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:28:29,919 - INFO  - >>>>>> Epoch 106
2022-10-20 17:28:29,919 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:28:32,206 - INFO  - Training [106][   20/  196]   Loss 0.106841   Top1 96.503906   Top5 99.882812   BatchTime 0.114326   LR 0.000010   
2022-10-20 17:28:33,767 - INFO  - Training [106][   40/  196]   Loss 0.109407   Top1 96.435547   Top5 99.863281   BatchTime 0.096186   LR 0.000010   
2022-10-20 17:28:35,330 - INFO  - Training [106][   60/  196]   Loss 0.108935   Top1 96.399740   Top5 99.876302   BatchTime 0.090172   LR 0.000010   
2022-10-20 17:28:36,889 - INFO  - Training [106][   80/  196]   Loss 0.109004   Top1 96.362305   Top5 99.882812   BatchTime 0.087109   LR 0.000010   
2022-10-20 17:28:38,451 - INFO  - Training [106][  100/  196]   Loss 0.111014   Top1 96.296875   Top5 99.871094   BatchTime 0.085307   LR 0.000010   
2022-10-20 17:28:40,011 - INFO  - Training [106][  120/  196]   Loss 0.110087   Top1 96.347656   Top5 99.869792   BatchTime 0.084093   LR 0.000010   
2022-10-20 17:28:41,574 - INFO  - Training [106][  140/  196]   Loss 0.110353   Top1 96.333705   Top5 99.874442   BatchTime 0.083246   LR 0.000010   
2022-10-20 17:28:43,133 - INFO  - Training [106][  160/  196]   Loss 0.110741   Top1 96.323242   Top5 99.877930   BatchTime 0.082579   LR 0.000010   
2022-10-20 17:28:44,684 - INFO  - Training [106][  180/  196]   Loss 0.112134   Top1 96.280382   Top5 99.867622   BatchTime 0.082023   LR 0.000010   
2022-10-20 17:28:46,011 - INFO  - ==> Top1: 96.226    Top5: 99.868    Loss: 0.113

2022-10-20 17:28:46,083 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:28:47,340 - INFO  - Validation [106][   20/   40]   Loss 0.501832   Top1 86.484375   Top5 99.101562   BatchTime 0.062796   
2022-10-20 17:28:47,873 - INFO  - Validation [106][   40/   40]   Loss 0.483381   Top1 86.670000   Top5 99.260000   BatchTime 0.044728   
2022-10-20 17:28:47,979 - INFO  - ==> Top1: 86.670    Top5: 99.260    Loss: 0.483

2022-10-20 17:28:47,980 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:28:49,697 - INFO  - Validation [106][   20/   40]   Loss 0.516187   Top1 86.699219   Top5 99.062500   BatchTime 0.085824   
2022-10-20 17:28:50,505 - INFO  - Validation [106][   40/   40]   Loss 0.501008   Top1 86.750000   Top5 99.250000   BatchTime 0.063132   
2022-10-20 17:28:50,635 - INFO  - ==> Top1: 86.750    Top5: 99.250    Loss: 0.501

2022-10-20 17:28:50,635 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:28:50,635 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:28:50,635 - INFO  - Scoreboard best 3 ==> Epoch [106][Top1: 86.750   Top5: 99.250]
2022-10-20 17:28:50,687 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:28:50,687 - INFO  - >>>>>> Epoch 107
2022-10-20 17:28:50,687 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:28:53,007 - INFO  - Training [107][   20/  196]   Loss 0.117853   Top1 96.074219   Top5 99.785156   BatchTime 0.115933   LR 0.000010   
2022-10-20 17:28:54,570 - INFO  - Training [107][   40/  196]   Loss 0.115408   Top1 96.113281   Top5 99.833984   BatchTime 0.097059   LR 0.000010   
2022-10-20 17:28:56,135 - INFO  - Training [107][   60/  196]   Loss 0.115208   Top1 96.087240   Top5 99.863281   BatchTime 0.090777   LR 0.000010   
2022-10-20 17:28:57,698 - INFO  - Training [107][   80/  196]   Loss 0.117079   Top1 96.015625   Top5 99.873047   BatchTime 0.087627   LR 0.000010   
2022-10-20 17:28:59,262 - INFO  - Training [107][  100/  196]   Loss 0.116068   Top1 96.015625   Top5 99.875000   BatchTime 0.085738   LR 0.000010   
2022-10-20 17:29:00,826 - INFO  - Training [107][  120/  196]   Loss 0.115889   Top1 96.005859   Top5 99.882812   BatchTime 0.084480   LR 0.000010   
2022-10-20 17:29:02,390 - INFO  - Training [107][  140/  196]   Loss 0.116129   Top1 96.001674   Top5 99.877232   BatchTime 0.083581   LR 0.000010   
2022-10-20 17:29:03,953 - INFO  - Training [107][  160/  196]   Loss 0.116658   Top1 96.020508   Top5 99.880371   BatchTime 0.082907   LR 0.000010   
2022-10-20 17:29:05,507 - INFO  - Training [107][  180/  196]   Loss 0.115479   Top1 96.091580   Top5 99.876302   BatchTime 0.082329   LR 0.000010   
2022-10-20 17:29:06,845 - INFO  - ==> Top1: 96.106    Top5: 99.882    Loss: 0.115

2022-10-20 17:29:06,917 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:29:08,143 - INFO  - Validation [107][   20/   40]   Loss 0.497974   Top1 86.230469   Top5 99.101562   BatchTime 0.061299   
2022-10-20 17:29:08,682 - INFO  - Validation [107][   40/   40]   Loss 0.478887   Top1 86.530000   Top5 99.220000   BatchTime 0.044106   
2022-10-20 17:29:08,791 - INFO  - ==> Top1: 86.530    Top5: 99.220    Loss: 0.479

2022-10-20 17:29:08,791 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:29:10,498 - INFO  - Validation [107][   20/   40]   Loss 0.513144   Top1 86.230469   Top5 99.082031   BatchTime 0.085342   
2022-10-20 17:29:11,300 - INFO  - Validation [107][   40/   40]   Loss 0.494632   Top1 86.510000   Top5 99.210000   BatchTime 0.062722   
2022-10-20 17:29:11,415 - INFO  - ==> Top1: 86.510    Top5: 99.210    Loss: 0.495

2022-10-20 17:29:11,415 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:29:11,415 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:29:11,415 - INFO  - Scoreboard best 3 ==> Epoch [106][Top1: 86.750   Top5: 99.250]
2022-10-20 17:29:11,470 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:29:11,470 - INFO  - >>>>>> Epoch 108
2022-10-20 17:29:11,470 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:29:13,788 - INFO  - Training [108][   20/  196]   Loss 0.100517   Top1 96.757812   Top5 99.882812   BatchTime 0.115834   LR 0.000010   
2022-10-20 17:29:15,352 - INFO  - Training [108][   40/  196]   Loss 0.109630   Top1 96.220703   Top5 99.912109   BatchTime 0.097011   LR 0.000010   
2022-10-20 17:29:16,920 - INFO  - Training [108][   60/  196]   Loss 0.115478   Top1 96.002604   Top5 99.889323   BatchTime 0.090808   LR 0.000010   
2022-10-20 17:29:18,481 - INFO  - Training [108][   80/  196]   Loss 0.113965   Top1 96.030273   Top5 99.892578   BatchTime 0.087622   LR 0.000010   
2022-10-20 17:29:20,043 - INFO  - Training [108][  100/  196]   Loss 0.111589   Top1 96.187500   Top5 99.894531   BatchTime 0.085713   LR 0.000010   
2022-10-20 17:29:21,603 - INFO  - Training [108][  120/  196]   Loss 0.112487   Top1 96.188151   Top5 99.889323   BatchTime 0.084434   LR 0.000010   
2022-10-20 17:29:23,164 - INFO  - Training [108][  140/  196]   Loss 0.112455   Top1 96.216518   Top5 99.880022   BatchTime 0.083520   LR 0.000010   
2022-10-20 17:29:24,725 - INFO  - Training [108][  160/  196]   Loss 0.112017   Top1 96.262207   Top5 99.885254   BatchTime 0.082835   LR 0.000010   
2022-10-20 17:29:26,276 - INFO  - Training [108][  180/  196]   Loss 0.111926   Top1 96.250000   Top5 99.891493   BatchTime 0.082250   LR 0.000010   
2022-10-20 17:29:27,603 - INFO  - ==> Top1: 96.232    Top5: 99.886    Loss: 0.112

2022-10-20 17:29:27,670 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:29:28,928 - INFO  - Validation [108][   20/   40]   Loss 0.504832   Top1 86.386719   Top5 99.082031   BatchTime 0.062892   
2022-10-20 17:29:29,464 - INFO  - Validation [108][   40/   40]   Loss 0.484511   Top1 86.670000   Top5 99.250000   BatchTime 0.044840   
2022-10-20 17:29:29,568 - INFO  - ==> Top1: 86.670    Top5: 99.250    Loss: 0.485

2022-10-20 17:29:29,568 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:29:31,281 - INFO  - Validation [108][   20/   40]   Loss 0.516669   Top1 86.425781   Top5 99.082031   BatchTime 0.085639   
2022-10-20 17:29:32,080 - INFO  - Validation [108][   40/   40]   Loss 0.498916   Top1 86.640000   Top5 99.230000   BatchTime 0.062791   
2022-10-20 17:29:32,198 - INFO  - ==> Top1: 86.640    Top5: 99.230    Loss: 0.499

2022-10-20 17:29:32,199 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:29:32,199 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:29:32,199 - INFO  - Scoreboard best 3 ==> Epoch [106][Top1: 86.750   Top5: 99.250]
2022-10-20 17:29:32,267 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:29:32,267 - INFO  - >>>>>> Epoch 109
2022-10-20 17:29:32,267 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:29:34,617 - INFO  - Training [109][   20/  196]   Loss 0.105126   Top1 96.601562   Top5 99.902344   BatchTime 0.117419   LR 0.000010   
2022-10-20 17:29:36,182 - INFO  - Training [109][   40/  196]   Loss 0.108564   Top1 96.464844   Top5 99.853516   BatchTime 0.097835   LR 0.000010   
2022-10-20 17:29:37,750 - INFO  - Training [109][   60/  196]   Loss 0.109807   Top1 96.360677   Top5 99.843750   BatchTime 0.091359   LR 0.000010   
2022-10-20 17:29:39,314 - INFO  - Training [109][   80/  196]   Loss 0.113955   Top1 96.186523   Top5 99.863281   BatchTime 0.088073   LR 0.000010   
2022-10-20 17:29:40,878 - INFO  - Training [109][  100/  196]   Loss 0.113847   Top1 96.210938   Top5 99.863281   BatchTime 0.086096   LR 0.000010   
2022-10-20 17:29:42,442 - INFO  - Training [109][  120/  196]   Loss 0.113061   Top1 96.236979   Top5 99.873047   BatchTime 0.084779   LR 0.000010   
2022-10-20 17:29:44,006 - INFO  - Training [109][  140/  196]   Loss 0.114027   Top1 96.210938   Top5 99.888393   BatchTime 0.083836   LR 0.000010   
2022-10-20 17:29:45,569 - INFO  - Training [109][  160/  196]   Loss 0.114200   Top1 96.210938   Top5 99.882812   BatchTime 0.083129   LR 0.000010   
2022-10-20 17:29:47,125 - INFO  - Training [109][  180/  196]   Loss 0.115034   Top1 96.200087   Top5 99.874132   BatchTime 0.082534   LR 0.000010   
2022-10-20 17:29:48,457 - INFO  - ==> Top1: 96.204    Top5: 99.872    Loss: 0.115

2022-10-20 17:29:48,524 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:29:49,769 - INFO  - Validation [109][   20/   40]   Loss 0.495133   Top1 86.933594   Top5 99.082031   BatchTime 0.062243   
2022-10-20 17:29:50,302 - INFO  - Validation [109][   40/   40]   Loss 0.481017   Top1 86.880000   Top5 99.210000   BatchTime 0.044445   
2022-10-20 17:29:50,415 - INFO  - ==> Top1: 86.880    Top5: 99.210    Loss: 0.481

2022-10-20 17:29:50,416 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:29:52,133 - INFO  - Validation [109][   20/   40]   Loss 0.511067   Top1 86.445312   Top5 99.042969   BatchTime 0.085843   
2022-10-20 17:29:52,933 - INFO  - Validation [109][   40/   40]   Loss 0.496181   Top1 86.700000   Top5 99.180000   BatchTime 0.062927   
2022-10-20 17:29:53,050 - INFO  - ==> Top1: 86.700    Top5: 99.180    Loss: 0.496

2022-10-20 17:29:53,050 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:29:53,050 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:29:53,050 - INFO  - Scoreboard best 3 ==> Epoch [106][Top1: 86.750   Top5: 99.250]
2022-10-20 17:29:53,113 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:29:53,113 - INFO  - >>>>>> Epoch 110
2022-10-20 17:29:53,113 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:29:55,422 - INFO  - Training [110][   20/  196]   Loss 0.115576   Top1 96.230469   Top5 99.863281   BatchTime 0.115414   LR 0.000010   
2022-10-20 17:29:56,986 - INFO  - Training [110][   40/  196]   Loss 0.114928   Top1 96.201172   Top5 99.863281   BatchTime 0.096809   LR 0.000010   
2022-10-20 17:29:58,551 - INFO  - Training [110][   60/  196]   Loss 0.115155   Top1 96.197917   Top5 99.850260   BatchTime 0.090616   LR 0.000010   
2022-10-20 17:30:00,115 - INFO  - Training [110][   80/  196]   Loss 0.115680   Top1 96.147461   Top5 99.858398   BatchTime 0.087512   LR 0.000010   
2022-10-20 17:30:01,679 - INFO  - Training [110][  100/  196]   Loss 0.115878   Top1 96.089844   Top5 99.867188   BatchTime 0.085650   LR 0.000010   
2022-10-20 17:30:03,243 - INFO  - Training [110][  120/  196]   Loss 0.114637   Top1 96.110026   Top5 99.873047   BatchTime 0.084409   LR 0.000010   
2022-10-20 17:30:04,807 - INFO  - Training [110][  140/  196]   Loss 0.114275   Top1 96.135603   Top5 99.877232   BatchTime 0.083524   LR 0.000010   
2022-10-20 17:30:06,371 - INFO  - Training [110][  160/  196]   Loss 0.112939   Top1 96.230469   Top5 99.882812   BatchTime 0.082857   LR 0.000010   
2022-10-20 17:30:07,926 - INFO  - Training [110][  180/  196]   Loss 0.112896   Top1 96.228299   Top5 99.880642   BatchTime 0.082288   LR 0.000010   
2022-10-20 17:30:09,256 - INFO  - ==> Top1: 96.274    Top5: 99.878    Loss: 0.112

2022-10-20 17:30:09,324 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:30:10,567 - INFO  - Validation [110][   20/   40]   Loss 0.493830   Top1 86.718750   Top5 99.160156   BatchTime 0.062157   
2022-10-20 17:30:11,106 - INFO  - Validation [110][   40/   40]   Loss 0.479273   Top1 86.840000   Top5 99.310000   BatchTime 0.044535   
2022-10-20 17:30:11,217 - INFO  - ==> Top1: 86.840    Top5: 99.310    Loss: 0.479

2022-10-20 17:30:11,218 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:30:13,153 - INFO  - Validation [110][   20/   40]   Loss 0.506525   Top1 86.503906   Top5 99.003906   BatchTime 0.096727   
2022-10-20 17:30:13,958 - INFO  - Validation [110][   40/   40]   Loss 0.493370   Top1 86.810000   Top5 99.180000   BatchTime 0.068505   
2022-10-20 17:30:14,084 - INFO  - ==> Top1: 86.810    Top5: 99.180    Loss: 0.493

2022-10-20 17:30:14,085 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:30:14,085 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:30:14,085 - INFO  - Scoreboard best 3 ==> Epoch [110][Top1: 86.810   Top5: 99.180]
2022-10-20 17:30:14,185 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:30:14,185 - INFO  - >>>>>> Epoch 111
2022-10-20 17:30:14,185 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:30:16,493 - INFO  - Training [111][   20/  196]   Loss 0.124636   Top1 95.957031   Top5 99.882812   BatchTime 0.115329   LR 0.000010   
2022-10-20 17:30:18,064 - INFO  - Training [111][   40/  196]   Loss 0.115862   Top1 96.220703   Top5 99.882812   BatchTime 0.096946   LR 0.000010   
2022-10-20 17:30:19,628 - INFO  - Training [111][   60/  196]   Loss 0.116105   Top1 96.165365   Top5 99.882812   BatchTime 0.090690   LR 0.000010   
2022-10-20 17:30:21,191 - INFO  - Training [111][   80/  196]   Loss 0.115494   Top1 96.230469   Top5 99.887695   BatchTime 0.087558   LR 0.000010   
2022-10-20 17:30:22,754 - INFO  - Training [111][  100/  196]   Loss 0.113777   Top1 96.261719   Top5 99.894531   BatchTime 0.085680   LR 0.000010   
2022-10-20 17:30:24,318 - INFO  - Training [111][  120/  196]   Loss 0.114178   Top1 96.250000   Top5 99.886068   BatchTime 0.084427   LR 0.000010   
2022-10-20 17:30:25,881 - INFO  - Training [111][  140/  196]   Loss 0.115171   Top1 96.202567   Top5 99.877232   BatchTime 0.083532   LR 0.000010   
2022-10-20 17:30:27,444 - INFO  - Training [111][  160/  196]   Loss 0.113622   Top1 96.254883   Top5 99.877930   BatchTime 0.082861   LR 0.000010   
2022-10-20 17:30:28,999 - INFO  - Training [111][  180/  196]   Loss 0.114376   Top1 96.236979   Top5 99.874132   BatchTime 0.082291   LR 0.000010   
2022-10-20 17:30:30,330 - INFO  - ==> Top1: 96.228    Top5: 99.876    Loss: 0.115

2022-10-20 17:30:30,396 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:30:31,657 - INFO  - Validation [111][   20/   40]   Loss 0.495422   Top1 86.484375   Top5 99.082031   BatchTime 0.063011   
2022-10-20 17:30:32,190 - INFO  - Validation [111][   40/   40]   Loss 0.479795   Top1 86.770000   Top5 99.250000   BatchTime 0.044845   
2022-10-20 17:30:32,283 - INFO  - ==> Top1: 86.770    Top5: 99.250    Loss: 0.480

2022-10-20 17:30:32,283 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:30:33,982 - INFO  - Validation [111][   20/   40]   Loss 0.512429   Top1 86.132812   Top5 99.082031   BatchTime 0.084893   
2022-10-20 17:30:34,790 - INFO  - Validation [111][   40/   40]   Loss 0.496172   Top1 86.610000   Top5 99.210000   BatchTime 0.062649   
2022-10-20 17:30:34,918 - INFO  - ==> Top1: 86.610    Top5: 99.210    Loss: 0.496

2022-10-20 17:30:34,918 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:30:34,918 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:30:34,918 - INFO  - Scoreboard best 3 ==> Epoch [110][Top1: 86.810   Top5: 99.180]
2022-10-20 17:30:34,944 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:30:34,944 - INFO  - >>>>>> Epoch 112
2022-10-20 17:30:34,944 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:30:37,242 - INFO  - Training [112][   20/  196]   Loss 0.115133   Top1 95.917969   Top5 99.921875   BatchTime 0.114830   LR 0.000010   
2022-10-20 17:30:38,802 - INFO  - Training [112][   40/  196]   Loss 0.116162   Top1 95.859375   Top5 99.863281   BatchTime 0.096421   LR 0.000010   
2022-10-20 17:30:40,365 - INFO  - Training [112][   60/  196]   Loss 0.114345   Top1 96.041667   Top5 99.856771   BatchTime 0.090337   LR 0.000010   
2022-10-20 17:30:41,929 - INFO  - Training [112][   80/  196]   Loss 0.114691   Top1 96.069336   Top5 99.838867   BatchTime 0.087296   LR 0.000010   
2022-10-20 17:30:43,496 - INFO  - Training [112][  100/  196]   Loss 0.114498   Top1 96.078125   Top5 99.851562   BatchTime 0.085509   LR 0.000010   
2022-10-20 17:30:45,055 - INFO  - Training [112][  120/  196]   Loss 0.113164   Top1 96.162109   Top5 99.869792   BatchTime 0.084252   LR 0.000010   
2022-10-20 17:30:46,619 - INFO  - Training [112][  140/  196]   Loss 0.112436   Top1 96.216518   Top5 99.880022   BatchTime 0.083383   LR 0.000010   
2022-10-20 17:30:48,183 - INFO  - Training [112][  160/  196]   Loss 0.112998   Top1 96.201172   Top5 99.873047   BatchTime 0.082733   LR 0.000010   
2022-10-20 17:30:49,737 - INFO  - Training [112][  180/  196]   Loss 0.113041   Top1 96.197917   Top5 99.869792   BatchTime 0.082173   LR 0.000010   
2022-10-20 17:30:51,059 - INFO  - ==> Top1: 96.180    Top5: 99.872    Loss: 0.114

2022-10-20 17:30:51,126 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:30:52,350 - INFO  - Validation [112][   20/   40]   Loss 0.497311   Top1 86.386719   Top5 99.101562   BatchTime 0.061167   
2022-10-20 17:30:52,888 - INFO  - Validation [112][   40/   40]   Loss 0.479472   Top1 86.570000   Top5 99.240000   BatchTime 0.044039   
2022-10-20 17:30:52,998 - INFO  - ==> Top1: 86.570    Top5: 99.240    Loss: 0.479

2022-10-20 17:30:52,998 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:30:54,719 - INFO  - Validation [112][   20/   40]   Loss 0.514227   Top1 86.347656   Top5 99.101562   BatchTime 0.086011   
2022-10-20 17:30:55,519 - INFO  - Validation [112][   40/   40]   Loss 0.497402   Top1 86.650000   Top5 99.230000   BatchTime 0.063013   
2022-10-20 17:30:55,642 - INFO  - ==> Top1: 86.650    Top5: 99.230    Loss: 0.497

2022-10-20 17:30:55,643 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:30:55,643 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:30:55,643 - INFO  - Scoreboard best 3 ==> Epoch [110][Top1: 86.810   Top5: 99.180]
2022-10-20 17:30:55,698 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:30:55,698 - INFO  - >>>>>> Epoch 113
2022-10-20 17:30:55,698 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:30:58,022 - INFO  - Training [113][   20/  196]   Loss 0.105746   Top1 96.660156   Top5 99.921875   BatchTime 0.116133   LR 0.000010   
2022-10-20 17:30:59,586 - INFO  - Training [113][   40/  196]   Loss 0.112287   Top1 96.435547   Top5 99.902344   BatchTime 0.097176   LR 0.000010   
2022-10-20 17:31:01,150 - INFO  - Training [113][   60/  196]   Loss 0.114546   Top1 96.269531   Top5 99.869792   BatchTime 0.090853   LR 0.000010   
2022-10-20 17:31:02,714 - INFO  - Training [113][   80/  196]   Loss 0.114469   Top1 96.162109   Top5 99.877930   BatchTime 0.087691   LR 0.000010   
2022-10-20 17:31:04,279 - INFO  - Training [113][  100/  196]   Loss 0.115353   Top1 96.121094   Top5 99.878906   BatchTime 0.085796   LR 0.000010   
2022-10-20 17:31:05,843 - INFO  - Training [113][  120/  196]   Loss 0.113477   Top1 96.194661   Top5 99.886068   BatchTime 0.084531   LR 0.000010   
2022-10-20 17:31:07,407 - INFO  - Training [113][  140/  196]   Loss 0.114073   Top1 96.146763   Top5 99.877232   BatchTime 0.083625   LR 0.000010   
2022-10-20 17:31:08,971 - INFO  - Training [113][  160/  196]   Loss 0.113173   Top1 96.171875   Top5 99.880371   BatchTime 0.082946   LR 0.000010   
2022-10-20 17:31:10,525 - INFO  - Training [113][  180/  196]   Loss 0.113045   Top1 96.189236   Top5 99.880642   BatchTime 0.082363   LR 0.000010   
2022-10-20 17:31:11,859 - INFO  - ==> Top1: 96.196    Top5: 99.872    Loss: 0.113

2022-10-20 17:31:11,925 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:31:13,178 - INFO  - Validation [113][   20/   40]   Loss 0.497209   Top1 86.542969   Top5 99.082031   BatchTime 0.062614   
2022-10-20 17:31:13,711 - INFO  - Validation [113][   40/   40]   Loss 0.482010   Top1 86.680000   Top5 99.290000   BatchTime 0.044628   
2022-10-20 17:31:13,819 - INFO  - ==> Top1: 86.680    Top5: 99.290    Loss: 0.482

2022-10-20 17:31:13,819 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:31:15,560 - INFO  - Validation [113][   20/   40]   Loss 0.512257   Top1 86.328125   Top5 99.140625   BatchTime 0.087035   
2022-10-20 17:31:16,458 - INFO  - Validation [113][   40/   40]   Loss 0.499584   Top1 86.640000   Top5 99.300000   BatchTime 0.065968   
2022-10-20 17:31:16,586 - INFO  - ==> Top1: 86.640    Top5: 99.300    Loss: 0.500

2022-10-20 17:31:16,586 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:31:16,586 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:31:16,586 - INFO  - Scoreboard best 3 ==> Epoch [110][Top1: 86.810   Top5: 99.180]
2022-10-20 17:31:16,636 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:31:16,637 - INFO  - >>>>>> Epoch 114
2022-10-20 17:31:16,638 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:31:18,996 - INFO  - Training [114][   20/  196]   Loss 0.121188   Top1 95.800781   Top5 99.824219   BatchTime 0.117781   LR 0.000010   
2022-10-20 17:31:20,557 - INFO  - Training [114][   40/  196]   Loss 0.116791   Top1 95.996094   Top5 99.873047   BatchTime 0.097900   LR 0.000010   
2022-10-20 17:31:22,115 - INFO  - Training [114][   60/  196]   Loss 0.115512   Top1 96.145833   Top5 99.856771   BatchTime 0.091238   LR 0.000010   
2022-10-20 17:31:23,673 - INFO  - Training [114][   80/  196]   Loss 0.114253   Top1 96.201172   Top5 99.858398   BatchTime 0.087906   LR 0.000010   
2022-10-20 17:31:25,231 - INFO  - Training [114][  100/  196]   Loss 0.114595   Top1 96.207031   Top5 99.847656   BatchTime 0.085901   LR 0.000010   
2022-10-20 17:31:26,789 - INFO  - Training [114][  120/  196]   Loss 0.114741   Top1 96.188151   Top5 99.853516   BatchTime 0.084569   LR 0.000010   
2022-10-20 17:31:28,347 - INFO  - Training [114][  140/  196]   Loss 0.113903   Top1 96.258371   Top5 99.860491   BatchTime 0.083617   LR 0.000010   
2022-10-20 17:31:29,905 - INFO  - Training [114][  160/  196]   Loss 0.113826   Top1 96.232910   Top5 99.860840   BatchTime 0.082900   LR 0.000010   
2022-10-20 17:31:31,454 - INFO  - Training [114][  180/  196]   Loss 0.113408   Top1 96.252170   Top5 99.858941   BatchTime 0.082294   LR 0.000010   
2022-10-20 17:31:32,780 - INFO  - ==> Top1: 96.264    Top5: 99.866    Loss: 0.114

2022-10-20 17:31:32,852 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:31:34,099 - INFO  - Validation [114][   20/   40]   Loss 0.501860   Top1 86.503906   Top5 99.160156   BatchTime 0.062297   
2022-10-20 17:31:34,632 - INFO  - Validation [114][   40/   40]   Loss 0.486954   Top1 86.650000   Top5 99.270000   BatchTime 0.044492   
2022-10-20 17:31:34,734 - INFO  - ==> Top1: 86.650    Top5: 99.270    Loss: 0.487

2022-10-20 17:31:34,734 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:31:36,482 - INFO  - Validation [114][   20/   40]   Loss 0.517056   Top1 86.406250   Top5 99.062500   BatchTime 0.087356   
2022-10-20 17:31:37,286 - INFO  - Validation [114][   40/   40]   Loss 0.503218   Top1 86.610000   Top5 99.210000   BatchTime 0.063773   
2022-10-20 17:31:37,404 - INFO  - ==> Top1: 86.610    Top5: 99.210    Loss: 0.503

2022-10-20 17:31:37,405 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:31:37,405 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:31:37,405 - INFO  - Scoreboard best 3 ==> Epoch [110][Top1: 86.810   Top5: 99.180]
2022-10-20 17:31:37,467 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:31:37,468 - INFO  - >>>>>> Epoch 115
2022-10-20 17:31:37,468 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:31:39,766 - INFO  - Training [115][   20/  196]   Loss 0.111077   Top1 96.386719   Top5 99.882812   BatchTime 0.114861   LR 0.000010   
2022-10-20 17:31:41,334 - INFO  - Training [115][   40/  196]   Loss 0.108726   Top1 96.425781   Top5 99.882812   BatchTime 0.096625   LR 0.000010   
2022-10-20 17:31:42,895 - INFO  - Training [115][   60/  196]   Loss 0.112618   Top1 96.399740   Top5 99.850260   BatchTime 0.090436   LR 0.000010   
2022-10-20 17:31:44,459 - INFO  - Training [115][   80/  196]   Loss 0.112241   Top1 96.430664   Top5 99.853516   BatchTime 0.087383   LR 0.000010   
2022-10-20 17:31:46,023 - INFO  - Training [115][  100/  196]   Loss 0.113598   Top1 96.339844   Top5 99.851562   BatchTime 0.085547   LR 0.000010   
2022-10-20 17:31:47,590 - INFO  - Training [115][  120/  196]   Loss 0.113727   Top1 96.344401   Top5 99.860026   BatchTime 0.084346   LR 0.000010   
2022-10-20 17:31:49,153 - INFO  - Training [115][  140/  196]   Loss 0.112977   Top1 96.353237   Top5 99.860491   BatchTime 0.083457   LR 0.000010   
2022-10-20 17:31:50,717 - INFO  - Training [115][  160/  196]   Loss 0.111673   Top1 96.364746   Top5 99.870605   BatchTime 0.082802   LR 0.000010   
2022-10-20 17:31:52,272 - INFO  - Training [115][  180/  196]   Loss 0.111025   Top1 96.378038   Top5 99.874132   BatchTime 0.082238   LR 0.000010   
2022-10-20 17:31:53,600 - INFO  - ==> Top1: 96.384    Top5: 99.864    Loss: 0.112

2022-10-20 17:31:53,673 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:31:54,922 - INFO  - Validation [115][   20/   40]   Loss 0.497027   Top1 86.406250   Top5 99.101562   BatchTime 0.062391   
2022-10-20 17:31:55,460 - INFO  - Validation [115][   40/   40]   Loss 0.485439   Top1 86.670000   Top5 99.230000   BatchTime 0.044650   
2022-10-20 17:31:55,560 - INFO  - ==> Top1: 86.670    Top5: 99.230    Loss: 0.485

2022-10-20 17:31:55,560 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:31:57,284 - INFO  - Validation [115][   20/   40]   Loss 0.514291   Top1 86.347656   Top5 99.023438   BatchTime 0.086156   
2022-10-20 17:31:58,086 - INFO  - Validation [115][   40/   40]   Loss 0.501464   Top1 86.600000   Top5 99.090000   BatchTime 0.063138   
2022-10-20 17:31:58,200 - INFO  - ==> Top1: 86.600    Top5: 99.090    Loss: 0.501

2022-10-20 17:31:58,200 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:31:58,200 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:31:58,200 - INFO  - Scoreboard best 3 ==> Epoch [110][Top1: 86.810   Top5: 99.180]
2022-10-20 17:31:58,272 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:31:58,272 - INFO  - >>>>>> Epoch 116
2022-10-20 17:31:58,272 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:32:00,613 - INFO  - Training [116][   20/  196]   Loss 0.101428   Top1 96.621094   Top5 99.863281   BatchTime 0.116998   LR 0.000010   
2022-10-20 17:32:02,175 - INFO  - Training [116][   40/  196]   Loss 0.107096   Top1 96.347656   Top5 99.882812   BatchTime 0.097533   LR 0.000010   
2022-10-20 17:32:03,736 - INFO  - Training [116][   60/  196]   Loss 0.111156   Top1 96.178385   Top5 99.869792   BatchTime 0.091048   LR 0.000010   
2022-10-20 17:32:05,297 - INFO  - Training [116][   80/  196]   Loss 0.114490   Top1 96.147461   Top5 99.853516   BatchTime 0.087791   LR 0.000010   
2022-10-20 17:32:06,857 - INFO  - Training [116][  100/  196]   Loss 0.114352   Top1 96.136719   Top5 99.863281   BatchTime 0.085841   LR 0.000010   
2022-10-20 17:32:08,418 - INFO  - Training [116][  120/  196]   Loss 0.114649   Top1 96.142578   Top5 99.866536   BatchTime 0.084541   LR 0.000010   
2022-10-20 17:32:09,979 - INFO  - Training [116][  140/  196]   Loss 0.113830   Top1 96.199777   Top5 99.868862   BatchTime 0.083612   LR 0.000010   
2022-10-20 17:32:11,540 - INFO  - Training [116][  160/  196]   Loss 0.114510   Top1 96.169434   Top5 99.865723   BatchTime 0.082915   LR 0.000010   
2022-10-20 17:32:13,091 - INFO  - Training [116][  180/  196]   Loss 0.114138   Top1 96.197917   Top5 99.865451   BatchTime 0.082321   LR 0.000010   
2022-10-20 17:32:14,417 - INFO  - ==> Top1: 96.172    Top5: 99.868    Loss: 0.115

2022-10-20 17:32:14,489 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:32:15,749 - INFO  - Validation [116][   20/   40]   Loss 0.499065   Top1 86.582031   Top5 99.179688   BatchTime 0.062956   
2022-10-20 17:32:16,293 - INFO  - Validation [116][   40/   40]   Loss 0.482641   Top1 86.670000   Top5 99.320000   BatchTime 0.045077   
2022-10-20 17:32:16,400 - INFO  - ==> Top1: 86.670    Top5: 99.320    Loss: 0.483

2022-10-20 17:32:16,400 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:32:18,143 - INFO  - Validation [116][   20/   40]   Loss 0.516005   Top1 86.347656   Top5 99.121094   BatchTime 0.087101   
2022-10-20 17:32:18,949 - INFO  - Validation [116][   40/   40]   Loss 0.501129   Top1 86.580000   Top5 99.250000   BatchTime 0.063699   
2022-10-20 17:32:19,069 - INFO  - ==> Top1: 86.580    Top5: 99.250    Loss: 0.501

2022-10-20 17:32:19,070 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:32:19,070 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:32:19,070 - INFO  - Scoreboard best 3 ==> Epoch [110][Top1: 86.810   Top5: 99.180]
2022-10-20 17:32:19,096 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:32:19,096 - INFO  - >>>>>> Epoch 117
2022-10-20 17:32:19,097 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:32:21,381 - INFO  - Training [117][   20/  196]   Loss 0.118173   Top1 95.917969   Top5 99.902344   BatchTime 0.114186   LR 0.000010   
2022-10-20 17:32:22,948 - INFO  - Training [117][   40/  196]   Loss 0.113707   Top1 96.054688   Top5 99.892578   BatchTime 0.096276   LR 0.000010   
2022-10-20 17:32:24,513 - INFO  - Training [117][   60/  196]   Loss 0.114533   Top1 96.022135   Top5 99.902344   BatchTime 0.090254   LR 0.000010   
2022-10-20 17:32:26,069 - INFO  - Training [117][   80/  196]   Loss 0.117633   Top1 95.883789   Top5 99.873047   BatchTime 0.087149   LR 0.000010   
2022-10-20 17:32:27,630 - INFO  - Training [117][  100/  196]   Loss 0.115853   Top1 96.031250   Top5 99.863281   BatchTime 0.085324   LR 0.000010   
2022-10-20 17:32:29,190 - INFO  - Training [117][  120/  196]   Loss 0.115756   Top1 96.031901   Top5 99.863281   BatchTime 0.084107   LR 0.000010   
2022-10-20 17:32:30,755 - INFO  - Training [117][  140/  196]   Loss 0.114857   Top1 96.060268   Top5 99.868862   BatchTime 0.083268   LR 0.000010   
2022-10-20 17:32:32,311 - INFO  - Training [117][  160/  196]   Loss 0.113963   Top1 96.113281   Top5 99.873047   BatchTime 0.082583   LR 0.000010   
2022-10-20 17:32:33,863 - INFO  - Training [117][  180/  196]   Loss 0.113973   Top1 96.152344   Top5 99.876302   BatchTime 0.082029   LR 0.000010   
2022-10-20 17:32:35,185 - INFO  - ==> Top1: 96.156    Top5: 99.876    Loss: 0.114

2022-10-20 17:32:35,253 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:32:36,493 - INFO  - Validation [117][   20/   40]   Loss 0.499590   Top1 86.621094   Top5 99.082031   BatchTime 0.061960   
2022-10-20 17:32:37,029 - INFO  - Validation [117][   40/   40]   Loss 0.484398   Top1 86.710000   Top5 99.240000   BatchTime 0.044376   
2022-10-20 17:32:37,146 - INFO  - ==> Top1: 86.710    Top5: 99.240    Loss: 0.484

2022-10-20 17:32:37,146 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 17:32:38,872 - INFO  - Validation [117][   20/   40]   Loss 0.513795   Top1 86.152344   Top5 99.062500   BatchTime 0.086292   
2022-10-20 17:32:39,676 - INFO  - Validation [117][   40/   40]   Loss 0.500727   Top1 86.540000   Top5 99.220000   BatchTime 0.063256   
2022-10-20 17:32:39,801 - INFO  - ==> Top1: 86.540    Top5: 99.220    Loss: 0.501

2022-10-20 17:32:39,801 - INFO  - Scoreboard best 1 ==> Epoch [94][Top1: 86.810   Top5: 99.290]
2022-10-20 17:32:39,801 - INFO  - Scoreboard best 2 ==> Epoch [71][Top1: 86.810   Top5: 99.190]
2022-10-20 17:32:39,801 - INFO  - Scoreboard best 3 ==> Epoch [110][Top1: 86.810   Top5: 99.180]
2022-10-20 17:32:39,868 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-165123/88_checkpoint.pth.tar

2022-10-20 17:32:39,868 - INFO  - >>>>>> Epoch 118
2022-10-20 17:32:39,868 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 17:32:42,208 - INFO  - Training [118][   20/  196]   Loss 0.116571   Top1 96.015625   Top5 99.902344   BatchTime 0.116939   LR 0.000010   
2022-10-20 17:32:43,772 - INFO  - Training [118][   40/  196]   Loss 0.116329   Top1 95.996094   Top5 99.892578   BatchTime 0.097565   LR 0.000010   
2022-10-20 17:32:45,336 - INFO  - Training [118][   60/  196]   Loss 0.118789   Top1 95.950521   Top5 99.856771   BatchTime 0.091105   LR 0.000010   
2022-10-20 17:32:46,899 - INFO  - Training [118][   80/  196]   Loss 0.116954   Top1 96.083984   Top5 99.858398   BatchTime 0.087867   LR 0.000010   
2022-10-20 17:32:48,462 - INFO  - Training [118][  100/  196]   Loss 0.116321   Top1 96.121094   Top5 99.855469   BatchTime 0.085928   LR 0.000010   
2022-10-20 17:32:50,025 - INFO  - Training [118][  120/  196]   Loss 0.114448   Top1 96.175130   Top5 99.866536   BatchTime 0.084631   LR 0.000010   
