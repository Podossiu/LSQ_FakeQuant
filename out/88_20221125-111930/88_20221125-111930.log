2022-11-25 11:19:30,435 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88_20221125-111930.log
2022-11-25 11:19:34,700 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-25 11:19:36,583 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-25 11:19:37,446 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
2022-11-25 11:19:37,447 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005

2022-11-25 11:19:37,717 - INFO  - >>>>>> Epoch   0
2022-11-25 11:19:37,719 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:19:45,211 - INFO  - Training [0][   20/  196]   Loss 1.580633   Top1 53.867188   Top5 89.355469   BatchTime 0.374495   LR 0.004999   
2022-11-25 11:19:52,667 - INFO  - Training [0][   40/  196]   Loss 1.492875   Top1 52.988281   Top5 89.707031   BatchTime 0.373664   LR 0.004995   
2022-11-25 11:20:00,512 - INFO  - Training [0][   60/  196]   Loss 1.387285   Top1 55.345052   Top5 90.950521   BatchTime 0.379849   LR 0.004989   
2022-11-25 11:20:08,396 - INFO  - Training [0][   80/  196]   Loss 1.320196   Top1 57.270508   Top5 91.743164   BatchTime 0.383441   LR 0.004980   
2022-11-25 11:20:16,063 - INFO  - Training [0][  100/  196]   Loss 1.259414   Top1 58.894531   Top5 92.488281   BatchTime 0.383419   LR 0.004968   
2022-11-25 11:20:23,812 - INFO  - Training [0][  120/  196]   Loss 1.213198   Top1 60.322266   Top5 93.072917   BatchTime 0.384093   LR 0.004954   
2022-11-25 11:20:31,640 - INFO  - Training [0][  140/  196]   Loss 1.179248   Top1 61.238839   Top5 93.462612   BatchTime 0.385133   LR 0.004938   
2022-11-25 11:20:39,744 - INFO  - Training [0][  160/  196]   Loss 1.153554   Top1 61.958008   Top5 93.708496   BatchTime 0.387638   LR 0.004919   
2022-11-25 11:20:48,501 - INFO  - Training [0][  180/  196]   Loss 1.130509   Top1 62.612847   Top5 93.895399   BatchTime 0.393219   LR 0.004897   
2022-11-25 11:20:55,354 - INFO  - ==> Top1: 63.152    Top5: 94.036    Loss: 1.112

2022-11-25 11:20:55,602 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:20:57,763 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:21:00,075 - INFO  - Validation [0][   20/   40]   Loss 0.865341   Top1 74.296875   Top5 97.812500   BatchTime 0.115533   
2022-11-25 11:21:01,348 - INFO  - Validation [0][   40/   40]   Loss 0.858100   Top1 74.050000   Top5 97.880000   BatchTime 0.089576   
2022-11-25 11:21:01,893 - INFO  - ==> Top1: 74.050    Top5: 97.880    Loss: 0.858

2022-11-25 11:21:01,894 - INFO  - ==> Sparsity : 0.226

2022-11-25 11:21:01,895 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 74.050   Top5: 97.880]
2022-11-25 11:21:08,505 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:21:08,506 - INFO  - >>>>>> Epoch   1
2022-11-25 11:21:08,508 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:21:17,074 - INFO  - Training [1][   20/  196]   Loss 0.925481   Top1 69.101562   Top5 95.156250   BatchTime 0.428135   LR 0.004853   
2022-11-25 11:21:24,298 - INFO  - Training [1][   40/  196]   Loss 0.925225   Top1 69.072266   Top5 95.546875   BatchTime 0.394669   LR 0.004825   
2022-11-25 11:21:31,888 - INFO  - Training [1][   60/  196]   Loss 0.905991   Top1 69.648438   Top5 95.690104   BatchTime 0.389611   LR 0.004794   
2022-11-25 11:21:39,794 - INFO  - Training [1][   80/  196]   Loss 0.896313   Top1 69.921875   Top5 95.898438   BatchTime 0.391039   LR 0.004761   
2022-11-25 11:21:46,952 - INFO  - Training [1][  100/  196]   Loss 0.886429   Top1 70.152344   Top5 96.035156   BatchTime 0.384408   LR 0.004725   
2022-11-25 11:21:54,356 - INFO  - Training [1][  120/  196]   Loss 0.878235   Top1 70.416667   Top5 96.217448   BatchTime 0.382040   LR 0.004687   
2022-11-25 11:22:01,949 - INFO  - Training [1][  140/  196]   Loss 0.865506   Top1 70.884487   Top5 96.358817   BatchTime 0.381699   LR 0.004647   
2022-11-25 11:22:09,396 - INFO  - Training [1][  160/  196]   Loss 0.861341   Top1 71.042480   Top5 96.384277   BatchTime 0.380528   LR 0.004605   
2022-11-25 11:22:16,650 - INFO  - Training [1][  180/  196]   Loss 0.852087   Top1 71.395399   Top5 96.401910   BatchTime 0.378544   LR 0.004560   
2022-11-25 11:22:21,586 - INFO  - ==> Top1: 71.560    Top5: 96.412    Loss: 0.849

2022-11-25 11:22:21,877 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:22:24,813 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:22:27,133 - INFO  - Validation [1][   20/   40]   Loss 0.723361   Top1 76.289062   Top5 97.636719   BatchTime 0.115901   
2022-11-25 11:22:28,315 - INFO  - Validation [1][   40/   40]   Loss 0.715044   Top1 76.170000   Top5 97.740000   BatchTime 0.087490   
2022-11-25 11:22:28,546 - INFO  - ==> Top1: 76.170    Top5: 97.740    Loss: 0.715

2022-11-25 11:22:28,546 - INFO  - ==> Sparsity : 0.255

2022-11-25 11:22:28,546 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.170   Top5: 97.740]
2022-11-25 11:22:28,547 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 74.050   Top5: 97.880]
2022-11-25 11:22:34,063 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:22:34,066 - INFO  - >>>>>> Epoch   2
2022-11-25 11:22:34,068 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:22:42,342 - INFO  - Training [2][   20/  196]   Loss 0.825766   Top1 71.796875   Top5 95.878906   BatchTime 0.413550   LR 0.004477   
2022-11-25 11:22:49,514 - INFO  - Training [2][   40/  196]   Loss 0.829900   Top1 72.285156   Top5 96.152344   BatchTime 0.386099   LR 0.004426   
2022-11-25 11:22:56,601 - INFO  - Training [2][   60/  196]   Loss 0.816762   Top1 72.617188   Top5 96.360677   BatchTime 0.375505   LR 0.004374   
2022-11-25 11:23:03,961 - INFO  - Training [2][   80/  196]   Loss 0.805124   Top1 72.880859   Top5 96.582031   BatchTime 0.373627   LR 0.004320   
2022-11-25 11:23:11,162 - INFO  - Training [2][  100/  196]   Loss 0.790376   Top1 73.343750   Top5 96.609375   BatchTime 0.370916   LR 0.004264   
2022-11-25 11:23:18,540 - INFO  - Training [2][  120/  196]   Loss 0.780425   Top1 73.717448   Top5 96.712240   BatchTime 0.370576   LR 0.004206   
2022-11-25 11:23:26,024 - INFO  - Training [2][  140/  196]   Loss 0.778089   Top1 73.783482   Top5 96.738281   BatchTime 0.371092   LR 0.004146   
2022-11-25 11:23:33,188 - INFO  - Training [2][  160/  196]   Loss 0.779509   Top1 73.830566   Top5 96.760254   BatchTime 0.369478   LR 0.004085   
2022-11-25 11:23:39,238 - INFO  - Training [2][  180/  196]   Loss 0.777639   Top1 73.934462   Top5 96.701389   BatchTime 0.362039   LR 0.004022   
2022-11-25 11:23:44,507 - INFO  - ==> Top1: 74.146    Top5: 96.738    Loss: 0.772

2022-11-25 11:23:44,847 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:23:46,549 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:23:50,184 - INFO  - Validation [2][   20/   40]   Loss 0.635498   Top1 78.886719   Top5 98.378906   BatchTime 0.181586   
2022-11-25 11:23:51,211 - INFO  - Validation [2][   40/   40]   Loss 0.623161   Top1 78.830000   Top5 98.520000   BatchTime 0.116481   
2022-11-25 11:23:51,427 - INFO  - ==> Top1: 78.830    Top5: 98.520    Loss: 0.623

2022-11-25 11:23:51,427 - INFO  - ==> Sparsity : 0.275

2022-11-25 11:23:51,427 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 78.830   Top5: 98.520]
2022-11-25 11:23:51,427 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 76.170   Top5: 97.740]
2022-11-25 11:23:51,428 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 74.050   Top5: 97.880]
2022-11-25 11:23:57,244 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:23:57,247 - INFO  - >>>>>> Epoch   3
2022-11-25 11:23:57,249 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:24:05,600 - INFO  - Training [3][   20/  196]   Loss 0.752663   Top1 74.726562   Top5 96.718750   BatchTime 0.417437   LR 0.003907   
2022-11-25 11:24:12,966 - INFO  - Training [3][   40/  196]   Loss 0.742807   Top1 75.195312   Top5 96.845703   BatchTime 0.392859   LR 0.003840   
2022-11-25 11:24:20,261 - INFO  - Training [3][   60/  196]   Loss 0.739871   Top1 75.052083   Top5 96.920573   BatchTime 0.383489   LR 0.003771   
2022-11-25 11:24:27,309 - INFO  - Training [3][   80/  196]   Loss 0.725311   Top1 75.732422   Top5 97.055664   BatchTime 0.375720   LR 0.003701   
2022-11-25 11:24:34,985 - INFO  - Training [3][  100/  196]   Loss 0.711092   Top1 76.316406   Top5 97.167969   BatchTime 0.377328   LR 0.003630   
2022-11-25 11:24:42,678 - INFO  - Training [3][  120/  196]   Loss 0.705416   Top1 76.562500   Top5 97.281901   BatchTime 0.378548   LR 0.003558   
2022-11-25 11:24:49,925 - INFO  - Training [3][  140/  196]   Loss 0.701352   Top1 76.699219   Top5 97.307478   BatchTime 0.376233   LR 0.003484   
2022-11-25 11:24:56,016 - INFO  - Training [3][  160/  196]   Loss 0.701080   Top1 76.701660   Top5 97.341309   BatchTime 0.367275   LR 0.003410   
2022-11-25 11:25:03,696 - INFO  - Training [3][  180/  196]   Loss 0.698114   Top1 76.727431   Top5 97.341580   BatchTime 0.369134   LR 0.003335   
2022-11-25 11:25:09,607 - INFO  - ==> Top1: 76.780    Top5: 97.310    Loss: 0.695

2022-11-25 11:25:09,874 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:25:11,921 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:25:15,154 - INFO  - Validation [3][   20/   40]   Loss 0.590158   Top1 80.117188   Top5 98.085938   BatchTime 0.161559   
2022-11-25 11:25:16,224 - INFO  - Validation [3][   40/   40]   Loss 0.595873   Top1 80.250000   Top5 98.170000   BatchTime 0.107519   
2022-11-25 11:25:16,424 - INFO  - ==> Top1: 80.250    Top5: 98.170    Loss: 0.596

2022-11-25 11:25:16,424 - INFO  - ==> Sparsity : 0.339

2022-11-25 11:25:16,424 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 80.250   Top5: 98.170]
2022-11-25 11:25:16,424 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 78.830   Top5: 98.520]
2022-11-25 11:25:16,424 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 76.170   Top5: 97.740]
2022-11-25 11:25:21,830 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:25:21,832 - INFO  - >>>>>> Epoch   4
2022-11-25 11:25:21,834 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:25:30,461 - INFO  - Training [4][   20/  196]   Loss 0.690537   Top1 76.660156   Top5 96.640625   BatchTime 0.431200   LR 0.003200   
2022-11-25 11:25:37,676 - INFO  - Training [4][   40/  196]   Loss 0.671614   Top1 77.656250   Top5 97.187500   BatchTime 0.395981   LR 0.003122   
2022-11-25 11:25:44,727 - INFO  - Training [4][   60/  196]   Loss 0.665749   Top1 77.864583   Top5 97.317708   BatchTime 0.381509   LR 0.003044   
2022-11-25 11:25:51,757 - INFO  - Training [4][   80/  196]   Loss 0.663249   Top1 77.827148   Top5 97.402344   BatchTime 0.374004   LR 0.002965   
2022-11-25 11:25:59,250 - INFO  - Training [4][  100/  196]   Loss 0.656790   Top1 78.089844   Top5 97.453125   BatchTime 0.374127   LR 0.002886   
2022-11-25 11:26:06,537 - INFO  - Training [4][  120/  196]   Loss 0.649980   Top1 78.304036   Top5 97.522786   BatchTime 0.372501   LR 0.002806   
2022-11-25 11:26:13,166 - INFO  - Training [4][  140/  196]   Loss 0.648924   Top1 78.348214   Top5 97.572545   BatchTime 0.366632   LR 0.002726   
2022-11-25 11:26:21,147 - INFO  - Training [4][  160/  196]   Loss 0.649112   Top1 78.315430   Top5 97.609863   BatchTime 0.370685   LR 0.002646   
2022-11-25 11:26:28,492 - INFO  - Training [4][  180/  196]   Loss 0.645870   Top1 78.448351   Top5 97.556424   BatchTime 0.370306   LR 0.002566   
2022-11-25 11:26:34,582 - INFO  - ==> Top1: 78.512    Top5: 97.560    Loss: 0.643

2022-11-25 11:26:34,861 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:26:36,844 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:26:39,160 - INFO  - Validation [4][   20/   40]   Loss 0.493526   Top1 83.085938   Top5 99.277344   BatchTime 0.115687   
2022-11-25 11:26:40,252 - INFO  - Validation [4][   40/   40]   Loss 0.473579   Top1 83.590000   Top5 99.390000   BatchTime 0.085142   
2022-11-25 11:26:40,469 - INFO  - ==> Top1: 83.590    Top5: 99.390    Loss: 0.474

2022-11-25 11:26:40,470 - INFO  - ==> Sparsity : 0.317

2022-11-25 11:26:40,470 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 83.590   Top5: 99.390]
2022-11-25 11:26:40,470 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 80.250   Top5: 98.170]
2022-11-25 11:26:40,470 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 78.830   Top5: 98.520]
2022-11-25 11:26:46,305 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:26:46,307 - INFO  - >>>>>> Epoch   5
2022-11-25 11:26:46,309 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:26:55,287 - INFO  - Training [5][   20/  196]   Loss 0.617332   Top1 79.726562   Top5 97.304688   BatchTime 0.448768   LR 0.002424   
2022-11-25 11:27:02,289 - INFO  - Training [5][   40/  196]   Loss 0.632386   Top1 78.710938   Top5 97.509766   BatchTime 0.399442   LR 0.002343   
2022-11-25 11:27:09,468 - INFO  - Training [5][   60/  196]   Loss 0.621105   Top1 79.095052   Top5 97.460938   BatchTime 0.385935   LR 0.002263   
2022-11-25 11:27:16,937 - INFO  - Training [5][   80/  196]   Loss 0.612264   Top1 79.394531   Top5 97.636719   BatchTime 0.382811   LR 0.002183   
2022-11-25 11:27:23,998 - INFO  - Training [5][  100/  196]   Loss 0.603443   Top1 79.632812   Top5 97.675781   BatchTime 0.376862   LR 0.002104   
2022-11-25 11:27:29,802 - INFO  - Training [5][  120/  196]   Loss 0.596468   Top1 79.954427   Top5 97.786458   BatchTime 0.362413   LR 0.002024   
2022-11-25 11:27:36,865 - INFO  - Training [5][  140/  196]   Loss 0.593122   Top1 80.066964   Top5 97.812500   BatchTime 0.361095   LR 0.001946   
2022-11-25 11:27:43,803 - INFO  - Training [5][  160/  196]   Loss 0.595252   Top1 79.997559   Top5 97.790527   BatchTime 0.359315   LR 0.001868   
2022-11-25 11:27:51,148 - INFO  - Training [5][  180/  196]   Loss 0.592759   Top1 80.101997   Top5 97.743056   BatchTime 0.360196   LR 0.001790   
2022-11-25 11:27:57,155 - INFO  - ==> Top1: 80.178    Top5: 97.760    Loss: 0.589

2022-11-25 11:27:57,395 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:27:59,450 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:28:02,092 - INFO  - Validation [5][   20/   40]   Loss 0.429830   Top1 85.429688   Top5 99.335938   BatchTime 0.132001   
2022-11-25 11:28:03,121 - INFO  - Validation [5][   40/   40]   Loss 0.418158   Top1 85.560000   Top5 99.420000   BatchTime 0.091722   
2022-11-25 11:28:03,332 - INFO  - ==> Top1: 85.560    Top5: 99.420    Loss: 0.418

2022-11-25 11:28:03,333 - INFO  - ==> Sparsity : 0.325

2022-11-25 11:28:03,333 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 85.560   Top5: 99.420]
2022-11-25 11:28:03,333 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 83.590   Top5: 99.390]
2022-11-25 11:28:03,333 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 80.250   Top5: 98.170]
2022-11-25 11:28:09,270 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:28:09,275 - INFO  - >>>>>> Epoch   6
2022-11-25 11:28:09,277 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:28:17,961 - INFO  - Training [6][   20/  196]   Loss 0.586829   Top1 80.000000   Top5 97.656250   BatchTime 0.434036   LR 0.001655   
2022-11-25 11:28:24,811 - INFO  - Training [6][   40/  196]   Loss 0.582934   Top1 80.136719   Top5 97.626953   BatchTime 0.388271   LR 0.001580   
2022-11-25 11:28:32,045 - INFO  - Training [6][   60/  196]   Loss 0.566034   Top1 80.885417   Top5 97.669271   BatchTime 0.379417   LR 0.001506   
2022-11-25 11:28:39,330 - INFO  - Training [6][   80/  196]   Loss 0.557906   Top1 81.259766   Top5 97.880859   BatchTime 0.375620   LR 0.001432   
2022-11-25 11:28:45,104 - INFO  - Training [6][  100/  196]   Loss 0.548787   Top1 81.535156   Top5 97.921875   BatchTime 0.358236   LR 0.001360   
2022-11-25 11:28:50,270 - INFO  - Training [6][  120/  196]   Loss 0.545918   Top1 81.699219   Top5 97.981771   BatchTime 0.341578   LR 0.001289   
2022-11-25 11:28:57,353 - INFO  - Training [6][  140/  196]   Loss 0.546752   Top1 81.646205   Top5 98.035714   BatchTime 0.343374   LR 0.001220   
2022-11-25 11:29:04,817 - INFO  - Training [6][  160/  196]   Loss 0.547381   Top1 81.550293   Top5 98.017578   BatchTime 0.347103   LR 0.001151   
2022-11-25 11:29:12,506 - INFO  - Training [6][  180/  196]   Loss 0.544693   Top1 81.612413   Top5 97.947049   BatchTime 0.351255   LR 0.001084   
2022-11-25 11:29:18,468 - INFO  - ==> Top1: 81.654    Top5: 97.956    Loss: 0.544

2022-11-25 11:29:18,750 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:29:20,094 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:29:22,930 - INFO  - Validation [6][   20/   40]   Loss 0.386833   Top1 87.207031   Top5 99.355469   BatchTime 0.141670   
2022-11-25 11:29:26,075 - INFO  - Validation [6][   40/   40]   Loss 0.373390   Top1 87.280000   Top5 99.570000   BatchTime 0.149470   
2022-11-25 11:29:26,318 - INFO  - ==> Top1: 87.280    Top5: 99.570    Loss: 0.373

2022-11-25 11:29:26,318 - INFO  - ==> Sparsity : 0.355

2022-11-25 11:29:26,319 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
2022-11-25 11:29:26,319 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 85.560   Top5: 99.420]
2022-11-25 11:29:26,319 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 83.590   Top5: 99.390]
2022-11-25 11:29:32,148 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:29:32,150 - INFO  - >>>>>> Epoch   7
2022-11-25 11:29:32,151 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:29:40,857 - INFO  - Training [7][   20/  196]   Loss 0.539054   Top1 81.562500   Top5 97.500000   BatchTime 0.435175   LR 0.000969   
2022-11-25 11:29:48,274 - INFO  - Training [7][   40/  196]   Loss 0.529116   Top1 82.207031   Top5 97.978516   BatchTime 0.403002   LR 0.000907   
2022-11-25 11:29:55,958 - INFO  - Training [7][   60/  196]   Loss 0.520880   Top1 82.662760   Top5 98.053385   BatchTime 0.396728   LR 0.000845   
2022-11-25 11:30:02,300 - INFO  - Training [7][   80/  196]   Loss 0.516600   Top1 82.739258   Top5 98.222656   BatchTime 0.376828   LR 0.000786   
2022-11-25 11:30:09,441 - INFO  - Training [7][  100/  196]   Loss 0.507641   Top1 83.074219   Top5 98.265625   BatchTime 0.372870   LR 0.000728   
2022-11-25 11:30:16,974 - INFO  - Training [7][  120/  196]   Loss 0.505611   Top1 83.102214   Top5 98.323568   BatchTime 0.373499   LR 0.000673   
2022-11-25 11:30:24,386 - INFO  - Training [7][  140/  196]   Loss 0.506346   Top1 83.060826   Top5 98.328683   BatchTime 0.373085   LR 0.000619   
2022-11-25 11:30:31,703 - INFO  - Training [7][  160/  196]   Loss 0.509379   Top1 82.902832   Top5 98.298340   BatchTime 0.372178   LR 0.000567   
2022-11-25 11:30:38,982 - INFO  - Training [7][  180/  196]   Loss 0.511151   Top1 82.840712   Top5 98.244358   BatchTime 0.371262   LR 0.000517   
2022-11-25 11:30:45,305 - INFO  - ==> Top1: 82.866    Top5: 98.244    Loss: 0.509

2022-11-25 11:30:45,632 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:30:47,123 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:30:49,472 - INFO  - Validation [7][   20/   40]   Loss 0.394080   Top1 86.523438   Top5 99.453125   BatchTime 0.117357   
2022-11-25 11:30:50,502 - INFO  - Validation [7][   40/   40]   Loss 0.387614   Top1 86.690000   Top5 99.470000   BatchTime 0.084437   
2022-11-25 11:30:50,744 - INFO  - ==> Top1: 86.690    Top5: 99.470    Loss: 0.388

2022-11-25 11:30:50,744 - INFO  - ==> Sparsity : 0.378

2022-11-25 11:30:50,745 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
2022-11-25 11:30:50,745 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
2022-11-25 11:30:50,745 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 85.560   Top5: 99.420]
2022-11-25 11:30:51,106 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:30:51,107 - INFO  - >>>>>> Epoch   8
2022-11-25 11:30:51,109 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:31:00,056 - INFO  - Training [8][   20/  196]   Loss 0.504432   Top1 83.066406   Top5 97.792969   BatchTime 0.447218   LR 0.000434   
2022-11-25 11:31:07,549 - INFO  - Training [8][   40/  196]   Loss 0.497548   Top1 83.046875   Top5 97.998047   BatchTime 0.410931   LR 0.000389   
2022-11-25 11:31:15,917 - INFO  - Training [8][   60/  196]   Loss 0.499035   Top1 83.242188   Top5 97.910156   BatchTime 0.413431   LR 0.000347   
2022-11-25 11:31:22,003 - INFO  - Training [8][   80/  196]   Loss 0.498141   Top1 83.212891   Top5 98.056641   BatchTime 0.386141   LR 0.000308   
2022-11-25 11:31:29,242 - INFO  - Training [8][  100/  196]   Loss 0.490663   Top1 83.429688   Top5 98.156250   BatchTime 0.381304   LR 0.000270   
2022-11-25 11:31:36,804 - INFO  - Training [8][  120/  196]   Loss 0.483779   Top1 83.603516   Top5 98.271484   BatchTime 0.380768   LR 0.000235   
2022-11-25 11:31:44,318 - INFO  - Training [8][  140/  196]   Loss 0.476849   Top1 83.861607   Top5 98.339844   BatchTime 0.380045   LR 0.000202   
2022-11-25 11:31:52,000 - INFO  - Training [8][  160/  196]   Loss 0.481357   Top1 83.737793   Top5 98.342285   BatchTime 0.380554   LR 0.000172   
2022-11-25 11:31:59,237 - INFO  - Training [8][  180/  196]   Loss 0.479796   Top1 83.808594   Top5 98.268229   BatchTime 0.378474   LR 0.000143   
2022-11-25 11:32:05,269 - INFO  - ==> Top1: 83.930    Top5: 98.262    Loss: 0.478

2022-11-25 11:32:05,566 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:32:07,204 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:32:10,131 - INFO  - Validation [8][   20/   40]   Loss 0.355714   Top1 87.890625   Top5 99.570312   BatchTime 0.146211   
2022-11-25 11:32:11,254 - INFO  - Validation [8][   40/   40]   Loss 0.343951   Top1 88.150000   Top5 99.650000   BatchTime 0.101196   
2022-11-25 11:32:11,464 - INFO  - ==> Top1: 88.150    Top5: 99.650    Loss: 0.344

2022-11-25 11:32:11,464 - INFO  - ==> Sparsity : 0.382

2022-11-25 11:32:11,464 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:32:11,465 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
2022-11-25 11:32:11,465 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
2022-11-25 11:32:16,444 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:32:16,449 - INFO  - >>>>>> Epoch   9
2022-11-25 11:32:16,451 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:32:25,454 - INFO  - Training [9][   20/  196]   Loss 0.479152   Top1 83.613281   Top5 97.988281   BatchTime 0.450032   LR 0.000100   
2022-11-25 11:32:33,053 - INFO  - Training [9][   40/  196]   Loss 0.490569   Top1 83.193359   Top5 98.154297   BatchTime 0.414975   LR 0.000079   
2022-11-25 11:32:39,328 - INFO  - Training [9][   60/  196]   Loss 0.484753   Top1 83.483073   Top5 98.164062   BatchTime 0.381231   LR 0.000060   
2022-11-25 11:32:45,499 - INFO  - Training [9][   80/  196]   Loss 0.483711   Top1 83.569336   Top5 98.256836   BatchTime 0.363060   LR 0.000044   
2022-11-25 11:32:52,831 - INFO  - Training [9][  100/  196]   Loss 0.476153   Top1 83.859375   Top5 98.261719   BatchTime 0.363767   LR 0.000030   
2022-11-25 11:33:00,479 - INFO  - Training [9][  120/  196]   Loss 0.471479   Top1 84.059245   Top5 98.323568   BatchTime 0.366872   LR 0.000019   
2022-11-25 11:33:07,990 - INFO  - Training [9][  140/  196]   Loss 0.470606   Top1 84.121094   Top5 98.381696   BatchTime 0.368115   LR 0.000010   
2022-11-25 11:33:15,144 - INFO  - Training [9][  160/  196]   Loss 0.472593   Top1 84.084473   Top5 98.347168   BatchTime 0.366810   LR 0.000004   
2022-11-25 11:33:22,518 - INFO  - Training [9][  180/  196]   Loss 0.472619   Top1 84.086372   Top5 98.287760   BatchTime 0.367023   LR 0.000001   
2022-11-25 11:33:29,170 - INFO  - ==> Top1: 84.154    Top5: 98.306    Loss: 0.470

2022-11-25 11:33:29,421 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:33:30,737 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:33:33,068 - INFO  - Validation [9][   20/   40]   Loss 0.430953   Top1 85.742188   Top5 99.414062   BatchTime 0.116448   
2022-11-25 11:33:34,107 - INFO  - Validation [9][   40/   40]   Loss 0.422394   Top1 85.990000   Top5 99.430000   BatchTime 0.084207   
2022-11-25 11:33:34,337 - INFO  - ==> Top1: 85.990    Top5: 99.430    Loss: 0.422

2022-11-25 11:33:34,338 - INFO  - ==> Sparsity : 0.385

2022-11-25 11:33:34,338 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:33:34,338 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
2022-11-25 11:33:34,338 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
2022-11-25 11:33:34,469 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:33:34,471 - INFO  - >>>>>> Epoch  10
2022-11-25 11:33:34,473 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:33:43,130 - INFO  - Training [10][   20/  196]   Loss 0.541183   Top1 81.562500   Top5 97.812500   BatchTime 0.432702   LR 0.002500   
2022-11-25 11:33:50,999 - INFO  - Training [10][   40/  196]   Loss 0.547983   Top1 81.201172   Top5 97.968750   BatchTime 0.413071   LR 0.002499   
2022-11-25 11:33:57,595 - INFO  - Training [10][   60/  196]   Loss 0.554575   Top1 81.035156   Top5 98.059896   BatchTime 0.385314   LR 0.002499   
2022-11-25 11:34:03,163 - INFO  - Training [10][   80/  196]   Loss 0.557130   Top1 81.186523   Top5 98.066406   BatchTime 0.358583   LR 0.002497   
2022-11-25 11:34:09,731 - INFO  - Training [10][  100/  196]   Loss 0.553021   Top1 81.359375   Top5 98.062500   BatchTime 0.352545   LR 0.002496   
2022-11-25 11:34:17,111 - INFO  - Training [10][  120/  196]   Loss 0.551728   Top1 81.510417   Top5 98.082682   BatchTime 0.355288   LR 0.002494   
2022-11-25 11:34:24,464 - INFO  - Training [10][  140/  196]   Loss 0.551747   Top1 81.523438   Top5 98.133371   BatchTime 0.357050   LR 0.002492   
2022-11-25 11:34:31,654 - INFO  - Training [10][  160/  196]   Loss 0.554557   Top1 81.379395   Top5 98.110352   BatchTime 0.357360   LR 0.002490   
2022-11-25 11:34:38,612 - INFO  - Training [10][  180/  196]   Loss 0.555874   Top1 81.354167   Top5 98.044705   BatchTime 0.356309   LR 0.002487   
2022-11-25 11:34:44,682 - INFO  - ==> Top1: 81.272    Top5: 98.016    Loss: 0.557

2022-11-25 11:34:44,972 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:34:46,618 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:34:49,173 - INFO  - Validation [10][   20/   40]   Loss 0.470347   Top1 83.964844   Top5 99.160156   BatchTime 0.127666   
2022-11-25 11:34:50,193 - INFO  - Validation [10][   40/   40]   Loss 0.445405   Top1 85.010000   Top5 99.200000   BatchTime 0.089328   
2022-11-25 11:34:50,421 - INFO  - ==> Top1: 85.010    Top5: 99.200    Loss: 0.445

2022-11-25 11:34:50,421 - INFO  - ==> Sparsity : 0.354

2022-11-25 11:34:50,422 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:34:50,422 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
2022-11-25 11:34:50,422 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
2022-11-25 11:34:50,565 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:34:50,566 - INFO  - >>>>>> Epoch  11
2022-11-25 11:34:50,568 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:34:58,952 - INFO  - Training [11][   20/  196]   Loss 0.576115   Top1 80.058594   Top5 97.460938   BatchTime 0.419053   LR 0.002481   
2022-11-25 11:35:05,705 - INFO  - Training [11][   40/  196]   Loss 0.573980   Top1 80.507812   Top5 97.597656   BatchTime 0.378340   LR 0.002478   
2022-11-25 11:35:13,473 - INFO  - Training [11][   60/  196]   Loss 0.571492   Top1 80.787760   Top5 97.721354   BatchTime 0.381693   LR 0.002474   
2022-11-25 11:35:20,106 - INFO  - Training [11][   80/  196]   Loss 0.569848   Top1 80.888672   Top5 97.788086   BatchTime 0.369189   LR 0.002470   
2022-11-25 11:35:26,920 - INFO  - Training [11][  100/  196]   Loss 0.562898   Top1 81.179688   Top5 97.828125   BatchTime 0.363487   LR 0.002465   
2022-11-25 11:35:34,136 - INFO  - Training [11][  120/  196]   Loss 0.558057   Top1 81.334635   Top5 97.884115   BatchTime 0.363038   LR 0.002460   
2022-11-25 11:35:41,619 - INFO  - Training [11][  140/  196]   Loss 0.560004   Top1 81.269531   Top5 97.901786   BatchTime 0.364626   LR 0.002455   
2022-11-25 11:35:48,968 - INFO  - Training [11][  160/  196]   Loss 0.564088   Top1 81.130371   Top5 97.893066   BatchTime 0.364976   LR 0.002450   
2022-11-25 11:35:56,744 - INFO  - Training [11][  180/  196]   Loss 0.562273   Top1 81.178385   Top5 97.855903   BatchTime 0.367624   LR 0.002444   
2022-11-25 11:36:02,911 - INFO  - ==> Top1: 81.124    Top5: 97.862    Loss: 0.564

2022-11-25 11:36:03,170 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:36:05,292 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:36:07,827 - INFO  - Validation [11][   20/   40]   Loss 0.471629   Top1 84.863281   Top5 99.160156   BatchTime 0.126671   
2022-11-25 11:36:08,863 - INFO  - Validation [11][   40/   40]   Loss 0.463346   Top1 84.820000   Top5 99.330000   BatchTime 0.089238   
2022-11-25 11:36:09,091 - INFO  - ==> Top1: 84.820    Top5: 99.330    Loss: 0.463

2022-11-25 11:36:09,091 - INFO  - ==> Sparsity : 0.371

2022-11-25 11:36:09,091 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:36:09,092 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
2022-11-25 11:36:09,092 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
2022-11-25 11:36:09,234 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:36:09,236 - INFO  - >>>>>> Epoch  12
2022-11-25 11:36:09,238 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:36:17,792 - INFO  - Training [12][   20/  196]   Loss 0.582583   Top1 80.957031   Top5 97.402344   BatchTime 0.427575   LR 0.002433   
2022-11-25 11:36:25,471 - INFO  - Training [12][   40/  196]   Loss 0.570571   Top1 81.191406   Top5 97.773438   BatchTime 0.405768   LR 0.002426   
2022-11-25 11:36:33,153 - INFO  - Training [12][   60/  196]   Loss 0.563050   Top1 81.354167   Top5 97.812500   BatchTime 0.398545   LR 0.002419   
2022-11-25 11:36:39,630 - INFO  - Training [12][   80/  196]   Loss 0.554230   Top1 81.503906   Top5 97.861328   BatchTime 0.379875   LR 0.002412   
2022-11-25 11:36:46,467 - INFO  - Training [12][  100/  196]   Loss 0.546425   Top1 81.781250   Top5 97.945312   BatchTime 0.372262   LR 0.002404   
2022-11-25 11:36:53,764 - INFO  - Training [12][  120/  196]   Loss 0.538152   Top1 82.076823   Top5 98.066406   BatchTime 0.371026   LR 0.002396   
2022-11-25 11:37:01,596 - INFO  - Training [12][  140/  196]   Loss 0.537551   Top1 82.059152   Top5 98.097098   BatchTime 0.373963   LR 0.002388   
2022-11-25 11:37:08,754 - INFO  - Training [12][  160/  196]   Loss 0.539040   Top1 81.972656   Top5 98.107910   BatchTime 0.371956   LR 0.002380   
2022-11-25 11:37:16,258 - INFO  - Training [12][  180/  196]   Loss 0.538464   Top1 81.976997   Top5 98.053385   BatchTime 0.372318   LR 0.002371   
2022-11-25 11:37:22,364 - INFO  - ==> Top1: 82.114    Top5: 98.072    Loss: 0.535

2022-11-25 11:37:22,669 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:37:24,383 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:37:26,901 - INFO  - Validation [12][   20/   40]   Loss 0.416398   Top1 86.210938   Top5 99.453125   BatchTime 0.125763   
2022-11-25 11:37:28,070 - INFO  - Validation [12][   40/   40]   Loss 0.414525   Top1 86.170000   Top5 99.500000   BatchTime 0.092115   
2022-11-25 11:37:28,302 - INFO  - ==> Top1: 86.170    Top5: 99.500    Loss: 0.415

2022-11-25 11:37:28,302 - INFO  - ==> Sparsity : 0.391

2022-11-25 11:37:28,302 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:37:28,302 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
2022-11-25 11:37:28,303 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
2022-11-25 11:37:28,426 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:37:28,427 - INFO  - >>>>>> Epoch  13
2022-11-25 11:37:28,429 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:37:36,655 - INFO  - Training [13][   20/  196]   Loss 0.524309   Top1 82.187500   Top5 97.578125   BatchTime 0.411166   LR 0.002355   
2022-11-25 11:37:43,860 - INFO  - Training [13][   40/  196]   Loss 0.540574   Top1 81.562500   Top5 97.753906   BatchTime 0.385702   LR 0.002345   
2022-11-25 11:37:51,050 - INFO  - Training [13][   60/  196]   Loss 0.532666   Top1 81.907552   Top5 97.884115   BatchTime 0.376965   LR 0.002336   
2022-11-25 11:37:57,275 - INFO  - Training [13][   80/  196]   Loss 0.537137   Top1 81.850586   Top5 97.871094   BatchTime 0.360537   LR 0.002325   
2022-11-25 11:38:04,329 - INFO  - Training [13][  100/  196]   Loss 0.530256   Top1 82.136719   Top5 97.914062   BatchTime 0.358972   LR 0.002315   
2022-11-25 11:38:11,551 - INFO  - Training [13][  120/  196]   Loss 0.526935   Top1 82.327474   Top5 97.991536   BatchTime 0.359329   LR 0.002304   
2022-11-25 11:38:18,734 - INFO  - Training [13][  140/  196]   Loss 0.525483   Top1 82.399554   Top5 98.071987   BatchTime 0.359302   LR 0.002293   
2022-11-25 11:38:26,221 - INFO  - Training [13][  160/  196]   Loss 0.527024   Top1 82.343750   Top5 98.093262   BatchTime 0.361177   LR 0.002282   
2022-11-25 11:38:33,364 - INFO  - Training [13][  180/  196]   Loss 0.526706   Top1 82.311198   Top5 98.036024   BatchTime 0.360734   LR 0.002271   
2022-11-25 11:38:39,896 - INFO  - ==> Top1: 82.372    Top5: 98.034    Loss: 0.525

2022-11-25 11:38:40,186 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:38:42,048 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:38:44,393 - INFO  - Validation [13][   20/   40]   Loss 0.431338   Top1 85.625000   Top5 99.218750   BatchTime 0.117203   
2022-11-25 11:38:45,495 - INFO  - Validation [13][   40/   40]   Loss 0.418862   Top1 85.790000   Top5 99.370000   BatchTime 0.086152   
2022-11-25 11:38:45,736 - INFO  - ==> Top1: 85.790    Top5: 99.370    Loss: 0.419

2022-11-25 11:38:45,736 - INFO  - ==> Sparsity : 0.388

2022-11-25 11:38:45,736 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:38:45,736 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
2022-11-25 11:38:45,736 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 86.690   Top5: 99.470]
2022-11-25 11:38:45,857 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:38:45,859 - INFO  - >>>>>> Epoch  14
2022-11-25 11:38:45,861 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:38:54,567 - INFO  - Training [14][   20/  196]   Loss 0.522021   Top1 82.363281   Top5 97.539062   BatchTime 0.435200   LR 0.002250   
2022-11-25 11:39:01,953 - INFO  - Training [14][   40/  196]   Loss 0.529107   Top1 82.138672   Top5 97.773438   BatchTime 0.402254   LR 0.002238   
2022-11-25 11:39:09,024 - INFO  - Training [14][   60/  196]   Loss 0.519941   Top1 82.539062   Top5 97.962240   BatchTime 0.386012   LR 0.002225   
2022-11-25 11:39:15,207 - INFO  - Training [14][   80/  196]   Loss 0.516161   Top1 82.739258   Top5 98.051758   BatchTime 0.366804   LR 0.002213   
2022-11-25 11:39:21,861 - INFO  - Training [14][  100/  196]   Loss 0.513440   Top1 82.812500   Top5 98.085938   BatchTime 0.359977   LR 0.002200   
2022-11-25 11:39:29,694 - INFO  - Training [14][  120/  196]   Loss 0.507248   Top1 82.958984   Top5 98.183594   BatchTime 0.365258   LR 0.002186   
2022-11-25 11:39:36,989 - INFO  - Training [14][  140/  196]   Loss 0.508391   Top1 83.010603   Top5 98.244978   BatchTime 0.365183   LR 0.002173   
2022-11-25 11:39:44,227 - INFO  - Training [14][  160/  196]   Loss 0.508463   Top1 83.081055   Top5 98.212891   BatchTime 0.364773   LR 0.002159   
2022-11-25 11:39:51,506 - INFO  - Training [14][  180/  196]   Loss 0.509005   Top1 83.116319   Top5 98.140191   BatchTime 0.364679   LR 0.002145   
2022-11-25 11:39:57,580 - INFO  - ==> Top1: 83.166    Top5: 98.130    Loss: 0.507

2022-11-25 11:39:57,820 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:39:59,193 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:40:01,806 - INFO  - Validation [14][   20/   40]   Loss 0.379010   Top1 87.851562   Top5 99.472656   BatchTime 0.130534   
2022-11-25 11:40:02,961 - INFO  - Validation [14][   40/   40]   Loss 0.369061   Top1 87.800000   Top5 99.570000   BatchTime 0.094149   
2022-11-25 11:40:03,210 - INFO  - ==> Top1: 87.800    Top5: 99.570    Loss: 0.369

2022-11-25 11:40:03,210 - INFO  - ==> Sparsity : 0.384

2022-11-25 11:40:03,210 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:40:03,210 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
2022-11-25 11:40:03,211 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
2022-11-25 11:40:03,331 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:40:03,332 - INFO  - >>>>>> Epoch  15
2022-11-25 11:40:03,334 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:40:11,673 - INFO  - Training [15][   20/  196]   Loss 0.511158   Top1 82.890625   Top5 97.500000   BatchTime 0.416807   LR 0.002120   
2022-11-25 11:40:18,246 - INFO  - Training [15][   40/  196]   Loss 0.514768   Top1 82.783203   Top5 97.851562   BatchTime 0.372740   LR 0.002106   
2022-11-25 11:40:25,813 - INFO  - Training [15][   60/  196]   Loss 0.515495   Top1 82.721354   Top5 97.936198   BatchTime 0.374603   LR 0.002091   
2022-11-25 11:40:32,173 - INFO  - Training [15][   80/  196]   Loss 0.510986   Top1 82.978516   Top5 98.095703   BatchTime 0.360455   LR 0.002076   
2022-11-25 11:40:38,846 - INFO  - Training [15][  100/  196]   Loss 0.500057   Top1 83.277344   Top5 98.136719   BatchTime 0.355094   LR 0.002061   
2022-11-25 11:40:46,980 - INFO  - Training [15][  120/  196]   Loss 0.498954   Top1 83.310547   Top5 98.232422   BatchTime 0.363696   LR 0.002045   
2022-11-25 11:40:54,277 - INFO  - Training [15][  140/  196]   Loss 0.495987   Top1 83.454241   Top5 98.278460   BatchTime 0.363855   LR 0.002030   
2022-11-25 11:41:01,750 - INFO  - Training [15][  160/  196]   Loss 0.498925   Top1 83.317871   Top5 98.244629   BatchTime 0.365079   LR 0.002014   
2022-11-25 11:41:09,143 - INFO  - Training [15][  180/  196]   Loss 0.499712   Top1 83.272569   Top5 98.161892   BatchTime 0.365588   LR 0.001998   
2022-11-25 11:41:15,564 - INFO  - ==> Top1: 83.328    Top5: 98.168    Loss: 0.499

2022-11-25 11:41:15,854 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:41:17,574 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:41:20,212 - INFO  - Validation [15][   20/   40]   Loss 0.476669   Top1 84.179688   Top5 99.277344   BatchTime 0.131785   
2022-11-25 11:41:21,275 - INFO  - Validation [15][   40/   40]   Loss 0.489917   Top1 83.830000   Top5 99.380000   BatchTime 0.092477   
2022-11-25 11:41:21,504 - INFO  - ==> Top1: 83.830    Top5: 99.380    Loss: 0.490

2022-11-25 11:41:21,504 - INFO  - ==> Sparsity : 0.392

2022-11-25 11:41:21,504 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:41:21,504 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
2022-11-25 11:41:21,505 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 87.280   Top5: 99.570]
2022-11-25 11:41:21,658 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:41:21,660 - INFO  - >>>>>> Epoch  16
2022-11-25 11:41:21,661 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:41:30,613 - INFO  - Training [16][   20/  196]   Loss 0.523776   Top1 82.363281   Top5 97.851562   BatchTime 0.447446   LR 0.001969   
2022-11-25 11:41:38,006 - INFO  - Training [16][   40/  196]   Loss 0.509619   Top1 82.880859   Top5 97.978516   BatchTime 0.408540   LR 0.001953   
2022-11-25 11:41:45,039 - INFO  - Training [16][   60/  196]   Loss 0.498575   Top1 83.196615   Top5 98.098958   BatchTime 0.389582   LR 0.001936   
2022-11-25 11:41:51,050 - INFO  - Training [16][   80/  196]   Loss 0.501346   Top1 83.208008   Top5 98.173828   BatchTime 0.367322   LR 0.001919   
2022-11-25 11:41:58,260 - INFO  - Training [16][  100/  196]   Loss 0.493672   Top1 83.496094   Top5 98.191406   BatchTime 0.365961   LR 0.001902   
2022-11-25 11:42:05,899 - INFO  - Training [16][  120/  196]   Loss 0.486306   Top1 83.805339   Top5 98.268229   BatchTime 0.368619   LR 0.001885   
2022-11-25 11:42:13,600 - INFO  - Training [16][  140/  196]   Loss 0.482897   Top1 83.936942   Top5 98.328683   BatchTime 0.370966   LR 0.001867   
2022-11-25 11:42:20,516 - INFO  - Training [16][  160/  196]   Loss 0.483137   Top1 83.947754   Top5 98.352051   BatchTime 0.367822   LR 0.001850   
2022-11-25 11:42:27,668 - INFO  - Training [16][  180/  196]   Loss 0.481535   Top1 84.025608   Top5 98.307292   BatchTime 0.366686   LR 0.001832   
2022-11-25 11:42:33,834 - INFO  - ==> Top1: 84.044    Top5: 98.290    Loss: 0.481

2022-11-25 11:42:34,085 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:42:35,711 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:42:38,175 - INFO  - Validation [16][   20/   40]   Loss 0.370619   Top1 87.460938   Top5 99.394531   BatchTime 0.123085   
2022-11-25 11:42:39,187 - INFO  - Validation [16][   40/   40]   Loss 0.361248   Top1 87.650000   Top5 99.530000   BatchTime 0.086864   
2022-11-25 11:42:39,418 - INFO  - ==> Top1: 87.650    Top5: 99.530    Loss: 0.361

2022-11-25 11:42:39,418 - INFO  - ==> Sparsity : 0.404

2022-11-25 11:42:39,419 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:42:39,419 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
2022-11-25 11:42:39,419 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 87.650   Top5: 99.530]
2022-11-25 11:42:39,559 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:42:39,561 - INFO  - >>>>>> Epoch  17
2022-11-25 11:42:39,563 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:42:47,868 - INFO  - Training [17][   20/  196]   Loss 0.506595   Top1 82.695312   Top5 97.773438   BatchTime 0.415131   LR 0.001800   
2022-11-25 11:42:54,961 - INFO  - Training [17][   40/  196]   Loss 0.492261   Top1 83.457031   Top5 98.007812   BatchTime 0.384886   LR 0.001782   
2022-11-25 11:43:01,916 - INFO  - Training [17][   60/  196]   Loss 0.489050   Top1 83.574219   Top5 98.092448   BatchTime 0.372513   LR 0.001764   
2022-11-25 11:43:07,786 - INFO  - Training [17][   80/  196]   Loss 0.489408   Top1 83.676758   Top5 98.183594   BatchTime 0.352762   LR 0.001746   
2022-11-25 11:43:15,086 - INFO  - Training [17][  100/  196]   Loss 0.481978   Top1 83.843750   Top5 98.203125   BatchTime 0.355207   LR 0.001727   
2022-11-25 11:43:22,932 - INFO  - Training [17][  120/  196]   Loss 0.477646   Top1 84.007161   Top5 98.281250   BatchTime 0.361385   LR 0.001708   
2022-11-25 11:43:30,308 - INFO  - Training [17][  140/  196]   Loss 0.472420   Top1 84.160156   Top5 98.342634   BatchTime 0.362448   LR 0.001690   
2022-11-25 11:43:37,651 - INFO  - Training [17][  160/  196]   Loss 0.473107   Top1 84.194336   Top5 98.352051   BatchTime 0.363035   LR 0.001671   
2022-11-25 11:43:44,783 - INFO  - Training [17][  180/  196]   Loss 0.472168   Top1 84.214410   Top5 98.300781   BatchTime 0.362319   LR 0.001652   
2022-11-25 11:43:50,724 - INFO  - ==> Top1: 84.238    Top5: 98.302    Loss: 0.471

2022-11-25 11:43:51,032 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:43:52,417 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:43:54,907 - INFO  - Validation [17][   20/   40]   Loss 0.411748   Top1 86.347656   Top5 99.335938   BatchTime 0.124379   
2022-11-25 11:43:56,131 - INFO  - Validation [17][   40/   40]   Loss 0.391512   Top1 86.890000   Top5 99.550000   BatchTime 0.092812   
2022-11-25 11:43:56,415 - INFO  - ==> Top1: 86.890    Top5: 99.550    Loss: 0.392

2022-11-25 11:43:56,415 - INFO  - ==> Sparsity : 0.406

2022-11-25 11:43:56,415 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:43:56,416 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
2022-11-25 11:43:56,416 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 87.650   Top5: 99.530]
2022-11-25 11:43:56,533 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:43:56,534 - INFO  - >>>>>> Epoch  18
2022-11-25 11:43:56,536 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:44:05,538 - INFO  - Training [18][   20/  196]   Loss 0.468160   Top1 83.984375   Top5 97.558594   BatchTime 0.449992   LR 0.001618   
2022-11-25 11:44:12,845 - INFO  - Training [18][   40/  196]   Loss 0.468505   Top1 84.052734   Top5 97.890625   BatchTime 0.407661   LR 0.001599   
2022-11-25 11:44:19,514 - INFO  - Training [18][   60/  196]   Loss 0.466338   Top1 84.218750   Top5 98.059896   BatchTime 0.382932   LR 0.001579   
2022-11-25 11:44:25,369 - INFO  - Training [18][   80/  196]   Loss 0.469782   Top1 84.121094   Top5 98.129883   BatchTime 0.360385   LR 0.001560   
2022-11-25 11:44:32,706 - INFO  - Training [18][  100/  196]   Loss 0.464696   Top1 84.273438   Top5 98.238281   BatchTime 0.361671   LR 0.001540   
2022-11-25 11:44:40,814 - INFO  - Training [18][  120/  196]   Loss 0.455484   Top1 84.602865   Top5 98.346354   BatchTime 0.368958   LR 0.001521   
2022-11-25 11:44:47,780 - INFO  - Training [18][  140/  196]   Loss 0.454442   Top1 84.723772   Top5 98.356585   BatchTime 0.366009   LR 0.001501   
2022-11-25 11:44:54,650 - INFO  - Training [18][  160/  196]   Loss 0.456488   Top1 84.606934   Top5 98.354492   BatchTime 0.363194   LR 0.001482   
2022-11-25 11:45:01,802 - INFO  - Training [18][  180/  196]   Loss 0.455972   Top1 84.594184   Top5 98.313802   BatchTime 0.362572   LR 0.001462   
2022-11-25 11:45:07,501 - INFO  - ==> Top1: 84.712    Top5: 98.322    Loss: 0.453

2022-11-25 11:45:07,761 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:45:09,249 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:45:11,717 - INFO  - Validation [18][   20/   40]   Loss 0.388944   Top1 87.265625   Top5 99.394531   BatchTime 0.123335   
2022-11-25 11:45:12,814 - INFO  - Validation [18][   40/   40]   Loss 0.375382   Top1 87.470000   Top5 99.510000   BatchTime 0.089087   
2022-11-25 11:45:13,059 - INFO  - ==> Top1: 87.470    Top5: 99.510    Loss: 0.375

2022-11-25 11:45:13,059 - INFO  - ==> Sparsity : 0.411

2022-11-25 11:45:13,059 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:45:13,060 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
2022-11-25 11:45:13,060 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 87.650   Top5: 99.530]
2022-11-25 11:45:13,192 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:45:13,194 - INFO  - >>>>>> Epoch  19
2022-11-25 11:45:13,196 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:45:21,918 - INFO  - Training [19][   20/  196]   Loss 0.455500   Top1 83.984375   Top5 98.125000   BatchTime 0.435992   LR 0.001427   
2022-11-25 11:45:29,031 - INFO  - Training [19][   40/  196]   Loss 0.456768   Top1 84.375000   Top5 98.164062   BatchTime 0.395819   LR 0.001407   
2022-11-25 11:45:36,179 - INFO  - Training [19][   60/  196]   Loss 0.460026   Top1 84.348958   Top5 98.157552   BatchTime 0.383017   LR 0.001387   
2022-11-25 11:45:41,694 - INFO  - Training [19][   80/  196]   Loss 0.460430   Top1 84.384766   Top5 98.198242   BatchTime 0.356196   LR 0.001367   
2022-11-25 11:45:48,582 - INFO  - Training [19][  100/  196]   Loss 0.450926   Top1 84.777344   Top5 98.242188   BatchTime 0.353835   LR 0.001347   
2022-11-25 11:45:56,083 - INFO  - Training [19][  120/  196]   Loss 0.445460   Top1 84.996745   Top5 98.320312   BatchTime 0.357374   LR 0.001327   
2022-11-25 11:46:04,132 - INFO  - Training [19][  140/  196]   Loss 0.443576   Top1 85.122768   Top5 98.373326   BatchTime 0.363806   LR 0.001307   
2022-11-25 11:46:10,865 - INFO  - Training [19][  160/  196]   Loss 0.448095   Top1 84.982910   Top5 98.388672   BatchTime 0.360416   LR 0.001287   
2022-11-25 11:46:17,693 - INFO  - Training [19][  180/  196]   Loss 0.447575   Top1 84.950087   Top5 98.313802   BatchTime 0.358298   LR 0.001266   
2022-11-25 11:46:23,399 - INFO  - ==> Top1: 85.036    Top5: 98.306    Loss: 0.446

2022-11-25 11:46:23,657 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:46:25,285 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:46:27,706 - INFO  - Validation [19][   20/   40]   Loss 0.365642   Top1 88.222656   Top5 99.375000   BatchTime 0.120959   
2022-11-25 11:46:28,786 - INFO  - Validation [19][   40/   40]   Loss 0.346461   Top1 88.530000   Top5 99.580000   BatchTime 0.087477   
2022-11-25 11:46:29,026 - INFO  - ==> Top1: 88.530    Top5: 99.580    Loss: 0.346

2022-11-25 11:46:29,027 - INFO  - ==> Sparsity : 0.410

2022-11-25 11:46:29,027 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 88.530   Top5: 99.580]
2022-11-25 11:46:29,027 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:46:29,027 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 87.800   Top5: 99.570]
2022-11-25 11:46:34,475 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:46:34,477 - INFO  - >>>>>> Epoch  20
2022-11-25 11:46:34,479 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:46:43,568 - INFO  - Training [20][   20/  196]   Loss 0.432781   Top1 84.882812   Top5 97.714844   BatchTime 0.454285   LR 0.001231   
2022-11-25 11:46:50,826 - INFO  - Training [20][   40/  196]   Loss 0.445021   Top1 84.951172   Top5 98.066406   BatchTime 0.408618   LR 0.001211   
2022-11-25 11:46:57,379 - INFO  - Training [20][   60/  196]   Loss 0.436701   Top1 85.384115   Top5 98.248698   BatchTime 0.381610   LR 0.001191   
2022-11-25 11:47:04,052 - INFO  - Training [20][   80/  196]   Loss 0.439570   Top1 85.209961   Top5 98.330078   BatchTime 0.369627   LR 0.001171   
2022-11-25 11:47:11,180 - INFO  - Training [20][  100/  196]   Loss 0.431219   Top1 85.527344   Top5 98.394531   BatchTime 0.366979   LR 0.001151   
2022-11-25 11:47:18,761 - INFO  - Training [20][  120/  196]   Loss 0.426459   Top1 85.709635   Top5 98.486328   BatchTime 0.368989   LR 0.001131   
2022-11-25 11:47:26,243 - INFO  - Training [20][  140/  196]   Loss 0.423234   Top1 85.789621   Top5 98.532366   BatchTime 0.369716   LR 0.001111   
2022-11-25 11:47:33,529 - INFO  - Training [20][  160/  196]   Loss 0.427618   Top1 85.668945   Top5 98.520508   BatchTime 0.369041   LR 0.001091   
2022-11-25 11:47:40,717 - INFO  - Training [20][  180/  196]   Loss 0.427501   Top1 85.664062   Top5 98.476562   BatchTime 0.367968   LR 0.001071   
2022-11-25 11:47:47,144 - INFO  - ==> Top1: 85.712    Top5: 98.470    Loss: 0.426

2022-11-25 11:47:47,366 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:47:48,873 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:47:51,234 - INFO  - Validation [20][   20/   40]   Loss 0.343728   Top1 88.183594   Top5 99.550781   BatchTime 0.117938   
2022-11-25 11:47:52,340 - INFO  - Validation [20][   40/   40]   Loss 0.332594   Top1 88.460000   Top5 99.650000   BatchTime 0.086626   
2022-11-25 11:47:52,582 - INFO  - ==> Top1: 88.460    Top5: 99.650    Loss: 0.333

2022-11-25 11:47:52,583 - INFO  - ==> Sparsity : 0.413

2022-11-25 11:47:52,583 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 88.530   Top5: 99.580]
2022-11-25 11:47:52,583 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 88.460   Top5: 99.650]
2022-11-25 11:47:52,583 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 88.150   Top5: 99.650]
2022-11-25 11:47:52,717 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:47:52,719 - INFO  - >>>>>> Epoch  21
2022-11-25 11:47:52,721 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:48:01,967 - INFO  - Training [21][   20/  196]   Loss 0.441926   Top1 84.882812   Top5 97.558594   BatchTime 0.462183   LR 0.001036   
2022-11-25 11:48:09,070 - INFO  - Training [21][   40/  196]   Loss 0.428715   Top1 85.400391   Top5 98.164062   BatchTime 0.408670   LR 0.001016   
2022-11-25 11:48:15,635 - INFO  - Training [21][   60/  196]   Loss 0.423521   Top1 85.664062   Top5 98.203125   BatchTime 0.381863   LR 0.000996   
2022-11-25 11:48:22,127 - INFO  - Training [21][   80/  196]   Loss 0.422834   Top1 85.839844   Top5 98.286133   BatchTime 0.367539   LR 0.000976   
2022-11-25 11:48:29,460 - INFO  - Training [21][  100/  196]   Loss 0.418115   Top1 86.000000   Top5 98.339844   BatchTime 0.367365   LR 0.000957   
2022-11-25 11:48:37,210 - INFO  - Training [21][  120/  196]   Loss 0.412307   Top1 86.106771   Top5 98.440755   BatchTime 0.370719   LR 0.000937   
2022-11-25 11:48:44,728 - INFO  - Training [21][  140/  196]   Loss 0.412041   Top1 86.065848   Top5 98.537946   BatchTime 0.371457   LR 0.000918   
2022-11-25 11:48:51,644 - INFO  - Training [21][  160/  196]   Loss 0.413490   Top1 86.052246   Top5 98.535156   BatchTime 0.368252   LR 0.000899   
2022-11-25 11:48:58,897 - INFO  - Training [21][  180/  196]   Loss 0.413288   Top1 86.056858   Top5 98.478733   BatchTime 0.367625   LR 0.000879   
2022-11-25 11:49:04,879 - INFO  - ==> Top1: 86.102    Top5: 98.476    Loss: 0.412

2022-11-25 11:49:05,178 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:49:07,026 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:49:09,542 - INFO  - Validation [21][   20/   40]   Loss 0.339932   Top1 88.828125   Top5 99.550781   BatchTime 0.125693   
2022-11-25 11:49:10,656 - INFO  - Validation [21][   40/   40]   Loss 0.323474   Top1 89.180000   Top5 99.660000   BatchTime 0.090689   
2022-11-25 11:49:10,915 - INFO  - ==> Top1: 89.180    Top5: 99.660    Loss: 0.323

2022-11-25 11:49:10,915 - INFO  - ==> Sparsity : 0.418

2022-11-25 11:49:10,915 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 89.180   Top5: 99.660]
2022-11-25 11:49:10,915 - INFO  - Scoreboard best 2 ==> Epoch [19][Top1: 88.530   Top5: 99.580]
2022-11-25 11:49:10,916 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 88.460   Top5: 99.650]
2022-11-25 11:49:17,538 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:49:17,542 - INFO  - >>>>>> Epoch  22
2022-11-25 11:49:17,544 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:49:26,167 - INFO  - Training [22][   20/  196]   Loss 0.439484   Top1 85.175781   Top5 97.832031   BatchTime 0.431002   LR 0.000846   
2022-11-25 11:49:32,534 - INFO  - Training [22][   40/  196]   Loss 0.436437   Top1 85.449219   Top5 98.095703   BatchTime 0.374682   LR 0.000827   
2022-11-25 11:49:39,724 - INFO  - Training [22][   60/  196]   Loss 0.428545   Top1 85.559896   Top5 98.190104   BatchTime 0.369610   LR 0.000808   
2022-11-25 11:49:47,106 - INFO  - Training [22][   80/  196]   Loss 0.425642   Top1 85.712891   Top5 98.344727   BatchTime 0.369485   LR 0.000789   
2022-11-25 11:49:54,733 - INFO  - Training [22][  100/  196]   Loss 0.415836   Top1 86.093750   Top5 98.402344   BatchTime 0.371860   LR 0.000770   
2022-11-25 11:50:02,186 - INFO  - Training [22][  120/  196]   Loss 0.408445   Top1 86.331380   Top5 98.505859   BatchTime 0.371986   LR 0.000752   
2022-11-25 11:50:09,219 - INFO  - Training [22][  140/  196]   Loss 0.405707   Top1 86.431362   Top5 98.582589   BatchTime 0.369080   LR 0.000734   
2022-11-25 11:50:16,519 - INFO  - Training [22][  160/  196]   Loss 0.405011   Top1 86.408691   Top5 98.632812   BatchTime 0.368569   LR 0.000715   
2022-11-25 11:50:23,910 - INFO  - Training [22][  180/  196]   Loss 0.405812   Top1 86.330295   Top5 98.578559   BatchTime 0.368680   LR 0.000697   
2022-11-25 11:50:29,820 - INFO  - ==> Top1: 86.356    Top5: 98.576    Loss: 0.405

2022-11-25 11:50:30,149 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:50:33,073 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:50:35,957 - INFO  - Validation [22][   20/   40]   Loss 0.325362   Top1 89.199219   Top5 99.648438   BatchTime 0.144136   
2022-11-25 11:50:37,016 - INFO  - Validation [22][   40/   40]   Loss 0.316925   Top1 89.340000   Top5 99.700000   BatchTime 0.098549   
2022-11-25 11:50:37,270 - INFO  - ==> Top1: 89.340    Top5: 99.700    Loss: 0.317

2022-11-25 11:50:37,271 - INFO  - ==> Sparsity : 0.427

2022-11-25 11:50:37,271 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.340   Top5: 99.700]
2022-11-25 11:50:37,271 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 89.180   Top5: 99.660]
2022-11-25 11:50:37,271 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 88.530   Top5: 99.580]
2022-11-25 11:50:42,983 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:50:42,986 - INFO  - >>>>>> Epoch  23
2022-11-25 11:50:42,987 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:50:50,381 - INFO  - Training [23][   20/  196]   Loss 0.418118   Top1 85.839844   Top5 98.066406   BatchTime 0.369568   LR 0.000666   
2022-11-25 11:50:56,181 - INFO  - Training [23][   40/  196]   Loss 0.424801   Top1 85.556641   Top5 98.291016   BatchTime 0.329779   LR 0.000648   
2022-11-25 11:51:03,318 - INFO  - Training [23][   60/  196]   Loss 0.408948   Top1 86.256510   Top5 98.385417   BatchTime 0.338801   LR 0.000630   
2022-11-25 11:51:10,907 - INFO  - Training [23][   80/  196]   Loss 0.409742   Top1 86.352539   Top5 98.476562   BatchTime 0.348960   LR 0.000613   
2022-11-25 11:51:18,443 - INFO  - Training [23][  100/  196]   Loss 0.406981   Top1 86.386719   Top5 98.511719   BatchTime 0.354534   LR 0.000596   
2022-11-25 11:51:26,111 - INFO  - Training [23][  120/  196]   Loss 0.398582   Top1 86.722005   Top5 98.613281   BatchTime 0.359338   LR 0.000579   
2022-11-25 11:51:33,458 - INFO  - Training [23][  140/  196]   Loss 0.396367   Top1 86.752232   Top5 98.641183   BatchTime 0.360485   LR 0.000562   
2022-11-25 11:51:40,979 - INFO  - Training [23][  160/  196]   Loss 0.398061   Top1 86.640625   Top5 98.627930   BatchTime 0.362430   LR 0.000545   
2022-11-25 11:51:48,955 - INFO  - Training [23][  180/  196]   Loss 0.398265   Top1 86.612413   Top5 98.561198   BatchTime 0.366470   LR 0.000529   
2022-11-25 11:51:54,573 - INFO  - ==> Top1: 86.656    Top5: 98.548    Loss: 0.397

2022-11-25 11:51:54,822 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:51:56,287 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:51:58,791 - INFO  - Validation [23][   20/   40]   Loss 0.329499   Top1 89.238281   Top5 99.609375   BatchTime 0.125120   
2022-11-25 11:51:59,759 - INFO  - Validation [23][   40/   40]   Loss 0.319621   Top1 89.290000   Top5 99.700000   BatchTime 0.086760   
2022-11-25 11:52:00,013 - INFO  - ==> Top1: 89.290    Top5: 99.700    Loss: 0.320

2022-11-25 11:52:00,013 - INFO  - ==> Sparsity : 0.426

2022-11-25 11:52:00,013 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.340   Top5: 99.700]
2022-11-25 11:52:00,013 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 89.290   Top5: 99.700]
2022-11-25 11:52:00,014 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 89.180   Top5: 99.660]
2022-11-25 11:52:00,167 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:52:00,169 - INFO  - >>>>>> Epoch  24
2022-11-25 11:52:00,171 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:52:07,131 - INFO  - Training [24][   20/  196]   Loss 0.383262   Top1 86.914062   Top5 98.105469   BatchTime 0.347856   LR 0.000500   
2022-11-25 11:52:13,600 - INFO  - Training [24][   40/  196]   Loss 0.379915   Top1 87.128906   Top5 98.349609   BatchTime 0.335661   LR 0.000484   
2022-11-25 11:52:20,928 - INFO  - Training [24][   60/  196]   Loss 0.382975   Top1 86.979167   Top5 98.417969   BatchTime 0.345907   LR 0.000468   
2022-11-25 11:52:28,348 - INFO  - Training [24][   80/  196]   Loss 0.385842   Top1 87.011719   Top5 98.476562   BatchTime 0.352179   LR 0.000453   
2022-11-25 11:52:35,982 - INFO  - Training [24][  100/  196]   Loss 0.381776   Top1 87.113281   Top5 98.496094   BatchTime 0.358081   LR 0.000437   
2022-11-25 11:52:43,458 - INFO  - Training [24][  120/  196]   Loss 0.379768   Top1 87.161458   Top5 98.600260   BatchTime 0.360697   LR 0.000422   
2022-11-25 11:52:50,258 - INFO  - Training [24][  140/  196]   Loss 0.378660   Top1 87.220982   Top5 98.663504   BatchTime 0.357741   LR 0.000407   
2022-11-25 11:52:57,424 - INFO  - Training [24][  160/  196]   Loss 0.380922   Top1 87.175293   Top5 98.664551   BatchTime 0.357811   LR 0.000392   
2022-11-25 11:53:04,840 - INFO  - Training [24][  180/  196]   Loss 0.381318   Top1 87.159288   Top5 98.626302   BatchTime 0.359255   LR 0.000378   
2022-11-25 11:53:11,023 - INFO  - ==> Top1: 87.226    Top5: 98.614    Loss: 0.380

2022-11-25 11:53:11,277 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:53:13,624 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:53:16,104 - INFO  - Validation [24][   20/   40]   Loss 0.512014   Top1 83.984375   Top5 98.945312   BatchTime 0.123859   
2022-11-25 11:53:17,073 - INFO  - Validation [24][   40/   40]   Loss 0.505019   Top1 83.750000   Top5 99.110000   BatchTime 0.086178   
2022-11-25 11:53:17,302 - INFO  - ==> Top1: 83.750    Top5: 99.110    Loss: 0.505

2022-11-25 11:53:17,302 - INFO  - ==> Sparsity : 0.431

2022-11-25 11:53:17,303 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 89.340   Top5: 99.700]
2022-11-25 11:53:17,303 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 89.290   Top5: 99.700]
2022-11-25 11:53:17,303 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 89.180   Top5: 99.660]
2022-11-25 11:53:17,424 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:53:17,426 - INFO  - >>>>>> Epoch  25
2022-11-25 11:53:17,428 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:53:25,444 - INFO  - Training [25][   20/  196]   Loss 0.394906   Top1 86.542969   Top5 98.125000   BatchTime 0.400688   LR 0.000353   
2022-11-25 11:53:32,052 - INFO  - Training [25][   40/  196]   Loss 0.394408   Top1 86.640625   Top5 98.310547   BatchTime 0.365540   LR 0.000339   
2022-11-25 11:53:39,302 - INFO  - Training [25][   60/  196]   Loss 0.389723   Top1 86.751302   Top5 98.470052   BatchTime 0.364528   LR 0.000325   
2022-11-25 11:53:46,602 - INFO  - Training [25][   80/  196]   Loss 0.385309   Top1 86.860352   Top5 98.647461   BatchTime 0.364649   LR 0.000312   
2022-11-25 11:53:54,654 - INFO  - Training [25][  100/  196]   Loss 0.376369   Top1 87.304688   Top5 98.632812   BatchTime 0.372233   LR 0.000299   
2022-11-25 11:54:02,301 - INFO  - Training [25][  120/  196]   Loss 0.370804   Top1 87.539062   Top5 98.730469   BatchTime 0.373922   LR 0.000286   
2022-11-25 11:54:09,477 - INFO  - Training [25][  140/  196]   Loss 0.370195   Top1 87.600446   Top5 98.766741   BatchTime 0.371758   LR 0.000273   
2022-11-25 11:54:16,652 - INFO  - Training [25][  160/  196]   Loss 0.372400   Top1 87.529297   Top5 98.750000   BatchTime 0.370135   LR 0.000261   
2022-11-25 11:54:23,946 - INFO  - Training [25][  180/  196]   Loss 0.372500   Top1 87.519531   Top5 98.719618   BatchTime 0.369528   LR 0.000248   
2022-11-25 11:54:29,974 - INFO  - ==> Top1: 87.632    Top5: 98.724    Loss: 0.369

2022-11-25 11:54:30,230 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:54:32,452 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:54:35,208 - INFO  - Validation [25][   20/   40]   Loss 0.320490   Top1 89.531250   Top5 99.628906   BatchTime 0.137703   
2022-11-25 11:54:36,273 - INFO  - Validation [25][   40/   40]   Loss 0.306126   Top1 89.690000   Top5 99.690000   BatchTime 0.095473   
2022-11-25 11:54:36,546 - INFO  - ==> Top1: 89.690    Top5: 99.690    Loss: 0.306

2022-11-25 11:54:36,547 - INFO  - ==> Sparsity : 0.431

2022-11-25 11:54:36,547 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 89.690   Top5: 99.690]
2022-11-25 11:54:36,547 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 89.340   Top5: 99.700]
2022-11-25 11:54:36,547 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 89.290   Top5: 99.700]
2022-11-25 11:54:42,379 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:54:42,384 - INFO  - >>>>>> Epoch  26
2022-11-25 11:54:42,387 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:54:49,773 - INFO  - Training [26][   20/  196]   Loss 0.389204   Top1 86.601562   Top5 98.105469   BatchTime 0.369180   LR 0.000228   
2022-11-25 11:54:56,337 - INFO  - Training [26][   40/  196]   Loss 0.373596   Top1 87.080078   Top5 98.378906   BatchTime 0.348704   LR 0.000216   
2022-11-25 11:55:03,697 - INFO  - Training [26][   60/  196]   Loss 0.375026   Top1 87.369792   Top5 98.430990   BatchTime 0.355139   LR 0.000205   
2022-11-25 11:55:11,160 - INFO  - Training [26][   80/  196]   Loss 0.372858   Top1 87.485352   Top5 98.564453   BatchTime 0.359637   LR 0.000194   
2022-11-25 11:55:18,813 - INFO  - Training [26][  100/  196]   Loss 0.369016   Top1 87.511719   Top5 98.605469   BatchTime 0.364236   LR 0.000183   
2022-11-25 11:55:26,101 - INFO  - Training [26][  120/  196]   Loss 0.363409   Top1 87.740885   Top5 98.684896   BatchTime 0.364266   LR 0.000173   
2022-11-25 11:55:33,357 - INFO  - Training [26][  140/  196]   Loss 0.362509   Top1 87.773438   Top5 98.758371   BatchTime 0.364052   LR 0.000163   
2022-11-25 11:55:40,455 - INFO  - Training [26][  160/  196]   Loss 0.366196   Top1 87.670898   Top5 98.715820   BatchTime 0.362910   LR 0.000153   
2022-11-25 11:55:47,647 - INFO  - Training [26][  180/  196]   Loss 0.365851   Top1 87.682292   Top5 98.663194   BatchTime 0.362539   LR 0.000144   
2022-11-25 11:55:53,873 - INFO  - ==> Top1: 87.718    Top5: 98.678    Loss: 0.365

2022-11-25 11:55:54,138 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:55:56,514 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:55:59,131 - INFO  - Validation [26][   20/   40]   Loss 0.316284   Top1 89.667969   Top5 99.609375   BatchTime 0.130721   
2022-11-25 11:56:00,154 - INFO  - Validation [26][   40/   40]   Loss 0.300084   Top1 89.850000   Top5 99.680000   BatchTime 0.090955   
2022-11-25 11:56:00,369 - INFO  - ==> Top1: 89.850    Top5: 99.680    Loss: 0.300

2022-11-25 11:56:00,369 - INFO  - ==> Sparsity : 0.444

2022-11-25 11:56:00,370 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 11:56:00,370 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 89.690   Top5: 99.690]
2022-11-25 11:56:00,370 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 89.340   Top5: 99.700]
2022-11-25 11:56:05,656 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:56:05,658 - INFO  - >>>>>> Epoch  27
2022-11-25 11:56:05,660 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:56:14,157 - INFO  - Training [27][   20/  196]   Loss 0.391811   Top1 86.816406   Top5 98.183594   BatchTime 0.424774   LR 0.000128   
2022-11-25 11:56:21,292 - INFO  - Training [27][   40/  196]   Loss 0.380734   Top1 87.080078   Top5 98.466797   BatchTime 0.390741   LR 0.000119   
2022-11-25 11:56:28,872 - INFO  - Training [27][   60/  196]   Loss 0.372656   Top1 87.382812   Top5 98.541667   BatchTime 0.386837   LR 0.000111   
2022-11-25 11:56:36,118 - INFO  - Training [27][   80/  196]   Loss 0.371476   Top1 87.451172   Top5 98.642578   BatchTime 0.380699   LR 0.000102   
2022-11-25 11:56:43,459 - INFO  - Training [27][  100/  196]   Loss 0.367359   Top1 87.554688   Top5 98.710938   BatchTime 0.377969   LR 0.000095   
2022-11-25 11:56:50,692 - INFO  - Training [27][  120/  196]   Loss 0.363891   Top1 87.685547   Top5 98.750000   BatchTime 0.375244   LR 0.000087   
2022-11-25 11:56:57,881 - INFO  - Training [27][  140/  196]   Loss 0.361134   Top1 87.834821   Top5 98.816964   BatchTime 0.372987   LR 0.000080   
2022-11-25 11:57:05,347 - INFO  - Training [27][  160/  196]   Loss 0.363728   Top1 87.739258   Top5 98.798828   BatchTime 0.373030   LR 0.000073   
2022-11-25 11:57:13,135 - INFO  - Training [27][  180/  196]   Loss 0.365264   Top1 87.671441   Top5 98.771701   BatchTime 0.374847   LR 0.000066   
2022-11-25 11:57:18,935 - INFO  - ==> Top1: 87.744    Top5: 98.770    Loss: 0.363

2022-11-25 11:57:19,263 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:57:21,009 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:57:23,989 - INFO  - Validation [27][   20/   40]   Loss 0.301977   Top1 89.921875   Top5 99.492188   BatchTime 0.148886   
2022-11-25 11:57:25,013 - INFO  - Validation [27][   40/   40]   Loss 0.288559   Top1 90.230000   Top5 99.660000   BatchTime 0.100061   
2022-11-25 11:57:25,432 - INFO  - ==> Top1: 90.230    Top5: 99.660    Loss: 0.289

2022-11-25 11:57:25,432 - INFO  - ==> Sparsity : 0.464

2022-11-25 11:57:25,433 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 11:57:25,433 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 11:57:25,433 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.690   Top5: 99.690]
2022-11-25 11:57:31,482 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 11:57:31,484 - INFO  - >>>>>> Epoch  28
2022-11-25 11:57:31,486 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:57:40,138 - INFO  - Training [28][   20/  196]   Loss 0.373753   Top1 87.460938   Top5 98.183594   BatchTime 0.432486   LR 0.000055   
2022-11-25 11:57:47,340 - INFO  - Training [28][   40/  196]   Loss 0.373757   Top1 87.402344   Top5 98.417969   BatchTime 0.396293   LR 0.000050   
2022-11-25 11:57:54,782 - INFO  - Training [28][   60/  196]   Loss 0.363939   Top1 87.662760   Top5 98.574219   BatchTime 0.388234   LR 0.000044   
2022-11-25 11:58:01,985 - INFO  - Training [28][   80/  196]   Loss 0.361991   Top1 87.749023   Top5 98.691406   BatchTime 0.381213   LR 0.000039   
2022-11-25 11:58:09,266 - INFO  - Training [28][  100/  196]   Loss 0.357953   Top1 87.882812   Top5 98.714844   BatchTime 0.377778   LR 0.000034   
2022-11-25 11:58:16,601 - INFO  - Training [28][  120/  196]   Loss 0.351949   Top1 88.085938   Top5 98.772786   BatchTime 0.375938   LR 0.000030   
2022-11-25 11:58:23,989 - INFO  - Training [28][  140/  196]   Loss 0.351854   Top1 88.125000   Top5 98.805804   BatchTime 0.375006   LR 0.000026   
2022-11-25 11:58:31,033 - INFO  - Training [28][  160/  196]   Loss 0.357320   Top1 87.946777   Top5 98.781738   BatchTime 0.372150   LR 0.000022   
2022-11-25 11:58:38,682 - INFO  - Training [28][  180/  196]   Loss 0.358169   Top1 87.903646   Top5 98.713108   BatchTime 0.373294   LR 0.000018   
2022-11-25 11:58:44,587 - INFO  - ==> Top1: 87.972    Top5: 98.734    Loss: 0.356

2022-11-25 11:58:44,834 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:58:46,282 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:58:48,757 - INFO  - Validation [28][   20/   40]   Loss 0.327957   Top1 89.316406   Top5 99.687500   BatchTime 0.123659   
2022-11-25 11:58:49,902 - INFO  - Validation [28][   40/   40]   Loss 0.312042   Top1 89.480000   Top5 99.750000   BatchTime 0.090452   
2022-11-25 11:58:50,164 - INFO  - ==> Top1: 89.480    Top5: 99.750    Loss: 0.312

2022-11-25 11:58:50,164 - INFO  - ==> Sparsity : 0.475

2022-11-25 11:58:50,164 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 11:58:50,164 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 11:58:50,164 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 89.690   Top5: 99.690]
2022-11-25 11:58:50,304 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 11:58:50,305 - INFO  - >>>>>> Epoch  29
2022-11-25 11:58:50,307 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:58:59,283 - INFO  - Training [29][   20/  196]   Loss 0.371729   Top1 87.343750   Top5 98.300781   BatchTime 0.448660   LR 0.000013   
2022-11-25 11:59:06,089 - INFO  - Training [29][   40/  196]   Loss 0.368446   Top1 87.275391   Top5 98.417969   BatchTime 0.394479   LR 0.000010   
2022-11-25 11:59:13,050 - INFO  - Training [29][   60/  196]   Loss 0.363390   Top1 87.519531   Top5 98.561198   BatchTime 0.378998   LR 0.000008   
2022-11-25 11:59:19,775 - INFO  - Training [29][   80/  196]   Loss 0.355201   Top1 87.890625   Top5 98.671875   BatchTime 0.368308   LR 0.000005   
2022-11-25 11:59:26,644 - INFO  - Training [29][  100/  196]   Loss 0.350280   Top1 88.089844   Top5 98.750000   BatchTime 0.363341   LR 0.000004   
2022-11-25 11:59:33,634 - INFO  - Training [29][  120/  196]   Loss 0.345654   Top1 88.248698   Top5 98.776042   BatchTime 0.361036   LR 0.000002   
2022-11-25 11:59:40,607 - INFO  - Training [29][  140/  196]   Loss 0.345133   Top1 88.300781   Top5 98.830915   BatchTime 0.359262   LR 0.000001   
2022-11-25 11:59:47,355 - INFO  - Training [29][  160/  196]   Loss 0.349629   Top1 88.093262   Top5 98.803711   BatchTime 0.356530   LR 0.000001   
2022-11-25 11:59:54,610 - INFO  - Training [29][  180/  196]   Loss 0.350950   Top1 88.040365   Top5 98.730469   BatchTime 0.357217   LR 0.000000   
2022-11-25 12:00:00,721 - INFO  - ==> Top1: 88.090    Top5: 98.750    Loss: 0.350

2022-11-25 12:00:00,969 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:00:02,403 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:00:04,826 - INFO  - Validation [29][   20/   40]   Loss 0.314652   Top1 89.921875   Top5 99.667969   BatchTime 0.121054   
2022-11-25 12:00:06,031 - INFO  - Validation [29][   40/   40]   Loss 0.295264   Top1 90.250000   Top5 99.740000   BatchTime 0.090656   
2022-11-25 12:00:06,250 - INFO  - ==> Top1: 90.250    Top5: 99.740    Loss: 0.295

2022-11-25 12:00:06,251 - INFO  - ==> Sparsity : 0.478

2022-11-25 12:00:06,251 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:00:06,251 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:00:06,251 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 12:00:14,483 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 12:00:14,489 - INFO  - >>>>>> Epoch  30
2022-11-25 12:00:14,494 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:00:23,813 - INFO  - Training [30][   20/  196]   Loss 0.381658   Top1 86.640625   Top5 98.183594   BatchTime 0.465666   LR 0.001250   
2022-11-25 12:00:31,600 - INFO  - Training [30][   40/  196]   Loss 0.396267   Top1 86.298828   Top5 98.339844   BatchTime 0.427506   LR 0.001250   
2022-11-25 12:00:39,025 - INFO  - Training [30][   60/  196]   Loss 0.403857   Top1 86.145833   Top5 98.339844   BatchTime 0.408753   LR 0.001250   
2022-11-25 12:00:46,253 - INFO  - Training [30][   80/  196]   Loss 0.406226   Top1 86.162109   Top5 98.457031   BatchTime 0.396919   LR 0.001250   
2022-11-25 12:00:53,598 - INFO  - Training [30][  100/  196]   Loss 0.403249   Top1 86.250000   Top5 98.507812   BatchTime 0.390984   LR 0.001250   
2022-11-25 12:01:00,759 - INFO  - Training [30][  120/  196]   Loss 0.398007   Top1 86.481120   Top5 98.597005   BatchTime 0.385493   LR 0.001249   
2022-11-25 12:01:07,570 - INFO  - Training [30][  140/  196]   Loss 0.394940   Top1 86.640625   Top5 98.660714   BatchTime 0.379072   LR 0.001249   
2022-11-25 12:01:15,127 - INFO  - Training [30][  160/  196]   Loss 0.397609   Top1 86.564941   Top5 98.652344   BatchTime 0.378918   LR 0.001249   
2022-11-25 12:01:22,472 - INFO  - Training [30][  180/  196]   Loss 0.400381   Top1 86.512587   Top5 98.572049   BatchTime 0.377622   LR 0.001248   
2022-11-25 12:01:28,900 - INFO  - ==> Top1: 86.474    Top5: 98.574    Loss: 0.400

2022-11-25 12:01:29,140 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:01:30,372 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:01:33,335 - INFO  - Validation [30][   20/   40]   Loss 0.329872   Top1 88.964844   Top5 99.511719   BatchTime 0.148064   
2022-11-25 12:01:35,743 - INFO  - Validation [30][   40/   40]   Loss 0.316423   Top1 89.200000   Top5 99.640000   BatchTime 0.134237   
2022-11-25 12:01:35,966 - INFO  - ==> Top1: 89.200    Top5: 99.640    Loss: 0.316

2022-11-25 12:01:35,966 - INFO  - ==> Sparsity : 0.463

2022-11-25 12:01:35,966 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:01:35,967 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:01:35,967 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 12:01:36,115 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:01:36,117 - INFO  - >>>>>> Epoch  31
2022-11-25 12:01:36,119 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:01:44,981 - INFO  - Training [31][   20/  196]   Loss 0.407890   Top1 85.937500   Top5 98.164062   BatchTime 0.443001   LR 0.001248   
2022-11-25 12:01:51,980 - INFO  - Training [31][   40/  196]   Loss 0.412186   Top1 85.849609   Top5 98.291016   BatchTime 0.396478   LR 0.001247   
2022-11-25 12:01:59,278 - INFO  - Training [31][   60/  196]   Loss 0.414586   Top1 85.735677   Top5 98.385417   BatchTime 0.385949   LR 0.001247   
2022-11-25 12:02:06,699 - INFO  - Training [31][   80/  196]   Loss 0.417337   Top1 85.732422   Top5 98.422852   BatchTime 0.382226   LR 0.001246   
2022-11-25 12:02:14,099 - INFO  - Training [31][  100/  196]   Loss 0.417911   Top1 85.703125   Top5 98.457031   BatchTime 0.379778   LR 0.001246   
2022-11-25 12:02:21,350 - INFO  - Training [31][  120/  196]   Loss 0.410683   Top1 85.983073   Top5 98.509115   BatchTime 0.376902   LR 0.001245   
2022-11-25 12:02:28,473 - INFO  - Training [31][  140/  196]   Loss 0.408807   Top1 86.138393   Top5 98.590960   BatchTime 0.373941   LR 0.001244   
2022-11-25 12:02:35,996 - INFO  - Training [31][  160/  196]   Loss 0.412756   Top1 86.064453   Top5 98.593750   BatchTime 0.374211   LR 0.001244   
2022-11-25 12:02:43,934 - INFO  - Training [31][  180/  196]   Loss 0.413212   Top1 86.072049   Top5 98.552517   BatchTime 0.376733   LR 0.001243   
2022-11-25 12:02:49,675 - INFO  - ==> Top1: 86.056    Top5: 98.568    Loss: 0.414

2022-11-25 12:02:49,887 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:02:51,072 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:02:55,015 - INFO  - Validation [31][   20/   40]   Loss 0.354109   Top1 88.750000   Top5 99.453125   BatchTime 0.197059   
2022-11-25 12:02:55,988 - INFO  - Validation [31][   40/   40]   Loss 0.342340   Top1 88.860000   Top5 99.620000   BatchTime 0.122867   
2022-11-25 12:02:56,192 - INFO  - ==> Top1: 88.860    Top5: 99.620    Loss: 0.342

2022-11-25 12:02:56,193 - INFO  - ==> Sparsity : 0.409

2022-11-25 12:02:56,193 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:02:56,193 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:02:56,193 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 12:02:56,332 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:02:56,334 - INFO  - >>>>>> Epoch  32
2022-11-25 12:02:56,336 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:03:05,104 - INFO  - Training [32][   20/  196]   Loss 0.423531   Top1 84.707031   Top5 97.890625   BatchTime 0.438290   LR 0.001242   
2022-11-25 12:03:12,248 - INFO  - Training [32][   40/  196]   Loss 0.431136   Top1 84.990234   Top5 98.134766   BatchTime 0.397754   LR 0.001241   
2022-11-25 12:03:19,322 - INFO  - Training [32][   60/  196]   Loss 0.423660   Top1 85.292969   Top5 98.242188   BatchTime 0.383072   LR 0.001240   
2022-11-25 12:03:26,667 - INFO  - Training [32][   80/  196]   Loss 0.419629   Top1 85.532227   Top5 98.315430   BatchTime 0.379112   LR 0.001239   
2022-11-25 12:03:33,647 - INFO  - Training [32][  100/  196]   Loss 0.409559   Top1 85.906250   Top5 98.382812   BatchTime 0.373085   LR 0.001238   
2022-11-25 12:03:40,867 - INFO  - Training [32][  120/  196]   Loss 0.404863   Top1 86.110026   Top5 98.489583   BatchTime 0.371070   LR 0.001237   
2022-11-25 12:03:47,891 - INFO  - Training [32][  140/  196]   Loss 0.404174   Top1 86.261161   Top5 98.537946   BatchTime 0.368229   LR 0.001236   
2022-11-25 12:03:55,706 - INFO  - Training [32][  160/  196]   Loss 0.404550   Top1 86.218262   Top5 98.518066   BatchTime 0.371047   LR 0.001235   
2022-11-25 12:04:03,678 - INFO  - Training [32][  180/  196]   Loss 0.404119   Top1 86.208767   Top5 98.463542   BatchTime 0.374109   LR 0.001234   
2022-11-25 12:04:09,811 - INFO  - ==> Top1: 86.208    Top5: 98.446    Loss: 0.404

2022-11-25 12:04:10,033 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:04:11,156 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:04:15,142 - INFO  - Validation [32][   20/   40]   Loss 0.424541   Top1 86.328125   Top5 99.355469   BatchTime 0.199195   
2022-11-25 12:04:16,116 - INFO  - Validation [32][   40/   40]   Loss 0.419861   Top1 86.410000   Top5 99.420000   BatchTime 0.123965   
2022-11-25 12:04:16,381 - INFO  - ==> Top1: 86.410    Top5: 99.420    Loss: 0.420

2022-11-25 12:04:16,382 - INFO  - ==> Sparsity : 0.409

2022-11-25 12:04:16,382 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:04:16,382 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:04:16,382 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 12:04:16,530 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:04:16,533 - INFO  - >>>>>> Epoch  33
2022-11-25 12:04:16,536 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:04:25,252 - INFO  - Training [33][   20/  196]   Loss 0.416247   Top1 86.171875   Top5 98.066406   BatchTime 0.435512   LR 0.001232   
2022-11-25 12:04:32,553 - INFO  - Training [33][   40/  196]   Loss 0.417619   Top1 86.201172   Top5 98.193359   BatchTime 0.400284   LR 0.001230   
2022-11-25 12:04:39,876 - INFO  - Training [33][   60/  196]   Loss 0.416610   Top1 86.223958   Top5 98.339844   BatchTime 0.388909   LR 0.001229   
2022-11-25 12:04:47,912 - INFO  - Training [33][   80/  196]   Loss 0.411676   Top1 86.425781   Top5 98.403320   BatchTime 0.392131   LR 0.001228   
2022-11-25 12:04:55,514 - INFO  - Training [33][  100/  196]   Loss 0.407609   Top1 86.535156   Top5 98.453125   BatchTime 0.389722   LR 0.001226   
2022-11-25 12:05:03,101 - INFO  - Training [33][  120/  196]   Loss 0.402745   Top1 86.702474   Top5 98.554688   BatchTime 0.387990   LR 0.001225   
2022-11-25 12:05:10,558 - INFO  - Training [33][  140/  196]   Loss 0.400023   Top1 86.788504   Top5 98.613281   BatchTime 0.385829   LR 0.001224   
2022-11-25 12:05:18,751 - INFO  - Training [33][  160/  196]   Loss 0.400773   Top1 86.721191   Top5 98.598633   BatchTime 0.388803   LR 0.001222   
2022-11-25 12:05:26,254 - INFO  - Training [33][  180/  196]   Loss 0.401967   Top1 86.592882   Top5 98.556858   BatchTime 0.387287   LR 0.001221   
2022-11-25 12:05:31,857 - INFO  - ==> Top1: 86.584    Top5: 98.578    Loss: 0.402

2022-11-25 12:05:32,142 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:05:34,821 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:05:37,935 - INFO  - Validation [33][   20/   40]   Loss 0.374989   Top1 88.242188   Top5 99.609375   BatchTime 0.155592   
2022-11-25 12:05:39,062 - INFO  - Validation [33][   40/   40]   Loss 0.373584   Top1 88.160000   Top5 99.630000   BatchTime 0.105979   
2022-11-25 12:05:39,316 - INFO  - ==> Top1: 88.160    Top5: 99.630    Loss: 0.374

2022-11-25 12:05:39,316 - INFO  - ==> Sparsity : 0.423

2022-11-25 12:05:39,317 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:05:39,317 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:05:39,317 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 12:05:39,448 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:05:39,450 - INFO  - >>>>>> Epoch  34
2022-11-25 12:05:39,452 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:05:48,324 - INFO  - Training [34][   20/  196]   Loss 0.422904   Top1 85.937500   Top5 98.046875   BatchTime 0.443491   LR 0.001218   
2022-11-25 12:05:55,896 - INFO  - Training [34][   40/  196]   Loss 0.419596   Top1 85.859375   Top5 98.369141   BatchTime 0.411045   LR 0.001216   
2022-11-25 12:06:04,151 - INFO  - Training [34][   60/  196]   Loss 0.416203   Top1 85.768229   Top5 98.470052   BatchTime 0.411609   LR 0.001215   
2022-11-25 12:06:11,616 - INFO  - Training [34][   80/  196]   Loss 0.413759   Top1 86.015625   Top5 98.491211   BatchTime 0.402014   LR 0.001213   
2022-11-25 12:06:19,070 - INFO  - Training [34][  100/  196]   Loss 0.403663   Top1 86.300781   Top5 98.527344   BatchTime 0.396152   LR 0.001211   
2022-11-25 12:06:26,243 - INFO  - Training [34][  120/  196]   Loss 0.400809   Top1 86.438802   Top5 98.577474   BatchTime 0.389901   LR 0.001209   
2022-11-25 12:06:34,395 - INFO  - Training [34][  140/  196]   Loss 0.399670   Top1 86.520647   Top5 98.638393   BatchTime 0.392428   LR 0.001208   
2022-11-25 12:06:41,519 - INFO  - Training [34][  160/  196]   Loss 0.400297   Top1 86.520996   Top5 98.618164   BatchTime 0.387903   LR 0.001206   
2022-11-25 12:06:48,468 - INFO  - Training [34][  180/  196]   Loss 0.401456   Top1 86.469184   Top5 98.561198   BatchTime 0.383403   LR 0.001204   
2022-11-25 12:06:53,408 - INFO  - ==> Top1: 86.492    Top5: 98.534    Loss: 0.401

2022-11-25 12:06:53,697 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:06:54,839 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:06:57,518 - INFO  - Validation [34][   20/   40]   Loss 0.350831   Top1 87.812500   Top5 99.550781   BatchTime 0.133834   
2022-11-25 12:06:58,524 - INFO  - Validation [34][   40/   40]   Loss 0.342275   Top1 88.380000   Top5 99.610000   BatchTime 0.092064   
2022-11-25 12:06:58,737 - INFO  - ==> Top1: 88.380    Top5: 99.610    Loss: 0.342

2022-11-25 12:06:58,737 - INFO  - ==> Sparsity : 0.469

2022-11-25 12:06:58,738 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:06:58,738 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:06:58,738 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 12:06:58,878 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:06:58,880 - INFO  - >>>>>> Epoch  35
2022-11-25 12:06:58,882 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:07:07,728 - INFO  - Training [35][   20/  196]   Loss 0.424569   Top1 85.117188   Top5 98.300781   BatchTime 0.442039   LR 0.001201   
2022-11-25 12:07:15,225 - INFO  - Training [35][   40/  196]   Loss 0.419970   Top1 85.566406   Top5 98.271484   BatchTime 0.408435   LR 0.001199   
2022-11-25 12:07:22,572 - INFO  - Training [35][   60/  196]   Loss 0.410391   Top1 85.963542   Top5 98.417969   BatchTime 0.394736   LR 0.001197   
2022-11-25 12:07:30,818 - INFO  - Training [35][   80/  196]   Loss 0.407485   Top1 86.083984   Top5 98.540039   BatchTime 0.399126   LR 0.001195   
2022-11-25 12:07:38,900 - INFO  - Training [35][  100/  196]   Loss 0.398365   Top1 86.457031   Top5 98.621094   BatchTime 0.400120   LR 0.001192   
2022-11-25 12:07:46,817 - INFO  - Training [35][  120/  196]   Loss 0.393510   Top1 86.608073   Top5 98.675130   BatchTime 0.399405   LR 0.001190   
2022-11-25 12:07:54,306 - INFO  - Training [35][  140/  196]   Loss 0.392758   Top1 86.618304   Top5 98.708147   BatchTime 0.395839   LR 0.001188   
2022-11-25 12:08:01,581 - INFO  - Training [35][  160/  196]   Loss 0.394433   Top1 86.616211   Top5 98.710938   BatchTime 0.391829   LR 0.001186   
2022-11-25 12:08:08,115 - INFO  - Training [35][  180/  196]   Loss 0.394859   Top1 86.595052   Top5 98.628472   BatchTime 0.384595   LR 0.001184   
2022-11-25 12:08:13,238 - INFO  - ==> Top1: 86.682    Top5: 98.640    Loss: 0.393

2022-11-25 12:08:13,453 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:08:15,134 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:08:17,615 - INFO  - Validation [35][   20/   40]   Loss 0.324275   Top1 88.906250   Top5 99.628906   BatchTime 0.123967   
2022-11-25 12:08:18,643 - INFO  - Validation [35][   40/   40]   Loss 0.317388   Top1 89.060000   Top5 99.650000   BatchTime 0.087693   
2022-11-25 12:08:18,865 - INFO  - ==> Top1: 89.060    Top5: 99.650    Loss: 0.317

2022-11-25 12:08:18,865 - INFO  - ==> Sparsity : 0.474

2022-11-25 12:08:18,865 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:08:18,865 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:08:18,866 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 12:08:18,988 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:08:18,990 - INFO  - >>>>>> Epoch  36
2022-11-25 12:08:18,992 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:08:27,715 - INFO  - Training [36][   20/  196]   Loss 0.439093   Top1 85.234375   Top5 97.910156   BatchTime 0.436033   LR 0.001180   
2022-11-25 12:08:34,579 - INFO  - Training [36][   40/  196]   Loss 0.415440   Top1 86.132812   Top5 98.271484   BatchTime 0.389604   LR 0.001177   
2022-11-25 12:08:41,774 - INFO  - Training [36][   60/  196]   Loss 0.403984   Top1 86.549479   Top5 98.391927   BatchTime 0.379663   LR 0.001175   
2022-11-25 12:08:49,486 - INFO  - Training [36][   80/  196]   Loss 0.397861   Top1 86.757812   Top5 98.496094   BatchTime 0.381138   LR 0.001173   
2022-11-25 12:08:56,443 - INFO  - Training [36][  100/  196]   Loss 0.389401   Top1 87.101562   Top5 98.550781   BatchTime 0.374481   LR 0.001170   
2022-11-25 12:09:04,505 - INFO  - Training [36][  120/  196]   Loss 0.384463   Top1 87.246094   Top5 98.632812   BatchTime 0.379250   LR 0.001168   
2022-11-25 12:09:11,923 - INFO  - Training [36][  140/  196]   Loss 0.383997   Top1 87.212612   Top5 98.669085   BatchTime 0.378059   LR 0.001165   
2022-11-25 12:09:20,061 - INFO  - Training [36][  160/  196]   Loss 0.384637   Top1 87.165527   Top5 98.649902   BatchTime 0.381663   LR 0.001163   
2022-11-25 12:09:27,244 - INFO  - Training [36][  180/  196]   Loss 0.385869   Top1 87.072483   Top5 98.574219   BatchTime 0.379160   LR 0.001160   
2022-11-25 12:09:32,189 - INFO  - ==> Top1: 87.166    Top5: 98.598    Loss: 0.383

2022-11-25 12:09:32,449 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:09:34,329 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:09:37,099 - INFO  - Validation [36][   20/   40]   Loss 0.348740   Top1 88.535156   Top5 99.453125   BatchTime 0.138392   
2022-11-25 12:09:38,117 - INFO  - Validation [36][   40/   40]   Loss 0.342625   Top1 88.700000   Top5 99.550000   BatchTime 0.094641   
2022-11-25 12:09:38,349 - INFO  - ==> Top1: 88.700    Top5: 99.550    Loss: 0.343

2022-11-25 12:09:38,349 - INFO  - ==> Sparsity : 0.406

2022-11-25 12:09:38,349 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:09:38,350 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:09:38,350 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 12:09:38,705 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:09:38,706 - INFO  - >>>>>> Epoch  37
2022-11-25 12:09:38,708 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:09:47,348 - INFO  - Training [37][   20/  196]   Loss 0.395349   Top1 86.542969   Top5 98.125000   BatchTime 0.431874   LR 0.001155   
2022-11-25 12:09:54,582 - INFO  - Training [37][   40/  196]   Loss 0.396739   Top1 86.572266   Top5 98.261719   BatchTime 0.396776   LR 0.001153   
2022-11-25 12:10:01,758 - INFO  - Training [37][   60/  196]   Loss 0.393722   Top1 86.640625   Top5 98.489583   BatchTime 0.384115   LR 0.001150   
2022-11-25 12:10:09,046 - INFO  - Training [37][   80/  196]   Loss 0.390739   Top1 86.835938   Top5 98.569336   BatchTime 0.379187   LR 0.001147   
2022-11-25 12:10:16,621 - INFO  - Training [37][  100/  196]   Loss 0.389298   Top1 86.867188   Top5 98.566406   BatchTime 0.379094   LR 0.001144   
2022-11-25 12:10:23,798 - INFO  - Training [37][  120/  196]   Loss 0.387106   Top1 86.962891   Top5 98.662109   BatchTime 0.375725   LR 0.001142   
2022-11-25 12:10:31,279 - INFO  - Training [37][  140/  196]   Loss 0.385796   Top1 87.025670   Top5 98.716518   BatchTime 0.375482   LR 0.001139   
2022-11-25 12:10:38,698 - INFO  - Training [37][  160/  196]   Loss 0.386619   Top1 86.982422   Top5 98.718262   BatchTime 0.374916   LR 0.001136   
2022-11-25 12:10:45,340 - INFO  - Training [37][  180/  196]   Loss 0.388940   Top1 86.883681   Top5 98.630642   BatchTime 0.370160   LR 0.001133   
2022-11-25 12:10:49,785 - INFO  - ==> Top1: 86.878    Top5: 98.628    Loss: 0.389

2022-11-25 12:10:49,994 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:10:51,161 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:10:53,676 - INFO  - Validation [37][   20/   40]   Loss 0.370275   Top1 87.988281   Top5 99.492188   BatchTime 0.125686   
2022-11-25 12:10:55,236 - INFO  - Validation [37][   40/   40]   Loss 0.356694   Top1 88.220000   Top5 99.590000   BatchTime 0.101856   
2022-11-25 12:10:55,472 - INFO  - ==> Top1: 88.220    Top5: 99.590    Loss: 0.357

2022-11-25 12:10:55,472 - INFO  - ==> Sparsity : 0.412

2022-11-25 12:10:55,473 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:10:55,473 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:10:55,473 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 12:10:55,634 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:10:55,635 - INFO  - >>>>>> Epoch  38
2022-11-25 12:10:55,637 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:11:04,272 - INFO  - Training [38][   20/  196]   Loss 0.399196   Top1 86.347656   Top5 98.398438   BatchTime 0.431616   LR 0.001128   
2022-11-25 12:11:11,606 - INFO  - Training [38][   40/  196]   Loss 0.395484   Top1 86.582031   Top5 98.496094   BatchTime 0.399143   LR 0.001125   
2022-11-25 12:11:18,787 - INFO  - Training [38][   60/  196]   Loss 0.393245   Top1 86.673177   Top5 98.567708   BatchTime 0.385787   LR 0.001122   
2022-11-25 12:11:25,931 - INFO  - Training [38][   80/  196]   Loss 0.390337   Top1 86.870117   Top5 98.598633   BatchTime 0.378638   LR 0.001119   
2022-11-25 12:11:34,114 - INFO  - Training [38][  100/  196]   Loss 0.383790   Top1 87.105469   Top5 98.656250   BatchTime 0.384734   LR 0.001116   
2022-11-25 12:11:41,436 - INFO  - Training [38][  120/  196]   Loss 0.378133   Top1 87.239583   Top5 98.746745   BatchTime 0.381632   LR 0.001112   
2022-11-25 12:11:49,218 - INFO  - Training [38][  140/  196]   Loss 0.376243   Top1 87.366071   Top5 98.794643   BatchTime 0.382700   LR 0.001109   
2022-11-25 12:11:56,879 - INFO  - Training [38][  160/  196]   Loss 0.379989   Top1 87.280273   Top5 98.769531   BatchTime 0.382740   LR 0.001106   
2022-11-25 12:12:03,354 - INFO  - Training [38][  180/  196]   Loss 0.380253   Top1 87.274306   Top5 98.697917   BatchTime 0.376189   LR 0.001103   
2022-11-25 12:12:08,701 - INFO  - ==> Top1: 87.266    Top5: 98.698    Loss: 0.380

2022-11-25 12:12:08,972 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:12:10,622 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:12:13,169 - INFO  - Validation [38][   20/   40]   Loss 0.317400   Top1 89.277344   Top5 99.707031   BatchTime 0.127309   
2022-11-25 12:12:14,229 - INFO  - Validation [38][   40/   40]   Loss 0.299785   Top1 89.720000   Top5 99.760000   BatchTime 0.090136   
2022-11-25 12:12:14,439 - INFO  - ==> Top1: 89.720    Top5: 99.760    Loss: 0.300

2022-11-25 12:12:14,440 - INFO  - ==> Sparsity : 0.424

2022-11-25 12:12:14,440 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:12:14,440 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:12:14,440 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 89.850   Top5: 99.680]
2022-11-25 12:12:14,559 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:12:14,561 - INFO  - >>>>>> Epoch  39
2022-11-25 12:12:14,563 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:12:23,059 - INFO  - Training [39][   20/  196]   Loss 0.409331   Top1 86.171875   Top5 98.203125   BatchTime 0.424669   LR 0.001097   
2022-11-25 12:12:30,341 - INFO  - Training [39][   40/  196]   Loss 0.404349   Top1 86.513672   Top5 98.417969   BatchTime 0.394403   LR 0.001094   
2022-11-25 12:12:38,051 - INFO  - Training [39][   60/  196]   Loss 0.395379   Top1 86.751302   Top5 98.535156   BatchTime 0.391430   LR 0.001090   
2022-11-25 12:12:45,961 - INFO  - Training [39][   80/  196]   Loss 0.395731   Top1 86.684570   Top5 98.637695   BatchTime 0.392446   LR 0.001087   
2022-11-25 12:12:53,606 - INFO  - Training [39][  100/  196]   Loss 0.385963   Top1 87.046875   Top5 98.667969   BatchTime 0.390408   LR 0.001084   
2022-11-25 12:13:00,880 - INFO  - Training [39][  120/  196]   Loss 0.381541   Top1 87.207031   Top5 98.730469   BatchTime 0.385953   LR 0.001080   
2022-11-25 12:13:08,577 - INFO  - Training [39][  140/  196]   Loss 0.382186   Top1 87.262835   Top5 98.752790   BatchTime 0.385794   LR 0.001077   
2022-11-25 12:13:15,348 - INFO  - Training [39][  160/  196]   Loss 0.382713   Top1 87.209473   Top5 98.735352   BatchTime 0.379888   LR 0.001073   
2022-11-25 12:13:21,476 - INFO  - Training [39][  180/  196]   Loss 0.382468   Top1 87.235243   Top5 98.682726   BatchTime 0.371725   LR 0.001070   
2022-11-25 12:13:27,375 - INFO  - ==> Top1: 87.306    Top5: 98.694    Loss: 0.381

2022-11-25 12:13:27,626 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:13:29,223 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:13:31,788 - INFO  - Validation [39][   20/   40]   Loss 0.337063   Top1 89.804688   Top5 99.609375   BatchTime 0.128158   
2022-11-25 12:13:32,959 - INFO  - Validation [39][   40/   40]   Loss 0.326441   Top1 90.100000   Top5 99.710000   BatchTime 0.093361   
2022-11-25 12:13:33,209 - INFO  - ==> Top1: 90.100    Top5: 99.710    Loss: 0.326

2022-11-25 12:13:33,209 - INFO  - ==> Sparsity : 0.407

2022-11-25 12:13:33,210 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:13:33,210 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:13:33,210 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
2022-11-25 12:13:33,333 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:13:33,335 - INFO  - >>>>>> Epoch  40
2022-11-25 12:13:33,337 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:13:41,866 - INFO  - Training [40][   20/  196]   Loss 0.387706   Top1 86.347656   Top5 98.242188   BatchTime 0.426323   LR 0.001064   
2022-11-25 12:13:48,593 - INFO  - Training [40][   40/  196]   Loss 0.379226   Top1 86.875000   Top5 98.447266   BatchTime 0.381340   LR 0.001060   
2022-11-25 12:13:55,706 - INFO  - Training [40][   60/  196]   Loss 0.379413   Top1 86.822917   Top5 98.561198   BatchTime 0.372774   LR 0.001056   
2022-11-25 12:14:03,493 - INFO  - Training [40][   80/  196]   Loss 0.377242   Top1 87.114258   Top5 98.647461   BatchTime 0.376919   LR 0.001053   
2022-11-25 12:14:10,861 - INFO  - Training [40][  100/  196]   Loss 0.372641   Top1 87.300781   Top5 98.683594   BatchTime 0.375210   LR 0.001049   
2022-11-25 12:14:18,260 - INFO  - Training [40][  120/  196]   Loss 0.365200   Top1 87.565104   Top5 98.779297   BatchTime 0.374333   LR 0.001045   
2022-11-25 12:14:25,114 - INFO  - Training [40][  140/  196]   Loss 0.363594   Top1 87.656250   Top5 98.816964   BatchTime 0.369816   LR 0.001042   
2022-11-25 12:14:31,811 - INFO  - Training [40][  160/  196]   Loss 0.367266   Top1 87.551270   Top5 98.774414   BatchTime 0.365445   LR 0.001038   
2022-11-25 12:14:37,407 - INFO  - Training [40][  180/  196]   Loss 0.369455   Top1 87.545573   Top5 98.715278   BatchTime 0.355929   LR 0.001034   
2022-11-25 12:14:43,859 - INFO  - ==> Top1: 87.542    Top5: 98.700    Loss: 0.370

2022-11-25 12:14:44,174 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:14:45,787 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:14:48,354 - INFO  - Validation [40][   20/   40]   Loss 0.423851   Top1 87.832031   Top5 99.511719   BatchTime 0.128252   
2022-11-25 12:14:49,463 - INFO  - Validation [40][   40/   40]   Loss 0.406807   Top1 88.200000   Top5 99.640000   BatchTime 0.091851   
2022-11-25 12:14:49,683 - INFO  - ==> Top1: 88.200    Top5: 99.640    Loss: 0.407

2022-11-25 12:14:49,684 - INFO  - ==> Sparsity : 0.427

2022-11-25 12:14:49,684 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:14:49,685 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:14:49,685 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
2022-11-25 12:14:49,813 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:14:49,814 - INFO  - >>>>>> Epoch  41
2022-11-25 12:14:49,816 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:14:58,783 - INFO  - Training [41][   20/  196]   Loss 0.387743   Top1 86.621094   Top5 98.261719   BatchTime 0.448203   LR 0.001027   
2022-11-25 12:15:06,158 - INFO  - Training [41][   40/  196]   Loss 0.395443   Top1 86.562500   Top5 98.378906   BatchTime 0.408489   LR 0.001023   
2022-11-25 12:15:13,340 - INFO  - Training [41][   60/  196]   Loss 0.382967   Top1 87.070312   Top5 98.541667   BatchTime 0.392025   LR 0.001020   
2022-11-25 12:15:20,787 - INFO  - Training [41][   80/  196]   Loss 0.377721   Top1 87.192383   Top5 98.710938   BatchTime 0.387104   LR 0.001016   
2022-11-25 12:15:28,176 - INFO  - Training [41][  100/  196]   Loss 0.371115   Top1 87.394531   Top5 98.726562   BatchTime 0.383565   LR 0.001012   
2022-11-25 12:15:35,425 - INFO  - Training [41][  120/  196]   Loss 0.364147   Top1 87.623698   Top5 98.795573   BatchTime 0.380050   LR 0.001008   
2022-11-25 12:15:42,871 - INFO  - Training [41][  140/  196]   Loss 0.364735   Top1 87.603237   Top5 98.819754   BatchTime 0.378942   LR 0.001004   
2022-11-25 12:15:49,408 - INFO  - Training [41][  160/  196]   Loss 0.365639   Top1 87.636719   Top5 98.798828   BatchTime 0.372431   LR 0.001000   
2022-11-25 12:15:54,777 - INFO  - Training [41][  180/  196]   Loss 0.368533   Top1 87.545573   Top5 98.745660   BatchTime 0.360876   LR 0.000996   
2022-11-25 12:15:59,700 - INFO  - ==> Top1: 87.586    Top5: 98.740    Loss: 0.367

2022-11-25 12:15:59,984 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:16:01,495 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:16:04,051 - INFO  - Validation [41][   20/   40]   Loss 0.351634   Top1 89.160156   Top5 99.609375   BatchTime 0.127697   
2022-11-25 12:16:05,171 - INFO  - Validation [41][   40/   40]   Loss 0.332117   Top1 89.480000   Top5 99.680000   BatchTime 0.091876   
2022-11-25 12:16:05,439 - INFO  - ==> Top1: 89.480    Top5: 99.680    Loss: 0.332

2022-11-25 12:16:05,440 - INFO  - ==> Sparsity : 0.417

2022-11-25 12:16:05,440 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:16:05,441 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:16:05,441 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
2022-11-25 12:16:05,563 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:16:05,565 - INFO  - >>>>>> Epoch  42
2022-11-25 12:16:05,567 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:16:14,216 - INFO  - Training [42][   20/  196]   Loss 0.379094   Top1 87.050781   Top5 98.203125   BatchTime 0.432268   LR 0.000988   
2022-11-25 12:16:21,351 - INFO  - Training [42][   40/  196]   Loss 0.388167   Top1 86.865234   Top5 98.281250   BatchTime 0.394520   LR 0.000984   
2022-11-25 12:16:28,822 - INFO  - Training [42][   60/  196]   Loss 0.377504   Top1 87.265625   Top5 98.424479   BatchTime 0.387524   LR 0.000980   
2022-11-25 12:16:36,475 - INFO  - Training [42][   80/  196]   Loss 0.375064   Top1 87.441406   Top5 98.574219   BatchTime 0.386311   LR 0.000976   
2022-11-25 12:16:43,727 - INFO  - Training [42][  100/  196]   Loss 0.369318   Top1 87.589844   Top5 98.636719   BatchTime 0.381562   LR 0.000972   
2022-11-25 12:16:51,459 - INFO  - Training [42][  120/  196]   Loss 0.366286   Top1 87.613932   Top5 98.723958   BatchTime 0.382406   LR 0.000968   
2022-11-25 12:16:59,679 - INFO  - Training [42][  140/  196]   Loss 0.367340   Top1 87.594866   Top5 98.791853   BatchTime 0.386486   LR 0.000964   
2022-11-25 12:17:06,904 - INFO  - Training [42][  160/  196]   Loss 0.369009   Top1 87.536621   Top5 98.791504   BatchTime 0.383333   LR 0.000959   
2022-11-25 12:17:12,532 - INFO  - Training [42][  180/  196]   Loss 0.369152   Top1 87.565104   Top5 98.730469   BatchTime 0.372008   LR 0.000955   
2022-11-25 12:17:17,480 - INFO  - ==> Top1: 87.688    Top5: 98.732    Loss: 0.366

2022-11-25 12:17:17,827 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:17:19,567 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:17:22,086 - INFO  - Validation [42][   20/   40]   Loss 0.323709   Top1 89.433594   Top5 99.667969   BatchTime 0.125810   
2022-11-25 12:17:23,102 - INFO  - Validation [42][   40/   40]   Loss 0.312252   Top1 89.410000   Top5 99.690000   BatchTime 0.088309   
2022-11-25 12:17:23,369 - INFO  - ==> Top1: 89.410    Top5: 99.690    Loss: 0.312

2022-11-25 12:17:23,369 - INFO  - ==> Sparsity : 0.444

2022-11-25 12:17:23,369 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:17:23,370 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:17:23,370 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
2022-11-25 12:17:23,508 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:17:23,509 - INFO  - >>>>>> Epoch  43
2022-11-25 12:17:23,511 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:17:32,270 - INFO  - Training [43][   20/  196]   Loss 0.383858   Top1 87.441406   Top5 98.339844   BatchTime 0.437784   LR 0.000947   
2022-11-25 12:17:39,853 - INFO  - Training [43][   40/  196]   Loss 0.374310   Top1 87.509766   Top5 98.466797   BatchTime 0.408490   LR 0.000943   
2022-11-25 12:17:47,790 - INFO  - Training [43][   60/  196]   Loss 0.370028   Top1 87.688802   Top5 98.522135   BatchTime 0.404594   LR 0.000939   
2022-11-25 12:17:55,065 - INFO  - Training [43][   80/  196]   Loss 0.361220   Top1 87.978516   Top5 98.671875   BatchTime 0.394385   LR 0.000934   
2022-11-25 12:18:02,366 - INFO  - Training [43][  100/  196]   Loss 0.355867   Top1 88.164062   Top5 98.722656   BatchTime 0.388523   LR 0.000930   
2022-11-25 12:18:09,840 - INFO  - Training [43][  120/  196]   Loss 0.352738   Top1 88.297526   Top5 98.753255   BatchTime 0.386052   LR 0.000926   
2022-11-25 12:18:17,801 - INFO  - Training [43][  140/  196]   Loss 0.354718   Top1 88.247768   Top5 98.833705   BatchTime 0.387760   LR 0.000921   
2022-11-25 12:18:24,884 - INFO  - Training [43][  160/  196]   Loss 0.355504   Top1 88.171387   Top5 98.840332   BatchTime 0.383561   LR 0.000917   
2022-11-25 12:18:31,240 - INFO  - Training [43][  180/  196]   Loss 0.357182   Top1 88.101128   Top5 98.773872   BatchTime 0.376250   LR 0.000912   
2022-11-25 12:18:36,370 - INFO  - ==> Top1: 88.066    Top5: 98.758    Loss: 0.357

2022-11-25 12:18:36,672 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:18:38,607 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:18:41,156 - INFO  - Validation [43][   20/   40]   Loss 1.030390   Top1 80.527344   Top5 98.339844   BatchTime 0.127357   
2022-11-25 12:18:42,323 - INFO  - Validation [43][   40/   40]   Loss 1.034757   Top1 80.110000   Top5 98.300000   BatchTime 0.092859   
2022-11-25 12:18:42,596 - INFO  - ==> Top1: 80.110    Top5: 98.300    Loss: 1.035

2022-11-25 12:18:42,596 - INFO  - ==> Sparsity : 0.514

2022-11-25 12:18:42,597 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:18:42,597 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:18:42,597 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
2022-11-25 12:18:42,747 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:18:42,749 - INFO  - >>>>>> Epoch  44
2022-11-25 12:18:42,751 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:18:50,970 - INFO  - Training [44][   20/  196]   Loss 0.376418   Top1 86.914062   Top5 98.183594   BatchTime 0.410827   LR 0.000904   
2022-11-25 12:18:58,302 - INFO  - Training [44][   40/  196]   Loss 0.379299   Top1 87.275391   Top5 98.408203   BatchTime 0.388713   LR 0.000900   
2022-11-25 12:19:06,078 - INFO  - Training [44][   60/  196]   Loss 0.369977   Top1 87.447917   Top5 98.554688   BatchTime 0.388742   LR 0.000895   
2022-11-25 12:19:13,290 - INFO  - Training [44][   80/  196]   Loss 0.370922   Top1 87.441406   Top5 98.701172   BatchTime 0.381709   LR 0.000891   
2022-11-25 12:19:20,573 - INFO  - Training [44][  100/  196]   Loss 0.364726   Top1 87.648438   Top5 98.750000   BatchTime 0.378190   LR 0.000886   
2022-11-25 12:19:27,718 - INFO  - Training [44][  120/  196]   Loss 0.360201   Top1 87.796224   Top5 98.818359   BatchTime 0.374706   LR 0.000882   
2022-11-25 12:19:35,440 - INFO  - Training [44][  140/  196]   Loss 0.358996   Top1 87.854353   Top5 98.881138   BatchTime 0.376330   LR 0.000877   
2022-11-25 12:19:42,406 - INFO  - Training [44][  160/  196]   Loss 0.359862   Top1 87.827148   Top5 98.852539   BatchTime 0.372827   LR 0.000873   
2022-11-25 12:19:48,964 - INFO  - Training [44][  180/  196]   Loss 0.361471   Top1 87.773438   Top5 98.789062   BatchTime 0.367833   LR 0.000868   
2022-11-25 12:19:54,807 - INFO  - ==> Top1: 87.862    Top5: 98.786    Loss: 0.359

2022-11-25 12:19:55,058 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:19:56,521 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:19:59,144 - INFO  - Validation [44][   20/   40]   Loss 0.303748   Top1 90.156250   Top5 99.667969   BatchTime 0.131039   
2022-11-25 12:20:00,325 - INFO  - Validation [44][   40/   40]   Loss 0.300591   Top1 90.050000   Top5 99.750000   BatchTime 0.095060   
2022-11-25 12:20:00,546 - INFO  - ==> Top1: 90.050    Top5: 99.750    Loss: 0.301

2022-11-25 12:20:00,546 - INFO  - ==> Sparsity : 0.419

2022-11-25 12:20:00,547 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:20:00,547 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:20:00,547 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
2022-11-25 12:20:00,678 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:20:00,679 - INFO  - >>>>>> Epoch  45
2022-11-25 12:20:00,681 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:20:09,147 - INFO  - Training [45][   20/  196]   Loss 0.363210   Top1 87.617188   Top5 98.437500   BatchTime 0.423156   LR 0.000860   
2022-11-25 12:20:16,757 - INFO  - Training [45][   40/  196]   Loss 0.368103   Top1 87.500000   Top5 98.632812   BatchTime 0.401835   LR 0.000855   
2022-11-25 12:20:24,275 - INFO  - Training [45][   60/  196]   Loss 0.365043   Top1 87.617188   Top5 98.658854   BatchTime 0.393179   LR 0.000850   
2022-11-25 12:20:31,320 - INFO  - Training [45][   80/  196]   Loss 0.360616   Top1 87.812500   Top5 98.828125   BatchTime 0.382949   LR 0.000846   
2022-11-25 12:20:38,532 - INFO  - Training [45][  100/  196]   Loss 0.353302   Top1 88.054688   Top5 98.890625   BatchTime 0.378482   LR 0.000841   
2022-11-25 12:20:45,709 - INFO  - Training [45][  120/  196]   Loss 0.351978   Top1 88.108724   Top5 98.938802   BatchTime 0.375211   LR 0.000836   
2022-11-25 12:20:53,285 - INFO  - Training [45][  140/  196]   Loss 0.351688   Top1 88.191964   Top5 98.995536   BatchTime 0.375720   LR 0.000832   
2022-11-25 12:21:00,000 - INFO  - Training [45][  160/  196]   Loss 0.351355   Top1 88.176270   Top5 98.972168   BatchTime 0.370724   LR 0.000827   
2022-11-25 12:21:07,061 - INFO  - Training [45][  180/  196]   Loss 0.351322   Top1 88.168403   Top5 98.927951   BatchTime 0.368759   LR 0.000822   
2022-11-25 12:21:12,906 - INFO  - ==> Top1: 88.210    Top5: 98.916    Loss: 0.351

2022-11-25 12:21:13,125 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:21:14,611 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:21:17,200 - INFO  - Validation [45][   20/   40]   Loss 0.424574   Top1 86.718750   Top5 99.257812   BatchTime 0.129349   
2022-11-25 12:21:18,300 - INFO  - Validation [45][   40/   40]   Loss 0.422344   Top1 86.590000   Top5 99.250000   BatchTime 0.092184   
2022-11-25 12:21:18,555 - INFO  - ==> Top1: 86.590    Top5: 99.250    Loss: 0.422

2022-11-25 12:21:18,555 - INFO  - ==> Sparsity : 0.460

2022-11-25 12:21:18,556 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:21:18,556 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:21:18,556 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
2022-11-25 12:21:18,709 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:21:18,712 - INFO  - >>>>>> Epoch  46
2022-11-25 12:21:18,714 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:21:27,644 - INFO  - Training [46][   20/  196]   Loss 0.343886   Top1 88.476562   Top5 98.261719   BatchTime 0.446358   LR 0.000814   
2022-11-25 12:21:35,281 - INFO  - Training [46][   40/  196]   Loss 0.350436   Top1 88.349609   Top5 98.496094   BatchTime 0.414093   LR 0.000809   
2022-11-25 12:21:42,605 - INFO  - Training [46][   60/  196]   Loss 0.350339   Top1 88.326823   Top5 98.541667   BatchTime 0.398133   LR 0.000804   
2022-11-25 12:21:49,753 - INFO  - Training [46][   80/  196]   Loss 0.349701   Top1 88.447266   Top5 98.657227   BatchTime 0.387946   LR 0.000799   
2022-11-25 12:21:57,178 - INFO  - Training [46][  100/  196]   Loss 0.343427   Top1 88.613281   Top5 98.730469   BatchTime 0.384608   LR 0.000794   
2022-11-25 12:22:04,578 - INFO  - Training [46][  120/  196]   Loss 0.342669   Top1 88.590495   Top5 98.785807   BatchTime 0.382176   LR 0.000789   
2022-11-25 12:22:10,812 - INFO  - Training [46][  140/  196]   Loss 0.341659   Top1 88.596540   Top5 98.864397   BatchTime 0.372104   LR 0.000785   
2022-11-25 12:22:17,165 - INFO  - Training [46][  160/  196]   Loss 0.345835   Top1 88.432617   Top5 98.867188   BatchTime 0.365300   LR 0.000780   
2022-11-25 12:22:24,500 - INFO  - Training [46][  180/  196]   Loss 0.346898   Top1 88.363715   Top5 98.823785   BatchTime 0.365458   LR 0.000775   
2022-11-25 12:22:30,216 - INFO  - ==> Top1: 88.400    Top5: 98.840    Loss: 0.347

2022-11-25 12:22:30,457 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:22:31,817 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:22:34,317 - INFO  - Validation [46][   20/   40]   Loss 0.484382   Top1 84.960938   Top5 99.335938   BatchTime 0.124912   
2022-11-25 12:22:35,433 - INFO  - Validation [46][   40/   40]   Loss 0.471844   Top1 85.310000   Top5 99.350000   BatchTime 0.090351   
2022-11-25 12:22:35,692 - INFO  - ==> Top1: 85.310    Top5: 99.350    Loss: 0.472

2022-11-25 12:22:35,692 - INFO  - ==> Sparsity : 0.449

2022-11-25 12:22:35,692 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:22:35,692 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:22:35,692 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
2022-11-25 12:22:36,014 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:22:36,016 - INFO  - >>>>>> Epoch  47
2022-11-25 12:22:36,018 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:22:44,505 - INFO  - Training [47][   20/  196]   Loss 0.366254   Top1 87.675781   Top5 98.320312   BatchTime 0.424234   LR 0.000766   
2022-11-25 12:22:52,319 - INFO  - Training [47][   40/  196]   Loss 0.363098   Top1 87.802734   Top5 98.486328   BatchTime 0.407464   LR 0.000761   
2022-11-25 12:22:59,299 - INFO  - Training [47][   60/  196]   Loss 0.352139   Top1 88.151042   Top5 98.613281   BatchTime 0.387974   LR 0.000756   
2022-11-25 12:23:06,600 - INFO  - Training [47][   80/  196]   Loss 0.349395   Top1 88.251953   Top5 98.784180   BatchTime 0.382250   LR 0.000752   
2022-11-25 12:23:14,006 - INFO  - Training [47][  100/  196]   Loss 0.344505   Top1 88.500000   Top5 98.851562   BatchTime 0.379855   LR 0.000747   
2022-11-25 12:23:21,013 - INFO  - Training [47][  120/  196]   Loss 0.341113   Top1 88.668620   Top5 98.929036   BatchTime 0.374942   LR 0.000742   
2022-11-25 12:23:26,856 - INFO  - Training [47][  140/  196]   Loss 0.339875   Top1 88.763951   Top5 98.976004   BatchTime 0.363112   LR 0.000737   
2022-11-25 12:23:33,483 - INFO  - Training [47][  160/  196]   Loss 0.343610   Top1 88.645020   Top5 98.959961   BatchTime 0.359139   LR 0.000732   
2022-11-25 12:23:41,147 - INFO  - Training [47][  180/  196]   Loss 0.344252   Top1 88.602431   Top5 98.938802   BatchTime 0.361814   LR 0.000727   
2022-11-25 12:23:46,719 - INFO  - ==> Top1: 88.602    Top5: 98.916    Loss: 0.344

2022-11-25 12:23:46,943 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:23:48,360 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:23:50,840 - INFO  - Validation [47][   20/   40]   Loss 0.330795   Top1 89.648438   Top5 99.648438   BatchTime 0.123937   
2022-11-25 12:23:51,866 - INFO  - Validation [47][   40/   40]   Loss 0.320128   Top1 89.850000   Top5 99.670000   BatchTime 0.087613   
2022-11-25 12:23:52,118 - INFO  - ==> Top1: 89.850    Top5: 99.670    Loss: 0.320

2022-11-25 12:23:52,119 - INFO  - ==> Sparsity : 0.447

2022-11-25 12:23:52,119 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:23:52,119 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:23:52,119 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 90.100   Top5: 99.710]
2022-11-25 12:23:52,251 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:23:52,252 - INFO  - >>>>>> Epoch  48
2022-11-25 12:23:52,254 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:24:00,648 - INFO  - Training [48][   20/  196]   Loss 0.371477   Top1 87.226562   Top5 98.222656   BatchTime 0.419561   LR 0.000718   
2022-11-25 12:24:08,138 - INFO  - Training [48][   40/  196]   Loss 0.364847   Top1 87.695312   Top5 98.476562   BatchTime 0.397026   LR 0.000713   
2022-11-25 12:24:15,563 - INFO  - Training [48][   60/  196]   Loss 0.357053   Top1 88.105469   Top5 98.580729   BatchTime 0.388438   LR 0.000708   
2022-11-25 12:24:22,725 - INFO  - Training [48][   80/  196]   Loss 0.351805   Top1 88.256836   Top5 98.715820   BatchTime 0.380851   LR 0.000703   
2022-11-25 12:24:29,958 - INFO  - Training [48][  100/  196]   Loss 0.340413   Top1 88.589844   Top5 98.812500   BatchTime 0.377007   LR 0.000698   
2022-11-25 12:24:36,422 - INFO  - Training [48][  120/  196]   Loss 0.334444   Top1 88.753255   Top5 98.870443   BatchTime 0.368037   LR 0.000693   
2022-11-25 12:24:43,262 - INFO  - Training [48][  140/  196]   Loss 0.333946   Top1 88.805804   Top5 98.920201   BatchTime 0.364315   LR 0.000688   
2022-11-25 12:24:50,542 - INFO  - Training [48][  160/  196]   Loss 0.335014   Top1 88.781738   Top5 98.920898   BatchTime 0.364279   LR 0.000683   
2022-11-25 12:24:58,066 - INFO  - Training [48][  180/  196]   Loss 0.335991   Top1 88.745660   Top5 98.901910   BatchTime 0.365600   LR 0.000678   
2022-11-25 12:25:04,097 - INFO  - ==> Top1: 88.820    Top5: 98.898    Loss: 0.335

2022-11-25 12:25:04,370 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:25:05,821 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:25:08,167 - INFO  - Validation [48][   20/   40]   Loss 0.319295   Top1 90.214844   Top5 99.648438   BatchTime 0.117202   
2022-11-25 12:25:09,208 - INFO  - Validation [48][   40/   40]   Loss 0.306920   Top1 90.550000   Top5 99.710000   BatchTime 0.084613   
2022-11-25 12:25:09,440 - INFO  - ==> Top1: 90.550    Top5: 99.710    Loss: 0.307

2022-11-25 12:25:09,441 - INFO  - ==> Sparsity : 0.450

2022-11-25 12:25:09,441 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
2022-11-25 12:25:09,441 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:25:09,441 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:25:14,501 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 12:25:14,504 - INFO  - >>>>>> Epoch  49
2022-11-25 12:25:14,506 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:25:23,764 - INFO  - Training [49][   20/  196]   Loss 0.342123   Top1 88.105469   Top5 98.359375   BatchTime 0.462734   LR 0.000669   
2022-11-25 12:25:31,524 - INFO  - Training [49][   40/  196]   Loss 0.340190   Top1 88.291016   Top5 98.613281   BatchTime 0.425393   LR 0.000664   
2022-11-25 12:25:38,846 - INFO  - Training [49][   60/  196]   Loss 0.339492   Top1 88.359375   Top5 98.665365   BatchTime 0.405611   LR 0.000659   
2022-11-25 12:25:46,066 - INFO  - Training [49][   80/  196]   Loss 0.335798   Top1 88.461914   Top5 98.847656   BatchTime 0.394459   LR 0.000654   
2022-11-25 12:25:52,088 - INFO  - Training [49][  100/  196]   Loss 0.334076   Top1 88.542969   Top5 98.855469   BatchTime 0.375791   LR 0.000649   
2022-11-25 12:25:58,429 - INFO  - Training [49][  120/  196]   Loss 0.328016   Top1 88.854167   Top5 98.912760   BatchTime 0.365997   LR 0.000644   
2022-11-25 12:26:05,883 - INFO  - Training [49][  140/  196]   Loss 0.327552   Top1 88.881138   Top5 98.959263   BatchTime 0.366957   LR 0.000639   
2022-11-25 12:26:13,458 - INFO  - Training [49][  160/  196]   Loss 0.332922   Top1 88.737793   Top5 98.918457   BatchTime 0.368427   LR 0.000634   
2022-11-25 12:26:20,796 - INFO  - Training [49][  180/  196]   Loss 0.335474   Top1 88.650174   Top5 98.893229   BatchTime 0.368257   LR 0.000629   
2022-11-25 12:26:27,008 - INFO  - ==> Top1: 88.632    Top5: 98.896    Loss: 0.335

2022-11-25 12:26:27,287 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:26:28,719 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:26:31,846 - INFO  - Validation [49][   20/   40]   Loss 0.334885   Top1 89.570312   Top5 99.570312   BatchTime 0.156278   
2022-11-25 12:26:33,113 - INFO  - Validation [49][   40/   40]   Loss 0.326140   Top1 89.580000   Top5 99.670000   BatchTime 0.109812   
2022-11-25 12:26:33,406 - INFO  - ==> Top1: 89.580    Top5: 99.670    Loss: 0.326

2022-11-25 12:26:33,406 - INFO  - ==> Sparsity : 0.460

2022-11-25 12:26:33,406 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
2022-11-25 12:26:33,406 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:26:33,407 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:26:33,543 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:26:33,544 - INFO  - >>>>>> Epoch  50
2022-11-25 12:26:33,546 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:26:42,680 - INFO  - Training [50][   20/  196]   Loss 0.359157   Top1 87.988281   Top5 98.398438   BatchTime 0.456563   LR 0.000620   
2022-11-25 12:26:49,973 - INFO  - Training [50][   40/  196]   Loss 0.356036   Top1 87.890625   Top5 98.535156   BatchTime 0.410595   LR 0.000615   
2022-11-25 12:26:57,235 - INFO  - Training [50][   60/  196]   Loss 0.352565   Top1 88.014323   Top5 98.652344   BatchTime 0.394765   LR 0.000610   
2022-11-25 12:27:03,732 - INFO  - Training [50][   80/  196]   Loss 0.347449   Top1 88.291016   Top5 98.754883   BatchTime 0.377287   LR 0.000605   
2022-11-25 12:27:10,296 - INFO  - Training [50][  100/  196]   Loss 0.338136   Top1 88.691406   Top5 98.839844   BatchTime 0.367470   LR 0.000600   
2022-11-25 12:27:17,520 - INFO  - Training [50][  120/  196]   Loss 0.330664   Top1 89.036458   Top5 98.912760   BatchTime 0.366424   LR 0.000595   
2022-11-25 12:27:24,766 - INFO  - Training [50][  140/  196]   Loss 0.328715   Top1 89.098772   Top5 98.989955   BatchTime 0.365833   LR 0.000590   
2022-11-25 12:27:31,939 - INFO  - Training [50][  160/  196]   Loss 0.330702   Top1 89.023438   Top5 98.962402   BatchTime 0.364936   LR 0.000585   
2022-11-25 12:27:39,287 - INFO  - Training [50][  180/  196]   Loss 0.331823   Top1 88.973524   Top5 98.936632   BatchTime 0.365208   LR 0.000580   
2022-11-25 12:27:45,262 - INFO  - ==> Top1: 89.046    Top5: 98.956    Loss: 0.330

2022-11-25 12:27:45,512 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:27:47,051 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:27:49,693 - INFO  - Validation [50][   20/   40]   Loss 0.316384   Top1 90.273438   Top5 99.648438   BatchTime 0.132025   
2022-11-25 12:27:51,478 - INFO  - Validation [50][   40/   40]   Loss 0.307324   Top1 90.180000   Top5 99.680000   BatchTime 0.110642   
2022-11-25 12:27:51,839 - INFO  - ==> Top1: 90.180    Top5: 99.680    Loss: 0.307

2022-11-25 12:27:51,840 - INFO  - ==> Sparsity : 0.467

2022-11-25 12:27:51,840 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
2022-11-25 12:27:51,841 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:27:51,841 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.230   Top5: 99.660]
2022-11-25 12:27:52,098 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:27:52,101 - INFO  - >>>>>> Epoch  51
2022-11-25 12:27:52,104 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:28:01,353 - INFO  - Training [51][   20/  196]   Loss 0.353735   Top1 88.046875   Top5 98.437500   BatchTime 0.462230   LR 0.000571   
2022-11-25 12:28:09,271 - INFO  - Training [51][   40/  196]   Loss 0.348420   Top1 88.388672   Top5 98.535156   BatchTime 0.429053   LR 0.000566   
2022-11-25 12:28:15,940 - INFO  - Training [51][   60/  196]   Loss 0.343995   Top1 88.450521   Top5 98.613281   BatchTime 0.397191   LR 0.000561   
2022-11-25 12:28:22,499 - INFO  - Training [51][   80/  196]   Loss 0.338131   Top1 88.803711   Top5 98.740234   BatchTime 0.379880   LR 0.000556   
2022-11-25 12:28:29,872 - INFO  - Training [51][  100/  196]   Loss 0.330272   Top1 89.042969   Top5 98.835938   BatchTime 0.377634   LR 0.000551   
2022-11-25 12:28:37,034 - INFO  - Training [51][  120/  196]   Loss 0.325010   Top1 89.192708   Top5 98.916016   BatchTime 0.374372   LR 0.000546   
2022-11-25 12:28:44,073 - INFO  - Training [51][  140/  196]   Loss 0.324934   Top1 89.168527   Top5 98.964844   BatchTime 0.371171   LR 0.000541   
2022-11-25 12:28:51,440 - INFO  - Training [51][  160/  196]   Loss 0.329154   Top1 89.008789   Top5 98.923340   BatchTime 0.370820   LR 0.000536   
2022-11-25 12:28:58,967 - INFO  - Training [51][  180/  196]   Loss 0.330130   Top1 88.975694   Top5 98.862847   BatchTime 0.371432   LR 0.000531   
2022-11-25 12:29:05,203 - INFO  - ==> Top1: 89.044    Top5: 98.892    Loss: 0.329

2022-11-25 12:29:05,488 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:29:07,434 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:29:10,070 - INFO  - Validation [51][   20/   40]   Loss 0.311347   Top1 90.722656   Top5 99.648438   BatchTime 0.131677   
2022-11-25 12:29:11,172 - INFO  - Validation [51][   40/   40]   Loss 0.298658   Top1 90.790000   Top5 99.690000   BatchTime 0.093398   
2022-11-25 12:29:11,397 - INFO  - ==> Top1: 90.790    Top5: 99.690    Loss: 0.299

2022-11-25 12:29:11,397 - INFO  - ==> Sparsity : 0.471

2022-11-25 12:29:11,397 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
2022-11-25 12:29:11,398 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
2022-11-25 12:29:11,398 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:29:17,134 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 12:29:17,142 - INFO  - >>>>>> Epoch  52
2022-11-25 12:29:17,145 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:29:25,591 - INFO  - Training [52][   20/  196]   Loss 0.333925   Top1 88.710938   Top5 98.632812   BatchTime 0.422076   LR 0.000523   
2022-11-25 12:29:31,412 - INFO  - Training [52][   40/  196]   Loss 0.340318   Top1 88.623047   Top5 98.642578   BatchTime 0.356565   LR 0.000518   
2022-11-25 12:29:38,329 - INFO  - Training [52][   60/  196]   Loss 0.339971   Top1 88.587240   Top5 98.652344   BatchTime 0.352988   LR 0.000513   
2022-11-25 12:29:45,845 - INFO  - Training [52][   80/  196]   Loss 0.331955   Top1 88.867188   Top5 98.833008   BatchTime 0.358688   LR 0.000508   
2022-11-25 12:29:53,880 - INFO  - Training [52][  100/  196]   Loss 0.324093   Top1 89.117188   Top5 98.890625   BatchTime 0.367297   LR 0.000503   
2022-11-25 12:30:01,389 - INFO  - Training [52][  120/  196]   Loss 0.320597   Top1 89.300130   Top5 98.916016   BatchTime 0.368662   LR 0.000498   
2022-11-25 12:30:08,694 - INFO  - Training [52][  140/  196]   Loss 0.315960   Top1 89.481027   Top5 98.978795   BatchTime 0.368168   LR 0.000493   
2022-11-25 12:30:16,274 - INFO  - Training [52][  160/  196]   Loss 0.320983   Top1 89.262695   Top5 98.979492   BatchTime 0.369527   LR 0.000488   
2022-11-25 12:30:24,535 - INFO  - Training [52][  180/  196]   Loss 0.321169   Top1 89.307726   Top5 98.951823   BatchTime 0.374357   LR 0.000483   
2022-11-25 12:30:30,592 - INFO  - ==> Top1: 89.366    Top5: 98.956    Loss: 0.319

2022-11-25 12:30:30,869 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:30:32,426 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:30:34,893 - INFO  - Validation [52][   20/   40]   Loss 0.352371   Top1 89.511719   Top5 99.394531   BatchTime 0.123250   
2022-11-25 12:30:35,971 - INFO  - Validation [52][   40/   40]   Loss 0.342738   Top1 89.490000   Top5 99.520000   BatchTime 0.088576   
2022-11-25 12:30:36,191 - INFO  - ==> Top1: 89.490    Top5: 99.520    Loss: 0.343

2022-11-25 12:30:36,192 - INFO  - ==> Sparsity : 0.552

2022-11-25 12:30:36,192 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
2022-11-25 12:30:36,192 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
2022-11-25 12:30:36,192 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:30:36,321 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:30:36,324 - INFO  - >>>>>> Epoch  53
2022-11-25 12:30:36,326 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:30:44,011 - INFO  - Training [53][   20/  196]   Loss 0.333321   Top1 88.574219   Top5 98.554688   BatchTime 0.384125   LR 0.000474   
2022-11-25 12:30:51,591 - INFO  - Training [53][   40/  196]   Loss 0.346658   Top1 88.203125   Top5 98.623047   BatchTime 0.381579   LR 0.000470   
2022-11-25 12:30:58,900 - INFO  - Training [53][   60/  196]   Loss 0.337591   Top1 88.658854   Top5 98.691406   BatchTime 0.376193   LR 0.000465   
2022-11-25 12:31:06,367 - INFO  - Training [53][   80/  196]   Loss 0.335122   Top1 88.715820   Top5 98.818359   BatchTime 0.375486   LR 0.000460   
2022-11-25 12:31:13,846 - INFO  - Training [53][  100/  196]   Loss 0.328255   Top1 88.988281   Top5 98.867188   BatchTime 0.375177   LR 0.000455   
2022-11-25 12:31:21,512 - INFO  - Training [53][  120/  196]   Loss 0.319173   Top1 89.287109   Top5 98.932292   BatchTime 0.376529   LR 0.000450   
2022-11-25 12:31:29,537 - INFO  - Training [53][  140/  196]   Loss 0.314195   Top1 89.461496   Top5 99.020647   BatchTime 0.380061   LR 0.000445   
2022-11-25 12:31:36,988 - INFO  - Training [53][  160/  196]   Loss 0.315963   Top1 89.331055   Top5 99.006348   BatchTime 0.379121   LR 0.000441   
2022-11-25 12:31:44,604 - INFO  - Training [53][  180/  196]   Loss 0.317651   Top1 89.279514   Top5 98.962674   BatchTime 0.379305   LR 0.000436   
2022-11-25 12:31:50,872 - INFO  - ==> Top1: 89.338    Top5: 98.972    Loss: 0.315

2022-11-25 12:31:51,116 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:31:52,545 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:31:56,757 - INFO  - Validation [53][   20/   40]   Loss 0.339709   Top1 89.707031   Top5 99.589844   BatchTime 0.210497   
2022-11-25 12:31:57,788 - INFO  - Validation [53][   40/   40]   Loss 0.330008   Top1 89.850000   Top5 99.650000   BatchTime 0.131022   
2022-11-25 12:31:58,355 - INFO  - ==> Top1: 89.850    Top5: 99.650    Loss: 0.330

2022-11-25 12:31:58,355 - INFO  - ==> Sparsity : 0.532

2022-11-25 12:31:58,355 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
2022-11-25 12:31:58,356 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
2022-11-25 12:31:58,356 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:31:58,515 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:31:58,517 - INFO  - >>>>>> Epoch  54
2022-11-25 12:31:58,519 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:32:04,909 - INFO  - Training [54][   20/  196]   Loss 0.328013   Top1 88.886719   Top5 98.496094   BatchTime 0.319397   LR 0.000427   
2022-11-25 12:32:11,943 - INFO  - Training [54][   40/  196]   Loss 0.320768   Top1 89.003906   Top5 98.828125   BatchTime 0.335540   LR 0.000423   
2022-11-25 12:32:19,190 - INFO  - Training [54][   60/  196]   Loss 0.326405   Top1 88.821615   Top5 98.925781   BatchTime 0.344482   LR 0.000418   
2022-11-25 12:32:27,168 - INFO  - Training [54][   80/  196]   Loss 0.323603   Top1 89.077148   Top5 98.989258   BatchTime 0.358074   LR 0.000413   
2022-11-25 12:32:34,736 - INFO  - Training [54][  100/  196]   Loss 0.316566   Top1 89.425781   Top5 99.039062   BatchTime 0.362143   LR 0.000408   
2022-11-25 12:32:41,764 - INFO  - Training [54][  120/  196]   Loss 0.309471   Top1 89.703776   Top5 99.098307   BatchTime 0.360353   LR 0.000404   
2022-11-25 12:32:48,867 - INFO  - Training [54][  140/  196]   Loss 0.307655   Top1 89.799107   Top5 99.123884   BatchTime 0.359607   LR 0.000399   
2022-11-25 12:32:56,660 - INFO  - Training [54][  160/  196]   Loss 0.310755   Top1 89.680176   Top5 99.106445   BatchTime 0.363364   LR 0.000394   
2022-11-25 12:33:03,998 - INFO  - Training [54][  180/  196]   Loss 0.309386   Top1 89.726562   Top5 99.062500   BatchTime 0.363751   LR 0.000390   
2022-11-25 12:33:10,226 - INFO  - ==> Top1: 89.758    Top5: 99.054    Loss: 0.308

2022-11-25 12:33:10,504 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:33:12,207 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:33:14,985 - INFO  - Validation [54][   20/   40]   Loss 0.383767   Top1 88.613281   Top5 99.355469   BatchTime 0.138814   
2022-11-25 12:33:16,112 - INFO  - Validation [54][   40/   40]   Loss 0.372804   Top1 88.770000   Top5 99.490000   BatchTime 0.097585   
2022-11-25 12:33:16,708 - INFO  - ==> Top1: 88.770    Top5: 99.490    Loss: 0.373

2022-11-25 12:33:16,709 - INFO  - ==> Sparsity : 0.546

2022-11-25 12:33:16,709 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
2022-11-25 12:33:16,710 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
2022-11-25 12:33:16,710 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 90.250   Top5: 99.740]
2022-11-25 12:33:16,844 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:33:16,846 - INFO  - >>>>>> Epoch  55
2022-11-25 12:33:16,848 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:33:25,317 - INFO  - Training [55][   20/  196]   Loss 0.316280   Top1 88.964844   Top5 98.710938   BatchTime 0.423312   LR 0.000381   
2022-11-25 12:33:32,648 - INFO  - Training [55][   40/  196]   Loss 0.307795   Top1 89.628906   Top5 98.710938   BatchTime 0.394938   LR 0.000377   
2022-11-25 12:33:39,984 - INFO  - Training [55][   60/  196]   Loss 0.309214   Top1 89.531250   Top5 98.808594   BatchTime 0.385556   LR 0.000372   
2022-11-25 12:33:47,276 - INFO  - Training [55][   80/  196]   Loss 0.308615   Top1 89.536133   Top5 98.979492   BatchTime 0.380312   LR 0.000368   
2022-11-25 12:33:54,679 - INFO  - Training [55][  100/  196]   Loss 0.307286   Top1 89.628906   Top5 98.945312   BatchTime 0.378284   LR 0.000363   
2022-11-25 12:34:01,757 - INFO  - Training [55][  120/  196]   Loss 0.301082   Top1 89.833984   Top5 99.016927   BatchTime 0.374216   LR 0.000358   
2022-11-25 12:34:09,867 - INFO  - Training [55][  140/  196]   Loss 0.302381   Top1 89.863281   Top5 99.065290   BatchTime 0.378688   LR 0.000354   
2022-11-25 12:34:17,162 - INFO  - Training [55][  160/  196]   Loss 0.303213   Top1 89.833984   Top5 99.082031   BatchTime 0.376941   LR 0.000349   
2022-11-25 12:34:24,507 - INFO  - Training [55][  180/  196]   Loss 0.304037   Top1 89.774306   Top5 99.053819   BatchTime 0.375864   LR 0.000345   
2022-11-25 12:34:29,801 - INFO  - ==> Top1: 89.812    Top5: 99.050    Loss: 0.303

2022-11-25 12:34:29,993 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:34:32,554 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:34:35,321 - INFO  - Validation [55][   20/   40]   Loss 0.323436   Top1 90.078125   Top5 99.609375   BatchTime 0.138208   
2022-11-25 12:34:36,819 - INFO  - Validation [55][   40/   40]   Loss 0.309215   Top1 90.300000   Top5 99.710000   BatchTime 0.106582   
2022-11-25 12:34:37,029 - INFO  - ==> Top1: 90.300    Top5: 99.710    Loss: 0.309

2022-11-25 12:34:37,030 - INFO  - ==> Sparsity : 0.544

2022-11-25 12:34:37,030 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
2022-11-25 12:34:37,030 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
2022-11-25 12:34:37,030 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 90.300   Top5: 99.710]
2022-11-25 12:34:37,201 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:34:37,203 - INFO  - >>>>>> Epoch  56
2022-11-25 12:34:37,206 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:34:46,017 - INFO  - Training [56][   20/  196]   Loss 0.325557   Top1 88.886719   Top5 98.671875   BatchTime 0.440375   LR 0.000337   
2022-11-25 12:34:53,834 - INFO  - Training [56][   40/  196]   Loss 0.320336   Top1 89.218750   Top5 98.798828   BatchTime 0.415615   LR 0.000333   
2022-11-25 12:35:01,595 - INFO  - Training [56][   60/  196]   Loss 0.313664   Top1 89.544271   Top5 98.873698   BatchTime 0.406432   LR 0.000328   
2022-11-25 12:35:08,980 - INFO  - Training [56][   80/  196]   Loss 0.313113   Top1 89.599609   Top5 98.979492   BatchTime 0.397124   LR 0.000324   
2022-11-25 12:35:16,139 - INFO  - Training [56][  100/  196]   Loss 0.306452   Top1 89.742188   Top5 99.039062   BatchTime 0.389294   LR 0.000319   
2022-11-25 12:35:24,097 - INFO  - Training [56][  120/  196]   Loss 0.301949   Top1 89.850260   Top5 99.108073   BatchTime 0.390722   LR 0.000315   
2022-11-25 12:35:31,481 - INFO  - Training [56][  140/  196]   Loss 0.300277   Top1 89.969308   Top5 99.140625   BatchTime 0.387647   LR 0.000311   
2022-11-25 12:35:39,039 - INFO  - Training [56][  160/  196]   Loss 0.303570   Top1 89.887695   Top5 99.118652   BatchTime 0.386429   LR 0.000306   
2022-11-25 12:35:46,077 - INFO  - Training [56][  180/  196]   Loss 0.303195   Top1 89.895833   Top5 99.069010   BatchTime 0.382592   LR 0.000302   
2022-11-25 12:35:51,961 - INFO  - ==> Top1: 89.944    Top5: 99.064    Loss: 0.302

2022-11-25 12:35:52,210 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:35:53,693 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:35:56,219 - INFO  - Validation [56][   20/   40]   Loss 0.294323   Top1 90.859375   Top5 99.609375   BatchTime 0.126243   
2022-11-25 12:35:57,351 - INFO  - Validation [56][   40/   40]   Loss 0.277298   Top1 91.220000   Top5 99.700000   BatchTime 0.091416   
2022-11-25 12:35:57,587 - INFO  - ==> Top1: 91.220    Top5: 99.700    Loss: 0.277

2022-11-25 12:35:57,588 - INFO  - ==> Sparsity : 0.546

2022-11-25 12:35:57,588 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:35:57,588 - INFO  - Scoreboard best 2 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
2022-11-25 12:35:57,589 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
2022-11-25 12:36:02,987 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 12:36:02,991 - INFO  - >>>>>> Epoch  57
2022-11-25 12:36:02,993 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:36:11,952 - INFO  - Training [57][   20/  196]   Loss 0.308413   Top1 89.414062   Top5 98.300781   BatchTime 0.447812   LR 0.000294   
2022-11-25 12:36:19,131 - INFO  - Training [57][   40/  196]   Loss 0.308863   Top1 89.511719   Top5 98.525391   BatchTime 0.403388   LR 0.000290   
2022-11-25 12:36:26,193 - INFO  - Training [57][   60/  196]   Loss 0.310563   Top1 89.505208   Top5 98.626302   BatchTime 0.386624   LR 0.000286   
2022-11-25 12:36:33,396 - INFO  - Training [57][   80/  196]   Loss 0.313083   Top1 89.506836   Top5 98.764648   BatchTime 0.380001   LR 0.000282   
2022-11-25 12:36:41,078 - INFO  - Training [57][  100/  196]   Loss 0.305562   Top1 89.738281   Top5 98.875000   BatchTime 0.380825   LR 0.000277   
2022-11-25 12:36:48,367 - INFO  - Training [57][  120/  196]   Loss 0.300081   Top1 89.957682   Top5 98.984375   BatchTime 0.378096   LR 0.000273   
2022-11-25 12:36:54,996 - INFO  - Training [57][  140/  196]   Loss 0.299749   Top1 89.988839   Top5 99.034598   BatchTime 0.371431   LR 0.000269   
2022-11-25 12:37:01,459 - INFO  - Training [57][  160/  196]   Loss 0.302261   Top1 89.960938   Top5 99.020996   BatchTime 0.365391   LR 0.000265   
2022-11-25 12:37:07,536 - INFO  - Training [57][  180/  196]   Loss 0.301102   Top1 89.995660   Top5 98.977865   BatchTime 0.358553   LR 0.000261   
2022-11-25 12:37:13,458 - INFO  - ==> Top1: 90.042    Top5: 98.982    Loss: 0.300

2022-11-25 12:37:13,758 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:37:15,504 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:37:18,079 - INFO  - Validation [57][   20/   40]   Loss 0.326764   Top1 90.078125   Top5 99.628906   BatchTime 0.128657   
2022-11-25 12:37:19,149 - INFO  - Validation [57][   40/   40]   Loss 0.309208   Top1 90.200000   Top5 99.660000   BatchTime 0.091091   
2022-11-25 12:37:19,392 - INFO  - ==> Top1: 90.200    Top5: 99.660    Loss: 0.309

2022-11-25 12:37:19,392 - INFO  - ==> Sparsity : 0.558

2022-11-25 12:37:19,392 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:37:19,392 - INFO  - Scoreboard best 2 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
2022-11-25 12:37:19,393 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 90.550   Top5: 99.710]
2022-11-25 12:37:19,518 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:37:19,520 - INFO  - >>>>>> Epoch  58
2022-11-25 12:37:19,522 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:37:28,407 - INFO  - Training [58][   20/  196]   Loss 0.317639   Top1 89.101562   Top5 98.769531   BatchTime 0.444108   LR 0.000254   
2022-11-25 12:37:35,613 - INFO  - Training [58][   40/  196]   Loss 0.321050   Top1 89.160156   Top5 98.779297   BatchTime 0.402206   LR 0.000250   
2022-11-25 12:37:42,533 - INFO  - Training [58][   60/  196]   Loss 0.314707   Top1 89.440104   Top5 98.795573   BatchTime 0.383471   LR 0.000246   
2022-11-25 12:37:50,351 - INFO  - Training [58][   80/  196]   Loss 0.309106   Top1 89.682617   Top5 98.920898   BatchTime 0.385327   LR 0.000242   
2022-11-25 12:37:57,638 - INFO  - Training [58][  100/  196]   Loss 0.302832   Top1 89.886719   Top5 98.949219   BatchTime 0.381132   LR 0.000238   
2022-11-25 12:38:04,724 - INFO  - Training [58][  120/  196]   Loss 0.297103   Top1 90.097656   Top5 99.016927   BatchTime 0.376658   LR 0.000234   
2022-11-25 12:38:11,796 - INFO  - Training [58][  140/  196]   Loss 0.295612   Top1 90.200893   Top5 99.056920   BatchTime 0.373366   LR 0.000230   
2022-11-25 12:38:17,579 - INFO  - Training [58][  160/  196]   Loss 0.298161   Top1 90.139160   Top5 99.040527   BatchTime 0.362838   LR 0.000226   
2022-11-25 12:38:24,521 - INFO  - Training [58][  180/  196]   Loss 0.298823   Top1 90.130208   Top5 98.995226   BatchTime 0.361091   LR 0.000222   
2022-11-25 12:38:31,002 - INFO  - ==> Top1: 90.132    Top5: 98.990    Loss: 0.298

2022-11-25 12:38:31,248 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:38:32,680 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:38:35,200 - INFO  - Validation [58][   20/   40]   Loss 0.299072   Top1 90.917969   Top5 99.589844   BatchTime 0.125923   
2022-11-25 12:38:36,301 - INFO  - Validation [58][   40/   40]   Loss 0.284580   Top1 91.130000   Top5 99.700000   BatchTime 0.090486   
2022-11-25 12:38:36,554 - INFO  - ==> Top1: 91.130    Top5: 99.700    Loss: 0.285

2022-11-25 12:38:36,554 - INFO  - ==> Sparsity : 0.552

2022-11-25 12:38:36,554 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:38:36,555 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
2022-11-25 12:38:36,555 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
2022-11-25 12:38:36,687 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:38:36,689 - INFO  - >>>>>> Epoch  59
2022-11-25 12:38:36,690 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:38:45,562 - INFO  - Training [59][   20/  196]   Loss 0.311720   Top1 89.511719   Top5 98.515625   BatchTime 0.443442   LR 0.000215   
2022-11-25 12:38:52,762 - INFO  - Training [59][   40/  196]   Loss 0.314301   Top1 89.765625   Top5 98.818359   BatchTime 0.401719   LR 0.000212   
2022-11-25 12:38:59,883 - INFO  - Training [59][   60/  196]   Loss 0.308641   Top1 89.824219   Top5 98.932292   BatchTime 0.386496   LR 0.000208   
2022-11-25 12:39:07,615 - INFO  - Training [59][   80/  196]   Loss 0.306313   Top1 89.804688   Top5 99.028320   BatchTime 0.386517   LR 0.000204   
2022-11-25 12:39:15,188 - INFO  - Training [59][  100/  196]   Loss 0.301484   Top1 89.972656   Top5 99.046875   BatchTime 0.384945   LR 0.000201   
2022-11-25 12:39:22,475 - INFO  - Training [59][  120/  196]   Loss 0.298112   Top1 90.074870   Top5 99.121094   BatchTime 0.381510   LR 0.000197   
2022-11-25 12:39:28,543 - INFO  - Training [59][  140/  196]   Loss 0.296761   Top1 90.159040   Top5 99.143415   BatchTime 0.370351   LR 0.000193   
2022-11-25 12:39:34,237 - INFO  - Training [59][  160/  196]   Loss 0.299391   Top1 90.039062   Top5 99.123535   BatchTime 0.359649   LR 0.000190   
2022-11-25 12:39:40,973 - INFO  - Training [59][  180/  196]   Loss 0.298045   Top1 90.080295   Top5 99.066840   BatchTime 0.357109   LR 0.000186   
2022-11-25 12:39:46,768 - INFO  - ==> Top1: 90.130    Top5: 99.070    Loss: 0.297

2022-11-25 12:39:46,996 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:39:48,430 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:39:51,142 - INFO  - Validation [59][   20/   40]   Loss 0.316612   Top1 90.351562   Top5 99.648438   BatchTime 0.135537   
2022-11-25 12:39:52,230 - INFO  - Validation [59][   40/   40]   Loss 0.301409   Top1 90.600000   Top5 99.730000   BatchTime 0.094958   
2022-11-25 12:39:52,451 - INFO  - ==> Top1: 90.600    Top5: 99.730    Loss: 0.301

2022-11-25 12:39:52,451 - INFO  - ==> Sparsity : 0.565

2022-11-25 12:39:52,452 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:39:52,452 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
2022-11-25 12:39:52,452 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
2022-11-25 12:39:52,574 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:39:52,576 - INFO  - >>>>>> Epoch  60
2022-11-25 12:39:52,578 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:40:01,115 - INFO  - Training [60][   20/  196]   Loss 0.296749   Top1 89.433594   Top5 98.769531   BatchTime 0.426704   LR 0.000180   
2022-11-25 12:40:08,839 - INFO  - Training [60][   40/  196]   Loss 0.298724   Top1 89.492188   Top5 98.935547   BatchTime 0.406464   LR 0.000176   
2022-11-25 12:40:16,011 - INFO  - Training [60][   60/  196]   Loss 0.297419   Top1 89.778646   Top5 98.945312   BatchTime 0.390507   LR 0.000173   
2022-11-25 12:40:23,983 - INFO  - Training [60][   80/  196]   Loss 0.296108   Top1 89.882812   Top5 99.013672   BatchTime 0.392531   LR 0.000169   
2022-11-25 12:40:31,136 - INFO  - Training [60][  100/  196]   Loss 0.292687   Top1 90.070312   Top5 99.003906   BatchTime 0.385550   LR 0.000166   
2022-11-25 12:40:38,200 - INFO  - Training [60][  120/  196]   Loss 0.289469   Top1 90.231120   Top5 99.046224   BatchTime 0.380160   LR 0.000162   
2022-11-25 12:40:44,795 - INFO  - Training [60][  140/  196]   Loss 0.286940   Top1 90.318080   Top5 99.104353   BatchTime 0.372960   LR 0.000159   
2022-11-25 12:40:50,964 - INFO  - Training [60][  160/  196]   Loss 0.289574   Top1 90.236816   Top5 99.072266   BatchTime 0.364890   LR 0.000156   
2022-11-25 12:40:56,779 - INFO  - Training [60][  180/  196]   Loss 0.288965   Top1 90.221354   Top5 99.066840   BatchTime 0.356652   LR 0.000152   
2022-11-25 12:41:02,958 - INFO  - ==> Top1: 90.324    Top5: 99.080    Loss: 0.287

2022-11-25 12:41:03,331 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:41:05,890 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:41:09,151 - INFO  - Validation [60][   20/   40]   Loss 0.320069   Top1 90.429688   Top5 99.648438   BatchTime 0.162987   
2022-11-25 12:41:10,239 - INFO  - Validation [60][   40/   40]   Loss 0.307432   Top1 90.650000   Top5 99.690000   BatchTime 0.108699   
2022-11-25 12:41:10,531 - INFO  - ==> Top1: 90.650    Top5: 99.690    Loss: 0.307

2022-11-25 12:41:10,531 - INFO  - ==> Sparsity : 0.575

2022-11-25 12:41:10,531 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:41:10,531 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
2022-11-25 12:41:10,531 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 90.790   Top5: 99.690]
2022-11-25 12:41:10,656 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:41:10,658 - INFO  - >>>>>> Epoch  61
2022-11-25 12:41:10,660 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:41:19,336 - INFO  - Training [61][   20/  196]   Loss 0.325200   Top1 88.964844   Top5 98.593750   BatchTime 0.433706   LR 0.000147   
2022-11-25 12:41:26,834 - INFO  - Training [61][   40/  196]   Loss 0.311689   Top1 89.648438   Top5 98.642578   BatchTime 0.404296   LR 0.000143   
2022-11-25 12:41:34,792 - INFO  - Training [61][   60/  196]   Loss 0.304644   Top1 89.837240   Top5 98.789062   BatchTime 0.402164   LR 0.000140   
2022-11-25 12:41:41,828 - INFO  - Training [61][   80/  196]   Loss 0.301886   Top1 89.960938   Top5 98.920898   BatchTime 0.389570   LR 0.000137   
2022-11-25 12:41:49,052 - INFO  - Training [61][  100/  196]   Loss 0.295653   Top1 90.167969   Top5 98.964844   BatchTime 0.383892   LR 0.000134   
2022-11-25 12:41:56,185 - INFO  - Training [61][  120/  196]   Loss 0.288732   Top1 90.452474   Top5 99.026693   BatchTime 0.379358   LR 0.000131   
2022-11-25 12:42:03,047 - INFO  - Training [61][  140/  196]   Loss 0.288989   Top1 90.396205   Top5 99.079241   BatchTime 0.374178   LR 0.000128   
2022-11-25 12:42:09,540 - INFO  - Training [61][  160/  196]   Loss 0.291400   Top1 90.268555   Top5 99.074707   BatchTime 0.367981   LR 0.000125   
2022-11-25 12:42:17,774 - INFO  - Training [61][  180/  196]   Loss 0.289968   Top1 90.303819   Top5 99.042969   BatchTime 0.372842   LR 0.000122   
2022-11-25 12:42:24,015 - INFO  - ==> Top1: 90.348    Top5: 99.062    Loss: 0.289

2022-11-25 12:42:24,347 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:42:26,034 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:42:28,536 - INFO  - Validation [61][   20/   40]   Loss 0.312395   Top1 90.644531   Top5 99.589844   BatchTime 0.125013   
2022-11-25 12:42:29,684 - INFO  - Validation [61][   40/   40]   Loss 0.294642   Top1 90.950000   Top5 99.690000   BatchTime 0.091214   
2022-11-25 12:42:30,084 - INFO  - ==> Top1: 90.950    Top5: 99.690    Loss: 0.295

2022-11-25 12:42:30,084 - INFO  - ==> Sparsity : 0.575

2022-11-25 12:42:30,084 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:42:30,084 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
2022-11-25 12:42:30,085 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 90.950   Top5: 99.690]
2022-11-25 12:42:30,220 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:42:30,222 - INFO  - >>>>>> Epoch  62
2022-11-25 12:42:30,223 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:42:39,313 - INFO  - Training [62][   20/  196]   Loss 0.285834   Top1 90.566406   Top5 98.613281   BatchTime 0.454341   LR 0.000117   
2022-11-25 12:42:47,046 - INFO  - Training [62][   40/  196]   Loss 0.296421   Top1 90.097656   Top5 98.837891   BatchTime 0.420492   LR 0.000114   
2022-11-25 12:42:54,262 - INFO  - Training [62][   60/  196]   Loss 0.295352   Top1 90.110677   Top5 98.932292   BatchTime 0.400600   LR 0.000111   
2022-11-25 12:43:01,407 - INFO  - Training [62][   80/  196]   Loss 0.295104   Top1 90.244141   Top5 99.008789   BatchTime 0.389752   LR 0.000108   
2022-11-25 12:43:08,643 - INFO  - Training [62][  100/  196]   Loss 0.291087   Top1 90.394531   Top5 99.050781   BatchTime 0.384162   LR 0.000105   
2022-11-25 12:43:15,498 - INFO  - Training [62][  120/  196]   Loss 0.284770   Top1 90.673828   Top5 99.098307   BatchTime 0.377260   LR 0.000102   
2022-11-25 12:43:21,762 - INFO  - Training [62][  140/  196]   Loss 0.286078   Top1 90.602679   Top5 99.157366   BatchTime 0.368112   LR 0.000100   
2022-11-25 12:43:28,764 - INFO  - Training [62][  160/  196]   Loss 0.288053   Top1 90.498047   Top5 99.155273   BatchTime 0.365854   LR 0.000097   
2022-11-25 12:43:35,803 - INFO  - Training [62][  180/  196]   Loss 0.289134   Top1 90.431858   Top5 99.138455   BatchTime 0.364310   LR 0.000094   
2022-11-25 12:43:41,718 - INFO  - ==> Top1: 90.442    Top5: 99.108    Loss: 0.288

2022-11-25 12:43:41,997 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:43:43,623 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:43:46,144 - INFO  - Validation [62][   20/   40]   Loss 0.309510   Top1 90.546875   Top5 99.609375   BatchTime 0.125957   
2022-11-25 12:43:47,203 - INFO  - Validation [62][   40/   40]   Loss 0.293375   Top1 90.790000   Top5 99.760000   BatchTime 0.089457   
2022-11-25 12:43:47,519 - INFO  - ==> Top1: 90.790    Top5: 99.760    Loss: 0.293

2022-11-25 12:43:47,519 - INFO  - ==> Sparsity : 0.571

2022-11-25 12:43:47,519 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:43:47,520 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
2022-11-25 12:43:47,520 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 90.950   Top5: 99.690]
2022-11-25 12:43:47,645 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:43:47,647 - INFO  - >>>>>> Epoch  63
2022-11-25 12:43:47,649 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:43:56,874 - INFO  - Training [63][   20/  196]   Loss 0.321829   Top1 88.945312   Top5 98.476562   BatchTime 0.461113   LR 0.000090   
2022-11-25 12:44:04,709 - INFO  - Training [63][   40/  196]   Loss 0.316896   Top1 89.062500   Top5 98.740234   BatchTime 0.426428   LR 0.000087   
2022-11-25 12:44:11,864 - INFO  - Training [63][   60/  196]   Loss 0.316437   Top1 89.205729   Top5 98.789062   BatchTime 0.403541   LR 0.000085   
2022-11-25 12:44:19,311 - INFO  - Training [63][   80/  196]   Loss 0.313652   Top1 89.375000   Top5 98.901367   BatchTime 0.395744   LR 0.000082   
2022-11-25 12:44:26,370 - INFO  - Training [63][  100/  196]   Loss 0.306584   Top1 89.679688   Top5 98.957031   BatchTime 0.387177   LR 0.000080   
2022-11-25 12:44:32,471 - INFO  - Training [63][  120/  196]   Loss 0.299959   Top1 89.918620   Top5 99.049479   BatchTime 0.373492   LR 0.000077   
2022-11-25 12:44:38,766 - INFO  - Training [63][  140/  196]   Loss 0.297102   Top1 90.033482   Top5 99.101562   BatchTime 0.365103   LR 0.000075   
2022-11-25 12:44:46,122 - INFO  - Training [63][  160/  196]   Loss 0.298241   Top1 89.992676   Top5 99.106445   BatchTime 0.365436   LR 0.000072   
2022-11-25 12:44:53,520 - INFO  - Training [63][  180/  196]   Loss 0.299625   Top1 89.865451   Top5 99.079861   BatchTime 0.365932   LR 0.000070   
2022-11-25 12:44:59,483 - INFO  - ==> Top1: 89.908    Top5: 99.080    Loss: 0.299

2022-11-25 12:44:59,827 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:45:01,552 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:45:04,182 - INFO  - Validation [63][   20/   40]   Loss 0.294874   Top1 90.996094   Top5 99.687500   BatchTime 0.131402   
2022-11-25 12:45:05,250 - INFO  - Validation [63][   40/   40]   Loss 0.284052   Top1 91.040000   Top5 99.790000   BatchTime 0.092408   
2022-11-25 12:45:05,527 - INFO  - ==> Top1: 91.040    Top5: 99.790    Loss: 0.284

2022-11-25 12:45:05,527 - INFO  - ==> Sparsity : 0.577

2022-11-25 12:45:05,528 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:45:05,528 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
2022-11-25 12:45:05,528 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 91.040   Top5: 99.790]
2022-11-25 12:45:05,652 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:45:05,654 - INFO  - >>>>>> Epoch  64
2022-11-25 12:45:05,656 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:45:14,755 - INFO  - Training [64][   20/  196]   Loss 0.305485   Top1 89.062500   Top5 98.652344   BatchTime 0.454828   LR 0.000066   
2022-11-25 12:45:22,349 - INFO  - Training [64][   40/  196]   Loss 0.307806   Top1 89.257812   Top5 98.818359   BatchTime 0.417260   LR 0.000064   
2022-11-25 12:45:29,478 - INFO  - Training [64][   60/  196]   Loss 0.305065   Top1 89.609375   Top5 98.834635   BatchTime 0.396988   LR 0.000062   
2022-11-25 12:45:36,442 - INFO  - Training [64][   80/  196]   Loss 0.300882   Top1 89.799805   Top5 98.969727   BatchTime 0.384789   LR 0.000059   
2022-11-25 12:45:43,022 - INFO  - Training [64][  100/  196]   Loss 0.295931   Top1 90.031250   Top5 98.988281   BatchTime 0.373629   LR 0.000057   
2022-11-25 12:45:49,735 - INFO  - Training [64][  120/  196]   Loss 0.292597   Top1 90.185547   Top5 99.059245   BatchTime 0.367299   LR 0.000055   
2022-11-25 12:45:56,922 - INFO  - Training [64][  140/  196]   Loss 0.291510   Top1 90.298549   Top5 99.109933   BatchTime 0.366164   LR 0.000053   
2022-11-25 12:46:04,132 - INFO  - Training [64][  160/  196]   Loss 0.294013   Top1 90.273438   Top5 99.108887   BatchTime 0.365459   LR 0.000051   
2022-11-25 12:46:11,492 - INFO  - Training [64][  180/  196]   Loss 0.294089   Top1 90.264757   Top5 99.088542   BatchTime 0.365737   LR 0.000049   
2022-11-25 12:46:17,253 - INFO  - ==> Top1: 90.296    Top5: 99.068    Loss: 0.293

2022-11-25 12:46:17,512 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:46:19,149 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:46:21,671 - INFO  - Validation [64][   20/   40]   Loss 0.340049   Top1 89.453125   Top5 99.589844   BatchTime 0.125973   
2022-11-25 12:46:22,749 - INFO  - Validation [64][   40/   40]   Loss 0.327733   Top1 89.820000   Top5 99.710000   BatchTime 0.089929   
2022-11-25 12:46:23,018 - INFO  - ==> Top1: 89.820    Top5: 99.710    Loss: 0.328

2022-11-25 12:46:23,019 - INFO  - ==> Sparsity : 0.586

2022-11-25 12:46:23,019 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:46:23,019 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
2022-11-25 12:46:23,019 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 91.040   Top5: 99.790]
2022-11-25 12:46:23,162 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:46:23,164 - INFO  - >>>>>> Epoch  65
2022-11-25 12:46:23,166 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:46:31,906 - INFO  - Training [65][   20/  196]   Loss 0.317738   Top1 89.257812   Top5 98.613281   BatchTime 0.436780   LR 0.000046   
2022-11-25 12:46:39,781 - INFO  - Training [65][   40/  196]   Loss 0.312731   Top1 89.326172   Top5 98.720703   BatchTime 0.415281   LR 0.000044   
2022-11-25 12:46:46,946 - INFO  - Training [65][   60/  196]   Loss 0.312275   Top1 89.283854   Top5 98.834635   BatchTime 0.396257   LR 0.000042   
2022-11-25 12:46:54,475 - INFO  - Training [65][   80/  196]   Loss 0.304291   Top1 89.667969   Top5 99.057617   BatchTime 0.391313   LR 0.000040   
2022-11-25 12:47:01,205 - INFO  - Training [65][  100/  196]   Loss 0.295080   Top1 90.007812   Top5 99.113281   BatchTime 0.380343   LR 0.000039   
2022-11-25 12:47:08,751 - INFO  - Training [65][  120/  196]   Loss 0.289507   Top1 90.266927   Top5 99.169922   BatchTime 0.379841   LR 0.000037   
2022-11-25 12:47:15,982 - INFO  - Training [65][  140/  196]   Loss 0.289075   Top1 90.304129   Top5 99.207589   BatchTime 0.377226   LR 0.000035   
2022-11-25 12:47:22,979 - INFO  - Training [65][  160/  196]   Loss 0.289418   Top1 90.273438   Top5 99.184570   BatchTime 0.373800   LR 0.000033   
2022-11-25 12:47:30,602 - INFO  - Training [65][  180/  196]   Loss 0.288354   Top1 90.308160   Top5 99.127604   BatchTime 0.374618   LR 0.000032   
2022-11-25 12:47:36,486 - INFO  - ==> Top1: 90.316    Top5: 99.128    Loss: 0.287

2022-11-25 12:47:36,763 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:47:38,322 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:47:40,821 - INFO  - Validation [65][   20/   40]   Loss 0.340163   Top1 89.667969   Top5 99.667969   BatchTime 0.124811   
2022-11-25 12:47:41,907 - INFO  - Validation [65][   40/   40]   Loss 0.328158   Top1 89.930000   Top5 99.720000   BatchTime 0.089561   
2022-11-25 12:47:42,149 - INFO  - ==> Top1: 89.930    Top5: 99.720    Loss: 0.328

2022-11-25 12:47:42,150 - INFO  - ==> Sparsity : 0.592

2022-11-25 12:47:42,150 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:47:42,150 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
2022-11-25 12:47:42,151 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 91.040   Top5: 99.790]
2022-11-25 12:47:42,482 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:47:42,484 - INFO  - >>>>>> Epoch  66
2022-11-25 12:47:42,486 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:47:52,149 - INFO  - Training [66][   20/  196]   Loss 0.306862   Top1 89.687500   Top5 98.769531   BatchTime 0.483019   LR 0.000029   
2022-11-25 12:47:59,959 - INFO  - Training [66][   40/  196]   Loss 0.305251   Top1 89.804688   Top5 98.896484   BatchTime 0.436765   LR 0.000028   
2022-11-25 12:48:07,280 - INFO  - Training [66][   60/  196]   Loss 0.307611   Top1 89.713542   Top5 98.938802   BatchTime 0.413202   LR 0.000026   
2022-11-25 12:48:13,414 - INFO  - Training [66][   80/  196]   Loss 0.304260   Top1 89.799805   Top5 99.028320   BatchTime 0.386570   LR 0.000025   
2022-11-25 12:48:20,330 - INFO  - Training [66][  100/  196]   Loss 0.293660   Top1 90.183594   Top5 99.093750   BatchTime 0.378412   LR 0.000023   
2022-11-25 12:48:27,399 - INFO  - Training [66][  120/  196]   Loss 0.289604   Top1 90.445964   Top5 99.127604   BatchTime 0.374252   LR 0.000022   
2022-11-25 12:48:34,441 - INFO  - Training [66][  140/  196]   Loss 0.288947   Top1 90.407366   Top5 99.157366   BatchTime 0.371086   LR 0.000021   
2022-11-25 12:48:41,618 - INFO  - Training [66][  160/  196]   Loss 0.290611   Top1 90.356445   Top5 99.140625   BatchTime 0.369560   LR 0.000019   
2022-11-25 12:48:48,896 - INFO  - Training [66][  180/  196]   Loss 0.289284   Top1 90.401476   Top5 99.136285   BatchTime 0.368928   LR 0.000018   
2022-11-25 12:48:54,930 - INFO  - ==> Top1: 90.450    Top5: 99.128    Loss: 0.287

2022-11-25 12:48:55,292 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:48:57,087 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:48:59,545 - INFO  - Validation [66][   20/   40]   Loss 0.299063   Top1 91.015625   Top5 99.589844   BatchTime 0.122797   
2022-11-25 12:49:00,564 - INFO  - Validation [66][   40/   40]   Loss 0.281293   Top1 91.240000   Top5 99.730000   BatchTime 0.086891   
2022-11-25 12:49:00,806 - INFO  - ==> Top1: 91.240    Top5: 99.730    Loss: 0.281

2022-11-25 12:49:00,806 - INFO  - ==> Sparsity : 0.594

2022-11-25 12:49:00,806 - INFO  - Scoreboard best 1 ==> Epoch [66][Top1: 91.240   Top5: 99.730]
2022-11-25 12:49:00,807 - INFO  - Scoreboard best 2 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:49:00,807 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 91.130   Top5: 99.700]
2022-11-25 12:49:07,242 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 12:49:07,246 - INFO  - >>>>>> Epoch  67
2022-11-25 12:49:07,249 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:49:16,846 - INFO  - Training [67][   20/  196]   Loss 0.302820   Top1 90.097656   Top5 98.554688   BatchTime 0.479701   LR 0.000016   
2022-11-25 12:49:23,005 - INFO  - Training [67][   40/  196]   Loss 0.301325   Top1 89.882812   Top5 98.828125   BatchTime 0.393826   LR 0.000015   
2022-11-25 12:49:29,110 - INFO  - Training [67][   60/  196]   Loss 0.303058   Top1 90.091146   Top5 98.873698   BatchTime 0.364309   LR 0.000014   
2022-11-25 12:49:37,306 - INFO  - Training [67][   80/  196]   Loss 0.301003   Top1 90.136719   Top5 98.974609   BatchTime 0.375673   LR 0.000013   
2022-11-25 12:49:45,129 - INFO  - Training [67][  100/  196]   Loss 0.295092   Top1 90.265625   Top5 99.023438   BatchTime 0.378774   LR 0.000012   
2022-11-25 12:49:52,232 - INFO  - Training [67][  120/  196]   Loss 0.289432   Top1 90.455729   Top5 99.069010   BatchTime 0.374833   LR 0.000011   
2022-11-25 12:49:59,600 - INFO  - Training [67][  140/  196]   Loss 0.285541   Top1 90.546875   Top5 99.157366   BatchTime 0.373913   LR 0.000010   
2022-11-25 12:50:06,813 - INFO  - Training [67][  160/  196]   Loss 0.287375   Top1 90.419922   Top5 99.150391   BatchTime 0.372258   LR 0.000009   
2022-11-25 12:50:13,616 - INFO  - Training [67][  180/  196]   Loss 0.288552   Top1 90.336372   Top5 99.118924   BatchTime 0.368687   LR 0.000008   
2022-11-25 12:50:19,352 - INFO  - ==> Top1: 90.318    Top5: 99.102    Loss: 0.289

2022-11-25 12:50:19,610 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:50:21,135 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:50:25,110 - INFO  - Validation [67][   20/   40]   Loss 0.306936   Top1 91.054688   Top5 99.648438   BatchTime 0.198593   
2022-11-25 12:50:26,430 - INFO  - Validation [67][   40/   40]   Loss 0.287882   Top1 91.330000   Top5 99.750000   BatchTime 0.132311   
2022-11-25 12:50:26,673 - INFO  - ==> Top1: 91.330    Top5: 99.750    Loss: 0.288

2022-11-25 12:50:26,673 - INFO  - ==> Sparsity : 0.596

2022-11-25 12:50:26,673 - INFO  - Scoreboard best 1 ==> Epoch [67][Top1: 91.330   Top5: 99.750]
2022-11-25 12:50:26,673 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 91.240   Top5: 99.730]
2022-11-25 12:50:26,674 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:50:33,075 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_best.pth.tar
save quantized models...
2022-11-25 12:50:33,077 - INFO  - >>>>>> Epoch  68
2022-11-25 12:50:33,079 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:50:41,110 - INFO  - Training [68][   20/  196]   Loss 0.305331   Top1 90.078125   Top5 98.613281   BatchTime 0.401429   LR 0.000007   
2022-11-25 12:50:48,445 - INFO  - Training [68][   40/  196]   Loss 0.310695   Top1 89.726562   Top5 98.789062   BatchTime 0.384081   LR 0.000006   
2022-11-25 12:50:55,960 - INFO  - Training [68][   60/  196]   Loss 0.303450   Top1 89.882812   Top5 98.867188   BatchTime 0.381302   LR 0.000006   
2022-11-25 12:51:03,110 - INFO  - Training [68][   80/  196]   Loss 0.297784   Top1 90.039062   Top5 98.955078   BatchTime 0.375346   LR 0.000005   
2022-11-25 12:51:10,552 - INFO  - Training [68][  100/  196]   Loss 0.291528   Top1 90.281250   Top5 98.996094   BatchTime 0.374696   LR 0.000004   
2022-11-25 12:51:17,549 - INFO  - Training [68][  120/  196]   Loss 0.285249   Top1 90.481771   Top5 99.049479   BatchTime 0.370556   LR 0.000004   
2022-11-25 12:51:24,666 - INFO  - Training [68][  140/  196]   Loss 0.283992   Top1 90.611049   Top5 99.118304   BatchTime 0.368456   LR 0.000003   
2022-11-25 12:51:31,795 - INFO  - Training [68][  160/  196]   Loss 0.288532   Top1 90.458984   Top5 99.116211   BatchTime 0.366955   LR 0.000003   
2022-11-25 12:51:38,939 - INFO  - Training [68][  180/  196]   Loss 0.288555   Top1 90.423177   Top5 99.084201   BatchTime 0.365868   LR 0.000002   
2022-11-25 12:51:44,558 - INFO  - ==> Top1: 90.370    Top5: 99.068    Loss: 0.290

2022-11-25 12:51:44,849 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:51:46,206 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:51:49,092 - INFO  - Validation [68][   20/   40]   Loss 0.316135   Top1 90.312500   Top5 99.667969   BatchTime 0.144182   
2022-11-25 12:51:50,497 - INFO  - Validation [68][   40/   40]   Loss 0.308233   Top1 90.390000   Top5 99.710000   BatchTime 0.107222   
2022-11-25 12:51:51,117 - INFO  - ==> Top1: 90.390    Top5: 99.710    Loss: 0.308

2022-11-25 12:51:51,117 - INFO  - ==> Sparsity : 0.596

2022-11-25 12:51:51,117 - INFO  - Scoreboard best 1 ==> Epoch [67][Top1: 91.330   Top5: 99.750]
2022-11-25 12:51:51,118 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 91.240   Top5: 99.730]
2022-11-25 12:51:51,118 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:51:51,371 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:51:51,374 - INFO  - >>>>>> Epoch  69
2022-11-25 12:51:51,378 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:52:00,587 - INFO  - Training [69][   20/  196]   Loss 0.306898   Top1 89.960938   Top5 98.496094   BatchTime 0.460267   LR 0.000002   
2022-11-25 12:52:08,656 - INFO  - Training [69][   40/  196]   Loss 0.305178   Top1 89.775391   Top5 98.759766   BatchTime 0.431863   LR 0.000001   
2022-11-25 12:52:15,900 - INFO  - Training [69][   60/  196]   Loss 0.304314   Top1 89.804688   Top5 98.867188   BatchTime 0.408648   LR 0.000001   
2022-11-25 12:52:23,004 - INFO  - Training [69][   80/  196]   Loss 0.299852   Top1 90.058594   Top5 98.964844   BatchTime 0.395279   LR 0.000001   
2022-11-25 12:52:30,233 - INFO  - Training [69][  100/  196]   Loss 0.293912   Top1 90.308594   Top5 99.031250   BatchTime 0.388508   LR 0.000000   
2022-11-25 12:52:38,053 - INFO  - Training [69][  120/  196]   Loss 0.290584   Top1 90.419922   Top5 99.101562   BatchTime 0.388924   LR 0.000000   
2022-11-25 12:52:46,316 - INFO  - Training [69][  140/  196]   Loss 0.289488   Top1 90.418527   Top5 99.162946   BatchTime 0.392387   LR 0.000000   
2022-11-25 12:52:54,122 - INFO  - Training [69][  160/  196]   Loss 0.292282   Top1 90.366211   Top5 99.128418   BatchTime 0.392125   LR 0.000000   
2022-11-25 12:53:01,110 - INFO  - Training [69][  180/  196]   Loss 0.293335   Top1 90.266927   Top5 99.095052   BatchTime 0.387379   LR 0.000000   
2022-11-25 12:53:06,447 - INFO  - ==> Top1: 90.292    Top5: 99.092    Loss: 0.293

2022-11-25 12:53:06,651 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:53:09,049 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:53:12,060 - INFO  - Validation [69][   20/   40]   Loss 0.295919   Top1 90.917969   Top5 99.667969   BatchTime 0.150437   
2022-11-25 12:53:13,174 - INFO  - Validation [69][   40/   40]   Loss 0.282769   Top1 91.040000   Top5 99.760000   BatchTime 0.103067   
2022-11-25 12:53:13,419 - INFO  - ==> Top1: 91.040    Top5: 99.760    Loss: 0.283

2022-11-25 12:53:13,419 - INFO  - ==> Sparsity : 0.596

2022-11-25 12:53:13,419 - INFO  - Scoreboard best 1 ==> Epoch [67][Top1: 91.330   Top5: 99.750]
2022-11-25 12:53:13,419 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 91.240   Top5: 99.730]
2022-11-25 12:53:13,420 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.220   Top5: 99.700]
2022-11-25 12:53:13,541 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/_checkpoint.pth.tar

2022-11-25 12:53:13,542 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 12:53:13,543 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:53:16,626 - INFO  - Validation [   20/   40]   Loss 0.295919   Top1 90.917969   Top5 99.667969   BatchTime 0.154070   
2022-11-25 12:53:18,223 - INFO  - Validation [   40/   40]   Loss 0.282769   Top1 91.040000   Top5 99.760000   BatchTime 0.116969   
2022-11-25 12:53:18,396 - INFO  - ==> Top1: 91.040    Top5: 99.760    Loss: 0.283

2022-11-25 12:53:18,396 - INFO  - ==> Sparsity : 0.000

2022-11-25 12:53:18,397 - INFO  - Program completed sucessfully ... exiting ...
2022-11-25 12:53:18,416 - INFO  - >>>>>> Epoch   0
2022-11-25 12:53:18,418 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:53:26,963 - INFO  - Training [0][   20/  196]   Loss 0.516422   Top1 82.500000   Top5 97.910156   BatchTime 0.427111   LR 0.004999   
2022-11-25 12:53:34,472 - INFO  - Training [0][   40/  196]   Loss 0.533692   Top1 81.699219   Top5 98.046875   BatchTime 0.401305   LR 0.004995   
2022-11-25 12:53:41,561 - INFO  - Training [0][   60/  196]   Loss 0.526782   Top1 81.796875   Top5 98.125000   BatchTime 0.385677   LR 0.004989   
2022-11-25 12:53:48,333 - INFO  - Training [0][   80/  196]   Loss 0.525310   Top1 81.889648   Top5 98.134766   BatchTime 0.373907   LR 0.004980   
2022-11-25 12:53:55,054 - INFO  - Training [0][  100/  196]   Loss 0.520647   Top1 81.980469   Top5 98.195312   BatchTime 0.366332   LR 0.004968   
2022-11-25 12:54:01,994 - INFO  - Training [0][  120/  196]   Loss 0.514339   Top1 82.268880   Top5 98.255208   BatchTime 0.363109   LR 0.004954   
2022-11-25 12:54:09,270 - INFO  - Training [0][  140/  196]   Loss 0.514726   Top1 82.260045   Top5 98.278460   BatchTime 0.363211   LR 0.004938   
2022-11-25 12:54:15,896 - INFO  - Training [0][  160/  196]   Loss 0.521801   Top1 82.028809   Top5 98.229980   BatchTime 0.359222   LR 0.004919   
2022-11-25 12:54:21,600 - INFO  - Training [0][  180/  196]   Loss 0.521345   Top1 81.948785   Top5 98.177083   BatchTime 0.350996   LR 0.004897   
2022-11-25 12:54:26,535 - INFO  - ==> Top1: 82.076    Top5: 98.210    Loss: 0.518

2022-11-25 12:54:26,886 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:54:28,800 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:54:31,361 - INFO  - Validation [0][   20/   40]   Loss 0.495652   Top1 84.394531   Top5 98.828125   BatchTime 0.127971   
2022-11-25 12:54:32,413 - INFO  - Validation [0][   40/   40]   Loss 0.491205   Top1 84.110000   Top5 99.030000   BatchTime 0.090284   
2022-11-25 12:54:32,758 - INFO  - ==> Top1: 84.110    Top5: 99.030    Loss: 0.491

2022-11-25 12:54:32,758 - INFO  - ==> Sparsity : 0.670

2022-11-25 12:54:32,759 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 12:54:39,696 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:54:39,703 - INFO  - >>>>>> Epoch   1
2022-11-25 12:54:39,707 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:54:48,171 - INFO  - Training [1][   20/  196]   Loss 0.561665   Top1 80.898438   Top5 97.519531   BatchTime 0.423026   LR 0.004853   
2022-11-25 12:54:55,035 - INFO  - Training [1][   40/  196]   Loss 0.555339   Top1 80.810547   Top5 97.705078   BatchTime 0.383121   LR 0.004825   
2022-11-25 12:55:01,887 - INFO  - Training [1][   60/  196]   Loss 0.538476   Top1 81.282552   Top5 97.981771   BatchTime 0.369611   LR 0.004794   
2022-11-25 12:55:08,616 - INFO  - Training [1][   80/  196]   Loss 0.528715   Top1 81.630859   Top5 98.095703   BatchTime 0.361315   LR 0.004761   
2022-11-25 12:55:15,244 - INFO  - Training [1][  100/  196]   Loss 0.514553   Top1 82.132812   Top5 98.183594   BatchTime 0.355331   LR 0.004725   
2022-11-25 12:55:22,108 - INFO  - Training [1][  120/  196]   Loss 0.502326   Top1 82.539062   Top5 98.271484   BatchTime 0.353307   LR 0.004687   
2022-11-25 12:55:28,750 - INFO  - Training [1][  140/  196]   Loss 0.493925   Top1 82.787388   Top5 98.356585   BatchTime 0.350278   LR 0.004647   
2022-11-25 12:55:34,586 - INFO  - Training [1][  160/  196]   Loss 0.496752   Top1 82.719727   Top5 98.330078   BatchTime 0.342970   LR 0.004605   
2022-11-25 12:55:40,604 - INFO  - Training [1][  180/  196]   Loss 0.499843   Top1 82.556424   Top5 98.224826   BatchTime 0.338292   LR 0.004560   
2022-11-25 12:55:46,061 - INFO  - ==> Top1: 82.576    Top5: 98.204    Loss: 0.499

2022-11-25 12:55:46,488 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:55:48,337 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:55:51,279 - INFO  - Validation [1][   20/   40]   Loss 0.396840   Top1 87.480469   Top5 99.472656   BatchTime 0.146941   
2022-11-25 12:55:53,092 - INFO  - Validation [1][   40/   40]   Loss 0.388780   Top1 87.230000   Top5 99.520000   BatchTime 0.118794   
2022-11-25 12:55:53,705 - INFO  - ==> Top1: 87.230    Top5: 99.520    Loss: 0.389

2022-11-25 12:55:53,705 - INFO  - ==> Sparsity : 0.684

2022-11-25 12:55:53,705 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 12:55:53,706 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 12:55:59,285 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:55:59,287 - INFO  - >>>>>> Epoch   2
2022-11-25 12:55:59,289 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:56:07,850 - INFO  - Training [2][   20/  196]   Loss 0.508608   Top1 81.738281   Top5 97.636719   BatchTime 0.427887   LR 0.004477   
2022-11-25 12:56:14,716 - INFO  - Training [2][   40/  196]   Loss 0.508021   Top1 82.226562   Top5 97.949219   BatchTime 0.385603   LR 0.004426   
2022-11-25 12:56:21,653 - INFO  - Training [2][   60/  196]   Loss 0.539377   Top1 81.067708   Top5 97.356771   BatchTime 0.372688   LR 0.004374   
2022-11-25 12:56:28,443 - INFO  - Training [2][   80/  196]   Loss 0.536415   Top1 81.230469   Top5 97.597656   BatchTime 0.364382   LR 0.004320   
2022-11-25 12:56:35,012 - INFO  - Training [2][  100/  196]   Loss 0.528031   Top1 81.558594   Top5 97.695312   BatchTime 0.357198   LR 0.004264   
2022-11-25 12:56:40,984 - INFO  - Training [2][  120/  196]   Loss 0.802920   Top1 70.777995   Top5 90.677083   BatchTime 0.347431   LR 0.004206   
2022-11-25 12:56:46,927 - INFO  - Training [2][  140/  196]   Loss 1.022893   Top1 62.034040   Top5 84.754464   BatchTime 0.340251   LR 0.004146   
2022-11-25 12:56:53,167 - INFO  - Training [2][  160/  196]   Loss 1.187122   Top1 55.517578   Top5 80.251465   BatchTime 0.336715   LR 0.004085   
2022-11-25 12:56:59,665 - INFO  - Training [2][  180/  196]   Loss 1.313738   Top1 50.390625   Top5 76.759983   BatchTime 0.335406   LR 0.004022   
2022-11-25 12:57:05,276 - INFO  - ==> Top1: 47.214    Top5: 74.666    Loss: 1.393

2022-11-25 12:57:05,524 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:57:06,989 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:57:09,843 - INFO  - Validation [2][   20/   40]   Loss 116.099051   Top1 10.253906   Top5 50.214844   BatchTime 0.142592   
2022-11-25 12:57:11,180 - INFO  - Validation [2][   40/   40]   Loss 116.525622   Top1 10.000000   Top5 50.000000   BatchTime 0.104729   
2022-11-25 12:57:11,756 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 116.526

2022-11-25 12:57:11,757 - INFO  - ==> Sparsity : 0.258

2022-11-25 12:57:11,757 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 12:57:11,757 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 12:57:11,758 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
2022-11-25 12:57:12,188 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:57:12,190 - INFO  - >>>>>> Epoch   3
2022-11-25 12:57:12,193 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:57:20,419 - INFO  - Training [3][   20/  196]   Loss 2.327054   Top1 9.824219   Top5 49.472656   BatchTime 0.411092   LR 0.003907   
2022-11-25 12:57:27,219 - INFO  - Training [3][   40/  196]   Loss 2.323355   Top1 10.039062   Top5 50.097656   BatchTime 0.375546   LR 0.003840   
2022-11-25 12:57:34,051 - INFO  - Training [3][   60/  196]   Loss 2.322061   Top1 9.960938   Top5 50.240885   BatchTime 0.364236   LR 0.003771   
2022-11-25 12:57:41,133 - INFO  - Training [3][   80/  196]   Loss 2.319563   Top1 10.053711   Top5 50.410156   BatchTime 0.361700   LR 0.003701   
2022-11-25 12:57:48,623 - INFO  - Training [3][  100/  196]   Loss 2.318637   Top1 10.000000   Top5 50.347656   BatchTime 0.364258   LR 0.003630   
2022-11-25 12:57:55,948 - INFO  - Training [3][  120/  196]   Loss 2.317855   Top1 9.941406   Top5 50.162760   BatchTime 0.364585   LR 0.003558   
2022-11-25 12:58:01,552 - INFO  - Training [3][  140/  196]   Loss 2.316902   Top1 10.002790   Top5 50.301339   BatchTime 0.352530   LR 0.003484   
2022-11-25 12:58:08,763 - INFO  - Training [3][  160/  196]   Loss 2.316340   Top1 9.924316   Top5 50.251465   BatchTime 0.353537   LR 0.003410   
2022-11-25 12:58:15,475 - INFO  - Training [3][  180/  196]   Loss 2.315677   Top1 9.913194   Top5 50.227865   BatchTime 0.351540   LR 0.003335   
2022-11-25 12:58:20,984 - INFO  - ==> Top1: 9.948    Top5: 50.232    Loss: 2.315

2022-11-25 12:58:21,299 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:58:23,172 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:58:25,941 - INFO  - Validation [3][   20/   40]   Loss 103.742659   Top1 10.253906   Top5 50.214844   BatchTime 0.138360   
2022-11-25 12:58:27,265 - INFO  - Validation [3][   40/   40]   Loss 104.088432   Top1 10.000000   Top5 50.000000   BatchTime 0.102288   
2022-11-25 12:58:27,534 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 104.088

2022-11-25 12:58:27,534 - INFO  - ==> Sparsity : 0.264

2022-11-25 12:58:27,535 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 12:58:27,535 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 12:58:27,535 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
2022-11-25 12:58:27,669 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:58:27,671 - INFO  - >>>>>> Epoch   4
2022-11-25 12:58:27,672 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:58:36,136 - INFO  - Training [4][   20/  196]   Loss 2.306656   Top1 9.863281   Top5 50.742188   BatchTime 0.423040   LR 0.003200   
2022-11-25 12:58:42,838 - INFO  - Training [4][   40/  196]   Loss 2.307224   Top1 9.960938   Top5 50.458984   BatchTime 0.379058   LR 0.003122   
2022-11-25 12:58:49,831 - INFO  - Training [4][   60/  196]   Loss 2.307761   Top1 10.000000   Top5 49.928385   BatchTime 0.369258   LR 0.003044   
2022-11-25 12:58:56,556 - INFO  - Training [4][   80/  196]   Loss 2.307957   Top1 9.863281   Top5 49.824219   BatchTime 0.361012   LR 0.002965   
2022-11-25 12:59:03,409 - INFO  - Training [4][  100/  196]   Loss 2.307858   Top1 9.890625   Top5 49.859375   BatchTime 0.357334   LR 0.002886   
2022-11-25 12:59:09,249 - INFO  - Training [4][  120/  196]   Loss 2.307439   Top1 9.892578   Top5 50.071615   BatchTime 0.346444   LR 0.002806   
2022-11-25 12:59:15,480 - INFO  - Training [4][  140/  196]   Loss 2.307251   Top1 9.857701   Top5 50.097656   BatchTime 0.341456   LR 0.002726   
2022-11-25 12:59:22,648 - INFO  - Training [4][  160/  196]   Loss 2.307415   Top1 9.929199   Top5 50.146484   BatchTime 0.343575   LR 0.002646   
2022-11-25 12:59:29,527 - INFO  - Training [4][  180/  196]   Loss 2.307233   Top1 9.945747   Top5 50.225694   BatchTime 0.343619   LR 0.002566   
2022-11-25 12:59:34,963 - INFO  - ==> Top1: 9.992    Top5: 50.216    Loss: 2.307

2022-11-25 12:59:35,288 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:59:36,906 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:59:39,656 - INFO  - Validation [4][   20/   40]   Loss 89.339193   Top1 10.253906   Top5 50.214844   BatchTime 0.137353   
2022-11-25 12:59:40,767 - INFO  - Validation [4][   40/   40]   Loss 89.656615   Top1 10.000000   Top5 50.000000   BatchTime 0.096452   
2022-11-25 12:59:41,035 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 89.657

2022-11-25 12:59:41,035 - INFO  - ==> Sparsity : 0.265

2022-11-25 12:59:41,035 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 12:59:41,035 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 12:59:41,035 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
2022-11-25 12:59:41,414 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:59:41,416 - INFO  - >>>>>> Epoch   5
2022-11-25 12:59:41,417 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:59:49,880 - INFO  - Training [5][   20/  196]   Loss 2.304920   Top1 10.214844   Top5 50.273438   BatchTime 0.423000   LR 0.002424   
2022-11-25 12:59:57,239 - INFO  - Training [5][   40/  196]   Loss 2.305294   Top1 9.853516   Top5 49.736328   BatchTime 0.395474   LR 0.002343   
2022-11-25 13:00:04,126 - INFO  - Training [5][   60/  196]   Loss 2.305535   Top1 9.863281   Top5 49.661458   BatchTime 0.378444   LR 0.002263   
2022-11-25 13:00:10,927 - INFO  - Training [5][   80/  196]   Loss 2.305024   Top1 9.965820   Top5 49.877930   BatchTime 0.368834   LR 0.002183   
2022-11-25 13:00:17,554 - INFO  - Training [5][  100/  196]   Loss 2.304900   Top1 9.906250   Top5 49.906250   BatchTime 0.361337   LR 0.002104   
2022-11-25 13:00:22,998 - INFO  - Training [5][  120/  196]   Loss 2.304944   Top1 9.977214   Top5 49.879557   BatchTime 0.346482   LR 0.002024   
2022-11-25 13:00:29,092 - INFO  - Training [5][  140/  196]   Loss 2.304929   Top1 9.952567   Top5 49.882812   BatchTime 0.340511   LR 0.001946   
2022-11-25 13:00:36,139 - INFO  - Training [5][  160/  196]   Loss 2.304884   Top1 9.941406   Top5 49.934082   BatchTime 0.341992   LR 0.001868   
2022-11-25 13:00:42,865 - INFO  - Training [5][  180/  196]   Loss 2.304912   Top1 9.878472   Top5 49.848090   BatchTime 0.341361   LR 0.001790   
2022-11-25 13:00:48,428 - INFO  - ==> Top1: 9.942    Top5: 49.992    Loss: 2.305

2022-11-25 13:00:48,697 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:00:50,134 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:00:52,664 - INFO  - Validation [5][   20/   40]   Loss 91.364597   Top1 10.253906   Top5 50.214844   BatchTime 0.126418   
2022-11-25 13:00:53,755 - INFO  - Validation [5][   40/   40]   Loss 91.681230   Top1 10.000000   Top5 50.000000   BatchTime 0.090501   
2022-11-25 13:00:53,993 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 91.681

2022-11-25 13:00:53,993 - INFO  - ==> Sparsity : 0.265

2022-11-25 13:00:53,993 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:00:53,994 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:00:53,994 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
2022-11-25 13:00:54,122 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:00:54,123 - INFO  - >>>>>> Epoch   6
2022-11-25 13:00:54,125 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:01:02,637 - INFO  - Training [6][   20/  196]   Loss 2.303533   Top1 10.703125   Top5 50.937500   BatchTime 0.425471   LR 0.001655   
2022-11-25 13:01:09,416 - INFO  - Training [6][   40/  196]   Loss 2.304858   Top1 10.234375   Top5 50.048828   BatchTime 0.382199   LR 0.001580   
2022-11-25 13:01:16,643 - INFO  - Training [6][   60/  196]   Loss 2.304987   Top1 10.175781   Top5 49.850260   BatchTime 0.375258   LR 0.001506   
2022-11-25 13:01:23,421 - INFO  - Training [6][   80/  196]   Loss 2.304773   Top1 10.112305   Top5 49.829102   BatchTime 0.366165   LR 0.001432   
2022-11-25 13:01:30,044 - INFO  - Training [6][  100/  196]   Loss 2.304760   Top1 10.089844   Top5 49.750000   BatchTime 0.359158   LR 0.001360   
2022-11-25 13:01:36,116 - INFO  - Training [6][  120/  196]   Loss 2.304729   Top1 10.019531   Top5 49.778646   BatchTime 0.349898   LR 0.001289   
2022-11-25 13:01:42,433 - INFO  - Training [6][  140/  196]   Loss 2.304695   Top1 9.972098   Top5 49.715402   BatchTime 0.345033   LR 0.001220   
2022-11-25 13:01:49,249 - INFO  - Training [6][  160/  196]   Loss 2.304645   Top1 9.926758   Top5 49.638672   BatchTime 0.344501   LR 0.001151   
2022-11-25 13:01:56,006 - INFO  - Training [6][  180/  196]   Loss 2.304575   Top1 9.893663   Top5 49.713542   BatchTime 0.343764   LR 0.001084   
2022-11-25 13:02:01,877 - INFO  - ==> Top1: 9.900    Top5: 49.646    Loss: 2.305

2022-11-25 13:02:02,133 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:02:03,768 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:02:06,283 - INFO  - Validation [6][   20/   40]   Loss 91.440081   Top1 10.253906   Top5 50.214844   BatchTime 0.125665   
2022-11-25 13:02:07,302 - INFO  - Validation [6][   40/   40]   Loss 91.761538   Top1 10.000000   Top5 50.000000   BatchTime 0.088305   
2022-11-25 13:02:07,559 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 91.762

2022-11-25 13:02:07,559 - INFO  - ==> Sparsity : 0.266

2022-11-25 13:02:07,560 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:02:07,560 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:02:07,560 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
2022-11-25 13:02:07,710 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:02:07,711 - INFO  - >>>>>> Epoch   7
2022-11-25 13:02:07,713 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:02:16,504 - INFO  - Training [7][   20/  196]   Loss 2.303742   Top1 10.273438   Top5 49.511719   BatchTime 0.439373   LR 0.000969   
2022-11-25 13:02:23,328 - INFO  - Training [7][   40/  196]   Loss 2.303727   Top1 10.253906   Top5 49.375000   BatchTime 0.390303   LR 0.000907   
2022-11-25 13:02:30,551 - INFO  - Training [7][   60/  196]   Loss 2.303915   Top1 10.182292   Top5 49.375000   BatchTime 0.380577   LR 0.000845   
2022-11-25 13:02:37,612 - INFO  - Training [7][   80/  196]   Loss 2.303755   Top1 10.166016   Top5 49.345703   BatchTime 0.373696   LR 0.000786   
2022-11-25 13:02:44,379 - INFO  - Training [7][  100/  196]   Loss 2.303706   Top1 10.164062   Top5 49.449219   BatchTime 0.366629   LR 0.000728   
2022-11-25 13:02:49,624 - INFO  - Training [7][  120/  196]   Loss 2.303584   Top1 10.133464   Top5 49.589844   BatchTime 0.349231   LR 0.000673   
2022-11-25 13:02:56,304 - INFO  - Training [7][  140/  196]   Loss 2.303664   Top1 10.041853   Top5 49.592634   BatchTime 0.347055   LR 0.000619   
2022-11-25 13:03:03,451 - INFO  - Training [7][  160/  196]   Loss 2.303610   Top1 10.046387   Top5 49.770508   BatchTime 0.348341   LR 0.000567   
2022-11-25 13:03:10,162 - INFO  - Training [7][  180/  196]   Loss 2.303574   Top1 10.065104   Top5 49.733073   BatchTime 0.346919   LR 0.000517   
2022-11-25 13:03:15,558 - INFO  - ==> Top1: 10.116    Top5: 49.882    Loss: 2.303

2022-11-25 13:03:15,879 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:03:17,347 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:03:19,885 - INFO  - Validation [7][   20/   40]   Loss 89.458520   Top1 10.253906   Top5 50.214844   BatchTime 0.126813   
2022-11-25 13:03:20,952 - INFO  - Validation [7][   40/   40]   Loss 89.772284   Top1 10.000000   Top5 50.000000   BatchTime 0.090068   
2022-11-25 13:03:21,206 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 89.772

2022-11-25 13:03:21,206 - INFO  - ==> Sparsity : 0.266

2022-11-25 13:03:21,206 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:03:21,206 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:03:21,207 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
2022-11-25 13:03:21,349 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:03:21,351 - INFO  - >>>>>> Epoch   8
2022-11-25 13:03:21,353 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:03:29,778 - INFO  - Training [8][   20/  196]   Loss 2.303927   Top1 9.746094   Top5 50.234375   BatchTime 0.421162   LR 0.000434   
2022-11-25 13:03:36,581 - INFO  - Training [8][   40/  196]   Loss 2.303904   Top1 9.609375   Top5 49.531250   BatchTime 0.380647   LR 0.000389   
2022-11-25 13:03:43,274 - INFO  - Training [8][   60/  196]   Loss 2.303463   Top1 9.648438   Top5 50.136719   BatchTime 0.365320   LR 0.000347   
2022-11-25 13:03:50,670 - INFO  - Training [8][   80/  196]   Loss 2.303351   Top1 9.707031   Top5 50.209961   BatchTime 0.366436   LR 0.000308   
2022-11-25 13:03:57,456 - INFO  - Training [8][  100/  196]   Loss 2.303443   Top1 9.761719   Top5 50.050781   BatchTime 0.361012   LR 0.000270   
2022-11-25 13:04:02,720 - INFO  - Training [8][  120/  196]   Loss 2.303389   Top1 9.772135   Top5 50.078125   BatchTime 0.344706   LR 0.000235   
2022-11-25 13:04:08,967 - INFO  - Training [8][  140/  196]   Loss 2.303464   Top1 9.679129   Top5 49.949777   BatchTime 0.340081   LR 0.000202   
2022-11-25 13:04:16,233 - INFO  - Training [8][  160/  196]   Loss 2.303483   Top1 9.719238   Top5 49.748535   BatchTime 0.342982   LR 0.000172   
2022-11-25 13:04:23,405 - INFO  - Training [8][  180/  196]   Loss 2.303461   Top1 9.754774   Top5 49.776476   BatchTime 0.344720   LR 0.000143   
2022-11-25 13:04:28,925 - INFO  - ==> Top1: 9.762    Top5: 49.792    Loss: 2.303

2022-11-25 13:04:29,151 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:04:31,411 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:04:34,041 - INFO  - Validation [8][   20/   40]   Loss 89.791621   Top1 10.253906   Top5 50.214844   BatchTime 0.131417   
2022-11-25 13:04:35,095 - INFO  - Validation [8][   40/   40]   Loss 90.104291   Top1 10.000000   Top5 50.000000   BatchTime 0.092059   
2022-11-25 13:04:35,360 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 90.104

2022-11-25 13:04:35,361 - INFO  - ==> Sparsity : 0.266

2022-11-25 13:04:35,361 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:04:35,361 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:04:35,361 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
2022-11-25 13:04:35,525 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:04:35,527 - INFO  - >>>>>> Epoch   9
2022-11-25 13:04:35,528 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:04:43,977 - INFO  - Training [9][   20/  196]   Loss 2.303374   Top1 9.394531   Top5 49.960938   BatchTime 0.422268   LR 0.000100   
2022-11-25 13:04:50,758 - INFO  - Training [9][   40/  196]   Loss 2.303266   Top1 9.833984   Top5 50.029297   BatchTime 0.380677   LR 0.000079   
2022-11-25 13:04:57,459 - INFO  - Training [9][   60/  196]   Loss 2.303219   Top1 10.039062   Top5 49.837240   BatchTime 0.365456   LR 0.000060   
2022-11-25 13:05:04,180 - INFO  - Training [9][   80/  196]   Loss 2.303228   Top1 10.048828   Top5 49.697266   BatchTime 0.358104   LR 0.000044   
2022-11-25 13:05:11,234 - INFO  - Training [9][  100/  196]   Loss 2.303224   Top1 10.019531   Top5 49.847656   BatchTime 0.357023   LR 0.000030   
2022-11-25 13:05:17,254 - INFO  - Training [9][  120/  196]   Loss 2.303219   Top1 10.068359   Top5 49.749349   BatchTime 0.347684   LR 0.000019   
2022-11-25 13:05:23,644 - INFO  - Training [9][  140/  196]   Loss 2.303089   Top1 10.094866   Top5 49.924665   BatchTime 0.343662   LR 0.000010   
2022-11-25 13:05:30,812 - INFO  - Training [9][  160/  196]   Loss 2.303029   Top1 10.078125   Top5 50.029297   BatchTime 0.345503   LR 0.000004   
2022-11-25 13:05:37,440 - INFO  - Training [9][  180/  196]   Loss 2.302966   Top1 10.119358   Top5 50.169271   BatchTime 0.343934   LR 0.000001   
2022-11-25 13:05:42,940 - INFO  - ==> Top1: 10.142    Top5: 50.152    Loss: 2.303

2022-11-25 13:05:43,234 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:05:45,035 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:05:47,718 - INFO  - Validation [9][   20/   40]   Loss 89.515043   Top1 10.253906   Top5 50.214844   BatchTime 0.134059   
2022-11-25 13:05:48,833 - INFO  - Validation [9][   40/   40]   Loss 89.829018   Top1 10.000000   Top5 50.000000   BatchTime 0.094902   
2022-11-25 13:05:49,081 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 89.829

2022-11-25 13:05:49,081 - INFO  - ==> Sparsity : 0.266

2022-11-25 13:05:49,082 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:05:49,082 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:05:49,082 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
2022-11-25 13:05:49,220 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:05:49,221 - INFO  - >>>>>> Epoch  10
2022-11-25 13:05:49,223 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:05:57,078 - INFO  - Training [10][   20/  196]   Loss 2.303830   Top1 9.746094   Top5 50.195312   BatchTime 0.392584   LR 0.002500   
2022-11-25 13:06:03,782 - INFO  - Training [10][   40/  196]   Loss 2.303867   Top1 9.990234   Top5 50.078125   BatchTime 0.363894   LR 0.002499   
2022-11-25 13:06:10,446 - INFO  - Training [10][   60/  196]   Loss 2.304228   Top1 10.097656   Top5 49.882812   BatchTime 0.353669   LR 0.002499   
2022-11-25 13:06:17,129 - INFO  - Training [10][   80/  196]   Loss 2.304718   Top1 9.848633   Top5 49.497070   BatchTime 0.348783   LR 0.002497   
2022-11-25 13:06:24,217 - INFO  - Training [10][  100/  196]   Loss 2.304897   Top1 9.742188   Top5 49.218750   BatchTime 0.349907   LR 0.002496   
2022-11-25 13:06:29,748 - INFO  - Training [10][  120/  196]   Loss 2.304772   Top1 9.690755   Top5 49.417318   BatchTime 0.337680   LR 0.002494   
2022-11-25 13:06:36,223 - INFO  - Training [10][  140/  196]   Loss 2.304747   Top1 9.673549   Top5 49.472656   BatchTime 0.335689   LR 0.002492   
2022-11-25 13:06:43,173 - INFO  - Training [10][  160/  196]   Loss 2.304561   Top1 9.699707   Top5 49.560547   BatchTime 0.337164   LR 0.002490   
2022-11-25 13:06:50,285 - INFO  - Training [10][  180/  196]   Loss 2.304543   Top1 9.715712   Top5 49.605035   BatchTime 0.339212   LR 0.002487   
2022-11-25 13:06:55,790 - INFO  - ==> Top1: 9.746    Top5: 49.574    Loss: 2.304

2022-11-25 13:06:56,059 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:06:57,927 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:07:00,633 - INFO  - Validation [10][   20/   40]   Loss 87.283808   Top1 10.253906   Top5 50.214844   BatchTime 0.135226   
2022-11-25 13:07:01,826 - INFO  - Validation [10][   40/   40]   Loss 87.587315   Top1 10.000000   Top5 50.000000   BatchTime 0.097444   
2022-11-25 13:07:02,096 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 87.587

2022-11-25 13:07:02,096 - INFO  - ==> Sparsity : 0.266

2022-11-25 13:07:02,096 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:07:02,097 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:07:02,097 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
2022-11-25 13:07:02,241 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:07:02,243 - INFO  - >>>>>> Epoch  11
2022-11-25 13:07:02,245 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:07:10,767 - INFO  - Training [11][   20/  196]   Loss 2.304356   Top1 9.199219   Top5 49.511719   BatchTime 0.425964   LR 0.002481   
2022-11-25 13:07:17,668 - INFO  - Training [11][   40/  196]   Loss 2.304007   Top1 9.677734   Top5 49.365234   BatchTime 0.385490   LR 0.002478   
2022-11-25 13:07:24,596 - INFO  - Training [11][   60/  196]   Loss 2.303780   Top1 10.032552   Top5 49.921875   BatchTime 0.372457   LR 0.002474   
2022-11-25 13:07:31,362 - INFO  - Training [11][   80/  196]   Loss 2.303997   Top1 9.907227   Top5 49.809570   BatchTime 0.363920   LR 0.002470   
2022-11-25 13:07:38,516 - INFO  - Training [11][  100/  196]   Loss 2.303882   Top1 10.050781   Top5 50.007812   BatchTime 0.362678   LR 0.002465   
2022-11-25 13:07:43,951 - INFO  - Training [11][  120/  196]   Loss 2.303825   Top1 10.071615   Top5 50.097656   BatchTime 0.347522   LR 0.002460   
2022-11-25 13:07:49,128 - INFO  - Training [11][  140/  196]   Loss 2.304020   Top1 9.991629   Top5 49.974888   BatchTime 0.334854   LR 0.002455   
2022-11-25 13:07:54,800 - INFO  - Training [11][  160/  196]   Loss 2.304024   Top1 10.073242   Top5 49.958496   BatchTime 0.328446   LR 0.002450   
2022-11-25 13:08:01,858 - INFO  - Training [11][  180/  196]   Loss 2.304100   Top1 10.026042   Top5 49.802517   BatchTime 0.331162   LR 0.002444   
2022-11-25 13:08:07,490 - INFO  - ==> Top1: 10.084    Top5: 49.800    Loss: 2.304

2022-11-25 13:08:07,775 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:08:09,541 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:08:12,228 - INFO  - Validation [11][   20/   40]   Loss 81.235638   Top1 10.253906   Top5 50.214844   BatchTime 0.134263   
2022-11-25 13:08:13,421 - INFO  - Validation [11][   40/   40]   Loss 81.513869   Top1 10.000000   Top5 50.000000   BatchTime 0.096981   
2022-11-25 13:08:13,693 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 81.514

2022-11-25 13:08:13,693 - INFO  - ==> Sparsity : 0.267

2022-11-25 13:08:13,693 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:08:13,693 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:08:13,694 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
2022-11-25 13:08:13,816 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:08:13,818 - INFO  - >>>>>> Epoch  12
2022-11-25 13:08:13,821 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:08:22,424 - INFO  - Training [12][   20/  196]   Loss 2.303231   Top1 9.804688   Top5 50.781250   BatchTime 0.430003   LR 0.002433   
2022-11-25 13:08:29,062 - INFO  - Training [12][   40/  196]   Loss 2.303552   Top1 9.785156   Top5 50.351562   BatchTime 0.380962   LR 0.002426   
2022-11-25 13:08:35,839 - INFO  - Training [12][   60/  196]   Loss 2.304031   Top1 9.843750   Top5 49.824219   BatchTime 0.366924   LR 0.002419   
2022-11-25 13:08:42,514 - INFO  - Training [12][   80/  196]   Loss 2.303885   Top1 9.848633   Top5 49.687500   BatchTime 0.358625   LR 0.002412   
2022-11-25 13:08:49,355 - INFO  - Training [12][  100/  196]   Loss 2.303787   Top1 9.820312   Top5 49.601562   BatchTime 0.355311   LR 0.002404   
2022-11-25 13:08:56,406 - INFO  - Training [12][  120/  196]   Loss 2.303836   Top1 9.781901   Top5 49.580078   BatchTime 0.354847   LR 0.002396   
2022-11-25 13:09:02,275 - INFO  - Training [12][  140/  196]   Loss 2.303793   Top1 9.924665   Top5 49.500558   BatchTime 0.346078   LR 0.002388   
2022-11-25 13:09:07,762 - INFO  - Training [12][  160/  196]   Loss 2.303793   Top1 9.863281   Top5 49.562988   BatchTime 0.337110   LR 0.002380   
2022-11-25 13:09:14,664 - INFO  - Training [12][  180/  196]   Loss 2.303809   Top1 9.878472   Top5 49.587674   BatchTime 0.337999   LR 0.002371   
2022-11-25 13:09:20,372 - INFO  - ==> Top1: 9.850    Top5: 49.552    Loss: 2.304

2022-11-25 13:09:20,696 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:09:22,299 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:09:24,969 - INFO  - Validation [12][   20/   40]   Loss 78.924787   Top1 10.253906   Top5 50.214844   BatchTime 0.133428   
2022-11-25 13:09:26,043 - INFO  - Validation [12][   40/   40]   Loss 79.192577   Top1 10.000000   Top5 50.000000   BatchTime 0.093559   
2022-11-25 13:09:26,273 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 79.193

2022-11-25 13:09:26,274 - INFO  - ==> Sparsity : 0.267

2022-11-25 13:09:26,274 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:09:26,274 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:09:26,274 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
2022-11-25 13:09:26,394 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:09:26,396 - INFO  - >>>>>> Epoch  13
2022-11-25 13:09:26,397 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:09:34,753 - INFO  - Training [13][   20/  196]   Loss 2.303229   Top1 10.078125   Top5 50.019531   BatchTime 0.417671   LR 0.002355   
2022-11-25 13:09:42,166 - INFO  - Training [13][   40/  196]   Loss 2.303204   Top1 10.253906   Top5 50.234375   BatchTime 0.394157   LR 0.002345   
2022-11-25 13:09:49,842 - INFO  - Training [13][   60/  196]   Loss 2.303539   Top1 10.182292   Top5 50.169271   BatchTime 0.390707   LR 0.002336   
2022-11-25 13:09:56,904 - INFO  - Training [13][   80/  196]   Loss 2.303741   Top1 10.000000   Top5 49.975586   BatchTime 0.381306   LR 0.002325   
2022-11-25 13:10:03,763 - INFO  - Training [13][  100/  196]   Loss 2.303761   Top1 10.015625   Top5 49.859375   BatchTime 0.373627   LR 0.002315   
2022-11-25 13:10:10,629 - INFO  - Training [13][  120/  196]   Loss 2.303739   Top1 10.055339   Top5 49.609375   BatchTime 0.368575   LR 0.002304   
2022-11-25 13:10:16,643 - INFO  - Training [13][  140/  196]   Loss 2.303741   Top1 9.994420   Top5 49.695871   BatchTime 0.358879   LR 0.002293   
2022-11-25 13:10:22,570 - INFO  - Training [13][  160/  196]   Loss 2.303582   Top1 10.073242   Top5 49.873047   BatchTime 0.351061   LR 0.002282   
2022-11-25 13:10:29,533 - INFO  - Training [13][  180/  196]   Loss 2.303713   Top1 10.028212   Top5 49.798177   BatchTime 0.350735   LR 0.002271   
2022-11-25 13:10:35,277 - INFO  - ==> Top1: 10.016    Top5: 49.776    Loss: 2.304

2022-11-25 13:10:35,557 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:10:37,055 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:10:39,736 - INFO  - Validation [13][   20/   40]   Loss 73.909235   Top1 10.253906   Top5 50.214844   BatchTime 0.133951   
2022-11-25 13:10:40,869 - INFO  - Validation [13][   40/   40]   Loss 74.152412   Top1 10.000000   Top5 50.000000   BatchTime 0.095298   
2022-11-25 13:10:41,156 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 74.152

2022-11-25 13:10:41,156 - INFO  - ==> Sparsity : 0.268

2022-11-25 13:10:41,156 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:10:41,157 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:10:41,157 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
2022-11-25 13:10:41,321 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:10:41,322 - INFO  - >>>>>> Epoch  14
2022-11-25 13:10:41,324 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:10:49,870 - INFO  - Training [14][   20/  196]   Loss 2.303434   Top1 9.707031   Top5 50.722656   BatchTime 0.427128   LR 0.002250   
2022-11-25 13:10:56,448 - INFO  - Training [14][   40/  196]   Loss 2.303515   Top1 9.892578   Top5 50.585938   BatchTime 0.378018   LR 0.002238   
2022-11-25 13:11:03,392 - INFO  - Training [14][   60/  196]   Loss 2.303635   Top1 9.941406   Top5 50.345052   BatchTime 0.367740   LR 0.002225   
2022-11-25 13:11:10,897 - INFO  - Training [14][   80/  196]   Loss 2.303527   Top1 9.980469   Top5 50.166016   BatchTime 0.369628   LR 0.002213   
2022-11-25 13:11:17,840 - INFO  - Training [14][  100/  196]   Loss 2.303318   Top1 10.074219   Top5 50.351562   BatchTime 0.365126   LR 0.002200   
2022-11-25 13:11:24,211 - INFO  - Training [14][  120/  196]   Loss 2.303252   Top1 10.091146   Top5 50.345052   BatchTime 0.357366   LR 0.002186   
2022-11-25 13:11:29,516 - INFO  - Training [14][  140/  196]   Loss 2.303379   Top1 9.974888   Top5 50.147879   BatchTime 0.344203   LR 0.002173   
2022-11-25 13:11:35,666 - INFO  - Training [14][  160/  196]   Loss 2.303443   Top1 9.960938   Top5 50.144043   BatchTime 0.339614   LR 0.002159   
2022-11-25 13:11:42,305 - INFO  - Training [14][  180/  196]   Loss 2.303531   Top1 9.984809   Top5 50.039062   BatchTime 0.338764   LR 0.002145   
2022-11-25 13:11:48,635 - INFO  - ==> Top1: 9.990    Top5: 50.040    Loss: 2.304

2022-11-25 13:11:48,901 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:11:50,381 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:11:53,093 - INFO  - Validation [14][   20/   40]   Loss 72.002252   Top1 10.253906   Top5 50.214844   BatchTime 0.135511   
2022-11-25 13:11:54,237 - INFO  - Validation [14][   40/   40]   Loss 72.244024   Top1 10.000000   Top5 50.000000   BatchTime 0.096355   
2022-11-25 13:11:54,511 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 72.244

2022-11-25 13:11:54,512 - INFO  - ==> Sparsity : 0.268

2022-11-25 13:11:54,512 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:11:54,512 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:11:54,512 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
2022-11-25 13:11:54,666 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:11:54,668 - INFO  - >>>>>> Epoch  15
2022-11-25 13:11:54,670 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:12:03,261 - INFO  - Training [15][   20/  196]   Loss 2.302939   Top1 9.882812   Top5 50.742188   BatchTime 0.429409   LR 0.002120   
2022-11-25 13:12:09,847 - INFO  - Training [15][   40/  196]   Loss 2.302961   Top1 10.078125   Top5 50.527344   BatchTime 0.379363   LR 0.002106   
2022-11-25 13:12:16,743 - INFO  - Training [15][   60/  196]   Loss 2.303472   Top1 9.824219   Top5 49.746094   BatchTime 0.367850   LR 0.002091   
2022-11-25 13:12:24,049 - INFO  - Training [15][   80/  196]   Loss 2.303436   Top1 9.824219   Top5 49.770508   BatchTime 0.367211   LR 0.002076   
2022-11-25 13:12:31,012 - INFO  - Training [15][  100/  196]   Loss 2.303518   Top1 9.820312   Top5 49.582031   BatchTime 0.363392   LR 0.002061   
2022-11-25 13:12:37,485 - INFO  - Training [15][  120/  196]   Loss 2.303424   Top1 9.951172   Top5 49.625651   BatchTime 0.356773   LR 0.002045   
2022-11-25 13:12:43,172 - INFO  - Training [15][  140/  196]   Loss 2.303421   Top1 9.958147   Top5 49.520089   BatchTime 0.346425   LR 0.002030   
2022-11-25 13:12:49,353 - INFO  - Training [15][  160/  196]   Loss 2.303384   Top1 9.978027   Top5 49.572754   BatchTime 0.341752   LR 0.002014   
2022-11-25 13:12:56,095 - INFO  - Training [15][  180/  196]   Loss 2.303314   Top1 10.030382   Top5 49.639757   BatchTime 0.341228   LR 0.001998   
2022-11-25 13:13:02,388 - INFO  - ==> Top1: 10.008    Top5: 49.566    Loss: 2.303

2022-11-25 13:13:02,674 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:13:04,353 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:13:06,955 - INFO  - Validation [15][   20/   40]   Loss 69.047340   Top1 10.253906   Top5 50.214844   BatchTime 0.130012   
2022-11-25 13:13:08,029 - INFO  - Validation [15][   40/   40]   Loss 69.280744   Top1 10.000000   Top5 50.000000   BatchTime 0.091847   
2022-11-25 13:13:08,290 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 69.281

2022-11-25 13:13:08,290 - INFO  - ==> Sparsity : 0.268

2022-11-25 13:13:08,290 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:13:08,290 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:13:08,290 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
2022-11-25 13:13:08,410 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:13:08,412 - INFO  - >>>>>> Epoch  16
2022-11-25 13:13:08,414 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:13:16,964 - INFO  - Training [16][   20/  196]   Loss 2.303654   Top1 9.980469   Top5 50.019531   BatchTime 0.427409   LR 0.001969   
2022-11-25 13:13:23,553 - INFO  - Training [16][   40/  196]   Loss 2.303312   Top1 10.039062   Top5 50.351562   BatchTime 0.378418   LR 0.001953   
2022-11-25 13:13:30,338 - INFO  - Training [16][   60/  196]   Loss 2.303755   Top1 9.811198   Top5 50.221354   BatchTime 0.365362   LR 0.001936   
2022-11-25 13:13:37,233 - INFO  - Training [16][   80/  196]   Loss 2.303661   Top1 9.609375   Top5 50.234375   BatchTime 0.360213   LR 0.001919   
2022-11-25 13:13:44,241 - INFO  - Training [16][  100/  196]   Loss 2.303558   Top1 9.648438   Top5 50.246094   BatchTime 0.358248   LR 0.001902   
2022-11-25 13:13:51,270 - INFO  - Training [16][  120/  196]   Loss 2.303668   Top1 9.658203   Top5 49.951172   BatchTime 0.357115   LR 0.001885   
2022-11-25 13:13:57,007 - INFO  - Training [16][  140/  196]   Loss 2.303622   Top1 9.715402   Top5 49.785156   BatchTime 0.347075   LR 0.001867   
2022-11-25 13:14:03,257 - INFO  - Training [16][  160/  196]   Loss 2.303567   Top1 9.702148   Top5 49.755859   BatchTime 0.342753   LR 0.001850   
2022-11-25 13:14:10,284 - INFO  - Training [16][  180/  196]   Loss 2.303513   Top1 9.667969   Top5 49.798177   BatchTime 0.343706   LR 0.001832   
2022-11-25 13:14:16,258 - INFO  - ==> Top1: 9.636    Top5: 49.824    Loss: 2.303

2022-11-25 13:14:16,519 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:14:18,167 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:14:20,934 - INFO  - Validation [16][   20/   40]   Loss 70.096271   Top1 10.253906   Top5 50.214844   BatchTime 0.138271   
2022-11-25 13:14:22,052 - INFO  - Validation [16][   40/   40]   Loss 70.330852   Top1 10.000000   Top5 50.000000   BatchTime 0.097075   
2022-11-25 13:14:22,306 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 70.331

2022-11-25 13:14:22,306 - INFO  - ==> Sparsity : 0.268

2022-11-25 13:14:22,307 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:14:22,307 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:14:22,307 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
2022-11-25 13:14:22,447 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:14:22,449 - INFO  - >>>>>> Epoch  17
2022-11-25 13:14:22,451 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:14:31,431 - INFO  - Training [17][   20/  196]   Loss 2.303421   Top1 9.843750   Top5 50.234375   BatchTime 0.448866   LR 0.001800   
2022-11-25 13:14:38,248 - INFO  - Training [17][   40/  196]   Loss 2.303755   Top1 9.941406   Top5 50.078125   BatchTime 0.394872   LR 0.001782   
2022-11-25 13:14:44,891 - INFO  - Training [17][   60/  196]   Loss 2.303471   Top1 9.843750   Top5 50.305990   BatchTime 0.373963   LR 0.001764   
2022-11-25 13:14:51,732 - INFO  - Training [17][   80/  196]   Loss 2.303497   Top1 9.824219   Top5 50.092773   BatchTime 0.365980   LR 0.001746   
2022-11-25 13:14:58,441 - INFO  - Training [17][  100/  196]   Loss 2.303538   Top1 9.824219   Top5 50.039062   BatchTime 0.359872   LR 0.001727   
2022-11-25 13:15:05,104 - INFO  - Training [17][  120/  196]   Loss 2.303479   Top1 9.863281   Top5 49.990234   BatchTime 0.355420   LR 0.001708   
2022-11-25 13:15:10,641 - INFO  - Training [17][  140/  196]   Loss 2.303481   Top1 9.905134   Top5 50.050223   BatchTime 0.344195   LR 0.001690   
2022-11-25 13:15:15,804 - INFO  - Training [17][  160/  196]   Loss 2.303428   Top1 9.936523   Top5 49.941406   BatchTime 0.333435   LR 0.001671   
2022-11-25 13:15:22,247 - INFO  - Training [17][  180/  196]   Loss 2.303467   Top1 9.906684   Top5 49.973958   BatchTime 0.332182   LR 0.001652   
2022-11-25 13:15:27,739 - INFO  - ==> Top1: 9.886    Top5: 49.994    Loss: 2.303

2022-11-25 13:15:28,027 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:15:29,441 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:15:32,026 - INFO  - Validation [17][   20/   40]   Loss 70.810470   Top1 10.253906   Top5 50.214844   BatchTime 0.129121   
2022-11-25 13:15:33,084 - INFO  - Validation [17][   40/   40]   Loss 71.052481   Top1 10.000000   Top5 50.000000   BatchTime 0.091042   
2022-11-25 13:15:33,357 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 71.052

2022-11-25 13:15:33,357 - INFO  - ==> Sparsity : 0.268

2022-11-25 13:15:33,357 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:15:33,357 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:15:33,357 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
2022-11-25 13:15:33,480 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:15:33,482 - INFO  - >>>>>> Epoch  18
2022-11-25 13:15:33,484 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:15:41,765 - INFO  - Training [18][   20/  196]   Loss 2.303742   Top1 9.589844   Top5 49.062500   BatchTime 0.413929   LR 0.001618   
2022-11-25 13:15:48,502 - INFO  - Training [18][   40/  196]   Loss 2.303793   Top1 9.804688   Top5 48.945312   BatchTime 0.375406   LR 0.001599   
2022-11-25 13:15:55,478 - INFO  - Training [18][   60/  196]   Loss 2.303603   Top1 9.628906   Top5 49.186198   BatchTime 0.366527   LR 0.001579   
2022-11-25 13:16:02,067 - INFO  - Training [18][   80/  196]   Loss 2.303653   Top1 9.702148   Top5 49.233398   BatchTime 0.357263   LR 0.001560   
2022-11-25 13:16:08,777 - INFO  - Training [18][  100/  196]   Loss 2.303530   Top1 9.710938   Top5 49.257812   BatchTime 0.352909   LR 0.001540   
2022-11-25 13:16:15,520 - INFO  - Training [18][  120/  196]   Loss 2.303466   Top1 9.667969   Top5 49.355469   BatchTime 0.350282   LR 0.001521   
2022-11-25 13:16:21,782 - INFO  - Training [18][  140/  196]   Loss 2.303435   Top1 9.723772   Top5 49.316406   BatchTime 0.344969   LR 0.001501   
2022-11-25 13:16:27,123 - INFO  - Training [18][  160/  196]   Loss 2.303428   Top1 9.707031   Top5 49.375000   BatchTime 0.335226   LR 0.001482   
2022-11-25 13:16:32,043 - INFO  - Training [18][  180/  196]   Loss 2.303436   Top1 9.735243   Top5 49.283854   BatchTime 0.325312   LR 0.001462   
2022-11-25 13:16:36,200 - INFO  - ==> Top1: 9.730    Top5: 49.268    Loss: 2.303

2022-11-25 13:16:36,497 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:16:38,404 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:16:40,900 - INFO  - Validation [18][   20/   40]   Loss 68.407526   Top1 10.253906   Top5 50.214844   BatchTime 0.124707   
2022-11-25 13:16:41,930 - INFO  - Validation [18][   40/   40]   Loss 68.641652   Top1 10.000000   Top5 50.000000   BatchTime 0.088121   
2022-11-25 13:16:42,214 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 68.642

2022-11-25 13:16:42,214 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:16:42,214 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:16:42,215 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:16:42,215 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
2022-11-25 13:16:42,356 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:16:42,358 - INFO  - >>>>>> Epoch  19
2022-11-25 13:16:42,360 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:16:50,817 - INFO  - Training [19][   20/  196]   Loss 2.303428   Top1 9.667969   Top5 49.414062   BatchTime 0.422747   LR 0.001427   
2022-11-25 13:16:57,740 - INFO  - Training [19][   40/  196]   Loss 2.303584   Top1 9.560547   Top5 49.238281   BatchTime 0.384432   LR 0.001407   
2022-11-25 13:17:04,401 - INFO  - Training [19][   60/  196]   Loss 2.303518   Top1 9.654948   Top5 49.414062   BatchTime 0.367310   LR 0.001387   
2022-11-25 13:17:11,245 - INFO  - Training [19][   80/  196]   Loss 2.303475   Top1 9.863281   Top5 49.418945   BatchTime 0.361027   LR 0.001367   
2022-11-25 13:17:17,948 - INFO  - Training [19][  100/  196]   Loss 2.303402   Top1 9.710938   Top5 49.390625   BatchTime 0.355854   LR 0.001347   
2022-11-25 13:17:24,587 - INFO  - Training [19][  120/  196]   Loss 2.303296   Top1 9.736328   Top5 49.677734   BatchTime 0.351864   LR 0.001327   
2022-11-25 13:17:31,602 - INFO  - Training [19][  140/  196]   Loss 2.303284   Top1 9.796317   Top5 49.681920   BatchTime 0.351708   LR 0.001307   
2022-11-25 13:17:38,310 - INFO  - Training [19][  160/  196]   Loss 2.303342   Top1 9.873047   Top5 49.614258   BatchTime 0.349670   LR 0.001287   
2022-11-25 13:17:44,752 - INFO  - Training [19][  180/  196]   Loss 2.303355   Top1 9.874132   Top5 49.542101   BatchTime 0.346604   LR 0.001266   
2022-11-25 13:17:49,314 - INFO  - ==> Top1: 9.888    Top5: 49.538    Loss: 2.303

2022-11-25 13:17:49,505 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:17:51,099 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:17:53,693 - INFO  - Validation [19][   20/   40]   Loss 67.944423   Top1 10.253906   Top5 50.214844   BatchTime 0.129592   
2022-11-25 13:17:54,748 - INFO  - Validation [19][   40/   40]   Loss 68.175355   Top1 10.000000   Top5 50.000000   BatchTime 0.091177   
2022-11-25 13:17:54,970 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 68.175

2022-11-25 13:17:54,971 - INFO  - ==> Sparsity : 0.268

2022-11-25 13:17:54,971 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:17:54,971 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:17:54,971 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
2022-11-25 13:17:55,083 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:17:55,085 - INFO  - >>>>>> Epoch  20
2022-11-25 13:17:55,087 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:18:03,522 - INFO  - Training [20][   20/  196]   Loss 2.303407   Top1 9.921875   Top5 50.156250   BatchTime 0.421674   LR 0.001231   
2022-11-25 13:18:10,363 - INFO  - Training [20][   40/  196]   Loss 2.303551   Top1 9.667969   Top5 49.697266   BatchTime 0.381858   LR 0.001211   
2022-11-25 13:18:16,980 - INFO  - Training [20][   60/  196]   Loss 2.303449   Top1 9.609375   Top5 49.817708   BatchTime 0.364846   LR 0.001191   
2022-11-25 13:18:23,640 - INFO  - Training [20][   80/  196]   Loss 2.303355   Top1 9.721680   Top5 49.794922   BatchTime 0.356890   LR 0.001171   
2022-11-25 13:18:30,317 - INFO  - Training [20][  100/  196]   Loss 2.303361   Top1 9.800781   Top5 49.621094   BatchTime 0.352279   LR 0.001151   
2022-11-25 13:18:37,460 - INFO  - Training [20][  120/  196]   Loss 2.303353   Top1 9.798177   Top5 49.602865   BatchTime 0.353090   LR 0.001131   
2022-11-25 13:18:44,952 - INFO  - Training [20][  140/  196]   Loss 2.303330   Top1 9.801897   Top5 49.559152   BatchTime 0.356160   LR 0.001111   
2022-11-25 13:18:51,613 - INFO  - Training [20][  160/  196]   Loss 2.303257   Top1 9.875488   Top5 49.672852   BatchTime 0.353272   LR 0.001091   
2022-11-25 13:18:57,547 - INFO  - Training [20][  180/  196]   Loss 2.303217   Top1 9.891493   Top5 49.741753   BatchTime 0.346984   LR 0.001071   
2022-11-25 13:19:02,078 - INFO  - ==> Top1: 9.918    Top5: 49.760    Loss: 2.303

2022-11-25 13:19:02,279 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:19:03,468 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:19:06,037 - INFO  - Validation [20][   20/   40]   Loss 67.518963   Top1 10.253906   Top5 50.214844   BatchTime 0.128364   
2022-11-25 13:19:07,063 - INFO  - Validation [20][   40/   40]   Loss 67.751711   Top1 10.000000   Top5 50.000000   BatchTime 0.089840   
2022-11-25 13:19:07,289 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 67.752

2022-11-25 13:19:07,289 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:19:07,289 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:19:07,290 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:19:07,290 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
2022-11-25 13:19:07,413 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:19:07,414 - INFO  - >>>>>> Epoch  21
2022-11-25 13:19:07,416 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:19:15,320 - INFO  - Training [21][   20/  196]   Loss 2.303271   Top1 8.906250   Top5 50.312500   BatchTime 0.395056   LR 0.001036   
2022-11-25 13:19:21,949 - INFO  - Training [21][   40/  196]   Loss 2.303147   Top1 9.394531   Top5 50.175781   BatchTime 0.363275   LR 0.001016   
2022-11-25 13:19:28,769 - INFO  - Training [21][   60/  196]   Loss 2.303082   Top1 9.824219   Top5 50.188802   BatchTime 0.355837   LR 0.000996   
2022-11-25 13:19:35,618 - INFO  - Training [21][   80/  196]   Loss 2.303106   Top1 9.799805   Top5 49.965820   BatchTime 0.352498   LR 0.000976   
2022-11-25 13:19:42,368 - INFO  - Training [21][  100/  196]   Loss 2.303153   Top1 9.585938   Top5 49.988281   BatchTime 0.349495   LR 0.000957   
2022-11-25 13:19:49,396 - INFO  - Training [21][  120/  196]   Loss 2.303065   Top1 9.794922   Top5 50.152995   BatchTime 0.349811   LR 0.000937   
2022-11-25 13:19:56,163 - INFO  - Training [21][  140/  196]   Loss 2.303114   Top1 9.785156   Top5 50.139509   BatchTime 0.348170   LR 0.000918   
2022-11-25 13:20:03,038 - INFO  - Training [21][  160/  196]   Loss 2.303137   Top1 9.736328   Top5 50.051270   BatchTime 0.347618   LR 0.000899   
2022-11-25 13:20:09,395 - INFO  - Training [21][  180/  196]   Loss 2.303108   Top1 9.793837   Top5 50.015191   BatchTime 0.344311   LR 0.000879   
2022-11-25 13:20:14,041 - INFO  - ==> Top1: 9.768    Top5: 49.984    Loss: 2.303

2022-11-25 13:20:14,356 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:20:16,406 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:20:19,632 - INFO  - Validation [21][   20/   40]   Loss 69.883735   Top1 10.253906   Top5 50.214844   BatchTime 0.161182   
2022-11-25 13:20:20,681 - INFO  - Validation [21][   40/   40]   Loss 70.121540   Top1 10.000000   Top5 50.000000   BatchTime 0.106816   
2022-11-25 13:20:20,946 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 70.122

2022-11-25 13:20:20,947 - INFO  - ==> Sparsity : 0.268

2022-11-25 13:20:20,947 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:20:20,947 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:20:20,947 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
2022-11-25 13:20:21,065 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:20:21,067 - INFO  - >>>>>> Epoch  22
2022-11-25 13:20:21,069 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:20:29,173 - INFO  - Training [22][   20/  196]   Loss 2.303218   Top1 9.765625   Top5 50.175781   BatchTime 0.405077   LR 0.000846   
2022-11-25 13:20:36,004 - INFO  - Training [22][   40/  196]   Loss 2.303269   Top1 9.609375   Top5 50.205078   BatchTime 0.373319   LR 0.000827   
2022-11-25 13:20:42,676 - INFO  - Training [22][   60/  196]   Loss 2.303142   Top1 9.752604   Top5 49.934896   BatchTime 0.360081   LR 0.000808   
2022-11-25 13:20:49,864 - INFO  - Training [22][   80/  196]   Loss 2.303131   Top1 9.819336   Top5 49.853516   BatchTime 0.359903   LR 0.000789   
2022-11-25 13:20:56,473 - INFO  - Training [22][  100/  196]   Loss 2.303100   Top1 9.703125   Top5 50.035156   BatchTime 0.354020   LR 0.000770   
2022-11-25 13:21:03,392 - INFO  - Training [22][  120/  196]   Loss 2.303042   Top1 9.791667   Top5 49.947917   BatchTime 0.352671   LR 0.000752   
2022-11-25 13:21:10,381 - INFO  - Training [22][  140/  196]   Loss 2.303121   Top1 9.838170   Top5 49.852121   BatchTime 0.352213   LR 0.000734   
2022-11-25 13:21:17,168 - INFO  - Training [22][  160/  196]   Loss 2.303102   Top1 9.755859   Top5 49.821777   BatchTime 0.350601   LR 0.000715   
2022-11-25 13:21:24,005 - INFO  - Training [22][  180/  196]   Loss 2.303109   Top1 9.691840   Top5 49.726562   BatchTime 0.349627   LR 0.000697   
2022-11-25 13:21:27,970 - INFO  - ==> Top1: 9.690    Top5: 49.752    Loss: 2.303

2022-11-25 13:21:28,195 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:21:30,274 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:21:33,179 - INFO  - Validation [22][   20/   40]   Loss 71.212675   Top1 10.253906   Top5 50.214844   BatchTime 0.145145   
2022-11-25 13:21:34,173 - INFO  - Validation [22][   40/   40]   Loss 71.454346   Top1 10.000000   Top5 50.000000   BatchTime 0.097428   
2022-11-25 13:21:34,445 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 71.454

2022-11-25 13:21:34,445 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:21:34,445 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:21:34,446 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:21:34,446 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
2022-11-25 13:21:34,563 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:21:34,565 - INFO  - >>>>>> Epoch  23
2022-11-25 13:21:34,567 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:21:42,898 - INFO  - Training [23][   20/  196]   Loss 2.303472   Top1 9.335938   Top5 49.277344   BatchTime 0.416416   LR 0.000666   
2022-11-25 13:21:49,573 - INFO  - Training [23][   40/  196]   Loss 2.303101   Top1 9.619141   Top5 49.453125   BatchTime 0.375091   LR 0.000648   
2022-11-25 13:21:56,337 - INFO  - Training [23][   60/  196]   Loss 2.303078   Top1 9.785156   Top5 49.720052   BatchTime 0.362789   LR 0.000630   
2022-11-25 13:22:03,012 - INFO  - Training [23][   80/  196]   Loss 2.303039   Top1 9.902344   Top5 49.628906   BatchTime 0.355528   LR 0.000613   
2022-11-25 13:22:09,788 - INFO  - Training [23][  100/  196]   Loss 2.302872   Top1 10.085938   Top5 49.761719   BatchTime 0.352187   LR 0.000596   
2022-11-25 13:22:16,587 - INFO  - Training [23][  120/  196]   Loss 2.302911   Top1 10.074870   Top5 49.707031   BatchTime 0.350150   LR 0.000579   
2022-11-25 13:22:23,313 - INFO  - Training [23][  140/  196]   Loss 2.302888   Top1 10.092076   Top5 49.807478   BatchTime 0.348169   LR 0.000562   
2022-11-25 13:22:30,116 - INFO  - Training [23][  160/  196]   Loss 2.302945   Top1 10.031738   Top5 49.675293   BatchTime 0.347164   LR 0.000545   
2022-11-25 13:22:36,879 - INFO  - Training [23][  180/  196]   Loss 2.302921   Top1 10.039062   Top5 49.711372   BatchTime 0.346162   LR 0.000529   
2022-11-25 13:22:42,452 - INFO  - ==> Top1: 10.078    Top5: 49.826    Loss: 2.303

2022-11-25 13:22:42,777 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:22:45,180 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:22:48,097 - INFO  - Validation [23][   20/   40]   Loss 71.951925   Top1 10.253906   Top5 50.214844   BatchTime 0.145744   
2022-11-25 13:22:49,073 - INFO  - Validation [23][   40/   40]   Loss 72.195528   Top1 10.000000   Top5 50.000000   BatchTime 0.097286   
2022-11-25 13:22:49,356 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 72.196

2022-11-25 13:22:49,357 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:22:49,357 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:22:49,357 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:22:49,358 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
2022-11-25 13:22:49,506 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:22:49,508 - INFO  - >>>>>> Epoch  24
2022-11-25 13:22:49,509 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:22:57,653 - INFO  - Training [24][   20/  196]   Loss 2.303030   Top1 9.687500   Top5 49.609375   BatchTime 0.407068   LR 0.000500   
2022-11-25 13:23:04,583 - INFO  - Training [24][   40/  196]   Loss 2.302656   Top1 10.273438   Top5 49.990234   BatchTime 0.376769   LR 0.000484   
2022-11-25 13:23:11,396 - INFO  - Training [24][   60/  196]   Loss 2.302744   Top1 10.045573   Top5 49.700521   BatchTime 0.364732   LR 0.000468   
2022-11-25 13:23:17,929 - INFO  - Training [24][   80/  196]   Loss 2.302883   Top1 10.014648   Top5 49.697266   BatchTime 0.355217   LR 0.000453   
2022-11-25 13:23:24,858 - INFO  - Training [24][  100/  196]   Loss 2.302855   Top1 9.988281   Top5 49.800781   BatchTime 0.353454   LR 0.000437   
2022-11-25 13:23:31,420 - INFO  - Training [24][  120/  196]   Loss 2.302904   Top1 9.886068   Top5 49.684245   BatchTime 0.349230   LR 0.000422   
2022-11-25 13:23:38,101 - INFO  - Training [24][  140/  196]   Loss 2.302915   Top1 9.919085   Top5 49.757254   BatchTime 0.347064   LR 0.000407   
2022-11-25 13:23:45,066 - INFO  - Training [24][  160/  196]   Loss 2.303003   Top1 9.843750   Top5 49.560547   BatchTime 0.347209   LR 0.000392   
2022-11-25 13:23:51,791 - INFO  - Training [24][  180/  196]   Loss 2.303072   Top1 9.861111   Top5 49.487847   BatchTime 0.345988   LR 0.000378   
2022-11-25 13:23:56,231 - INFO  - ==> Top1: 9.856    Top5: 49.608    Loss: 2.303

2022-11-25 13:23:56,444 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:23:59,612 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:24:02,579 - INFO  - Validation [24][   20/   40]   Loss 72.275293   Top1 10.253906   Top5 50.214844   BatchTime 0.148282   
2022-11-25 13:24:03,637 - INFO  - Validation [24][   40/   40]   Loss 72.522234   Top1 10.000000   Top5 50.000000   BatchTime 0.100591   
2022-11-25 13:24:03,898 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 72.522

2022-11-25 13:24:03,898 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:24:03,899 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:24:03,899 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:24:03,899 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
2022-11-25 13:24:04,047 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:24:04,049 - INFO  - >>>>>> Epoch  25
2022-11-25 13:24:04,051 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:24:12,896 - INFO  - Training [25][   20/  196]   Loss 2.302570   Top1 10.117188   Top5 50.097656   BatchTime 0.442142   LR 0.000353   
2022-11-25 13:24:19,768 - INFO  - Training [25][   40/  196]   Loss 2.302632   Top1 10.019531   Top5 49.726562   BatchTime 0.392867   LR 0.000339   
2022-11-25 13:24:26,476 - INFO  - Training [25][   60/  196]   Loss 2.302732   Top1 9.960938   Top5 49.726562   BatchTime 0.373723   LR 0.000325   
2022-11-25 13:24:33,255 - INFO  - Training [25][   80/  196]   Loss 2.302677   Top1 9.995117   Top5 49.887695   BatchTime 0.365028   LR 0.000312   
2022-11-25 13:24:40,086 - INFO  - Training [25][  100/  196]   Loss 2.302635   Top1 9.984375   Top5 50.039062   BatchTime 0.360333   LR 0.000299   
2022-11-25 13:24:47,179 - INFO  - Training [25][  120/  196]   Loss 2.302617   Top1 10.074870   Top5 50.065104   BatchTime 0.359379   LR 0.000286   
2022-11-25 13:24:54,715 - INFO  - Training [25][  140/  196]   Loss 2.302658   Top1 10.016741   Top5 49.916295   BatchTime 0.361867   LR 0.000273   
2022-11-25 13:25:01,808 - INFO  - Training [25][  160/  196]   Loss 2.302744   Top1 9.948730   Top5 49.780273   BatchTime 0.360964   LR 0.000261   
2022-11-25 13:25:08,384 - INFO  - Training [25][  180/  196]   Loss 2.302756   Top1 10.030382   Top5 49.778646   BatchTime 0.357392   LR 0.000248   
2022-11-25 13:25:12,712 - INFO  - ==> Top1: 10.028    Top5: 49.734    Loss: 2.303

2022-11-25 13:25:12,923 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:25:14,927 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:25:17,942 - INFO  - Validation [25][   20/   40]   Loss 72.273362   Top1 10.253906   Top5 50.214844   BatchTime 0.150692   
2022-11-25 13:25:19,119 - INFO  - Validation [25][   40/   40]   Loss 72.519174   Top1 10.000000   Top5 50.000000   BatchTime 0.104780   
2022-11-25 13:25:19,390 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 72.519

2022-11-25 13:25:19,390 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:25:19,391 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:25:19,391 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:25:19,391 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
2022-11-25 13:25:19,536 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:25:19,538 - INFO  - >>>>>> Epoch  26
2022-11-25 13:25:19,540 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:25:27,683 - INFO  - Training [26][   20/  196]   Loss 2.302313   Top1 10.585938   Top5 52.109375   BatchTime 0.407013   LR 0.000228   
2022-11-25 13:25:34,463 - INFO  - Training [26][   40/  196]   Loss 2.302520   Top1 10.273438   Top5 50.751953   BatchTime 0.373022   LR 0.000216   
2022-11-25 13:25:41,445 - INFO  - Training [26][   60/  196]   Loss 2.302500   Top1 10.227865   Top5 50.820312   BatchTime 0.365048   LR 0.000205   
2022-11-25 13:25:48,830 - INFO  - Training [26][   80/  196]   Loss 2.302513   Top1 10.278320   Top5 50.844727   BatchTime 0.366095   LR 0.000194   
2022-11-25 13:25:55,433 - INFO  - Training [26][  100/  196]   Loss 2.302624   Top1 10.261719   Top5 50.605469   BatchTime 0.358902   LR 0.000183   
2022-11-25 13:26:02,311 - INFO  - Training [26][  120/  196]   Loss 2.302719   Top1 10.123698   Top5 50.384115   BatchTime 0.356404   LR 0.000173   
2022-11-25 13:26:09,039 - INFO  - Training [26][  140/  196]   Loss 2.302832   Top1 10.044643   Top5 50.223214   BatchTime 0.353544   LR 0.000163   
2022-11-25 13:26:15,778 - INFO  - Training [26][  160/  196]   Loss 2.302817   Top1 10.097656   Top5 50.104980   BatchTime 0.351467   LR 0.000153   
2022-11-25 13:26:22,550 - INFO  - Training [26][  180/  196]   Loss 2.302794   Top1 10.130208   Top5 50.052083   BatchTime 0.350042   LR 0.000144   
2022-11-25 13:26:26,978 - INFO  - ==> Top1: 10.110    Top5: 50.064    Loss: 2.303

2022-11-25 13:26:27,254 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:26:29,467 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:26:32,420 - INFO  - Validation [26][   20/   40]   Loss 72.029857   Top1 10.253906   Top5 50.214844   BatchTime 0.147555   
2022-11-25 13:26:33,441 - INFO  - Validation [26][   40/   40]   Loss 72.275830   Top1 10.000000   Top5 50.000000   BatchTime 0.099317   
2022-11-25 13:26:33,677 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 72.276

2022-11-25 13:26:33,677 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:26:33,678 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:26:33,678 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:26:33,678 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
2022-11-25 13:26:33,808 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:26:33,810 - INFO  - >>>>>> Epoch  27
2022-11-25 13:26:33,811 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:26:42,062 - INFO  - Training [27][   20/  196]   Loss 2.303177   Top1 9.472656   Top5 49.667969   BatchTime 0.412424   LR 0.000128   
2022-11-25 13:26:48,819 - INFO  - Training [27][   40/  196]   Loss 2.302951   Top1 9.882812   Top5 50.126953   BatchTime 0.375122   LR 0.000119   
2022-11-25 13:26:55,271 - INFO  - Training [27][   60/  196]   Loss 2.302867   Top1 10.130208   Top5 50.019531   BatchTime 0.357620   LR 0.000111   
2022-11-25 13:27:01,938 - INFO  - Training [27][   80/  196]   Loss 2.302885   Top1 10.083008   Top5 50.000000   BatchTime 0.351549   LR 0.000102   
2022-11-25 13:27:08,666 - INFO  - Training [27][  100/  196]   Loss 2.302943   Top1 9.953125   Top5 49.933594   BatchTime 0.348516   LR 0.000095   
2022-11-25 13:27:15,281 - INFO  - Training [27][  120/  196]   Loss 2.302920   Top1 9.993490   Top5 50.003255   BatchTime 0.345555   LR 0.000087   
2022-11-25 13:27:21,950 - INFO  - Training [27][  140/  196]   Loss 2.302926   Top1 10.041853   Top5 49.927455   BatchTime 0.343825   LR 0.000080   
2022-11-25 13:27:28,573 - INFO  - Training [27][  160/  196]   Loss 2.302967   Top1 9.916992   Top5 49.804688   BatchTime 0.342241   LR 0.000073   
2022-11-25 13:27:35,423 - INFO  - Training [27][  180/  196]   Loss 2.302973   Top1 9.982639   Top5 49.748264   BatchTime 0.342267   LR 0.000066   
2022-11-25 13:27:41,147 - INFO  - ==> Top1: 9.994    Top5: 49.782    Loss: 2.303

2022-11-25 13:27:41,415 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:27:43,734 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:27:46,986 - INFO  - Validation [27][   20/   40]   Loss 72.597249   Top1 10.253906   Top5 50.214844   BatchTime 0.162478   
2022-11-25 13:27:48,492 - INFO  - Validation [27][   40/   40]   Loss 72.843558   Top1 10.000000   Top5 50.000000   BatchTime 0.118910   
2022-11-25 13:27:48,776 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 72.844

2022-11-25 13:27:48,776 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:27:48,776 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:27:48,777 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:27:48,777 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
2022-11-25 13:27:48,888 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:27:48,890 - INFO  - >>>>>> Epoch  28
2022-11-25 13:27:48,892 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:27:57,126 - INFO  - Training [28][   20/  196]   Loss 2.303255   Top1 9.453125   Top5 49.121094   BatchTime 0.411594   LR 0.000055   
2022-11-25 13:28:03,965 - INFO  - Training [28][   40/  196]   Loss 2.302827   Top1 10.175781   Top5 49.921875   BatchTime 0.376775   LR 0.000050   
2022-11-25 13:28:10,625 - INFO  - Training [28][   60/  196]   Loss 2.303141   Top1 9.889323   Top5 49.433594   BatchTime 0.362180   LR 0.000044   
2022-11-25 13:28:17,289 - INFO  - Training [28][   80/  196]   Loss 2.302903   Top1 10.009766   Top5 49.926758   BatchTime 0.354939   LR 0.000039   
2022-11-25 13:28:23,950 - INFO  - Training [28][  100/  196]   Loss 2.302852   Top1 10.035156   Top5 49.906250   BatchTime 0.350555   LR 0.000034   
2022-11-25 13:28:30,415 - INFO  - Training [28][  120/  196]   Loss 2.302909   Top1 9.938151   Top5 49.798177   BatchTime 0.346008   LR 0.000030   
2022-11-25 13:28:37,008 - INFO  - Training [28][  140/  196]   Loss 2.302876   Top1 9.991629   Top5 49.762835   BatchTime 0.343666   LR 0.000026   
2022-11-25 13:28:44,118 - INFO  - Training [28][  160/  196]   Loss 2.302814   Top1 10.034180   Top5 49.841309   BatchTime 0.345147   LR 0.000022   
2022-11-25 13:28:50,814 - INFO  - Training [28][  180/  196]   Loss 2.302878   Top1 9.965278   Top5 49.796007   BatchTime 0.343997   LR 0.000018   
2022-11-25 13:28:56,242 - INFO  - ==> Top1: 9.940    Top5: 49.832    Loss: 2.303

2022-11-25 13:28:56,447 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:28:57,746 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:29:00,733 - INFO  - Validation [28][   20/   40]   Loss 72.538111   Top1 10.253906   Top5 50.214844   BatchTime 0.149261   
2022-11-25 13:29:02,995 - INFO  - Validation [28][   40/   40]   Loss 72.785309   Top1 10.000000   Top5 50.000000   BatchTime 0.131198   
2022-11-25 13:29:03,523 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 72.785

2022-11-25 13:29:03,523 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:29:03,523 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:29:03,523 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:29:03,524 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 10.000   Top5: 50.000]
2022-11-25 13:29:03,658 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:29:03,660 - INFO  - >>>>>> Epoch  29
2022-11-25 13:29:03,662 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:29:11,261 - INFO  - Training [29][   20/  196]   Loss 2.302629   Top1 10.097656   Top5 50.214844   BatchTime 0.379811   LR 0.000013   
2022-11-25 13:29:17,974 - INFO  - Training [29][   40/  196]   Loss 2.302701   Top1 10.000000   Top5 50.292969   BatchTime 0.357742   LR 0.000010   
2022-11-25 13:29:24,566 - INFO  - Training [29][   60/  196]   Loss 2.302761   Top1 9.967448   Top5 50.013021   BatchTime 0.348363   LR 0.000008   
2022-11-25 13:29:31,116 - INFO  - Training [29][   80/  196]   Loss 2.302809   Top1 9.907227   Top5 49.995117   BatchTime 0.343145   LR 0.000005   
2022-11-25 13:29:38,628 - INFO  - Training [29][  100/  196]   Loss 2.302803   Top1 9.957031   Top5 50.089844   BatchTime 0.349628   LR 0.000004   
2022-11-25 13:29:45,278 - INFO  - Training [29][  120/  196]   Loss 2.302818   Top1 9.928385   Top5 50.006510   BatchTime 0.346780   LR 0.000002   
2022-11-25 13:29:51,965 - INFO  - Training [29][  140/  196]   Loss 2.302803   Top1 9.938616   Top5 49.983259   BatchTime 0.345000   LR 0.000001   
2022-11-25 13:29:58,595 - INFO  - Training [29][  160/  196]   Loss 2.302840   Top1 9.941406   Top5 49.897461   BatchTime 0.343314   LR 0.000001   
2022-11-25 13:30:05,416 - INFO  - Training [29][  180/  196]   Loss 2.302824   Top1 9.993490   Top5 49.898003   BatchTime 0.343059   LR 0.000000   
2022-11-25 13:30:10,941 - INFO  - ==> Top1: 10.012    Top5: 50.000    Loss: 2.303

2022-11-25 13:30:11,285 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:30:12,993 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:30:15,695 - INFO  - Validation [29][   20/   40]   Loss 72.414732   Top1 10.253906   Top5 50.214844   BatchTime 0.135046   
2022-11-25 13:30:16,946 - INFO  - Validation [29][   40/   40]   Loss 72.660979   Top1 10.000000   Top5 50.000000   BatchTime 0.098782   
2022-11-25 13:30:17,545 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 72.661

2022-11-25 13:30:17,546 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:30:17,546 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:30:17,546 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:30:17,546 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 10.000   Top5: 50.000]
2022-11-25 13:30:17,686 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:30:17,688 - INFO  - >>>>>> Epoch  30
2022-11-25 13:30:17,690 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:30:24,976 - INFO  - Training [30][   20/  196]   Loss 2.302748   Top1 9.218750   Top5 50.449219   BatchTime 0.364177   LR 0.001250   
2022-11-25 13:30:31,645 - INFO  - Training [30][   40/  196]   Loss 2.302894   Top1 9.589844   Top5 50.263672   BatchTime 0.348803   LR 0.001250   
2022-11-25 13:30:38,469 - INFO  - Training [30][   60/  196]   Loss 2.302899   Top1 9.811198   Top5 50.390625   BatchTime 0.346276   LR 0.001250   
2022-11-25 13:30:45,310 - INFO  - Training [30][   80/  196]   Loss 2.303003   Top1 9.721680   Top5 50.043945   BatchTime 0.345212   LR 0.001250   
2022-11-25 13:30:51,951 - INFO  - Training [30][  100/  196]   Loss 2.303070   Top1 9.753906   Top5 49.714844   BatchTime 0.342582   LR 0.001250   
2022-11-25 13:30:58,634 - INFO  - Training [30][  120/  196]   Loss 2.303141   Top1 9.752604   Top5 49.625651   BatchTime 0.341171   LR 0.001249   
2022-11-25 13:31:05,257 - INFO  - Training [30][  140/  196]   Loss 2.303135   Top1 9.782366   Top5 49.628906   BatchTime 0.339737   LR 0.001249   
2022-11-25 13:31:11,962 - INFO  - Training [30][  160/  196]   Loss 2.303185   Top1 9.809570   Top5 49.587402   BatchTime 0.339176   LR 0.001249   
2022-11-25 13:31:18,667 - INFO  - Training [30][  180/  196]   Loss 2.303154   Top1 9.815538   Top5 49.696181   BatchTime 0.338740   LR 0.001248   
2022-11-25 13:31:24,241 - INFO  - ==> Top1: 9.832    Top5: 49.676    Loss: 2.303

2022-11-25 13:31:24,524 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:31:26,212 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:31:28,853 - INFO  - Validation [30][   20/   40]   Loss 63.828444   Top1 10.253906   Top5 50.214844   BatchTime 0.131964   
2022-11-25 13:31:29,983 - INFO  - Validation [30][   40/   40]   Loss 64.047161   Top1 10.000000   Top5 50.000000   BatchTime 0.094237   
2022-11-25 13:31:30,265 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 64.047

2022-11-25 13:31:30,265 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:31:30,265 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:31:30,265 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:31:30,266 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 10.000   Top5: 50.000]
2022-11-25 13:31:30,401 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:31:30,402 - INFO  - >>>>>> Epoch  31
2022-11-25 13:31:30,404 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:31:37,944 - INFO  - Training [31][   20/  196]   Loss 2.302972   Top1 9.726562   Top5 50.214844   BatchTime 0.376860   LR 0.001248   
2022-11-25 13:31:44,731 - INFO  - Training [31][   40/  196]   Loss 2.303417   Top1 10.039062   Top5 49.453125   BatchTime 0.358105   LR 0.001247   
2022-11-25 13:31:51,459 - INFO  - Training [31][   60/  196]   Loss 2.303417   Top1 10.097656   Top5 49.394531   BatchTime 0.350869   LR 0.001247   
2022-11-25 13:31:58,615 - INFO  - Training [31][   80/  196]   Loss 2.303293   Top1 10.102539   Top5 49.624023   BatchTime 0.352607   LR 0.001246   
2022-11-25 13:32:06,214 - INFO  - Training [31][  100/  196]   Loss 2.303217   Top1 10.210938   Top5 49.859375   BatchTime 0.358069   LR 0.001246   
2022-11-25 13:32:12,857 - INFO  - Training [31][  120/  196]   Loss 2.303279   Top1 10.061849   Top5 49.830729   BatchTime 0.353748   LR 0.001245   
2022-11-25 13:32:19,634 - INFO  - Training [31][  140/  196]   Loss 2.303311   Top1 9.966518   Top5 49.877232   BatchTime 0.351622   LR 0.001244   
2022-11-25 13:32:26,337 - INFO  - Training [31][  160/  196]   Loss 2.303279   Top1 9.956055   Top5 49.970703   BatchTime 0.349560   LR 0.001244   
2022-11-25 13:32:33,007 - INFO  - Training [31][  180/  196]   Loss 2.303195   Top1 10.008681   Top5 50.104167   BatchTime 0.347779   LR 0.001243   
2022-11-25 13:32:38,405 - INFO  - ==> Top1: 10.010    Top5: 50.042    Loss: 2.303

2022-11-25 13:32:38,643 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:32:39,965 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:32:42,466 - INFO  - Validation [31][   20/   40]   Loss 63.445699   Top1 10.253906   Top5 50.214844   BatchTime 0.124959   
2022-11-25 13:32:43,488 - INFO  - Validation [31][   40/   40]   Loss 63.656669   Top1 10.000000   Top5 50.000000   BatchTime 0.088031   
2022-11-25 13:32:43,755 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 63.657

2022-11-25 13:32:43,756 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:32:43,756 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:32:43,756 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:32:43,756 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 10.000   Top5: 50.000]
2022-11-25 13:32:43,919 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:32:43,921 - INFO  - >>>>>> Epoch  32
2022-11-25 13:32:43,923 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:32:50,732 - INFO  - Training [32][   20/  196]   Loss 2.302914   Top1 10.859375   Top5 50.253906   BatchTime 0.340304   LR 0.001242   
2022-11-25 13:32:56,794 - INFO  - Training [32][   40/  196]   Loss 2.303262   Top1 10.390625   Top5 49.882812   BatchTime 0.321722   LR 0.001241   
2022-11-25 13:33:03,509 - INFO  - Training [32][   60/  196]   Loss 2.303224   Top1 10.000000   Top5 49.550781   BatchTime 0.326398   LR 0.001240   
2022-11-25 13:33:10,074 - INFO  - Training [32][   80/  196]   Loss 2.303154   Top1 10.224609   Top5 49.687500   BatchTime 0.326853   LR 0.001239   
2022-11-25 13:33:16,935 - INFO  - Training [32][  100/  196]   Loss 2.303168   Top1 10.082031   Top5 49.562500   BatchTime 0.330095   LR 0.001238   
2022-11-25 13:33:23,616 - INFO  - Training [32][  120/  196]   Loss 2.303260   Top1 10.022786   Top5 49.560547   BatchTime 0.330749   LR 0.001237   
2022-11-25 13:33:30,649 - INFO  - Training [32][  140/  196]   Loss 2.303264   Top1 9.910714   Top5 49.542411   BatchTime 0.333740   LR 0.001236   
2022-11-25 13:33:38,067 - INFO  - Training [32][  160/  196]   Loss 2.303210   Top1 9.929199   Top5 49.638672   BatchTime 0.338381   LR 0.001235   
2022-11-25 13:33:44,873 - INFO  - Training [32][  180/  196]   Loss 2.303206   Top1 9.986979   Top5 49.526910   BatchTime 0.338592   LR 0.001234   
2022-11-25 13:33:50,425 - INFO  - ==> Top1: 9.988    Top5: 49.552    Loss: 2.303

2022-11-25 13:33:50,945 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:33:52,379 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:33:54,930 - INFO  - Validation [32][   20/   40]   Loss 59.931615   Top1 10.253906   Top5 50.214844   BatchTime 0.127460   
2022-11-25 13:33:55,977 - INFO  - Validation [32][   40/   40]   Loss 60.136036   Top1 10.000000   Top5 50.000000   BatchTime 0.089912   
2022-11-25 13:33:56,203 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 60.136

2022-11-25 13:33:56,203 - INFO  - ==> Sparsity : 0.269

2022-11-25 13:33:56,204 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:33:56,204 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:33:56,204 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 10.000   Top5: 50.000]
2022-11-25 13:33:56,343 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:33:56,345 - INFO  - >>>>>> Epoch  33
2022-11-25 13:33:56,347 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:34:03,218 - INFO  - Training [33][   20/  196]   Loss 2.302972   Top1 10.292969   Top5 50.019531   BatchTime 0.343424   LR 0.001232   
2022-11-25 13:34:09,326 - INFO  - Training [33][   40/  196]   Loss 2.302832   Top1 10.224609   Top5 49.589844   BatchTime 0.324423   LR 0.001230   
2022-11-25 13:34:15,936 - INFO  - Training [33][   60/  196]   Loss 2.302958   Top1 10.104167   Top5 49.707031   BatchTime 0.326441   LR 0.001229   
2022-11-25 13:34:22,626 - INFO  - Training [33][   80/  196]   Loss 2.302918   Top1 10.029297   Top5 49.814453   BatchTime 0.328461   LR 0.001228   
2022-11-25 13:34:29,756 - INFO  - Training [33][  100/  196]   Loss 2.302958   Top1 9.894531   Top5 49.843750   BatchTime 0.334063   LR 0.001226   
2022-11-25 13:34:36,653 - INFO  - Training [33][  120/  196]   Loss 2.302860   Top1 9.925130   Top5 49.964193   BatchTime 0.335861   LR 0.001225   
2022-11-25 13:34:43,310 - INFO  - Training [33][  140/  196]   Loss 2.302973   Top1 9.885603   Top5 49.891183   BatchTime 0.335431   LR 0.001224   
2022-11-25 13:34:49,872 - INFO  - Training [33][  160/  196]   Loss 2.302955   Top1 9.968262   Top5 49.892578   BatchTime 0.334516   LR 0.001222   
2022-11-25 13:34:56,418 - INFO  - Training [33][  180/  196]   Loss 2.303018   Top1 9.904514   Top5 49.843750   BatchTime 0.333711   LR 0.001221   
2022-11-25 13:35:01,880 - INFO  - ==> Top1: 9.912    Top5: 49.806    Loss: 2.303

2022-11-25 13:35:02,165 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:35:03,661 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:35:06,360 - INFO  - Validation [33][   20/   40]   Loss 55.188247   Top1 10.253906   Top5 50.214844   BatchTime 0.134858   
2022-11-25 13:35:07,495 - INFO  - Validation [33][   40/   40]   Loss 55.374905   Top1 10.000000   Top5 50.000000   BatchTime 0.095814   
2022-11-25 13:35:07,746 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 55.375

2022-11-25 13:35:07,747 - INFO  - ==> Sparsity : 0.270

2022-11-25 13:35:07,747 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:35:07,747 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:35:07,748 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 10.000   Top5: 50.000]
2022-11-25 13:35:07,894 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:35:07,895 - INFO  - >>>>>> Epoch  34
2022-11-25 13:35:07,897 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:35:15,099 - INFO  - Training [34][   20/  196]   Loss 2.302650   Top1 9.941406   Top5 50.117188   BatchTime 0.359965   LR 0.001218   
2022-11-25 13:35:20,777 - INFO  - Training [34][   40/  196]   Loss 2.302850   Top1 10.068359   Top5 49.619141   BatchTime 0.321926   LR 0.001216   
2022-11-25 13:35:27,480 - INFO  - Training [34][   60/  196]   Loss 2.302867   Top1 10.000000   Top5 49.739583   BatchTime 0.326333   LR 0.001215   
2022-11-25 13:35:34,600 - INFO  - Training [34][   80/  196]   Loss 2.303008   Top1 9.887695   Top5 49.990234   BatchTime 0.333742   LR 0.001213   
2022-11-25 13:35:41,246 - INFO  - Training [34][  100/  196]   Loss 2.303067   Top1 9.925781   Top5 49.937500   BatchTime 0.333452   LR 0.001211   
2022-11-25 13:35:48,342 - INFO  - Training [34][  120/  196]   Loss 2.303037   Top1 9.941406   Top5 49.918620   BatchTime 0.337011   LR 0.001209   
2022-11-25 13:35:55,148 - INFO  - Training [34][  140/  196]   Loss 2.303136   Top1 9.776786   Top5 49.938616   BatchTime 0.337483   LR 0.001208   
2022-11-25 13:36:02,008 - INFO  - Training [34][  160/  196]   Loss 2.303087   Top1 9.814453   Top5 50.039062   BatchTime 0.338173   LR 0.001206   
2022-11-25 13:36:08,814 - INFO  - Training [34][  180/  196]   Loss 2.303115   Top1 9.848090   Top5 50.000000   BatchTime 0.338409   LR 0.001204   
2022-11-25 13:36:14,580 - INFO  - ==> Top1: 9.902    Top5: 49.980    Loss: 2.303

2022-11-25 13:36:14,837 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:36:16,292 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:36:18,872 - INFO  - Validation [34][   20/   40]   Loss 54.358937   Top1 10.253906   Top5 50.214844   BatchTime 0.128889   
2022-11-25 13:36:19,941 - INFO  - Validation [34][   40/   40]   Loss 54.543002   Top1 10.000000   Top5 50.000000   BatchTime 0.091174   
2022-11-25 13:36:20,205 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 54.543

2022-11-25 13:36:20,206 - INFO  - ==> Sparsity : 0.270

2022-11-25 13:36:20,206 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:36:20,206 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:36:20,206 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 10.000   Top5: 50.000]
2022-11-25 13:36:20,346 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:36:20,348 - INFO  - >>>>>> Epoch  35
2022-11-25 13:36:20,350 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:36:27,707 - INFO  - Training [35][   20/  196]   Loss 2.303189   Top1 10.703125   Top5 48.964844   BatchTime 0.367730   LR 0.001201   
2022-11-25 13:36:33,965 - INFO  - Training [35][   40/  196]   Loss 2.302850   Top1 10.527344   Top5 49.619141   BatchTime 0.340326   LR 0.001199   
2022-11-25 13:36:39,222 - INFO  - Training [35][   60/  196]   Loss 2.303139   Top1 10.364583   Top5 49.511719   BatchTime 0.314501   LR 0.001197   
2022-11-25 13:36:44,031 - INFO  - Training [35][   80/  196]   Loss 2.303115   Top1 10.424805   Top5 49.516602   BatchTime 0.295987   LR 0.001195   
2022-11-25 13:36:49,045 - INFO  - Training [35][  100/  196]   Loss 2.303025   Top1 10.390625   Top5 49.484375   BatchTime 0.286926   LR 0.001192   
2022-11-25 13:36:54,018 - INFO  - Training [35][  120/  196]   Loss 2.303064   Top1 10.292969   Top5 49.580078   BatchTime 0.280548   LR 0.001190   
2022-11-25 13:36:59,023 - INFO  - Training [35][  140/  196]   Loss 2.303021   Top1 10.301339   Top5 49.606585   BatchTime 0.276221   LR 0.001188   
2022-11-25 13:37:03,990 - INFO  - Training [35][  160/  196]   Loss 2.302959   Top1 10.249023   Top5 49.675293   BatchTime 0.272736   LR 0.001186   
2022-11-25 13:37:08,536 - INFO  - Training [35][  180/  196]   Loss 2.303011   Top1 10.121528   Top5 49.626736   BatchTime 0.267684   LR 0.001184   
2022-11-25 13:37:12,262 - INFO  - ==> Top1: 10.080    Top5: 49.620    Loss: 2.303

2022-11-25 13:37:12,483 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:37:13,609 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:37:16,118 - INFO  - Validation [35][   20/   40]   Loss 53.290930   Top1 10.253906   Top5 50.214844   BatchTime 0.125362   
2022-11-25 13:37:17,190 - INFO  - Validation [35][   40/   40]   Loss 53.470376   Top1 10.000000   Top5 50.000000   BatchTime 0.089482   
2022-11-25 13:37:17,425 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 53.470

2022-11-25 13:37:17,425 - INFO  - ==> Sparsity : 0.270

2022-11-25 13:37:17,425 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:37:17,426 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:37:17,426 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 10.000   Top5: 50.000]
2022-11-25 13:37:17,571 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:37:17,573 - INFO  - >>>>>> Epoch  36
2022-11-25 13:37:17,574 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:37:23,857 - INFO  - Training [36][   20/  196]   Loss 2.302856   Top1 10.390625   Top5 50.468750   BatchTime 0.314040   LR 0.001180   
2022-11-25 13:37:29,251 - INFO  - Training [36][   40/  196]   Loss 2.303336   Top1 9.638672   Top5 49.638672   BatchTime 0.291868   LR 0.001177   
2022-11-25 13:37:34,200 - INFO  - Training [36][   60/  196]   Loss 2.303318   Top1 9.544271   Top5 49.596354   BatchTime 0.277047   LR 0.001175   
2022-11-25 13:37:38,623 - INFO  - Training [36][   80/  196]   Loss 2.303273   Top1 9.296875   Top5 49.594727   BatchTime 0.263077   LR 0.001173   
2022-11-25 13:37:43,200 - INFO  - Training [36][  100/  196]   Loss 2.303275   Top1 9.406250   Top5 49.441406   BatchTime 0.256232   LR 0.001170   
2022-11-25 13:37:48,054 - INFO  - Training [36][  120/  196]   Loss 2.303152   Top1 9.482422   Top5 49.619141   BatchTime 0.253972   LR 0.001168   
2022-11-25 13:37:52,551 - INFO  - Training [36][  140/  196]   Loss 2.303211   Top1 9.547991   Top5 49.606585   BatchTime 0.249817   LR 0.001165   
2022-11-25 13:37:57,099 - INFO  - Training [36][  160/  196]   Loss 2.303240   Top1 9.504395   Top5 49.543457   BatchTime 0.247014   LR 0.001163   
2022-11-25 13:38:01,614 - INFO  - Training [36][  180/  196]   Loss 2.303172   Top1 9.611545   Top5 49.631076   BatchTime 0.244649   LR 0.001160   
2022-11-25 13:38:05,741 - INFO  - ==> Top1: 9.692    Top5: 49.702    Loss: 2.303

2022-11-25 13:38:05,962 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:38:07,108 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:38:09,749 - INFO  - Validation [36][   20/   40]   Loss 53.301538   Top1 10.253906   Top5 50.214844   BatchTime 0.131916   
2022-11-25 13:38:10,845 - INFO  - Validation [36][   40/   40]   Loss 53.484531   Top1 10.000000   Top5 50.000000   BatchTime 0.093373   
2022-11-25 13:38:11,088 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 53.485

2022-11-25 13:38:11,089 - INFO  - ==> Sparsity : 0.270

2022-11-25 13:38:11,089 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:38:11,089 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:38:11,089 - INFO  - Scoreboard best 3 ==> Epoch [36][Top1: 10.000   Top5: 50.000]
2022-11-25 13:38:11,253 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:38:11,255 - INFO  - >>>>>> Epoch  37
2022-11-25 13:38:11,257 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:38:17,588 - INFO  - Training [37][   20/  196]   Loss 2.302806   Top1 9.863281   Top5 50.136719   BatchTime 0.316462   LR 0.001155   
2022-11-25 13:38:22,708 - INFO  - Training [37][   40/  196]   Loss 2.302865   Top1 10.009766   Top5 50.009766   BatchTime 0.286211   LR 0.001153   
2022-11-25 13:38:27,978 - INFO  - Training [37][   60/  196]   Loss 2.303084   Top1 9.778646   Top5 49.544271   BatchTime 0.278646   LR 0.001150   
2022-11-25 13:38:33,104 - INFO  - Training [37][   80/  196]   Loss 2.302951   Top1 10.068359   Top5 49.565430   BatchTime 0.273058   LR 0.001147   
2022-11-25 13:38:38,104 - INFO  - Training [37][  100/  196]   Loss 2.302976   Top1 10.011719   Top5 49.742188   BatchTime 0.268442   LR 0.001144   
2022-11-25 13:38:43,047 - INFO  - Training [37][  120/  196]   Loss 2.303340   Top1 9.980469   Top5 49.599609   BatchTime 0.264898   LR 0.001142   
2022-11-25 13:38:48,071 - INFO  - Training [37][  140/  196]   Loss 2.303321   Top1 9.930246   Top5 49.550781   BatchTime 0.262940   LR 0.001139   
2022-11-25 13:38:53,067 - INFO  - Training [37][  160/  196]   Loss 2.303252   Top1 9.965820   Top5 49.575195   BatchTime 0.261296   LR 0.001136   
2022-11-25 13:38:58,102 - INFO  - Training [37][  180/  196]   Loss 2.303253   Top1 9.941406   Top5 49.433594   BatchTime 0.260232   LR 0.001133   
2022-11-25 13:39:02,248 - INFO  - ==> Top1: 9.954    Top5: 49.572    Loss: 2.303

2022-11-25 13:39:02,457 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:39:03,583 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:39:06,197 - INFO  - Validation [37][   20/   40]   Loss 47.170946   Top1 10.253906   Top5 50.214844   BatchTime 0.130610   
2022-11-25 13:39:07,236 - INFO  - Validation [37][   40/   40]   Loss 47.333457   Top1 10.000000   Top5 50.000000   BatchTime 0.091294   
2022-11-25 13:39:07,463 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.333

2022-11-25 13:39:07,463 - INFO  - ==> Sparsity : 0.271

2022-11-25 13:39:07,464 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:39:07,464 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:39:07,464 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 10.000   Top5: 50.000]
2022-11-25 13:39:07,579 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:39:07,580 - INFO  - >>>>>> Epoch  38
2022-11-25 13:39:07,582 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:39:13,550 - INFO  - Training [38][   20/  196]   Loss 2.303025   Top1 9.238281   Top5 49.785156   BatchTime 0.298277   LR 0.001128   
2022-11-25 13:39:18,592 - INFO  - Training [38][   40/  196]   Loss 2.302843   Top1 9.941406   Top5 50.361328   BatchTime 0.275183   LR 0.001125   
2022-11-25 13:39:23,657 - INFO  - Training [38][   60/  196]   Loss 2.302942   Top1 9.947917   Top5 49.986979   BatchTime 0.267879   LR 0.001122   
2022-11-25 13:39:28,790 - INFO  - Training [38][   80/  196]   Loss 2.302954   Top1 10.083008   Top5 50.024414   BatchTime 0.265065   LR 0.001119   
2022-11-25 13:39:33,750 - INFO  - Training [38][  100/  196]   Loss 2.303019   Top1 10.117188   Top5 49.890625   BatchTime 0.261655   LR 0.001116   
2022-11-25 13:39:38,281 - INFO  - Training [38][  120/  196]   Loss 2.303132   Top1 10.013021   Top5 49.739583   BatchTime 0.255804   LR 0.001112   
2022-11-25 13:39:42,640 - INFO  - Training [38][  140/  196]   Loss 2.303075   Top1 9.974888   Top5 49.891183   BatchTime 0.250399   LR 0.001109   
2022-11-25 13:39:47,718 - INFO  - Training [38][  160/  196]   Loss 2.303060   Top1 9.958496   Top5 49.848633   BatchTime 0.250832   LR 0.001106   
2022-11-25 13:39:53,924 - INFO  - Training [38][  180/  196]   Loss 2.303088   Top1 9.947917   Top5 49.748264   BatchTime 0.257442   LR 0.001103   
2022-11-25 13:39:58,959 - INFO  - ==> Top1: 9.960    Top5: 49.792    Loss: 2.303

2022-11-25 13:39:59,170 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:40:00,575 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:40:03,301 - INFO  - Validation [38][   20/   40]   Loss 45.631766   Top1 10.253906   Top5 50.214844   BatchTime 0.136186   
2022-11-25 13:40:04,409 - INFO  - Validation [38][   40/   40]   Loss 45.788757   Top1 10.000000   Top5 50.000000   BatchTime 0.095808   
2022-11-25 13:40:04,631 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 45.789

2022-11-25 13:40:04,632 - INFO  - ==> Sparsity : 0.271

2022-11-25 13:40:04,632 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:40:04,632 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:40:04,632 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 10.000   Top5: 50.000]
2022-11-25 13:40:04,795 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:40:04,797 - INFO  - >>>>>> Epoch  39
2022-11-25 13:40:04,799 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:40:11,336 - INFO  - Training [39][   20/  196]   Loss 2.303596   Top1 9.238281   Top5 49.980469   BatchTime 0.326698   LR 0.001097   
2022-11-25 13:40:15,886 - INFO  - Training [39][   40/  196]   Loss 2.303182   Top1 9.931641   Top5 50.205078   BatchTime 0.277107   LR 0.001094   
2022-11-25 13:40:20,846 - INFO  - Training [39][   60/  196]   Loss 2.303204   Top1 9.928385   Top5 50.006510   BatchTime 0.267405   LR 0.001090   
2022-11-25 13:40:26,252 - INFO  - Training [39][   80/  196]   Loss 2.303064   Top1 9.799805   Top5 50.195312   BatchTime 0.268123   LR 0.001087   
2022-11-25 13:40:31,975 - INFO  - Training [39][  100/  196]   Loss 2.303020   Top1 9.835938   Top5 50.246094   BatchTime 0.271731   LR 0.001084   
2022-11-25 13:40:37,831 - INFO  - Training [39][  120/  196]   Loss 2.303107   Top1 9.785156   Top5 49.964193   BatchTime 0.275241   LR 0.001080   
2022-11-25 13:40:43,961 - INFO  - Training [39][  140/  196]   Loss 2.303121   Top1 9.704241   Top5 49.860491   BatchTime 0.279708   LR 0.001077   
2022-11-25 13:40:49,340 - INFO  - Training [39][  160/  196]   Loss 2.303056   Top1 9.819336   Top5 49.936523   BatchTime 0.278365   LR 0.001073   
2022-11-25 13:40:54,087 - INFO  - Training [39][  180/  196]   Loss 2.303043   Top1 9.880642   Top5 49.921875   BatchTime 0.273806   LR 0.001070   
2022-11-25 13:40:58,183 - INFO  - ==> Top1: 9.868    Top5: 49.774    Loss: 2.303

2022-11-25 13:40:58,385 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:40:59,511 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:41:02,242 - INFO  - Validation [39][   20/   40]   Loss 43.501040   Top1 10.253906   Top5 50.214844   BatchTime 0.136497   
2022-11-25 13:41:03,334 - INFO  - Validation [39][   40/   40]   Loss 43.648147   Top1 10.000000   Top5 50.000000   BatchTime 0.095555   
2022-11-25 13:41:03,569 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 43.648

2022-11-25 13:41:03,569 - INFO  - ==> Sparsity : 0.271

2022-11-25 13:41:03,570 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:41:03,570 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:41:03,570 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 10.000   Top5: 50.000]
2022-11-25 13:41:03,980 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:41:03,981 - INFO  - >>>>>> Epoch  40
2022-11-25 13:41:03,983 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:41:09,897 - INFO  - Training [40][   20/  196]   Loss 2.302855   Top1 10.097656   Top5 50.507812   BatchTime 0.295544   LR 0.001064   
2022-11-25 13:41:14,531 - INFO  - Training [40][   40/  196]   Loss 2.303158   Top1 9.990234   Top5 50.292969   BatchTime 0.263637   LR 0.001060   
2022-11-25 13:41:19,149 - INFO  - Training [40][   60/  196]   Loss 2.303119   Top1 9.785156   Top5 50.123698   BatchTime 0.252718   LR 0.001056   
2022-11-25 13:41:24,253 - INFO  - Training [40][   80/  196]   Loss 2.303028   Top1 9.863281   Top5 50.043945   BatchTime 0.253336   LR 0.001053   
2022-11-25 13:41:28,671 - INFO  - Training [40][  100/  196]   Loss 2.303042   Top1 9.804688   Top5 50.050781   BatchTime 0.246852   LR 0.001049   
2022-11-25 13:41:32,909 - INFO  - Training [40][  120/  196]   Loss 2.303099   Top1 9.833984   Top5 49.873047   BatchTime 0.241024   LR 0.001045   
2022-11-25 13:41:37,477 - INFO  - Training [40][  140/  196]   Loss 2.303059   Top1 9.882812   Top5 49.866071   BatchTime 0.239217   LR 0.001042   
2022-11-25 13:41:42,028 - INFO  - Training [40][  160/  196]   Loss 2.303045   Top1 9.948730   Top5 49.846191   BatchTime 0.237758   LR 0.001038   
2022-11-25 13:41:46,569 - INFO  - Training [40][  180/  196]   Loss 2.303007   Top1 9.906684   Top5 49.796007   BatchTime 0.236572   LR 0.001034   
2022-11-25 13:41:50,318 - INFO  - ==> Top1: 9.890    Top5: 49.928    Loss: 2.303

2022-11-25 13:41:50,495 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:41:51,575 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:41:54,162 - INFO  - Validation [40][   20/   40]   Loss 42.986398   Top1 10.253906   Top5 50.214844   BatchTime 0.129266   
2022-11-25 13:41:55,250 - INFO  - Validation [40][   40/   40]   Loss 43.132325   Top1 10.000000   Top5 50.000000   BatchTime 0.091837   
2022-11-25 13:41:55,525 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 43.132

2022-11-25 13:41:55,525 - INFO  - ==> Sparsity : 0.271

2022-11-25 13:41:55,525 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:41:55,525 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:41:55,526 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 10.000   Top5: 50.000]
2022-11-25 13:41:55,671 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:41:55,673 - INFO  - >>>>>> Epoch  41
2022-11-25 13:41:55,674 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:42:02,925 - INFO  - Training [41][   20/  196]   Loss 2.302877   Top1 9.824219   Top5 50.859375   BatchTime 0.362402   LR 0.001027   
2022-11-25 13:42:08,464 - INFO  - Training [41][   40/  196]   Loss 2.303077   Top1 9.414062   Top5 50.107422   BatchTime 0.319665   LR 0.001023   
2022-11-25 13:42:13,728 - INFO  - Training [41][   60/  196]   Loss 2.303039   Top1 9.550781   Top5 49.895833   BatchTime 0.300841   LR 0.001020   
2022-11-25 13:42:18,862 - INFO  - Training [41][   80/  196]   Loss 2.302980   Top1 9.687500   Top5 50.014648   BatchTime 0.289805   LR 0.001016   
2022-11-25 13:42:24,112 - INFO  - Training [41][  100/  196]   Loss 2.302967   Top1 9.796875   Top5 50.085938   BatchTime 0.284349   LR 0.001012   
2022-11-25 13:42:29,061 - INFO  - Training [41][  120/  196]   Loss 2.303011   Top1 9.889323   Top5 49.957682   BatchTime 0.278199   LR 0.001008   
2022-11-25 13:42:34,076 - INFO  - Training [41][  140/  196]   Loss 2.302947   Top1 9.969308   Top5 50.136719   BatchTime 0.274278   LR 0.001004   
2022-11-25 13:42:39,072 - INFO  - Training [41][  160/  196]   Loss 2.302903   Top1 10.034180   Top5 50.258789   BatchTime 0.271216   LR 0.001000   
2022-11-25 13:42:44,104 - INFO  - Training [41][  180/  196]   Loss 2.302895   Top1 10.045573   Top5 50.164931   BatchTime 0.269034   LR 0.000996   
2022-11-25 13:42:48,263 - INFO  - ==> Top1: 10.066    Top5: 50.178    Loss: 2.303

2022-11-25 13:42:48,452 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:42:49,382 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:42:51,826 - INFO  - Validation [41][   20/   40]   Loss 36.980595   Top1 10.253906   Top5 50.214844   BatchTime 0.122154   
2022-11-25 13:42:52,829 - INFO  - Validation [41][   40/   40]   Loss 37.104587   Top1 10.000000   Top5 50.000000   BatchTime 0.086138   
2022-11-25 13:42:53,089 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 37.105

2022-11-25 13:42:53,089 - INFO  - ==> Sparsity : 0.271

2022-11-25 13:42:53,089 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:42:53,090 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:42:53,090 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 10.000   Top5: 50.000]
2022-11-25 13:42:53,491 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:42:53,493 - INFO  - >>>>>> Epoch  42
2022-11-25 13:42:53,495 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:42:59,716 - INFO  - Training [42][   20/  196]   Loss 2.302629   Top1 10.390625   Top5 50.175781   BatchTime 0.310965   LR 0.000988   
2022-11-25 13:43:04,313 - INFO  - Training [42][   40/  196]   Loss 2.302867   Top1 10.292969   Top5 49.912109   BatchTime 0.270394   LR 0.000984   
2022-11-25 13:43:09,271 - INFO  - Training [42][   60/  196]   Loss 2.302867   Top1 10.319010   Top5 50.071615   BatchTime 0.262896   LR 0.000980   
2022-11-25 13:43:14,318 - INFO  - Training [42][   80/  196]   Loss 2.302857   Top1 10.166016   Top5 50.043945   BatchTime 0.260256   LR 0.000976   
2022-11-25 13:43:20,258 - INFO  - Training [42][  100/  196]   Loss 2.302963   Top1 10.007812   Top5 49.730469   BatchTime 0.267606   LR 0.000972   
2022-11-25 13:43:25,051 - INFO  - Training [42][  120/  196]   Loss 2.302918   Top1 10.061849   Top5 49.905599   BatchTime 0.262951   LR 0.000968   
2022-11-25 13:43:29,779 - INFO  - Training [42][  140/  196]   Loss 2.302960   Top1 9.980469   Top5 49.910714   BatchTime 0.259153   LR 0.000964   
2022-11-25 13:43:34,816 - INFO  - Training [42][  160/  196]   Loss 2.302950   Top1 9.973145   Top5 49.899902   BatchTime 0.258238   LR 0.000959   
2022-11-25 13:43:39,830 - INFO  - Training [42][  180/  196]   Loss 2.303007   Top1 9.963108   Top5 49.913194   BatchTime 0.257404   LR 0.000955   
2022-11-25 13:43:43,993 - INFO  - ==> Top1: 9.976    Top5: 49.942    Loss: 2.303

2022-11-25 13:43:44,218 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:43:45,416 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:43:48,080 - INFO  - Validation [42][   20/   40]   Loss 37.126526   Top1 10.253906   Top5 50.214844   BatchTime 0.133099   
2022-11-25 13:43:49,240 - INFO  - Validation [42][   40/   40]   Loss 37.253994   Top1 10.000000   Top5 50.000000   BatchTime 0.095561   
2022-11-25 13:43:49,455 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 37.254

2022-11-25 13:43:49,455 - INFO  - ==> Sparsity : 0.271

2022-11-25 13:43:49,456 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:43:49,456 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:43:49,456 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 10.000   Top5: 50.000]
2022-11-25 13:43:49,574 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:43:49,575 - INFO  - >>>>>> Epoch  43
2022-11-25 13:43:49,577 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:43:55,819 - INFO  - Training [43][   20/  196]   Loss 2.302339   Top1 10.312500   Top5 50.722656   BatchTime 0.311961   LR 0.000947   
2022-11-25 13:44:00,625 - INFO  - Training [43][   40/  196]   Loss 2.302456   Top1 10.107422   Top5 50.117188   BatchTime 0.276149   LR 0.000943   
2022-11-25 13:44:05,624 - INFO  - Training [43][   60/  196]   Loss 2.302754   Top1 9.863281   Top5 49.811198   BatchTime 0.267405   LR 0.000939   
2022-11-25 13:44:10,408 - INFO  - Training [43][   80/  196]   Loss 2.302952   Top1 9.819336   Top5 49.394531   BatchTime 0.260353   LR 0.000934   
2022-11-25 13:44:15,780 - INFO  - Training [43][  100/  196]   Loss 2.302993   Top1 9.746094   Top5 49.273438   BatchTime 0.261999   LR 0.000930   
2022-11-25 13:44:20,510 - INFO  - Training [43][  120/  196]   Loss 2.303007   Top1 9.817708   Top5 49.195964   BatchTime 0.257748   LR 0.000926   
2022-11-25 13:44:25,307 - INFO  - Training [43][  140/  196]   Loss 2.302995   Top1 9.796317   Top5 49.282924   BatchTime 0.255193   LR 0.000921   
2022-11-25 13:44:30,033 - INFO  - Training [43][  160/  196]   Loss 2.302985   Top1 9.841309   Top5 49.270020   BatchTime 0.252832   LR 0.000917   
2022-11-25 13:44:34,479 - INFO  - Training [43][  180/  196]   Loss 2.302963   Top1 9.891493   Top5 49.379340   BatchTime 0.249440   LR 0.000912   
2022-11-25 13:44:38,487 - INFO  - ==> Top1: 9.884    Top5: 49.346    Loss: 2.303

2022-11-25 13:44:38,766 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:44:40,436 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:44:42,905 - INFO  - Validation [43][   20/   40]   Loss 36.026351   Top1 10.253906   Top5 50.214844   BatchTime 0.123397   
2022-11-25 13:44:43,933 - INFO  - Validation [43][   40/   40]   Loss 36.149903   Top1 10.000000   Top5 50.000000   BatchTime 0.087401   
2022-11-25 13:44:44,159 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 36.150

2022-11-25 13:44:44,159 - INFO  - ==> Sparsity : 0.271

2022-11-25 13:44:44,160 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:44:44,160 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:44:44,160 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 10.000   Top5: 50.000]
2022-11-25 13:44:44,304 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:44:44,305 - INFO  - >>>>>> Epoch  44
2022-11-25 13:44:44,307 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:44:50,616 - INFO  - Training [44][   20/  196]   Loss 2.302984   Top1 9.902344   Top5 49.863281   BatchTime 0.315286   LR 0.000904   
2022-11-25 13:44:55,607 - INFO  - Training [44][   40/  196]   Loss 2.303178   Top1 9.912109   Top5 49.423828   BatchTime 0.282432   LR 0.000900   
2022-11-25 13:45:00,547 - INFO  - Training [44][   60/  196]   Loss 2.303188   Top1 9.830729   Top5 49.218750   BatchTime 0.270616   LR 0.000895   
2022-11-25 13:45:05,568 - INFO  - Training [44][   80/  196]   Loss 2.303215   Top1 9.833984   Top5 49.135742   BatchTime 0.265724   LR 0.000891   
2022-11-25 13:45:10,566 - INFO  - Training [44][  100/  196]   Loss 2.303134   Top1 9.867188   Top5 49.523438   BatchTime 0.262558   LR 0.000886   
2022-11-25 13:45:15,666 - INFO  - Training [44][  120/  196]   Loss 2.303034   Top1 9.905599   Top5 49.641927   BatchTime 0.261296   LR 0.000882   
2022-11-25 13:45:20,563 - INFO  - Training [44][  140/  196]   Loss 2.302954   Top1 9.896763   Top5 49.707031   BatchTime 0.258947   LR 0.000877   
2022-11-25 13:45:25,808 - INFO  - Training [44][  160/  196]   Loss 2.302912   Top1 9.909668   Top5 49.790039   BatchTime 0.259358   LR 0.000873   
2022-11-25 13:45:30,963 - INFO  - Training [44][  180/  196]   Loss 2.302935   Top1 9.809028   Top5 49.787326   BatchTime 0.259183   LR 0.000868   
2022-11-25 13:45:35,038 - INFO  - ==> Top1: 9.790    Top5: 49.824    Loss: 2.303

2022-11-25 13:45:35,454 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:45:36,829 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:45:39,342 - INFO  - Validation [44][   20/   40]   Loss 36.499133   Top1 10.253906   Top5 50.214844   BatchTime 0.125555   
2022-11-25 13:45:40,366 - INFO  - Validation [44][   40/   40]   Loss 36.624191   Top1 10.000000   Top5 50.000000   BatchTime 0.088366   
2022-11-25 13:45:40,584 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 36.624

2022-11-25 13:45:40,584 - INFO  - ==> Sparsity : 0.271

2022-11-25 13:45:40,584 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:45:40,585 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:45:40,585 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 10.000   Top5: 50.000]
2022-11-25 13:45:40,726 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:45:40,727 - INFO  - >>>>>> Epoch  45
2022-11-25 13:45:40,729 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:45:46,712 - INFO  - Training [45][   20/  196]   Loss 2.302981   Top1 10.585938   Top5 49.140625   BatchTime 0.298994   LR 0.000860   
2022-11-25 13:45:51,063 - INFO  - Training [45][   40/  196]   Loss 2.302804   Top1 10.253906   Top5 49.765625   BatchTime 0.258279   LR 0.000855   
2022-11-25 13:45:55,482 - INFO  - Training [45][   60/  196]   Loss 2.302942   Top1 10.182292   Top5 49.602865   BatchTime 0.245843   LR 0.000850   
2022-11-25 13:45:59,921 - INFO  - Training [45][   80/  196]   Loss 2.302869   Top1 10.244141   Top5 49.716797   BatchTime 0.239862   LR 0.000846   
2022-11-25 13:46:04,513 - INFO  - Training [45][  100/  196]   Loss 2.302928   Top1 10.187500   Top5 49.640625   BatchTime 0.237816   LR 0.000841   
2022-11-25 13:46:09,372 - INFO  - Training [45][  120/  196]   Loss 2.302895   Top1 10.152995   Top5 49.674479   BatchTime 0.238667   LR 0.000836   
2022-11-25 13:46:15,504 - INFO  - Training [45][  140/  196]   Loss 2.302820   Top1 10.189732   Top5 49.829799   BatchTime 0.248370   LR 0.000832   
2022-11-25 13:46:21,639 - INFO  - Training [45][  160/  196]   Loss 2.302857   Top1 10.202637   Top5 49.863281   BatchTime 0.255666   LR 0.000827   
2022-11-25 13:46:27,779 - INFO  - Training [45][  180/  196]   Loss 2.302878   Top1 10.186632   Top5 49.871962   BatchTime 0.261372   LR 0.000822   
2022-11-25 13:46:32,791 - INFO  - ==> Top1: 10.196    Top5: 49.830    Loss: 2.303

2022-11-25 13:46:32,976 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:46:34,151 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:46:36,641 - INFO  - Validation [45][   20/   40]   Loss 29.772500   Top1 10.253906   Top5 50.214844   BatchTime 0.124379   
2022-11-25 13:46:37,788 - INFO  - Validation [45][   40/   40]   Loss 29.873142   Top1 10.000000   Top5 50.000000   BatchTime 0.090887   
2022-11-25 13:46:38,001 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 29.873

2022-11-25 13:46:38,001 - INFO  - ==> Sparsity : 0.271

2022-11-25 13:46:38,002 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:46:38,002 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:46:38,002 - INFO  - Scoreboard best 3 ==> Epoch [45][Top1: 10.000   Top5: 50.000]
2022-11-25 13:46:38,137 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:46:38,139 - INFO  - >>>>>> Epoch  46
2022-11-25 13:46:38,141 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:46:45,664 - INFO  - Training [46][   20/  196]   Loss 2.302825   Top1 9.648438   Top5 50.175781   BatchTime 0.376041   LR 0.000814   
2022-11-25 13:46:51,785 - INFO  - Training [46][   40/  196]   Loss 2.302910   Top1 9.853516   Top5 50.224609   BatchTime 0.341033   LR 0.000809   
2022-11-25 13:46:57,872 - INFO  - Training [46][   60/  196]   Loss 2.302831   Top1 9.882812   Top5 50.403646   BatchTime 0.328803   LR 0.000804   
2022-11-25 13:47:04,002 - INFO  - Training [46][   80/  196]   Loss 2.302817   Top1 9.863281   Top5 50.292969   BatchTime 0.323237   LR 0.000799   
2022-11-25 13:47:09,355 - INFO  - Training [46][  100/  196]   Loss 2.302808   Top1 9.925781   Top5 50.066406   BatchTime 0.312118   LR 0.000794   
2022-11-25 13:47:13,873 - INFO  - Training [46][  120/  196]   Loss 2.302816   Top1 9.938151   Top5 50.094401   BatchTime 0.297742   LR 0.000789   
2022-11-25 13:47:18,560 - INFO  - Training [46][  140/  196]   Loss 2.302867   Top1 9.988839   Top5 50.013951   BatchTime 0.288686   LR 0.000785   
2022-11-25 13:47:23,361 - INFO  - Training [46][  160/  196]   Loss 2.302887   Top1 9.934082   Top5 49.919434   BatchTime 0.282609   LR 0.000780   
2022-11-25 13:47:27,842 - INFO  - Training [46][  180/  196]   Loss 2.302921   Top1 9.902344   Top5 49.724392   BatchTime 0.276100   LR 0.000775   
2022-11-25 13:47:31,631 - INFO  - ==> Top1: 9.850    Top5: 49.536    Loss: 2.303

2022-11-25 13:47:31,870 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:47:33,002 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:47:35,585 - INFO  - Validation [46][   20/   40]   Loss 48.901380   Top1 10.253906   Top5 50.214844   BatchTime 0.129047   
2022-11-25 13:47:36,723 - INFO  - Validation [46][   40/   40]   Loss 49.069843   Top1 10.000000   Top5 50.000000   BatchTime 0.092994   
2022-11-25 13:47:36,939 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 49.070

2022-11-25 13:47:36,939 - INFO  - ==> Sparsity : 0.271

2022-11-25 13:47:36,939 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:47:36,940 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:47:36,940 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 10.000   Top5: 50.000]
2022-11-25 13:47:37,059 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:47:37,061 - INFO  - >>>>>> Epoch  47
2022-11-25 13:47:37,062 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:47:43,338 - INFO  - Training [47][   20/  196]   Loss 2.302904   Top1 9.550781   Top5 49.511719   BatchTime 0.313680   LR 0.000766   
2022-11-25 13:47:48,342 - INFO  - Training [47][   40/  196]   Loss 2.302770   Top1 9.833984   Top5 50.273438   BatchTime 0.281920   LR 0.000761   
2022-11-25 13:47:53,237 - INFO  - Training [47][   60/  196]   Loss 2.302952   Top1 9.895833   Top5 50.045573   BatchTime 0.269532   LR 0.000756   
2022-11-25 13:47:57,861 - INFO  - Training [47][   80/  196]   Loss 2.302926   Top1 9.946289   Top5 50.004883   BatchTime 0.259956   LR 0.000752   
2022-11-25 13:48:02,985 - INFO  - Training [47][  100/  196]   Loss 2.302869   Top1 10.046875   Top5 49.964844   BatchTime 0.259195   LR 0.000747   
2022-11-25 13:48:08,404 - INFO  - Training [47][  120/  196]   Loss 2.302848   Top1 10.065104   Top5 50.042318   BatchTime 0.261156   LR 0.000742   
2022-11-25 13:48:13,380 - INFO  - Training [47][  140/  196]   Loss 2.302942   Top1 9.966518   Top5 49.921875   BatchTime 0.259390   LR 0.000737   
2022-11-25 13:48:18,365 - INFO  - Training [47][  160/  196]   Loss 2.302858   Top1 9.980469   Top5 50.021973   BatchTime 0.258126   LR 0.000732   
2022-11-25 13:48:23,476 - INFO  - Training [47][  180/  196]   Loss 2.302913   Top1 9.895833   Top5 49.898003   BatchTime 0.257837   LR 0.000727   
2022-11-25 13:48:27,612 - INFO  - ==> Top1: 9.870    Top5: 49.868    Loss: 2.303

2022-11-25 13:48:27,792 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:48:28,932 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:48:31,422 - INFO  - Validation [47][   20/   40]   Loss 45.660366   Top1 10.253906   Top5 50.214844   BatchTime 0.124409   
2022-11-25 13:48:32,483 - INFO  - Validation [47][   40/   40]   Loss 45.819242   Top1 10.000000   Top5 50.000000   BatchTime 0.088753   
2022-11-25 13:48:32,687 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 45.819

2022-11-25 13:48:32,687 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:48:32,687 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:48:32,687 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:48:32,687 - INFO  - Scoreboard best 3 ==> Epoch [47][Top1: 10.000   Top5: 50.000]
2022-11-25 13:48:32,805 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:48:32,807 - INFO  - >>>>>> Epoch  48
2022-11-25 13:48:32,809 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:48:39,031 - INFO  - Training [48][   20/  196]   Loss 2.303063   Top1 9.492188   Top5 49.980469   BatchTime 0.311001   LR 0.000718   
2022-11-25 13:48:43,696 - INFO  - Training [48][   40/  196]   Loss 2.303067   Top1 9.863281   Top5 49.570312   BatchTime 0.272121   LR 0.000713   
2022-11-25 13:48:48,814 - INFO  - Training [48][   60/  196]   Loss 2.302875   Top1 9.993490   Top5 49.980469   BatchTime 0.266711   LR 0.000708   
2022-11-25 13:48:53,828 - INFO  - Training [48][   80/  196]   Loss 2.302853   Top1 10.078125   Top5 49.902344   BatchTime 0.262709   LR 0.000703   
2022-11-25 13:48:58,861 - INFO  - Training [48][  100/  196]   Loss 2.302880   Top1 10.105469   Top5 49.757812   BatchTime 0.260498   LR 0.000698   
2022-11-25 13:49:03,974 - INFO  - Training [48][  120/  196]   Loss 2.302888   Top1 10.130208   Top5 49.788411   BatchTime 0.259687   LR 0.000693   
2022-11-25 13:49:08,695 - INFO  - Training [48][  140/  196]   Loss 2.302982   Top1 9.910714   Top5 49.695871   BatchTime 0.256309   LR 0.000688   
2022-11-25 13:49:13,373 - INFO  - Training [48][  160/  196]   Loss 2.302984   Top1 9.943848   Top5 49.729004   BatchTime 0.253511   LR 0.000683   
2022-11-25 13:49:18,234 - INFO  - Training [48][  180/  196]   Loss 2.302959   Top1 9.928385   Top5 49.785156   BatchTime 0.252348   LR 0.000678   
2022-11-25 13:49:21,932 - INFO  - ==> Top1: 9.952    Top5: 49.848    Loss: 2.303

2022-11-25 13:49:22,153 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:49:23,420 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:49:25,971 - INFO  - Validation [48][   20/   40]   Loss 44.203104   Top1 10.253906   Top5 50.214844   BatchTime 0.127507   
2022-11-25 13:49:27,056 - INFO  - Validation [48][   40/   40]   Loss 44.356135   Top1 10.000000   Top5 50.000000   BatchTime 0.090864   
2022-11-25 13:49:27,288 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 44.356

2022-11-25 13:49:27,288 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:49:27,289 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:49:27,289 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:49:27,289 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 10.000   Top5: 50.000]
2022-11-25 13:49:27,404 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:49:27,406 - INFO  - >>>>>> Epoch  49
2022-11-25 13:49:27,408 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:49:33,603 - INFO  - Training [49][   20/  196]   Loss 2.303170   Top1 9.628906   Top5 48.437500   BatchTime 0.309663   LR 0.000669   
2022-11-25 13:49:38,112 - INFO  - Training [49][   40/  196]   Loss 2.303081   Top1 10.058594   Top5 49.130859   BatchTime 0.267547   LR 0.000664   
2022-11-25 13:49:43,035 - INFO  - Training [49][   60/  196]   Loss 2.303066   Top1 10.019531   Top5 49.277344   BatchTime 0.260409   LR 0.000659   
2022-11-25 13:49:48,038 - INFO  - Training [49][   80/  196]   Loss 2.302955   Top1 9.902344   Top5 49.594727   BatchTime 0.257845   LR 0.000654   
2022-11-25 13:49:53,054 - INFO  - Training [49][  100/  196]   Loss 2.302968   Top1 9.937500   Top5 49.718750   BatchTime 0.256437   LR 0.000649   
2022-11-25 13:49:57,804 - INFO  - Training [49][  120/  196]   Loss 2.302957   Top1 9.866536   Top5 49.843750   BatchTime 0.253284   LR 0.000644   
2022-11-25 13:50:02,854 - INFO  - Training [49][  140/  196]   Loss 2.302907   Top1 9.815848   Top5 49.846540   BatchTime 0.253170   LR 0.000639   
2022-11-25 13:50:08,380 - INFO  - Training [49][  160/  196]   Loss 2.302886   Top1 9.836426   Top5 49.848633   BatchTime 0.256057   LR 0.000634   
2022-11-25 13:50:14,545 - INFO  - Training [49][  180/  196]   Loss 2.302867   Top1 9.878472   Top5 49.815538   BatchTime 0.261855   LR 0.000629   
2022-11-25 13:50:19,306 - INFO  - ==> Top1: 9.902    Top5: 49.748    Loss: 2.303

2022-11-25 13:50:19,516 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:50:20,878 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:50:23,354 - INFO  - Validation [49][   20/   40]   Loss 42.515286   Top1 10.253906   Top5 50.214844   BatchTime 0.123705   
2022-11-25 13:50:24,342 - INFO  - Validation [49][   40/   40]   Loss 42.662280   Top1 10.000000   Top5 50.000000   BatchTime 0.086545   
2022-11-25 13:50:24,602 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 42.662

2022-11-25 13:50:24,602 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:50:24,602 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:50:24,602 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:50:24,603 - INFO  - Scoreboard best 3 ==> Epoch [49][Top1: 10.000   Top5: 50.000]
2022-11-25 13:50:24,765 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:50:24,766 - INFO  - >>>>>> Epoch  50
2022-11-25 13:50:24,768 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:50:30,568 - INFO  - Training [50][   20/  196]   Loss 2.302890   Top1 9.863281   Top5 49.941406   BatchTime 0.289862   LR 0.000620   
2022-11-25 13:50:35,068 - INFO  - Training [50][   40/  196]   Loss 2.303021   Top1 9.873047   Top5 49.550781   BatchTime 0.257426   LR 0.000615   
2022-11-25 13:50:39,312 - INFO  - Training [50][   60/  196]   Loss 2.302974   Top1 9.837240   Top5 49.830729   BatchTime 0.242357   LR 0.000610   
2022-11-25 13:50:43,772 - INFO  - Training [50][   80/  196]   Loss 2.302924   Top1 9.931641   Top5 49.765625   BatchTime 0.237505   LR 0.000605   
2022-11-25 13:50:48,515 - INFO  - Training [50][  100/  196]   Loss 2.302974   Top1 9.875000   Top5 49.761719   BatchTime 0.237433   LR 0.000600   
2022-11-25 13:50:53,073 - INFO  - Training [50][  120/  196]   Loss 2.303028   Top1 9.768880   Top5 49.677734   BatchTime 0.235850   LR 0.000595   
2022-11-25 13:50:57,986 - INFO  - Training [50][  140/  196]   Loss 2.302996   Top1 9.824219   Top5 49.709821   BatchTime 0.237247   LR 0.000590   
2022-11-25 13:51:03,403 - INFO  - Training [50][  160/  196]   Loss 2.303011   Top1 9.711914   Top5 49.560547   BatchTime 0.241445   LR 0.000585   
2022-11-25 13:51:08,673 - INFO  - Training [50][  180/  196]   Loss 2.303000   Top1 9.704861   Top5 49.613715   BatchTime 0.243895   LR 0.000580   
2022-11-25 13:51:12,818 - INFO  - ==> Top1: 9.712    Top5: 49.554    Loss: 2.303

2022-11-25 13:51:13,015 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:51:13,971 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:51:16,585 - INFO  - Validation [50][   20/   40]   Loss 41.038318   Top1 10.253906   Top5 50.214844   BatchTime 0.130631   
2022-11-25 13:51:17,666 - INFO  - Validation [50][   40/   40]   Loss 41.182097   Top1 10.000000   Top5 50.000000   BatchTime 0.092343   
2022-11-25 13:51:17,912 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 41.182

2022-11-25 13:51:17,912 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:51:17,913 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:51:17,913 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:51:17,913 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 10.000   Top5: 50.000]
2022-11-25 13:51:18,030 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:51:18,032 - INFO  - >>>>>> Epoch  51
2022-11-25 13:51:18,033 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:51:24,769 - INFO  - Training [51][   20/  196]   Loss 2.302922   Top1 9.726562   Top5 49.062500   BatchTime 0.336660   LR 0.000571   
2022-11-25 13:51:29,672 - INFO  - Training [51][   40/  196]   Loss 2.302939   Top1 9.912109   Top5 49.433594   BatchTime 0.290897   LR 0.000566   
2022-11-25 13:51:34,692 - INFO  - Training [51][   60/  196]   Loss 2.302844   Top1 9.941406   Top5 49.713542   BatchTime 0.277609   LR 0.000561   
2022-11-25 13:51:39,403 - INFO  - Training [51][   80/  196]   Loss 2.302863   Top1 9.931641   Top5 49.672852   BatchTime 0.267085   LR 0.000556   
2022-11-25 13:51:44,351 - INFO  - Training [51][  100/  196]   Loss 2.302869   Top1 9.859375   Top5 49.656250   BatchTime 0.263148   LR 0.000551   
2022-11-25 13:51:49,368 - INFO  - Training [51][  120/  196]   Loss 2.302897   Top1 9.833984   Top5 49.573568   BatchTime 0.261100   LR 0.000546   
2022-11-25 13:51:54,468 - INFO  - Training [51][  140/  196]   Loss 2.302917   Top1 9.860491   Top5 49.564732   BatchTime 0.260227   LR 0.000541   
2022-11-25 13:52:00,523 - INFO  - Training [51][  160/  196]   Loss 2.302912   Top1 9.851074   Top5 49.655762   BatchTime 0.265544   LR 0.000536   
2022-11-25 13:52:05,539 - INFO  - Training [51][  180/  196]   Loss 2.302894   Top1 9.865451   Top5 49.628906   BatchTime 0.263905   LR 0.000531   
2022-11-25 13:52:09,649 - INFO  - ==> Top1: 9.868    Top5: 49.714    Loss: 2.303

2022-11-25 13:52:09,874 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:52:11,013 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:52:13,568 - INFO  - Validation [51][   20/   40]   Loss 46.212422   Top1 10.253906   Top5 50.214844   BatchTime 0.127681   
2022-11-25 13:52:14,639 - INFO  - Validation [51][   40/   40]   Loss 46.372534   Top1 10.000000   Top5 50.000000   BatchTime 0.090606   
2022-11-25 13:52:14,865 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 46.373

2022-11-25 13:52:14,866 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:52:14,866 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:52:14,866 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:52:14,866 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 10.000   Top5: 50.000]
2022-11-25 13:52:14,987 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:52:14,988 - INFO  - >>>>>> Epoch  52
2022-11-25 13:52:14,990 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:52:20,949 - INFO  - Training [52][   20/  196]   Loss 2.302667   Top1 10.039062   Top5 49.160156   BatchTime 0.297827   LR 0.000523   
2022-11-25 13:52:25,522 - INFO  - Training [52][   40/  196]   Loss 2.302663   Top1 10.058594   Top5 49.619141   BatchTime 0.263238   LR 0.000518   
2022-11-25 13:52:30,105 - INFO  - Training [52][   60/  196]   Loss 2.302714   Top1 10.078125   Top5 49.335938   BatchTime 0.251877   LR 0.000513   
2022-11-25 13:52:35,082 - INFO  - Training [52][   80/  196]   Loss 2.302748   Top1 10.136719   Top5 49.580078   BatchTime 0.251121   LR 0.000508   
2022-11-25 13:52:40,059 - INFO  - Training [52][  100/  196]   Loss 2.302757   Top1 10.121094   Top5 49.632812   BatchTime 0.250665   LR 0.000503   
2022-11-25 13:52:45,053 - INFO  - Training [52][  120/  196]   Loss 2.302781   Top1 10.029297   Top5 49.622396   BatchTime 0.250508   LR 0.000498   
2022-11-25 13:52:50,387 - INFO  - Training [52][  140/  196]   Loss 2.302740   Top1 10.131138   Top5 49.726562   BatchTime 0.252817   LR 0.000493   
2022-11-25 13:52:55,435 - INFO  - Training [52][  160/  196]   Loss 2.302758   Top1 10.144043   Top5 49.785156   BatchTime 0.252766   LR 0.000488   
2022-11-25 13:52:59,827 - INFO  - Training [52][  180/  196]   Loss 2.302750   Top1 10.117188   Top5 49.765625   BatchTime 0.249077   LR 0.000483   
2022-11-25 13:53:03,761 - INFO  - ==> Top1: 10.048    Top5: 49.650    Loss: 2.303

2022-11-25 13:53:03,962 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:53:04,931 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:53:07,575 - INFO  - Validation [52][   20/   40]   Loss 47.399948   Top1 10.253906   Top5 50.214844   BatchTime 0.132096   
2022-11-25 13:53:08,652 - INFO  - Validation [52][   40/   40]   Loss 47.564392   Top1 10.000000   Top5 50.000000   BatchTime 0.092970   
2022-11-25 13:53:08,902 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.564

2022-11-25 13:53:08,902 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:53:08,902 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:53:08,903 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:53:08,903 - INFO  - Scoreboard best 3 ==> Epoch [52][Top1: 10.000   Top5: 50.000]
2022-11-25 13:53:09,064 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:53:09,065 - INFO  - >>>>>> Epoch  53
2022-11-25 13:53:09,067 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:53:15,231 - INFO  - Training [53][   20/  196]   Loss 2.302714   Top1 10.371094   Top5 49.667969   BatchTime 0.308060   LR 0.000474   
2022-11-25 13:53:19,727 - INFO  - Training [53][   40/  196]   Loss 2.302742   Top1 10.224609   Top5 50.175781   BatchTime 0.266444   LR 0.000470   
2022-11-25 13:53:24,610 - INFO  - Training [53][   60/  196]   Loss 2.302688   Top1 10.130208   Top5 50.468750   BatchTime 0.259008   LR 0.000465   
2022-11-25 13:53:29,484 - INFO  - Training [53][   80/  196]   Loss 2.302722   Top1 10.073242   Top5 50.083008   BatchTime 0.255177   LR 0.000460   
2022-11-25 13:53:34,343 - INFO  - Training [53][  100/  196]   Loss 2.302896   Top1 9.949219   Top5 49.636719   BatchTime 0.252728   LR 0.000455   
2022-11-25 13:53:39,283 - INFO  - Training [53][  120/  196]   Loss 2.302884   Top1 9.899089   Top5 49.713542   BatchTime 0.251776   LR 0.000450   
2022-11-25 13:53:44,296 - INFO  - Training [53][  140/  196]   Loss 2.302951   Top1 9.801897   Top5 49.573103   BatchTime 0.251616   LR 0.000445   
2022-11-25 13:53:49,090 - INFO  - Training [53][  160/  196]   Loss 2.302944   Top1 9.807129   Top5 49.704590   BatchTime 0.250126   LR 0.000441   
2022-11-25 13:53:54,224 - INFO  - Training [53][  180/  196]   Loss 2.302928   Top1 9.819878   Top5 49.756944   BatchTime 0.250853   LR 0.000436   
2022-11-25 13:53:58,016 - INFO  - ==> Top1: 9.806    Top5: 49.722    Loss: 2.303

2022-11-25 13:53:58,267 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:53:59,760 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:54:02,229 - INFO  - Validation [53][   20/   40]   Loss 44.664213   Top1 10.253906   Top5 50.214844   BatchTime 0.123414   
2022-11-25 13:54:03,301 - INFO  - Validation [53][   40/   40]   Loss 44.820480   Top1 10.000000   Top5 50.000000   BatchTime 0.088491   
2022-11-25 13:54:03,507 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 44.820

2022-11-25 13:54:03,508 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:54:03,508 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:54:03,509 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:54:03,509 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 10.000   Top5: 50.000]
2022-11-25 13:54:03,685 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:54:03,687 - INFO  - >>>>>> Epoch  54
2022-11-25 13:54:03,689 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:54:09,676 - INFO  - Training [54][   20/  196]   Loss 2.302581   Top1 10.156250   Top5 50.722656   BatchTime 0.299199   LR 0.000427   
2022-11-25 13:54:14,446 - INFO  - Training [54][   40/  196]   Loss 2.302521   Top1 9.824219   Top5 50.449219   BatchTime 0.268863   LR 0.000423   
2022-11-25 13:54:19,246 - INFO  - Training [54][   60/  196]   Loss 2.302589   Top1 9.785156   Top5 50.553385   BatchTime 0.259234   LR 0.000418   
2022-11-25 13:54:23,886 - INFO  - Training [54][   80/  196]   Loss 2.302659   Top1 9.750977   Top5 50.405273   BatchTime 0.252431   LR 0.000413   
2022-11-25 13:54:28,761 - INFO  - Training [54][  100/  196]   Loss 2.302731   Top1 9.691406   Top5 50.175781   BatchTime 0.250692   LR 0.000408   
2022-11-25 13:54:33,525 - INFO  - Training [54][  120/  196]   Loss 2.302762   Top1 9.674479   Top5 49.934896   BatchTime 0.248607   LR 0.000404   
2022-11-25 13:54:38,097 - INFO  - Training [54][  140/  196]   Loss 2.302777   Top1 9.673549   Top5 49.824219   BatchTime 0.245746   LR 0.000399   
2022-11-25 13:54:42,568 - INFO  - Training [54][  160/  196]   Loss 2.302814   Top1 9.670410   Top5 49.807129   BatchTime 0.242972   LR 0.000394   
2022-11-25 13:54:47,166 - INFO  - Training [54][  180/  196]   Loss 2.302788   Top1 9.832899   Top5 49.796007   BatchTime 0.241522   LR 0.000390   
2022-11-25 13:54:51,502 - INFO  - ==> Top1: 9.858    Top5: 49.720    Loss: 2.303

2022-11-25 13:54:51,766 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:54:53,115 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:54:55,748 - INFO  - Validation [54][   20/   40]   Loss 44.495374   Top1 10.253906   Top5 50.214844   BatchTime 0.131567   
2022-11-25 13:54:56,875 - INFO  - Validation [54][   40/   40]   Loss 44.652284   Top1 10.000000   Top5 50.000000   BatchTime 0.093965   
2022-11-25 13:54:57,101 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 44.652

2022-11-25 13:54:57,102 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:54:57,102 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:54:57,102 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:54:57,102 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 10.000   Top5: 50.000]
2022-11-25 13:54:57,220 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:54:57,221 - INFO  - >>>>>> Epoch  55
2022-11-25 13:54:57,223 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:55:03,143 - INFO  - Training [55][   20/  196]   Loss 2.302702   Top1 10.312500   Top5 49.980469   BatchTime 0.295841   LR 0.000381   
2022-11-25 13:55:07,754 - INFO  - Training [55][   40/  196]   Loss 2.302606   Top1 10.048828   Top5 50.361328   BatchTime 0.263214   LR 0.000377   
2022-11-25 13:55:12,554 - INFO  - Training [55][   60/  196]   Loss 2.302764   Top1 9.934896   Top5 49.837240   BatchTime 0.255476   LR 0.000372   
2022-11-25 13:55:17,529 - INFO  - Training [55][   80/  196]   Loss 2.302775   Top1 9.960938   Top5 49.682617   BatchTime 0.253785   LR 0.000368   
2022-11-25 13:55:22,239 - INFO  - Training [55][  100/  196]   Loss 2.302812   Top1 9.921875   Top5 49.496094   BatchTime 0.250126   LR 0.000363   
2022-11-25 13:55:26,797 - INFO  - Training [55][  120/  196]   Loss 2.302839   Top1 9.889323   Top5 49.661458   BatchTime 0.246425   LR 0.000358   
2022-11-25 13:55:31,390 - INFO  - Training [55][  140/  196]   Loss 2.302839   Top1 9.919085   Top5 49.690290   BatchTime 0.244026   LR 0.000354   
2022-11-25 13:55:36,361 - INFO  - Training [55][  160/  196]   Loss 2.302907   Top1 9.863281   Top5 49.504395   BatchTime 0.244595   LR 0.000349   
2022-11-25 13:55:41,365 - INFO  - Training [55][  180/  196]   Loss 2.302950   Top1 9.756944   Top5 49.440104   BatchTime 0.245216   LR 0.000345   
2022-11-25 13:55:45,891 - INFO  - ==> Top1: 9.820    Top5: 49.470    Loss: 2.303

2022-11-25 13:55:46,123 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:55:47,305 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:55:49,915 - INFO  - Validation [55][   20/   40]   Loss 35.337687   Top1 10.253906   Top5 50.214844   BatchTime 0.130397   
2022-11-25 13:55:51,076 - INFO  - Validation [55][   40/   40]   Loss 35.458949   Top1 10.000000   Top5 50.000000   BatchTime 0.094244   
2022-11-25 13:55:51,331 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 35.459

2022-11-25 13:55:51,332 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:55:51,332 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:55:51,332 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:55:51,332 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 10.000   Top5: 50.000]
2022-11-25 13:55:51,503 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:55:51,505 - INFO  - >>>>>> Epoch  56
2022-11-25 13:55:51,507 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:55:58,199 - INFO  - Training [56][   20/  196]   Loss 2.302870   Top1 10.273438   Top5 49.394531   BatchTime 0.334462   LR 0.000337   
2022-11-25 13:56:02,741 - INFO  - Training [56][   40/  196]   Loss 2.302792   Top1 10.185547   Top5 49.570312   BatchTime 0.280773   LR 0.000333   
2022-11-25 13:56:07,340 - INFO  - Training [56][   60/  196]   Loss 2.302798   Top1 10.032552   Top5 49.733073   BatchTime 0.263841   LR 0.000328   
2022-11-25 13:56:12,068 - INFO  - Training [56][   80/  196]   Loss 2.302843   Top1 9.887695   Top5 49.790039   BatchTime 0.256976   LR 0.000324   
2022-11-25 13:56:17,049 - INFO  - Training [56][  100/  196]   Loss 2.302858   Top1 9.953125   Top5 49.765625   BatchTime 0.255393   LR 0.000319   
2022-11-25 13:56:22,046 - INFO  - Training [56][  120/  196]   Loss 2.302886   Top1 10.042318   Top5 49.648438   BatchTime 0.254463   LR 0.000315   
2022-11-25 13:56:26,709 - INFO  - Training [56][  140/  196]   Loss 2.302873   Top1 10.106027   Top5 49.561942   BatchTime 0.251418   LR 0.000311   
2022-11-25 13:56:31,297 - INFO  - Training [56][  160/  196]   Loss 2.302888   Top1 10.039062   Top5 49.626465   BatchTime 0.248666   LR 0.000306   
2022-11-25 13:56:35,850 - INFO  - Training [56][  180/  196]   Loss 2.302882   Top1 9.991319   Top5 49.620226   BatchTime 0.246329   LR 0.000302   
2022-11-25 13:56:39,616 - INFO  - ==> Top1: 10.000    Top5: 49.682    Loss: 2.303

2022-11-25 13:56:39,865 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:56:41,468 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:56:44,283 - INFO  - Validation [56][   20/   40]   Loss 38.531119   Top1 10.253906   Top5 50.214844   BatchTime 0.140653   
2022-11-25 13:56:45,341 - INFO  - Validation [56][   40/   40]   Loss 38.663107   Top1 10.000000   Top5 50.000000   BatchTime 0.096795   
2022-11-25 13:56:45,550 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 38.663

2022-11-25 13:56:45,551 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:56:45,551 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:56:45,551 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:56:45,551 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 10.000   Top5: 50.000]
2022-11-25 13:56:45,701 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:56:45,703 - INFO  - >>>>>> Epoch  57
2022-11-25 13:56:45,705 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:56:52,334 - INFO  - Training [57][   20/  196]   Loss 2.302885   Top1 9.863281   Top5 49.570312   BatchTime 0.331350   LR 0.000294   
2022-11-25 13:56:57,348 - INFO  - Training [57][   40/  196]   Loss 2.302752   Top1 9.765625   Top5 49.628906   BatchTime 0.291020   LR 0.000290   
2022-11-25 13:57:02,480 - INFO  - Training [57][   60/  196]   Loss 2.302840   Top1 9.576823   Top5 49.479167   BatchTime 0.279548   LR 0.000286   
2022-11-25 13:57:07,481 - INFO  - Training [57][   80/  196]   Loss 2.302690   Top1 9.858398   Top5 49.921875   BatchTime 0.272163   LR 0.000282   
2022-11-25 13:57:12,460 - INFO  - Training [57][  100/  196]   Loss 2.302686   Top1 9.937500   Top5 49.812500   BatchTime 0.267523   LR 0.000277   
2022-11-25 13:57:17,396 - INFO  - Training [57][  120/  196]   Loss 2.302646   Top1 9.983724   Top5 50.117188   BatchTime 0.264073   LR 0.000273   
2022-11-25 13:57:22,450 - INFO  - Training [57][  140/  196]   Loss 2.302669   Top1 9.986049   Top5 50.142299   BatchTime 0.262447   LR 0.000269   
2022-11-25 13:57:27,732 - INFO  - Training [57][  160/  196]   Loss 2.302688   Top1 9.968262   Top5 50.109863   BatchTime 0.262651   LR 0.000265   
2022-11-25 13:57:32,737 - INFO  - Training [57][  180/  196]   Loss 2.302705   Top1 9.932726   Top5 50.043403   BatchTime 0.261272   LR 0.000261   
2022-11-25 13:57:36,778 - INFO  - ==> Top1: 9.930    Top5: 50.092    Loss: 2.303

2022-11-25 13:57:36,962 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:57:38,986 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:57:41,549 - INFO  - Validation [57][   20/   40]   Loss 38.249504   Top1 10.253906   Top5 50.214844   BatchTime 0.128078   
2022-11-25 13:57:42,886 - INFO  - Validation [57][   40/   40]   Loss 38.381375   Top1 10.000000   Top5 50.000000   BatchTime 0.097463   
2022-11-25 13:57:43,118 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 38.381

2022-11-25 13:57:43,118 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:57:43,119 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:57:43,119 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:57:43,119 - INFO  - Scoreboard best 3 ==> Epoch [57][Top1: 10.000   Top5: 50.000]
2022-11-25 13:57:43,278 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:57:43,280 - INFO  - >>>>>> Epoch  58
2022-11-25 13:57:43,281 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:57:49,201 - INFO  - Training [58][   20/  196]   Loss 2.302621   Top1 9.902344   Top5 49.824219   BatchTime 0.295866   LR 0.000254   
2022-11-25 13:57:53,815 - INFO  - Training [58][   40/  196]   Loss 2.302874   Top1 10.175781   Top5 49.667969   BatchTime 0.263267   LR 0.000250   
2022-11-25 13:57:58,763 - INFO  - Training [58][   60/  196]   Loss 2.302746   Top1 10.123698   Top5 49.817708   BatchTime 0.257980   LR 0.000246   
2022-11-25 13:58:04,310 - INFO  - Training [58][   80/  196]   Loss 2.302776   Top1 10.004883   Top5 49.794922   BatchTime 0.262818   LR 0.000242   
2022-11-25 13:58:09,180 - INFO  - Training [58][  100/  196]   Loss 2.302744   Top1 10.218750   Top5 49.730469   BatchTime 0.258961   LR 0.000238   
2022-11-25 13:58:14,026 - INFO  - Training [58][  120/  196]   Loss 2.302749   Top1 10.081380   Top5 49.671224   BatchTime 0.256176   LR 0.000234   
2022-11-25 13:58:18,880 - INFO  - Training [58][  140/  196]   Loss 2.302741   Top1 10.106027   Top5 49.684710   BatchTime 0.254257   LR 0.000230   
2022-11-25 13:58:23,844 - INFO  - Training [58][  160/  196]   Loss 2.302770   Top1 10.112305   Top5 49.685059   BatchTime 0.253495   LR 0.000226   
2022-11-25 13:58:28,886 - INFO  - Training [58][  180/  196]   Loss 2.302787   Top1 10.045573   Top5 49.680990   BatchTime 0.253341   LR 0.000222   
2022-11-25 13:58:33,099 - INFO  - ==> Top1: 9.970    Top5: 49.652    Loss: 2.303

2022-11-25 13:58:33,337 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:58:34,554 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:58:37,233 - INFO  - Validation [58][   20/   40]   Loss 36.612827   Top1 10.253906   Top5 50.214844   BatchTime 0.133885   
2022-11-25 13:58:38,205 - INFO  - Validation [58][   40/   40]   Loss 36.738423   Top1 10.000000   Top5 50.000000   BatchTime 0.091256   
2022-11-25 13:58:38,512 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 36.738

2022-11-25 13:58:38,512 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:58:38,512 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:58:38,512 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:58:38,513 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 10.000   Top5: 50.000]
2022-11-25 13:58:38,641 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:58:38,642 - INFO  - >>>>>> Epoch  59
2022-11-25 13:58:38,644 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:58:45,013 - INFO  - Training [59][   20/  196]   Loss 2.303158   Top1 9.375000   Top5 49.765625   BatchTime 0.318302   LR 0.000215   
2022-11-25 13:58:49,371 - INFO  - Training [59][   40/  196]   Loss 2.303101   Top1 9.580078   Top5 49.765625   BatchTime 0.268099   LR 0.000212   
2022-11-25 13:58:53,992 - INFO  - Training [59][   60/  196]   Loss 2.302915   Top1 9.667969   Top5 50.227865   BatchTime 0.255746   LR 0.000208   
2022-11-25 13:58:58,281 - INFO  - Training [59][   80/  196]   Loss 2.302875   Top1 9.692383   Top5 50.195312   BatchTime 0.245422   LR 0.000204   
2022-11-25 13:59:02,579 - INFO  - Training [59][  100/  196]   Loss 2.302802   Top1 9.718750   Top5 50.335938   BatchTime 0.239319   LR 0.000201   
2022-11-25 13:59:07,050 - INFO  - Training [59][  120/  196]   Loss 2.302845   Top1 9.749349   Top5 50.074870   BatchTime 0.236692   LR 0.000197   
2022-11-25 13:59:11,469 - INFO  - Training [59][  140/  196]   Loss 2.302839   Top1 9.704241   Top5 49.972098   BatchTime 0.234445   LR 0.000193   
2022-11-25 13:59:15,699 - INFO  - Training [59][  160/  196]   Loss 2.302823   Top1 9.780273   Top5 49.982910   BatchTime 0.231576   LR 0.000190   
2022-11-25 13:59:19,849 - INFO  - Training [59][  180/  196]   Loss 2.302811   Top1 9.796007   Top5 49.965278   BatchTime 0.228897   LR 0.000186   
2022-11-25 13:59:23,306 - INFO  - ==> Top1: 9.808    Top5: 49.852    Loss: 2.303

2022-11-25 13:59:23,494 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:59:24,696 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:59:27,238 - INFO  - Validation [59][   20/   40]   Loss 40.837832   Top1 10.253906   Top5 50.214844   BatchTime 0.127016   
2022-11-25 13:59:28,331 - INFO  - Validation [59][   40/   40]   Loss 40.979012   Top1 10.000000   Top5 50.000000   BatchTime 0.090837   
2022-11-25 13:59:28,548 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 40.979

2022-11-25 13:59:28,549 - INFO  - ==> Sparsity : 0.272

2022-11-25 13:59:28,549 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 13:59:28,549 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 13:59:28,549 - INFO  - Scoreboard best 3 ==> Epoch [59][Top1: 10.000   Top5: 50.000]
2022-11-25 13:59:28,718 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:59:28,720 - INFO  - >>>>>> Epoch  60
2022-11-25 13:59:28,722 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:59:35,660 - INFO  - Training [60][   20/  196]   Loss 2.302997   Top1 10.332031   Top5 48.769531   BatchTime 0.346766   LR 0.000180   
2022-11-25 13:59:41,047 - INFO  - Training [60][   40/  196]   Loss 2.302954   Top1 9.990234   Top5 49.433594   BatchTime 0.308070   LR 0.000176   
2022-11-25 13:59:46,006 - INFO  - Training [60][   60/  196]   Loss 2.302804   Top1 10.058594   Top5 49.661458   BatchTime 0.288013   LR 0.000173   
2022-11-25 13:59:50,704 - INFO  - Training [60][   80/  196]   Loss 2.302851   Top1 9.907227   Top5 49.453125   BatchTime 0.274742   LR 0.000169   
2022-11-25 13:59:55,203 - INFO  - Training [60][  100/  196]   Loss 2.302823   Top1 9.921875   Top5 49.554688   BatchTime 0.264779   LR 0.000166   
2022-11-25 13:59:59,665 - INFO  - Training [60][  120/  196]   Loss 2.302869   Top1 9.840495   Top5 49.534505   BatchTime 0.257836   LR 0.000162   
2022-11-25 14:00:04,209 - INFO  - Training [60][  140/  196]   Loss 2.302830   Top1 9.852121   Top5 49.720982   BatchTime 0.253454   LR 0.000159   
2022-11-25 14:00:08,727 - INFO  - Training [60][  160/  196]   Loss 2.302779   Top1 9.848633   Top5 49.721680   BatchTime 0.250012   LR 0.000156   
2022-11-25 14:00:13,149 - INFO  - Training [60][  180/  196]   Loss 2.302787   Top1 9.887153   Top5 49.720052   BatchTime 0.246798   LR 0.000152   
2022-11-25 14:00:16,986 - INFO  - ==> Top1: 9.902    Top5: 49.660    Loss: 2.303

2022-11-25 14:00:17,187 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:00:18,307 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:00:20,880 - INFO  - Validation [60][   20/   40]   Loss 44.705653   Top1 10.253906   Top5 50.214844   BatchTime 0.128576   
2022-11-25 14:00:21,978 - INFO  - Validation [60][   40/   40]   Loss 44.859769   Top1 10.000000   Top5 50.000000   BatchTime 0.091739   
2022-11-25 14:00:22,259 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 44.860

2022-11-25 14:00:22,260 - INFO  - ==> Sparsity : 0.272

2022-11-25 14:00:22,260 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 14:00:22,260 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 14:00:22,260 - INFO  - Scoreboard best 3 ==> Epoch [60][Top1: 10.000   Top5: 50.000]
2022-11-25 14:00:22,408 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:00:22,410 - INFO  - >>>>>> Epoch  61
2022-11-25 14:00:22,412 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:00:30,111 - INFO  - Training [61][   20/  196]   Loss 2.302898   Top1 10.000000   Top5 49.511719   BatchTime 0.384845   LR 0.000147   
2022-11-25 14:00:35,482 - INFO  - Training [61][   40/  196]   Loss 2.302929   Top1 9.375000   Top5 49.257812   BatchTime 0.326685   LR 0.000143   
2022-11-25 14:00:39,753 - INFO  - Training [61][   60/  196]   Loss 2.302867   Top1 9.667969   Top5 49.687500   BatchTime 0.288979   LR 0.000140   
2022-11-25 14:00:44,042 - INFO  - Training [61][   80/  196]   Loss 2.302835   Top1 9.873047   Top5 49.750977   BatchTime 0.270351   LR 0.000137   
2022-11-25 14:00:48,284 - INFO  - Training [61][  100/  196]   Loss 2.302854   Top1 9.886719   Top5 49.738281   BatchTime 0.258701   LR 0.000134   
2022-11-25 14:00:52,459 - INFO  - Training [61][  120/  196]   Loss 2.302825   Top1 9.931641   Top5 49.749349   BatchTime 0.250374   LR 0.000131   
2022-11-25 14:00:56,599 - INFO  - Training [61][  140/  196]   Loss 2.302838   Top1 9.913504   Top5 49.707031   BatchTime 0.244177   LR 0.000128   
2022-11-25 14:01:01,087 - INFO  - Training [61][  160/  196]   Loss 2.302866   Top1 9.914551   Top5 49.799805   BatchTime 0.241704   LR 0.000125   
2022-11-25 14:01:05,337 - INFO  - Training [61][  180/  196]   Loss 2.302904   Top1 9.858941   Top5 49.735243   BatchTime 0.238457   LR 0.000122   
2022-11-25 14:01:09,067 - INFO  - ==> Top1: 9.884    Top5: 49.768    Loss: 2.303

2022-11-25 14:01:09,276 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:01:10,419 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:01:12,952 - INFO  - Validation [61][   20/   40]   Loss 47.742422   Top1 10.253906   Top5 50.214844   BatchTime 0.126579   
2022-11-25 14:01:14,046 - INFO  - Validation [61][   40/   40]   Loss 47.906875   Top1 10.000000   Top5 50.000000   BatchTime 0.090644   
2022-11-25 14:01:14,281 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.907

2022-11-25 14:01:14,281 - INFO  - ==> Sparsity : 0.272

2022-11-25 14:01:14,281 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 14:01:14,281 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 14:01:14,282 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 10.000   Top5: 50.000]
2022-11-25 14:01:14,402 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:01:14,403 - INFO  - >>>>>> Epoch  62
2022-11-25 14:01:14,405 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:01:21,104 - INFO  - Training [62][   20/  196]   Loss 2.302888   Top1 10.566406   Top5 49.257812   BatchTime 0.334831   LR 0.000117   
2022-11-25 14:01:25,810 - INFO  - Training [62][   40/  196]   Loss 2.302844   Top1 10.185547   Top5 49.335938   BatchTime 0.285065   LR 0.000114   
2022-11-25 14:01:30,535 - INFO  - Training [62][   60/  196]   Loss 2.302853   Top1 10.006510   Top5 49.511719   BatchTime 0.268781   LR 0.000111   
2022-11-25 14:01:36,098 - INFO  - Training [62][   80/  196]   Loss 2.302803   Top1 10.039062   Top5 49.877930   BatchTime 0.271133   LR 0.000108   
2022-11-25 14:01:40,811 - INFO  - Training [62][  100/  196]   Loss 2.302759   Top1 10.062500   Top5 49.941406   BatchTime 0.264032   LR 0.000105   
2022-11-25 14:01:45,615 - INFO  - Training [62][  120/  196]   Loss 2.302715   Top1 10.065104   Top5 49.957682   BatchTime 0.260061   LR 0.000102   
2022-11-25 14:01:50,603 - INFO  - Training [62][  140/  196]   Loss 2.302702   Top1 10.119978   Top5 49.946987   BatchTime 0.258536   LR 0.000100   
2022-11-25 14:01:55,575 - INFO  - Training [62][  160/  196]   Loss 2.302706   Top1 10.063477   Top5 49.895020   BatchTime 0.257292   LR 0.000097   
2022-11-25 14:02:00,576 - INFO  - Training [62][  180/  196]   Loss 2.302711   Top1 9.963108   Top5 49.822049   BatchTime 0.256486   LR 0.000094   
2022-11-25 14:02:04,740 - INFO  - ==> Top1: 9.920    Top5: 49.828    Loss: 2.303

2022-11-25 14:02:04,992 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:02:06,385 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:02:08,939 - INFO  - Validation [62][   20/   40]   Loss 48.772469   Top1 10.253906   Top5 50.214844   BatchTime 0.127589   
2022-11-25 14:02:09,983 - INFO  - Validation [62][   40/   40]   Loss 48.942976   Top1 10.000000   Top5 50.000000   BatchTime 0.089912   
2022-11-25 14:02:10,218 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 48.943

2022-11-25 14:02:10,219 - INFO  - ==> Sparsity : 0.272

2022-11-25 14:02:10,219 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 14:02:10,219 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 14:02:10,219 - INFO  - Scoreboard best 3 ==> Epoch [62][Top1: 10.000   Top5: 50.000]
2022-11-25 14:02:10,338 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:02:10,340 - INFO  - >>>>>> Epoch  63
2022-11-25 14:02:10,341 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:02:16,818 - INFO  - Training [63][   20/  196]   Loss 2.302628   Top1 9.648438   Top5 49.882812   BatchTime 0.323690   LR 0.000090   
2022-11-25 14:02:21,846 - INFO  - Training [63][   40/  196]   Loss 2.302645   Top1 10.009766   Top5 49.726562   BatchTime 0.287544   LR 0.000087   
2022-11-25 14:02:26,774 - INFO  - Training [63][   60/  196]   Loss 2.302632   Top1 9.895833   Top5 50.006510   BatchTime 0.273841   LR 0.000085   
2022-11-25 14:02:32,115 - INFO  - Training [63][   80/  196]   Loss 2.302631   Top1 10.009766   Top5 50.073242   BatchTime 0.272139   LR 0.000082   
2022-11-25 14:02:36,639 - INFO  - Training [63][  100/  196]   Loss 2.302687   Top1 9.925781   Top5 49.941406   BatchTime 0.262953   LR 0.000080   
2022-11-25 14:02:41,124 - INFO  - Training [63][  120/  196]   Loss 2.302708   Top1 9.863281   Top5 49.820964   BatchTime 0.256502   LR 0.000077   
2022-11-25 14:02:46,016 - INFO  - Training [63][  140/  196]   Loss 2.302747   Top1 9.829799   Top5 49.726562   BatchTime 0.254799   LR 0.000075   
2022-11-25 14:02:50,585 - INFO  - Training [63][  160/  196]   Loss 2.302727   Top1 9.853516   Top5 49.765625   BatchTime 0.251508   LR 0.000072   
2022-11-25 14:02:55,267 - INFO  - Training [63][  180/  196]   Loss 2.302700   Top1 9.932726   Top5 49.793837   BatchTime 0.249568   LR 0.000070   
2022-11-25 14:02:59,106 - INFO  - ==> Top1: 9.926    Top5: 49.808    Loss: 2.303

2022-11-25 14:02:59,302 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:03:00,457 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:03:02,959 - INFO  - Validation [63][   20/   40]   Loss 47.247188   Top1 10.253906   Top5 50.214844   BatchTime 0.125017   
2022-11-25 14:03:04,013 - INFO  - Validation [63][   40/   40]   Loss 47.411246   Top1 10.000000   Top5 50.000000   BatchTime 0.088856   
2022-11-25 14:03:04,233 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.411

2022-11-25 14:03:04,234 - INFO  - ==> Sparsity : 0.272

2022-11-25 14:03:04,234 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 14:03:04,234 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 14:03:04,234 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 10.000   Top5: 50.000]
2022-11-25 14:03:04,350 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:03:04,352 - INFO  - >>>>>> Epoch  64
2022-11-25 14:03:04,354 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:03:10,622 - INFO  - Training [64][   20/  196]   Loss 2.302757   Top1 10.449219   Top5 50.039062   BatchTime 0.313318   LR 0.000066   
2022-11-25 14:03:15,572 - INFO  - Training [64][   40/  196]   Loss 2.302832   Top1 10.146484   Top5 49.960938   BatchTime 0.280414   LR 0.000064   
2022-11-25 14:03:20,647 - INFO  - Training [64][   60/  196]   Loss 2.302693   Top1 9.908854   Top5 50.208333   BatchTime 0.271518   LR 0.000062   
2022-11-25 14:03:25,350 - INFO  - Training [64][   80/  196]   Loss 2.302550   Top1 10.185547   Top5 50.410156   BatchTime 0.262421   LR 0.000059   
2022-11-25 14:03:30,869 - INFO  - Training [64][  100/  196]   Loss 2.302541   Top1 10.187500   Top5 50.484375   BatchTime 0.265129   LR 0.000057   
2022-11-25 14:03:35,681 - INFO  - Training [64][  120/  196]   Loss 2.302609   Top1 10.045573   Top5 50.312500   BatchTime 0.261043   LR 0.000055   
2022-11-25 14:03:40,672 - INFO  - Training [64][  140/  196]   Loss 2.302611   Top1 10.086496   Top5 50.295759   BatchTime 0.259401   LR 0.000053   
2022-11-25 14:03:45,356 - INFO  - Training [64][  160/  196]   Loss 2.302617   Top1 10.183105   Top5 50.300293   BatchTime 0.256247   LR 0.000051   
2022-11-25 14:03:50,274 - INFO  - Training [64][  180/  196]   Loss 2.302637   Top1 10.147569   Top5 50.275608   BatchTime 0.255099   LR 0.000049   
2022-11-25 14:03:54,284 - INFO  - ==> Top1: 10.208    Top5: 50.330    Loss: 2.303

2022-11-25 14:03:54,540 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:03:55,922 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:03:58,497 - INFO  - Validation [64][   20/   40]   Loss 47.445906   Top1 10.253906   Top5 50.214844   BatchTime 0.128649   
2022-11-25 14:03:59,568 - INFO  - Validation [64][   40/   40]   Loss 47.610502   Top1 10.000000   Top5 50.000000   BatchTime 0.091107   
2022-11-25 14:03:59,831 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.611

2022-11-25 14:03:59,831 - INFO  - ==> Sparsity : 0.272

2022-11-25 14:03:59,831 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 14:03:59,831 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 14:03:59,832 - INFO  - Scoreboard best 3 ==> Epoch [64][Top1: 10.000   Top5: 50.000]
2022-11-25 14:03:59,990 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:03:59,992 - INFO  - >>>>>> Epoch  65
2022-11-25 14:03:59,994 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:04:06,366 - INFO  - Training [65][   20/  196]   Loss 2.303259   Top1 9.707031   Top5 48.457031   BatchTime 0.318483   LR 0.000046   
2022-11-25 14:04:11,491 - INFO  - Training [65][   40/  196]   Loss 2.303031   Top1 9.726562   Top5 49.472656   BatchTime 0.287366   LR 0.000044   
2022-11-25 14:04:17,271 - INFO  - Training [65][   60/  196]   Loss 2.302941   Top1 9.837240   Top5 49.570312   BatchTime 0.287898   LR 0.000042   
2022-11-25 14:04:23,344 - INFO  - Training [65][   80/  196]   Loss 2.302808   Top1 9.877930   Top5 49.765625   BatchTime 0.291834   LR 0.000040   
2022-11-25 14:04:29,192 - INFO  - Training [65][  100/  196]   Loss 2.302880   Top1 9.738281   Top5 49.675781   BatchTime 0.291954   LR 0.000039   
2022-11-25 14:04:33,570 - INFO  - Training [65][  120/  196]   Loss 2.302865   Top1 9.807943   Top5 49.752604   BatchTime 0.279776   LR 0.000037   
2022-11-25 14:04:39,130 - INFO  - Training [65][  140/  196]   Loss 2.302861   Top1 9.874442   Top5 49.592634   BatchTime 0.279518   LR 0.000035   
2022-11-25 14:04:44,242 - INFO  - Training [65][  160/  196]   Loss 2.302865   Top1 9.841309   Top5 49.672852   BatchTime 0.276528   LR 0.000033   
2022-11-25 14:04:48,372 - INFO  - Training [65][  180/  196]   Loss 2.302828   Top1 9.928385   Top5 49.832899   BatchTime 0.268748   LR 0.000032   
2022-11-25 14:04:51,755 - INFO  - ==> Top1: 9.950    Top5: 49.858    Loss: 2.303

2022-11-25 14:04:52,011 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:04:53,603 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:04:56,218 - INFO  - Validation [65][   20/   40]   Loss 46.992323   Top1 10.253906   Top5 50.214844   BatchTime 0.130641   
2022-11-25 14:04:57,329 - INFO  - Validation [65][   40/   40]   Loss 47.155453   Top1 10.000000   Top5 50.000000   BatchTime 0.093098   
2022-11-25 14:04:57,553 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.155

2022-11-25 14:04:57,554 - INFO  - ==> Sparsity : 0.272

2022-11-25 14:04:57,554 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 14:04:57,554 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 14:04:57,554 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 10.000   Top5: 50.000]
2022-11-25 14:04:57,716 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:04:57,718 - INFO  - >>>>>> Epoch  66
2022-11-25 14:04:57,720 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:05:03,887 - INFO  - Training [66][   20/  196]   Loss 2.302428   Top1 10.097656   Top5 50.664062   BatchTime 0.308215   LR 0.000029   
2022-11-25 14:05:08,545 - INFO  - Training [66][   40/  196]   Loss 2.302594   Top1 9.960938   Top5 50.253906   BatchTime 0.270545   LR 0.000028   
2022-11-25 14:05:13,395 - INFO  - Training [66][   60/  196]   Loss 2.302587   Top1 10.084635   Top5 50.058594   BatchTime 0.261197   LR 0.000026   
2022-11-25 14:05:18,395 - INFO  - Training [66][   80/  196]   Loss 2.302664   Top1 10.048828   Top5 50.078125   BatchTime 0.258404   LR 0.000025   
2022-11-25 14:05:23,923 - INFO  - Training [66][  100/  196]   Loss 2.302657   Top1 10.062500   Top5 49.941406   BatchTime 0.262001   LR 0.000023   
2022-11-25 14:05:28,721 - INFO  - Training [66][  120/  196]   Loss 2.302696   Top1 10.084635   Top5 49.886068   BatchTime 0.258312   LR 0.000022   
2022-11-25 14:05:33,942 - INFO  - Training [66][  140/  196]   Loss 2.302662   Top1 10.097656   Top5 49.969308   BatchTime 0.258705   LR 0.000021   
2022-11-25 14:05:38,838 - INFO  - Training [66][  160/  196]   Loss 2.302704   Top1 10.046387   Top5 49.885254   BatchTime 0.256967   LR 0.000019   
2022-11-25 14:05:43,921 - INFO  - Training [66][  180/  196]   Loss 2.302686   Top1 10.019531   Top5 49.906684   BatchTime 0.256656   LR 0.000018   
2022-11-25 14:05:47,758 - INFO  - ==> Top1: 10.050    Top5: 50.032    Loss: 2.303

2022-11-25 14:05:47,939 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:05:48,944 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:05:51,500 - INFO  - Validation [66][   20/   40]   Loss 47.421818   Top1 10.253906   Top5 50.214844   BatchTime 0.127725   
2022-11-25 14:05:52,581 - INFO  - Validation [66][   40/   40]   Loss 47.586262   Top1 10.000000   Top5 50.000000   BatchTime 0.090900   
2022-11-25 14:05:52,820 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.586

2022-11-25 14:05:52,820 - INFO  - ==> Sparsity : 0.272

2022-11-25 14:05:52,821 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 14:05:52,821 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 14:05:52,821 - INFO  - Scoreboard best 3 ==> Epoch [66][Top1: 10.000   Top5: 50.000]
2022-11-25 14:05:52,962 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:05:52,964 - INFO  - >>>>>> Epoch  67
2022-11-25 14:05:52,966 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:05:59,821 - INFO  - Training [67][   20/  196]   Loss 2.302887   Top1 10.312500   Top5 50.078125   BatchTime 0.342601   LR 0.000016   
2022-11-25 14:06:05,608 - INFO  - Training [67][   40/  196]   Loss 2.302731   Top1 10.263672   Top5 49.736328   BatchTime 0.315975   LR 0.000015   
2022-11-25 14:06:10,230 - INFO  - Training [67][   60/  196]   Loss 2.302775   Top1 10.045573   Top5 49.680990   BatchTime 0.287680   LR 0.000014   
2022-11-25 14:06:15,001 - INFO  - Training [67][   80/  196]   Loss 2.302726   Top1 10.078125   Top5 49.663086   BatchTime 0.275397   LR 0.000013   
2022-11-25 14:06:19,684 - INFO  - Training [67][  100/  196]   Loss 2.302682   Top1 10.074219   Top5 49.867188   BatchTime 0.267153   LR 0.000012   
2022-11-25 14:06:24,199 - INFO  - Training [67][  120/  196]   Loss 2.302689   Top1 10.039062   Top5 49.843750   BatchTime 0.260252   LR 0.000011   
2022-11-25 14:06:28,632 - INFO  - Training [67][  140/  196]   Loss 2.302693   Top1 10.053013   Top5 49.933036   BatchTime 0.254734   LR 0.000010   
2022-11-25 14:06:33,586 - INFO  - Training [67][  160/  196]   Loss 2.302709   Top1 10.058594   Top5 49.943848   BatchTime 0.253858   LR 0.000009   
2022-11-25 14:06:38,690 - INFO  - Training [67][  180/  196]   Loss 2.302761   Top1 10.101997   Top5 49.767795   BatchTime 0.254003   LR 0.000008   
2022-11-25 14:06:43,391 - INFO  - ==> Top1: 10.070    Top5: 49.734    Loss: 2.303

2022-11-25 14:06:43,645 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:06:45,233 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:06:47,886 - INFO  - Validation [67][   20/   40]   Loss 47.013233   Top1 10.253906   Top5 50.214844   BatchTime 0.132537   
2022-11-25 14:06:48,837 - INFO  - Validation [67][   40/   40]   Loss 47.176510   Top1 10.000000   Top5 50.000000   BatchTime 0.090053   
2022-11-25 14:06:49,075 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.177

2022-11-25 14:06:49,075 - INFO  - ==> Sparsity : 0.272

2022-11-25 14:06:49,076 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 14:06:49,076 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 14:06:49,076 - INFO  - Scoreboard best 3 ==> Epoch [67][Top1: 10.000   Top5: 50.000]
2022-11-25 14:06:49,208 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:06:49,210 - INFO  - >>>>>> Epoch  68
2022-11-25 14:06:49,212 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:06:55,773 - INFO  - Training [68][   20/  196]   Loss 2.302673   Top1 10.390625   Top5 49.785156   BatchTime 0.327902   LR 0.000007   
2022-11-25 14:07:00,739 - INFO  - Training [68][   40/  196]   Loss 2.302522   Top1 10.322266   Top5 50.107422   BatchTime 0.288120   LR 0.000006   
2022-11-25 14:07:05,778 - INFO  - Training [68][   60/  196]   Loss 2.302516   Top1 10.299479   Top5 50.058594   BatchTime 0.276058   LR 0.000006   
2022-11-25 14:07:10,362 - INFO  - Training [68][   80/  196]   Loss 2.302516   Top1 10.161133   Top5 50.209961   BatchTime 0.264342   LR 0.000005   
2022-11-25 14:07:15,130 - INFO  - Training [68][  100/  196]   Loss 2.302636   Top1 10.085938   Top5 50.199219   BatchTime 0.259154   LR 0.000004   
2022-11-25 14:07:20,157 - INFO  - Training [68][  120/  196]   Loss 2.302668   Top1 10.045573   Top5 50.110677   BatchTime 0.257849   LR 0.000004   
2022-11-25 14:07:24,965 - INFO  - Training [68][  140/  196]   Loss 2.302626   Top1 10.209263   Top5 50.279018   BatchTime 0.255356   LR 0.000003   
2022-11-25 14:07:29,872 - INFO  - Training [68][  160/  196]   Loss 2.302596   Top1 10.219727   Top5 50.336914   BatchTime 0.254108   LR 0.000003   
2022-11-25 14:07:34,902 - INFO  - Training [68][  180/  196]   Loss 2.302623   Top1 10.199653   Top5 50.227865   BatchTime 0.253816   LR 0.000002   
2022-11-25 14:07:38,807 - INFO  - ==> Top1: 10.158    Top5: 50.148    Loss: 2.303

2022-11-25 14:07:39,017 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:07:40,335 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:07:42,968 - INFO  - Validation [68][   20/   40]   Loss 47.307878   Top1 10.253906   Top5 50.214844   BatchTime 0.131549   
2022-11-25 14:07:43,959 - INFO  - Validation [68][   40/   40]   Loss 47.472448   Top1 10.000000   Top5 50.000000   BatchTime 0.090576   
2022-11-25 14:07:44,223 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.472

2022-11-25 14:07:44,224 - INFO  - ==> Sparsity : 0.272

2022-11-25 14:07:44,224 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 14:07:44,224 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 14:07:44,224 - INFO  - Scoreboard best 3 ==> Epoch [68][Top1: 10.000   Top5: 50.000]
2022-11-25 14:07:44,339 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:07:44,341 - INFO  - >>>>>> Epoch  69
2022-11-25 14:07:44,343 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 14:07:50,031 - INFO  - Training [69][   20/  196]   Loss 2.302662   Top1 9.570312   Top5 50.156250   BatchTime 0.284293   LR 0.000002   
2022-11-25 14:07:54,143 - INFO  - Training [69][   40/  196]   Loss 2.302766   Top1 9.990234   Top5 50.107422   BatchTime 0.244938   LR 0.000001   
2022-11-25 14:07:58,356 - INFO  - Training [69][   60/  196]   Loss 2.302754   Top1 10.039062   Top5 49.869792   BatchTime 0.233516   LR 0.000001   
2022-11-25 14:08:03,311 - INFO  - Training [69][   80/  196]   Loss 2.302705   Top1 10.034180   Top5 50.053711   BatchTime 0.237076   LR 0.000001   
2022-11-25 14:08:08,248 - INFO  - Training [69][  100/  196]   Loss 2.302734   Top1 9.996094   Top5 49.906250   BatchTime 0.239028   LR 0.000000   
2022-11-25 14:08:12,910 - INFO  - Training [69][  120/  196]   Loss 2.302728   Top1 9.925130   Top5 50.104167   BatchTime 0.238041   LR 0.000000   
2022-11-25 14:08:17,646 - INFO  - Training [69][  140/  196]   Loss 2.302711   Top1 10.030692   Top5 50.086496   BatchTime 0.237861   LR 0.000000   
2022-11-25 14:08:22,447 - INFO  - Training [69][  160/  196]   Loss 2.302705   Top1 10.056152   Top5 49.990234   BatchTime 0.238132   LR 0.000000   
2022-11-25 14:08:27,105 - INFO  - Training [69][  180/  196]   Loss 2.302726   Top1 10.028212   Top5 49.884983   BatchTime 0.237551   LR 0.000000   
2022-11-25 14:08:30,813 - INFO  - ==> Top1: 10.054    Top5: 49.926    Loss: 2.303

2022-11-25 14:08:31,049 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 14:08:32,797 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:08:35,421 - INFO  - Validation [69][   20/   40]   Loss 46.923034   Top1 10.253906   Top5 50.214844   BatchTime 0.131123   
2022-11-25 14:08:36,460 - INFO  - Validation [69][   40/   40]   Loss 47.085261   Top1 10.000000   Top5 50.000000   BatchTime 0.091525   
2022-11-25 14:08:36,656 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.085

2022-11-25 14:08:36,656 - INFO  - ==> Sparsity : 0.272

2022-11-25 14:08:36,656 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.230   Top5: 99.520]
2022-11-25 14:08:36,657 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 84.110   Top5: 99.030]
2022-11-25 14:08:36,657 - INFO  - Scoreboard best 3 ==> Epoch [69][Top1: 10.000   Top5: 50.000]
2022-11-25 14:08:36,772 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-111930/88hard_pruning_checkpoint.pth.tar

2022-11-25 14:08:36,774 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 14:08:36,774 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 14:08:39,329 - INFO  - Validation [   20/   40]   Loss 46.923034   Top1 10.253906   Top5 50.214844   BatchTime 0.127658   
2022-11-25 14:08:40,347 - INFO  - Validation [   40/   40]   Loss 47.085261   Top1 10.000000   Top5 50.000000   BatchTime 0.089269   
2022-11-25 14:08:40,526 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 47.085

2022-11-25 14:08:40,526 - INFO  - ==> Sparsity : 0.000

2022-11-25 14:08:40,527 - INFO  - Program completed sucessfully ... exiting ...
