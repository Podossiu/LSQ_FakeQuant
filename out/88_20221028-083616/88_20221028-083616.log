2022-10-28 08:36:16,115 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-083616/88_20221028-083616.log
2022-10-28 08:36:17,885 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 08:36:17,918 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-28 08:36:18,085 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 08:36:18,085 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 08:36:19,437 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 08:36:19,437 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:36:22,428 - INFO  - Validation [   20/   40]   Loss 3047.717822   Top1 12.753906   Top5 57.070312   BatchTime 0.149544   
2022-10-28 08:36:24,066 - INFO  - Validation [   40/   40]   Loss 3031.409704   Top1 12.670000   Top5 56.460000   BatchTime 0.115723   
2022-10-28 08:36:24,131 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-28 08:36:24,131 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 08:36:24,131 - INFO  - >>>>>> Epoch   0
2022-10-28 08:36:24,131 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 08:36:26,395 - INFO  - Training [0][   20/  196]   Loss 1.096289   Top1 71.308594   Top5 97.285156   BatchTime 0.113128   LR 0.001000   
2022-10-28 08:36:28,108 - INFO  - Training [0][   40/  196]   Loss 0.855736   Top1 76.347656   Top5 98.027344   BatchTime 0.099402   LR 0.001000   
2022-10-28 08:36:29,815 - INFO  - Training [0][   60/  196]   Loss 0.743810   Top1 78.782552   Top5 98.404948   BatchTime 0.094722   LR 0.001000   
2022-10-28 08:36:31,524 - INFO  - Training [0][   80/  196]   Loss 0.670478   Top1 80.332031   Top5 98.662109   BatchTime 0.092401   LR 0.001000   
2022-10-28 08:36:33,234 - INFO  - Training [0][  100/  196]   Loss 0.613272   Top1 81.718750   Top5 98.851562   BatchTime 0.091023   LR 0.001000   
2022-10-28 08:36:34,941 - INFO  - Training [0][  120/  196]   Loss 0.567600   Top1 82.835286   Top5 98.981120   BatchTime 0.090073   LR 0.001000   
2022-10-28 08:36:36,648 - INFO  - Training [0][  140/  196]   Loss 0.538431   Top1 83.535156   Top5 99.056920   BatchTime 0.089396   LR 0.001000   
2022-10-28 08:36:38,353 - INFO  - Training [0][  160/  196]   Loss 0.512746   Top1 84.194336   Top5 99.125977   BatchTime 0.088882   LR 0.001000   
2022-10-28 08:36:40,050 - INFO  - Training [0][  180/  196]   Loss 0.493594   Top1 84.654948   Top5 99.179688   BatchTime 0.088432   LR 0.001000   
2022-10-28 08:36:41,461 - INFO  - ==> Top1: 84.960    Top5: 99.210    Loss: 0.481

2022-10-28 08:36:41,582 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:36:43,206 - INFO  - Validation [0][   20/   40]   Loss 0.439370   Top1 86.386719   Top5 99.453125   BatchTime 0.081170   
2022-10-28 08:36:44,285 - INFO  - Validation [0][   40/   40]   Loss 0.427836   Top1 86.440000   Top5 99.480000   BatchTime 0.067558   
2022-10-28 08:36:44,363 - INFO  - ==> Top1: 86.440    Top5: 99.480    Loss: 0.428

2022-10-28 08:36:44,363 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:36:46,038 - INFO  - Validation [0][   20/   40]   Loss 2.517079   Top1 12.011719   Top5 49.023438   BatchTime 0.083723   
2022-10-28 08:36:46,969 - INFO  - Validation [0][   40/   40]   Loss 2.515456   Top1 12.000000   Top5 49.260000   BatchTime 0.065132   
2022-10-28 08:36:47,062 - INFO  - ==> Top1: 12.000    Top5: 49.260    Loss: 2.515

2022-10-28 08:36:47,062 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 08:36:47,062 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 12.000   Top5: 49.260]
2022-10-28 08:36:47,097 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221028-083616/88_checkpoint.pth.tar

2022-10-28 08:36:47,097 - INFO  - >>>>>> Epoch   1
2022-10-28 08:36:47,097 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 08:36:49,452 - INFO  - Training [1][   20/  196]   Loss 0.303735   Top1 89.921875   Top5 99.726562   BatchTime 0.117674   LR 0.001000   
