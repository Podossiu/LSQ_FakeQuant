2022-10-20 18:29:21,602 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_20221020-182921.log
2022-10-20 18:29:22,795 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-20 18:29:22,830 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-20 18:29:22,875 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-20 18:29:22,876 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-20 18:29:24,018 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-20 18:29:24,018 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:29:24,891 - INFO  - Validation [   20/   40]   Loss 3047.717615   Top1 12.753906   Top5 57.070312   BatchTime 0.041798   
2022-10-20 18:29:25,021 - INFO  - Validation [   40/   40]   Loss 3031.409504   Top1 12.670000   Top5 56.460000   BatchTime 0.024161   
2022-10-20 18:29:25,086 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-20 18:29:25,086 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-20 18:29:25,086 - INFO  - >>>>>> Epoch   0
2022-10-20 18:29:25,086 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:29:26,145 - INFO  - Training [0][   20/  196]   Loss 1.139152   Top1 70.117188   Top5 97.304688   BatchTime 0.052876   LR 0.001000   
2022-10-20 18:29:26,660 - INFO  - Training [0][   40/  196]   Loss 0.862339   Top1 75.966797   Top5 98.164062   BatchTime 0.039333   LR 0.001000   
2022-10-20 18:29:27,173 - INFO  - Training [0][   60/  196]   Loss 0.726084   Top1 79.127604   Top5 98.528646   BatchTime 0.034760   LR 0.001000   
2022-10-20 18:29:27,686 - INFO  - Training [0][   80/  196]   Loss 0.652414   Top1 80.708008   Top5 98.774414   BatchTime 0.032484   LR 0.001000   
2022-10-20 18:29:28,201 - INFO  - Training [0][  100/  196]   Loss 0.601200   Top1 82.015625   Top5 98.941406   BatchTime 0.031137   LR 0.001000   
2022-10-20 18:29:28,713 - INFO  - Training [0][  120/  196]   Loss 0.566465   Top1 82.871094   Top5 99.026693   BatchTime 0.030211   LR 0.001000   
2022-10-20 18:29:29,225 - INFO  - Training [0][  140/  196]   Loss 0.535287   Top1 83.624442   Top5 99.126674   BatchTime 0.029558   LR 0.001000   
2022-10-20 18:29:29,739 - INFO  - Training [0][  160/  196]   Loss 0.513832   Top1 84.145508   Top5 99.201660   BatchTime 0.029071   LR 0.001000   
2022-10-20 18:29:30,249 - INFO  - Training [0][  180/  196]   Loss 0.494310   Top1 84.613715   Top5 99.249132   BatchTime 0.028676   LR 0.001000   
2022-10-20 18:29:30,707 - INFO  - ==> Top1: 84.952    Top5: 99.278    Loss: 0.481

2022-10-20 18:29:30,728 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:29:31,356 - INFO  - Validation [0][   20/   40]   Loss 0.429199   Top1 86.796875   Top5 99.238281   BatchTime 0.031356   
2022-10-20 18:29:31,484 - INFO  - Validation [0][   40/   40]   Loss 0.418552   Top1 86.700000   Top5 99.320000   BatchTime 0.018879   
2022-10-20 18:29:31,553 - INFO  - ==> Top1: 86.700    Top5: 99.320    Loss: 0.419

2022-10-20 18:29:31,553 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:29:34,429 - INFO  - Validation [0][   20/   40]   Loss 0.429199   Top1 86.796875   Top5 99.238281   BatchTime 0.143800   
2022-10-20 18:29:36,599 - INFO  - Validation [0][   40/   40]   Loss 0.418552   Top1 86.700000   Top5 99.320000   BatchTime 0.126147   
2022-10-20 18:29:36,677 - INFO  - ==> Top1: 86.700    Top5: 99.320    Loss: 0.419

2022-10-20 18:29:36,677 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 86.700   Top5: 99.320]
2022-10-20 18:29:36,677 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-20 18:29:37,830 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_best.pth.tar
save quantized models...
2022-10-20 18:29:37,830 - INFO  - >>>>>> Epoch   1
2022-10-20 18:29:37,831 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:29:38,885 - INFO  - Training [1][   20/  196]   Loss 0.277985   Top1 90.468750   Top5 99.687500   BatchTime 0.052692   LR 0.001000   
2022-10-20 18:29:39,400 - INFO  - Training [1][   40/  196]   Loss 0.285557   Top1 90.126953   Top5 99.765625   BatchTime 0.039232   LR 0.001000   
2022-10-20 18:29:39,916 - INFO  - Training [1][   60/  196]   Loss 0.287505   Top1 89.993490   Top5 99.765625   BatchTime 0.034751   LR 0.001000   
2022-10-20 18:29:40,428 - INFO  - Training [1][   80/  196]   Loss 0.291101   Top1 89.921875   Top5 99.760742   BatchTime 0.032465   LR 0.001000   
2022-10-20 18:29:40,943 - INFO  - Training [1][  100/  196]   Loss 0.289989   Top1 90.039062   Top5 99.761719   BatchTime 0.031114   LR 0.001000   
2022-10-20 18:29:41,457 - INFO  - Training [1][  120/  196]   Loss 0.287042   Top1 90.146484   Top5 99.765625   BatchTime 0.030218   LR 0.001000   
2022-10-20 18:29:41,974 - INFO  - Training [1][  140/  196]   Loss 0.284859   Top1 90.203683   Top5 99.751674   BatchTime 0.029589   LR 0.001000   
2022-10-20 18:29:42,487 - INFO  - Training [1][  160/  196]   Loss 0.282924   Top1 90.205078   Top5 99.763184   BatchTime 0.029099   LR 0.001000   
2022-10-20 18:29:42,997 - INFO  - Training [1][  180/  196]   Loss 0.279746   Top1 90.260417   Top5 99.772135   BatchTime 0.028700   LR 0.001000   
2022-10-20 18:29:43,470 - INFO  - ==> Top1: 90.320    Top5: 99.756    Loss: 0.279

2022-10-20 18:29:43,492 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:29:44,170 - INFO  - Validation [1][   20/   40]   Loss 0.378469   Top1 88.105469   Top5 99.511719   BatchTime 0.033852   
2022-10-20 18:29:44,298 - INFO  - Validation [1][   40/   40]   Loss 0.374599   Top1 87.870000   Top5 99.530000   BatchTime 0.020118   
2022-10-20 18:29:44,367 - INFO  - ==> Top1: 87.870    Top5: 99.530    Loss: 0.375

2022-10-20 18:29:44,367 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:29:47,347 - INFO  - Validation [1][   20/   40]   Loss 0.378469   Top1 88.105469   Top5 99.511719   BatchTime 0.148962   
2022-10-20 18:29:49,550 - INFO  - Validation [1][   40/   40]   Loss 0.374599   Top1 87.870000   Top5 99.530000   BatchTime 0.129554   
2022-10-20 18:29:49,629 - INFO  - ==> Top1: 87.870    Top5: 99.530    Loss: 0.375

2022-10-20 18:29:49,629 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 87.870   Top5: 99.530]
2022-10-20 18:29:49,629 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 86.700   Top5: 99.320]
2022-10-20 18:29:49,629 - INFO  - Scoreboard best 3 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-20 18:29:50,850 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_best.pth.tar
save quantized models...
2022-10-20 18:29:50,850 - INFO  - >>>>>> Epoch   2
2022-10-20 18:29:50,851 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:29:51,909 - INFO  - Training [2][   20/  196]   Loss 0.235915   Top1 91.328125   Top5 99.824219   BatchTime 0.052911   LR 0.001000   
2022-10-20 18:29:52,425 - INFO  - Training [2][   40/  196]   Loss 0.239592   Top1 91.376953   Top5 99.824219   BatchTime 0.039359   LR 0.001000   
2022-10-20 18:29:52,944 - INFO  - Training [2][   60/  196]   Loss 0.240661   Top1 91.458333   Top5 99.804688   BatchTime 0.034878   LR 0.001000   
2022-10-20 18:29:53,459 - INFO  - Training [2][   80/  196]   Loss 0.235847   Top1 91.665039   Top5 99.814453   BatchTime 0.032597   LR 0.001000   
2022-10-20 18:29:53,976 - INFO  - Training [2][  100/  196]   Loss 0.236627   Top1 91.703125   Top5 99.824219   BatchTime 0.031246   LR 0.001000   
2022-10-20 18:29:54,489 - INFO  - Training [2][  120/  196]   Loss 0.235339   Top1 91.790365   Top5 99.833984   BatchTime 0.030311   LR 0.001000   
2022-10-20 18:29:55,003 - INFO  - Training [2][  140/  196]   Loss 0.236505   Top1 91.755022   Top5 99.835379   BatchTime 0.029655   LR 0.001000   
2022-10-20 18:29:55,518 - INFO  - Training [2][  160/  196]   Loss 0.235277   Top1 91.791992   Top5 99.838867   BatchTime 0.029169   LR 0.001000   
2022-10-20 18:29:56,029 - INFO  - Training [2][  180/  196]   Loss 0.235221   Top1 91.835938   Top5 99.850260   BatchTime 0.028764   LR 0.001000   
2022-10-20 18:29:56,511 - INFO  - ==> Top1: 91.818    Top5: 99.850    Loss: 0.236

2022-10-20 18:29:56,532 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:29:57,209 - INFO  - Validation [2][   20/   40]   Loss 0.374920   Top1 88.183594   Top5 99.492188   BatchTime 0.033806   
2022-10-20 18:29:57,336 - INFO  - Validation [2][   40/   40]   Loss 0.366935   Top1 88.350000   Top5 99.520000   BatchTime 0.020091   
2022-10-20 18:29:57,419 - INFO  - ==> Top1: 88.350    Top5: 99.520    Loss: 0.367

2022-10-20 18:29:57,419 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:30:00,420 - INFO  - Validation [2][   20/   40]   Loss 0.374920   Top1 88.183594   Top5 99.492188   BatchTime 0.150015   
2022-10-20 18:30:02,624 - INFO  - Validation [2][   40/   40]   Loss 0.366934   Top1 88.350000   Top5 99.520000   BatchTime 0.130109   
2022-10-20 18:30:02,704 - INFO  - ==> Top1: 88.350    Top5: 99.520    Loss: 0.367

2022-10-20 18:30:02,705 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 88.350   Top5: 99.520]
2022-10-20 18:30:02,705 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 87.870   Top5: 99.530]
2022-10-20 18:30:02,705 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 86.700   Top5: 99.320]
2022-10-20 18:30:04,176 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_best.pth.tar
save quantized models...
2022-10-20 18:30:04,176 - INFO  - >>>>>> Epoch   3
2022-10-20 18:30:04,176 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:30:05,273 - INFO  - Training [3][   20/  196]   Loss 0.220999   Top1 92.226562   Top5 99.902344   BatchTime 0.054834   LR 0.001000   
2022-10-20 18:30:05,792 - INFO  - Training [3][   40/  196]   Loss 0.219223   Top1 92.373047   Top5 99.873047   BatchTime 0.040373   LR 0.001000   
2022-10-20 18:30:06,305 - INFO  - Training [3][   60/  196]   Loss 0.213339   Top1 92.610677   Top5 99.863281   BatchTime 0.035472   LR 0.001000   
2022-10-20 18:30:06,820 - INFO  - Training [3][   80/  196]   Loss 0.212908   Top1 92.587891   Top5 99.877930   BatchTime 0.033035   LR 0.001000   
2022-10-20 18:30:07,335 - INFO  - Training [3][  100/  196]   Loss 0.213736   Top1 92.507812   Top5 99.878906   BatchTime 0.031582   LR 0.001000   
2022-10-20 18:30:07,851 - INFO  - Training [3][  120/  196]   Loss 0.213103   Top1 92.565104   Top5 99.882812   BatchTime 0.030621   LR 0.001000   
2022-10-20 18:30:08,366 - INFO  - Training [3][  140/  196]   Loss 0.212293   Top1 92.628348   Top5 99.893973   BatchTime 0.029923   LR 0.001000   
2022-10-20 18:30:08,880 - INFO  - Training [3][  160/  196]   Loss 0.212586   Top1 92.626953   Top5 99.882812   BatchTime 0.029395   LR 0.001000   
2022-10-20 18:30:09,391 - INFO  - Training [3][  180/  196]   Loss 0.213409   Top1 92.580295   Top5 99.882812   BatchTime 0.028965   LR 0.001000   
2022-10-20 18:30:09,870 - INFO  - ==> Top1: 92.522    Top5: 99.882    Loss: 0.214

2022-10-20 18:30:09,893 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:30:10,574 - INFO  - Validation [3][   20/   40]   Loss 0.365595   Top1 88.808594   Top5 99.589844   BatchTime 0.034016   
2022-10-20 18:30:10,701 - INFO  - Validation [3][   40/   40]   Loss 0.351780   Top1 89.070000   Top5 99.610000   BatchTime 0.020203   
2022-10-20 18:30:10,781 - INFO  - ==> Top1: 89.070    Top5: 99.610    Loss: 0.352

2022-10-20 18:30:10,781 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:30:13,741 - INFO  - Validation [3][   20/   40]   Loss 0.365595   Top1 88.808594   Top5 99.589844   BatchTime 0.147972   
2022-10-20 18:30:15,944 - INFO  - Validation [3][   40/   40]   Loss 0.351780   Top1 89.070000   Top5 99.610000   BatchTime 0.129045   
2022-10-20 18:30:16,032 - INFO  - ==> Top1: 89.070    Top5: 99.610    Loss: 0.352

2022-10-20 18:30:16,032 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 89.070   Top5: 99.610]
2022-10-20 18:30:16,032 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 88.350   Top5: 99.520]
2022-10-20 18:30:16,032 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 87.870   Top5: 99.530]
2022-10-20 18:30:17,377 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_best.pth.tar
save quantized models...
2022-10-20 18:30:17,377 - INFO  - >>>>>> Epoch   4
2022-10-20 18:30:17,377 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:30:18,466 - INFO  - Training [4][   20/  196]   Loss 0.185332   Top1 93.437500   Top5 99.921875   BatchTime 0.054407   LR 0.001000   
2022-10-20 18:30:18,985 - INFO  - Training [4][   40/  196]   Loss 0.189334   Top1 93.183594   Top5 99.931641   BatchTime 0.040169   LR 0.001000   
2022-10-20 18:30:19,505 - INFO  - Training [4][   60/  196]   Loss 0.191501   Top1 93.131510   Top5 99.921875   BatchTime 0.035448   LR 0.001000   
2022-10-20 18:30:20,021 - INFO  - Training [4][   80/  196]   Loss 0.193833   Top1 93.129883   Top5 99.897461   BatchTime 0.033032   LR 0.001000   
2022-10-20 18:30:20,536 - INFO  - Training [4][  100/  196]   Loss 0.194987   Top1 93.132812   Top5 99.902344   BatchTime 0.031582   LR 0.001000   
2022-10-20 18:30:21,050 - INFO  - Training [4][  120/  196]   Loss 0.195243   Top1 93.131510   Top5 99.902344   BatchTime 0.030602   LR 0.001000   
2022-10-20 18:30:21,565 - INFO  - Training [4][  140/  196]   Loss 0.196166   Top1 93.097098   Top5 99.902344   BatchTime 0.029908   LR 0.001000   
2022-10-20 18:30:22,081 - INFO  - Training [4][  160/  196]   Loss 0.195676   Top1 93.122559   Top5 99.890137   BatchTime 0.029393   LR 0.001000   
2022-10-20 18:30:22,592 - INFO  - Training [4][  180/  196]   Loss 0.195223   Top1 93.157552   Top5 99.891493   BatchTime 0.028968   LR 0.001000   
2022-10-20 18:30:23,077 - INFO  - ==> Top1: 93.144    Top5: 99.892    Loss: 0.196

2022-10-20 18:30:23,100 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:30:23,802 - INFO  - Validation [4][   20/   40]   Loss 0.354683   Top1 88.847656   Top5 99.628906   BatchTime 0.035078   
2022-10-20 18:30:23,930 - INFO  - Validation [4][   40/   40]   Loss 0.344338   Top1 89.210000   Top5 99.580000   BatchTime 0.020737   
2022-10-20 18:30:24,005 - INFO  - ==> Top1: 89.210    Top5: 99.580    Loss: 0.344

2022-10-20 18:30:24,005 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:30:27,027 - INFO  - Validation [4][   20/   40]   Loss 0.354683   Top1 88.847656   Top5 99.628906   BatchTime 0.151075   
2022-10-20 18:30:29,238 - INFO  - Validation [4][   40/   40]   Loss 0.344338   Top1 89.210000   Top5 99.580000   BatchTime 0.130816   
2022-10-20 18:30:29,323 - INFO  - ==> Top1: 89.210    Top5: 99.580    Loss: 0.344

2022-10-20 18:30:29,323 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 89.210   Top5: 99.580]
2022-10-20 18:30:29,323 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 89.070   Top5: 99.610]
2022-10-20 18:30:29,323 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 88.350   Top5: 99.520]
2022-10-20 18:30:30,592 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_best.pth.tar
save quantized models...
2022-10-20 18:30:30,593 - INFO  - >>>>>> Epoch   5
2022-10-20 18:30:30,593 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:30:31,739 - INFO  - Training [5][   20/  196]   Loss 0.180772   Top1 93.808594   Top5 99.941406   BatchTime 0.057182   LR 0.001000   
2022-10-20 18:30:32,257 - INFO  - Training [5][   40/  196]   Loss 0.183861   Top1 93.525391   Top5 99.902344   BatchTime 0.041539   LR 0.001000   
2022-10-20 18:30:32,776 - INFO  - Training [5][   60/  196]   Loss 0.184282   Top1 93.528646   Top5 99.889323   BatchTime 0.036343   LR 0.001000   
2022-10-20 18:30:33,295 - INFO  - Training [5][   80/  196]   Loss 0.184617   Top1 93.540039   Top5 99.897461   BatchTime 0.033749   LR 0.001000   
2022-10-20 18:30:33,810 - INFO  - Training [5][  100/  196]   Loss 0.185582   Top1 93.531250   Top5 99.910156   BatchTime 0.032146   LR 0.001000   
2022-10-20 18:30:34,329 - INFO  - Training [5][  120/  196]   Loss 0.187567   Top1 93.444010   Top5 99.912109   BatchTime 0.031111   LR 0.001000   
2022-10-20 18:30:34,846 - INFO  - Training [5][  140/  196]   Loss 0.186335   Top1 93.482143   Top5 99.913504   BatchTime 0.030359   LR 0.001000   
2022-10-20 18:30:35,360 - INFO  - Training [5][  160/  196]   Loss 0.186443   Top1 93.461914   Top5 99.921875   BatchTime 0.029781   LR 0.001000   
2022-10-20 18:30:35,871 - INFO  - Training [5][  180/  196]   Loss 0.184584   Top1 93.532986   Top5 99.924045   BatchTime 0.029311   LR 0.001000   
2022-10-20 18:30:36,362 - INFO  - ==> Top1: 93.560    Top5: 99.916    Loss: 0.183

2022-10-20 18:30:36,384 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:30:37,076 - INFO  - Validation [5][   20/   40]   Loss 0.353893   Top1 89.003906   Top5 99.648438   BatchTime 0.034584   
2022-10-20 18:30:37,204 - INFO  - Validation [5][   40/   40]   Loss 0.343790   Top1 89.240000   Top5 99.640000   BatchTime 0.020490   
2022-10-20 18:30:37,278 - INFO  - ==> Top1: 89.240    Top5: 99.640    Loss: 0.344

2022-10-20 18:30:37,278 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:30:40,351 - INFO  - Validation [5][   20/   40]   Loss 0.353893   Top1 89.003906   Top5 99.648438   BatchTime 0.153641   
2022-10-20 18:30:42,551 - INFO  - Validation [5][   40/   40]   Loss 0.343790   Top1 89.240000   Top5 99.640000   BatchTime 0.131820   
2022-10-20 18:30:42,645 - INFO  - ==> Top1: 89.240    Top5: 99.640    Loss: 0.344

2022-10-20 18:30:42,646 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 89.240   Top5: 99.640]
2022-10-20 18:30:42,646 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 89.210   Top5: 99.580]
2022-10-20 18:30:42,646 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 89.070   Top5: 99.610]
2022-10-20 18:30:43,798 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_best.pth.tar
save quantized models...
2022-10-20 18:30:43,799 - INFO  - >>>>>> Epoch   6
2022-10-20 18:30:43,799 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:30:44,962 - INFO  - Training [6][   20/  196]   Loss 0.175212   Top1 93.789062   Top5 99.980469   BatchTime 0.058112   LR 0.001000   
2022-10-20 18:30:45,479 - INFO  - Training [6][   40/  196]   Loss 0.176574   Top1 93.847656   Top5 99.921875   BatchTime 0.041982   LR 0.001000   
2022-10-20 18:30:45,996 - INFO  - Training [6][   60/  196]   Loss 0.172399   Top1 93.984375   Top5 99.928385   BatchTime 0.036607   LR 0.001000   
2022-10-20 18:30:46,514 - INFO  - Training [6][   80/  196]   Loss 0.174800   Top1 93.837891   Top5 99.931641   BatchTime 0.033927   LR 0.001000   
2022-10-20 18:30:47,026 - INFO  - Training [6][  100/  196]   Loss 0.174475   Top1 93.816406   Top5 99.933594   BatchTime 0.032266   LR 0.001000   
2022-10-20 18:30:47,540 - INFO  - Training [6][  120/  196]   Loss 0.174290   Top1 93.873698   Top5 99.921875   BatchTime 0.031171   LR 0.001000   
2022-10-20 18:30:48,057 - INFO  - Training [6][  140/  196]   Loss 0.175609   Top1 93.867188   Top5 99.921875   BatchTime 0.030409   LR 0.001000   
2022-10-20 18:30:48,578 - INFO  - Training [6][  160/  196]   Loss 0.175433   Top1 93.857422   Top5 99.924316   BatchTime 0.029862   LR 0.001000   
2022-10-20 18:30:49,088 - INFO  - Training [6][  180/  196]   Loss 0.175498   Top1 93.880208   Top5 99.926215   BatchTime 0.029376   LR 0.001000   
2022-10-20 18:30:49,575 - INFO  - ==> Top1: 93.906    Top5: 99.922    Loss: 0.174

2022-10-20 18:30:49,597 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:30:50,310 - INFO  - Validation [6][   20/   40]   Loss 0.350365   Top1 89.375000   Top5 99.687500   BatchTime 0.035609   
2022-10-20 18:30:50,437 - INFO  - Validation [6][   40/   40]   Loss 0.342363   Top1 89.530000   Top5 99.670000   BatchTime 0.021003   
2022-10-20 18:30:50,521 - INFO  - ==> Top1: 89.530    Top5: 99.670    Loss: 0.342

2022-10-20 18:30:50,521 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:30:53,557 - INFO  - Validation [6][   20/   40]   Loss 0.350365   Top1 89.375000   Top5 99.687500   BatchTime 0.151746   
2022-10-20 18:30:55,737 - INFO  - Validation [6][   40/   40]   Loss 0.342362   Top1 89.530000   Top5 99.670000   BatchTime 0.130386   
2022-10-20 18:30:55,833 - INFO  - ==> Top1: 89.530    Top5: 99.670    Loss: 0.342

2022-10-20 18:30:55,833 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 89.530   Top5: 99.670]
2022-10-20 18:30:55,833 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 89.240   Top5: 99.640]
2022-10-20 18:30:55,833 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 89.210   Top5: 99.580]
2022-10-20 18:30:57,165 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_best.pth.tar
save quantized models...
2022-10-20 18:30:57,166 - INFO  - >>>>>> Epoch   7
2022-10-20 18:30:57,166 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:30:58,286 - INFO  - Training [7][   20/  196]   Loss 0.156895   Top1 94.511719   Top5 100.000000   BatchTime 0.056007   LR 0.001000   
2022-10-20 18:30:58,803 - INFO  - Training [7][   40/  196]   Loss 0.165860   Top1 94.179688   Top5 99.960938   BatchTime 0.040917   LR 0.001000   
2022-10-20 18:30:59,319 - INFO  - Training [7][   60/  196]   Loss 0.164526   Top1 94.140625   Top5 99.960938   BatchTime 0.035880   LR 0.001000   
2022-10-20 18:30:59,838 - INFO  - Training [7][   80/  196]   Loss 0.164916   Top1 94.140625   Top5 99.960938   BatchTime 0.033392   LR 0.001000   
2022-10-20 18:31:00,351 - INFO  - Training [7][  100/  196]   Loss 0.165399   Top1 94.113281   Top5 99.953125   BatchTime 0.031843   LR 0.001000   
2022-10-20 18:31:00,867 - INFO  - Training [7][  120/  196]   Loss 0.164418   Top1 94.222005   Top5 99.941406   BatchTime 0.030840   LR 0.001000   
2022-10-20 18:31:01,385 - INFO  - Training [7][  140/  196]   Loss 0.164727   Top1 94.213170   Top5 99.944196   BatchTime 0.030132   LR 0.001000   
2022-10-20 18:31:01,904 - INFO  - Training [7][  160/  196]   Loss 0.164790   Top1 94.211426   Top5 99.946289   BatchTime 0.029606   LR 0.001000   
2022-10-20 18:31:02,413 - INFO  - Training [7][  180/  196]   Loss 0.164920   Top1 94.186198   Top5 99.943576   BatchTime 0.029147   LR 0.001000   
2022-10-20 18:31:02,907 - INFO  - ==> Top1: 94.206    Top5: 99.944    Loss: 0.164

2022-10-20 18:31:02,929 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:31:03,662 - INFO  - Validation [7][   20/   40]   Loss 0.356019   Top1 89.277344   Top5 99.570312   BatchTime 0.036621   
2022-10-20 18:31:03,790 - INFO  - Validation [7][   40/   40]   Loss 0.349445   Top1 89.270000   Top5 99.570000   BatchTime 0.021507   
2022-10-20 18:31:03,875 - INFO  - ==> Top1: 89.270    Top5: 99.570    Loss: 0.349

2022-10-20 18:31:03,875 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:31:06,878 - INFO  - Validation [7][   20/   40]   Loss 0.356019   Top1 89.277344   Top5 99.570312   BatchTime 0.150136   
2022-10-20 18:31:09,037 - INFO  - Validation [7][   40/   40]   Loss 0.349445   Top1 89.270000   Top5 99.570000   BatchTime 0.129041   
2022-10-20 18:31:09,130 - INFO  - ==> Top1: 89.270    Top5: 99.570    Loss: 0.349

2022-10-20 18:31:09,130 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 89.530   Top5: 99.670]
2022-10-20 18:31:09,130 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.270   Top5: 99.570]
2022-10-20 18:31:09,130 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 89.240   Top5: 99.640]
2022-10-20 18:31:09,176 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_checkpoint.pth.tar

2022-10-20 18:31:09,177 - INFO  - >>>>>> Epoch   8
2022-10-20 18:31:09,177 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:31:10,313 - INFO  - Training [8][   20/  196]   Loss 0.155700   Top1 94.433594   Top5 99.921875   BatchTime 0.056776   LR 0.001000   
2022-10-20 18:31:10,832 - INFO  - Training [8][   40/  196]   Loss 0.151516   Top1 94.501953   Top5 99.941406   BatchTime 0.041376   LR 0.001000   
2022-10-20 18:31:11,348 - INFO  - Training [8][   60/  196]   Loss 0.154912   Top1 94.414062   Top5 99.921875   BatchTime 0.036178   LR 0.001000   
2022-10-20 18:31:11,865 - INFO  - Training [8][   80/  196]   Loss 0.159523   Top1 94.301758   Top5 99.926758   BatchTime 0.033598   LR 0.001000   
2022-10-20 18:31:12,383 - INFO  - Training [8][  100/  196]   Loss 0.158881   Top1 94.296875   Top5 99.933594   BatchTime 0.032061   LR 0.001000   
2022-10-20 18:31:12,900 - INFO  - Training [8][  120/  196]   Loss 0.159654   Top1 94.290365   Top5 99.931641   BatchTime 0.031025   LR 0.001000   
2022-10-20 18:31:13,415 - INFO  - Training [8][  140/  196]   Loss 0.158943   Top1 94.330357   Top5 99.930246   BatchTime 0.030268   LR 0.001000   
2022-10-20 18:31:13,931 - INFO  - Training [8][  160/  196]   Loss 0.157779   Top1 94.375000   Top5 99.934082   BatchTime 0.029708   LR 0.001000   
2022-10-20 18:31:14,443 - INFO  - Training [8][  180/  196]   Loss 0.157068   Top1 94.383681   Top5 99.937066   BatchTime 0.029250   LR 0.001000   
2022-10-20 18:31:14,929 - INFO  - ==> Top1: 94.410    Top5: 99.940    Loss: 0.156

2022-10-20 18:31:14,951 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:31:15,680 - INFO  - Validation [8][   20/   40]   Loss 0.346918   Top1 89.589844   Top5 99.648438   BatchTime 0.036394   
2022-10-20 18:31:15,808 - INFO  - Validation [8][   40/   40]   Loss 0.336257   Top1 89.640000   Top5 99.650000   BatchTime 0.021401   
2022-10-20 18:31:15,901 - INFO  - ==> Top1: 89.640    Top5: 99.650    Loss: 0.336

2022-10-20 18:31:15,901 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:31:18,987 - INFO  - Validation [8][   20/   40]   Loss 0.346918   Top1 89.589844   Top5 99.648438   BatchTime 0.154277   
2022-10-20 18:31:21,154 - INFO  - Validation [8][   40/   40]   Loss 0.336257   Top1 89.640000   Top5 99.650000   BatchTime 0.131325   
2022-10-20 18:31:21,247 - INFO  - ==> Top1: 89.640    Top5: 99.650    Loss: 0.336

2022-10-20 18:31:21,247 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 89.640   Top5: 99.650]
2022-10-20 18:31:21,247 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 89.530   Top5: 99.670]
2022-10-20 18:31:21,248 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.270   Top5: 99.570]
2022-10-20 18:31:22,371 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_best.pth.tar
save quantized models...
2022-10-20 18:31:22,372 - INFO  - >>>>>> Epoch   9
2022-10-20 18:31:22,372 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:31:23,472 - INFO  - Training [9][   20/  196]   Loss 0.161362   Top1 94.472656   Top5 99.941406   BatchTime 0.054973   LR 0.001000   
2022-10-20 18:31:23,991 - INFO  - Training [9][   40/  196]   Loss 0.156617   Top1 94.726562   Top5 99.921875   BatchTime 0.040459   LR 0.001000   
2022-10-20 18:31:24,508 - INFO  - Training [9][   60/  196]   Loss 0.155192   Top1 94.746094   Top5 99.928385   BatchTime 0.035599   LR 0.001000   
2022-10-20 18:31:25,025 - INFO  - Training [9][   80/  196]   Loss 0.155077   Top1 94.741211   Top5 99.941406   BatchTime 0.033161   LR 0.001000   
2022-10-20 18:31:25,545 - INFO  - Training [9][  100/  196]   Loss 0.154074   Top1 94.742188   Top5 99.945312   BatchTime 0.031722   LR 0.001000   
2022-10-20 18:31:26,061 - INFO  - Training [9][  120/  196]   Loss 0.154074   Top1 94.729818   Top5 99.941406   BatchTime 0.030734   LR 0.001000   
2022-10-20 18:31:26,576 - INFO  - Training [9][  140/  196]   Loss 0.153010   Top1 94.779576   Top5 99.930246   BatchTime 0.030025   LR 0.001000   
2022-10-20 18:31:27,092 - INFO  - Training [9][  160/  196]   Loss 0.151726   Top1 94.846191   Top5 99.936523   BatchTime 0.029498   LR 0.001000   
2022-10-20 18:31:27,604 - INFO  - Training [9][  180/  196]   Loss 0.152579   Top1 94.791667   Top5 99.939236   BatchTime 0.029065   LR 0.001000   
2022-10-20 18:31:28,098 - INFO  - ==> Top1: 94.792    Top5: 99.944    Loss: 0.152

2022-10-20 18:31:28,120 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:31:28,873 - INFO  - Validation [9][   20/   40]   Loss 0.359754   Top1 89.570312   Top5 99.589844   BatchTime 0.037652   
2022-10-20 18:31:29,001 - INFO  - Validation [9][   40/   40]   Loss 0.348403   Top1 89.740000   Top5 99.540000   BatchTime 0.022022   
2022-10-20 18:31:29,093 - INFO  - ==> Top1: 89.740    Top5: 99.540    Loss: 0.348

2022-10-20 18:31:29,094 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:31:32,155 - INFO  - Validation [9][   20/   40]   Loss 0.359754   Top1 89.570312   Top5 99.589844   BatchTime 0.153062   
2022-10-20 18:31:34,356 - INFO  - Validation [9][   40/   40]   Loss 0.348403   Top1 89.740000   Top5 99.540000   BatchTime 0.131546   
2022-10-20 18:31:34,462 - INFO  - ==> Top1: 89.740    Top5: 99.540    Loss: 0.348

2022-10-20 18:31:34,463 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 89.740   Top5: 99.540]
2022-10-20 18:31:34,463 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 89.640   Top5: 99.650]
2022-10-20 18:31:34,463 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 89.530   Top5: 99.670]
2022-10-20 18:31:35,886 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_checkpoint.pth.tar
                Best: /home/ilena7440/LSQFakeQuant/out/88_20221020-182921/88_best.pth.tar
save quantized models...
2022-10-20 18:31:35,886 - INFO  - >>>>>> Epoch  10
2022-10-20 18:31:35,886 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:31:37,103 - INFO  - Training [10][   20/  196]   Loss 0.141225   Top1 95.097656   Top5 99.941406   BatchTime 0.060822   LR 0.001000   
2022-10-20 18:31:37,618 - INFO  - Training [10][   40/  196]   Loss 0.147259   Top1 94.775391   Top5 99.941406   BatchTime 0.043268   LR 0.001000   
2022-10-20 18:31:38,135 - INFO  - Training [10][   60/  196]   Loss 0.148760   Top1 94.733073   Top5 99.954427   BatchTime 0.037459   LR 0.001000   
2022-10-20 18:31:38,655 - INFO  - Training [10][   80/  196]   Loss 0.149252   Top1 94.716797   Top5 99.956055   BatchTime 0.034600   LR 0.001000   
2022-10-20 18:31:39,173 - INFO  - Training [10][  100/  196]   Loss 0.148953   Top1 94.753906   Top5 99.953125   BatchTime 0.032860   LR 0.001000   
2022-10-20 18:31:39,689 - INFO  - Training [10][  120/  196]   Loss 0.147843   Top1 94.807943   Top5 99.954427   BatchTime 0.031683   LR 0.001000   
