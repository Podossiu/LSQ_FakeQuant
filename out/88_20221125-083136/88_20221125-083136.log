2022-11-25 08:31:36,812 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083136/88_20221125-083136.log
2022-11-25 08:31:42,052 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-25 08:31:44,086 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-25 08:31:45,347 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 08:31:48,981 - INFO  - Validation [   20/   40]   Loss 0.453618   Top1 91.464844   Top5 99.492188   BatchTime 0.181509   
2022-11-25 08:31:49,316 - INFO  - Validation [   40/   40]   Loss 0.456191   Top1 91.370000   Top5 99.570000   BatchTime 0.099158   
2022-11-25 08:31:49,403 - INFO  - ==> Top1: 91.370    Top5: 99.570    Loss: 0.456

2022-11-25 08:31:49,403 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.0005
               maximize: False
               weight_decay: 4e-05
           )
2022-11-25 08:31:49,405 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.0005

2022-11-25 08:31:49,467 - INFO  - >>>>>> Epoch   0
2022-11-25 08:31:49,470 - INFO  - Training: 50000 samples (256 per mini-batch)
