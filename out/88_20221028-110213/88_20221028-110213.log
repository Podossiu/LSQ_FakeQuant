2022-10-28 11:02:13,582 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-110213/88_20221028-110213.log
2022-10-28 11:02:15,321 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 11:02:15,428 - INFO  - Created `mobilenetv2` model
          Use pre-trained model = True
2022-10-28 11:02:15,444 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 11:02:15,444 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 11:02:16,694 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 11:02:16,695 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 11:02:18,372 - INFO  - Validation [   20/   40]   Loss 7.499609   Top1 0.000000   Top5 0.000000   BatchTime 0.083843   
2022-10-28 11:02:19,052 - INFO  - Validation [   40/   40]   Loss 7.499092   Top1 0.000000   Top5 0.000000   BatchTime 0.058904   
2022-10-28 11:02:19,110 - INFO  - ==> Top1: 0.000    Top5: 0.000    Loss: 7.499

2022-10-28 11:02:19,110 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 0.000   Top5: 0.000]
2022-10-28 11:02:19,110 - INFO  - >>>>>> Epoch   0
2022-10-28 11:02:19,110 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 11:02:20,548 - INFO  - Training [0][   20/  196]   Loss 10.512629   Top1 0.351562   Top5 1.464844   BatchTime 0.071842   LR 0.001000   
2022-10-28 11:02:21,319 - INFO  - Training [0][   40/  196]   Loss 8.346917   Top1 3.212891   Top5 8.603516   BatchTime 0.055190   LR 0.001000   
2022-10-28 11:02:22,088 - INFO  - Training [0][   60/  196]   Loss 7.159327   Top1 7.799479   Top5 19.147135   BatchTime 0.049621   LR 0.001000   
2022-10-28 11:02:22,849 - INFO  - Training [0][   80/  196]   Loss 6.337106   Top1 12.270508   Top5 29.223633   BatchTime 0.046725   LR 0.001000   
2022-10-28 11:02:23,615 - INFO  - Training [0][  100/  196]   Loss 5.707549   Top1 16.019531   Top5 37.667969   BatchTime 0.045035   LR 0.001000   
2022-10-28 11:02:24,374 - INFO  - Training [0][  120/  196]   Loss 5.210510   Top1 19.355469   Top5 44.645182   BatchTime 0.043852   LR 0.001000   
2022-10-28 11:02:25,137 - INFO  - Training [0][  140/  196]   Loss 4.813021   Top1 22.207031   Top5 50.298549   BatchTime 0.043038   LR 0.001000   
2022-10-28 11:02:25,898 - INFO  - Training [0][  160/  196]   Loss 4.489720   Top1 24.611816   Top5 54.826660   BatchTime 0.042416   LR 0.001000   
2022-10-28 11:02:26,653 - INFO  - Training [0][  180/  196]   Loss 4.217677   Top1 26.814236   Top5 58.539497   BatchTime 0.041897   LR 0.001000   
2022-10-28 11:02:27,314 - INFO  - ==> Top1: 28.282    Top5: 61.028    Loss: 4.037

2022-10-28 11:02:27,417 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 11:02:28,233 - INFO  - Validation [0][   20/   40]   Loss 1.970405   Top1 45.429688   Top5 88.691406   BatchTime 0.040786   
2022-10-28 11:02:28,528 - INFO  - Validation [0][   40/   40]   Loss 1.968186   Top1 44.810000   Top5 88.910000   BatchTime 0.027769   
2022-10-28 11:02:28,603 - INFO  - ==> Top1: 44.810    Top5: 88.910    Loss: 1.968

2022-10-28 11:02:28,603 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 11:02:30,387 - INFO  - Validation [0][   20/   40]   Loss 1.982766   Top1 45.722656   Top5 88.632812   BatchTime 0.089127   
2022-10-28 11:02:31,475 - INFO  - Validation [0][   40/   40]   Loss 1.979175   Top1 44.840000   Top5 88.860000   BatchTime 0.071766   
2022-10-28 11:02:31,551 - INFO  - ==> Top1: 44.840    Top5: 88.860    Loss: 1.979

2022-10-28 11:02:31,551 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 44.840   Top5: 88.860]
2022-10-28 11:02:31,551 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 0.000   Top5: 0.000]
