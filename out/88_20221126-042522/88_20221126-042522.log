2022-11-26 04:25:22,734 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88_20221126-042522.log
2022-11-26 04:25:27,256 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-26 04:25:29,112 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-26 04:25:29,817 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
2022-11-26 04:25:29,818 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005

2022-11-26 04:25:29,847 - INFO  - >>>>>> Epoch   0
2022-11-26 04:25:29,848 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:25:36,607 - INFO  - Training [0][   20/  196]   Loss 1.580746   Top1 53.750000   Top5 88.906250   BatchTime 0.337854   LR 0.004999   
2022-11-26 04:25:41,853 - INFO  - Training [0][   40/  196]   Loss 1.496292   Top1 52.783203   Top5 89.541016   BatchTime 0.300083   LR 0.004995   
2022-11-26 04:25:46,970 - INFO  - Training [0][   60/  196]   Loss 1.397735   Top1 55.123698   Top5 90.703125   BatchTime 0.285327   LR 0.004989   
2022-11-26 04:25:52,106 - INFO  - Training [0][   80/  196]   Loss 1.336352   Top1 56.752930   Top5 91.464844   BatchTime 0.278193   LR 0.004980   
2022-11-26 04:25:57,102 - INFO  - Training [0][  100/  196]   Loss 1.275738   Top1 58.519531   Top5 92.171875   BatchTime 0.272514   LR 0.004968   
2022-11-26 04:26:02,068 - INFO  - Training [0][  120/  196]   Loss 1.222449   Top1 60.185547   Top5 92.783203   BatchTime 0.268482   LR 0.004954   
2022-11-26 04:26:07,073 - INFO  - Training [0][  140/  196]   Loss 1.190312   Top1 61.163504   Top5 93.164062   BatchTime 0.265878   LR 0.004938   
2022-11-26 04:26:12,584 - INFO  - Training [0][  160/  196]   Loss 1.166264   Top1 61.916504   Top5 93.393555   BatchTime 0.267086   LR 0.004919   
2022-11-26 04:26:17,723 - INFO  - Training [0][  180/  196]   Loss 1.144198   Top1 62.465278   Top5 93.576389   BatchTime 0.265958   LR 0.004897   
2022-11-26 04:26:21,744 - INFO  - ==> Top1: 62.964    Top5: 93.760    Loss: 1.126

2022-11-26 04:26:21,933 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:26:23,124 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:26:25,314 - INFO  - Validation [0][   20/   40]   Loss 0.895440   Top1 70.957031   Top5 97.363281   BatchTime 0.109425   
2022-11-26 04:26:26,393 - INFO  - Validation [0][   40/   40]   Loss 0.906538   Top1 70.790000   Top5 97.130000   BatchTime 0.081704   
2022-11-26 04:26:26,576 - INFO  - ==> Top1: 70.790    Top5: 97.130    Loss: 0.907

2022-11-26 04:26:26,576 - INFO  - ==> Sparsity : 0.225

2022-11-26 04:26:26,577 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:26:31,152 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_best.pth.tar
save quantized models...
2022-11-26 04:26:31,154 - INFO  - >>>>>> Epoch   1
2022-11-26 04:26:31,156 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:26:37,439 - INFO  - Training [1][   20/  196]   Loss 0.946618   Top1 68.535156   Top5 95.253906   BatchTime 0.314045   LR 0.004853   
2022-11-26 04:26:42,521 - INFO  - Training [1][   40/  196]   Loss 0.953847   Top1 68.359375   Top5 95.478516   BatchTime 0.284068   LR 0.004825   
2022-11-26 04:26:47,485 - INFO  - Training [1][   60/  196]   Loss 0.943377   Top1 68.483073   Top5 95.598958   BatchTime 0.272115   LR 0.004794   
2022-11-26 04:26:52,503 - INFO  - Training [1][   80/  196]   Loss 0.927948   Top1 69.140625   Top5 95.732422   BatchTime 0.266802   LR 0.004761   
2022-11-26 04:26:57,549 - INFO  - Training [1][  100/  196]   Loss 0.908337   Top1 69.964844   Top5 95.863281   BatchTime 0.263901   LR 0.004725   
2022-11-26 04:27:02,485 - INFO  - Training [1][  120/  196]   Loss 0.899003   Top1 70.335286   Top5 96.083984   BatchTime 0.261057   LR 0.004687   
2022-11-26 04:27:07,489 - INFO  - Training [1][  140/  196]   Loss 0.890353   Top1 70.638951   Top5 96.202567   BatchTime 0.259502   LR 0.004647   
2022-11-26 04:27:12,594 - INFO  - Training [1][  160/  196]   Loss 0.884566   Top1 70.859375   Top5 96.230469   BatchTime 0.258969   LR 0.004605   
2022-11-26 04:27:17,426 - INFO  - Training [1][  180/  196]   Loss 0.872594   Top1 71.276042   Top5 96.250000   BatchTime 0.257038   LR 0.004560   
2022-11-26 04:27:21,556 - INFO  - ==> Top1: 71.470    Top5: 96.278    Loss: 0.867

2022-11-26 04:27:21,730 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:27:22,650 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:27:24,871 - INFO  - Validation [1][   20/   40]   Loss 0.754639   Top1 75.839844   Top5 97.753906   BatchTime 0.110950   
2022-11-26 04:27:25,945 - INFO  - Validation [1][   40/   40]   Loss 0.738611   Top1 76.020000   Top5 97.780000   BatchTime 0.082332   
2022-11-26 04:27:26,147 - INFO  - ==> Top1: 76.020    Top5: 97.780    Loss: 0.739

2022-11-26 04:27:26,147 - INFO  - ==> Sparsity : 0.286

2022-11-26 04:27:26,147 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:27:26,147 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:27:30,720 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_best.pth.tar
save quantized models...
2022-11-26 04:27:30,722 - INFO  - >>>>>> Epoch   2
2022-11-26 04:27:30,724 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:27:37,071 - INFO  - Training [2][   20/  196]   Loss 0.832800   Top1 72.089844   Top5 95.664062   BatchTime 0.317256   LR 0.004477   
2022-11-26 04:27:42,106 - INFO  - Training [2][   40/  196]   Loss 1.570073   Top1 45.703125   Top5 78.193359   BatchTime 0.284491   LR 0.004426   
2022-11-26 04:27:47,095 - INFO  - Training [2][   60/  196]   Loss 1.832511   Top1 33.645833   Top5 68.906250   BatchTime 0.272824   LR 0.004374   
2022-11-26 04:27:52,074 - INFO  - Training [2][   80/  196]   Loss 1.960379   Top1 27.607422   Top5 64.360352   BatchTime 0.266854   LR 0.004320   
2022-11-26 04:27:57,075 - INFO  - Training [2][  100/  196]   Loss 2.036684   Top1 24.125000   Top5 61.625000   BatchTime 0.263485   LR 0.004264   
2022-11-26 04:28:02,029 - INFO  - Training [2][  120/  196]   Loss 2.087516   Top1 21.725260   Top5 59.667969   BatchTime 0.260860   LR 0.004206   
2022-11-26 04:28:07,018 - INFO  - Training [2][  140/  196]   Loss 2.123092   Top1 20.011161   Top5 58.317522   BatchTime 0.259225   LR 0.004146   
2022-11-26 04:28:12,065 - INFO  - Training [2][  160/  196]   Loss 2.149865   Top1 18.747559   Top5 57.438965   BatchTime 0.258367   LR 0.004085   
2022-11-26 04:28:16,809 - INFO  - Training [2][  180/  196]   Loss 2.170433   Top1 17.849392   Top5 56.733941   BatchTime 0.256013   LR 0.004022   
2022-11-26 04:28:20,823 - INFO  - ==> Top1: 17.166    Top5: 56.140    Loss: 2.184

2022-11-26 04:28:21,042 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:28:22,003 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:28:24,212 - INFO  - Validation [2][   20/   40]   Loss 2.389739   Top1 10.253906   Top5 50.078125   BatchTime 0.110394   
2022-11-26 04:28:25,262 - INFO  - Validation [2][   40/   40]   Loss 2.390388   Top1 10.000000   Top5 50.000000   BatchTime 0.081450   
2022-11-26 04:28:25,452 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.390

2022-11-26 04:28:25,453 - INFO  - ==> Sparsity : 0.315

2022-11-26 04:28:25,453 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:28:25,453 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:28:25,453 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
2022-11-26 04:28:25,587 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:28:25,588 - INFO  - >>>>>> Epoch   3
2022-11-26 04:28:25,590 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:28:31,910 - INFO  - Training [3][   20/  196]   Loss 2.336336   Top1 10.195312   Top5 51.250000   BatchTime 0.315892   LR 0.003907   
2022-11-26 04:28:37,064 - INFO  - Training [3][   40/  196]   Loss 2.334600   Top1 10.195312   Top5 50.830078   BatchTime 0.286778   LR 0.003840   
2022-11-26 04:28:41,966 - INFO  - Training [3][   60/  196]   Loss 2.335026   Top1 10.221354   Top5 50.631510   BatchTime 0.272883   LR 0.003771   
2022-11-26 04:28:47,006 - INFO  - Training [3][   80/  196]   Loss 2.334255   Top1 10.288086   Top5 50.751953   BatchTime 0.267673   LR 0.003701   
2022-11-26 04:28:52,068 - INFO  - Training [3][  100/  196]   Loss 2.333834   Top1 10.238281   Top5 50.617188   BatchTime 0.264754   LR 0.003630   
2022-11-26 04:28:57,088 - INFO  - Training [3][  120/  196]   Loss 2.334353   Top1 10.006510   Top5 50.442708   BatchTime 0.262457   LR 0.003558   
2022-11-26 04:29:01,999 - INFO  - Training [3][  140/  196]   Loss 2.333774   Top1 9.991629   Top5 50.432478   BatchTime 0.260045   LR 0.003484   
2022-11-26 04:29:07,081 - INFO  - Training [3][  160/  196]   Loss 2.333644   Top1 10.100098   Top5 50.397949   BatchTime 0.259301   LR 0.003410   
2022-11-26 04:29:11,957 - INFO  - Training [3][  180/  196]   Loss 2.333907   Top1 10.023872   Top5 50.221354   BatchTime 0.257578   LR 0.003335   
2022-11-26 04:29:16,028 - INFO  - ==> Top1: 10.074    Top5: 50.112    Loss: 2.334

2022-11-26 04:29:16,234 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:29:17,340 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:29:19,573 - INFO  - Validation [3][   20/   40]   Loss 2.335316   Top1 9.863281   Top5 50.078125   BatchTime 0.111593   
2022-11-26 04:29:20,702 - INFO  - Validation [3][   40/   40]   Loss 2.335024   Top1 10.000000   Top5 50.000000   BatchTime 0.084020   
2022-11-26 04:29:20,930 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.335

2022-11-26 04:29:20,930 - INFO  - ==> Sparsity : 0.260

2022-11-26 04:29:20,931 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:29:20,931 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:29:20,931 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
2022-11-26 04:29:21,059 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:29:21,061 - INFO  - >>>>>> Epoch   4
2022-11-26 04:29:21,063 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:29:27,471 - INFO  - Training [4][   20/  196]   Loss 2.331820   Top1 10.039062   Top5 50.429688   BatchTime 0.320308   LR 0.003200   
2022-11-26 04:29:32,297 - INFO  - Training [4][   40/  196]   Loss 2.330997   Top1 10.078125   Top5 50.126953   BatchTime 0.280793   LR 0.003122   
2022-11-26 04:29:37,209 - INFO  - Training [4][   60/  196]   Loss 2.330936   Top1 10.026042   Top5 50.104167   BatchTime 0.269060   LR 0.003044   
2022-11-26 04:29:42,230 - INFO  - Training [4][   80/  196]   Loss 2.330542   Top1 10.078125   Top5 50.146484   BatchTime 0.264556   LR 0.002965   
2022-11-26 04:29:47,376 - INFO  - Training [4][  100/  196]   Loss 2.330757   Top1 9.992188   Top5 50.046875   BatchTime 0.263103   LR 0.002886   
2022-11-26 04:29:52,502 - INFO  - Training [4][  120/  196]   Loss 2.330412   Top1 10.065104   Top5 50.166016   BatchTime 0.261972   LR 0.002806   
2022-11-26 04:29:57,497 - INFO  - Training [4][  140/  196]   Loss 2.330398   Top1 9.997210   Top5 50.206473   BatchTime 0.260225   LR 0.002726   
2022-11-26 04:30:02,502 - INFO  - Training [4][  160/  196]   Loss 2.330355   Top1 10.053711   Top5 50.014648   BatchTime 0.258974   LR 0.002646   
2022-11-26 04:30:07,258 - INFO  - Training [4][  180/  196]   Loss 2.330298   Top1 10.054253   Top5 50.015191   BatchTime 0.256624   LR 0.002566   
2022-11-26 04:30:11,283 - INFO  - ==> Top1: 10.146    Top5: 49.976    Loss: 2.330

2022-11-26 04:30:11,511 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:30:13,088 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:30:15,434 - INFO  - Validation [4][   20/   40]   Loss 2.450002   Top1 10.078125   Top5 49.960938   BatchTime 0.117240   
2022-11-26 04:30:16,508 - INFO  - Validation [4][   40/   40]   Loss 2.451310   Top1 10.000000   Top5 50.000000   BatchTime 0.085462   
2022-11-26 04:30:16,703 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.451

2022-11-26 04:30:16,703 - INFO  - ==> Sparsity : 0.291

2022-11-26 04:30:16,703 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:30:16,703 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:30:16,704 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
2022-11-26 04:30:16,814 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:30:16,815 - INFO  - >>>>>> Epoch   5
2022-11-26 04:30:16,817 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:30:23,226 - INFO  - Training [5][   20/  196]   Loss 2.329710   Top1 9.414062   Top5 50.527344   BatchTime 0.320341   LR 0.002424   
2022-11-26 04:30:28,514 - INFO  - Training [5][   40/  196]   Loss 2.329541   Top1 9.453125   Top5 49.648438   BatchTime 0.292377   LR 0.002343   
2022-11-26 04:30:33,471 - INFO  - Training [5][   60/  196]   Loss 2.329656   Top1 9.583333   Top5 49.674479   BatchTime 0.277534   LR 0.002263   
2022-11-26 04:30:38,528 - INFO  - Training [5][   80/  196]   Loss 2.329465   Top1 9.643555   Top5 49.487305   BatchTime 0.271357   LR 0.002183   
2022-11-26 04:30:43,574 - INFO  - Training [5][  100/  196]   Loss 2.329218   Top1 9.675781   Top5 49.519531   BatchTime 0.267551   LR 0.002104   
2022-11-26 04:30:48,570 - INFO  - Training [5][  120/  196]   Loss 2.328998   Top1 9.847005   Top5 49.615885   BatchTime 0.264592   LR 0.002024   
2022-11-26 04:30:53,585 - INFO  - Training [5][  140/  196]   Loss 2.328809   Top1 9.729353   Top5 49.631696   BatchTime 0.262612   LR 0.001946   
2022-11-26 04:30:58,651 - INFO  - Training [5][  160/  196]   Loss 2.328715   Top1 9.770508   Top5 49.665527   BatchTime 0.261450   LR 0.001868   
2022-11-26 04:31:03,606 - INFO  - Training [5][  180/  196]   Loss 2.328701   Top1 9.817708   Top5 49.659288   BatchTime 0.259923   LR 0.001790   
2022-11-26 04:31:07,377 - INFO  - ==> Top1: 9.842    Top5: 49.576    Loss: 2.329

2022-11-26 04:31:07,652 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:31:09,061 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:31:11,385 - INFO  - Validation [5][   20/   40]   Loss 2.772228   Top1 10.078125   Top5 49.980469   BatchTime 0.116093   
2022-11-26 04:31:12,586 - INFO  - Validation [5][   40/   40]   Loss 2.775725   Top1 10.000000   Top5 50.000000   BatchTime 0.088094   
2022-11-26 04:31:12,784 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.776

2022-11-26 04:31:12,784 - INFO  - ==> Sparsity : 0.339

2022-11-26 04:31:12,785 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:31:12,785 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:31:12,785 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
2022-11-26 04:31:12,918 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:31:12,919 - INFO  - >>>>>> Epoch   6
2022-11-26 04:31:12,921 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:31:19,303 - INFO  - Training [6][   20/  196]   Loss 2.327092   Top1 10.058594   Top5 50.742188   BatchTime 0.318947   LR 0.001655   
2022-11-26 04:31:24,573 - INFO  - Training [6][   40/  196]   Loss 2.327177   Top1 9.912109   Top5 50.341797   BatchTime 0.291233   LR 0.001580   
2022-11-26 04:31:29,572 - INFO  - Training [6][   60/  196]   Loss 2.327333   Top1 10.058594   Top5 49.921875   BatchTime 0.277467   LR 0.001506   
2022-11-26 04:31:34,516 - INFO  - Training [6][   80/  196]   Loss 2.327353   Top1 9.985352   Top5 50.053711   BatchTime 0.269894   LR 0.001432   
2022-11-26 04:31:39,574 - INFO  - Training [6][  100/  196]   Loss 2.327241   Top1 9.968750   Top5 50.031250   BatchTime 0.266500   LR 0.001360   
2022-11-26 04:31:44,609 - INFO  - Training [6][  120/  196]   Loss 2.327253   Top1 9.951172   Top5 49.918620   BatchTime 0.264040   LR 0.001289   
2022-11-26 04:31:49,583 - INFO  - Training [6][  140/  196]   Loss 2.327224   Top1 9.958147   Top5 49.963728   BatchTime 0.261849   LR 0.001220   
2022-11-26 04:31:54,467 - INFO  - Training [6][  160/  196]   Loss 2.327277   Top1 9.926758   Top5 49.904785   BatchTime 0.259642   LR 0.001151   
2022-11-26 04:31:59,361 - INFO  - Training [6][  180/  196]   Loss 2.327204   Top1 9.976128   Top5 49.989149   BatchTime 0.257982   LR 0.001084   
2022-11-26 04:32:03,336 - INFO  - ==> Top1: 9.964    Top5: 49.906    Loss: 2.327

2022-11-26 04:32:03,513 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:32:04,532 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:32:06,840 - INFO  - Validation [6][   20/   40]   Loss 2.457179   Top1 10.078125   Top5 49.960938   BatchTime 0.115347   
2022-11-26 04:32:07,994 - INFO  - Validation [6][   40/   40]   Loss 2.458518   Top1 10.000000   Top5 50.000000   BatchTime 0.086530   
2022-11-26 04:32:08,217 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.459

2022-11-26 04:32:08,218 - INFO  - ==> Sparsity : 0.419

2022-11-26 04:32:08,218 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:32:08,218 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:32:08,219 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
2022-11-26 04:32:08,350 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:32:08,351 - INFO  - >>>>>> Epoch   7
2022-11-26 04:32:08,353 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:32:14,730 - INFO  - Training [7][   20/  196]   Loss 2.325562   Top1 10.136719   Top5 51.171875   BatchTime 0.318724   LR 0.000969   
2022-11-26 04:32:19,922 - INFO  - Training [7][   40/  196]   Loss 2.326406   Top1 9.638672   Top5 50.078125   BatchTime 0.289165   LR 0.000907   
2022-11-26 04:32:25,080 - INFO  - Training [7][   60/  196]   Loss 2.326418   Top1 9.687500   Top5 50.136719   BatchTime 0.278737   LR 0.000845   
2022-11-26 04:32:30,080 - INFO  - Training [7][   80/  196]   Loss 2.326537   Top1 9.638672   Top5 49.907227   BatchTime 0.271547   LR 0.000786   
2022-11-26 04:32:35,065 - INFO  - Training [7][  100/  196]   Loss 2.326726   Top1 9.570312   Top5 49.628906   BatchTime 0.267087   LR 0.000728   
2022-11-26 04:32:40,087 - INFO  - Training [7][  120/  196]   Loss 2.326489   Top1 9.739583   Top5 49.609375   BatchTime 0.264422   LR 0.000673   
2022-11-26 04:32:45,084 - INFO  - Training [7][  140/  196]   Loss 2.326233   Top1 9.726562   Top5 49.966518   BatchTime 0.262344   LR 0.000619   
2022-11-26 04:32:50,037 - INFO  - Training [7][  160/  196]   Loss 2.326057   Top1 9.758301   Top5 50.146484   BatchTime 0.260508   LR 0.000567   
2022-11-26 04:32:55,004 - INFO  - Training [7][  180/  196]   Loss 2.325981   Top1 9.780816   Top5 50.026042   BatchTime 0.259156   LR 0.000517   
2022-11-26 04:32:59,084 - INFO  - ==> Top1: 9.824    Top5: 50.064    Loss: 2.326

2022-11-26 04:32:59,260 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:33:00,449 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:33:02,709 - INFO  - Validation [7][   20/   40]   Loss 2.393330   Top1 10.078125   Top5 49.804688   BatchTime 0.112903   
2022-11-26 04:33:03,798 - INFO  - Validation [7][   40/   40]   Loss 2.394332   Top1 10.000000   Top5 50.000000   BatchTime 0.083664   
2022-11-26 04:33:04,006 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.394

2022-11-26 04:33:04,007 - INFO  - ==> Sparsity : 0.494

2022-11-26 04:33:04,007 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:33:04,007 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:33:04,007 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
2022-11-26 04:33:04,120 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:33:04,122 - INFO  - >>>>>> Epoch   8
2022-11-26 04:33:04,123 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:33:10,189 - INFO  - Training [8][   20/  196]   Loss 2.324335   Top1 9.882812   Top5 50.156250   BatchTime 0.303175   LR 0.000434   
2022-11-26 04:33:15,377 - INFO  - Training [8][   40/  196]   Loss 2.323811   Top1 10.029297   Top5 50.058594   BatchTime 0.281285   LR 0.000389   
2022-11-26 04:33:20,507 - INFO  - Training [8][   60/  196]   Loss 2.323574   Top1 9.980469   Top5 50.312500   BatchTime 0.273023   LR 0.000347   
2022-11-26 04:33:25,571 - INFO  - Training [8][   80/  196]   Loss 2.323600   Top1 9.858398   Top5 50.185547   BatchTime 0.268068   LR 0.000308   
2022-11-26 04:33:30,607 - INFO  - Training [8][  100/  196]   Loss 2.323787   Top1 9.773438   Top5 49.914062   BatchTime 0.264813   LR 0.000270   
2022-11-26 04:33:35,574 - INFO  - Training [8][  120/  196]   Loss 2.323505   Top1 9.915365   Top5 50.074870   BatchTime 0.262063   LR 0.000235   
2022-11-26 04:33:40,539 - INFO  - Training [8][  140/  196]   Loss 2.323463   Top1 9.888393   Top5 50.011161   BatchTime 0.260094   LR 0.000202   
2022-11-26 04:33:45,539 - INFO  - Training [8][  160/  196]   Loss 2.323501   Top1 9.853516   Top5 49.882812   BatchTime 0.258827   LR 0.000172   
2022-11-26 04:33:50,459 - INFO  - Training [8][  180/  196]   Loss 2.323520   Top1 9.863281   Top5 49.811198   BatchTime 0.257405   LR 0.000143   
2022-11-26 04:33:54,566 - INFO  - ==> Top1: 9.914    Top5: 49.818    Loss: 2.323

2022-11-26 04:33:54,766 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:33:55,823 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:33:58,122 - INFO  - Validation [8][   20/   40]   Loss 2.410998   Top1 10.078125   Top5 49.804688   BatchTime 0.114878   
2022-11-26 04:33:59,212 - INFO  - Validation [8][   40/   40]   Loss 2.412194   Top1 10.000000   Top5 50.000000   BatchTime 0.084693   
2022-11-26 04:33:59,429 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.412

2022-11-26 04:33:59,429 - INFO  - ==> Sparsity : 0.536

2022-11-26 04:33:59,430 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:33:59,430 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:33:59,430 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
2022-11-26 04:33:59,706 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:33:59,708 - INFO  - >>>>>> Epoch   9
2022-11-26 04:33:59,710 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:34:06,009 - INFO  - Training [9][   20/  196]   Loss 2.322635   Top1 10.195312   Top5 49.882812   BatchTime 0.314839   LR 0.000100   
2022-11-26 04:34:11,003 - INFO  - Training [9][   40/  196]   Loss 2.322728   Top1 9.785156   Top5 50.253906   BatchTime 0.282275   LR 0.000079   
2022-11-26 04:34:16,006 - INFO  - Training [9][   60/  196]   Loss 2.322871   Top1 9.765625   Top5 50.162760   BatchTime 0.271567   LR 0.000060   
2022-11-26 04:34:20,987 - INFO  - Training [9][   80/  196]   Loss 2.322592   Top1 9.951172   Top5 50.434570   BatchTime 0.265939   LR 0.000044   
2022-11-26 04:34:26,111 - INFO  - Training [9][  100/  196]   Loss 2.322683   Top1 9.917969   Top5 50.363281   BatchTime 0.263980   LR 0.000030   
2022-11-26 04:34:31,006 - INFO  - Training [9][  120/  196]   Loss 2.322750   Top1 10.009766   Top5 50.224609   BatchTime 0.260778   LR 0.000019   
2022-11-26 04:34:35,971 - INFO  - Training [9][  140/  196]   Loss 2.322739   Top1 9.969308   Top5 50.186942   BatchTime 0.258989   LR 0.000010   
2022-11-26 04:34:41,001 - INFO  - Training [9][  160/  196]   Loss 2.322728   Top1 9.987793   Top5 50.046387   BatchTime 0.258055   LR 0.000004   
2022-11-26 04:34:45,965 - INFO  - Training [9][  180/  196]   Loss 2.322721   Top1 9.954427   Top5 50.080295   BatchTime 0.256959   LR 0.000001   
2022-11-26 04:34:50,066 - INFO  - ==> Top1: 9.958    Top5: 50.108    Loss: 2.323

2022-11-26 04:34:50,273 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:34:51,322 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:34:53,580 - INFO  - Validation [9][   20/   40]   Loss 2.347614   Top1 10.078125   Top5 49.804688   BatchTime 0.112784   
2022-11-26 04:34:54,685 - INFO  - Validation [9][   40/   40]   Loss 2.347898   Top1 10.000000   Top5 50.000000   BatchTime 0.084036   
2022-11-26 04:34:54,900 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.348

2022-11-26 04:34:54,900 - INFO  - ==> Sparsity : 0.540

2022-11-26 04:34:54,900 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:34:54,901 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:34:54,901 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
2022-11-26 04:34:55,021 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:34:55,023 - INFO  - >>>>>> Epoch  10
2022-11-26 04:34:55,024 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:35:01,478 - INFO  - Training [10][   20/  196]   Loss 2.324797   Top1 10.253906   Top5 50.136719   BatchTime 0.322575   LR 0.002500   
2022-11-26 04:35:06,689 - INFO  - Training [10][   40/  196]   Loss 2.324550   Top1 10.244141   Top5 49.521484   BatchTime 0.291542   LR 0.002499   
2022-11-26 04:35:12,068 - INFO  - Training [10][   60/  196]   Loss 2.323934   Top1 10.247396   Top5 49.563802   BatchTime 0.284020   LR 0.002499   
2022-11-26 04:35:16,993 - INFO  - Training [10][   80/  196]   Loss 2.323447   Top1 10.117188   Top5 49.448242   BatchTime 0.274578   LR 0.002497   
2022-11-26 04:35:21,985 - INFO  - Training [10][  100/  196]   Loss 2.323314   Top1 10.117188   Top5 49.546875   BatchTime 0.269578   LR 0.002496   
2022-11-26 04:35:27,218 - INFO  - Training [10][  120/  196]   Loss 2.323090   Top1 10.078125   Top5 49.707031   BatchTime 0.268256   LR 0.002494   
2022-11-26 04:35:32,230 - INFO  - Training [10][  140/  196]   Loss 2.323033   Top1 10.094866   Top5 49.732143   BatchTime 0.265737   LR 0.002492   
2022-11-26 04:35:37,288 - INFO  - Training [10][  160/  196]   Loss 2.322860   Top1 10.085449   Top5 49.812012   BatchTime 0.264129   LR 0.002490   
2022-11-26 04:35:41,960 - INFO  - Training [10][  180/  196]   Loss 2.322767   Top1 10.010851   Top5 49.789497   BatchTime 0.260735   LR 0.002487   
2022-11-26 04:35:46,100 - INFO  - ==> Top1: 9.974    Top5: 49.876    Loss: 2.323

2022-11-26 04:35:46,311 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:35:47,570 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:35:49,904 - INFO  - Validation [10][   20/   40]   Loss 2.309767   Top1 10.253906   Top5 49.960938   BatchTime 0.116592   
2022-11-26 04:35:51,010 - INFO  - Validation [10][   40/   40]   Loss 2.310188   Top1 10.000000   Top5 50.000000   BatchTime 0.085947   
2022-11-26 04:35:51,218 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.310

2022-11-26 04:35:51,219 - INFO  - ==> Sparsity : 0.592

2022-11-26 04:35:51,219 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:35:51,219 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:35:51,219 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
2022-11-26 04:35:51,336 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:35:51,338 - INFO  - >>>>>> Epoch  11
2022-11-26 04:35:51,340 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:35:57,499 - INFO  - Training [11][   20/  196]   Loss 2.320538   Top1 9.687500   Top5 50.976562   BatchTime 0.307869   LR 0.002481   
2022-11-26 04:36:02,571 - INFO  - Training [11][   40/  196]   Loss 2.321561   Top1 9.453125   Top5 50.136719   BatchTime 0.280720   LR 0.002478   
2022-11-26 04:36:07,571 - INFO  - Training [11][   60/  196]   Loss 2.321331   Top1 9.856771   Top5 50.247396   BatchTime 0.270477   LR 0.002474   
2022-11-26 04:36:12,578 - INFO  - Training [11][   80/  196]   Loss 2.321360   Top1 9.863281   Top5 50.092773   BatchTime 0.265444   LR 0.002470   
2022-11-26 04:36:17,484 - INFO  - Training [11][  100/  196]   Loss 2.321396   Top1 9.839844   Top5 49.957031   BatchTime 0.261416   LR 0.002465   
2022-11-26 04:36:22,476 - INFO  - Training [11][  120/  196]   Loss 2.321296   Top1 9.820964   Top5 49.873047   BatchTime 0.259444   LR 0.002460   
2022-11-26 04:36:27,527 - INFO  - Training [11][  140/  196]   Loss 2.321158   Top1 9.885603   Top5 49.840960   BatchTime 0.258461   LR 0.002455   
2022-11-26 04:36:32,583 - INFO  - Training [11][  160/  196]   Loss 2.321138   Top1 9.848633   Top5 49.770508   BatchTime 0.257752   LR 0.002450   
2022-11-26 04:36:37,446 - INFO  - Training [11][  180/  196]   Loss 2.321145   Top1 9.878472   Top5 49.717882   BatchTime 0.256128   LR 0.002444   
2022-11-26 04:36:41,583 - INFO  - ==> Top1: 9.846    Top5: 49.698    Loss: 2.321

2022-11-26 04:36:41,779 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:36:42,709 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:36:44,987 - INFO  - Validation [11][   20/   40]   Loss 2.340532   Top1 9.882812   Top5 49.785156   BatchTime 0.113829   
2022-11-26 04:36:46,079 - INFO  - Validation [11][   40/   40]   Loss 2.339230   Top1 10.000000   Top5 50.000000   BatchTime 0.084231   
2022-11-26 04:36:46,310 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.339

2022-11-26 04:36:46,311 - INFO  - ==> Sparsity : 0.602

2022-11-26 04:36:46,311 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:36:46,311 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:36:46,311 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
2022-11-26 04:36:46,586 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:36:46,588 - INFO  - >>>>>> Epoch  12
2022-11-26 04:36:46,589 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:36:52,858 - INFO  - Training [12][   20/  196]   Loss 2.320659   Top1 9.804688   Top5 49.785156   BatchTime 0.313290   LR 0.002433   
2022-11-26 04:36:57,823 - INFO  - Training [12][   40/  196]   Loss 2.321080   Top1 9.882812   Top5 49.873047   BatchTime 0.280785   LR 0.002426   
2022-11-26 04:37:02,807 - INFO  - Training [12][   60/  196]   Loss 2.320868   Top1 9.928385   Top5 50.286458   BatchTime 0.270260   LR 0.002419   
2022-11-26 04:37:07,799 - INFO  - Training [12][   80/  196]   Loss 2.321086   Top1 9.814453   Top5 50.000000   BatchTime 0.265089   LR 0.002412   
2022-11-26 04:37:12,933 - INFO  - Training [12][  100/  196]   Loss 2.321078   Top1 9.968750   Top5 50.179688   BatchTime 0.263406   LR 0.002404   
2022-11-26 04:37:17,980 - INFO  - Training [12][  120/  196]   Loss 2.321136   Top1 10.058594   Top5 50.042318   BatchTime 0.261564   LR 0.002396   
2022-11-26 04:37:22,973 - INFO  - Training [12][  140/  196]   Loss nan   Top1 10.041853   Top5 49.944196   BatchTime 0.259862   LR 0.002388   
2022-11-26 04:37:28,006 - INFO  - Training [12][  160/  196]   Loss nan   Top1 10.085449   Top5 49.975586   BatchTime 0.258833   LR 0.002380   
2022-11-26 04:37:32,712 - INFO  - Training [12][  180/  196]   Loss nan   Top1 10.071615   Top5 49.852431   BatchTime 0.256222   LR 0.002371   
2022-11-26 04:37:36,800 - INFO  - ==> Top1: 10.038    Top5: 49.842    Loss: nan

2022-11-26 04:37:36,993 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:37:38,381 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:37:40,643 - INFO  - Validation [12][   20/   40]   Loss 2.350814   Top1 9.882812   Top5 49.785156   BatchTime 0.113033   
2022-11-26 04:37:41,677 - INFO  - Validation [12][   40/   40]   Loss 2.349360   Top1 10.000000   Top5 50.000000   BatchTime 0.082378   
2022-11-26 04:37:41,873 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.349

2022-11-26 04:37:41,873 - INFO  - ==> Sparsity : 0.609

2022-11-26 04:37:41,873 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:37:41,874 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:37:41,874 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
2022-11-26 04:37:41,988 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:37:41,990 - INFO  - >>>>>> Epoch  13
2022-11-26 04:37:41,992 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:37:48,295 - INFO  - Training [13][   20/  196]   Loss nan   Top1 9.960938   Top5 50.390625   BatchTime 0.315049   LR 0.002355   
2022-11-26 04:37:53,724 - INFO  - Training [13][   40/  196]   Loss nan   Top1 9.941406   Top5 49.570312   BatchTime 0.293236   LR 0.002345   
2022-11-26 04:37:58,815 - INFO  - Training [13][   60/  196]   Loss nan   Top1 10.130208   Top5 49.524740   BatchTime 0.280347   LR 0.002336   
2022-11-26 04:38:03,830 - INFO  - Training [13][   80/  196]   Loss nan   Top1 9.990234   Top5 49.570312   BatchTime 0.272945   LR 0.002325   
2022-11-26 04:38:08,816 - INFO  - Training [13][  100/  196]   Loss nan   Top1 9.988281   Top5 49.535156   BatchTime 0.268212   LR 0.002315   
2022-11-26 04:38:13,757 - INFO  - Training [13][  120/  196]   Loss nan   Top1 9.921875   Top5 49.567057   BatchTime 0.264685   LR 0.002304   
2022-11-26 04:38:18,747 - INFO  - Training [13][  140/  196]   Loss nan   Top1 9.952567   Top5 49.536830   BatchTime 0.262517   LR 0.002293   
2022-11-26 04:38:23,812 - INFO  - Training [13][  160/  196]   Loss nan   Top1 9.938965   Top5 49.599609   BatchTime 0.261357   LR 0.002282   
2022-11-26 04:38:28,575 - INFO  - Training [13][  180/  196]   Loss nan   Top1 9.954427   Top5 49.594184   BatchTime 0.258777   LR 0.002271   
2022-11-26 04:38:32,558 - INFO  - ==> Top1: 9.998    Top5: 49.784    Loss: nan

2022-11-26 04:38:32,730 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:38:33,687 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:38:36,027 - INFO  - Validation [13][   20/   40]   Loss 2.347446   Top1 9.882812   Top5 49.785156   BatchTime 0.116962   
2022-11-26 04:38:37,134 - INFO  - Validation [13][   40/   40]   Loss 2.346011   Top1 10.000000   Top5 50.000000   BatchTime 0.086119   
2022-11-26 04:38:37,333 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.346

2022-11-26 04:38:37,333 - INFO  - ==> Sparsity : 0.634

2022-11-26 04:38:37,334 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:38:37,334 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:38:37,334 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
2022-11-26 04:38:37,444 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:38:37,446 - INFO  - >>>>>> Epoch  14
2022-11-26 04:38:37,447 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:38:43,991 - INFO  - Training [14][   20/  196]   Loss nan   Top1 9.531250   Top5 50.429688   BatchTime 0.327093   LR 0.002250   
2022-11-26 04:38:49,092 - INFO  - Training [14][   40/  196]   Loss nan   Top1 9.804688   Top5 50.341797   BatchTime 0.291065   LR 0.002238   
2022-11-26 04:38:54,142 - INFO  - Training [14][   60/  196]   Loss nan   Top1 9.791667   Top5 50.045573   BatchTime 0.278210   LR 0.002225   
2022-11-26 04:38:59,254 - INFO  - Training [14][   80/  196]   Loss nan   Top1 9.858398   Top5 50.048828   BatchTime 0.272559   LR 0.002213   
2022-11-26 04:39:04,247 - INFO  - Training [14][  100/  196]   Loss nan   Top1 9.843750   Top5 50.101562   BatchTime 0.267974   LR 0.002200   
2022-11-26 04:39:09,249 - INFO  - Training [14][  120/  196]   Loss nan   Top1 9.967448   Top5 50.263672   BatchTime 0.264993   LR 0.002186   
2022-11-26 04:39:14,231 - INFO  - Training [14][  140/  196]   Loss nan   Top1 9.972098   Top5 50.245536   BatchTime 0.262721   LR 0.002173   
2022-11-26 04:39:19,221 - INFO  - Training [14][  160/  196]   Loss nan   Top1 9.992676   Top5 50.090332   BatchTime 0.261066   LR 0.002159   
2022-11-26 04:39:24,271 - INFO  - Training [14][  180/  196]   Loss nan   Top1 9.939236   Top5 50.082465   BatchTime 0.260118   LR 0.002145   
2022-11-26 04:39:28,299 - INFO  - ==> Top1: 9.972    Top5: 50.078    Loss: nan

2022-11-26 04:39:28,527 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:39:30,072 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:39:32,563 - INFO  - Validation [14][   20/   40]   Loss 2.346487   Top1 9.882812   Top5 49.785156   BatchTime 0.124505   
2022-11-26 04:39:33,673 - INFO  - Validation [14][   40/   40]   Loss 2.345050   Top1 10.000000   Top5 50.000000   BatchTime 0.090011   
2022-11-26 04:39:33,880 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.345

2022-11-26 04:39:33,881 - INFO  - ==> Sparsity : 0.619

2022-11-26 04:39:33,881 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:39:33,881 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:39:33,881 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
2022-11-26 04:39:34,016 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:39:34,018 - INFO  - >>>>>> Epoch  15
2022-11-26 04:39:34,020 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:39:40,466 - INFO  - Training [15][   20/  196]   Loss nan   Top1 9.726562   Top5 50.449219   BatchTime 0.322186   LR 0.002120   
2022-11-26 04:39:45,582 - INFO  - Training [15][   40/  196]   Loss nan   Top1 9.423828   Top5 50.224609   BatchTime 0.288993   LR 0.002106   
2022-11-26 04:39:50,489 - INFO  - Training [15][   60/  196]   Loss nan   Top1 9.791667   Top5 49.980469   BatchTime 0.274437   LR 0.002091   
2022-11-26 04:39:55,584 - INFO  - Training [15][   80/  196]   Loss nan   Top1 9.682617   Top5 49.907227   BatchTime 0.269514   LR 0.002076   
2022-11-26 04:40:00,589 - INFO  - Training [15][  100/  196]   Loss nan   Top1 9.769531   Top5 49.722656   BatchTime 0.265661   LR 0.002061   
2022-11-26 04:40:05,582 - INFO  - Training [15][  120/  196]   Loss nan   Top1 9.882812   Top5 49.694010   BatchTime 0.262994   LR 0.002045   
2022-11-26 04:40:10,586 - INFO  - Training [15][  140/  196]   Loss nan   Top1 9.891183   Top5 49.589844   BatchTime 0.261165   LR 0.002030   
2022-11-26 04:40:15,500 - INFO  - Training [15][  160/  196]   Loss nan   Top1 9.892578   Top5 49.536133   BatchTime 0.259229   LR 0.002014   
2022-11-26 04:40:20,338 - INFO  - Training [15][  180/  196]   Loss nan   Top1 9.861111   Top5 49.602865   BatchTime 0.257306   LR 0.001998   
2022-11-26 04:40:24,341 - INFO  - ==> Top1: 9.886    Top5: 49.558    Loss: nan

2022-11-26 04:40:24,563 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:40:25,759 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:40:28,093 - INFO  - Validation [15][   20/   40]   Loss 2.343832   Top1 9.882812   Top5 49.785156   BatchTime 0.116628   
2022-11-26 04:40:29,186 - INFO  - Validation [15][   40/   40]   Loss 2.342511   Top1 10.000000   Top5 50.000000   BatchTime 0.085652   
2022-11-26 04:40:29,406 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.343

2022-11-26 04:40:29,406 - INFO  - ==> Sparsity : 0.622

2022-11-26 04:40:29,406 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:40:29,407 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:40:29,407 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
2022-11-26 04:40:29,530 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:40:29,532 - INFO  - >>>>>> Epoch  16
2022-11-26 04:40:29,533 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:40:36,193 - INFO  - Training [16][   20/  196]   Loss nan   Top1 9.765625   Top5 49.960938   BatchTime 0.332871   LR 0.001969   
2022-11-26 04:40:41,207 - INFO  - Training [16][   40/  196]   Loss nan   Top1 9.921875   Top5 49.580078   BatchTime 0.291767   LR 0.001953   
2022-11-26 04:40:46,343 - INFO  - Training [16][   60/  196]   Loss nan   Top1 9.882812   Top5 49.615885   BatchTime 0.280113   LR 0.001936   
2022-11-26 04:40:51,315 - INFO  - Training [16][   80/  196]   Loss nan   Top1 9.794922   Top5 49.589844   BatchTime 0.272240   LR 0.001919   
2022-11-26 04:40:56,221 - INFO  - Training [16][  100/  196]   Loss nan   Top1 9.925781   Top5 49.546875   BatchTime 0.266844   LR 0.001902   
2022-11-26 04:41:01,271 - INFO  - Training [16][  120/  196]   Loss nan   Top1 9.856771   Top5 49.583333   BatchTime 0.264454   LR 0.001885   
2022-11-26 04:41:06,221 - INFO  - Training [16][  140/  196]   Loss nan   Top1 9.840960   Top5 49.430804   BatchTime 0.262032   LR 0.001867   
2022-11-26 04:41:11,261 - INFO  - Training [16][  160/  196]   Loss nan   Top1 9.777832   Top5 49.270020   BatchTime 0.260779   LR 0.001850   
2022-11-26 04:41:16,244 - INFO  - Training [16][  180/  196]   Loss nan   Top1 9.815538   Top5 49.296875   BatchTime 0.259484   LR 0.001832   
2022-11-26 04:41:20,343 - INFO  - ==> Top1: 9.814    Top5: 49.244    Loss: nan

2022-11-26 04:41:20,606 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:41:21,995 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:41:24,265 - INFO  - Validation [16][   20/   40]   Loss 2.332541   Top1 9.882812   Top5 49.785156   BatchTime 0.113423   
2022-11-26 04:41:25,320 - INFO  - Validation [16][   40/   40]   Loss 2.331517   Top1 10.000000   Top5 50.000000   BatchTime 0.083093   
2022-11-26 04:41:25,507 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.332

2022-11-26 04:41:25,507 - INFO  - ==> Sparsity : 0.625

2022-11-26 04:41:25,507 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:41:25,508 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:41:25,508 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
2022-11-26 04:41:25,637 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:41:25,638 - INFO  - >>>>>> Epoch  17
2022-11-26 04:41:25,640 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:41:32,087 - INFO  - Training [17][   20/  196]   Loss nan   Top1 10.683594   Top5 50.039062   BatchTime 0.322243   LR 0.001800   
2022-11-26 04:41:37,425 - INFO  - Training [17][   40/  196]   Loss nan   Top1 10.341797   Top5 49.785156   BatchTime 0.294563   LR 0.001782   
2022-11-26 04:41:42,603 - INFO  - Training [17][   60/  196]   Loss nan   Top1 10.208333   Top5 49.596354   BatchTime 0.282672   LR 0.001764   
2022-11-26 04:41:47,582 - INFO  - Training [17][   80/  196]   Loss nan   Top1 10.205078   Top5 49.658203   BatchTime 0.274241   LR 0.001746   
2022-11-26 04:41:52,597 - INFO  - Training [17][  100/  196]   Loss nan   Top1 10.199219   Top5 49.398438   BatchTime 0.269539   LR 0.001727   
2022-11-26 04:41:57,574 - INFO  - Training [17][  120/  196]   Loss nan   Top1 10.081380   Top5 49.492188   BatchTime 0.266095   LR 0.001708   
2022-11-26 04:42:02,590 - INFO  - Training [17][  140/  196]   Loss nan   Top1 10.097656   Top5 49.575893   BatchTime 0.263905   LR 0.001690   
2022-11-26 04:42:07,559 - INFO  - Training [17][  160/  196]   Loss nan   Top1 10.153809   Top5 49.519043   BatchTime 0.261975   LR 0.001671   
2022-11-26 04:42:12,680 - INFO  - Training [17][  180/  196]   Loss nan   Top1 10.099826   Top5 49.635417   BatchTime 0.261316   LR 0.001652   
2022-11-26 04:42:16,834 - INFO  - ==> Top1: 10.164    Top5: 49.674    Loss: nan

2022-11-26 04:42:17,034 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:42:18,071 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:42:20,381 - INFO  - Validation [17][   20/   40]   Loss 2.306973   Top1 9.882812   Top5 49.804688   BatchTime 0.115444   
2022-11-26 04:42:21,490 - INFO  - Validation [17][   40/   40]   Loss 2.306331   Top1 10.000000   Top5 50.000000   BatchTime 0.085444   
2022-11-26 04:42:21,719 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.306

2022-11-26 04:42:21,719 - INFO  - ==> Sparsity : 0.623

2022-11-26 04:42:21,719 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:42:21,719 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:42:21,720 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
2022-11-26 04:42:21,831 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:42:21,832 - INFO  - >>>>>> Epoch  18
2022-11-26 04:42:21,834 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:42:27,685 - INFO  - Training [18][   20/  196]   Loss nan   Top1 10.410156   Top5 50.332031   BatchTime 0.292430   LR 0.001618   
2022-11-26 04:42:32,460 - INFO  - Training [18][   40/  196]   Loss nan   Top1 10.175781   Top5 49.853516   BatchTime 0.265595   LR 0.001599   
2022-11-26 04:42:37,399 - INFO  - Training [18][   60/  196]   Loss nan   Top1 10.156250   Top5 50.156250   BatchTime 0.259369   LR 0.001579   
2022-11-26 04:42:41,848 - INFO  - Training [18][   80/  196]   Loss nan   Top1 10.092773   Top5 50.209961   BatchTime 0.250144   LR 0.001560   
2022-11-26 04:42:46,519 - INFO  - Training [18][  100/  196]   Loss nan   Top1 10.085938   Top5 50.300781   BatchTime 0.246824   LR 0.001540   
2022-11-26 04:42:51,578 - INFO  - Training [18][  120/  196]   Loss nan   Top1 9.977214   Top5 50.247396   BatchTime 0.247841   LR 0.001521   
2022-11-26 04:42:56,319 - INFO  - Training [18][  140/  196]   Loss nan   Top1 9.980469   Top5 50.217634   BatchTime 0.246303   LR 0.001501   
2022-11-26 04:43:01,303 - INFO  - Training [18][  160/  196]   Loss nan   Top1 9.931641   Top5 50.117188   BatchTime 0.246662   LR 0.001482   
2022-11-26 04:43:06,052 - INFO  - Training [18][  180/  196]   Loss nan   Top1 9.963108   Top5 50.028212   BatchTime 0.245641   LR 0.001462   
2022-11-26 04:43:10,081 - INFO  - ==> Top1: 9.962    Top5: 50.070    Loss: nan

2022-11-26 04:43:10,278 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:43:11,507 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:43:13,840 - INFO  - Validation [18][   20/   40]   Loss 2.311844   Top1 9.882812   Top5 49.882812   BatchTime 0.116539   
2022-11-26 04:43:14,954 - INFO  - Validation [18][   40/   40]   Loss 2.311126   Top1 10.000000   Top5 50.000000   BatchTime 0.086128   
2022-11-26 04:43:15,179 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.311

2022-11-26 04:43:15,179 - INFO  - ==> Sparsity : 0.626

2022-11-26 04:43:15,180 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:43:15,180 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:43:15,180 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
2022-11-26 04:43:15,309 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:43:15,311 - INFO  - >>>>>> Epoch  19
2022-11-26 04:43:15,313 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:43:21,742 - INFO  - Training [19][   20/  196]   Loss nan   Top1 10.390625   Top5 50.488281   BatchTime 0.321363   LR 0.001427   
2022-11-26 04:43:26,721 - INFO  - Training [19][   40/  196]   Loss nan   Top1 10.107422   Top5 49.697266   BatchTime 0.285133   LR 0.001407   
2022-11-26 04:43:31,720 - INFO  - Training [19][   60/  196]   Loss nan   Top1 10.286458   Top5 49.791667   BatchTime 0.273409   LR 0.001387   
2022-11-26 04:43:36,709 - INFO  - Training [19][   80/  196]   Loss nan   Top1 10.151367   Top5 49.741211   BatchTime 0.267424   LR 0.001367   
2022-11-26 04:43:41,792 - INFO  - Training [19][  100/  196]   Loss nan   Top1 9.976562   Top5 49.273438   BatchTime 0.264763   LR 0.001347   
2022-11-26 04:43:46,778 - INFO  - Training [19][  120/  196]   Loss nan   Top1 10.019531   Top5 49.449870   BatchTime 0.262185   LR 0.001327   
2022-11-26 04:43:51,725 - INFO  - Training [19][  140/  196]   Loss nan   Top1 9.960938   Top5 49.511719   BatchTime 0.260067   LR 0.001307   
2022-11-26 04:43:56,756 - INFO  - Training [19][  160/  196]   Loss nan   Top1 9.936523   Top5 49.638672   BatchTime 0.259002   LR 0.001287   
2022-11-26 04:44:01,691 - INFO  - Training [19][  180/  196]   Loss nan   Top1 9.911024   Top5 49.633247   BatchTime 0.257638   LR 0.001266   
2022-11-26 04:44:05,827 - INFO  - ==> Top1: 9.868    Top5: 49.750    Loss: nan

2022-11-26 04:44:06,110 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:44:07,458 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:44:09,820 - INFO  - Validation [19][   20/   40]   Loss 2.320097   Top1 9.882812   Top5 49.785156   BatchTime 0.118027   
2022-11-26 04:44:10,863 - INFO  - Validation [19][   40/   40]   Loss 2.319094   Top1 10.000000   Top5 50.000000   BatchTime 0.085095   
2022-11-26 04:44:11,095 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.319

2022-11-26 04:44:11,095 - INFO  - ==> Sparsity : 0.630

2022-11-26 04:44:11,095 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:44:11,095 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:44:11,096 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
2022-11-26 04:44:11,213 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:44:11,215 - INFO  - >>>>>> Epoch  20
2022-11-26 04:44:11,216 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:44:17,465 - INFO  - Training [20][   20/  196]   Loss nan   Top1 9.570312   Top5 50.097656   BatchTime 0.312299   LR 0.001231   
2022-11-26 04:44:22,573 - INFO  - Training [20][   40/  196]   Loss nan   Top1 10.048828   Top5 49.511719   BatchTime 0.283863   LR 0.001211   
2022-11-26 04:44:27,585 - INFO  - Training [20][   60/  196]   Loss nan   Top1 10.019531   Top5 49.433594   BatchTime 0.272773   LR 0.001191   
2022-11-26 04:44:32,609 - INFO  - Training [20][   80/  196]   Loss nan   Top1 10.068359   Top5 49.296875   BatchTime 0.267377   LR 0.001171   
2022-11-26 04:44:37,584 - INFO  - Training [20][  100/  196]   Loss nan   Top1 9.929688   Top5 49.398438   BatchTime 0.263652   LR 0.001151   
2022-11-26 04:44:42,579 - INFO  - Training [20][  120/  196]   Loss nan   Top1 9.882812   Top5 49.423828   BatchTime 0.261331   LR 0.001131   
2022-11-26 04:44:47,567 - INFO  - Training [20][  140/  196]   Loss nan   Top1 9.893973   Top5 49.447545   BatchTime 0.259631   LR 0.001111   
2022-11-26 04:44:52,845 - INFO  - Training [20][  160/  196]   Loss nan   Top1 9.841309   Top5 49.494629   BatchTime 0.260160   LR 0.001091   
2022-11-26 04:44:57,955 - INFO  - Training [20][  180/  196]   Loss nan   Top1 9.822049   Top5 49.578993   BatchTime 0.259646   LR 0.001071   
2022-11-26 04:45:02,045 - INFO  - ==> Top1: 9.836    Top5: 49.616    Loss: nan

2022-11-26 04:45:02,250 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:45:03,305 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:45:05,664 - INFO  - Validation [20][   20/   40]   Loss 2.303959   Top1 9.882812   Top5 50.019531   BatchTime 0.117863   
2022-11-26 04:45:06,765 - INFO  - Validation [20][   40/   40]   Loss 2.303690   Top1 10.000000   Top5 50.000000   BatchTime 0.086442   
2022-11-26 04:45:07,013 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.304

2022-11-26 04:45:07,013 - INFO  - ==> Sparsity : 0.627

2022-11-26 04:45:07,013 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:45:07,014 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:45:07,014 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
2022-11-26 04:45:07,142 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:45:07,143 - INFO  - >>>>>> Epoch  21
2022-11-26 04:45:07,145 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:45:13,299 - INFO  - Training [21][   20/  196]   Loss nan   Top1 10.371094   Top5 50.605469   BatchTime 0.307571   LR 0.001036   
2022-11-26 04:45:18,247 - INFO  - Training [21][   40/  196]   Loss nan   Top1 10.166016   Top5 50.234375   BatchTime 0.277477   LR 0.001016   
2022-11-26 04:45:23,266 - INFO  - Training [21][   60/  196]   Loss nan   Top1 10.045573   Top5 50.136719   BatchTime 0.268639   LR 0.000996   
2022-11-26 04:45:28,297 - INFO  - Training [21][   80/  196]   Loss nan   Top1 10.092773   Top5 50.209961   BatchTime 0.264367   LR 0.000976   
2022-11-26 04:45:33,217 - INFO  - Training [21][  100/  196]   Loss nan   Top1 10.054688   Top5 50.261719   BatchTime 0.260689   LR 0.000957   
2022-11-26 04:45:38,517 - INFO  - Training [21][  120/  196]   Loss nan   Top1 10.058594   Top5 50.104167   BatchTime 0.261408   LR 0.000937   
2022-11-26 04:45:43,490 - INFO  - Training [21][  140/  196]   Loss nan   Top1 10.027902   Top5 49.983259   BatchTime 0.259588   LR 0.000918   
2022-11-26 04:45:48,464 - INFO  - Training [21][  160/  196]   Loss nan   Top1 10.061035   Top5 50.031738   BatchTime 0.258224   LR 0.000899   
2022-11-26 04:45:53,738 - INFO  - Training [21][  180/  196]   Loss nan   Top1 10.023872   Top5 49.947917   BatchTime 0.258834   LR 0.000879   
2022-11-26 04:45:57,659 - INFO  - ==> Top1: 10.088    Top5: 49.980    Loss: nan

2022-11-26 04:45:57,875 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:45:59,207 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:46:01,519 - INFO  - Validation [21][   20/   40]   Loss 2.307700   Top1 9.882812   Top5 49.882812   BatchTime 0.115536   
2022-11-26 04:46:02,608 - INFO  - Validation [21][   40/   40]   Loss 2.307280   Top1 10.000000   Top5 50.000000   BatchTime 0.085006   
2022-11-26 04:46:02,848 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.307

2022-11-26 04:46:02,848 - INFO  - ==> Sparsity : 0.629

2022-11-26 04:46:02,848 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:46:02,848 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:46:02,848 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
2022-11-26 04:46:02,962 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:46:02,963 - INFO  - >>>>>> Epoch  22
2022-11-26 04:46:02,965 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:46:09,312 - INFO  - Training [22][   20/  196]   Loss nan   Top1 9.570312   Top5 50.371094   BatchTime 0.317234   LR 0.000846   
2022-11-26 04:46:14,198 - INFO  - Training [22][   40/  196]   Loss nan   Top1 9.628906   Top5 51.230469   BatchTime 0.280759   LR 0.000827   
2022-11-26 04:46:19,007 - INFO  - Training [22][   60/  196]   Loss nan   Top1 9.726562   Top5 50.755208   BatchTime 0.267317   LR 0.000808   
2022-11-26 04:46:23,471 - INFO  - Training [22][   80/  196]   Loss nan   Top1 9.804688   Top5 50.732422   BatchTime 0.256294   LR 0.000789   
2022-11-26 04:46:28,472 - INFO  - Training [22][  100/  196]   Loss nan   Top1 9.761719   Top5 50.640625   BatchTime 0.255041   LR 0.000770   
2022-11-26 04:46:33,458 - INFO  - Training [22][  120/  196]   Loss nan   Top1 9.716797   Top5 50.338542   BatchTime 0.254081   LR 0.000752   
2022-11-26 04:46:38,462 - INFO  - Training [22][  140/  196]   Loss nan   Top1 9.679129   Top5 50.276228   BatchTime 0.253530   LR 0.000734   
2022-11-26 04:46:43,452 - INFO  - Training [22][  160/  196]   Loss nan   Top1 9.702148   Top5 50.100098   BatchTime 0.253021   LR 0.000715   
2022-11-26 04:46:48,375 - INFO  - Training [22][  180/  196]   Loss nan   Top1 9.752604   Top5 49.980469   BatchTime 0.252257   LR 0.000697   
2022-11-26 04:46:52,155 - INFO  - ==> Top1: 9.750    Top5: 49.908    Loss: nan

2022-11-26 04:46:52,350 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:46:53,356 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:46:55,608 - INFO  - Validation [22][   20/   40]   Loss 2.306795   Top1 9.882812   Top5 49.765625   BatchTime 0.112528   
2022-11-26 04:46:56,674 - INFO  - Validation [22][   40/   40]   Loss 2.306219   Top1 10.000000   Top5 50.000000   BatchTime 0.082931   
2022-11-26 04:46:56,864 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.306

2022-11-26 04:46:56,864 - INFO  - ==> Sparsity : 0.631

2022-11-26 04:46:56,864 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:46:56,865 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:46:56,865 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
2022-11-26 04:46:56,996 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:46:56,997 - INFO  - >>>>>> Epoch  23
2022-11-26 04:46:56,999 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:47:02,846 - INFO  - Training [23][   20/  196]   Loss nan   Top1 9.921875   Top5 49.609375   BatchTime 0.292106   LR 0.000666   
2022-11-26 04:47:07,971 - INFO  - Training [23][   40/  196]   Loss nan   Top1 9.912109   Top5 49.453125   BatchTime 0.274181   LR 0.000648   
2022-11-26 04:47:12,951 - INFO  - Training [23][   60/  196]   Loss nan   Top1 9.934896   Top5 49.127604   BatchTime 0.265792   LR 0.000630   
2022-11-26 04:47:17,936 - INFO  - Training [23][   80/  196]   Loss nan   Top1 9.965820   Top5 49.155273   BatchTime 0.261656   LR 0.000613   
2022-11-26 04:47:22,924 - INFO  - Training [23][  100/  196]   Loss nan   Top1 10.058594   Top5 49.355469   BatchTime 0.259205   LR 0.000596   
2022-11-26 04:47:27,922 - INFO  - Training [23][  120/  196]   Loss nan   Top1 9.954427   Top5 49.498698   BatchTime 0.257648   LR 0.000579   
2022-11-26 04:47:32,932 - INFO  - Training [23][  140/  196]   Loss nan   Top1 9.807478   Top5 49.469866   BatchTime 0.256627   LR 0.000562   
2022-11-26 04:47:37,926 - INFO  - Training [23][  160/  196]   Loss nan   Top1 9.877930   Top5 49.426270   BatchTime 0.255759   LR 0.000545   
2022-11-26 04:47:42,856 - INFO  - Training [23][  180/  196]   Loss nan   Top1 9.830729   Top5 49.526910   BatchTime 0.254729   LR 0.000529   
2022-11-26 04:47:46,565 - INFO  - ==> Top1: 9.810    Top5: 49.530    Loss: nan

2022-11-26 04:47:46,764 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:47:47,853 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:47:50,206 - INFO  - Validation [23][   20/   40]   Loss 2.306856   Top1 9.882812   Top5 50.039062   BatchTime 0.117562   
2022-11-26 04:47:51,306 - INFO  - Validation [23][   40/   40]   Loss 2.306343   Top1 10.000000   Top5 50.000000   BatchTime 0.086294   
2022-11-26 04:47:51,535 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.306

2022-11-26 04:47:51,536 - INFO  - ==> Sparsity : 0.631

2022-11-26 04:47:51,536 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:47:51,536 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:47:51,536 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
2022-11-26 04:47:51,647 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:47:51,648 - INFO  - >>>>>> Epoch  24
2022-11-26 04:47:51,650 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:47:57,627 - INFO  - Training [24][   20/  196]   Loss nan   Top1 9.824219   Top5 50.234375   BatchTime 0.298753   LR 0.000500   
2022-11-26 04:48:02,505 - INFO  - Training [24][   40/  196]   Loss nan   Top1 10.087891   Top5 50.498047   BatchTime 0.271322   LR 0.000484   
2022-11-26 04:48:07,207 - INFO  - Training [24][   60/  196]   Loss nan   Top1 10.130208   Top5 50.774740   BatchTime 0.259247   LR 0.000468   
2022-11-26 04:48:12,184 - INFO  - Training [24][   80/  196]   Loss nan   Top1 10.126953   Top5 50.341797   BatchTime 0.256649   LR 0.000453   
2022-11-26 04:48:17,168 - INFO  - Training [24][  100/  196]   Loss nan   Top1 10.097656   Top5 50.265625   BatchTime 0.255159   LR 0.000437   
2022-11-26 04:48:22,149 - INFO  - Training [24][  120/  196]   Loss nan   Top1 9.964193   Top5 50.009766   BatchTime 0.254140   LR 0.000422   
2022-11-26 04:48:27,153 - INFO  - Training [24][  140/  196]   Loss nan   Top1 9.969308   Top5 49.938616   BatchTime 0.253573   LR 0.000407   
2022-11-26 04:48:32,145 - INFO  - Training [24][  160/  196]   Loss nan   Top1 9.958496   Top5 49.938965   BatchTime 0.253075   LR 0.000392   
2022-11-26 04:48:36,897 - INFO  - Training [24][  180/  196]   Loss nan   Top1 9.950087   Top5 49.950087   BatchTime 0.251357   LR 0.000378   
2022-11-26 04:48:40,527 - INFO  - ==> Top1: 10.012    Top5: 49.910    Loss: nan

2022-11-26 04:48:40,724 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:48:41,920 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:48:44,206 - INFO  - Validation [24][   20/   40]   Loss 2.313929   Top1 9.882812   Top5 50.039062   BatchTime 0.114245   
2022-11-26 04:48:45,324 - INFO  - Validation [24][   40/   40]   Loss 2.313251   Top1 10.000000   Top5 50.000000   BatchTime 0.085077   
2022-11-26 04:48:45,548 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.313

2022-11-26 04:48:45,548 - INFO  - ==> Sparsity : 0.632

2022-11-26 04:48:45,548 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:48:45,549 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:48:45,549 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
2022-11-26 04:48:45,679 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:48:45,680 - INFO  - >>>>>> Epoch  25
2022-11-26 04:48:45,682 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:48:52,011 - INFO  - Training [25][   20/  196]   Loss nan   Top1 9.843750   Top5 50.000000   BatchTime 0.316287   LR 0.000353   
2022-11-26 04:48:56,836 - INFO  - Training [25][   40/  196]   Loss nan   Top1 9.960938   Top5 49.804688   BatchTime 0.278776   LR 0.000339   
2022-11-26 04:49:01,831 - INFO  - Training [25][   60/  196]   Loss nan   Top1 10.039062   Top5 49.889323   BatchTime 0.269100   LR 0.000325   
2022-11-26 04:49:07,084 - INFO  - Training [25][   80/  196]   Loss nan   Top1 9.980469   Top5 49.912109   BatchTime 0.267483   LR 0.000312   
2022-11-26 04:49:12,008 - INFO  - Training [25][  100/  196]   Loss nan   Top1 10.015625   Top5 49.933594   BatchTime 0.263229   LR 0.000299   
2022-11-26 04:49:16,897 - INFO  - Training [25][  120/  196]   Loss nan   Top1 10.058594   Top5 49.895833   BatchTime 0.260096   LR 0.000286   
2022-11-26 04:49:21,755 - INFO  - Training [25][  140/  196]   Loss nan   Top1 9.991629   Top5 49.743304   BatchTime 0.257641   LR 0.000273   
2022-11-26 04:49:26,691 - INFO  - Training [25][  160/  196]   Loss nan   Top1 9.946289   Top5 49.743652   BatchTime 0.256288   LR 0.000261   
2022-11-26 04:49:31,476 - INFO  - Training [25][  180/  196]   Loss nan   Top1 9.989149   Top5 49.743924   BatchTime 0.254390   LR 0.000248   
2022-11-26 04:49:35,459 - INFO  - ==> Top1: 9.988    Top5: 49.732    Loss: nan

2022-11-26 04:49:35,669 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:49:36,618 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:49:38,908 - INFO  - Validation [25][   20/   40]   Loss 2.304977   Top1 9.882812   Top5 50.039062   BatchTime 0.114415   
2022-11-26 04:49:40,016 - INFO  - Validation [25][   40/   40]   Loss 2.304803   Top1 10.000000   Top5 50.000000   BatchTime 0.084921   
2022-11-26 04:49:40,201 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305

2022-11-26 04:49:40,201 - INFO  - ==> Sparsity : 0.632

2022-11-26 04:49:40,202 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:49:40,202 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:49:40,202 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
2022-11-26 04:49:40,479 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:49:40,481 - INFO  - >>>>>> Epoch  26
2022-11-26 04:49:40,483 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:49:46,997 - INFO  - Training [26][   20/  196]   Loss nan   Top1 9.492188   Top5 49.179688   BatchTime 0.325590   LR 0.000228   
2022-11-26 04:49:52,029 - INFO  - Training [26][   40/  196]   Loss nan   Top1 9.228516   Top5 48.847656   BatchTime 0.288602   LR 0.000216   
2022-11-26 04:49:56,985 - INFO  - Training [26][   60/  196]   Loss nan   Top1 9.472656   Top5 48.997396   BatchTime 0.274994   LR 0.000205   
2022-11-26 04:50:02,030 - INFO  - Training [26][   80/  196]   Loss nan   Top1 9.599609   Top5 49.267578   BatchTime 0.269315   LR 0.000194   
2022-11-26 04:50:06,985 - INFO  - Training [26][  100/  196]   Loss nan   Top1 9.636719   Top5 49.312500   BatchTime 0.264997   LR 0.000183   
2022-11-26 04:50:12,086 - INFO  - Training [26][  120/  196]   Loss nan   Top1 9.739583   Top5 49.335938   BatchTime 0.263335   LR 0.000173   
2022-11-26 04:50:17,107 - INFO  - Training [26][  140/  196]   Loss nan   Top1 9.796317   Top5 49.416853   BatchTime 0.261584   LR 0.000163   
2022-11-26 04:50:22,080 - INFO  - Training [26][  160/  196]   Loss nan   Top1 9.877930   Top5 49.729004   BatchTime 0.259964   LR 0.000153   
2022-11-26 04:50:26,836 - INFO  - Training [26][  180/  196]   Loss nan   Top1 9.832899   Top5 49.796007   BatchTime 0.257502   LR 0.000144   
2022-11-26 04:50:30,698 - INFO  - ==> Top1: 9.826    Top5: 49.792    Loss: nan

2022-11-26 04:50:30,893 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:50:32,017 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:50:34,329 - INFO  - Validation [26][   20/   40]   Loss 2.305283   Top1 9.882812   Top5 50.039062   BatchTime 0.115489   
2022-11-26 04:50:35,428 - INFO  - Validation [26][   40/   40]   Loss 2.305098   Top1 10.000000   Top5 50.000000   BatchTime 0.085232   
2022-11-26 04:50:35,623 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305

2022-11-26 04:50:35,624 - INFO  - ==> Sparsity : 0.632

2022-11-26 04:50:35,624 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:50:35,624 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:50:35,624 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
2022-11-26 04:50:35,733 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:50:35,735 - INFO  - >>>>>> Epoch  27
2022-11-26 04:50:35,736 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:50:42,001 - INFO  - Training [27][   20/  196]   Loss nan   Top1 10.019531   Top5 50.585938   BatchTime 0.313123   LR 0.000128   
2022-11-26 04:50:47,039 - INFO  - Training [27][   40/  196]   Loss nan   Top1 10.283203   Top5 50.107422   BatchTime 0.282505   LR 0.000119   
2022-11-26 04:50:51,992 - INFO  - Training [27][   60/  196]   Loss nan   Top1 10.156250   Top5 50.084635   BatchTime 0.270892   LR 0.000111   
2022-11-26 04:50:56,975 - INFO  - Training [27][   80/  196]   Loss nan   Top1 10.058594   Top5 49.965820   BatchTime 0.265456   LR 0.000102   
2022-11-26 04:51:01,922 - INFO  - Training [27][  100/  196]   Loss nan   Top1 10.074219   Top5 50.031250   BatchTime 0.261829   LR 0.000095   
2022-11-26 04:51:06,967 - INFO  - Training [27][  120/  196]   Loss nan   Top1 10.139974   Top5 49.899089   BatchTime 0.260231   LR 0.000087   
2022-11-26 04:51:12,096 - INFO  - Training [27][  140/  196]   Loss nan   Top1 10.119978   Top5 49.751674   BatchTime 0.259689   LR 0.000080   
2022-11-26 04:51:17,070 - INFO  - Training [27][  160/  196]   Loss nan   Top1 10.085449   Top5 49.755859   BatchTime 0.258319   LR 0.000073   
2022-11-26 04:51:21,850 - INFO  - Training [27][  180/  196]   Loss nan   Top1 10.010851   Top5 49.720052   BatchTime 0.256170   LR 0.000066   
2022-11-26 04:51:25,810 - INFO  - ==> Top1: 9.978    Top5: 49.706    Loss: nan

2022-11-26 04:51:25,988 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:51:27,262 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:51:29,548 - INFO  - Validation [27][   20/   40]   Loss 2.305041   Top1 9.882812   Top5 50.039062   BatchTime 0.114206   
2022-11-26 04:51:30,684 - INFO  - Validation [27][   40/   40]   Loss 2.304821   Top1 10.000000   Top5 50.000000   BatchTime 0.085501   
2022-11-26 04:51:30,903 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305

2022-11-26 04:51:30,904 - INFO  - ==> Sparsity : 0.633

2022-11-26 04:51:30,904 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:51:30,904 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:51:30,904 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
2022-11-26 04:51:31,038 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:51:31,040 - INFO  - >>>>>> Epoch  28
2022-11-26 04:51:31,041 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:51:37,553 - INFO  - Training [28][   20/  196]   Loss nan   Top1 9.609375   Top5 49.433594   BatchTime 0.325457   LR 0.000055   
2022-11-26 04:51:42,520 - INFO  - Training [28][   40/  196]   Loss nan   Top1 10.000000   Top5 50.263672   BatchTime 0.286910   LR 0.000050   
2022-11-26 04:51:47,592 - INFO  - Training [28][   60/  196]   Loss nan   Top1 9.928385   Top5 50.423177   BatchTime 0.275793   LR 0.000044   
2022-11-26 04:51:52,605 - INFO  - Training [28][   80/  196]   Loss nan   Top1 10.053711   Top5 50.322266   BatchTime 0.269517   LR 0.000039   
2022-11-26 04:51:57,580 - INFO  - Training [28][  100/  196]   Loss nan   Top1 9.921875   Top5 50.160156   BatchTime 0.265360   LR 0.000034   
2022-11-26 04:52:02,596 - INFO  - Training [28][  120/  196]   Loss nan   Top1 9.899089   Top5 50.139974   BatchTime 0.262928   LR 0.000030   
2022-11-26 04:52:07,487 - INFO  - Training [28][  140/  196]   Loss nan   Top1 9.972098   Top5 50.234375   BatchTime 0.260305   LR 0.000026   
2022-11-26 04:52:12,469 - INFO  - Training [28][  160/  196]   Loss nan   Top1 9.860840   Top5 50.153809   BatchTime 0.258906   LR 0.000022   
2022-11-26 04:52:17,493 - INFO  - Training [28][  180/  196]   Loss nan   Top1 9.841580   Top5 49.997830   BatchTime 0.258049   LR 0.000018   
2022-11-26 04:52:21,556 - INFO  - ==> Top1: 9.816    Top5: 50.010    Loss: nan

2022-11-26 04:52:21,724 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:52:22,693 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:52:25,039 - INFO  - Validation [28][   20/   40]   Loss 2.305744   Top1 9.882812   Top5 50.039062   BatchTime 0.117200   
2022-11-26 04:52:26,169 - INFO  - Validation [28][   40/   40]   Loss 2.305485   Top1 10.000000   Top5 50.000000   BatchTime 0.086858   
2022-11-26 04:52:26,364 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305

2022-11-26 04:52:26,364 - INFO  - ==> Sparsity : 0.633

2022-11-26 04:52:26,364 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:52:26,364 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:52:26,365 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 10.000   Top5: 50.000]
2022-11-26 04:52:26,656 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:52:26,657 - INFO  - >>>>>> Epoch  29
2022-11-26 04:52:26,659 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:52:33,010 - INFO  - Training [29][   20/  196]   Loss nan   Top1 10.117188   Top5 49.726562   BatchTime 0.317442   LR 0.000013   
2022-11-26 04:52:38,084 - INFO  - Training [29][   40/  196]   Loss nan   Top1 10.185547   Top5 49.794922   BatchTime 0.285571   LR 0.000010   
2022-11-26 04:52:43,111 - INFO  - Training [29][   60/  196]   Loss nan   Top1 9.934896   Top5 50.123698   BatchTime 0.274168   LR 0.000008   
2022-11-26 04:52:48,075 - INFO  - Training [29][   80/  196]   Loss nan   Top1 10.000000   Top5 50.053711   BatchTime 0.267671   LR 0.000005   
2022-11-26 04:52:53,093 - INFO  - Training [29][  100/  196]   Loss nan   Top1 9.992188   Top5 50.175781   BatchTime 0.264320   LR 0.000004   
2022-11-26 04:52:58,094 - INFO  - Training [29][  120/  196]   Loss nan   Top1 10.130208   Top5 50.309245   BatchTime 0.261939   LR 0.000002   
2022-11-26 04:53:03,099 - INFO  - Training [29][  140/  196]   Loss nan   Top1 10.069754   Top5 50.270647   BatchTime 0.260266   LR 0.000001   
2022-11-26 04:53:08,077 - INFO  - Training [29][  160/  196]   Loss nan   Top1 10.019531   Top5 50.217285   BatchTime 0.258844   LR 0.000001   
2022-11-26 04:53:12,878 - INFO  - Training [29][  180/  196]   Loss nan   Top1 9.997830   Top5 50.223524   BatchTime 0.256756   LR 0.000000   
2022-11-26 04:53:16,842 - INFO  - ==> Top1: 9.966    Top5: 50.250    Loss: nan

2022-11-26 04:53:17,048 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:53:18,335 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:53:20,652 - INFO  - Validation [29][   20/   40]   Loss 2.314708   Top1 9.882812   Top5 50.039062   BatchTime 0.115800   
2022-11-26 04:53:21,768 - INFO  - Validation [29][   40/   40]   Loss 2.314089   Top1 10.000000   Top5 50.000000   BatchTime 0.085792   
2022-11-26 04:53:22,003 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.314

2022-11-26 04:53:22,003 - INFO  - ==> Sparsity : 0.632

2022-11-26 04:53:22,003 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:53:22,003 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:53:22,004 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 10.000   Top5: 50.000]
2022-11-26 04:53:22,123 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:53:22,125 - INFO  - >>>>>> Epoch  30
2022-11-26 04:53:22,127 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:53:28,241 - INFO  - Training [30][   20/  196]   Loss nan   Top1 9.238281   Top5 49.199219   BatchTime 0.305617   LR 0.001250   
2022-11-26 04:53:32,979 - INFO  - Training [30][   40/  196]   Loss nan   Top1 9.824219   Top5 49.736328   BatchTime 0.271261   LR 0.001250   
2022-11-26 04:53:37,737 - INFO  - Training [30][   60/  196]   Loss nan   Top1 10.097656   Top5 50.097656   BatchTime 0.260130   LR 0.001250   
2022-11-26 04:53:42,411 - INFO  - Training [30][   80/  196]   Loss nan   Top1 10.004883   Top5 49.711914   BatchTime 0.253518   LR 0.001250   
2022-11-26 04:53:47,420 - INFO  - Training [30][  100/  196]   Loss nan   Top1 9.902344   Top5 49.503906   BatchTime 0.252909   LR 0.001250   
2022-11-26 04:53:52,498 - INFO  - Training [30][  120/  196]   Loss nan   Top1 9.899089   Top5 49.619141   BatchTime 0.253071   LR 0.001249   
2022-11-26 04:53:57,583 - INFO  - Training [30][  140/  196]   Loss nan   Top1 9.913504   Top5 49.595424   BatchTime 0.253242   LR 0.001249   
2022-11-26 04:54:02,834 - INFO  - Training [30][  160/  196]   Loss nan   Top1 9.968262   Top5 49.687500   BatchTime 0.254401   LR 0.001249   
2022-11-26 04:54:07,696 - INFO  - Training [30][  180/  196]   Loss nan   Top1 9.958767   Top5 49.552951   BatchTime 0.253148   LR 0.001248   
2022-11-26 04:54:11,848 - INFO  - ==> Top1: 9.968    Top5: 49.522    Loss: nan

2022-11-26 04:54:12,119 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:54:13,470 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:54:15,686 - INFO  - Validation [30][   20/   40]   Loss 2.313959   Top1 10.078125   Top5 50.058594   BatchTime 0.110748   
2022-11-26 04:54:16,752 - INFO  - Validation [30][   40/   40]   Loss 2.314514   Top1 10.000000   Top5 50.000000   BatchTime 0.082010   
2022-11-26 04:54:16,930 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.315

2022-11-26 04:54:16,930 - INFO  - ==> Sparsity : 0.594

2022-11-26 04:54:16,931 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:54:16,931 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:54:16,931 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 10.000   Top5: 50.000]
2022-11-26 04:54:17,060 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:54:17,062 - INFO  - >>>>>> Epoch  31
2022-11-26 04:54:17,063 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:54:23,584 - INFO  - Training [31][   20/  196]   Loss nan   Top1 10.507812   Top5 49.687500   BatchTime 0.325905   LR 0.001248   
2022-11-26 04:54:28,609 - INFO  - Training [31][   40/  196]   Loss nan   Top1 10.527344   Top5 50.439453   BatchTime 0.288588   LR 0.001247   
2022-11-26 04:54:33,563 - INFO  - Training [31][   60/  196]   Loss nan   Top1 10.397135   Top5 50.364583   BatchTime 0.274961   LR 0.001247   
2022-11-26 04:54:38,514 - INFO  - Training [31][   80/  196]   Loss nan   Top1 10.283203   Top5 50.546875   BatchTime 0.268097   LR 0.001246   
2022-11-26 04:54:43,479 - INFO  - Training [31][  100/  196]   Loss nan   Top1 10.167969   Top5 50.328125   BatchTime 0.264135   LR 0.001246   
2022-11-26 04:54:48,521 - INFO  - Training [31][  120/  196]   Loss nan   Top1 10.299479   Top5 50.410156   BatchTime 0.262125   LR 0.001245   
2022-11-26 04:54:53,482 - INFO  - Training [31][  140/  196]   Loss nan   Top1 10.167411   Top5 50.365513   BatchTime 0.260112   LR 0.001244   
2022-11-26 04:54:58,546 - INFO  - Training [31][  160/  196]   Loss nan   Top1 10.153809   Top5 50.231934   BatchTime 0.259248   LR 0.001244   
2022-11-26 04:55:03,524 - INFO  - Training [31][  180/  196]   Loss nan   Top1 10.067274   Top5 50.156250   BatchTime 0.258102   LR 0.001243   
2022-11-26 04:55:07,590 - INFO  - ==> Top1: 10.094    Top5: 50.316    Loss: nan

2022-11-26 04:55:07,785 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:55:08,983 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:55:11,206 - INFO  - Validation [31][   20/   40]   Loss 2.391478   Top1 10.078125   Top5 50.058594   BatchTime 0.111111   
2022-11-26 04:55:12,248 - INFO  - Validation [31][   40/   40]   Loss 2.393134   Top1 10.000000   Top5 50.000000   BatchTime 0.081607   
2022-11-26 04:55:12,455 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.393

2022-11-26 04:55:12,456 - INFO  - ==> Sparsity : 0.608

2022-11-26 04:55:12,456 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:55:12,456 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:55:12,456 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 10.000   Top5: 50.000]
2022-11-26 04:55:12,584 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:55:12,586 - INFO  - >>>>>> Epoch  32
2022-11-26 04:55:12,588 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:55:19,073 - INFO  - Training [32][   20/  196]   Loss nan   Top1 9.960938   Top5 50.000000   BatchTime 0.324148   LR 0.001242   
2022-11-26 04:55:23,989 - INFO  - Training [32][   40/  196]   Loss nan   Top1 9.804688   Top5 50.078125   BatchTime 0.284980   LR 0.001241   
2022-11-26 04:55:28,744 - INFO  - Training [32][   60/  196]   Loss nan   Top1 9.674479   Top5 49.746094   BatchTime 0.269235   LR 0.001240   
2022-11-26 04:55:33,825 - INFO  - Training [32][   80/  196]   Loss nan   Top1 9.960938   Top5 49.833984   BatchTime 0.265433   LR 0.001239   
2022-11-26 04:55:38,753 - INFO  - Training [32][  100/  196]   Loss nan   Top1 10.062500   Top5 49.847656   BatchTime 0.261624   LR 0.001238   
2022-11-26 04:55:43,765 - INFO  - Training [32][  120/  196]   Loss nan   Top1 10.110677   Top5 49.619141   BatchTime 0.259791   LR 0.001237   
2022-11-26 04:55:48,757 - INFO  - Training [32][  140/  196]   Loss nan   Top1 10.114397   Top5 49.760045   BatchTime 0.258329   LR 0.001236   
2022-11-26 04:55:53,749 - INFO  - Training [32][  160/  196]   Loss nan   Top1 10.112305   Top5 49.812012   BatchTime 0.257242   LR 0.001235   
2022-11-26 04:55:58,717 - INFO  - Training [32][  180/  196]   Loss nan   Top1 10.052083   Top5 49.759115   BatchTime 0.256259   LR 0.001234   
2022-11-26 04:56:02,796 - INFO  - ==> Top1: 9.990    Top5: 49.668    Loss: nan

2022-11-26 04:56:03,011 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:56:04,372 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:56:06,675 - INFO  - Validation [32][   20/   40]   Loss 2.307618   Top1 10.078125   Top5 50.058594   BatchTime 0.115030   
2022-11-26 04:56:07,742 - INFO  - Validation [32][   40/   40]   Loss 2.307892   Top1 10.000000   Top5 50.000000   BatchTime 0.084198   
2022-11-26 04:56:07,902 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.308

2022-11-26 04:56:07,903 - INFO  - ==> Sparsity : 0.617

2022-11-26 04:56:07,903 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:56:07,903 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:56:07,903 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 10.000   Top5: 50.000]
2022-11-26 04:56:08,025 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:56:08,027 - INFO  - >>>>>> Epoch  33
2022-11-26 04:56:08,029 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:56:14,607 - INFO  - Training [33][   20/  196]   Loss nan   Top1 9.921875   Top5 50.019531   BatchTime 0.328789   LR 0.001232   
2022-11-26 04:56:19,601 - INFO  - Training [33][   40/  196]   Loss nan   Top1 9.785156   Top5 49.433594   BatchTime 0.289254   LR 0.001230   
2022-11-26 04:56:24,497 - INFO  - Training [33][   60/  196]   Loss nan   Top1 9.739583   Top5 49.544271   BatchTime 0.274436   LR 0.001229   
2022-11-26 04:56:29,722 - INFO  - Training [33][   80/  196]   Loss nan   Top1 9.980469   Top5 49.731445   BatchTime 0.271134   LR 0.001228   
2022-11-26 04:56:34,802 - INFO  - Training [33][  100/  196]   Loss nan   Top1 9.878906   Top5 49.546875   BatchTime 0.267707   LR 0.001226   
2022-11-26 04:56:39,801 - INFO  - Training [33][  120/  196]   Loss nan   Top1 9.895833   Top5 49.765625   BatchTime 0.264748   LR 0.001225   
2022-11-26 04:56:44,737 - INFO  - Training [33][  140/  196]   Loss nan   Top1 9.933036   Top5 49.829799   BatchTime 0.262183   LR 0.001224   
2022-11-26 04:56:49,781 - INFO  - Training [33][  160/  196]   Loss nan   Top1 9.968262   Top5 49.721680   BatchTime 0.260934   LR 0.001222   
2022-11-26 04:56:54,441 - INFO  - Training [33][  180/  196]   Loss nan   Top1 9.945747   Top5 49.683160   BatchTime 0.257827   LR 0.001221   
2022-11-26 04:56:58,290 - INFO  - ==> Top1: 9.936    Top5: 49.708    Loss: nan

2022-11-26 04:56:58,497 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:56:59,753 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:57:02,100 - INFO  - Validation [33][   20/   40]   Loss 2.377448   Top1 10.078125   Top5 50.214844   BatchTime 0.117259   
2022-11-26 04:57:03,152 - INFO  - Validation [33][   40/   40]   Loss 2.378859   Top1 10.000000   Top5 50.000000   BatchTime 0.084941   
2022-11-26 04:57:03,375 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.379

2022-11-26 04:57:03,376 - INFO  - ==> Sparsity : 0.624

2022-11-26 04:57:03,376 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:57:03,376 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:57:03,376 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 10.000   Top5: 50.000]
2022-11-26 04:57:03,509 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:57:03,511 - INFO  - >>>>>> Epoch  34
2022-11-26 04:57:03,512 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:57:09,850 - INFO  - Training [34][   20/  196]   Loss nan   Top1 11.152344   Top5 51.132812   BatchTime 0.316758   LR 0.001218   
2022-11-26 04:57:14,762 - INFO  - Training [34][   40/  196]   Loss nan   Top1 10.673828   Top5 50.703125   BatchTime 0.281184   LR 0.001216   
2022-11-26 04:57:19,820 - INFO  - Training [34][   60/  196]   Loss nan   Top1 10.214844   Top5 50.377604   BatchTime 0.271751   LR 0.001215   
2022-11-26 04:57:24,826 - INFO  - Training [34][   80/  196]   Loss nan   Top1 10.092773   Top5 50.419922   BatchTime 0.266380   LR 0.001213   
2022-11-26 04:57:29,801 - INFO  - Training [34][  100/  196]   Loss nan   Top1 10.027344   Top5 50.242188   BatchTime 0.262858   LR 0.001211   
2022-11-26 04:57:34,833 - INFO  - Training [34][  120/  196]   Loss nan   Top1 9.951172   Top5 50.120443   BatchTime 0.260980   LR 0.001209   
2022-11-26 04:57:39,772 - INFO  - Training [34][  140/  196]   Loss nan   Top1 9.866071   Top5 50.025112   BatchTime 0.258979   LR 0.001208   
2022-11-26 04:57:44,993 - INFO  - Training [34][  160/  196]   Loss nan   Top1 9.973145   Top5 49.943848   BatchTime 0.259235   LR 0.001206   
2022-11-26 04:57:50,135 - INFO  - Training [34][  180/  196]   Loss nan   Top1 10.019531   Top5 49.917535   BatchTime 0.258999   LR 0.001204   
2022-11-26 04:57:54,275 - INFO  - ==> Top1: 9.988    Top5: 49.904    Loss: nan

2022-11-26 04:57:54,464 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:57:55,617 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:57:57,864 - INFO  - Validation [34][   20/   40]   Loss 16.407087   Top1 10.078125   Top5 50.195312   BatchTime 0.112271   
2022-11-26 04:57:58,937 - INFO  - Validation [34][   40/   40]   Loss 16.444496   Top1 10.000000   Top5 50.000000   BatchTime 0.082976   
2022-11-26 04:57:59,116 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 16.444

2022-11-26 04:57:59,116 - INFO  - ==> Sparsity : 0.459

2022-11-26 04:57:59,116 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:57:59,116 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:57:59,117 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 10.000   Top5: 50.000]
2022-11-26 04:57:59,230 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:57:59,232 - INFO  - >>>>>> Epoch  35
2022-11-26 04:57:59,233 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:58:05,293 - INFO  - Training [35][   20/  196]   Loss nan   Top1 9.375000   Top5 50.136719   BatchTime 0.302857   LR 0.001201   
2022-11-26 04:58:10,339 - INFO  - Training [35][   40/  196]   Loss nan   Top1 9.697266   Top5 50.000000   BatchTime 0.277589   LR 0.001199   
2022-11-26 04:58:15,223 - INFO  - Training [35][   60/  196]   Loss nan   Top1 9.804688   Top5 50.039062   BatchTime 0.266447   LR 0.001197   
2022-11-26 04:58:20,221 - INFO  - Training [35][   80/  196]   Loss nan   Top1 9.648438   Top5 49.790039   BatchTime 0.262312   LR 0.001195   
2022-11-26 04:58:25,319 - INFO  - Training [35][  100/  196]   Loss nan   Top1 9.621094   Top5 49.929688   BatchTime 0.260835   LR 0.001192   
2022-11-26 04:58:30,233 - INFO  - Training [35][  120/  196]   Loss nan   Top1 9.710286   Top5 49.990234   BatchTime 0.258308   LR 0.001190   
2022-11-26 04:58:35,247 - INFO  - Training [35][  140/  196]   Loss nan   Top1 9.737723   Top5 49.963728   BatchTime 0.257221   LR 0.001188   
2022-11-26 04:58:40,252 - INFO  - Training [35][  160/  196]   Loss nan   Top1 9.807129   Top5 49.924316   BatchTime 0.256347   LR 0.001186   
2022-11-26 04:58:44,939 - INFO  - Training [35][  180/  196]   Loss nan   Top1 9.730903   Top5 49.947917   BatchTime 0.253903   LR 0.001184   
2022-11-26 04:58:48,811 - INFO  - ==> Top1: 9.674    Top5: 49.956    Loss: nan

2022-11-26 04:58:48,992 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:58:50,248 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:58:52,512 - INFO  - Validation [35][   20/   40]   Loss 12.463055   Top1 10.078125   Top5 50.058594   BatchTime 0.113112   
2022-11-26 04:58:53,610 - INFO  - Validation [35][   40/   40]   Loss 12.490792   Top1 10.000000   Top5 50.000000   BatchTime 0.084009   
2022-11-26 04:58:53,838 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 12.491

2022-11-26 04:58:53,838 - INFO  - ==> Sparsity : 0.464

2022-11-26 04:58:53,838 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:58:53,838 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:58:53,838 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 10.000   Top5: 50.000]
2022-11-26 04:58:53,957 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:58:53,959 - INFO  - >>>>>> Epoch  36
2022-11-26 04:58:53,960 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:59:00,230 - INFO  - Training [36][   20/  196]   Loss nan   Top1 9.960938   Top5 50.996094   BatchTime 0.313339   LR 0.001180   
2022-11-26 04:59:05,271 - INFO  - Training [36][   40/  196]   Loss nan   Top1 10.205078   Top5 51.142578   BatchTime 0.282696   LR 0.001177   
2022-11-26 04:59:10,230 - INFO  - Training [36][   60/  196]   Loss nan   Top1 9.960938   Top5 50.455729   BatchTime 0.271111   LR 0.001175   
2022-11-26 04:59:15,250 - INFO  - Training [36][   80/  196]   Loss nan   Top1 9.995117   Top5 50.122070   BatchTime 0.266085   LR 0.001173   
2022-11-26 04:59:20,248 - INFO  - Training [36][  100/  196]   Loss nan   Top1 9.902344   Top5 50.183594   BatchTime 0.262842   LR 0.001170   
2022-11-26 04:59:25,312 - INFO  - Training [36][  120/  196]   Loss nan   Top1 9.837240   Top5 49.977214   BatchTime 0.261236   LR 0.001168   
2022-11-26 04:59:30,155 - INFO  - Training [36][  140/  196]   Loss nan   Top1 9.801897   Top5 49.785156   BatchTime 0.258505   LR 0.001165   
2022-11-26 04:59:34,950 - INFO  - Training [36][  160/  196]   Loss nan   Top1 9.797363   Top5 49.770508   BatchTime 0.256163   LR 0.001163   
2022-11-26 04:59:40,000 - INFO  - Training [36][  180/  196]   Loss nan   Top1 9.772135   Top5 49.698351   BatchTime 0.255755   LR 0.001160   
2022-11-26 04:59:44,075 - INFO  - ==> Top1: 9.760    Top5: 49.634    Loss: nan

2022-11-26 04:59:44,272 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 04:59:45,311 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 04:59:47,552 - INFO  - Validation [36][   20/   40]   Loss 10.397360   Top1 10.078125   Top5 50.058594   BatchTime 0.111975   
2022-11-26 04:59:48,517 - INFO  - Validation [36][   40/   40]   Loss 10.419389   Top1 10.000000   Top5 50.000000   BatchTime 0.080097   
2022-11-26 04:59:48,745 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 10.419

2022-11-26 04:59:48,745 - INFO  - ==> Sparsity : 0.467

2022-11-26 04:59:48,745 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 04:59:48,746 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 04:59:48,746 - INFO  - Scoreboard best 3 ==> Epoch [36][Top1: 10.000   Top5: 50.000]
2022-11-26 04:59:48,879 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 04:59:48,880 - INFO  - >>>>>> Epoch  37
2022-11-26 04:59:48,882 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 04:59:55,082 - INFO  - Training [37][   20/  196]   Loss nan   Top1 9.492188   Top5 50.175781   BatchTime 0.309870   LR 0.001155   
2022-11-26 05:00:00,208 - INFO  - Training [37][   40/  196]   Loss nan   Top1 9.433594   Top5 50.058594   BatchTime 0.283085   LR 0.001153   
2022-11-26 05:00:05,620 - INFO  - Training [37][   60/  196]   Loss nan   Top1 9.472656   Top5 49.947917   BatchTime 0.278925   LR 0.001150   
2022-11-26 05:00:10,821 - INFO  - Training [37][   80/  196]   Loss nan   Top1 9.501953   Top5 50.029297   BatchTime 0.274193   LR 0.001147   
2022-11-26 05:00:15,802 - INFO  - Training [37][  100/  196]   Loss nan   Top1 9.742188   Top5 50.183594   BatchTime 0.269168   LR 0.001144   
2022-11-26 05:00:20,816 - INFO  - Training [37][  120/  196]   Loss nan   Top1 9.788411   Top5 50.231120   BatchTime 0.266092   LR 0.001142   
2022-11-26 05:00:25,991 - INFO  - Training [37][  140/  196]   Loss nan   Top1 9.796317   Top5 50.234375   BatchTime 0.265044   LR 0.001139   
2022-11-26 05:00:31,339 - INFO  - Training [37][  160/  196]   Loss nan   Top1 9.799805   Top5 50.253906   BatchTime 0.265334   LR 0.001136   
2022-11-26 05:00:36,209 - INFO  - Training [37][  180/  196]   Loss nan   Top1 9.759115   Top5 50.115017   BatchTime 0.262908   LR 0.001133   
2022-11-26 05:00:40,335 - INFO  - ==> Top1: 9.690    Top5: 50.188    Loss: nan

2022-11-26 05:00:40,600 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:00:42,009 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:00:44,216 - INFO  - Validation [37][   20/   40]   Loss 5.650106   Top1 10.078125   Top5 50.195312   BatchTime 0.110246   
2022-11-26 05:00:45,333 - INFO  - Validation [37][   40/   40]   Loss 5.661198   Top1 10.000000   Top5 50.000000   BatchTime 0.083064   
2022-11-26 05:00:45,540 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 5.661

2022-11-26 05:00:45,540 - INFO  - ==> Sparsity : 0.480

2022-11-26 05:00:45,540 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:00:45,541 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:00:45,541 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 10.000   Top5: 50.000]
2022-11-26 05:00:45,653 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:00:45,654 - INFO  - >>>>>> Epoch  38
2022-11-26 05:00:45,656 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:00:51,788 - INFO  - Training [38][   20/  196]   Loss nan   Top1 10.156250   Top5 50.195312   BatchTime 0.306477   LR 0.001128   
2022-11-26 05:00:56,674 - INFO  - Training [38][   40/  196]   Loss nan   Top1 9.794922   Top5 50.302734   BatchTime 0.275389   LR 0.001125   
2022-11-26 05:01:01,539 - INFO  - Training [38][   60/  196]   Loss nan   Top1 9.993490   Top5 50.371094   BatchTime 0.264671   LR 0.001122   
2022-11-26 05:01:06,517 - INFO  - Training [38][   80/  196]   Loss nan   Top1 9.941406   Top5 50.258789   BatchTime 0.260731   LR 0.001119   
2022-11-26 05:01:11,515 - INFO  - Training [38][  100/  196]   Loss nan   Top1 9.960938   Top5 50.230469   BatchTime 0.258569   LR 0.001116   
2022-11-26 05:01:16,700 - INFO  - Training [38][  120/  196]   Loss nan   Top1 9.964193   Top5 50.130208   BatchTime 0.258676   LR 0.001112   
2022-11-26 05:01:21,759 - INFO  - Training [38][  140/  196]   Loss nan   Top1 10.027902   Top5 50.072545   BatchTime 0.257863   LR 0.001109   
2022-11-26 05:01:26,751 - INFO  - Training [38][  160/  196]   Loss nan   Top1 10.036621   Top5 50.036621   BatchTime 0.256824   LR 0.001106   
2022-11-26 05:01:31,700 - INFO  - Training [38][  180/  196]   Loss nan   Top1 10.010851   Top5 50.002170   BatchTime 0.255785   LR 0.001103   
2022-11-26 05:01:35,849 - INFO  - ==> Top1: 9.974    Top5: 49.994    Loss: nan

2022-11-26 05:01:36,147 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:01:37,734 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:01:40,007 - INFO  - Validation [38][   20/   40]   Loss 7.848091   Top1 10.078125   Top5 50.195312   BatchTime 0.113587   
2022-11-26 05:01:41,057 - INFO  - Validation [38][   40/   40]   Loss 7.863141   Top1 10.000000   Top5 50.000000   BatchTime 0.083036   
2022-11-26 05:01:41,279 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 7.863

2022-11-26 05:01:41,279 - INFO  - ==> Sparsity : 0.483

2022-11-26 05:01:41,280 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:01:41,280 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:01:41,280 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 10.000   Top5: 50.000]
2022-11-26 05:01:41,391 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:01:41,393 - INFO  - >>>>>> Epoch  39
2022-11-26 05:01:41,395 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:01:47,785 - INFO  - Training [39][   20/  196]   Loss nan   Top1 10.136719   Top5 49.960938   BatchTime 0.319415   LR 0.001097   
2022-11-26 05:01:52,782 - INFO  - Training [39][   40/  196]   Loss nan   Top1 9.736328   Top5 49.570312   BatchTime 0.284637   LR 0.001094   
2022-11-26 05:01:57,747 - INFO  - Training [39][   60/  196]   Loss nan   Top1 9.928385   Top5 49.622396   BatchTime 0.272497   LR 0.001090   
2022-11-26 05:02:02,851 - INFO  - Training [39][   80/  196]   Loss nan   Top1 9.980469   Top5 49.780273   BatchTime 0.268175   LR 0.001087   
2022-11-26 05:02:07,835 - INFO  - Training [39][  100/  196]   Loss nan   Top1 9.937500   Top5 49.718750   BatchTime 0.264380   LR 0.001084   
2022-11-26 05:02:12,821 - INFO  - Training [39][  120/  196]   Loss nan   Top1 9.853516   Top5 49.742839   BatchTime 0.261862   LR 0.001080   
2022-11-26 05:02:18,002 - INFO  - Training [39][  140/  196]   Loss nan   Top1 9.919085   Top5 49.815848   BatchTime 0.261463   LR 0.001077   
2022-11-26 05:02:22,926 - INFO  - Training [39][  160/  196]   Loss nan   Top1 9.914551   Top5 49.855957   BatchTime 0.259555   LR 0.001073   
2022-11-26 05:02:27,828 - INFO  - Training [39][  180/  196]   Loss nan   Top1 9.891493   Top5 49.926215   BatchTime 0.257948   LR 0.001070   
2022-11-26 05:02:31,799 - INFO  - ==> Top1: 9.892    Top5: 49.886    Loss: nan

2022-11-26 05:02:32,016 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:02:33,394 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:02:35,655 - INFO  - Validation [39][   20/   40]   Loss 8.200191   Top1 10.078125   Top5 50.058594   BatchTime 0.112979   
2022-11-26 05:02:36,651 - INFO  - Validation [39][   40/   40]   Loss 8.216335   Top1 10.000000   Top5 50.000000   BatchTime 0.081403   
2022-11-26 05:02:36,881 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 8.216

2022-11-26 05:02:36,881 - INFO  - ==> Sparsity : 0.485

2022-11-26 05:02:36,881 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:02:36,882 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:02:36,882 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 10.000   Top5: 50.000]
2022-11-26 05:02:37,013 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:02:37,014 - INFO  - >>>>>> Epoch  40
2022-11-26 05:02:37,016 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:02:43,471 - INFO  - Training [40][   20/  196]   Loss nan   Top1 10.097656   Top5 50.039062   BatchTime 0.322624   LR 0.001064   
2022-11-26 05:02:48,808 - INFO  - Training [40][   40/  196]   Loss nan   Top1 9.833984   Top5 50.166016   BatchTime 0.294730   LR 0.001060   
2022-11-26 05:02:53,758 - INFO  - Training [40][   60/  196]   Loss nan   Top1 9.876302   Top5 49.856771   BatchTime 0.278994   LR 0.001056   
2022-11-26 05:02:58,707 - INFO  - Training [40][   80/  196]   Loss nan   Top1 9.907227   Top5 49.931641   BatchTime 0.271099   LR 0.001053   
2022-11-26 05:03:03,695 - INFO  - Training [40][  100/  196]   Loss nan   Top1 10.164062   Top5 50.105469   BatchTime 0.266759   LR 0.001049   
2022-11-26 05:03:08,702 - INFO  - Training [40][  120/  196]   Loss nan   Top1 10.143229   Top5 50.048828   BatchTime 0.264023   LR 0.001045   
2022-11-26 05:03:13,704 - INFO  - Training [40][  140/  196]   Loss nan   Top1 10.066964   Top5 50.086496   BatchTime 0.262034   LR 0.001042   
2022-11-26 05:03:18,687 - INFO  - Training [40][  160/  196]   Loss nan   Top1 10.036621   Top5 49.941406   BatchTime 0.260424   LR 0.001038   
2022-11-26 05:03:23,616 - INFO  - Training [40][  180/  196]   Loss nan   Top1 10.015191   Top5 49.963108   BatchTime 0.258870   LR 0.001034   
2022-11-26 05:03:27,613 - INFO  - ==> Top1: 10.022    Top5: 49.968    Loss: nan

2022-11-26 05:03:27,811 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:03:28,967 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:03:31,212 - INFO  - Validation [40][   20/   40]   Loss 9.101910   Top1 10.078125   Top5 50.058594   BatchTime 0.112172   
2022-11-26 05:03:32,287 - INFO  - Validation [40][   40/   40]   Loss 9.120362   Top1 10.000000   Top5 50.000000   BatchTime 0.082964   
2022-11-26 05:03:32,501 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 9.120

2022-11-26 05:03:32,501 - INFO  - ==> Sparsity : 0.487

2022-11-26 05:03:32,502 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:03:32,502 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:03:32,502 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 10.000   Top5: 50.000]
2022-11-26 05:03:32,630 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:03:32,632 - INFO  - >>>>>> Epoch  41
2022-11-26 05:03:32,634 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:03:38,993 - INFO  - Training [41][   20/  196]   Loss nan   Top1 10.449219   Top5 51.191406   BatchTime 0.317863   LR 0.001027   
2022-11-26 05:03:44,256 - INFO  - Training [41][   40/  196]   Loss nan   Top1 10.312500   Top5 50.781250   BatchTime 0.290506   LR 0.001023   
2022-11-26 05:03:49,319 - INFO  - Training [41][   60/  196]   Loss nan   Top1 10.195312   Top5 50.312500   BatchTime 0.278045   LR 0.001020   
2022-11-26 05:03:54,293 - INFO  - Training [41][   80/  196]   Loss nan   Top1 10.249023   Top5 50.166016   BatchTime 0.270704   LR 0.001016   
2022-11-26 05:03:59,197 - INFO  - Training [41][  100/  196]   Loss nan   Top1 10.265625   Top5 50.050781   BatchTime 0.265605   LR 0.001012   
2022-11-26 05:04:04,221 - INFO  - Training [41][  120/  196]   Loss nan   Top1 10.172526   Top5 49.947917   BatchTime 0.263203   LR 0.001008   
2022-11-26 05:04:09,209 - INFO  - Training [41][  140/  196]   Loss nan   Top1 10.086496   Top5 49.952567   BatchTime 0.261230   LR 0.001004   
2022-11-26 05:04:14,207 - INFO  - Training [41][  160/  196]   Loss nan   Top1 10.026855   Top5 49.921875   BatchTime 0.259815   LR 0.001000   
2022-11-26 05:04:19,115 - INFO  - Training [41][  180/  196]   Loss nan   Top1 10.062934   Top5 49.967448   BatchTime 0.258215   LR 0.000996   
2022-11-26 05:04:23,041 - INFO  - ==> Top1: 10.062    Top5: 50.088    Loss: nan

2022-11-26 05:04:23,239 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:04:24,433 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:04:26,626 - INFO  - Validation [41][   20/   40]   Loss 6.002224   Top1 10.078125   Top5 50.058594   BatchTime 0.109592   
2022-11-26 05:04:27,746 - INFO  - Validation [41][   40/   40]   Loss 6.013194   Top1 10.000000   Top5 50.000000   BatchTime 0.082786   
2022-11-26 05:04:27,960 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 6.013

2022-11-26 05:04:27,960 - INFO  - ==> Sparsity : 0.490

2022-11-26 05:04:27,960 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:04:27,960 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:04:27,960 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 10.000   Top5: 50.000]
2022-11-26 05:04:28,090 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:04:28,092 - INFO  - >>>>>> Epoch  42
2022-11-26 05:04:28,093 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:04:34,498 - INFO  - Training [42][   20/  196]   Loss nan   Top1 10.742188   Top5 49.394531   BatchTime 0.320089   LR 0.000988   
2022-11-26 05:04:39,417 - INFO  - Training [42][   40/  196]   Loss nan   Top1 10.537109   Top5 49.667969   BatchTime 0.283027   LR 0.000984   
2022-11-26 05:04:44,545 - INFO  - Training [42][   60/  196]   Loss nan   Top1 10.182292   Top5 49.472656   BatchTime 0.274156   LR 0.000980   
2022-11-26 05:04:49,622 - INFO  - Training [42][   80/  196]   Loss nan   Top1 10.219727   Top5 49.916992   BatchTime 0.269074   LR 0.000976   
2022-11-26 05:04:54,989 - INFO  - Training [42][  100/  196]   Loss nan   Top1 10.160156   Top5 49.800781   BatchTime 0.268928   LR 0.000972   
2022-11-26 05:05:00,074 - INFO  - Training [42][  120/  196]   Loss nan   Top1 10.182292   Top5 49.580078   BatchTime 0.266476   LR 0.000968   
2022-11-26 05:05:05,022 - INFO  - Training [42][  140/  196]   Loss nan   Top1 10.228795   Top5 49.617746   BatchTime 0.263752   LR 0.000964   
2022-11-26 05:05:09,988 - INFO  - Training [42][  160/  196]   Loss nan   Top1 10.158691   Top5 49.663086   BatchTime 0.261821   LR 0.000959   
2022-11-26 05:05:14,925 - INFO  - Training [42][  180/  196]   Loss nan   Top1 10.075955   Top5 49.600694   BatchTime 0.260160   LR 0.000955   
2022-11-26 05:05:18,854 - INFO  - ==> Top1: 10.110    Top5: 49.584    Loss: nan

2022-11-26 05:05:19,054 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:05:20,238 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:05:22,620 - INFO  - Validation [42][   20/   40]   Loss 3.825160   Top1 10.078125   Top5 50.058594   BatchTime 0.119021   
2022-11-26 05:05:23,770 - INFO  - Validation [42][   40/   40]   Loss 3.832590   Top1 10.000000   Top5 50.000000   BatchTime 0.088245   
2022-11-26 05:05:23,986 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 3.833

2022-11-26 05:05:23,986 - INFO  - ==> Sparsity : 0.491

2022-11-26 05:05:23,987 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:05:23,987 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:05:23,987 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 10.000   Top5: 50.000]
2022-11-26 05:05:24,256 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:05:24,258 - INFO  - >>>>>> Epoch  43
2022-11-26 05:05:24,260 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:05:30,627 - INFO  - Training [43][   20/  196]   Loss nan   Top1 9.394531   Top5 49.296875   BatchTime 0.318270   LR 0.000947   
2022-11-26 05:05:35,789 - INFO  - Training [43][   40/  196]   Loss nan   Top1 9.951172   Top5 49.726562   BatchTime 0.288176   LR 0.000943   
2022-11-26 05:05:40,793 - INFO  - Training [43][   60/  196]   Loss nan   Top1 9.941406   Top5 49.407552   BatchTime 0.275512   LR 0.000939   
2022-11-26 05:05:45,752 - INFO  - Training [43][   80/  196]   Loss nan   Top1 9.936523   Top5 49.785156   BatchTime 0.268622   LR 0.000934   
2022-11-26 05:05:50,719 - INFO  - Training [43][  100/  196]   Loss nan   Top1 9.855469   Top5 49.902344   BatchTime 0.264572   LR 0.000930   
2022-11-26 05:05:55,743 - INFO  - Training [43][  120/  196]   Loss nan   Top1 9.886068   Top5 49.736328   BatchTime 0.262339   LR 0.000926   
2022-11-26 05:06:00,767 - INFO  - Training [43][  140/  196]   Loss nan   Top1 9.871652   Top5 50.013951   BatchTime 0.260750   LR 0.000921   
2022-11-26 05:06:05,815 - INFO  - Training [43][  160/  196]   Loss nan   Top1 9.843750   Top5 49.843750   BatchTime 0.259703   LR 0.000917   
2022-11-26 05:06:10,750 - INFO  - Training [43][  180/  196]   Loss nan   Top1 9.952257   Top5 49.924045   BatchTime 0.258262   LR 0.000912   
2022-11-26 05:06:14,856 - INFO  - ==> Top1: 9.902    Top5: 49.814    Loss: nan

2022-11-26 05:06:15,090 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:06:16,383 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:06:18,639 - INFO  - Validation [43][   20/   40]   Loss 9.351119   Top1 10.078125   Top5 50.058594   BatchTime 0.112732   
2022-11-26 05:06:19,712 - INFO  - Validation [43][   40/   40]   Loss 9.371401   Top1 10.000000   Top5 50.000000   BatchTime 0.083195   
2022-11-26 05:06:19,889 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 9.371

2022-11-26 05:06:19,890 - INFO  - ==> Sparsity : 0.493

2022-11-26 05:06:19,890 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:06:19,890 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:06:19,890 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 10.000   Top5: 50.000]
2022-11-26 05:06:20,019 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:06:20,020 - INFO  - >>>>>> Epoch  44
2022-11-26 05:06:20,022 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:06:26,326 - INFO  - Training [44][   20/  196]   Loss nan   Top1 10.664062   Top5 49.531250   BatchTime 0.315076   LR 0.000904   
2022-11-26 05:06:31,323 - INFO  - Training [44][   40/  196]   Loss nan   Top1 10.253906   Top5 49.375000   BatchTime 0.282456   LR 0.000900   
2022-11-26 05:06:36,321 - INFO  - Training [44][   60/  196]   Loss nan   Top1 10.104167   Top5 49.733073   BatchTime 0.271605   LR 0.000895   
2022-11-26 05:06:41,394 - INFO  - Training [44][   80/  196]   Loss nan   Top1 10.068359   Top5 49.682617   BatchTime 0.267121   LR 0.000891   
2022-11-26 05:06:46,336 - INFO  - Training [44][  100/  196]   Loss nan   Top1 9.972656   Top5 49.593750   BatchTime 0.263110   LR 0.000886   
2022-11-26 05:06:51,179 - INFO  - Training [44][  120/  196]   Loss nan   Top1 9.973958   Top5 49.479167   BatchTime 0.259621   LR 0.000882   
2022-11-26 05:06:56,158 - INFO  - Training [44][  140/  196]   Loss nan   Top1 9.980469   Top5 49.455915   BatchTime 0.258091   LR 0.000877   
2022-11-26 05:07:01,135 - INFO  - Training [44][  160/  196]   Loss nan   Top1 10.039062   Top5 49.475098   BatchTime 0.256937   LR 0.000873   
2022-11-26 05:07:05,959 - INFO  - Training [44][  180/  196]   Loss nan   Top1 9.973958   Top5 49.461806   BatchTime 0.255187   LR 0.000868   
2022-11-26 05:07:09,762 - INFO  - ==> Top1: 9.984    Top5: 49.410    Loss: nan

2022-11-26 05:07:09,963 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:07:11,258 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:07:13,638 - INFO  - Validation [44][   20/   40]   Loss 9.361306   Top1 10.078125   Top5 50.058594   BatchTime 0.118881   
2022-11-26 05:07:14,757 - INFO  - Validation [44][   40/   40]   Loss 9.381198   Top1 10.000000   Top5 50.000000   BatchTime 0.087424   
2022-11-26 05:07:14,946 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 9.381

2022-11-26 05:07:14,946 - INFO  - ==> Sparsity : 0.493

2022-11-26 05:07:14,946 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:07:14,946 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:07:14,946 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 10.000   Top5: 50.000]
2022-11-26 05:07:15,074 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:07:15,076 - INFO  - >>>>>> Epoch  45
2022-11-26 05:07:15,077 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:07:21,518 - INFO  - Training [45][   20/  196]   Loss nan   Top1 10.136719   Top5 50.117188   BatchTime 0.321891   LR 0.000860   
2022-11-26 05:07:26,449 - INFO  - Training [45][   40/  196]   Loss nan   Top1 10.175781   Top5 49.746094   BatchTime 0.284237   LR 0.000855   
2022-11-26 05:07:31,587 - INFO  - Training [45][   60/  196]   Loss nan   Top1 9.915365   Top5 49.928385   BatchTime 0.275121   LR 0.000850   
2022-11-26 05:07:36,602 - INFO  - Training [45][   80/  196]   Loss nan   Top1 9.838867   Top5 49.760742   BatchTime 0.269026   LR 0.000846   
2022-11-26 05:07:41,468 - INFO  - Training [45][  100/  196]   Loss nan   Top1 9.812500   Top5 49.921875   BatchTime 0.263881   LR 0.000841   
2022-11-26 05:07:46,605 - INFO  - Training [45][  120/  196]   Loss nan   Top1 9.778646   Top5 50.065104   BatchTime 0.262703   LR 0.000836   
2022-11-26 05:07:51,679 - INFO  - Training [45][  140/  196]   Loss nan   Top1 9.771205   Top5 49.980469   BatchTime 0.261415   LR 0.000832   
2022-11-26 05:07:56,775 - INFO  - Training [45][  160/  196]   Loss nan   Top1 9.814453   Top5 50.090332   BatchTime 0.260588   LR 0.000827   
2022-11-26 05:08:01,751 - INFO  - Training [45][  180/  196]   Loss nan   Top1 9.843750   Top5 50.036892   BatchTime 0.259282   LR 0.000822   
2022-11-26 05:08:05,811 - INFO  - ==> Top1: 9.846    Top5: 49.966    Loss: nan

2022-11-26 05:08:06,018 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:08:07,133 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:08:09,467 - INFO  - Validation [45][   20/   40]   Loss 9.508318   Top1 10.078125   Top5 50.058594   BatchTime 0.116621   
2022-11-26 05:08:10,465 - INFO  - Validation [45][   40/   40]   Loss 9.529464   Top1 10.000000   Top5 50.000000   BatchTime 0.083261   
2022-11-26 05:08:10,689 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 9.529

2022-11-26 05:08:10,689 - INFO  - ==> Sparsity : 0.494

2022-11-26 05:08:10,689 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:08:10,689 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:08:10,690 - INFO  - Scoreboard best 3 ==> Epoch [45][Top1: 10.000   Top5: 50.000]
2022-11-26 05:08:11,011 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:08:11,013 - INFO  - >>>>>> Epoch  46
2022-11-26 05:08:11,015 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:08:17,662 - INFO  - Training [46][   20/  196]   Loss nan   Top1 10.976562   Top5 50.449219   BatchTime 0.332221   LR 0.000814   
2022-11-26 05:08:22,849 - INFO  - Training [46][   40/  196]   Loss nan   Top1 10.605469   Top5 50.205078   BatchTime 0.295799   LR 0.000809   
2022-11-26 05:08:27,836 - INFO  - Training [46][   60/  196]   Loss nan   Top1 10.377604   Top5 50.110677   BatchTime 0.280318   LR 0.000804   
2022-11-26 05:08:32,824 - INFO  - Training [46][   80/  196]   Loss nan   Top1 10.371094   Top5 49.760742   BatchTime 0.272580   LR 0.000799   
2022-11-26 05:08:37,829 - INFO  - Training [46][  100/  196]   Loss nan   Top1 10.312500   Top5 49.652344   BatchTime 0.268120   LR 0.000794   
2022-11-26 05:08:42,839 - INFO  - Training [46][  120/  196]   Loss nan   Top1 10.260417   Top5 49.674479   BatchTime 0.265179   LR 0.000789   
2022-11-26 05:08:47,853 - INFO  - Training [46][  140/  196]   Loss nan   Top1 10.089286   Top5 49.542411   BatchTime 0.263110   LR 0.000785   
2022-11-26 05:08:52,801 - INFO  - Training [46][  160/  196]   Loss nan   Top1 10.017090   Top5 49.611816   BatchTime 0.261147   LR 0.000780   
2022-11-26 05:08:57,718 - INFO  - Training [46][  180/  196]   Loss nan   Top1 10.060764   Top5 49.782986   BatchTime 0.259445   LR 0.000775   
2022-11-26 05:09:01,854 - INFO  - ==> Top1: 10.044    Top5: 49.754    Loss: nan

2022-11-26 05:09:02,136 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:09:03,622 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:09:05,918 - INFO  - Validation [46][   20/   40]   Loss 8.825549   Top1 10.078125   Top5 50.058594   BatchTime 0.114682   
2022-11-26 05:09:06,977 - INFO  - Validation [46][   40/   40]   Loss 8.844259   Top1 10.000000   Top5 50.000000   BatchTime 0.083842   
2022-11-26 05:09:07,188 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 8.844

2022-11-26 05:09:07,188 - INFO  - ==> Sparsity : 0.496

2022-11-26 05:09:07,188 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:09:07,188 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:09:07,188 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 10.000   Top5: 50.000]
2022-11-26 05:09:07,299 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:09:07,301 - INFO  - >>>>>> Epoch  47
2022-11-26 05:09:07,303 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:09:13,600 - INFO  - Training [47][   20/  196]   Loss nan   Top1 9.980469   Top5 49.980469   BatchTime 0.314744   LR 0.000766   
2022-11-26 05:09:18,491 - INFO  - Training [47][   40/  196]   Loss nan   Top1 10.048828   Top5 49.863281   BatchTime 0.279666   LR 0.000761   
2022-11-26 05:09:23,585 - INFO  - Training [47][   60/  196]   Loss nan   Top1 9.869792   Top5 49.687500   BatchTime 0.271337   LR 0.000756   
2022-11-26 05:09:28,628 - INFO  - Training [47][   80/  196]   Loss nan   Top1 9.785156   Top5 49.638672   BatchTime 0.266544   LR 0.000752   
2022-11-26 05:09:33,474 - INFO  - Training [47][  100/  196]   Loss nan   Top1 9.789062   Top5 49.820312   BatchTime 0.261688   LR 0.000747   
2022-11-26 05:09:38,500 - INFO  - Training [47][  120/  196]   Loss nan   Top1 9.746094   Top5 49.684245   BatchTime 0.259959   LR 0.000742   
2022-11-26 05:09:43,488 - INFO  - Training [47][  140/  196]   Loss nan   Top1 9.732143   Top5 49.732143   BatchTime 0.258452   LR 0.000737   
2022-11-26 05:09:48,586 - INFO  - Training [47][  160/  196]   Loss nan   Top1 9.870605   Top5 49.758301   BatchTime 0.258003   LR 0.000732   
2022-11-26 05:09:53,471 - INFO  - Training [47][  180/  196]   Loss nan   Top1 9.832899   Top5 49.722222   BatchTime 0.256477   LR 0.000727   
2022-11-26 05:09:57,532 - INFO  - ==> Top1: 9.868    Top5: 49.788    Loss: nan

2022-11-26 05:09:57,727 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:09:58,835 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:10:01,160 - INFO  - Validation [47][   20/   40]   Loss 8.354766   Top1 10.078125   Top5 50.058594   BatchTime 0.116185   
2022-11-26 05:10:02,254 - INFO  - Validation [47][   40/   40]   Loss 8.371239   Top1 10.000000   Top5 50.000000   BatchTime 0.085436   
2022-11-26 05:10:02,437 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 8.371

2022-11-26 05:10:02,437 - INFO  - ==> Sparsity : 0.497

2022-11-26 05:10:02,437 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:10:02,437 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:10:02,438 - INFO  - Scoreboard best 3 ==> Epoch [47][Top1: 10.000   Top5: 50.000]
2022-11-26 05:10:02,578 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:10:02,580 - INFO  - >>>>>> Epoch  48
2022-11-26 05:10:02,582 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:10:08,875 - INFO  - Training [48][   20/  196]   Loss nan   Top1 9.667969   Top5 49.824219   BatchTime 0.314545   LR 0.000718   
2022-11-26 05:10:13,679 - INFO  - Training [48][   40/  196]   Loss nan   Top1 9.511719   Top5 48.955078   BatchTime 0.277364   LR 0.000713   
2022-11-26 05:10:18,664 - INFO  - Training [48][   60/  196]   Loss nan   Top1 9.778646   Top5 49.270833   BatchTime 0.267994   LR 0.000708   
2022-11-26 05:10:23,683 - INFO  - Training [48][   80/  196]   Loss nan   Top1 9.873047   Top5 49.604492   BatchTime 0.263731   LR 0.000703   
2022-11-26 05:10:28,661 - INFO  - Training [48][  100/  196]   Loss nan   Top1 9.839844   Top5 49.585938   BatchTime 0.260763   LR 0.000698   
2022-11-26 05:10:33,660 - INFO  - Training [48][  120/  196]   Loss nan   Top1 9.820964   Top5 49.625651   BatchTime 0.258961   LR 0.000693   
2022-11-26 05:10:38,642 - INFO  - Training [48][  140/  196]   Loss nan   Top1 9.866071   Top5 49.662388   BatchTime 0.257548   LR 0.000688   
2022-11-26 05:10:43,718 - INFO  - Training [48][  160/  196]   Loss nan   Top1 9.843750   Top5 49.763184   BatchTime 0.257084   LR 0.000683   
2022-11-26 05:10:48,696 - INFO  - Training [48][  180/  196]   Loss nan   Top1 9.884983   Top5 49.802517   BatchTime 0.256174   LR 0.000678   
2022-11-26 05:10:52,682 - INFO  - ==> Top1: 9.796    Top5: 49.734    Loss: nan

2022-11-26 05:10:52,873 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:10:54,066 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:10:56,297 - INFO  - Validation [48][   20/   40]   Loss 8.328492   Top1 10.078125   Top5 50.058594   BatchTime 0.111496   
2022-11-26 05:10:57,421 - INFO  - Validation [48][   40/   40]   Loss 8.345505   Top1 10.000000   Top5 50.000000   BatchTime 0.083838   
2022-11-26 05:10:57,587 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 8.346

2022-11-26 05:10:57,587 - INFO  - ==> Sparsity : 0.498

2022-11-26 05:10:57,587 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:10:57,588 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:10:57,588 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 10.000   Top5: 50.000]
2022-11-26 05:10:57,722 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:10:57,724 - INFO  - >>>>>> Epoch  49
2022-11-26 05:10:57,725 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:11:04,105 - INFO  - Training [49][   20/  196]   Loss nan   Top1 9.902344   Top5 50.195312   BatchTime 0.318856   LR 0.000669   
2022-11-26 05:11:09,212 - INFO  - Training [49][   40/  196]   Loss nan   Top1 10.009766   Top5 50.253906   BatchTime 0.287109   LR 0.000664   
2022-11-26 05:11:14,246 - INFO  - Training [49][   60/  196]   Loss nan   Top1 10.006510   Top5 50.312500   BatchTime 0.275311   LR 0.000659   
2022-11-26 05:11:19,285 - INFO  - Training [49][   80/  196]   Loss nan   Top1 9.799805   Top5 50.356445   BatchTime 0.269465   LR 0.000654   
2022-11-26 05:11:24,339 - INFO  - Training [49][  100/  196]   Loss nan   Top1 9.968750   Top5 50.386719   BatchTime 0.266109   LR 0.000649   
2022-11-26 05:11:29,275 - INFO  - Training [49][  120/  196]   Loss nan   Top1 10.110677   Top5 50.305990   BatchTime 0.262890   LR 0.000644   
2022-11-26 05:11:34,178 - INFO  - Training [49][  140/  196]   Loss nan   Top1 9.938616   Top5 50.100446   BatchTime 0.260359   LR 0.000639   
2022-11-26 05:11:39,176 - INFO  - Training [49][  160/  196]   Loss nan   Top1 9.890137   Top5 49.995117   BatchTime 0.259047   LR 0.000634   
2022-11-26 05:11:44,120 - INFO  - Training [49][  180/  196]   Loss nan   Top1 9.884983   Top5 49.928385   BatchTime 0.257732   LR 0.000629   
2022-11-26 05:11:47,879 - INFO  - ==> Top1: 9.894    Top5: 49.928    Loss: nan

2022-11-26 05:11:48,071 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:11:49,168 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:11:51,429 - INFO  - Validation [49][   20/   40]   Loss 6.815486   Top1 10.078125   Top5 50.058594   BatchTime 0.113012   
2022-11-26 05:11:52,556 - INFO  - Validation [49][   40/   40]   Loss 6.829690   Top1 10.000000   Top5 50.000000   BatchTime 0.084666   
2022-11-26 05:11:52,779 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 6.830

2022-11-26 05:11:52,779 - INFO  - ==> Sparsity : 0.499

2022-11-26 05:11:52,779 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:11:52,779 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:11:52,780 - INFO  - Scoreboard best 3 ==> Epoch [49][Top1: 10.000   Top5: 50.000]
2022-11-26 05:11:52,911 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:11:52,913 - INFO  - >>>>>> Epoch  50
2022-11-26 05:11:52,915 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:11:59,152 - INFO  - Training [50][   20/  196]   Loss nan   Top1 10.039062   Top5 50.605469   BatchTime 0.311748   LR 0.000620   
2022-11-26 05:12:04,265 - INFO  - Training [50][   40/  196]   Loss nan   Top1 9.912109   Top5 49.843750   BatchTime 0.283703   LR 0.000615   
2022-11-26 05:12:09,345 - INFO  - Training [50][   60/  196]   Loss nan   Top1 9.804688   Top5 49.576823   BatchTime 0.273791   LR 0.000610   
2022-11-26 05:12:14,264 - INFO  - Training [50][   80/  196]   Loss nan   Top1 9.741211   Top5 49.575195   BatchTime 0.266829   LR 0.000605   
2022-11-26 05:12:19,328 - INFO  - Training [50][  100/  196]   Loss nan   Top1 9.828125   Top5 49.589844   BatchTime 0.264104   LR 0.000600   
2022-11-26 05:12:24,517 - INFO  - Training [50][  120/  196]   Loss nan   Top1 9.882812   Top5 49.651693   BatchTime 0.263328   LR 0.000595   
2022-11-26 05:12:29,485 - INFO  - Training [50][  140/  196]   Loss nan   Top1 9.804688   Top5 49.746094   BatchTime 0.261192   LR 0.000590   
2022-11-26 05:12:34,495 - INFO  - Training [50][  160/  196]   Loss nan   Top1 9.814453   Top5 49.687500   BatchTime 0.259859   LR 0.000585   
2022-11-26 05:12:39,487 - INFO  - Training [50][  180/  196]   Loss nan   Top1 9.835069   Top5 49.759115   BatchTime 0.258715   LR 0.000580   
2022-11-26 05:12:43,607 - INFO  - ==> Top1: 9.840    Top5: 49.772    Loss: nan

2022-11-26 05:12:43,771 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:12:44,800 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:12:47,101 - INFO  - Validation [50][   20/   40]   Loss 6.356808   Top1 10.078125   Top5 50.058594   BatchTime 0.114949   
2022-11-26 05:12:48,301 - INFO  - Validation [50][   40/   40]   Loss 6.369970   Top1 10.000000   Top5 50.000000   BatchTime 0.087478   
2022-11-26 05:12:48,525 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 6.370

2022-11-26 05:12:48,525 - INFO  - ==> Sparsity : 0.500

2022-11-26 05:12:48,526 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:12:48,526 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:12:48,526 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 10.000   Top5: 50.000]
2022-11-26 05:12:48,656 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:12:48,658 - INFO  - >>>>>> Epoch  51
2022-11-26 05:12:48,660 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:12:54,772 - INFO  - Training [51][   20/  196]   Loss nan   Top1 10.234375   Top5 50.097656   BatchTime 0.305464   LR 0.000571   
2022-11-26 05:12:59,575 - INFO  - Training [51][   40/  196]   Loss nan   Top1 10.302734   Top5 49.794922   BatchTime 0.272813   LR 0.000566   
2022-11-26 05:13:04,573 - INFO  - Training [51][   60/  196]   Loss nan   Top1 10.260417   Top5 49.563802   BatchTime 0.265168   LR 0.000561   
2022-11-26 05:13:09,507 - INFO  - Training [51][   80/  196]   Loss nan   Top1 10.112305   Top5 49.624023   BatchTime 0.260561   LR 0.000556   
2022-11-26 05:13:14,495 - INFO  - Training [51][  100/  196]   Loss nan   Top1 10.035156   Top5 49.816406   BatchTime 0.258322   LR 0.000551   
2022-11-26 05:13:19,584 - INFO  - Training [51][  120/  196]   Loss nan   Top1 9.983724   Top5 49.622396   BatchTime 0.257674   LR 0.000546   
2022-11-26 05:13:24,594 - INFO  - Training [51][  140/  196]   Loss nan   Top1 9.949777   Top5 49.729353   BatchTime 0.256648   LR 0.000541   
2022-11-26 05:13:29,596 - INFO  - Training [51][  160/  196]   Loss nan   Top1 9.895020   Top5 49.731445   BatchTime 0.255834   LR 0.000536   
2022-11-26 05:13:34,692 - INFO  - Training [51][  180/  196]   Loss nan   Top1 9.841580   Top5 49.776476   BatchTime 0.255717   LR 0.000531   
2022-11-26 05:13:38,880 - INFO  - ==> Top1: 9.870    Top5: 49.708    Loss: nan

2022-11-26 05:13:39,185 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:13:40,625 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:13:42,912 - INFO  - Validation [51][   20/   40]   Loss 6.856363   Top1 10.078125   Top5 50.058594   BatchTime 0.114254   
2022-11-26 05:13:43,968 - INFO  - Validation [51][   40/   40]   Loss 6.870533   Top1 10.000000   Top5 50.000000   BatchTime 0.083548   
2022-11-26 05:13:44,149 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 6.871

2022-11-26 05:13:44,149 - INFO  - ==> Sparsity : 0.501

2022-11-26 05:13:44,150 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:13:44,150 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:13:44,150 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 10.000   Top5: 50.000]
2022-11-26 05:13:44,262 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:13:44,263 - INFO  - >>>>>> Epoch  52
2022-11-26 05:13:44,265 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:13:50,484 - INFO  - Training [52][   20/  196]   Loss nan   Top1 10.429688   Top5 51.406250   BatchTime 0.310810   LR 0.000523   
2022-11-26 05:13:55,512 - INFO  - Training [52][   40/  196]   Loss nan   Top1 10.117188   Top5 50.908203   BatchTime 0.281126   LR 0.000518   
2022-11-26 05:14:00,871 - INFO  - Training [52][   60/  196]   Loss nan   Top1 10.032552   Top5 50.579427   BatchTime 0.276732   LR 0.000513   
2022-11-26 05:14:05,749 - INFO  - Training [52][   80/  196]   Loss nan   Top1 10.122070   Top5 50.332031   BatchTime 0.268515   LR 0.000508   
2022-11-26 05:14:10,798 - INFO  - Training [52][  100/  196]   Loss nan   Top1 10.070312   Top5 50.484375   BatchTime 0.265308   LR 0.000503   
2022-11-26 05:14:15,744 - INFO  - Training [52][  120/  196]   Loss nan   Top1 10.039062   Top5 50.283203   BatchTime 0.262303   LR 0.000498   
2022-11-26 05:14:20,876 - INFO  - Training [52][  140/  196]   Loss nan   Top1 10.114397   Top5 50.362723   BatchTime 0.261488   LR 0.000493   
2022-11-26 05:14:25,826 - INFO  - Training [52][  160/  196]   Loss nan   Top1 10.026855   Top5 50.292969   BatchTime 0.259739   LR 0.000488   
2022-11-26 05:14:30,696 - INFO  - Training [52][  180/  196]   Loss nan   Top1 9.952257   Top5 50.032552   BatchTime 0.257934   LR 0.000483   
2022-11-26 05:14:34,842 - INFO  - ==> Top1: 9.864    Top5: 49.974    Loss: nan

2022-11-26 05:14:35,075 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:14:36,446 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:14:38,670 - INFO  - Validation [52][   20/   40]   Loss 6.555215   Top1 10.078125   Top5 50.058594   BatchTime 0.111078   
2022-11-26 05:14:39,729 - INFO  - Validation [52][   40/   40]   Loss 6.569484   Top1 10.000000   Top5 50.000000   BatchTime 0.082028   
2022-11-26 05:14:39,895 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 6.569

2022-11-26 05:14:39,896 - INFO  - ==> Sparsity : 0.501

2022-11-26 05:14:39,896 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:14:39,896 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:14:39,896 - INFO  - Scoreboard best 3 ==> Epoch [52][Top1: 10.000   Top5: 50.000]
2022-11-26 05:14:40,012 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:14:40,013 - INFO  - >>>>>> Epoch  53
2022-11-26 05:14:40,015 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:14:46,401 - INFO  - Training [53][   20/  196]   Loss nan   Top1 10.078125   Top5 50.507812   BatchTime 0.319154   LR 0.000474   
2022-11-26 05:14:51,551 - INFO  - Training [53][   40/  196]   Loss nan   Top1 10.156250   Top5 50.458984   BatchTime 0.288328   LR 0.000470   
2022-11-26 05:14:56,604 - INFO  - Training [53][   60/  196]   Loss nan   Top1 10.039062   Top5 50.390625   BatchTime 0.276433   LR 0.000465   
2022-11-26 05:15:01,469 - INFO  - Training [53][   80/  196]   Loss nan   Top1 10.156250   Top5 50.043945   BatchTime 0.268137   LR 0.000460   
2022-11-26 05:15:06,469 - INFO  - Training [53][  100/  196]   Loss nan   Top1 10.078125   Top5 49.984375   BatchTime 0.264515   LR 0.000455   
2022-11-26 05:15:11,526 - INFO  - Training [53][  120/  196]   Loss nan   Top1 10.045573   Top5 50.045573   BatchTime 0.262566   LR 0.000450   
2022-11-26 05:15:16,648 - INFO  - Training [53][  140/  196]   Loss nan   Top1 10.030692   Top5 50.069754   BatchTime 0.261640   LR 0.000445   
2022-11-26 05:15:21,793 - INFO  - Training [53][  160/  196]   Loss nan   Top1 10.097656   Top5 50.021973   BatchTime 0.261091   LR 0.000441   
2022-11-26 05:15:26,771 - INFO  - Training [53][  180/  196]   Loss nan   Top1 10.056424   Top5 50.026042   BatchTime 0.259738   LR 0.000436   
2022-11-26 05:15:30,964 - INFO  - ==> Top1: 10.058    Top5: 50.122    Loss: nan

2022-11-26 05:15:31,343 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:15:32,720 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:15:34,995 - INFO  - Validation [53][   20/   40]   Loss 7.036533   Top1 10.078125   Top5 50.058594   BatchTime 0.113664   
2022-11-26 05:15:36,094 - INFO  - Validation [53][   40/   40]   Loss 7.051983   Top1 10.000000   Top5 50.000000   BatchTime 0.084292   
2022-11-26 05:15:36,312 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 7.052

2022-11-26 05:15:36,312 - INFO  - ==> Sparsity : 0.502

2022-11-26 05:15:36,312 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:15:36,313 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:15:36,313 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 10.000   Top5: 50.000]
2022-11-26 05:15:36,442 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:15:36,443 - INFO  - >>>>>> Epoch  54
2022-11-26 05:15:36,445 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:15:42,835 - INFO  - Training [54][   20/  196]   Loss nan   Top1 10.585938   Top5 50.214844   BatchTime 0.319360   LR 0.000427   
2022-11-26 05:15:47,877 - INFO  - Training [54][   40/  196]   Loss nan   Top1 10.224609   Top5 50.458984   BatchTime 0.285731   LR 0.000423   
2022-11-26 05:15:53,063 - INFO  - Training [54][   60/  196]   Loss nan   Top1 10.253906   Top5 50.123698   BatchTime 0.276917   LR 0.000418   
2022-11-26 05:15:57,972 - INFO  - Training [54][   80/  196]   Loss nan   Top1 10.097656   Top5 49.863281   BatchTime 0.269051   LR 0.000413   
2022-11-26 05:16:03,050 - INFO  - Training [54][  100/  196]   Loss nan   Top1 9.949219   Top5 49.773438   BatchTime 0.266022   LR 0.000408   
2022-11-26 05:16:08,025 - INFO  - Training [54][  120/  196]   Loss nan   Top1 9.938151   Top5 49.755859   BatchTime 0.263139   LR 0.000404   
2022-11-26 05:16:13,122 - INFO  - Training [54][  140/  196]   Loss nan   Top1 9.997210   Top5 49.857701   BatchTime 0.261953   LR 0.000399   
2022-11-26 05:16:18,254 - INFO  - Training [54][  160/  196]   Loss nan   Top1 10.036621   Top5 49.916992   BatchTime 0.261287   LR 0.000394   
2022-11-26 05:16:23,225 - INFO  - Training [54][  180/  196]   Loss nan   Top1 10.045573   Top5 50.006510   BatchTime 0.259872   LR 0.000390   
2022-11-26 05:16:27,366 - INFO  - ==> Top1: 10.102    Top5: 50.030    Loss: nan

2022-11-26 05:16:27,655 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:16:29,070 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:16:31,358 - INFO  - Validation [54][   20/   40]   Loss 7.378641   Top1 10.078125   Top5 50.058594   BatchTime 0.114333   
2022-11-26 05:16:32,499 - INFO  - Validation [54][   40/   40]   Loss 7.394665   Top1 10.000000   Top5 50.000000   BatchTime 0.085692   
2022-11-26 05:16:32,679 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 7.395

2022-11-26 05:16:32,679 - INFO  - ==> Sparsity : 0.503

2022-11-26 05:16:32,679 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:16:32,680 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:16:32,680 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 10.000   Top5: 50.000]
2022-11-26 05:16:32,794 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:16:32,796 - INFO  - >>>>>> Epoch  55
2022-11-26 05:16:32,798 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:16:38,963 - INFO  - Training [55][   20/  196]   Loss nan   Top1 10.527344   Top5 50.761719   BatchTime 0.308152   LR 0.000381   
2022-11-26 05:16:43,960 - INFO  - Training [55][   40/  196]   Loss nan   Top1 9.804688   Top5 50.390625   BatchTime 0.279006   LR 0.000377   
2022-11-26 05:16:49,029 - INFO  - Training [55][   60/  196]   Loss nan   Top1 10.000000   Top5 50.221354   BatchTime 0.270483   LR 0.000372   
2022-11-26 05:16:54,082 - INFO  - Training [55][   80/  196]   Loss nan   Top1 10.078125   Top5 50.039062   BatchTime 0.266025   LR 0.000368   
2022-11-26 05:16:59,021 - INFO  - Training [55][  100/  196]   Loss nan   Top1 9.976562   Top5 50.019531   BatchTime 0.262208   LR 0.000363   
2022-11-26 05:17:04,010 - INFO  - Training [55][  120/  196]   Loss nan   Top1 9.941406   Top5 49.915365   BatchTime 0.260083   LR 0.000358   
2022-11-26 05:17:09,006 - INFO  - Training [55][  140/  196]   Loss nan   Top1 9.843750   Top5 49.804688   BatchTime 0.258608   LR 0.000354   
2022-11-26 05:17:13,996 - INFO  - Training [55][  160/  196]   Loss nan   Top1 9.838867   Top5 49.838867   BatchTime 0.257469   LR 0.000349   
2022-11-26 05:17:18,961 - INFO  - Training [55][  180/  196]   Loss nan   Top1 9.865451   Top5 49.806858   BatchTime 0.256444   LR 0.000345   
2022-11-26 05:17:23,165 - INFO  - ==> Top1: 9.898    Top5: 49.834    Loss: nan

2022-11-26 05:17:23,365 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:17:24,571 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:17:26,899 - INFO  - Validation [55][   20/   40]   Loss 6.093926   Top1 10.078125   Top5 50.058594   BatchTime 0.116314   
2022-11-26 05:17:28,016 - INFO  - Validation [55][   40/   40]   Loss 6.107328   Top1 10.000000   Top5 50.000000   BatchTime 0.086077   
2022-11-26 05:17:28,222 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 6.107

2022-11-26 05:17:28,222 - INFO  - ==> Sparsity : 0.503

2022-11-26 05:17:28,223 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:17:28,223 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:17:28,223 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 10.000   Top5: 50.000]
2022-11-26 05:17:28,358 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:17:28,359 - INFO  - >>>>>> Epoch  56
2022-11-26 05:17:28,361 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:17:34,270 - INFO  - Training [56][   20/  196]   Loss nan   Top1 10.390625   Top5 51.738281   BatchTime 0.295334   LR 0.000337   
2022-11-26 05:17:39,225 - INFO  - Training [56][   40/  196]   Loss nan   Top1 10.078125   Top5 50.556641   BatchTime 0.271535   LR 0.000333   
2022-11-26 05:17:44,231 - INFO  - Training [56][   60/  196]   Loss nan   Top1 10.019531   Top5 50.670573   BatchTime 0.264458   LR 0.000328   
2022-11-26 05:17:49,349 - INFO  - Training [56][   80/  196]   Loss nan   Top1 10.117188   Top5 50.605469   BatchTime 0.262319   LR 0.000324   
2022-11-26 05:17:54,536 - INFO  - Training [56][  100/  196]   Loss nan   Top1 10.113281   Top5 50.421875   BatchTime 0.261720   LR 0.000319   
2022-11-26 05:17:59,594 - INFO  - Training [56][  120/  196]   Loss nan   Top1 10.205078   Top5 50.410156   BatchTime 0.260250   LR 0.000315   
2022-11-26 05:18:04,559 - INFO  - Training [56][  140/  196]   Loss nan   Top1 10.128348   Top5 50.373884   BatchTime 0.258533   LR 0.000311   
2022-11-26 05:18:09,480 - INFO  - Training [56][  160/  196]   Loss nan   Top1 10.205078   Top5 50.341797   BatchTime 0.256971   LR 0.000306   
2022-11-26 05:18:14,503 - INFO  - Training [56][  180/  196]   Loss nan   Top1 10.210503   Top5 50.184462   BatchTime 0.256326   LR 0.000302   
2022-11-26 05:18:18,428 - INFO  - ==> Top1: 10.134    Top5: 50.108    Loss: nan

2022-11-26 05:18:18,648 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:18:19,756 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:18:22,057 - INFO  - Validation [56][   20/   40]   Loss 6.445062   Top1 10.078125   Top5 50.214844   BatchTime 0.114968   
2022-11-26 05:18:23,189 - INFO  - Validation [56][   40/   40]   Loss 6.460538   Top1 10.000000   Top5 50.000000   BatchTime 0.085797   
2022-11-26 05:18:23,370 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 6.461

2022-11-26 05:18:23,371 - INFO  - ==> Sparsity : 0.503

2022-11-26 05:18:23,371 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:18:23,371 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:18:23,371 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 10.000   Top5: 50.000]
2022-11-26 05:18:23,491 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:18:23,493 - INFO  - >>>>>> Epoch  57
2022-11-26 05:18:23,495 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:18:30,024 - INFO  - Training [57][   20/  196]   Loss nan   Top1 10.097656   Top5 50.117188   BatchTime 0.326294   LR 0.000294   
2022-11-26 05:18:35,530 - INFO  - Training [57][   40/  196]   Loss nan   Top1 10.068359   Top5 49.677734   BatchTime 0.300806   LR 0.000290   
2022-11-26 05:18:40,482 - INFO  - Training [57][   60/  196]   Loss nan   Top1 9.811198   Top5 49.687500   BatchTime 0.283079   LR 0.000286   
2022-11-26 05:18:45,484 - INFO  - Training [57][   80/  196]   Loss nan   Top1 9.765625   Top5 49.692383   BatchTime 0.274826   LR 0.000282   
2022-11-26 05:18:50,592 - INFO  - Training [57][  100/  196]   Loss nan   Top1 9.875000   Top5 49.859375   BatchTime 0.270943   LR 0.000277   
2022-11-26 05:18:55,581 - INFO  - Training [57][  120/  196]   Loss nan   Top1 9.970703   Top5 49.951172   BatchTime 0.267357   LR 0.000273   
2022-11-26 05:19:00,595 - INFO  - Training [57][  140/  196]   Loss nan   Top1 9.980469   Top5 49.771205   BatchTime 0.264977   LR 0.000269   
2022-11-26 05:19:05,606 - INFO  - Training [57][  160/  196]   Loss nan   Top1 10.080566   Top5 49.787598   BatchTime 0.263176   LR 0.000265   
2022-11-26 05:19:10,298 - INFO  - Training [57][  180/  196]   Loss nan   Top1 10.082465   Top5 49.809028   BatchTime 0.259996   LR 0.000261   
2022-11-26 05:19:14,311 - INFO  - ==> Top1: 10.054    Top5: 49.708    Loss: nan

2022-11-26 05:19:14,549 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:19:15,964 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:19:18,220 - INFO  - Validation [57][   20/   40]   Loss 6.520866   Top1 10.078125   Top5 50.214844   BatchTime 0.112734   
2022-11-26 05:19:19,299 - INFO  - Validation [57][   40/   40]   Loss 6.535842   Top1 10.000000   Top5 50.000000   BatchTime 0.083328   
2022-11-26 05:19:19,516 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 6.536

2022-11-26 05:19:19,517 - INFO  - ==> Sparsity : 0.503

2022-11-26 05:19:19,517 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:19:19,517 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:19:19,517 - INFO  - Scoreboard best 3 ==> Epoch [57][Top1: 10.000   Top5: 50.000]
2022-11-26 05:19:19,652 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:19:19,655 - INFO  - >>>>>> Epoch  58
2022-11-26 05:19:19,657 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:19:26,022 - INFO  - Training [58][   20/  196]   Loss nan   Top1 10.136719   Top5 49.003906   BatchTime 0.318124   LR 0.000254   
2022-11-26 05:19:30,968 - INFO  - Training [58][   40/  196]   Loss nan   Top1 10.117188   Top5 49.394531   BatchTime 0.282710   LR 0.000250   
2022-11-26 05:19:35,693 - INFO  - Training [58][   60/  196]   Loss nan   Top1 9.947917   Top5 49.778646   BatchTime 0.267216   LR 0.000246   
2022-11-26 05:19:40,742 - INFO  - Training [58][   80/  196]   Loss nan   Top1 9.794922   Top5 49.848633   BatchTime 0.263526   LR 0.000242   
2022-11-26 05:19:45,755 - INFO  - Training [58][  100/  196]   Loss nan   Top1 9.847656   Top5 49.667969   BatchTime 0.260955   LR 0.000238   
2022-11-26 05:19:50,748 - INFO  - Training [58][  120/  196]   Loss nan   Top1 9.915365   Top5 49.886068   BatchTime 0.259063   LR 0.000234   
2022-11-26 05:19:55,695 - INFO  - Training [58][  140/  196]   Loss nan   Top1 10.019531   Top5 50.086496   BatchTime 0.257394   LR 0.000230   
2022-11-26 05:20:00,737 - INFO  - Training [58][  160/  196]   Loss nan   Top1 9.992676   Top5 50.073242   BatchTime 0.256733   LR 0.000226   
2022-11-26 05:20:05,726 - INFO  - Training [58][  180/  196]   Loss nan   Top1 9.956597   Top5 50.000000   BatchTime 0.255921   LR 0.000222   
2022-11-26 05:20:09,717 - INFO  - ==> Top1: 9.902    Top5: 49.922    Loss: nan

2022-11-26 05:20:09,888 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:20:11,092 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:20:13,452 - INFO  - Validation [58][   20/   40]   Loss 5.985838   Top1 10.078125   Top5 50.214844   BatchTime 0.117923   
2022-11-26 05:20:14,580 - INFO  - Validation [58][   40/   40]   Loss 5.999957   Top1 10.000000   Top5 50.000000   BatchTime 0.087184   
2022-11-26 05:20:14,761 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 6.000

2022-11-26 05:20:14,761 - INFO  - ==> Sparsity : 0.504

2022-11-26 05:20:14,762 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:20:14,762 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:20:14,762 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 10.000   Top5: 50.000]
2022-11-26 05:20:14,874 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:20:14,875 - INFO  - >>>>>> Epoch  59
2022-11-26 05:20:14,877 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:20:21,242 - INFO  - Training [59][   20/  196]   Loss nan   Top1 10.117188   Top5 50.761719   BatchTime 0.318153   LR 0.000215   
2022-11-26 05:20:26,246 - INFO  - Training [59][   40/  196]   Loss nan   Top1 9.902344   Top5 50.742188   BatchTime 0.284176   LR 0.000212   
2022-11-26 05:20:31,240 - INFO  - Training [59][   60/  196]   Loss nan   Top1 10.000000   Top5 50.742188   BatchTime 0.272684   LR 0.000208   
2022-11-26 05:20:36,255 - INFO  - Training [59][   80/  196]   Loss nan   Top1 9.863281   Top5 50.454102   BatchTime 0.267196   LR 0.000204   
2022-11-26 05:20:41,262 - INFO  - Training [59][  100/  196]   Loss nan   Top1 9.843750   Top5 50.347656   BatchTime 0.263820   LR 0.000201   
2022-11-26 05:20:46,290 - INFO  - Training [59][  120/  196]   Loss nan   Top1 9.951172   Top5 50.403646   BatchTime 0.261757   LR 0.000197   
2022-11-26 05:20:51,270 - INFO  - Training [59][  140/  196]   Loss nan   Top1 10.000000   Top5 50.329241   BatchTime 0.259931   LR 0.000193   
2022-11-26 05:20:56,262 - INFO  - Training [59][  160/  196]   Loss nan   Top1 9.948730   Top5 50.212402   BatchTime 0.258636   LR 0.000190   
2022-11-26 05:21:01,260 - INFO  - Training [59][  180/  196]   Loss nan   Top1 9.978299   Top5 50.271267   BatchTime 0.257668   LR 0.000186   
2022-11-26 05:21:05,372 - INFO  - ==> Top1: 9.986    Top5: 50.288    Loss: nan

2022-11-26 05:21:05,652 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:21:07,114 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:21:09,343 - INFO  - Validation [59][   20/   40]   Loss 5.790123   Top1 10.078125   Top5 50.214844   BatchTime 0.111352   
2022-11-26 05:21:10,441 - INFO  - Validation [59][   40/   40]   Loss 5.803408   Top1 10.000000   Top5 50.000000   BatchTime 0.083134   
2022-11-26 05:21:10,659 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 5.803

2022-11-26 05:21:10,659 - INFO  - ==> Sparsity : 0.504

2022-11-26 05:21:10,659 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:21:10,660 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:21:10,660 - INFO  - Scoreboard best 3 ==> Epoch [59][Top1: 10.000   Top5: 50.000]
2022-11-26 05:21:10,918 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:21:10,920 - INFO  - >>>>>> Epoch  60
2022-11-26 05:21:10,921 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:21:17,340 - INFO  - Training [60][   20/  196]   Loss nan   Top1 10.214844   Top5 51.054688   BatchTime 0.320819   LR 0.000180   
2022-11-26 05:21:22,268 - INFO  - Training [60][   40/  196]   Loss nan   Top1 9.804688   Top5 49.804688   BatchTime 0.283600   LR 0.000176   
2022-11-26 05:21:27,252 - INFO  - Training [60][   60/  196]   Loss nan   Top1 9.628906   Top5 49.830729   BatchTime 0.272140   LR 0.000173   
2022-11-26 05:21:32,249 - INFO  - Training [60][   80/  196]   Loss nan   Top1 9.589844   Top5 49.643555   BatchTime 0.266570   LR 0.000169   
2022-11-26 05:21:37,240 - INFO  - Training [60][  100/  196]   Loss nan   Top1 9.742188   Top5 49.746094   BatchTime 0.263165   LR 0.000166   
2022-11-26 05:21:43,086 - INFO  - Training [60][  120/  196]   Loss nan   Top1 9.938151   Top5 49.980469   BatchTime 0.268013   LR 0.000162   
2022-11-26 05:21:48,669 - INFO  - Training [60][  140/  196]   Loss nan   Top1 9.986049   Top5 50.061384   BatchTime 0.269607   LR 0.000159   
2022-11-26 05:21:54,240 - INFO  - Training [60][  160/  196]   Loss nan   Top1 10.068359   Top5 49.895020   BatchTime 0.270726   LR 0.000156   
2022-11-26 05:21:59,587 - INFO  - Training [60][  180/  196]   Loss nan   Top1 10.082465   Top5 49.941406   BatchTime 0.270352   LR 0.000152   
2022-11-26 05:22:03,702 - INFO  - ==> Top1: 10.046    Top5: 49.874    Loss: nan

2022-11-26 05:22:03,902 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:22:05,044 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:22:07,362 - INFO  - Validation [60][   20/   40]   Loss 5.936855   Top1 10.078125   Top5 50.214844   BatchTime 0.115822   
2022-11-26 05:22:08,515 - INFO  - Validation [60][   40/   40]   Loss 5.950592   Top1 10.000000   Top5 50.000000   BatchTime 0.086734   
2022-11-26 05:22:08,716 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 5.951

2022-11-26 05:22:08,717 - INFO  - ==> Sparsity : 0.505

2022-11-26 05:22:08,717 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:22:08,717 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:22:08,717 - INFO  - Scoreboard best 3 ==> Epoch [60][Top1: 10.000   Top5: 50.000]
2022-11-26 05:22:08,847 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:22:08,848 - INFO  - >>>>>> Epoch  61
2022-11-26 05:22:08,850 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:22:15,166 - INFO  - Training [61][   20/  196]   Loss nan   Top1 9.726562   Top5 49.296875   BatchTime 0.315691   LR 0.000147   
2022-11-26 05:22:20,606 - INFO  - Training [61][   40/  196]   Loss nan   Top1 9.892578   Top5 49.931641   BatchTime 0.293835   LR 0.000143   
2022-11-26 05:22:26,133 - INFO  - Training [61][   60/  196]   Loss nan   Top1 10.045573   Top5 50.390625   BatchTime 0.288009   LR 0.000140   
2022-11-26 05:22:31,668 - INFO  - Training [61][   80/  196]   Loss nan   Top1 10.141602   Top5 50.170898   BatchTime 0.285187   LR 0.000137   
2022-11-26 05:22:37,301 - INFO  - Training [61][  100/  196]   Loss nan   Top1 10.269531   Top5 50.019531   BatchTime 0.284479   LR 0.000134   
2022-11-26 05:22:43,184 - INFO  - Training [61][  120/  196]   Loss nan   Top1 10.175781   Top5 49.850260   BatchTime 0.286095   LR 0.000131   
2022-11-26 05:22:49,111 - INFO  - Training [61][  140/  196]   Loss nan   Top1 10.159040   Top5 50.078125   BatchTime 0.287554   LR 0.000128   
2022-11-26 05:22:54,332 - INFO  - Training [61][  160/  196]   Loss nan   Top1 10.056152   Top5 49.987793   BatchTime 0.284241   LR 0.000125   
2022-11-26 05:22:59,837 - INFO  - Training [61][  180/  196]   Loss nan   Top1 9.973958   Top5 49.869792   BatchTime 0.283242   LR 0.000122   
2022-11-26 05:23:04,219 - INFO  - ==> Top1: 9.988    Top5: 49.920    Loss: nan

2022-11-26 05:23:04,419 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:23:05,728 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:23:08,045 - INFO  - Validation [61][   20/   40]   Loss 5.816324   Top1 10.078125   Top5 50.214844   BatchTime 0.115766   
2022-11-26 05:23:09,122 - INFO  - Validation [61][   40/   40]   Loss 5.829630   Top1 10.000000   Top5 50.000000   BatchTime 0.084828   
2022-11-26 05:23:09,307 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 5.830

2022-11-26 05:23:09,307 - INFO  - ==> Sparsity : 0.505

2022-11-26 05:23:09,307 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:23:09,308 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:23:09,308 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 10.000   Top5: 50.000]
2022-11-26 05:23:09,424 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:23:09,425 - INFO  - >>>>>> Epoch  62
2022-11-26 05:23:09,427 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:23:16,534 - INFO  - Training [62][   20/  196]   Loss nan   Top1 9.101562   Top5 49.589844   BatchTime 0.355218   LR 0.000117   
2022-11-26 05:23:22,123 - INFO  - Training [62][   40/  196]   Loss nan   Top1 9.707031   Top5 49.755859   BatchTime 0.317314   LR 0.000114   
2022-11-26 05:23:27,639 - INFO  - Training [62][   60/  196]   Loss nan   Top1 9.986979   Top5 50.182292   BatchTime 0.303477   LR 0.000111   
2022-11-26 05:23:33,381 - INFO  - Training [62][   80/  196]   Loss nan   Top1 9.892578   Top5 50.395508   BatchTime 0.299379   LR 0.000108   
2022-11-26 05:23:39,023 - INFO  - Training [62][  100/  196]   Loss nan   Top1 9.988281   Top5 50.367188   BatchTime 0.295930   LR 0.000105   
2022-11-26 05:23:44,354 - INFO  - Training [62][  120/  196]   Loss nan   Top1 9.882812   Top5 50.260417   BatchTime 0.291031   LR 0.000102   
2022-11-26 05:23:49,689 - INFO  - Training [62][  140/  196]   Loss nan   Top1 9.888393   Top5 50.209263   BatchTime 0.287563   LR 0.000100   
2022-11-26 05:23:55,446 - INFO  - Training [62][  160/  196]   Loss nan   Top1 9.924316   Top5 50.246582   BatchTime 0.287594   LR 0.000097   
2022-11-26 05:24:00,974 - INFO  - Training [62][  180/  196]   Loss nan   Top1 9.852431   Top5 50.232205   BatchTime 0.286353   LR 0.000094   
2022-11-26 05:24:05,428 - INFO  - ==> Top1: 9.846    Top5: 50.192    Loss: nan

2022-11-26 05:24:05,786 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:24:07,262 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:24:09,496 - INFO  - Validation [62][   20/   40]   Loss 5.854396   Top1 10.078125   Top5 50.214844   BatchTime 0.111614   
2022-11-26 05:24:10,439 - INFO  - Validation [62][   40/   40]   Loss 5.867798   Top1 10.000000   Top5 50.000000   BatchTime 0.079396   
2022-11-26 05:24:10,634 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 5.868

2022-11-26 05:24:10,634 - INFO  - ==> Sparsity : 0.505

2022-11-26 05:24:10,635 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:24:10,635 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:24:10,635 - INFO  - Scoreboard best 3 ==> Epoch [62][Top1: 10.000   Top5: 50.000]
2022-11-26 05:24:10,933 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:24:10,935 - INFO  - >>>>>> Epoch  63
2022-11-26 05:24:10,937 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:24:18,291 - INFO  - Training [63][   20/  196]   Loss nan   Top1 9.824219   Top5 49.863281   BatchTime 0.367574   LR 0.000090   
2022-11-26 05:24:23,879 - INFO  - Training [63][   40/  196]   Loss nan   Top1 9.882812   Top5 50.253906   BatchTime 0.323503   LR 0.000087   
2022-11-26 05:24:29,462 - INFO  - Training [63][   60/  196]   Loss nan   Top1 9.856771   Top5 50.332031   BatchTime 0.308712   LR 0.000085   
2022-11-26 05:24:34,560 - INFO  - Training [63][   80/  196]   Loss nan   Top1 9.829102   Top5 50.244141   BatchTime 0.295260   LR 0.000082   
2022-11-26 05:24:39,794 - INFO  - Training [63][  100/  196]   Loss nan   Top1 9.847656   Top5 50.156250   BatchTime 0.288540   LR 0.000080   
2022-11-26 05:24:45,764 - INFO  - Training [63][  120/  196]   Loss nan   Top1 9.765625   Top5 50.195312   BatchTime 0.290199   LR 0.000077   
2022-11-26 05:24:51,357 - INFO  - Training [63][  140/  196]   Loss nan   Top1 9.818638   Top5 50.212054   BatchTime 0.288695   LR 0.000075   
2022-11-26 05:24:57,669 - INFO  - Training [63][  160/  196]   Loss nan   Top1 9.782715   Top5 50.048828   BatchTime 0.292056   LR 0.000072   
2022-11-26 05:25:03,613 - INFO  - Training [63][  180/  196]   Loss nan   Top1 9.741753   Top5 50.060764   BatchTime 0.292627   LR 0.000070   
2022-11-26 05:25:08,878 - INFO  - ==> Top1: 9.784    Top5: 50.094    Loss: nan

2022-11-26 05:25:09,196 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:25:10,690 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:25:12,870 - INFO  - Validation [63][   20/   40]   Loss 5.462350   Top1 10.078125   Top5 50.214844   BatchTime 0.108912   
2022-11-26 05:25:13,974 - INFO  - Validation [63][   40/   40]   Loss 5.474957   Top1 10.000000   Top5 50.000000   BatchTime 0.082074   
2022-11-26 05:25:14,156 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 5.475

2022-11-26 05:25:14,156 - INFO  - ==> Sparsity : 0.505

2022-11-26 05:25:14,157 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:25:14,157 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:25:14,157 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 10.000   Top5: 50.000]
2022-11-26 05:25:14,268 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:25:14,270 - INFO  - >>>>>> Epoch  64
2022-11-26 05:25:14,271 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:25:21,130 - INFO  - Training [64][   20/  196]   Loss nan   Top1 9.531250   Top5 50.058594   BatchTime 0.342821   LR 0.000066   
2022-11-26 05:25:26,568 - INFO  - Training [64][   40/  196]   Loss nan   Top1 9.873047   Top5 49.785156   BatchTime 0.307365   LR 0.000064   
2022-11-26 05:25:31,594 - INFO  - Training [64][   60/  196]   Loss nan   Top1 10.032552   Top5 50.006510   BatchTime 0.288674   LR 0.000062   
2022-11-26 05:25:37,152 - INFO  - Training [64][   80/  196]   Loss nan   Top1 9.858398   Top5 49.897461   BatchTime 0.285976   LR 0.000059   
2022-11-26 05:25:42,367 - INFO  - Training [64][  100/  196]   Loss nan   Top1 9.722656   Top5 50.078125   BatchTime 0.280926   LR 0.000057   
2022-11-26 05:25:47,783 - INFO  - Training [64][  120/  196]   Loss nan   Top1 9.677734   Top5 49.941406   BatchTime 0.279236   LR 0.000055   
2022-11-26 05:25:53,110 - INFO  - Training [64][  140/  196]   Loss nan   Top1 9.726562   Top5 50.016741   BatchTime 0.277396   LR 0.000053   
2022-11-26 05:25:58,346 - INFO  - Training [64][  160/  196]   Loss nan   Top1 9.736328   Top5 50.019531   BatchTime 0.275451   LR 0.000051   
2022-11-26 05:26:03,997 - INFO  - Training [64][  180/  196]   Loss nan   Top1 9.676649   Top5 49.976128   BatchTime 0.276235   LR 0.000049   
2022-11-26 05:26:08,197 - INFO  - ==> Top1: 9.758    Top5: 50.158    Loss: nan

2022-11-26 05:26:08,378 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:26:09,297 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:26:11,441 - INFO  - Validation [64][   20/   40]   Loss 5.291993   Top1 10.078125   Top5 50.058594   BatchTime 0.107140   
2022-11-26 05:26:12,441 - INFO  - Validation [64][   40/   40]   Loss 5.304166   Top1 10.000000   Top5 50.000000   BatchTime 0.078571   
2022-11-26 05:26:12,608 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 5.304

2022-11-26 05:26:12,609 - INFO  - ==> Sparsity : 0.505

2022-11-26 05:26:12,609 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:26:12,609 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:26:12,610 - INFO  - Scoreboard best 3 ==> Epoch [64][Top1: 10.000   Top5: 50.000]
2022-11-26 05:26:12,719 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:26:12,721 - INFO  - >>>>>> Epoch  65
2022-11-26 05:26:12,722 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:26:19,109 - INFO  - Training [65][   20/  196]   Loss nan   Top1 10.175781   Top5 50.312500   BatchTime 0.319195   LR 0.000046   
2022-11-26 05:26:24,351 - INFO  - Training [65][   40/  196]   Loss nan   Top1 9.912109   Top5 50.078125   BatchTime 0.290660   LR 0.000044   
2022-11-26 05:26:30,053 - INFO  - Training [65][   60/  196]   Loss nan   Top1 9.967448   Top5 50.611979   BatchTime 0.288798   LR 0.000042   
2022-11-26 05:26:35,324 - INFO  - Training [65][   80/  196]   Loss nan   Top1 9.941406   Top5 50.571289   BatchTime 0.282487   LR 0.000040   
2022-11-26 05:26:40,322 - INFO  - Training [65][  100/  196]   Loss nan   Top1 9.902344   Top5 50.292969   BatchTime 0.275971   LR 0.000039   
2022-11-26 05:26:45,567 - INFO  - Training [65][  120/  196]   Loss nan   Top1 9.928385   Top5 50.351562   BatchTime 0.273679   LR 0.000037   
2022-11-26 05:26:50,835 - INFO  - Training [65][  140/  196]   Loss nan   Top1 9.896763   Top5 50.368304   BatchTime 0.272212   LR 0.000035   
2022-11-26 05:26:56,235 - INFO  - Training [65][  160/  196]   Loss nan   Top1 9.782715   Top5 50.246582   BatchTime 0.271935   LR 0.000033   
2022-11-26 05:27:01,632 - INFO  - Training [65][  180/  196]   Loss nan   Top1 9.863281   Top5 50.186632   BatchTime 0.271703   LR 0.000032   
2022-11-26 05:27:05,761 - INFO  - ==> Top1: 9.830    Top5: 50.048    Loss: nan

2022-11-26 05:27:05,935 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:27:07,185 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:27:09,377 - INFO  - Validation [65][   20/   40]   Loss 5.257781   Top1 10.078125   Top5 50.214844   BatchTime 0.109497   
2022-11-26 05:27:10,397 - INFO  - Validation [65][   40/   40]   Loss 5.270060   Top1 10.000000   Top5 50.000000   BatchTime 0.080255   
2022-11-26 05:27:10,573 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 5.270

2022-11-26 05:27:10,573 - INFO  - ==> Sparsity : 0.506

2022-11-26 05:27:10,573 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:27:10,573 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:27:10,574 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 10.000   Top5: 50.000]
2022-11-26 05:27:10,685 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:27:10,687 - INFO  - >>>>>> Epoch  66
2022-11-26 05:27:10,688 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:27:17,150 - INFO  - Training [66][   20/  196]   Loss nan   Top1 9.863281   Top5 49.707031   BatchTime 0.322939   LR 0.000029   
2022-11-26 05:27:23,209 - INFO  - Training [66][   40/  196]   Loss nan   Top1 9.746094   Top5 49.345703   BatchTime 0.312963   LR 0.000028   
2022-11-26 05:27:29,073 - INFO  - Training [66][   60/  196]   Loss nan   Top1 9.954427   Top5 49.290365   BatchTime 0.306370   LR 0.000026   
2022-11-26 05:27:34,745 - INFO  - Training [66][   80/  196]   Loss nan   Top1 9.775391   Top5 49.174805   BatchTime 0.300672   LR 0.000025   
2022-11-26 05:27:40,659 - INFO  - Training [66][  100/  196]   Loss nan   Top1 9.984375   Top5 49.402344   BatchTime 0.299677   LR 0.000023   
2022-11-26 05:27:46,257 - INFO  - Training [66][  120/  196]   Loss nan   Top1 9.928385   Top5 49.274089   BatchTime 0.296384   LR 0.000022   
2022-11-26 05:27:51,660 - INFO  - Training [66][  140/  196]   Loss nan   Top1 9.941406   Top5 49.377790   BatchTime 0.292635   LR 0.000021   
2022-11-26 05:27:57,323 - INFO  - Training [66][  160/  196]   Loss nan   Top1 9.929199   Top5 49.338379   BatchTime 0.291447   LR 0.000019   
2022-11-26 05:28:02,475 - INFO  - Training [66][  180/  196]   Loss nan   Top1 9.960938   Top5 49.481337   BatchTime 0.287687   LR 0.000018   
2022-11-26 05:28:06,701 - INFO  - ==> Top1: 9.930    Top5: 49.540    Loss: nan

2022-11-26 05:28:06,881 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:28:07,937 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:28:10,165 - INFO  - Validation [66][   20/   40]   Loss 4.994287   Top1 10.078125   Top5 50.058594   BatchTime 0.111289   
2022-11-26 05:28:11,248 - INFO  - Validation [66][   40/   40]   Loss 5.005848   Top1 10.000000   Top5 50.000000   BatchTime 0.082729   
2022-11-26 05:28:11,424 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 5.006

2022-11-26 05:28:11,424 - INFO  - ==> Sparsity : 0.506

2022-11-26 05:28:11,424 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:28:11,424 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:28:11,424 - INFO  - Scoreboard best 3 ==> Epoch [66][Top1: 10.000   Top5: 50.000]
2022-11-26 05:28:11,537 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:28:11,538 - INFO  - >>>>>> Epoch  67
2022-11-26 05:28:11,540 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:28:18,443 - INFO  - Training [67][   20/  196]   Loss nan   Top1 10.175781   Top5 50.683594   BatchTime 0.345054   LR 0.000016   
2022-11-26 05:28:23,358 - INFO  - Training [67][   40/  196]   Loss nan   Top1 10.146484   Top5 50.791016   BatchTime 0.295381   LR 0.000015   
2022-11-26 05:28:28,515 - INFO  - Training [67][   60/  196]   Loss nan   Top1 9.973958   Top5 50.481771   BatchTime 0.282881   LR 0.000014   
2022-11-26 05:28:33,602 - INFO  - Training [67][   80/  196]   Loss nan   Top1 9.921875   Top5 50.590820   BatchTime 0.275739   LR 0.000013   
2022-11-26 05:28:39,018 - INFO  - Training [67][  100/  196]   Loss nan   Top1 9.957031   Top5 50.570312   BatchTime 0.274759   LR 0.000012   
2022-11-26 05:28:44,760 - INFO  - Training [67][  120/  196]   Loss nan   Top1 9.902344   Top5 50.458984   BatchTime 0.276809   LR 0.000011   
2022-11-26 05:28:50,423 - INFO  - Training [67][  140/  196]   Loss nan   Top1 9.891183   Top5 50.337612   BatchTime 0.277718   LR 0.000010   
2022-11-26 05:28:55,654 - INFO  - Training [67][  160/  196]   Loss nan   Top1 9.934082   Top5 50.473633   BatchTime 0.275695   LR 0.000009   
2022-11-26 05:29:00,334 - INFO  - Training [67][  180/  196]   Loss nan   Top1 9.943576   Top5 50.501302   BatchTime 0.271060   LR 0.000008   
2022-11-26 05:29:04,462 - INFO  - ==> Top1: 9.922    Top5: 50.420    Loss: nan

2022-11-26 05:29:04,662 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:29:05,595 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:29:07,881 - INFO  - Validation [67][   20/   40]   Loss 4.913918   Top1 10.078125   Top5 50.214844   BatchTime 0.114182   
2022-11-26 05:29:08,833 - INFO  - Validation [67][   40/   40]   Loss 4.925227   Top1 10.000000   Top5 50.000000   BatchTime 0.080905   
2022-11-26 05:29:09,028 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 4.925

2022-11-26 05:29:09,028 - INFO  - ==> Sparsity : 0.506

2022-11-26 05:29:09,028 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:29:09,028 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:29:09,029 - INFO  - Scoreboard best 3 ==> Epoch [67][Top1: 10.000   Top5: 50.000]
2022-11-26 05:29:09,137 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:29:09,138 - INFO  - >>>>>> Epoch  68
2022-11-26 05:29:09,140 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:29:15,296 - INFO  - Training [68][   20/  196]   Loss nan   Top1 10.546875   Top5 50.644531   BatchTime 0.307668   LR 0.000007   
2022-11-26 05:29:20,399 - INFO  - Training [68][   40/  196]   Loss nan   Top1 10.292969   Top5 50.302734   BatchTime 0.281405   LR 0.000006   
2022-11-26 05:29:26,127 - INFO  - Training [68][   60/  196]   Loss nan   Top1 9.928385   Top5 50.123698   BatchTime 0.283074   LR 0.000006   
2022-11-26 05:29:32,113 - INFO  - Training [68][   80/  196]   Loss nan   Top1 9.965820   Top5 50.029297   BatchTime 0.287130   LR 0.000005   
2022-11-26 05:29:37,364 - INFO  - Training [68][  100/  196]   Loss nan   Top1 9.941406   Top5 50.000000   BatchTime 0.282209   LR 0.000004   
2022-11-26 05:29:42,400 - INFO  - Training [68][  120/  196]   Loss nan   Top1 9.938151   Top5 49.993490   BatchTime 0.277141   LR 0.000004   
2022-11-26 05:29:47,999 - INFO  - Training [68][  140/  196]   Loss nan   Top1 9.860491   Top5 50.080915   BatchTime 0.277542   LR 0.000003   
2022-11-26 05:29:53,846 - INFO  - Training [68][  160/  196]   Loss nan   Top1 9.892578   Top5 50.109863   BatchTime 0.279392   LR 0.000003   
2022-11-26 05:29:59,539 - INFO  - Training [68][  180/  196]   Loss nan   Top1 9.930556   Top5 50.217014   BatchTime 0.279976   LR 0.000002   
2022-11-26 05:30:03,709 - INFO  - ==> Top1: 9.942    Top5: 50.264    Loss: nan

2022-11-26 05:30:03,925 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:30:05,054 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:30:07,432 - INFO  - Validation [68][   20/   40]   Loss 4.921660   Top1 10.078125   Top5 50.214844   BatchTime 0.118761   
2022-11-26 05:30:08,403 - INFO  - Validation [68][   40/   40]   Loss 4.932975   Top1 10.000000   Top5 50.000000   BatchTime 0.083682   
2022-11-26 05:30:08,556 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 4.933

2022-11-26 05:30:08,557 - INFO  - ==> Sparsity : 0.506

2022-11-26 05:30:08,557 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:30:08,557 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:30:08,557 - INFO  - Scoreboard best 3 ==> Epoch [68][Top1: 10.000   Top5: 50.000]
2022-11-26 05:30:08,668 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:30:08,669 - INFO  - >>>>>> Epoch  69
2022-11-26 05:30:08,671 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:30:15,151 - INFO  - Training [69][   20/  196]   Loss nan   Top1 9.160156   Top5 49.550781   BatchTime 0.323881   LR 0.000002   
2022-11-26 05:30:20,438 - INFO  - Training [69][   40/  196]   Loss nan   Top1 9.472656   Top5 49.316406   BatchTime 0.294102   LR 0.000001   
2022-11-26 05:30:25,520 - INFO  - Training [69][   60/  196]   Loss nan   Top1 9.648438   Top5 49.661458   BatchTime 0.280779   LR 0.000001   
2022-11-26 05:30:30,976 - INFO  - Training [69][   80/  196]   Loss nan   Top1 9.755859   Top5 50.014648   BatchTime 0.278778   LR 0.000001   
2022-11-26 05:30:36,897 - INFO  - Training [69][  100/  196]   Loss nan   Top1 9.660156   Top5 49.796875   BatchTime 0.282232   LR 0.000000   
2022-11-26 05:30:43,056 - INFO  - Training [69][  120/  196]   Loss nan   Top1 9.824219   Top5 49.853516   BatchTime 0.286516   LR 0.000000   
2022-11-26 05:30:48,929 - INFO  - Training [69][  140/  196]   Loss nan   Top1 9.891183   Top5 49.946987   BatchTime 0.287537   LR 0.000000   
2022-11-26 05:30:54,967 - INFO  - Training [69][  160/  196]   Loss nan   Top1 9.897461   Top5 49.873047   BatchTime 0.289331   LR 0.000000   
2022-11-26 05:31:00,623 - INFO  - Training [69][  180/  196]   Loss nan   Top1 9.932726   Top5 49.854601   BatchTime 0.288608   LR 0.000000   
2022-11-26 05:31:04,738 - INFO  - ==> Top1: 9.930    Top5: 49.886    Loss: nan

2022-11-26 05:31:04,904 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:31:06,116 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:31:08,292 - INFO  - Validation [69][   20/   40]   Loss 4.920627   Top1 10.078125   Top5 50.058594   BatchTime 0.108749   
2022-11-26 05:31:09,243 - INFO  - Validation [69][   40/   40]   Loss 4.931939   Top1 10.000000   Top5 50.000000   BatchTime 0.078147   
2022-11-26 05:31:09,429 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 4.932

2022-11-26 05:31:09,429 - INFO  - ==> Sparsity : 0.506

2022-11-26 05:31:09,429 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-26 05:31:09,430 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-26 05:31:09,430 - INFO  - Scoreboard best 3 ==> Epoch [69][Top1: 10.000   Top5: 50.000]
2022-11-26 05:31:09,556 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/_checkpoint.pth.tar

2022-11-26 05:31:09,557 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-26 05:31:09,558 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:31:11,832 - INFO  - Validation [   20/   40]   Loss 4.920627   Top1 10.078125   Top5 50.058594   BatchTime 0.113610   
2022-11-26 05:31:12,787 - INFO  - Validation [   40/   40]   Loss 4.931939   Top1 10.000000   Top5 50.000000   BatchTime 0.080688   
2022-11-26 05:31:12,898 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 4.932

2022-11-26 05:31:12,898 - INFO  - ==> Sparsity : 0.000

2022-11-26 05:31:12,899 - INFO  - Program completed sucessfully ... exiting ...
2022-11-26 05:31:12,919 - INFO  - >>>>>> Epoch   0
2022-11-26 05:31:12,921 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:31:19,395 - INFO  - Training [0][   20/  196]   Loss 2.304389   Top1 9.687500   Top5 49.765625   BatchTime 0.323575   LR 0.004999   
2022-11-26 05:31:24,726 - INFO  - Training [0][   40/  196]   Loss 2.304516   Top1 9.902344   Top5 49.511719   BatchTime 0.295062   LR 0.004995   
2022-11-26 05:31:29,986 - INFO  - Training [0][   60/  196]   Loss 2.304449   Top1 10.032552   Top5 49.498698   BatchTime 0.284377   LR 0.004989   
2022-11-26 05:31:34,685 - INFO  - Training [0][   80/  196]   Loss 2.304839   Top1 9.838867   Top5 49.482422   BatchTime 0.272022   LR 0.004980   
2022-11-26 05:31:39,638 - INFO  - Training [0][  100/  196]   Loss 2.304816   Top1 9.925781   Top5 49.585938   BatchTime 0.267142   LR 0.004968   
2022-11-26 05:31:44,444 - INFO  - Training [0][  120/  196]   Loss 2.304689   Top1 9.915365   Top5 49.619141   BatchTime 0.262667   LR 0.004954   
2022-11-26 05:31:49,020 - INFO  - Training [0][  140/  196]   Loss 2.304458   Top1 9.988839   Top5 49.698661   BatchTime 0.257826   LR 0.004938   
2022-11-26 05:31:53,776 - INFO  - Training [0][  160/  196]   Loss 2.304511   Top1 9.978027   Top5 49.614258   BatchTime 0.255326   LR 0.004919   
2022-11-26 05:31:58,337 - INFO  - Training [0][  180/  196]   Loss 2.304524   Top1 9.982639   Top5 49.563802   BatchTime 0.252292   LR 0.004897   
2022-11-26 05:32:02,502 - INFO  - ==> Top1: 9.956    Top5: 49.564    Loss: 2.305

2022-11-26 05:32:02,705 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:32:03,878 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:32:06,170 - INFO  - Validation [0][   20/   40]   Loss 2.687663   Top1 10.078125   Top5 50.058594   BatchTime 0.114524   
2022-11-26 05:32:07,097 - INFO  - Validation [0][   40/   40]   Loss 2.692103   Top1 10.000000   Top5 50.000000   BatchTime 0.080432   
2022-11-26 05:32:07,289 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.692

2022-11-26 05:32:07,290 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:32:07,290 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 10.000   Top5: 50.000]
2022-11-26 05:32:12,531 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:32:12,533 - INFO  - >>>>>> Epoch   1
2022-11-26 05:32:12,535 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:32:18,689 - INFO  - Training [1][   20/  196]   Loss 2.303628   Top1 9.785156   Top5 49.648438   BatchTime 0.307571   LR 0.004853   
2022-11-26 05:32:23,701 - INFO  - Training [1][   40/  196]   Loss 2.303760   Top1 9.716797   Top5 49.687500   BatchTime 0.279079   LR 0.004825   
2022-11-26 05:32:28,841 - INFO  - Training [1][   60/  196]   Loss 2.303579   Top1 9.765625   Top5 50.032552   BatchTime 0.271727   LR 0.004794   
2022-11-26 05:32:33,515 - INFO  - Training [1][   80/  196]   Loss 2.303465   Top1 9.912109   Top5 50.063477   BatchTime 0.262215   LR 0.004761   
2022-11-26 05:32:38,543 - INFO  - Training [1][  100/  196]   Loss 2.303532   Top1 9.746094   Top5 49.906250   BatchTime 0.260052   LR 0.004725   
2022-11-26 05:32:43,286 - INFO  - Training [1][  120/  196]   Loss 2.303488   Top1 9.736328   Top5 49.967448   BatchTime 0.256236   LR 0.004687   
2022-11-26 05:32:48,255 - INFO  - Training [1][  140/  196]   Loss 2.303494   Top1 9.762835   Top5 49.935826   BatchTime 0.255123   LR 0.004647   
2022-11-26 05:32:53,109 - INFO  - Training [1][  160/  196]   Loss 2.303468   Top1 9.702148   Top5 50.007324   BatchTime 0.253569   LR 0.004605   
2022-11-26 05:32:57,950 - INFO  - Training [1][  180/  196]   Loss 2.303507   Top1 9.815538   Top5 50.004340   BatchTime 0.252288   LR 0.004560   
2022-11-26 05:33:02,015 - INFO  - ==> Top1: 9.810    Top5: 49.946    Loss: 2.304

2022-11-26 05:33:02,233 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:33:03,156 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:33:05,370 - INFO  - Validation [1][   20/   40]   Loss 2.825407   Top1 10.078125   Top5 50.195312   BatchTime 0.110605   
2022-11-26 05:33:06,441 - INFO  - Validation [1][   40/   40]   Loss 2.829568   Top1 10.000000   Top5 50.000000   BatchTime 0.082069   
2022-11-26 05:33:06,636 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.830

2022-11-26 05:33:06,636 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:33:06,636 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 10.000   Top5: 50.000]
2022-11-26 05:33:06,637 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 10.000   Top5: 50.000]
2022-11-26 05:33:11,706 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:33:11,709 - INFO  - >>>>>> Epoch   2
2022-11-26 05:33:11,711 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:33:17,539 - INFO  - Training [2][   20/  196]   Loss 2.304554   Top1 8.984375   Top5 50.136719   BatchTime 0.291271   LR 0.004477   
2022-11-26 05:33:22,256 - INFO  - Training [2][   40/  196]   Loss 2.304356   Top1 9.277344   Top5 50.000000   BatchTime 0.263561   LR 0.004426   
2022-11-26 05:33:27,036 - INFO  - Training [2][   60/  196]   Loss 2.303855   Top1 9.381510   Top5 50.247396   BatchTime 0.255377   LR 0.004374   
2022-11-26 05:33:31,788 - INFO  - Training [2][   80/  196]   Loss 2.303803   Top1 9.389648   Top5 50.483398   BatchTime 0.250936   LR 0.004320   
2022-11-26 05:33:36,737 - INFO  - Training [2][  100/  196]   Loss 2.303672   Top1 9.367188   Top5 50.609375   BatchTime 0.250238   LR 0.004264   
2022-11-26 05:33:41,398 - INFO  - Training [2][  120/  196]   Loss 2.303665   Top1 9.401042   Top5 50.458984   BatchTime 0.247364   LR 0.004206   
2022-11-26 05:33:45,849 - INFO  - Training [2][  140/  196]   Loss 2.303615   Top1 9.506138   Top5 50.418527   BatchTime 0.243821   LR 0.004146   
2022-11-26 05:33:50,490 - INFO  - Training [2][  160/  196]   Loss 2.303502   Top1 9.580078   Top5 50.419922   BatchTime 0.242354   LR 0.004085   
2022-11-26 05:33:55,447 - INFO  - Training [2][  180/  196]   Loss 2.303438   Top1 9.680990   Top5 50.481771   BatchTime 0.242959   LR 0.004022   
2022-11-26 05:33:59,551 - INFO  - ==> Top1: 9.708    Top5: 50.450    Loss: 2.303

2022-11-26 05:33:59,783 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:34:00,888 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:34:03,082 - INFO  - Validation [2][   20/   40]   Loss 2.868390   Top1 10.078125   Top5 50.195312   BatchTime 0.109567   
2022-11-26 05:34:04,158 - INFO  - Validation [2][   40/   40]   Loss 2.874310   Top1 10.000000   Top5 50.000000   BatchTime 0.081676   
2022-11-26 05:34:04,349 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.874

2022-11-26 05:34:04,349 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:34:04,350 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
2022-11-26 05:34:04,350 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 10.000   Top5: 50.000]
2022-11-26 05:34:04,350 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 10.000   Top5: 50.000]
2022-11-26 05:34:09,256 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:34:09,258 - INFO  - >>>>>> Epoch   3
2022-11-26 05:34:09,259 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:34:15,241 - INFO  - Training [3][   20/  196]   Loss 2.303479   Top1 10.917969   Top5 49.355469   BatchTime 0.298957   LR 0.003907   
2022-11-26 05:34:20,416 - INFO  - Training [3][   40/  196]   Loss 2.303651   Top1 10.175781   Top5 49.277344   BatchTime 0.278869   LR 0.003840   
2022-11-26 05:34:25,495 - INFO  - Training [3][   60/  196]   Loss 2.303547   Top1 10.013021   Top5 49.127604   BatchTime 0.270558   LR 0.003771   
2022-11-26 05:34:30,467 - INFO  - Training [3][   80/  196]   Loss 2.303338   Top1 10.019531   Top5 49.555664   BatchTime 0.265066   LR 0.003701   
2022-11-26 05:34:35,252 - INFO  - Training [3][  100/  196]   Loss 2.303370   Top1 10.027344   Top5 49.589844   BatchTime 0.259899   LR 0.003630   
2022-11-26 05:34:40,214 - INFO  - Training [3][  120/  196]   Loss 2.303407   Top1 9.951172   Top5 49.547526   BatchTime 0.257940   LR 0.003558   
2022-11-26 05:34:44,651 - INFO  - Training [3][  140/  196]   Loss 2.303386   Top1 9.944196   Top5 49.539621   BatchTime 0.252783   LR 0.003484   
2022-11-26 05:34:49,503 - INFO  - Training [3][  160/  196]   Loss 2.303384   Top1 9.990234   Top5 49.567871   BatchTime 0.251503   LR 0.003410   
2022-11-26 05:34:54,059 - INFO  - Training [3][  180/  196]   Loss 2.303464   Top1 10.000000   Top5 49.600694   BatchTime 0.248874   LR 0.003335   
2022-11-26 05:34:58,091 - INFO  - ==> Top1: 10.018    Top5: 49.676    Loss: 2.303

2022-11-26 05:34:58,302 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:34:59,410 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:35:01,693 - INFO  - Validation [3][   20/   40]   Loss 2.747521   Top1 10.078125   Top5 50.195312   BatchTime 0.114026   
2022-11-26 05:35:02,782 - INFO  - Validation [3][   40/   40]   Loss 2.752066   Top1 10.000000   Top5 50.000000   BatchTime 0.084256   
2022-11-26 05:35:02,980 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.752

2022-11-26 05:35:02,980 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:35:02,981 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
2022-11-26 05:35:02,981 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
2022-11-26 05:35:02,981 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 10.000   Top5: 50.000]
2022-11-26 05:35:07,909 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:35:07,911 - INFO  - >>>>>> Epoch   4
2022-11-26 05:35:07,912 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:35:14,292 - INFO  - Training [4][   20/  196]   Loss 2.303261   Top1 9.628906   Top5 50.566406   BatchTime 0.318850   LR 0.003200   
2022-11-26 05:35:19,285 - INFO  - Training [4][   40/  196]   Loss 2.303135   Top1 9.775391   Top5 50.283203   BatchTime 0.284270   LR 0.003122   
2022-11-26 05:35:24,625 - INFO  - Training [4][   60/  196]   Loss 2.303209   Top1 9.863281   Top5 50.292969   BatchTime 0.278505   LR 0.003044   
2022-11-26 05:35:29,652 - INFO  - Training [4][   80/  196]   Loss 2.303196   Top1 9.985352   Top5 50.361328   BatchTime 0.271718   LR 0.002965   
2022-11-26 05:35:34,469 - INFO  - Training [4][  100/  196]   Loss 2.303123   Top1 10.027344   Top5 50.375000   BatchTime 0.265546   LR 0.002886   
2022-11-26 05:35:39,200 - INFO  - Training [4][  120/  196]   Loss 2.303149   Top1 9.951172   Top5 50.253906   BatchTime 0.260714   LR 0.002806   
2022-11-26 05:35:44,235 - INFO  - Training [4][  140/  196]   Loss 2.303098   Top1 10.000000   Top5 50.228795   BatchTime 0.259426   LR 0.002726   
2022-11-26 05:35:49,003 - INFO  - Training [4][  160/  196]   Loss 2.303060   Top1 10.068359   Top5 50.292969   BatchTime 0.256804   LR 0.002646   
2022-11-26 05:35:53,922 - INFO  - Training [4][  180/  196]   Loss 2.303088   Top1 10.125868   Top5 50.199653   BatchTime 0.255593   LR 0.002566   
2022-11-26 05:35:58,006 - INFO  - ==> Top1: 10.096    Top5: 50.178    Loss: 2.303

2022-11-26 05:35:58,228 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:35:59,336 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:36:01,659 - INFO  - Validation [4][   20/   40]   Loss 2.931219   Top1 10.078125   Top5 50.058594   BatchTime 0.116053   
2022-11-26 05:36:02,596 - INFO  - Validation [4][   40/   40]   Loss 2.936154   Top1 10.000000   Top5 50.000000   BatchTime 0.081453   
2022-11-26 05:36:02,785 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.936

2022-11-26 05:36:02,786 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:36:02,786 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
2022-11-26 05:36:02,786 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
2022-11-26 05:36:02,786 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
2022-11-26 05:36:08,685 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:36:08,687 - INFO  - >>>>>> Epoch   5
2022-11-26 05:36:08,689 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:36:14,944 - INFO  - Training [5][   20/  196]   Loss 2.303172   Top1 9.433594   Top5 49.941406   BatchTime 0.312656   LR 0.002424   
2022-11-26 05:36:19,731 - INFO  - Training [5][   40/  196]   Loss 2.303705   Top1 9.267578   Top5 48.896484   BatchTime 0.276014   LR 0.002343   
2022-11-26 05:36:24,663 - INFO  - Training [5][   60/  196]   Loss 2.303474   Top1 9.355469   Top5 49.121094   BatchTime 0.266208   LR 0.002263   
2022-11-26 05:36:29,754 - INFO  - Training [5][   80/  196]   Loss 2.303340   Top1 9.433594   Top5 49.638672   BatchTime 0.263287   LR 0.002183   
2022-11-26 05:36:34,711 - INFO  - Training [5][  100/  196]   Loss 2.303246   Top1 9.464844   Top5 49.652344   BatchTime 0.260202   LR 0.002104   
2022-11-26 05:36:39,531 - INFO  - Training [5][  120/  196]   Loss 2.303274   Top1 9.449870   Top5 49.726562   BatchTime 0.256998   LR 0.002024   
2022-11-26 05:36:44,194 - INFO  - Training [5][  140/  196]   Loss 2.303246   Top1 9.522879   Top5 49.726562   BatchTime 0.253591   LR 0.001946   
2022-11-26 05:36:49,803 - INFO  - Training [5][  160/  196]   Loss 2.303208   Top1 9.575195   Top5 49.724121   BatchTime 0.256950   LR 0.001868   
2022-11-26 05:36:55,117 - INFO  - Training [5][  180/  196]   Loss 2.303238   Top1 9.565972   Top5 49.680990   BatchTime 0.257918   LR 0.001790   
2022-11-26 05:36:59,306 - INFO  - ==> Top1: 9.668    Top5: 49.704    Loss: 2.303

2022-11-26 05:36:59,517 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:37:00,697 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:37:03,037 - INFO  - Validation [5][   20/   40]   Loss 2.714660   Top1 10.078125   Top5 50.214844   BatchTime 0.116896   
2022-11-26 05:37:04,112 - INFO  - Validation [5][   40/   40]   Loss 2.718793   Top1 10.000000   Top5 50.000000   BatchTime 0.085341   
2022-11-26 05:37:04,327 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.719

2022-11-26 05:37:04,328 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:37:04,328 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
2022-11-26 05:37:04,328 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
2022-11-26 05:37:04,328 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
2022-11-26 05:37:10,166 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:37:10,170 - INFO  - >>>>>> Epoch   6
2022-11-26 05:37:10,172 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:37:16,506 - INFO  - Training [6][   20/  196]   Loss 2.302847   Top1 10.292969   Top5 49.511719   BatchTime 0.316578   LR 0.001655   
2022-11-26 05:37:21,432 - INFO  - Training [6][   40/  196]   Loss 2.302952   Top1 9.960938   Top5 50.029297   BatchTime 0.281441   LR 0.001580   
2022-11-26 05:37:26,236 - INFO  - Training [6][   60/  196]   Loss 2.302808   Top1 10.143229   Top5 50.149740   BatchTime 0.267694   LR 0.001506   
2022-11-26 05:37:30,953 - INFO  - Training [6][   80/  196]   Loss 2.302886   Top1 10.161133   Top5 50.131836   BatchTime 0.259734   LR 0.001432   
2022-11-26 05:37:35,735 - INFO  - Training [6][  100/  196]   Loss 2.302960   Top1 10.058594   Top5 50.132812   BatchTime 0.255607   LR 0.001360   
2022-11-26 05:37:40,696 - INFO  - Training [6][  120/  196]   Loss 2.302951   Top1 10.120443   Top5 49.964193   BatchTime 0.254348   LR 0.001289   
2022-11-26 05:37:45,584 - INFO  - Training [6][  140/  196]   Loss 2.302921   Top1 10.142299   Top5 49.938616   BatchTime 0.252929   LR 0.001220   
2022-11-26 05:37:50,729 - INFO  - Training [6][  160/  196]   Loss 2.302961   Top1 10.085449   Top5 49.902344   BatchTime 0.253466   LR 0.001151   
2022-11-26 05:37:55,214 - INFO  - Training [6][  180/  196]   Loss 2.302936   Top1 10.101997   Top5 49.876302   BatchTime 0.250217   LR 0.001084   
2022-11-26 05:37:58,866 - INFO  - ==> Top1: 10.108    Top5: 49.856    Loss: 2.303

2022-11-26 05:37:59,125 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:38:00,442 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:38:02,724 - INFO  - Validation [6][   20/   40]   Loss 2.749345   Top1 10.078125   Top5 50.214844   BatchTime 0.114006   
2022-11-26 05:38:03,769 - INFO  - Validation [6][   40/   40]   Loss 2.753932   Top1 10.000000   Top5 50.000000   BatchTime 0.083132   
2022-11-26 05:38:03,949 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.754

2022-11-26 05:38:03,950 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:38:03,950 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
2022-11-26 05:38:03,950 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
2022-11-26 05:38:03,950 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
2022-11-26 05:38:08,810 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:38:08,813 - INFO  - >>>>>> Epoch   7
2022-11-26 05:38:08,815 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:38:14,904 - INFO  - Training [7][   20/  196]   Loss 2.302688   Top1 9.824219   Top5 49.296875   BatchTime 0.304337   LR 0.000969   
2022-11-26 05:38:19,629 - INFO  - Training [7][   40/  196]   Loss 2.302655   Top1 10.048828   Top5 49.824219   BatchTime 0.270300   LR 0.000907   
2022-11-26 05:38:24,464 - INFO  - Training [7][   60/  196]   Loss 2.302618   Top1 9.980469   Top5 49.720052   BatchTime 0.260783   LR 0.000845   
2022-11-26 05:38:29,469 - INFO  - Training [7][   80/  196]   Loss 2.302717   Top1 10.043945   Top5 49.648438   BatchTime 0.258156   LR 0.000786   
2022-11-26 05:38:34,512 - INFO  - Training [7][  100/  196]   Loss 2.302753   Top1 9.988281   Top5 49.582031   BatchTime 0.256950   LR 0.000728   
2022-11-26 05:38:39,326 - INFO  - Training [7][  120/  196]   Loss 2.302685   Top1 10.094401   Top5 49.817708   BatchTime 0.254244   LR 0.000673   
2022-11-26 05:38:44,471 - INFO  - Training [7][  140/  196]   Loss 2.302745   Top1 10.033482   Top5 49.740513   BatchTime 0.254666   LR 0.000619   
2022-11-26 05:38:49,616 - INFO  - Training [7][  160/  196]   Loss 2.302717   Top1 10.019531   Top5 49.787598   BatchTime 0.254993   LR 0.000567   
2022-11-26 05:38:54,604 - INFO  - Training [7][  180/  196]   Loss 2.302752   Top1 10.019531   Top5 49.763455   BatchTime 0.254372   LR 0.000517   
2022-11-26 05:38:58,718 - INFO  - ==> Top1: 10.038    Top5: 49.756    Loss: 2.303

2022-11-26 05:38:58,959 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:39:00,113 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:39:02,525 - INFO  - Validation [7][   20/   40]   Loss 2.815656   Top1 10.078125   Top5 50.214844   BatchTime 0.120514   
2022-11-26 05:39:03,503 - INFO  - Validation [7][   40/   40]   Loss 2.820296   Top1 10.000000   Top5 50.000000   BatchTime 0.084721   
2022-11-26 05:39:03,699 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.820

2022-11-26 05:39:03,699 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:39:03,700 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
2022-11-26 05:39:03,700 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
2022-11-26 05:39:03,700 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
2022-11-26 05:39:08,287 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:39:08,289 - INFO  - >>>>>> Epoch   8
2022-11-26 05:39:08,291 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:39:14,279 - INFO  - Training [8][   20/  196]   Loss 2.302965   Top1 9.609375   Top5 49.882812   BatchTime 0.299313   LR 0.000434   
2022-11-26 05:39:19,262 - INFO  - Training [8][   40/  196]   Loss 2.302933   Top1 9.824219   Top5 49.853516   BatchTime 0.274235   LR 0.000389   
2022-11-26 05:39:24,902 - INFO  - Training [8][   60/  196]   Loss 2.302832   Top1 9.739583   Top5 49.615885   BatchTime 0.276830   LR 0.000347   
2022-11-26 05:39:29,425 - INFO  - Training [8][   80/  196]   Loss 2.302769   Top1 9.921875   Top5 49.804688   BatchTime 0.264148   LR 0.000308   
2022-11-26 05:39:34,470 - INFO  - Training [8][  100/  196]   Loss 2.302712   Top1 9.988281   Top5 49.968750   BatchTime 0.261768   LR 0.000270   
2022-11-26 05:39:39,094 - INFO  - Training [8][  120/  196]   Loss 2.302712   Top1 10.019531   Top5 49.915365   BatchTime 0.256674   LR 0.000235   
2022-11-26 05:39:43,810 - INFO  - Training [8][  140/  196]   Loss 2.302734   Top1 10.066964   Top5 49.966518   BatchTime 0.253691   LR 0.000202   
2022-11-26 05:39:48,731 - INFO  - Training [8][  160/  196]   Loss 2.302766   Top1 9.980469   Top5 50.014648   BatchTime 0.252735   LR 0.000172   
2022-11-26 05:39:53,101 - INFO  - Training [8][  180/  196]   Loss 2.302752   Top1 9.995660   Top5 50.010851   BatchTime 0.248932   LR 0.000143   
2022-11-26 05:39:56,710 - INFO  - ==> Top1: 9.978    Top5: 49.994    Loss: 2.303

2022-11-26 05:39:56,885 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:39:57,887 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:40:00,209 - INFO  - Validation [8][   20/   40]   Loss 2.813715   Top1 10.078125   Top5 50.214844   BatchTime 0.116014   
2022-11-26 05:40:01,276 - INFO  - Validation [8][   40/   40]   Loss 2.818641   Top1 10.000000   Top5 50.000000   BatchTime 0.084679   
2022-11-26 05:40:01,461 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.819

2022-11-26 05:40:01,461 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:40:01,461 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
2022-11-26 05:40:01,462 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
2022-11-26 05:40:01,462 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
2022-11-26 05:40:06,153 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:40:06,154 - INFO  - >>>>>> Epoch   9
2022-11-26 05:40:06,156 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:40:11,987 - INFO  - Training [9][   20/  196]   Loss 2.302699   Top1 10.605469   Top5 50.312500   BatchTime 0.291415   LR 0.000100   
2022-11-26 05:40:16,424 - INFO  - Training [9][   40/  196]   Loss 2.302577   Top1 10.507812   Top5 50.166016   BatchTime 0.256631   LR 0.000079   
2022-11-26 05:40:21,452 - INFO  - Training [9][   60/  196]   Loss 2.302550   Top1 10.247396   Top5 50.045573   BatchTime 0.254879   LR 0.000060   
2022-11-26 05:40:26,966 - INFO  - Training [9][   80/  196]   Loss 2.302529   Top1 10.224609   Top5 50.307617   BatchTime 0.260095   LR 0.000044   
2022-11-26 05:40:32,024 - INFO  - Training [9][  100/  196]   Loss 2.302541   Top1 10.273438   Top5 50.269531   BatchTime 0.258651   LR 0.000030   
2022-11-26 05:40:37,167 - INFO  - Training [9][  120/  196]   Loss 2.302570   Top1 10.198568   Top5 50.133464   BatchTime 0.258403   LR 0.000019   
2022-11-26 05:40:42,100 - INFO  - Training [9][  140/  196]   Loss 2.302624   Top1 10.117188   Top5 49.991629   BatchTime 0.256721   LR 0.000010   
2022-11-26 05:40:46,719 - INFO  - Training [9][  160/  196]   Loss 2.302619   Top1 10.080566   Top5 50.151367   BatchTime 0.253497   LR 0.000004   
2022-11-26 05:40:51,915 - INFO  - Training [9][  180/  196]   Loss 2.302680   Top1 9.963108   Top5 50.062934   BatchTime 0.254197   LR 0.000001   
2022-11-26 05:40:56,107 - INFO  - ==> Top1: 9.992    Top5: 50.088    Loss: 2.303

2022-11-26 05:40:56,325 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:40:57,486 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:40:59,906 - INFO  - Validation [9][   20/   40]   Loss 2.856546   Top1 10.078125   Top5 50.214844   BatchTime 0.120908   
2022-11-26 05:41:01,004 - INFO  - Validation [9][   40/   40]   Loss 2.861621   Top1 10.000000   Top5 50.000000   BatchTime 0.087918   
2022-11-26 05:41:01,226 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.862

2022-11-26 05:41:01,226 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:41:01,227 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
2022-11-26 05:41:01,227 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
2022-11-26 05:41:01,227 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
2022-11-26 05:41:06,128 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:41:06,133 - INFO  - >>>>>> Epoch  10
2022-11-26 05:41:06,135 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:41:13,398 - INFO  - Training [10][   20/  196]   Loss 2.302634   Top1 10.468750   Top5 49.199219   BatchTime 0.362996   LR 0.002500   
2022-11-26 05:41:18,721 - INFO  - Training [10][   40/  196]   Loss 2.302719   Top1 10.439453   Top5 49.687500   BatchTime 0.314578   LR 0.002499   
2022-11-26 05:41:23,735 - INFO  - Training [10][   60/  196]   Loss 2.302843   Top1 10.247396   Top5 49.459635   BatchTime 0.293279   LR 0.002499   
2022-11-26 05:41:28,799 - INFO  - Training [10][   80/  196]   Loss 2.302796   Top1 10.249023   Top5 49.677734   BatchTime 0.283259   LR 0.002497   
2022-11-26 05:41:33,417 - INFO  - Training [10][  100/  196]   Loss 2.302769   Top1 10.312500   Top5 49.816406   BatchTime 0.272793   LR 0.002496   
2022-11-26 05:41:38,148 - INFO  - Training [10][  120/  196]   Loss 2.302799   Top1 10.325521   Top5 49.820964   BatchTime 0.266749   LR 0.002494   
2022-11-26 05:41:43,259 - INFO  - Training [10][  140/  196]   Loss 2.302892   Top1 10.267857   Top5 49.587054   BatchTime 0.265145   LR 0.002492   
2022-11-26 05:41:48,009 - INFO  - Training [10][  160/  196]   Loss 2.302899   Top1 10.180664   Top5 49.543457   BatchTime 0.261691   LR 0.002490   
2022-11-26 05:41:53,259 - INFO  - Training [10][  180/  196]   Loss 2.302864   Top1 10.201823   Top5 49.628906   BatchTime 0.261779   LR 0.002487   
2022-11-26 05:41:57,398 - INFO  - ==> Top1: 10.216    Top5: 49.628    Loss: 2.303

2022-11-26 05:41:57,625 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:41:58,743 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:42:01,124 - INFO  - Validation [10][   20/   40]   Loss 2.671312   Top1 10.078125   Top5 50.058594   BatchTime 0.118955   
2022-11-26 05:42:02,113 - INFO  - Validation [10][   40/   40]   Loss 2.675713   Top1 10.000000   Top5 50.000000   BatchTime 0.084229   
2022-11-26 05:42:02,301 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.676

2022-11-26 05:42:02,301 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:42:02,301 - INFO  - Scoreboard best 1 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
2022-11-26 05:42:02,302 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
2022-11-26 05:42:02,302 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
2022-11-26 05:42:07,127 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:42:07,129 - INFO  - >>>>>> Epoch  11
2022-11-26 05:42:07,131 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:42:13,700 - INFO  - Training [11][   20/  196]   Loss 2.302797   Top1 10.078125   Top5 49.589844   BatchTime 0.328318   LR 0.002481   
2022-11-26 05:42:19,162 - INFO  - Training [11][   40/  196]   Loss 2.302776   Top1 10.234375   Top5 49.443359   BatchTime 0.300715   LR 0.002478   
2022-11-26 05:42:24,477 - INFO  - Training [11][   60/  196]   Loss 2.302904   Top1 10.240885   Top5 49.654948   BatchTime 0.289062   LR 0.002474   
2022-11-26 05:42:29,444 - INFO  - Training [11][   80/  196]   Loss 2.302981   Top1 9.931641   Top5 49.697266   BatchTime 0.278880   LR 0.002470   
2022-11-26 05:42:34,369 - INFO  - Training [11][  100/  196]   Loss 2.302925   Top1 9.906250   Top5 49.671875   BatchTime 0.272357   LR 0.002465   
2022-11-26 05:42:39,302 - INFO  - Training [11][  120/  196]   Loss 2.302968   Top1 9.788411   Top5 49.531250   BatchTime 0.268075   LR 0.002460   
2022-11-26 05:42:44,395 - INFO  - Training [11][  140/  196]   Loss 2.302969   Top1 9.849330   Top5 49.536830   BatchTime 0.266151   LR 0.002455   
2022-11-26 05:42:49,352 - INFO  - Training [11][  160/  196]   Loss 2.302946   Top1 9.899902   Top5 49.597168   BatchTime 0.263861   LR 0.002450   
2022-11-26 05:42:54,354 - INFO  - Training [11][  180/  196]   Loss 2.302995   Top1 9.889323   Top5 49.563802   BatchTime 0.262334   LR 0.002444   
2022-11-26 05:42:58,523 - INFO  - ==> Top1: 9.918    Top5: 49.526    Loss: 2.303

2022-11-26 05:42:58,875 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:42:59,785 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:43:02,152 - INFO  - Validation [11][   20/   40]   Loss 2.613989   Top1 10.078125   Top5 50.214844   BatchTime 0.118251   
2022-11-26 05:43:03,236 - INFO  - Validation [11][   40/   40]   Loss 2.617917   Top1 10.000000   Top5 50.000000   BatchTime 0.086233   
2022-11-26 05:43:03,442 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.618

2022-11-26 05:43:03,442 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:43:03,443 - INFO  - Scoreboard best 1 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
2022-11-26 05:43:03,443 - INFO  - Scoreboard best 2 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
2022-11-26 05:43:03,443 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
2022-11-26 05:43:08,000 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:43:08,002 - INFO  - >>>>>> Epoch  12
2022-11-26 05:43:08,004 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:43:15,111 - INFO  - Training [12][   20/  196]   Loss 2.302981   Top1 10.703125   Top5 50.292969   BatchTime 0.355247   LR 0.002433   
2022-11-26 05:43:19,891 - INFO  - Training [12][   40/  196]   Loss 2.302906   Top1 10.390625   Top5 50.312500   BatchTime 0.297108   LR 0.002426   
2022-11-26 05:43:24,800 - INFO  - Training [12][   60/  196]   Loss 2.303071   Top1 10.338542   Top5 50.000000   BatchTime 0.279898   LR 0.002419   
2022-11-26 05:43:29,694 - INFO  - Training [12][   80/  196]   Loss 2.303146   Top1 10.043945   Top5 49.848633   BatchTime 0.271094   LR 0.002412   
2022-11-26 05:43:34,851 - INFO  - Training [12][  100/  196]   Loss 2.303137   Top1 9.949219   Top5 49.734375   BatchTime 0.268439   LR 0.002404   
2022-11-26 05:43:39,486 - INFO  - Training [12][  120/  196]   Loss 2.303155   Top1 9.889323   Top5 49.518229   BatchTime 0.262327   LR 0.002396   
2022-11-26 05:43:44,476 - INFO  - Training [12][  140/  196]   Loss 2.303179   Top1 9.944196   Top5 49.536830   BatchTime 0.260495   LR 0.002388   
2022-11-26 05:43:49,514 - INFO  - Training [12][  160/  196]   Loss 2.303194   Top1 9.851074   Top5 49.455566   BatchTime 0.259417   LR 0.002380   
2022-11-26 05:43:54,185 - INFO  - Training [12][  180/  196]   Loss 2.303174   Top1 9.913194   Top5 49.513889   BatchTime 0.256543   LR 0.002371   
2022-11-26 05:43:58,392 - INFO  - ==> Top1: 9.872    Top5: 49.534    Loss: 2.303

2022-11-26 05:43:58,661 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:44:00,211 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:44:02,944 - INFO  - Validation [12][   20/   40]   Loss 2.662041   Top1 10.078125   Top5 50.214844   BatchTime 0.136484   
2022-11-26 05:44:03,977 - INFO  - Validation [12][   40/   40]   Loss 2.666380   Top1 10.000000   Top5 50.000000   BatchTime 0.094072   
2022-11-26 05:44:04,185 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.666

2022-11-26 05:44:04,186 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:44:04,186 - INFO  - Scoreboard best 1 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
2022-11-26 05:44:04,186 - INFO  - Scoreboard best 2 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
2022-11-26 05:44:04,186 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
2022-11-26 05:44:09,559 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:44:09,565 - INFO  - >>>>>> Epoch  13
2022-11-26 05:44:09,568 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:44:15,384 - INFO  - Training [13][   20/  196]   Loss 2.303118   Top1 9.570312   Top5 49.433594   BatchTime 0.290708   LR 0.002355   
2022-11-26 05:44:20,257 - INFO  - Training [13][   40/  196]   Loss 2.303148   Top1 9.775391   Top5 49.765625   BatchTime 0.267158   LR 0.002345   
2022-11-26 05:44:25,211 - INFO  - Training [13][   60/  196]   Loss 2.303139   Top1 9.837240   Top5 49.615885   BatchTime 0.260678   LR 0.002336   
2022-11-26 05:44:30,176 - INFO  - Training [13][   80/  196]   Loss 2.303111   Top1 9.804688   Top5 49.516602   BatchTime 0.257567   LR 0.002325   
2022-11-26 05:44:35,009 - INFO  - Training [13][  100/  196]   Loss 2.303002   Top1 10.015625   Top5 49.578125   BatchTime 0.254384   LR 0.002315   
2022-11-26 05:44:39,831 - INFO  - Training [13][  120/  196]   Loss 2.302985   Top1 9.996745   Top5 49.560547   BatchTime 0.252169   LR 0.002304   
2022-11-26 05:44:44,752 - INFO  - Training [13][  140/  196]   Loss 2.303001   Top1 9.921875   Top5 49.534040   BatchTime 0.251296   LR 0.002293   
2022-11-26 05:44:49,704 - INFO  - Training [13][  160/  196]   Loss 2.302978   Top1 9.929199   Top5 49.511719   BatchTime 0.250835   LR 0.002282   
2022-11-26 05:44:54,611 - INFO  - Training [13][  180/  196]   Loss 2.302963   Top1 9.887153   Top5 49.592014   BatchTime 0.250223   LR 0.002271   
2022-11-26 05:44:58,228 - INFO  - ==> Top1: 9.932    Top5: 49.696    Loss: 2.303

2022-11-26 05:44:58,438 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:44:59,779 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:45:02,198 - INFO  - Validation [13][   20/   40]   Loss 2.777978   Top1 10.078125   Top5 50.214844   BatchTime 0.120895   
2022-11-26 05:45:03,188 - INFO  - Validation [13][   40/   40]   Loss 2.782532   Top1 10.000000   Top5 50.000000   BatchTime 0.085196   
2022-11-26 05:45:03,396 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.783

2022-11-26 05:45:03,396 - INFO  - ==> Sparsity : 0.521

2022-11-26 05:45:03,397 - INFO  - Scoreboard best 1 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
2022-11-26 05:45:03,397 - INFO  - Scoreboard best 2 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
2022-11-26 05:45:03,397 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
2022-11-26 05:45:08,970 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:45:08,972 - INFO  - >>>>>> Epoch  14
2022-11-26 05:45:08,974 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:45:14,977 - INFO  - Training [14][   20/  196]   Loss 2.303220   Top1 9.628906   Top5 49.687500   BatchTime 0.300031   LR 0.002250   
2022-11-26 05:45:19,747 - INFO  - Training [14][   40/  196]   Loss 2.303132   Top1 10.185547   Top5 49.296875   BatchTime 0.269254   LR 0.002238   
2022-11-26 05:45:24,732 - INFO  - Training [14][   60/  196]   Loss 2.303141   Top1 10.045573   Top5 49.401042   BatchTime 0.262593   LR 0.002225   
2022-11-26 05:45:29,701 - INFO  - Training [14][   80/  196]   Loss 2.303099   Top1 9.970703   Top5 49.355469   BatchTime 0.259058   LR 0.002213   
2022-11-26 05:45:34,434 - INFO  - Training [14][  100/  196]   Loss 2.303016   Top1 10.042969   Top5 49.320312   BatchTime 0.254568   LR 0.002200   
2022-11-26 05:45:39,569 - INFO  - Training [14][  120/  196]   Loss 2.303020   Top1 10.120443   Top5 49.417318   BatchTime 0.254935   LR 0.002186   
2022-11-26 05:45:44,719 - INFO  - Training [14][  140/  196]   Loss 2.302993   Top1 10.153460   Top5 49.486607   BatchTime 0.255303   LR 0.002173   
2022-11-26 05:45:49,836 - INFO  - Training [14][  160/  196]   Loss 2.302981   Top1 10.090332   Top5 49.538574   BatchTime 0.255370   LR 0.002159   
2022-11-26 05:45:54,500 - INFO  - Training [14][  180/  196]   Loss 2.303001   Top1 10.071615   Top5 49.474826   BatchTime 0.252904   LR 0.002145   
2022-11-26 05:45:58,603 - INFO  - ==> Top1: 10.118    Top5: 49.512    Loss: 2.303

2022-11-26 05:45:58,806 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:46:00,094 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:46:02,556 - INFO  - Validation [14][   20/   40]   Loss 2.578017   Top1 10.078125   Top5 50.058594   BatchTime 0.123042   
2022-11-26 05:46:03,619 - INFO  - Validation [14][   40/   40]   Loss 2.581469   Top1 10.000000   Top5 50.000000   BatchTime 0.088101   
2022-11-26 05:46:03,819 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.581

2022-11-26 05:46:03,819 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:46:03,819 - INFO  - Scoreboard best 1 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
2022-11-26 05:46:03,819 - INFO  - Scoreboard best 2 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
2022-11-26 05:46:03,819 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
2022-11-26 05:46:08,702 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:46:08,705 - INFO  - >>>>>> Epoch  15
2022-11-26 05:46:08,706 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:46:14,942 - INFO  - Training [15][   20/  196]   Loss 2.302806   Top1 9.589844   Top5 49.453125   BatchTime 0.311675   LR 0.002120   
2022-11-26 05:46:19,497 - INFO  - Training [15][   40/  196]   Loss 2.303058   Top1 9.658203   Top5 49.130859   BatchTime 0.269711   LR 0.002106   
2022-11-26 05:46:24,311 - INFO  - Training [15][   60/  196]   Loss 2.303067   Top1 9.986979   Top5 49.427083   BatchTime 0.260042   LR 0.002091   
2022-11-26 05:46:29,561 - INFO  - Training [15][   80/  196]   Loss 2.303005   Top1 10.019531   Top5 49.658203   BatchTime 0.260653   LR 0.002076   
2022-11-26 05:46:34,254 - INFO  - Training [15][  100/  196]   Loss 2.302981   Top1 9.941406   Top5 49.648438   BatchTime 0.255454   LR 0.002061   
2022-11-26 05:46:39,276 - INFO  - Training [15][  120/  196]   Loss 2.303024   Top1 9.830729   Top5 49.534505   BatchTime 0.254725   LR 0.002045   
2022-11-26 05:46:44,017 - INFO  - Training [15][  140/  196]   Loss 2.303002   Top1 9.807478   Top5 49.436384   BatchTime 0.252199   LR 0.002030   
2022-11-26 05:46:48,765 - INFO  - Training [15][  160/  196]   Loss 2.302958   Top1 9.865723   Top5 49.460449   BatchTime 0.250350   LR 0.002014   
2022-11-26 05:46:53,710 - INFO  - Training [15][  180/  196]   Loss 2.302955   Top1 9.848090   Top5 49.429253   BatchTime 0.250004   LR 0.001998   
2022-11-26 05:46:57,777 - INFO  - ==> Top1: 9.808    Top5: 49.352    Loss: 2.303

2022-11-26 05:46:58,003 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:46:59,203 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:47:01,801 - INFO  - Validation [15][   20/   40]   Loss 2.594021   Top1 10.078125   Top5 50.214844   BatchTime 0.129832   
2022-11-26 05:47:02,948 - INFO  - Validation [15][   40/   40]   Loss 2.597991   Top1 10.000000   Top5 50.000000   BatchTime 0.093591   
2022-11-26 05:47:03,166 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.598

2022-11-26 05:47:03,166 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:47:03,166 - INFO  - Scoreboard best 1 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
2022-11-26 05:47:03,167 - INFO  - Scoreboard best 2 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
2022-11-26 05:47:03,167 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
2022-11-26 05:47:08,198 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:47:08,201 - INFO  - >>>>>> Epoch  16
2022-11-26 05:47:08,202 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:47:14,660 - INFO  - Training [16][   20/  196]   Loss 2.302361   Top1 10.097656   Top5 50.605469   BatchTime 0.322773   LR 0.001969   
2022-11-26 05:47:19,788 - INFO  - Training [16][   40/  196]   Loss 2.302720   Top1 10.029297   Top5 50.136719   BatchTime 0.289570   LR 0.001953   
2022-11-26 05:47:24,731 - INFO  - Training [16][   60/  196]   Loss 2.302861   Top1 9.752604   Top5 50.104167   BatchTime 0.275442   LR 0.001936   
2022-11-26 05:47:29,718 - INFO  - Training [16][   80/  196]   Loss 2.302881   Top1 9.565430   Top5 50.146484   BatchTime 0.268909   LR 0.001919   
2022-11-26 05:47:34,503 - INFO  - Training [16][  100/  196]   Loss 2.302910   Top1 9.617188   Top5 50.007812   BatchTime 0.262977   LR 0.001902   
2022-11-26 05:47:39,478 - INFO  - Training [16][  120/  196]   Loss 2.302932   Top1 9.694010   Top5 49.915365   BatchTime 0.260608   LR 0.001885   
2022-11-26 05:47:44,743 - INFO  - Training [16][  140/  196]   Loss 2.302934   Top1 9.673549   Top5 49.760045   BatchTime 0.260986   LR 0.001867   
2022-11-26 05:47:49,734 - INFO  - Training [16][  160/  196]   Loss 2.302972   Top1 9.685059   Top5 49.643555   BatchTime 0.259553   LR 0.001850   
2022-11-26 05:47:54,113 - INFO  - Training [16][  180/  196]   Loss 2.302928   Top1 9.676649   Top5 49.817708   BatchTime 0.255042   LR 0.001832   
2022-11-26 05:47:57,851 - INFO  - ==> Top1: 9.648    Top5: 49.918    Loss: 2.303

2022-11-26 05:47:58,121 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:47:59,512 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:48:01,983 - INFO  - Validation [16][   20/   40]   Loss 2.626808   Top1 10.078125   Top5 50.214844   BatchTime 0.123452   
2022-11-26 05:48:02,886 - INFO  - Validation [16][   40/   40]   Loss 2.630941   Top1 10.000000   Top5 50.000000   BatchTime 0.084319   
2022-11-26 05:48:03,088 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.631

2022-11-26 05:48:03,088 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:48:03,088 - INFO  - Scoreboard best 1 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
2022-11-26 05:48:03,088 - INFO  - Scoreboard best 2 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
2022-11-26 05:48:03,089 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
2022-11-26 05:48:07,969 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:48:07,972 - INFO  - >>>>>> Epoch  17
2022-11-26 05:48:07,974 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:48:14,136 - INFO  - Training [17][   20/  196]   Loss 2.303010   Top1 9.355469   Top5 50.468750   BatchTime 0.308035   LR 0.001800   
2022-11-26 05:48:18,899 - INFO  - Training [17][   40/  196]   Loss 2.302896   Top1 9.824219   Top5 50.224609   BatchTime 0.273071   LR 0.001782   
2022-11-26 05:48:23,460 - INFO  - Training [17][   60/  196]   Loss 2.302871   Top1 9.889323   Top5 50.149740   BatchTime 0.258065   LR 0.001764   
2022-11-26 05:48:28,382 - INFO  - Training [17][   80/  196]   Loss 2.302947   Top1 9.682617   Top5 50.039062   BatchTime 0.255079   LR 0.001746   
2022-11-26 05:48:33,753 - INFO  - Training [17][  100/  196]   Loss 2.302978   Top1 9.726562   Top5 49.878906   BatchTime 0.257769   LR 0.001727   
2022-11-26 05:48:38,548 - INFO  - Training [17][  120/  196]   Loss 2.302973   Top1 9.736328   Top5 49.687500   BatchTime 0.254762   LR 0.001708   
2022-11-26 05:48:43,472 - INFO  - Training [17][  140/  196]   Loss 2.302994   Top1 9.771205   Top5 49.676339   BatchTime 0.253542   LR 0.001690   
2022-11-26 05:48:48,420 - INFO  - Training [17][  160/  196]   Loss 2.302985   Top1 9.819336   Top5 49.567871   BatchTime 0.252772   LR 0.001671   
2022-11-26 05:48:52,835 - INFO  - Training [17][  180/  196]   Loss 2.302912   Top1 9.934896   Top5 49.670139   BatchTime 0.249216   LR 0.001652   
2022-11-26 05:48:56,435 - INFO  - ==> Top1: 9.850    Top5: 49.664    Loss: 2.303

2022-11-26 05:48:56,672 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:48:57,857 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:49:00,393 - INFO  - Validation [17][   20/   40]   Loss 2.594315   Top1 10.078125   Top5 50.214844   BatchTime 0.126709   
2022-11-26 05:49:01,515 - INFO  - Validation [17][   40/   40]   Loss 2.598484   Top1 10.000000   Top5 50.000000   BatchTime 0.091402   
2022-11-26 05:49:01,733 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.598

2022-11-26 05:49:01,733 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:49:01,733 - INFO  - Scoreboard best 1 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
2022-11-26 05:49:01,733 - INFO  - Scoreboard best 2 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
2022-11-26 05:49:01,734 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
2022-11-26 05:49:06,380 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:49:06,382 - INFO  - >>>>>> Epoch  18
2022-11-26 05:49:06,384 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:49:12,599 - INFO  - Training [18][   20/  196]   Loss 2.302340   Top1 10.625000   Top5 51.035156   BatchTime 0.310638   LR 0.001618   
2022-11-26 05:49:17,428 - INFO  - Training [18][   40/  196]   Loss 2.302508   Top1 10.263672   Top5 50.673828   BatchTime 0.276033   LR 0.001599   
2022-11-26 05:49:22,458 - INFO  - Training [18][   60/  196]   Loss 2.302511   Top1 10.091146   Top5 50.846354   BatchTime 0.267855   LR 0.001579   
2022-11-26 05:49:27,522 - INFO  - Training [18][   80/  196]   Loss 2.302571   Top1 10.063477   Top5 50.605469   BatchTime 0.264190   LR 0.001560   
2022-11-26 05:49:32,671 - INFO  - Training [18][  100/  196]   Loss 2.302581   Top1 10.042969   Top5 50.523438   BatchTime 0.262845   LR 0.001540   
2022-11-26 05:49:37,678 - INFO  - Training [18][  120/  196]   Loss 2.302645   Top1 10.065104   Top5 50.445964   BatchTime 0.260759   LR 0.001521   
2022-11-26 05:49:42,460 - INFO  - Training [18][  140/  196]   Loss 2.302666   Top1 10.039062   Top5 50.471540   BatchTime 0.257669   LR 0.001501   
2022-11-26 05:49:47,241 - INFO  - Training [18][  160/  196]   Loss 2.302693   Top1 10.041504   Top5 50.385742   BatchTime 0.255338   LR 0.001482   
2022-11-26 05:49:52,172 - INFO  - Training [18][  180/  196]   Loss 2.302735   Top1 9.934896   Top5 50.312500   BatchTime 0.254362   LR 0.001462   
2022-11-26 05:49:55,863 - INFO  - ==> Top1: 9.916    Top5: 50.216    Loss: 2.303

2022-11-26 05:49:56,060 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:49:57,180 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:49:59,658 - INFO  - Validation [18][   20/   40]   Loss 2.546859   Top1 10.078125   Top5 49.980469   BatchTime 0.123831   
2022-11-26 05:50:00,750 - INFO  - Validation [18][   40/   40]   Loss 2.550109   Top1 10.000000   Top5 50.000000   BatchTime 0.089219   
2022-11-26 05:50:00,988 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.550

2022-11-26 05:50:00,989 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:50:00,989 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
2022-11-26 05:50:00,989 - INFO  - Scoreboard best 2 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
2022-11-26 05:50:00,989 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
2022-11-26 05:50:05,628 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:50:05,630 - INFO  - >>>>>> Epoch  19
2022-11-26 05:50:05,632 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:50:11,986 - INFO  - Training [19][   20/  196]   Loss 2.302935   Top1 9.609375   Top5 49.726562   BatchTime 0.317582   LR 0.001427   
2022-11-26 05:50:16,841 - INFO  - Training [19][   40/  196]   Loss 2.302770   Top1 10.039062   Top5 49.824219   BatchTime 0.280177   LR 0.001407   
2022-11-26 05:50:21,782 - INFO  - Training [19][   60/  196]   Loss 2.302848   Top1 9.954427   Top5 50.136719   BatchTime 0.269121   LR 0.001387   
2022-11-26 05:50:26,709 - INFO  - Training [19][   80/  196]   Loss 2.302844   Top1 9.760742   Top5 49.941406   BatchTime 0.263434   LR 0.001367   
2022-11-26 05:50:31,674 - INFO  - Training [19][  100/  196]   Loss 2.302756   Top1 9.804688   Top5 50.144531   BatchTime 0.260393   LR 0.001347   
2022-11-26 05:50:36,245 - INFO  - Training [19][  120/  196]   Loss 2.302747   Top1 9.850260   Top5 50.022786   BatchTime 0.255086   LR 0.001327   
2022-11-26 05:50:41,049 - INFO  - Training [19][  140/  196]   Loss 2.302756   Top1 9.849330   Top5 49.963728   BatchTime 0.252956   LR 0.001307   
2022-11-26 05:50:45,487 - INFO  - Training [19][  160/  196]   Loss 2.302773   Top1 9.831543   Top5 49.973145   BatchTime 0.249076   LR 0.001287   
2022-11-26 05:50:50,476 - INFO  - Training [19][  180/  196]   Loss 2.302787   Top1 9.839410   Top5 49.893663   BatchTime 0.249116   LR 0.001266   
2022-11-26 05:50:54,592 - INFO  - ==> Top1: 9.808    Top5: 49.908    Loss: 2.303

2022-11-26 05:50:54,817 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:50:56,174 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:50:58,641 - INFO  - Validation [19][   20/   40]   Loss 2.538703   Top1 10.078125   Top5 50.214844   BatchTime 0.123307   
2022-11-26 05:50:59,633 - INFO  - Validation [19][   40/   40]   Loss 2.542089   Top1 10.000000   Top5 50.000000   BatchTime 0.086439   
2022-11-26 05:50:59,828 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.542

2022-11-26 05:50:59,828 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:50:59,829 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
2022-11-26 05:50:59,829 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
2022-11-26 05:50:59,829 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
2022-11-26 05:51:05,062 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:51:05,067 - INFO  - >>>>>> Epoch  20
2022-11-26 05:51:05,069 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:51:11,087 - INFO  - Training [20][   20/  196]   Loss 2.302785   Top1 9.902344   Top5 49.433594   BatchTime 0.300783   LR 0.001231   
2022-11-26 05:51:15,531 - INFO  - Training [20][   40/  196]   Loss 2.302811   Top1 9.921875   Top5 49.482422   BatchTime 0.261495   LR 0.001211   
2022-11-26 05:51:20,429 - INFO  - Training [20][   60/  196]   Loss 2.302742   Top1 10.429688   Top5 49.609375   BatchTime 0.255960   LR 0.001191   
2022-11-26 05:51:25,449 - INFO  - Training [20][   80/  196]   Loss 2.302698   Top1 10.288086   Top5 49.731445   BatchTime 0.254715   LR 0.001171   
2022-11-26 05:51:30,234 - INFO  - Training [20][  100/  196]   Loss 2.302723   Top1 10.253906   Top5 49.605469   BatchTime 0.251622   LR 0.001151   
2022-11-26 05:51:34,961 - INFO  - Training [20][  120/  196]   Loss 2.302708   Top1 10.166016   Top5 49.625651   BatchTime 0.249077   LR 0.001131   
2022-11-26 05:51:40,082 - INFO  - Training [20][  140/  196]   Loss 2.302738   Top1 10.139509   Top5 49.623326   BatchTime 0.250069   LR 0.001111   
2022-11-26 05:51:45,004 - INFO  - Training [20][  160/  196]   Loss 2.302730   Top1 10.222168   Top5 49.602051   BatchTime 0.249578   LR 0.001091   
2022-11-26 05:51:50,193 - INFO  - Training [20][  180/  196]   Loss 2.302719   Top1 10.240885   Top5 49.548611   BatchTime 0.250675   LR 0.001071   
2022-11-26 05:51:54,297 - INFO  - ==> Top1: 10.194    Top5: 49.534    Loss: 2.303

2022-11-26 05:51:54,483 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:51:55,723 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:51:58,308 - INFO  - Validation [20][   20/   40]   Loss 2.591823   Top1 10.078125   Top5 50.214844   BatchTime 0.129141   
2022-11-26 05:51:59,255 - INFO  - Validation [20][   40/   40]   Loss 2.595702   Top1 10.000000   Top5 50.000000   BatchTime 0.088251   
2022-11-26 05:51:59,459 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.596

2022-11-26 05:51:59,459 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:51:59,460 - INFO  - Scoreboard best 1 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
2022-11-26 05:51:59,460 - INFO  - Scoreboard best 2 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
2022-11-26 05:51:59,460 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
2022-11-26 05:52:04,729 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:52:04,733 - INFO  - >>>>>> Epoch  21
2022-11-26 05:52:04,735 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:52:11,539 - INFO  - Training [21][   20/  196]   Loss 2.302928   Top1 9.570312   Top5 49.023438   BatchTime 0.340071   LR 0.001036   
2022-11-26 05:52:16,480 - INFO  - Training [21][   40/  196]   Loss 2.302790   Top1 10.029297   Top5 49.042969   BatchTime 0.293549   LR 0.001016   
2022-11-26 05:52:21,530 - INFO  - Training [21][   60/  196]   Loss 2.302654   Top1 10.227865   Top5 49.746094   BatchTime 0.279865   LR 0.000996   
2022-11-26 05:52:26,450 - INFO  - Training [21][   80/  196]   Loss 2.302682   Top1 10.205078   Top5 49.594727   BatchTime 0.271402   LR 0.000976   
2022-11-26 05:52:31,609 - INFO  - Training [21][  100/  196]   Loss 2.302757   Top1 10.152344   Top5 49.503906   BatchTime 0.268712   LR 0.000957   
2022-11-26 05:52:36,359 - INFO  - Training [21][  120/  196]   Loss 2.302710   Top1 10.087891   Top5 49.583333   BatchTime 0.263508   LR 0.000937   
2022-11-26 05:52:41,215 - INFO  - Training [21][  140/  196]   Loss 2.302740   Top1 10.013951   Top5 49.528460   BatchTime 0.260550   LR 0.000918   
2022-11-26 05:52:46,239 - INFO  - Training [21][  160/  196]   Loss 2.302731   Top1 9.980469   Top5 49.570312   BatchTime 0.259384   LR 0.000899   
2022-11-26 05:52:51,375 - INFO  - Training [21][  180/  196]   Loss 2.302737   Top1 9.939236   Top5 49.476997   BatchTime 0.259094   LR 0.000879   
2022-11-26 05:52:55,015 - INFO  - ==> Top1: 9.920    Top5: 49.468    Loss: 2.303

2022-11-26 05:52:55,223 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:52:56,122 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:52:58,628 - INFO  - Validation [21][   20/   40]   Loss 2.581823   Top1 10.078125   Top5 50.058594   BatchTime 0.125206   
2022-11-26 05:52:59,734 - INFO  - Validation [21][   40/   40]   Loss 2.585696   Top1 10.000000   Top5 50.000000   BatchTime 0.090265   
2022-11-26 05:53:00,006 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.586

2022-11-26 05:53:00,006 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:53:00,006 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
2022-11-26 05:53:00,006 - INFO  - Scoreboard best 2 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
2022-11-26 05:53:00,007 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
2022-11-26 05:53:05,352 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:53:05,357 - INFO  - >>>>>> Epoch  22
2022-11-26 05:53:05,359 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:53:12,028 - INFO  - Training [22][   20/  196]   Loss 2.302719   Top1 9.863281   Top5 49.921875   BatchTime 0.333317   LR 0.000846   
2022-11-26 05:53:16,860 - INFO  - Training [22][   40/  196]   Loss 2.302845   Top1 9.482422   Top5 49.423828   BatchTime 0.287456   LR 0.000827   
2022-11-26 05:53:21,663 - INFO  - Training [22][   60/  196]   Loss 2.302712   Top1 9.752604   Top5 49.654948   BatchTime 0.271700   LR 0.000808   
2022-11-26 05:53:26,421 - INFO  - Training [22][   80/  196]   Loss 2.302698   Top1 9.750977   Top5 49.648438   BatchTime 0.263244   LR 0.000789   
2022-11-26 05:53:31,090 - INFO  - Training [22][  100/  196]   Loss 2.302674   Top1 9.695312   Top5 49.625000   BatchTime 0.257283   LR 0.000770   
2022-11-26 05:53:35,799 - INFO  - Training [22][  120/  196]   Loss 2.302718   Top1 9.687500   Top5 49.541016   BatchTime 0.253642   LR 0.000752   
2022-11-26 05:53:40,931 - INFO  - Training [22][  140/  196]   Loss 2.302709   Top1 9.681920   Top5 49.581473   BatchTime 0.254070   LR 0.000734   
2022-11-26 05:53:45,926 - INFO  - Training [22][  160/  196]   Loss 2.302723   Top1 9.685059   Top5 49.482422   BatchTime 0.253525   LR 0.000715   
2022-11-26 05:53:50,487 - INFO  - Training [22][  180/  196]   Loss 2.302753   Top1 9.635417   Top5 49.433594   BatchTime 0.250695   LR 0.000697   
2022-11-26 05:53:54,661 - INFO  - ==> Top1: 9.648    Top5: 49.560    Loss: 2.303

2022-11-26 05:53:54,881 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:53:55,972 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:53:58,556 - INFO  - Validation [22][   20/   40]   Loss 2.555123   Top1 10.078125   Top5 50.214844   BatchTime 0.129106   
2022-11-26 05:53:59,583 - INFO  - Validation [22][   40/   40]   Loss 2.558773   Top1 10.000000   Top5 50.000000   BatchTime 0.090234   
2022-11-26 05:53:59,839 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.559

2022-11-26 05:53:59,839 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:53:59,839 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
2022-11-26 05:53:59,840 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
2022-11-26 05:53:59,840 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
2022-11-26 05:54:04,849 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:54:04,853 - INFO  - >>>>>> Epoch  23
2022-11-26 05:54:04,855 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:54:10,752 - INFO  - Training [23][   20/  196]   Loss 2.302740   Top1 9.824219   Top5 49.628906   BatchTime 0.294717   LR 0.000666   
2022-11-26 05:54:15,356 - INFO  - Training [23][   40/  196]   Loss 2.302582   Top1 10.332031   Top5 49.335938   BatchTime 0.262463   LR 0.000648   
2022-11-26 05:54:19,977 - INFO  - Training [23][   60/  196]   Loss 2.302700   Top1 10.162760   Top5 49.414062   BatchTime 0.251990   LR 0.000630   
2022-11-26 05:54:25,024 - INFO  - Training [23][   80/  196]   Loss 2.302595   Top1 10.175781   Top5 49.707031   BatchTime 0.252080   LR 0.000613   
2022-11-26 05:54:29,748 - INFO  - Training [23][  100/  196]   Loss 2.302629   Top1 10.062500   Top5 49.781250   BatchTime 0.248900   LR 0.000596   
2022-11-26 05:54:34,729 - INFO  - Training [23][  120/  196]   Loss 2.302682   Top1 10.061849   Top5 49.746094   BatchTime 0.248930   LR 0.000579   
2022-11-26 05:54:39,703 - INFO  - Training [23][  140/  196]   Loss 2.302668   Top1 10.136719   Top5 49.799107   BatchTime 0.248894   LR 0.000562   
2022-11-26 05:54:44,354 - INFO  - Training [23][  160/  196]   Loss 2.302691   Top1 10.100098   Top5 49.763184   BatchTime 0.246849   LR 0.000545   
2022-11-26 05:54:48,860 - INFO  - Training [23][  180/  196]   Loss 2.302665   Top1 10.041233   Top5 49.991319   BatchTime 0.244453   LR 0.000529   
2022-11-26 05:54:52,650 - INFO  - ==> Top1: 10.044    Top5: 49.964    Loss: 2.303

2022-11-26 05:54:52,876 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:54:54,290 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:54:57,048 - INFO  - Validation [23][   20/   40]   Loss 2.565373   Top1 10.078125   Top5 50.214844   BatchTime 0.137814   
2022-11-26 05:54:58,141 - INFO  - Validation [23][   40/   40]   Loss 2.569258   Top1 10.000000   Top5 50.000000   BatchTime 0.096234   
2022-11-26 05:54:58,406 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.569

2022-11-26 05:54:58,406 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:54:58,407 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
2022-11-26 05:54:58,407 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
2022-11-26 05:54:58,407 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
2022-11-26 05:55:03,690 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:55:03,692 - INFO  - >>>>>> Epoch  24
2022-11-26 05:55:03,694 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:55:09,930 - INFO  - Training [24][   20/  196]   Loss 2.302669   Top1 9.785156   Top5 50.175781   BatchTime 0.311671   LR 0.000500   
2022-11-26 05:55:14,734 - INFO  - Training [24][   40/  196]   Loss 2.302694   Top1 9.677734   Top5 49.960938   BatchTime 0.275919   LR 0.000484   
2022-11-26 05:55:19,525 - INFO  - Training [24][   60/  196]   Loss 2.302774   Top1 9.811198   Top5 49.759115   BatchTime 0.263799   LR 0.000468   
2022-11-26 05:55:24,606 - INFO  - Training [24][   80/  196]   Loss 2.302819   Top1 9.843750   Top5 49.511719   BatchTime 0.261363   LR 0.000453   
2022-11-26 05:55:29,094 - INFO  - Training [24][  100/  196]   Loss 2.302796   Top1 9.792969   Top5 49.605469   BatchTime 0.253970   LR 0.000437   
2022-11-26 05:55:34,162 - INFO  - Training [24][  120/  196]   Loss 2.302777   Top1 9.869792   Top5 49.723307   BatchTime 0.253870   LR 0.000422   
2022-11-26 05:55:39,165 - INFO  - Training [24][  140/  196]   Loss 2.302802   Top1 9.907924   Top5 49.547991   BatchTime 0.253341   LR 0.000407   
2022-11-26 05:55:43,981 - INFO  - Training [24][  160/  196]   Loss 2.302813   Top1 9.907227   Top5 49.548340   BatchTime 0.251774   LR 0.000392   
2022-11-26 05:55:48,624 - INFO  - Training [24][  180/  196]   Loss 2.302794   Top1 9.893663   Top5 49.557292   BatchTime 0.249595   LR 0.000378   
2022-11-26 05:55:52,261 - INFO  - ==> Top1: 9.896    Top5: 49.622    Loss: 2.303

2022-11-26 05:55:52,442 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:55:53,578 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:55:56,293 - INFO  - Validation [24][   20/   40]   Loss 2.516159   Top1 10.078125   Top5 50.214844   BatchTime 0.135622   
2022-11-26 05:55:57,338 - INFO  - Validation [24][   40/   40]   Loss 2.519656   Top1 10.000000   Top5 50.000000   BatchTime 0.093949   
2022-11-26 05:55:57,572 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.520

2022-11-26 05:55:57,573 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:55:57,573 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
2022-11-26 05:55:57,573 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
2022-11-26 05:55:57,574 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
2022-11-26 05:56:03,294 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:56:03,299 - INFO  - >>>>>> Epoch  25
2022-11-26 05:56:03,300 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:56:09,749 - INFO  - Training [25][   20/  196]   Loss 2.302524   Top1 9.707031   Top5 50.214844   BatchTime 0.322278   LR 0.000353   
2022-11-26 05:56:14,511 - INFO  - Training [25][   40/  196]   Loss 2.302565   Top1 10.273438   Top5 50.166016   BatchTime 0.280200   LR 0.000339   
2022-11-26 05:56:19,743 - INFO  - Training [25][   60/  196]   Loss 2.302607   Top1 10.221354   Top5 49.850260   BatchTime 0.273999   LR 0.000325   
2022-11-26 05:56:24,463 - INFO  - Training [25][   80/  196]   Loss 2.302630   Top1 10.156250   Top5 49.536133   BatchTime 0.264500   LR 0.000312   
2022-11-26 05:56:29,309 - INFO  - Training [25][  100/  196]   Loss 2.302603   Top1 10.164062   Top5 49.796875   BatchTime 0.260063   LR 0.000299   
2022-11-26 05:56:34,200 - INFO  - Training [25][  120/  196]   Loss 2.302590   Top1 10.117188   Top5 49.993490   BatchTime 0.257475   LR 0.000286   
2022-11-26 05:56:38,855 - INFO  - Training [25][  140/  196]   Loss 2.302586   Top1 10.114397   Top5 50.122768   BatchTime 0.253940   LR 0.000273   
2022-11-26 05:56:43,515 - INFO  - Training [25][  160/  196]   Loss 2.302613   Top1 10.009766   Top5 50.073242   BatchTime 0.251321   LR 0.000261   
2022-11-26 05:56:48,173 - INFO  - Training [25][  180/  196]   Loss 2.302600   Top1 10.002170   Top5 50.067274   BatchTime 0.249275   LR 0.000248   
2022-11-26 05:56:51,805 - INFO  - ==> Top1: 9.992    Top5: 50.024    Loss: 2.303

2022-11-26 05:56:52,002 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:56:53,157 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:56:55,836 - INFO  - Validation [25][   20/   40]   Loss 2.521958   Top1 10.078125   Top5 50.214844   BatchTime 0.133857   
2022-11-26 05:56:56,885 - INFO  - Validation [25][   40/   40]   Loss 2.525511   Top1 10.000000   Top5 50.000000   BatchTime 0.093173   
2022-11-26 05:56:57,092 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.526

2022-11-26 05:56:57,092 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:56:57,092 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
2022-11-26 05:56:57,092 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
2022-11-26 05:56:57,093 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
2022-11-26 05:57:01,963 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:57:01,968 - INFO  - >>>>>> Epoch  26
2022-11-26 05:57:01,970 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:57:08,256 - INFO  - Training [26][   20/  196]   Loss 2.302720   Top1 9.628906   Top5 50.937500   BatchTime 0.314204   LR 0.000228   
2022-11-26 05:57:13,390 - INFO  - Training [26][   40/  196]   Loss 2.302694   Top1 9.863281   Top5 50.175781   BatchTime 0.285442   LR 0.000216   
2022-11-26 05:57:18,236 - INFO  - Training [26][   60/  196]   Loss 2.302667   Top1 9.902344   Top5 50.188802   BatchTime 0.271057   LR 0.000205   
2022-11-26 05:57:22,991 - INFO  - Training [26][   80/  196]   Loss 2.302700   Top1 9.785156   Top5 50.107422   BatchTime 0.262731   LR 0.000194   
2022-11-26 05:57:27,491 - INFO  - Training [26][  100/  196]   Loss 2.302679   Top1 9.757812   Top5 50.101562   BatchTime 0.255187   LR 0.000183   
2022-11-26 05:57:32,460 - INFO  - Training [26][  120/  196]   Loss 2.302718   Top1 9.781901   Top5 49.983724   BatchTime 0.254065   LR 0.000173   
2022-11-26 05:57:37,231 - INFO  - Training [26][  140/  196]   Loss 2.302719   Top1 9.720982   Top5 49.924665   BatchTime 0.251851   LR 0.000163   
2022-11-26 05:57:41,555 - INFO  - Training [26][  160/  196]   Loss 2.302750   Top1 9.658203   Top5 49.765625   BatchTime 0.247391   LR 0.000153   
2022-11-26 05:57:46,227 - INFO  - Training [26][  180/  196]   Loss 2.302736   Top1 9.717882   Top5 49.774306   BatchTime 0.245858   LR 0.000144   
2022-11-26 05:57:50,361 - INFO  - ==> Top1: 9.788    Top5: 49.678    Loss: 2.303

2022-11-26 05:57:51,014 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:57:52,266 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:57:54,858 - INFO  - Validation [26][   20/   40]   Loss 2.518576   Top1 10.078125   Top5 50.214844   BatchTime 0.129520   
2022-11-26 05:57:55,767 - INFO  - Validation [26][   40/   40]   Loss 2.522061   Top1 10.000000   Top5 50.000000   BatchTime 0.087495   
2022-11-26 05:57:56,014 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.522

2022-11-26 05:57:56,015 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:57:56,015 - INFO  - Scoreboard best 1 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
2022-11-26 05:57:56,015 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
2022-11-26 05:57:56,015 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
2022-11-26 05:58:00,718 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:58:00,723 - INFO  - >>>>>> Epoch  27
2022-11-26 05:58:00,725 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:58:06,675 - INFO  - Training [27][   20/  196]   Loss 2.302455   Top1 9.960938   Top5 49.921875   BatchTime 0.297368   LR 0.000128   
2022-11-26 05:58:11,784 - INFO  - Training [27][   40/  196]   Loss 2.302630   Top1 9.824219   Top5 49.941406   BatchTime 0.276404   LR 0.000119   
2022-11-26 05:58:16,720 - INFO  - Training [27][   60/  196]   Loss 2.302608   Top1 9.934896   Top5 50.273438   BatchTime 0.266542   LR 0.000111   
2022-11-26 05:58:21,902 - INFO  - Training [27][   80/  196]   Loss 2.302638   Top1 9.765625   Top5 50.053711   BatchTime 0.264676   LR 0.000102   
2022-11-26 05:58:26,704 - INFO  - Training [27][  100/  196]   Loss 2.302627   Top1 9.859375   Top5 50.179688   BatchTime 0.259765   LR 0.000095   
2022-11-26 05:58:31,550 - INFO  - Training [27][  120/  196]   Loss 2.302662   Top1 9.824219   Top5 50.192057   BatchTime 0.256854   LR 0.000087   
2022-11-26 05:58:36,200 - INFO  - Training [27][  140/  196]   Loss 2.302684   Top1 9.799107   Top5 50.114397   BatchTime 0.253374   LR 0.000080   
2022-11-26 05:58:41,643 - INFO  - Training [27][  160/  196]   Loss 2.302677   Top1 9.782715   Top5 50.112305   BatchTime 0.255720   LR 0.000073   
2022-11-26 05:58:46,656 - INFO  - Training [27][  180/  196]   Loss 2.302691   Top1 9.822049   Top5 50.000000   BatchTime 0.255156   LR 0.000066   
2022-11-26 05:58:50,868 - INFO  - ==> Top1: 9.830    Top5: 49.964    Loss: 2.303

2022-11-26 05:58:51,122 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:58:52,473 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:58:55,233 - INFO  - Validation [27][   20/   40]   Loss 2.525293   Top1 10.078125   Top5 50.214844   BatchTime 0.137795   
2022-11-26 05:58:56,300 - INFO  - Validation [27][   40/   40]   Loss 2.528959   Top1 10.000000   Top5 50.000000   BatchTime 0.095618   
2022-11-26 05:58:56,527 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.529

2022-11-26 05:58:56,527 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:58:56,528 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
2022-11-26 05:58:56,528 - INFO  - Scoreboard best 2 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
2022-11-26 05:58:56,528 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
2022-11-26 05:59:01,619 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 05:59:01,621 - INFO  - >>>>>> Epoch  28
2022-11-26 05:59:01,623 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 05:59:08,515 - INFO  - Training [28][   20/  196]   Loss 2.302523   Top1 10.351562   Top5 50.703125   BatchTime 0.344536   LR 0.000055   
2022-11-26 05:59:13,233 - INFO  - Training [28][   40/  196]   Loss 2.302643   Top1 10.195312   Top5 50.146484   BatchTime 0.290214   LR 0.000050   
2022-11-26 05:59:18,223 - INFO  - Training [28][   60/  196]   Loss 2.302640   Top1 9.947917   Top5 50.013021   BatchTime 0.276639   LR 0.000044   
2022-11-26 05:59:23,253 - INFO  - Training [28][   80/  196]   Loss 2.302626   Top1 10.039062   Top5 49.902344   BatchTime 0.270355   LR 0.000039   
2022-11-26 05:59:27,981 - INFO  - Training [28][  100/  196]   Loss 2.302630   Top1 10.046875   Top5 49.792969   BatchTime 0.263557   LR 0.000034   
2022-11-26 05:59:33,148 - INFO  - Training [28][  120/  196]   Loss 2.302608   Top1 10.185547   Top5 49.768880   BatchTime 0.262688   LR 0.000030   
2022-11-26 05:59:37,969 - INFO  - Training [28][  140/  196]   Loss 2.302610   Top1 10.175781   Top5 49.804688   BatchTime 0.259598   LR 0.000026   
2022-11-26 05:59:43,165 - INFO  - Training [28][  160/  196]   Loss 2.302634   Top1 10.192871   Top5 49.763184   BatchTime 0.259626   LR 0.000022   
2022-11-26 05:59:48,201 - INFO  - Training [28][  180/  196]   Loss 2.302643   Top1 10.125868   Top5 49.754774   BatchTime 0.258753   LR 0.000018   
2022-11-26 05:59:52,249 - INFO  - ==> Top1: 10.108    Top5: 49.798    Loss: 2.303

2022-11-26 05:59:52,438 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 05:59:53,505 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 05:59:56,117 - INFO  - Validation [28][   20/   40]   Loss 2.516543   Top1 10.078125   Top5 50.214844   BatchTime 0.130507   
2022-11-26 05:59:57,084 - INFO  - Validation [28][   40/   40]   Loss 2.520139   Top1 10.000000   Top5 50.000000   BatchTime 0.089439   
2022-11-26 05:59:57,355 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.520

2022-11-26 05:59:57,355 - INFO  - ==> Sparsity : 0.520

2022-11-26 05:59:57,356 - INFO  - Scoreboard best 1 ==> Epoch [28][Top1: 10.000   Top5: 50.000]
2022-11-26 05:59:57,356 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
2022-11-26 05:59:57,356 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
2022-11-26 06:00:01,986 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:00:01,989 - INFO  - >>>>>> Epoch  29
2022-11-26 06:00:01,990 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:00:08,803 - INFO  - Training [29][   20/  196]   Loss 2.302537   Top1 10.371094   Top5 50.546875   BatchTime 0.340528   LR 0.000013   
2022-11-26 06:00:13,663 - INFO  - Training [29][   40/  196]   Loss 2.302624   Top1 10.078125   Top5 50.166016   BatchTime 0.291758   LR 0.000010   
2022-11-26 06:00:18,311 - INFO  - Training [29][   60/  196]   Loss 2.302532   Top1 10.039062   Top5 50.364583   BatchTime 0.271963   LR 0.000008   
2022-11-26 06:00:23,353 - INFO  - Training [29][   80/  196]   Loss 2.302515   Top1 10.097656   Top5 50.297852   BatchTime 0.266997   LR 0.000005   
2022-11-26 06:00:28,041 - INFO  - Training [29][  100/  196]   Loss 2.302559   Top1 10.089844   Top5 50.097656   BatchTime 0.260476   LR 0.000004   
2022-11-26 06:00:32,500 - INFO  - Training [29][  120/  196]   Loss 2.302548   Top1 10.247396   Top5 50.221354   BatchTime 0.254227   LR 0.000002   
2022-11-26 06:00:37,409 - INFO  - Training [29][  140/  196]   Loss 2.302572   Top1 10.228795   Top5 50.186942   BatchTime 0.252967   LR 0.000001   
2022-11-26 06:00:42,203 - INFO  - Training [29][  160/  196]   Loss 2.302559   Top1 10.195312   Top5 50.402832   BatchTime 0.251313   LR 0.000001   
2022-11-26 06:00:47,202 - INFO  - Training [29][  180/  196]   Loss 2.302572   Top1 10.236545   Top5 50.347222   BatchTime 0.251162   LR 0.000000   
2022-11-26 06:00:51,375 - INFO  - ==> Top1: 10.238    Top5: 50.438    Loss: 2.303

2022-11-26 06:00:51,695 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:00:53,101 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:00:55,831 - INFO  - Validation [29][   20/   40]   Loss 2.544763   Top1 10.078125   Top5 50.214844   BatchTime 0.136388   
2022-11-26 06:00:56,758 - INFO  - Validation [29][   40/   40]   Loss 2.548569   Top1 10.000000   Top5 50.000000   BatchTime 0.091393   
2022-11-26 06:00:57,040 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.549

2022-11-26 06:00:57,040 - INFO  - ==> Sparsity : 0.520

2022-11-26 06:00:57,040 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 10.000   Top5: 50.000]
2022-11-26 06:00:57,040 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 10.000   Top5: 50.000]
2022-11-26 06:00:57,040 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
2022-11-26 06:01:02,083 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:01:02,085 - INFO  - >>>>>> Epoch  30
2022-11-26 06:01:02,087 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:01:08,654 - INFO  - Training [30][   20/  196]   Loss 2.302642   Top1 10.761719   Top5 50.292969   BatchTime 0.328254   LR 0.001250   
2022-11-26 06:01:13,713 - INFO  - Training [30][   40/  196]   Loss 2.302748   Top1 10.107422   Top5 49.677734   BatchTime 0.290601   LR 0.001250   
2022-11-26 06:01:18,884 - INFO  - Training [30][   60/  196]   Loss 2.302747   Top1 10.117188   Top5 49.778646   BatchTime 0.279916   LR 0.001250   
2022-11-26 06:01:23,876 - INFO  - Training [30][   80/  196]   Loss 2.302883   Top1 10.009766   Top5 49.511719   BatchTime 0.272335   LR 0.001250   
2022-11-26 06:01:28,736 - INFO  - Training [30][  100/  196]   Loss 2.302816   Top1 9.964844   Top5 49.679688   BatchTime 0.266460   LR 0.001250   
2022-11-26 06:01:33,741 - INFO  - Training [30][  120/  196]   Loss 2.302766   Top1 9.977214   Top5 49.833984   BatchTime 0.263767   LR 0.001249   
2022-11-26 06:01:38,525 - INFO  - Training [30][  140/  196]   Loss 2.302784   Top1 9.966518   Top5 49.712612   BatchTime 0.260252   LR 0.001249   
2022-11-26 06:01:43,376 - INFO  - Training [30][  160/  196]   Loss 2.302803   Top1 9.921875   Top5 49.614258   BatchTime 0.258041   LR 0.001249   
2022-11-26 06:01:47,825 - INFO  - Training [30][  180/  196]   Loss 2.302840   Top1 9.902344   Top5 49.563802   BatchTime 0.254086   LR 0.001248   
2022-11-26 06:01:51,394 - INFO  - ==> Top1: 9.944    Top5: 49.528    Loss: 2.303

2022-11-26 06:01:51,635 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:01:53,078 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:01:55,761 - INFO  - Validation [30][   20/   40]   Loss 2.483234   Top1 10.078125   Top5 50.214844   BatchTime 0.134048   
2022-11-26 06:01:56,877 - INFO  - Validation [30][   40/   40]   Loss 2.486508   Top1 10.000000   Top5 50.000000   BatchTime 0.094945   
2022-11-26 06:01:57,110 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.487

2022-11-26 06:01:57,111 - INFO  - ==> Sparsity : 0.521

2022-11-26 06:01:57,111 - INFO  - Scoreboard best 1 ==> Epoch [30][Top1: 10.000   Top5: 50.000]
2022-11-26 06:01:57,111 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 10.000   Top5: 50.000]
2022-11-26 06:01:57,111 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 10.000   Top5: 50.000]
2022-11-26 06:02:02,020 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:02:02,025 - INFO  - >>>>>> Epoch  31
2022-11-26 06:02:02,028 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:02:08,415 - INFO  - Training [31][   20/  196]   Loss 2.302760   Top1 9.511719   Top5 49.023438   BatchTime 0.319265   LR 0.001248   
2022-11-26 06:02:12,843 - INFO  - Training [31][   40/  196]   Loss 2.302753   Top1 9.970703   Top5 49.101562   BatchTime 0.270335   LR 0.001247   
2022-11-26 06:02:17,415 - INFO  - Training [31][   60/  196]   Loss 2.302734   Top1 10.058594   Top5 49.622396   BatchTime 0.256412   LR 0.001247   
2022-11-26 06:02:21,780 - INFO  - Training [31][   80/  196]   Loss 2.302730   Top1 9.970703   Top5 49.780273   BatchTime 0.246879   LR 0.001246   
2022-11-26 06:02:26,603 - INFO  - Training [31][  100/  196]   Loss 2.302736   Top1 9.871094   Top5 49.757812   BatchTime 0.245734   LR 0.001246   
2022-11-26 06:02:31,018 - INFO  - Training [31][  120/  196]   Loss 2.302779   Top1 9.794922   Top5 49.628906   BatchTime 0.241564   LR 0.001245   
2022-11-26 06:02:35,668 - INFO  - Training [31][  140/  196]   Loss 2.302757   Top1 9.779576   Top5 49.670759   BatchTime 0.240266   LR 0.001244   
2022-11-26 06:02:40,161 - INFO  - Training [31][  160/  196]   Loss 2.302693   Top1 9.782715   Top5 49.882812   BatchTime 0.238317   LR 0.001244   
2022-11-26 06:02:44,528 - INFO  - Training [31][  180/  196]   Loss 2.302692   Top1 9.848090   Top5 49.924045   BatchTime 0.236100   LR 0.001243   
2022-11-26 06:02:48,126 - INFO  - ==> Top1: 9.836    Top5: 49.754    Loss: 2.303

2022-11-26 06:02:48,338 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:02:49,428 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:02:52,210 - INFO  - Validation [31][   20/   40]   Loss 2.461789   Top1 10.078125   Top5 50.214844   BatchTime 0.139020   
2022-11-26 06:02:53,319 - INFO  - Validation [31][   40/   40]   Loss 2.464751   Top1 10.000000   Top5 50.000000   BatchTime 0.097234   
2022-11-26 06:02:53,583 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.465

2022-11-26 06:02:53,584 - INFO  - ==> Sparsity : 0.521

2022-11-26 06:02:53,584 - INFO  - Scoreboard best 1 ==> Epoch [31][Top1: 10.000   Top5: 50.000]
2022-11-26 06:02:53,584 - INFO  - Scoreboard best 2 ==> Epoch [30][Top1: 10.000   Top5: 50.000]
2022-11-26 06:02:53,585 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 10.000   Top5: 50.000]
2022-11-26 06:02:58,418 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:02:58,420 - INFO  - >>>>>> Epoch  32
2022-11-26 06:02:58,421 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:03:04,558 - INFO  - Training [32][   20/  196]   Loss 2.302965   Top1 9.394531   Top5 50.000000   BatchTime 0.306747   LR 0.001242   
2022-11-26 06:03:08,901 - INFO  - Training [32][   40/  196]   Loss 2.302750   Top1 9.736328   Top5 50.136719   BatchTime 0.261928   LR 0.001241   
2022-11-26 06:03:13,370 - INFO  - Training [32][   60/  196]   Loss 2.302717   Top1 9.746094   Top5 50.136719   BatchTime 0.249106   LR 0.001240   
2022-11-26 06:03:17,821 - INFO  - Training [32][   80/  196]   Loss 2.302733   Top1 9.824219   Top5 50.068359   BatchTime 0.242469   LR 0.001239   
2022-11-26 06:03:22,360 - INFO  - Training [32][  100/  196]   Loss 2.302736   Top1 9.894531   Top5 49.875000   BatchTime 0.239359   LR 0.001238   
2022-11-26 06:03:26,751 - INFO  - Training [32][  120/  196]   Loss 2.302763   Top1 9.915365   Top5 49.830729   BatchTime 0.236056   LR 0.001237   
2022-11-26 06:03:31,138 - INFO  - Training [32][  140/  196]   Loss 2.302772   Top1 9.952567   Top5 49.846540   BatchTime 0.233674   LR 0.001236   
2022-11-26 06:03:35,751 - INFO  - Training [32][  160/  196]   Loss 2.302763   Top1 9.924316   Top5 49.760742   BatchTime 0.233297   LR 0.001235   
2022-11-26 06:03:39,977 - INFO  - Training [32][  180/  196]   Loss 2.302762   Top1 9.954427   Top5 49.815538   BatchTime 0.230852   LR 0.001234   
2022-11-26 06:03:43,565 - INFO  - ==> Top1: 9.970    Top5: 49.750    Loss: 2.303

2022-11-26 06:03:43,748 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:03:44,709 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:03:47,492 - INFO  - Validation [32][   20/   40]   Loss 2.462371   Top1 10.078125   Top5 50.214844   BatchTime 0.139031   
2022-11-26 06:03:48,627 - INFO  - Validation [32][   40/   40]   Loss 2.465374   Top1 10.000000   Top5 50.000000   BatchTime 0.097912   
2022-11-26 06:03:48,915 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.465

2022-11-26 06:03:48,915 - INFO  - ==> Sparsity : 0.521

2022-11-26 06:03:48,915 - INFO  - Scoreboard best 1 ==> Epoch [32][Top1: 10.000   Top5: 50.000]
2022-11-26 06:03:48,916 - INFO  - Scoreboard best 2 ==> Epoch [31][Top1: 10.000   Top5: 50.000]
2022-11-26 06:03:48,916 - INFO  - Scoreboard best 3 ==> Epoch [30][Top1: 10.000   Top5: 50.000]
2022-11-26 06:03:53,793 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:03:53,797 - INFO  - >>>>>> Epoch  33
2022-11-26 06:03:53,799 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:04:00,065 - INFO  - Training [33][   20/  196]   Loss 2.302814   Top1 9.472656   Top5 49.316406   BatchTime 0.313189   LR 0.001232   
2022-11-26 06:04:04,617 - INFO  - Training [33][   40/  196]   Loss 2.302764   Top1 9.794922   Top5 49.716797   BatchTime 0.270371   LR 0.001230   
2022-11-26 06:04:09,226 - INFO  - Training [33][   60/  196]   Loss 2.302776   Top1 9.667969   Top5 49.635417   BatchTime 0.257071   LR 0.001229   
2022-11-26 06:04:13,492 - INFO  - Training [33][   80/  196]   Loss 2.302833   Top1 9.790039   Top5 49.506836   BatchTime 0.246132   LR 0.001228   
2022-11-26 06:04:17,763 - INFO  - Training [33][  100/  196]   Loss 2.302815   Top1 9.902344   Top5 49.382812   BatchTime 0.239615   LR 0.001226   
2022-11-26 06:04:21,909 - INFO  - Training [33][  120/  196]   Loss 2.302841   Top1 9.837240   Top5 49.381510   BatchTime 0.234221   LR 0.001225   
2022-11-26 06:04:26,077 - INFO  - Training [33][  140/  196]   Loss 2.302819   Top1 9.955357   Top5 49.439174   BatchTime 0.230534   LR 0.001224   
2022-11-26 06:04:30,168 - INFO  - Training [33][  160/  196]   Loss 2.302812   Top1 10.004883   Top5 49.541016   BatchTime 0.227287   LR 0.001222   
2022-11-26 06:04:34,240 - INFO  - Training [33][  180/  196]   Loss 2.302809   Top1 9.984809   Top5 49.548611   BatchTime 0.224656   LR 0.001221   
2022-11-26 06:04:37,529 - INFO  - ==> Top1: 9.920    Top5: 49.416    Loss: 2.303

2022-11-26 06:04:37,713 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:04:38,935 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:04:41,617 - INFO  - Validation [33][   20/   40]   Loss 2.460385   Top1 10.078125   Top5 50.058594   BatchTime 0.133984   
2022-11-26 06:04:42,683 - INFO  - Validation [33][   40/   40]   Loss 2.463114   Top1 10.000000   Top5 50.000000   BatchTime 0.093665   
2022-11-26 06:04:42,911 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.463

2022-11-26 06:04:42,912 - INFO  - ==> Sparsity : 0.521

2022-11-26 06:04:42,912 - INFO  - Scoreboard best 1 ==> Epoch [33][Top1: 10.000   Top5: 50.000]
2022-11-26 06:04:42,912 - INFO  - Scoreboard best 2 ==> Epoch [32][Top1: 10.000   Top5: 50.000]
2022-11-26 06:04:42,912 - INFO  - Scoreboard best 3 ==> Epoch [31][Top1: 10.000   Top5: 50.000]
2022-11-26 06:04:47,822 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:04:47,824 - INFO  - >>>>>> Epoch  34
2022-11-26 06:04:47,826 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:04:54,327 - INFO  - Training [34][   20/  196]   Loss 2.302695   Top1 9.589844   Top5 49.570312   BatchTime 0.324945   LR 0.001218   
2022-11-26 06:04:58,928 - INFO  - Training [34][   40/  196]   Loss 2.302720   Top1 9.824219   Top5 49.804688   BatchTime 0.277486   LR 0.001216   
2022-11-26 06:05:03,385 - INFO  - Training [34][   60/  196]   Loss 2.302830   Top1 9.752604   Top5 49.583333   BatchTime 0.259275   LR 0.001215   
2022-11-26 06:05:07,783 - INFO  - Training [34][   80/  196]   Loss 2.302757   Top1 9.970703   Top5 49.829102   BatchTime 0.249433   LR 0.001213   
2022-11-26 06:05:12,338 - INFO  - Training [34][  100/  196]   Loss 2.302760   Top1 9.914062   Top5 49.835938   BatchTime 0.245090   LR 0.001211   
2022-11-26 06:05:16,961 - INFO  - Training [34][  120/  196]   Loss 2.302805   Top1 9.899089   Top5 49.703776   BatchTime 0.242766   LR 0.001209   
2022-11-26 06:05:21,356 - INFO  - Training [34][  140/  196]   Loss 2.302866   Top1 9.807478   Top5 49.522879   BatchTime 0.239479   LR 0.001208   
2022-11-26 06:05:25,869 - INFO  - Training [34][  160/  196]   Loss 2.302851   Top1 9.865723   Top5 49.570312   BatchTime 0.237750   LR 0.001206   
2022-11-26 06:05:30,552 - INFO  - Training [34][  180/  196]   Loss 2.302839   Top1 9.950087   Top5 49.615885   BatchTime 0.237352   LR 0.001204   
2022-11-26 06:05:34,094 - INFO  - ==> Top1: 9.906    Top5: 49.530    Loss: 2.303

2022-11-26 06:05:34,287 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:05:35,179 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:05:38,195 - INFO  - Validation [34][   20/   40]   Loss 2.481671   Top1 10.078125   Top5 50.214844   BatchTime 0.150698   
2022-11-26 06:05:39,259 - INFO  - Validation [34][   40/   40]   Loss 2.484716   Top1 10.000000   Top5 50.000000   BatchTime 0.101969   
2022-11-26 06:05:39,564 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.485

2022-11-26 06:05:39,564 - INFO  - ==> Sparsity : 0.521

2022-11-26 06:05:39,565 - INFO  - Scoreboard best 1 ==> Epoch [34][Top1: 10.000   Top5: 50.000]
2022-11-26 06:05:39,565 - INFO  - Scoreboard best 2 ==> Epoch [33][Top1: 10.000   Top5: 50.000]
2022-11-26 06:05:39,565 - INFO  - Scoreboard best 3 ==> Epoch [32][Top1: 10.000   Top5: 50.000]
2022-11-26 06:05:44,640 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:05:44,643 - INFO  - >>>>>> Epoch  35
2022-11-26 06:05:44,645 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:05:51,193 - INFO  - Training [35][   20/  196]   Loss 2.302712   Top1 10.273438   Top5 50.312500   BatchTime 0.327292   LR 0.001201   
2022-11-26 06:05:55,760 - INFO  - Training [35][   40/  196]   Loss 2.302626   Top1 10.322266   Top5 50.527344   BatchTime 0.277820   LR 0.001199   
2022-11-26 06:05:59,947 - INFO  - Training [35][   60/  196]   Loss 2.302549   Top1 10.403646   Top5 50.462240   BatchTime 0.255003   LR 0.001197   
2022-11-26 06:06:04,377 - INFO  - Training [35][   80/  196]   Loss 2.302611   Top1 10.278320   Top5 50.322266   BatchTime 0.246623   LR 0.001195   
2022-11-26 06:06:08,756 - INFO  - Training [35][  100/  196]   Loss 2.302533   Top1 10.402344   Top5 50.484375   BatchTime 0.241084   LR 0.001192   
2022-11-26 06:06:13,032 - INFO  - Training [35][  120/  196]   Loss 2.302609   Top1 10.263672   Top5 50.263672   BatchTime 0.236539   LR 0.001190   
2022-11-26 06:06:17,612 - INFO  - Training [35][  140/  196]   Loss 2.302690   Top1 10.139509   Top5 50.080915   BatchTime 0.235459   LR 0.001188   
2022-11-26 06:06:22,020 - INFO  - Training [35][  160/  196]   Loss 2.302689   Top1 10.085449   Top5 50.100098   BatchTime 0.233580   LR 0.001186   
2022-11-26 06:06:26,550 - INFO  - Training [35][  180/  196]   Loss 2.302702   Top1 10.071615   Top5 50.054253   BatchTime 0.232789   LR 0.001184   
2022-11-26 06:06:30,071 - INFO  - ==> Top1: 10.018    Top5: 49.896    Loss: 2.303

2022-11-26 06:06:30,285 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:06:31,390 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:06:34,062 - INFO  - Validation [35][   20/   40]   Loss 2.513241   Top1 10.078125   Top5 49.980469   BatchTime 0.133516   
2022-11-26 06:06:35,016 - INFO  - Validation [35][   40/   40]   Loss 2.516366   Top1 10.000000   Top5 50.000000   BatchTime 0.090606   
2022-11-26 06:06:35,220 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.516

2022-11-26 06:06:35,220 - INFO  - ==> Sparsity : 0.521

2022-11-26 06:06:35,221 - INFO  - Scoreboard best 1 ==> Epoch [35][Top1: 10.000   Top5: 50.000]
2022-11-26 06:06:35,221 - INFO  - Scoreboard best 2 ==> Epoch [34][Top1: 10.000   Top5: 50.000]
2022-11-26 06:06:35,221 - INFO  - Scoreboard best 3 ==> Epoch [33][Top1: 10.000   Top5: 50.000]
2022-11-26 06:06:39,786 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:06:39,788 - INFO  - >>>>>> Epoch  36
2022-11-26 06:06:39,790 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:06:46,212 - INFO  - Training [36][   20/  196]   Loss 2.303026   Top1 9.824219   Top5 49.277344   BatchTime 0.320981   LR 0.001180   
2022-11-26 06:06:50,561 - INFO  - Training [36][   40/  196]   Loss 2.302975   Top1 9.697266   Top5 49.316406   BatchTime 0.269238   LR 0.001177   
2022-11-26 06:06:55,058 - INFO  - Training [36][   60/  196]   Loss 2.302885   Top1 9.785156   Top5 49.433594   BatchTime 0.254428   LR 0.001175   
2022-11-26 06:06:59,594 - INFO  - Training [36][   80/  196]   Loss 2.302882   Top1 9.731445   Top5 49.423828   BatchTime 0.247530   LR 0.001173   
2022-11-26 06:07:04,173 - INFO  - Training [36][  100/  196]   Loss 2.302824   Top1 9.828125   Top5 49.730469   BatchTime 0.243812   LR 0.001170   
2022-11-26 06:07:08,698 - INFO  - Training [36][  120/  196]   Loss 2.302864   Top1 9.811198   Top5 49.381510   BatchTime 0.240878   LR 0.001168   
2022-11-26 06:07:13,221 - INFO  - Training [36][  140/  196]   Loss 2.302849   Top1 9.804688   Top5 49.439174   BatchTime 0.238774   LR 0.001165   
2022-11-26 06:07:17,631 - INFO  - Training [36][  160/  196]   Loss 2.302834   Top1 9.782715   Top5 49.423828   BatchTime 0.236491   LR 0.001163   
2022-11-26 06:07:22,597 - INFO  - Training [36][  180/  196]   Loss 2.302839   Top1 9.761285   Top5 49.455295   BatchTime 0.237801   LR 0.001160   
2022-11-26 06:07:26,188 - INFO  - ==> Top1: 9.760    Top5: 49.404    Loss: 2.303

2022-11-26 06:07:26,367 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:07:27,413 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:07:30,189 - INFO  - Validation [36][   20/   40]   Loss 2.486122   Top1 10.078125   Top5 50.214844   BatchTime 0.138691   
2022-11-26 06:07:31,321 - INFO  - Validation [36][   40/   40]   Loss 2.489295   Top1 10.000000   Top5 50.000000   BatchTime 0.097648   
2022-11-26 06:07:31,557 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.489

2022-11-26 06:07:31,557 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:07:31,558 - INFO  - Scoreboard best 1 ==> Epoch [36][Top1: 10.000   Top5: 50.000]
2022-11-26 06:07:31,558 - INFO  - Scoreboard best 2 ==> Epoch [35][Top1: 10.000   Top5: 50.000]
2022-11-26 06:07:31,558 - INFO  - Scoreboard best 3 ==> Epoch [34][Top1: 10.000   Top5: 50.000]
2022-11-26 06:07:36,192 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:07:36,194 - INFO  - >>>>>> Epoch  37
2022-11-26 06:07:36,196 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:07:42,357 - INFO  - Training [37][   20/  196]   Loss 2.302737   Top1 10.546875   Top5 49.609375   BatchTime 0.307914   LR 0.001155   
2022-11-26 06:07:46,841 - INFO  - Training [37][   40/  196]   Loss 2.302844   Top1 9.736328   Top5 49.042969   BatchTime 0.266054   LR 0.001153   
2022-11-26 06:07:51,232 - INFO  - Training [37][   60/  196]   Loss 2.302870   Top1 9.765625   Top5 48.919271   BatchTime 0.250567   LR 0.001150   
2022-11-26 06:07:55,670 - INFO  - Training [37][   80/  196]   Loss 2.302823   Top1 9.897461   Top5 49.213867   BatchTime 0.243396   LR 0.001147   
2022-11-26 06:08:00,340 - INFO  - Training [37][  100/  196]   Loss 2.302828   Top1 9.914062   Top5 49.210938   BatchTime 0.241410   LR 0.001144   
2022-11-26 06:08:04,782 - INFO  - Training [37][  120/  196]   Loss 2.302811   Top1 9.811198   Top5 49.225260   BatchTime 0.238196   LR 0.001142   
2022-11-26 06:08:09,342 - INFO  - Training [37][  140/  196]   Loss 2.302806   Top1 9.860491   Top5 49.363839   BatchTime 0.236739   LR 0.001139   
2022-11-26 06:08:13,903 - INFO  - Training [37][  160/  196]   Loss 2.302771   Top1 9.863281   Top5 49.453125   BatchTime 0.235652   LR 0.001136   
2022-11-26 06:08:18,230 - INFO  - Training [37][  180/  196]   Loss 2.302805   Top1 9.843750   Top5 49.403212   BatchTime 0.233506   LR 0.001133   
2022-11-26 06:08:21,983 - INFO  - ==> Top1: 9.824    Top5: 49.410    Loss: 2.303

2022-11-26 06:08:22,191 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:08:23,181 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:08:26,045 - INFO  - Validation [37][   20/   40]   Loss 2.493626   Top1 10.078125   Top5 50.058594   BatchTime 0.143124   
2022-11-26 06:08:27,161 - INFO  - Validation [37][   40/   40]   Loss 2.496594   Top1 10.000000   Top5 50.000000   BatchTime 0.099453   
2022-11-26 06:08:27,397 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.497

2022-11-26 06:08:27,397 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:08:27,397 - INFO  - Scoreboard best 1 ==> Epoch [37][Top1: 10.000   Top5: 50.000]
2022-11-26 06:08:27,398 - INFO  - Scoreboard best 2 ==> Epoch [36][Top1: 10.000   Top5: 50.000]
2022-11-26 06:08:27,398 - INFO  - Scoreboard best 3 ==> Epoch [35][Top1: 10.000   Top5: 50.000]
2022-11-26 06:08:32,750 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:08:32,751 - INFO  - >>>>>> Epoch  38
2022-11-26 06:08:32,753 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:08:39,358 - INFO  - Training [38][   20/  196]   Loss 2.302648   Top1 10.371094   Top5 49.902344   BatchTime 0.330123   LR 0.001128   
2022-11-26 06:08:43,956 - INFO  - Training [38][   40/  196]   Loss 2.302581   Top1 10.439453   Top5 50.322266   BatchTime 0.280020   LR 0.001125   
2022-11-26 06:08:48,542 - INFO  - Training [38][   60/  196]   Loss 2.302614   Top1 10.312500   Top5 50.455729   BatchTime 0.263107   LR 0.001122   
2022-11-26 06:08:52,981 - INFO  - Training [38][   80/  196]   Loss 2.302650   Top1 10.249023   Top5 50.356445   BatchTime 0.252815   LR 0.001119   
2022-11-26 06:08:57,477 - INFO  - Training [38][  100/  196]   Loss 2.302722   Top1 10.066406   Top5 50.152344   BatchTime 0.247216   LR 0.001116   
2022-11-26 06:09:02,174 - INFO  - Training [38][  120/  196]   Loss 2.302736   Top1 10.042318   Top5 50.113932   BatchTime 0.245154   LR 0.001112   
2022-11-26 06:09:06,721 - INFO  - Training [38][  140/  196]   Loss 2.302735   Top1 10.036272   Top5 50.078125   BatchTime 0.242610   LR 0.001109   
2022-11-26 06:09:11,364 - INFO  - Training [38][  160/  196]   Loss 2.302748   Top1 9.938965   Top5 49.948730   BatchTime 0.241303   LR 0.001106   
2022-11-26 06:09:15,741 - INFO  - Training [38][  180/  196]   Loss 2.302766   Top1 10.045573   Top5 49.780816   BatchTime 0.238807   LR 0.001103   
2022-11-26 06:09:19,504 - INFO  - ==> Top1: 10.000    Top5: 49.798    Loss: 2.303

2022-11-26 06:09:19,710 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:09:20,650 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:09:23,484 - INFO  - Validation [38][   20/   40]   Loss 2.511339   Top1 10.078125   Top5 50.058594   BatchTime 0.141624   
2022-11-26 06:09:24,634 - INFO  - Validation [38][   40/   40]   Loss 2.514624   Top1 10.000000   Top5 50.000000   BatchTime 0.099564   
2022-11-26 06:09:24,923 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.515

2022-11-26 06:09:24,923 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:09:24,923 - INFO  - Scoreboard best 1 ==> Epoch [38][Top1: 10.000   Top5: 50.000]
2022-11-26 06:09:24,924 - INFO  - Scoreboard best 2 ==> Epoch [37][Top1: 10.000   Top5: 50.000]
2022-11-26 06:09:24,924 - INFO  - Scoreboard best 3 ==> Epoch [36][Top1: 10.000   Top5: 50.000]
2022-11-26 06:09:30,122 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:09:30,124 - INFO  - >>>>>> Epoch  39
2022-11-26 06:09:30,126 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:09:36,496 - INFO  - Training [39][   20/  196]   Loss 2.302344   Top1 10.957031   Top5 50.781250   BatchTime 0.318389   LR 0.001097   
2022-11-26 06:09:40,863 - INFO  - Training [39][   40/  196]   Loss 2.302663   Top1 10.371094   Top5 50.136719   BatchTime 0.268366   LR 0.001094   
2022-11-26 06:09:45,437 - INFO  - Training [39][   60/  196]   Loss 2.302741   Top1 10.221354   Top5 49.694010   BatchTime 0.255147   LR 0.001090   
2022-11-26 06:09:49,770 - INFO  - Training [39][   80/  196]   Loss 2.302756   Top1 10.219727   Top5 49.692383   BatchTime 0.245526   LR 0.001087   
2022-11-26 06:09:54,312 - INFO  - Training [39][  100/  196]   Loss 2.302758   Top1 10.207031   Top5 49.714844   BatchTime 0.241836   LR 0.001084   
2022-11-26 06:09:58,598 - INFO  - Training [39][  120/  196]   Loss 2.302767   Top1 10.061849   Top5 49.674479   BatchTime 0.237244   LR 0.001080   
2022-11-26 06:10:02,916 - INFO  - Training [39][  140/  196]   Loss 2.302750   Top1 10.089286   Top5 49.720982   BatchTime 0.234196   LR 0.001077   
2022-11-26 06:10:07,483 - INFO  - Training [39][  160/  196]   Loss 2.302772   Top1 10.026855   Top5 49.567871   BatchTime 0.233464   LR 0.001073   
2022-11-26 06:10:11,748 - INFO  - Training [39][  180/  196]   Loss 2.302795   Top1 9.889323   Top5 49.487847   BatchTime 0.231218   LR 0.001070   
2022-11-26 06:10:15,550 - INFO  - ==> Top1: 9.886    Top5: 49.470    Loss: 2.303

2022-11-26 06:10:15,754 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:10:16,672 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:10:19,481 - INFO  - Validation [39][   20/   40]   Loss 2.469919   Top1 10.078125   Top5 50.058594   BatchTime 0.140365   
2022-11-26 06:10:20,611 - INFO  - Validation [39][   40/   40]   Loss 2.472936   Top1 10.000000   Top5 50.000000   BatchTime 0.098437   
2022-11-26 06:10:20,908 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.473

2022-11-26 06:10:20,909 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:10:20,909 - INFO  - Scoreboard best 1 ==> Epoch [39][Top1: 10.000   Top5: 50.000]
2022-11-26 06:10:20,909 - INFO  - Scoreboard best 2 ==> Epoch [38][Top1: 10.000   Top5: 50.000]
2022-11-26 06:10:20,910 - INFO  - Scoreboard best 3 ==> Epoch [37][Top1: 10.000   Top5: 50.000]
2022-11-26 06:10:25,810 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:10:25,813 - INFO  - >>>>>> Epoch  40
2022-11-26 06:10:25,814 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:10:32,227 - INFO  - Training [40][   20/  196]   Loss 2.302663   Top1 9.531250   Top5 50.058594   BatchTime 0.320517   LR 0.001064   
2022-11-26 06:10:36,886 - INFO  - Training [40][   40/  196]   Loss 2.302689   Top1 9.580078   Top5 49.833984   BatchTime 0.276736   LR 0.001060   
2022-11-26 06:10:41,443 - INFO  - Training [40][   60/  196]   Loss 2.302700   Top1 9.863281   Top5 49.986979   BatchTime 0.260443   LR 0.001056   
2022-11-26 06:10:45,733 - INFO  - Training [40][   80/  196]   Loss 2.302730   Top1 9.873047   Top5 49.721680   BatchTime 0.248959   LR 0.001053   
2022-11-26 06:10:50,239 - INFO  - Training [40][  100/  196]   Loss 2.302749   Top1 9.914062   Top5 49.730469   BatchTime 0.244222   LR 0.001049   
2022-11-26 06:10:54,634 - INFO  - Training [40][  120/  196]   Loss 2.302759   Top1 9.886068   Top5 49.677734   BatchTime 0.240142   LR 0.001045   
2022-11-26 06:10:59,024 - INFO  - Training [40][  140/  196]   Loss 2.302738   Top1 9.910714   Top5 49.617746   BatchTime 0.237193   LR 0.001042   
2022-11-26 06:11:03,674 - INFO  - Training [40][  160/  196]   Loss 2.302736   Top1 9.924316   Top5 49.558105   BatchTime 0.236607   LR 0.001038   
2022-11-26 06:11:08,126 - INFO  - Training [40][  180/  196]   Loss 2.302752   Top1 9.813368   Top5 49.518229   BatchTime 0.235050   LR 0.001034   
2022-11-26 06:11:11,776 - INFO  - ==> Top1: 9.784    Top5: 49.490    Loss: 2.303

2022-11-26 06:11:11,962 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:11:13,349 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:11:16,135 - INFO  - Validation [40][   20/   40]   Loss 2.463646   Top1 10.078125   Top5 50.214844   BatchTime 0.139212   
2022-11-26 06:11:17,172 - INFO  - Validation [40][   40/   40]   Loss 2.466346   Top1 10.000000   Top5 50.000000   BatchTime 0.095540   
2022-11-26 06:11:17,409 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.466

2022-11-26 06:11:17,409 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:11:17,409 - INFO  - Scoreboard best 1 ==> Epoch [40][Top1: 10.000   Top5: 50.000]
2022-11-26 06:11:17,410 - INFO  - Scoreboard best 2 ==> Epoch [39][Top1: 10.000   Top5: 50.000]
2022-11-26 06:11:17,410 - INFO  - Scoreboard best 3 ==> Epoch [38][Top1: 10.000   Top5: 50.000]
2022-11-26 06:11:22,230 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:11:22,233 - INFO  - >>>>>> Epoch  41
2022-11-26 06:11:22,234 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:11:28,664 - INFO  - Training [41][   20/  196]   Loss 2.302615   Top1 9.960938   Top5 50.605469   BatchTime 0.321365   LR 0.001027   
2022-11-26 06:11:33,047 - INFO  - Training [41][   40/  196]   Loss 2.302705   Top1 9.912109   Top5 50.175781   BatchTime 0.270261   LR 0.001023   
2022-11-26 06:11:37,469 - INFO  - Training [41][   60/  196]   Loss 2.302645   Top1 10.143229   Top5 50.572917   BatchTime 0.253875   LR 0.001020   
2022-11-26 06:11:41,979 - INFO  - Training [41][   80/  196]   Loss 2.302692   Top1 9.926758   Top5 50.219727   BatchTime 0.246777   LR 0.001016   
2022-11-26 06:11:46,648 - INFO  - Training [41][  100/  196]   Loss 2.302716   Top1 9.859375   Top5 49.902344   BatchTime 0.244113   LR 0.001012   
2022-11-26 06:11:51,055 - INFO  - Training [41][  120/  196]   Loss 2.302741   Top1 9.895833   Top5 49.710286   BatchTime 0.240148   LR 0.001008   
2022-11-26 06:11:55,760 - INFO  - Training [41][  140/  196]   Loss 2.302767   Top1 9.854911   Top5 49.453125   BatchTime 0.239447   LR 0.001004   
2022-11-26 06:12:00,426 - INFO  - Training [41][  160/  196]   Loss 2.302756   Top1 9.699707   Top5 49.584961   BatchTime 0.238680   LR 0.001000   
2022-11-26 06:12:05,009 - INFO  - Training [41][  180/  196]   Loss 2.302758   Top1 9.698351   Top5 49.592014   BatchTime 0.237622   LR 0.000996   
2022-11-26 06:12:08,794 - INFO  - ==> Top1: 9.686    Top5: 49.534    Loss: 2.303

2022-11-26 06:12:08,999 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:12:10,099 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:12:12,928 - INFO  - Validation [41][   20/   40]   Loss 2.457378   Top1 10.078125   Top5 50.058594   BatchTime 0.141384   
2022-11-26 06:12:14,024 - INFO  - Validation [41][   40/   40]   Loss 2.460233   Top1 10.000000   Top5 50.000000   BatchTime 0.098094   
2022-11-26 06:12:14,268 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.460

2022-11-26 06:12:14,268 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:12:14,268 - INFO  - Scoreboard best 1 ==> Epoch [41][Top1: 10.000   Top5: 50.000]
2022-11-26 06:12:14,269 - INFO  - Scoreboard best 2 ==> Epoch [40][Top1: 10.000   Top5: 50.000]
2022-11-26 06:12:14,269 - INFO  - Scoreboard best 3 ==> Epoch [39][Top1: 10.000   Top5: 50.000]
2022-11-26 06:12:19,288 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:12:19,290 - INFO  - >>>>>> Epoch  42
2022-11-26 06:12:19,292 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:12:25,857 - INFO  - Training [42][   20/  196]   Loss 2.302471   Top1 10.292969   Top5 50.058594   BatchTime 0.328141   LR 0.000988   
2022-11-26 06:12:30,355 - INFO  - Training [42][   40/  196]   Loss 2.302582   Top1 10.068359   Top5 50.126953   BatchTime 0.276539   LR 0.000984   
2022-11-26 06:12:34,773 - INFO  - Training [42][   60/  196]   Loss 2.302657   Top1 9.967448   Top5 49.908854   BatchTime 0.257986   LR 0.000980   
2022-11-26 06:12:39,162 - INFO  - Training [42][   80/  196]   Loss 2.302727   Top1 10.024414   Top5 49.555664   BatchTime 0.248356   LR 0.000976   
2022-11-26 06:12:43,568 - INFO  - Training [42][  100/  196]   Loss 2.302736   Top1 9.906250   Top5 49.539062   BatchTime 0.242742   LR 0.000972   
2022-11-26 06:12:48,252 - INFO  - Training [42][  120/  196]   Loss 2.302715   Top1 9.990234   Top5 49.694010   BatchTime 0.241317   LR 0.000968   
2022-11-26 06:12:52,715 - INFO  - Training [42][  140/  196]   Loss 2.302741   Top1 10.041853   Top5 49.494978   BatchTime 0.238718   LR 0.000964   
2022-11-26 06:12:57,384 - INFO  - Training [42][  160/  196]   Loss 2.302755   Top1 9.916992   Top5 49.516602   BatchTime 0.238058   LR 0.000959   
2022-11-26 06:13:01,732 - INFO  - Training [42][  180/  196]   Loss 2.302763   Top1 9.867622   Top5 49.461806   BatchTime 0.235767   LR 0.000955   
2022-11-26 06:13:05,351 - INFO  - ==> Top1: 9.834    Top5: 49.396    Loss: 2.303

2022-11-26 06:13:05,579 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:13:06,832 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:13:09,699 - INFO  - Validation [42][   20/   40]   Loss 2.457730   Top1 10.078125   Top5 50.058594   BatchTime 0.143262   
2022-11-26 06:13:10,801 - INFO  - Validation [42][   40/   40]   Loss 2.460317   Top1 10.000000   Top5 50.000000   BatchTime 0.099204   
2022-11-26 06:13:11,159 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.460

2022-11-26 06:13:11,159 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:13:11,159 - INFO  - Scoreboard best 1 ==> Epoch [42][Top1: 10.000   Top5: 50.000]
2022-11-26 06:13:11,160 - INFO  - Scoreboard best 2 ==> Epoch [41][Top1: 10.000   Top5: 50.000]
2022-11-26 06:13:11,160 - INFO  - Scoreboard best 3 ==> Epoch [40][Top1: 10.000   Top5: 50.000]
2022-11-26 06:13:16,541 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:13:16,543 - INFO  - >>>>>> Epoch  43
2022-11-26 06:13:16,545 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:13:22,933 - INFO  - Training [43][   20/  196]   Loss 2.302734   Top1 8.769531   Top5 49.707031   BatchTime 0.319295   LR 0.000947   
2022-11-26 06:13:27,690 - INFO  - Training [43][   40/  196]   Loss 2.302773   Top1 9.179688   Top5 50.019531   BatchTime 0.278584   LR 0.000943   
2022-11-26 06:13:32,366 - INFO  - Training [43][   60/  196]   Loss 2.302675   Top1 9.726562   Top5 50.195312   BatchTime 0.263655   LR 0.000939   
2022-11-26 06:13:37,130 - INFO  - Training [43][   80/  196]   Loss 2.302749   Top1 9.794922   Top5 49.951172   BatchTime 0.257291   LR 0.000934   
2022-11-26 06:13:41,784 - INFO  - Training [43][  100/  196]   Loss 2.302793   Top1 9.656250   Top5 49.765625   BatchTime 0.252364   LR 0.000930   
2022-11-26 06:13:46,232 - INFO  - Training [43][  120/  196]   Loss 2.302777   Top1 9.625651   Top5 49.723307   BatchTime 0.247375   LR 0.000926   
2022-11-26 06:13:50,965 - INFO  - Training [43][  140/  196]   Loss 2.302764   Top1 9.665179   Top5 49.693080   BatchTime 0.245840   LR 0.000921   
2022-11-26 06:13:55,608 - INFO  - Training [43][  160/  196]   Loss 2.302779   Top1 9.675293   Top5 49.636230   BatchTime 0.244126   LR 0.000917   
2022-11-26 06:13:59,892 - INFO  - Training [43][  180/  196]   Loss 2.302766   Top1 9.724392   Top5 49.648438   BatchTime 0.240803   LR 0.000912   
2022-11-26 06:14:03,477 - INFO  - ==> Top1: 9.788    Top5: 49.638    Loss: 2.303

2022-11-26 06:14:03,709 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:14:04,734 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:14:07,656 - INFO  - Validation [43][   20/   40]   Loss 2.463955   Top1 10.078125   Top5 50.058594   BatchTime 0.146013   
2022-11-26 06:14:08,767 - INFO  - Validation [43][   40/   40]   Loss 2.466490   Top1 10.000000   Top5 50.000000   BatchTime 0.100782   
2022-11-26 06:14:09,084 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.466

2022-11-26 06:14:09,084 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:14:09,084 - INFO  - Scoreboard best 1 ==> Epoch [43][Top1: 10.000   Top5: 50.000]
2022-11-26 06:14:09,084 - INFO  - Scoreboard best 2 ==> Epoch [42][Top1: 10.000   Top5: 50.000]
2022-11-26 06:14:09,084 - INFO  - Scoreboard best 3 ==> Epoch [41][Top1: 10.000   Top5: 50.000]
2022-11-26 06:14:13,709 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:14:13,711 - INFO  - >>>>>> Epoch  44
2022-11-26 06:14:13,713 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:14:20,168 - INFO  - Training [44][   20/  196]   Loss 2.302799   Top1 9.492188   Top5 49.218750   BatchTime 0.322628   LR 0.000904   
2022-11-26 06:14:24,644 - INFO  - Training [44][   40/  196]   Loss 2.302764   Top1 9.697266   Top5 49.414062   BatchTime 0.273212   LR 0.000900   
2022-11-26 06:14:29,215 - INFO  - Training [44][   60/  196]   Loss 2.302790   Top1 9.648438   Top5 49.427083   BatchTime 0.258323   LR 0.000895   
2022-11-26 06:14:33,645 - INFO  - Training [44][   80/  196]   Loss 2.302782   Top1 9.653320   Top5 49.335938   BatchTime 0.249123   LR 0.000891   
2022-11-26 06:14:38,044 - INFO  - Training [44][  100/  196]   Loss 2.302761   Top1 9.750000   Top5 49.324219   BatchTime 0.243281   LR 0.000886   
2022-11-26 06:14:42,576 - INFO  - Training [44][  120/  196]   Loss 2.302735   Top1 9.889323   Top5 49.410807   BatchTime 0.240505   LR 0.000882   
2022-11-26 06:14:47,243 - INFO  - Training [44][  140/  196]   Loss 2.302736   Top1 9.891183   Top5 49.369420   BatchTime 0.239477   LR 0.000877   
2022-11-26 06:14:51,764 - INFO  - Training [44][  160/  196]   Loss 2.302740   Top1 9.848633   Top5 49.338379   BatchTime 0.237801   LR 0.000873   
2022-11-26 06:14:56,016 - INFO  - Training [44][  180/  196]   Loss 2.302736   Top1 9.848090   Top5 49.279514   BatchTime 0.235002   LR 0.000868   
2022-11-26 06:14:59,802 - INFO  - ==> Top1: 9.852    Top5: 49.276    Loss: 2.303

2022-11-26 06:14:59,998 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:15:01,349 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:15:04,294 - INFO  - Validation [44][   20/   40]   Loss 2.460708   Top1 10.078125   Top5 50.214844   BatchTime 0.147123   
2022-11-26 06:15:05,401 - INFO  - Validation [44][   40/   40]   Loss 2.463680   Top1 10.000000   Top5 50.000000   BatchTime 0.101272   
2022-11-26 06:15:05,715 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.464

2022-11-26 06:15:05,716 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:15:05,716 - INFO  - Scoreboard best 1 ==> Epoch [44][Top1: 10.000   Top5: 50.000]
2022-11-26 06:15:05,716 - INFO  - Scoreboard best 2 ==> Epoch [43][Top1: 10.000   Top5: 50.000]
2022-11-26 06:15:05,716 - INFO  - Scoreboard best 3 ==> Epoch [42][Top1: 10.000   Top5: 50.000]
2022-11-26 06:15:10,922 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:15:10,925 - INFO  - >>>>>> Epoch  45
2022-11-26 06:15:10,927 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:15:17,115 - INFO  - Training [45][   20/  196]   Loss 2.302752   Top1 10.644531   Top5 48.730469   BatchTime 0.309257   LR 0.000860   
2022-11-26 06:15:21,454 - INFO  - Training [45][   40/  196]   Loss 2.302665   Top1 10.195312   Top5 49.619141   BatchTime 0.263123   LR 0.000855   
2022-11-26 06:15:26,294 - INFO  - Training [45][   60/  196]   Loss 2.302679   Top1 10.104167   Top5 49.361979   BatchTime 0.256065   LR 0.000850   
2022-11-26 06:15:30,659 - INFO  - Training [45][   80/  196]   Loss 2.302684   Top1 10.009766   Top5 49.506836   BatchTime 0.246614   LR 0.000846   
2022-11-26 06:15:35,275 - INFO  - Training [45][  100/  196]   Loss 2.302718   Top1 9.894531   Top5 49.609375   BatchTime 0.243457   LR 0.000841   
2022-11-26 06:15:39,887 - INFO  - Training [45][  120/  196]   Loss 2.302687   Top1 9.925130   Top5 49.723307   BatchTime 0.241311   LR 0.000836   
2022-11-26 06:15:44,349 - INFO  - Training [45][  140/  196]   Loss 2.302695   Top1 9.983259   Top5 49.746094   BatchTime 0.238711   LR 0.000832   
2022-11-26 06:15:48,959 - INFO  - Training [45][  160/  196]   Loss 2.302688   Top1 9.916992   Top5 49.758301   BatchTime 0.237680   LR 0.000827   
2022-11-26 06:15:53,338 - INFO  - Training [45][  180/  196]   Loss 2.302706   Top1 9.841580   Top5 49.654948   BatchTime 0.235601   LR 0.000822   
2022-11-26 06:15:56,902 - INFO  - ==> Top1: 9.838    Top5: 49.500    Loss: 2.303

2022-11-26 06:15:57,127 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:15:58,279 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:16:01,236 - INFO  - Validation [45][   20/   40]   Loss 2.437522   Top1 10.078125   Top5 50.058594   BatchTime 0.147789   
2022-11-26 06:16:02,324 - INFO  - Validation [45][   40/   40]   Loss 2.440034   Top1 10.000000   Top5 50.000000   BatchTime 0.101080   
2022-11-26 06:16:02,569 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.440

2022-11-26 06:16:02,569 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:16:02,569 - INFO  - Scoreboard best 1 ==> Epoch [45][Top1: 10.000   Top5: 50.000]
2022-11-26 06:16:02,570 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 10.000   Top5: 50.000]
2022-11-26 06:16:02,570 - INFO  - Scoreboard best 3 ==> Epoch [43][Top1: 10.000   Top5: 50.000]
2022-11-26 06:16:07,694 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:16:07,697 - INFO  - >>>>>> Epoch  46
2022-11-26 06:16:07,699 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:16:14,031 - INFO  - Training [46][   20/  196]   Loss 2.302640   Top1 9.960938   Top5 49.941406   BatchTime 0.316492   LR 0.000814   
2022-11-26 06:16:18,472 - INFO  - Training [46][   40/  196]   Loss 2.302525   Top1 10.302734   Top5 50.556641   BatchTime 0.269283   LR 0.000809   
2022-11-26 06:16:23,082 - INFO  - Training [46][   60/  196]   Loss 2.302607   Top1 10.234375   Top5 49.869792   BatchTime 0.256349   LR 0.000804   
2022-11-26 06:16:27,462 - INFO  - Training [46][   80/  196]   Loss 2.302636   Top1 10.078125   Top5 50.004883   BatchTime 0.247021   LR 0.000799   
2022-11-26 06:16:32,014 - INFO  - Training [46][  100/  196]   Loss 2.302676   Top1 9.976562   Top5 49.636719   BatchTime 0.243136   LR 0.000794   
2022-11-26 06:16:36,605 - INFO  - Training [46][  120/  196]   Loss 2.302666   Top1 9.986979   Top5 49.739583   BatchTime 0.240863   LR 0.000789   
2022-11-26 06:16:40,987 - INFO  - Training [46][  140/  196]   Loss 2.302679   Top1 9.969308   Top5 49.740513   BatchTime 0.237755   LR 0.000785   
2022-11-26 06:16:45,394 - INFO  - Training [46][  160/  196]   Loss 2.302680   Top1 9.992676   Top5 49.694824   BatchTime 0.235579   LR 0.000780   
2022-11-26 06:16:49,716 - INFO  - Training [46][  180/  196]   Loss 2.302690   Top1 9.939236   Top5 49.585503   BatchTime 0.233415   LR 0.000775   
2022-11-26 06:16:53,469 - INFO  - ==> Top1: 9.930    Top5: 49.480    Loss: 2.303

2022-11-26 06:16:53,683 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:16:54,875 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:16:57,805 - INFO  - Validation [46][   20/   40]   Loss 2.442624   Top1 10.078125   Top5 50.058594   BatchTime 0.146375   
2022-11-26 06:16:58,908 - INFO  - Validation [46][   40/   40]   Loss 2.445348   Top1 10.000000   Top5 50.000000   BatchTime 0.100780   
2022-11-26 06:16:59,156 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.445

2022-11-26 06:16:59,156 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:16:59,157 - INFO  - Scoreboard best 1 ==> Epoch [46][Top1: 10.000   Top5: 50.000]
2022-11-26 06:16:59,157 - INFO  - Scoreboard best 2 ==> Epoch [45][Top1: 10.000   Top5: 50.000]
2022-11-26 06:16:59,157 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 10.000   Top5: 50.000]
2022-11-26 06:17:03,867 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:17:03,869 - INFO  - >>>>>> Epoch  47
2022-11-26 06:17:03,871 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:17:10,443 - INFO  - Training [47][   20/  196]   Loss 2.302633   Top1 9.785156   Top5 51.113281   BatchTime 0.328509   LR 0.000766   
2022-11-26 06:17:14,874 - INFO  - Training [47][   40/  196]   Loss 2.302759   Top1 9.638672   Top5 50.380859   BatchTime 0.275009   LR 0.000761   
2022-11-26 06:17:19,497 - INFO  - Training [47][   60/  196]   Loss 2.302714   Top1 9.635417   Top5 50.319010   BatchTime 0.260396   LR 0.000756   
2022-11-26 06:17:23,926 - INFO  - Training [47][   80/  196]   Loss 2.302728   Top1 9.653320   Top5 49.916992   BatchTime 0.250659   LR 0.000752   
2022-11-26 06:17:28,271 - INFO  - Training [47][  100/  196]   Loss 2.302722   Top1 9.679688   Top5 50.039062   BatchTime 0.243974   LR 0.000747   
2022-11-26 06:17:32,668 - INFO  - Training [47][  120/  196]   Loss 2.302709   Top1 9.684245   Top5 49.957682   BatchTime 0.239950   LR 0.000742   
2022-11-26 06:17:37,246 - INFO  - Training [47][  140/  196]   Loss 2.302706   Top1 9.818638   Top5 49.930246   BatchTime 0.238377   LR 0.000737   
2022-11-26 06:17:41,843 - INFO  - Training [47][  160/  196]   Loss 2.302715   Top1 9.753418   Top5 49.904785   BatchTime 0.237305   LR 0.000732   
2022-11-26 06:17:46,137 - INFO  - Training [47][  180/  196]   Loss 2.302716   Top1 9.776476   Top5 49.898003   BatchTime 0.234795   LR 0.000727   
2022-11-26 06:17:49,687 - INFO  - ==> Top1: 9.784    Top5: 49.810    Loss: 2.303

2022-11-26 06:17:49,915 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:17:51,369 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:17:54,389 - INFO  - Validation [47][   20/   40]   Loss 2.446026   Top1 10.078125   Top5 50.058594   BatchTime 0.150943   
2022-11-26 06:17:55,427 - INFO  - Validation [47][   40/   40]   Loss 2.448734   Top1 10.000000   Top5 50.000000   BatchTime 0.101426   
2022-11-26 06:17:55,773 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.449

2022-11-26 06:17:55,773 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:17:55,773 - INFO  - Scoreboard best 1 ==> Epoch [47][Top1: 10.000   Top5: 50.000]
2022-11-26 06:17:55,773 - INFO  - Scoreboard best 2 ==> Epoch [46][Top1: 10.000   Top5: 50.000]
2022-11-26 06:17:55,773 - INFO  - Scoreboard best 3 ==> Epoch [45][Top1: 10.000   Top5: 50.000]
2022-11-26 06:18:00,639 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:18:00,641 - INFO  - >>>>>> Epoch  48
2022-11-26 06:18:00,643 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:18:07,135 - INFO  - Training [48][   20/  196]   Loss 2.302807   Top1 9.550781   Top5 49.511719   BatchTime 0.324515   LR 0.000718   
2022-11-26 06:18:11,564 - INFO  - Training [48][   40/  196]   Loss 2.302689   Top1 9.892578   Top5 49.912109   BatchTime 0.272973   LR 0.000713   
2022-11-26 06:18:15,871 - INFO  - Training [48][   60/  196]   Loss 2.302646   Top1 10.149740   Top5 49.596354   BatchTime 0.253760   LR 0.000708   
2022-11-26 06:18:20,178 - INFO  - Training [48][   80/  196]   Loss 2.302635   Top1 10.166016   Top5 49.746094   BatchTime 0.244166   LR 0.000703   
2022-11-26 06:18:24,299 - INFO  - Training [48][  100/  196]   Loss 2.302648   Top1 10.089844   Top5 49.707031   BatchTime 0.236538   LR 0.000698   
2022-11-26 06:18:28,620 - INFO  - Training [48][  120/  196]   Loss 2.302707   Top1 10.029297   Top5 49.423828   BatchTime 0.233123   LR 0.000693   
2022-11-26 06:18:32,730 - INFO  - Training [48][  140/  196]   Loss 2.302706   Top1 10.036272   Top5 49.347098   BatchTime 0.229175   LR 0.000688   
2022-11-26 06:18:36,806 - INFO  - Training [48][  160/  196]   Loss 2.302692   Top1 9.995117   Top5 49.401855   BatchTime 0.226007   LR 0.000683   
2022-11-26 06:18:41,025 - INFO  - Training [48][  180/  196]   Loss 2.302701   Top1 10.062934   Top5 49.348958   BatchTime 0.224331   LR 0.000678   
2022-11-26 06:18:44,312 - INFO  - ==> Top1: 10.054    Top5: 49.432    Loss: 2.303

2022-11-26 06:18:44,505 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:18:45,557 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:18:48,558 - INFO  - Validation [48][   20/   40]   Loss 2.418745   Top1 10.078125   Top5 50.058594   BatchTime 0.149955   
2022-11-26 06:18:49,571 - INFO  - Validation [48][   40/   40]   Loss 2.420999   Top1 10.000000   Top5 50.000000   BatchTime 0.100307   
2022-11-26 06:18:49,872 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.421

2022-11-26 06:18:49,873 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:18:49,873 - INFO  - Scoreboard best 1 ==> Epoch [48][Top1: 10.000   Top5: 50.000]
2022-11-26 06:18:49,873 - INFO  - Scoreboard best 2 ==> Epoch [47][Top1: 10.000   Top5: 50.000]
2022-11-26 06:18:49,873 - INFO  - Scoreboard best 3 ==> Epoch [46][Top1: 10.000   Top5: 50.000]
2022-11-26 06:18:55,186 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:18:55,190 - INFO  - >>>>>> Epoch  49
2022-11-26 06:18:55,192 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:19:01,713 - INFO  - Training [49][   20/  196]   Loss 2.302733   Top1 9.687500   Top5 50.195312   BatchTime 0.325926   LR 0.000669   
2022-11-26 06:19:06,749 - INFO  - Training [49][   40/  196]   Loss 2.302718   Top1 9.794922   Top5 50.185547   BatchTime 0.288862   LR 0.000664   
2022-11-26 06:19:11,358 - INFO  - Training [49][   60/  196]   Loss 2.302740   Top1 9.641927   Top5 49.720052   BatchTime 0.269399   LR 0.000659   
2022-11-26 06:19:15,895 - INFO  - Training [49][   80/  196]   Loss 2.302688   Top1 9.555664   Top5 50.048828   BatchTime 0.258751   LR 0.000654   
2022-11-26 06:19:20,408 - INFO  - Training [49][  100/  196]   Loss 2.302702   Top1 9.519531   Top5 49.835938   BatchTime 0.252132   LR 0.000649   
2022-11-26 06:19:24,946 - INFO  - Training [49][  120/  196]   Loss 2.302676   Top1 9.687500   Top5 49.850260   BatchTime 0.247927   LR 0.000644   
2022-11-26 06:19:29,421 - INFO  - Training [49][  140/  196]   Loss 2.302721   Top1 9.740513   Top5 49.804688   BatchTime 0.244474   LR 0.000639   
2022-11-26 06:19:33,932 - INFO  - Training [49][  160/  196]   Loss 2.302719   Top1 9.760742   Top5 49.873047   BatchTime 0.242108   LR 0.000634   
2022-11-26 06:19:38,430 - INFO  - Training [49][  180/  196]   Loss 2.302697   Top1 9.811198   Top5 49.854601   BatchTime 0.240193   LR 0.000629   
2022-11-26 06:19:42,124 - INFO  - ==> Top1: 9.758    Top5: 49.762    Loss: 2.303

2022-11-26 06:19:42,314 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:19:43,426 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:19:46,374 - INFO  - Validation [49][   20/   40]   Loss 2.443406   Top1 10.078125   Top5 50.058594   BatchTime 0.147300   
2022-11-26 06:19:47,492 - INFO  - Validation [49][   40/   40]   Loss 2.446049   Top1 10.000000   Top5 50.000000   BatchTime 0.101620   
2022-11-26 06:19:47,754 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.446

2022-11-26 06:19:47,755 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:19:47,755 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 10.000   Top5: 50.000]
2022-11-26 06:19:47,755 - INFO  - Scoreboard best 2 ==> Epoch [48][Top1: 10.000   Top5: 50.000]
2022-11-26 06:19:47,755 - INFO  - Scoreboard best 3 ==> Epoch [47][Top1: 10.000   Top5: 50.000]
2022-11-26 06:19:52,551 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:19:52,554 - INFO  - >>>>>> Epoch  50
2022-11-26 06:19:52,555 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:19:59,420 - INFO  - Training [50][   20/  196]   Loss 2.302660   Top1 10.429688   Top5 49.746094   BatchTime 0.343116   LR 0.000620   
2022-11-26 06:20:03,923 - INFO  - Training [50][   40/  196]   Loss 2.302671   Top1 10.390625   Top5 49.697266   BatchTime 0.284129   LR 0.000615   
2022-11-26 06:20:08,317 - INFO  - Training [50][   60/  196]   Loss 2.302724   Top1 10.188802   Top5 49.687500   BatchTime 0.262653   LR 0.000610   
2022-11-26 06:20:12,958 - INFO  - Training [50][   80/  196]   Loss 2.302720   Top1 10.083008   Top5 49.682617   BatchTime 0.254997   LR 0.000605   
2022-11-26 06:20:17,350 - INFO  - Training [50][  100/  196]   Loss 2.302682   Top1 9.910156   Top5 49.792969   BatchTime 0.247921   LR 0.000600   
2022-11-26 06:20:22,107 - INFO  - Training [50][  120/  196]   Loss 2.302686   Top1 9.921875   Top5 49.772135   BatchTime 0.246236   LR 0.000595   
2022-11-26 06:20:26,852 - INFO  - Training [50][  140/  196]   Loss 2.302694   Top1 9.827009   Top5 49.642857   BatchTime 0.244955   LR 0.000590   
2022-11-26 06:20:31,477 - INFO  - Training [50][  160/  196]   Loss 2.302685   Top1 9.943848   Top5 49.650879   BatchTime 0.243243   LR 0.000585   
2022-11-26 06:20:35,964 - INFO  - Training [50][  180/  196]   Loss 2.302683   Top1 10.036892   Top5 49.691840   BatchTime 0.241145   LR 0.000580   
2022-11-26 06:20:39,779 - INFO  - ==> Top1: 10.044    Top5: 49.718    Loss: 2.303

2022-11-26 06:20:39,985 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:20:41,436 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:20:44,422 - INFO  - Validation [50][   20/   40]   Loss 2.411294   Top1 10.078125   Top5 50.058594   BatchTime 0.149209   
2022-11-26 06:20:45,484 - INFO  - Validation [50][   40/   40]   Loss 2.413544   Top1 10.000000   Top5 50.000000   BatchTime 0.101150   
2022-11-26 06:20:45,803 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.414

2022-11-26 06:20:45,804 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:20:45,804 - INFO  - Scoreboard best 1 ==> Epoch [50][Top1: 10.000   Top5: 50.000]
2022-11-26 06:20:45,804 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 10.000   Top5: 50.000]
2022-11-26 06:20:45,804 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 10.000   Top5: 50.000]
2022-11-26 06:20:50,758 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:20:50,764 - INFO  - >>>>>> Epoch  51
2022-11-26 06:20:50,766 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:20:57,005 - INFO  - Training [51][   20/  196]   Loss 2.302618   Top1 9.511719   Top5 49.531250   BatchTime 0.311851   LR 0.000571   
2022-11-26 06:21:01,404 - INFO  - Training [51][   40/  196]   Loss 2.302631   Top1 10.019531   Top5 49.716797   BatchTime 0.265902   LR 0.000566   
2022-11-26 06:21:05,598 - INFO  - Training [51][   60/  196]   Loss 2.302562   Top1 10.000000   Top5 50.000000   BatchTime 0.247157   LR 0.000561   
2022-11-26 06:21:09,644 - INFO  - Training [51][   80/  196]   Loss 2.302638   Top1 10.078125   Top5 49.804688   BatchTime 0.235947   LR 0.000556   
2022-11-26 06:21:13,702 - INFO  - Training [51][  100/  196]   Loss 2.302678   Top1 9.968750   Top5 49.492188   BatchTime 0.229335   LR 0.000551   
2022-11-26 06:21:18,012 - INFO  - Training [51][  120/  196]   Loss 2.302687   Top1 10.022786   Top5 49.563802   BatchTime 0.227031   LR 0.000546   
2022-11-26 06:21:22,315 - INFO  - Training [51][  140/  196]   Loss 2.302671   Top1 9.997210   Top5 49.673549   BatchTime 0.225332   LR 0.000541   
2022-11-26 06:21:26,474 - INFO  - Training [51][  160/  196]   Loss 2.302677   Top1 9.916992   Top5 49.675293   BatchTime 0.223162   LR 0.000536   
2022-11-26 06:21:30,684 - INFO  - Training [51][  180/  196]   Loss 2.302669   Top1 9.984809   Top5 49.613715   BatchTime 0.221752   LR 0.000531   
2022-11-26 06:21:34,093 - INFO  - ==> Top1: 10.002    Top5: 49.596    Loss: 2.303

2022-11-26 06:21:34,301 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:21:35,395 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:21:38,464 - INFO  - Validation [51][   20/   40]   Loss 2.461370   Top1 10.078125   Top5 50.058594   BatchTime 0.153337   
2022-11-26 06:21:39,641 - INFO  - Validation [51][   40/   40]   Loss 2.463954   Top1 10.000000   Top5 50.000000   BatchTime 0.106101   
2022-11-26 06:21:39,871 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.464

2022-11-26 06:21:39,872 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:21:39,872 - INFO  - Scoreboard best 1 ==> Epoch [51][Top1: 10.000   Top5: 50.000]
2022-11-26 06:21:39,872 - INFO  - Scoreboard best 2 ==> Epoch [50][Top1: 10.000   Top5: 50.000]
2022-11-26 06:21:39,872 - INFO  - Scoreboard best 3 ==> Epoch [49][Top1: 10.000   Top5: 50.000]
2022-11-26 06:21:44,974 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:21:44,976 - INFO  - >>>>>> Epoch  52
2022-11-26 06:21:44,978 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:21:51,707 - INFO  - Training [52][   20/  196]   Loss 2.302548   Top1 10.800781   Top5 50.820312   BatchTime 0.336357   LR 0.000523   
2022-11-26 06:21:56,444 - INFO  - Training [52][   40/  196]   Loss 2.302616   Top1 10.253906   Top5 50.039062   BatchTime 0.286600   LR 0.000518   
2022-11-26 06:22:01,103 - INFO  - Training [52][   60/  196]   Loss 2.302653   Top1 10.110677   Top5 49.654948   BatchTime 0.268713   LR 0.000513   
2022-11-26 06:22:05,522 - INFO  - Training [52][   80/  196]   Loss 2.302634   Top1 10.249023   Top5 49.741211   BatchTime 0.256777   LR 0.000508   
2022-11-26 06:22:10,016 - INFO  - Training [52][  100/  196]   Loss 2.302650   Top1 10.156250   Top5 49.746094   BatchTime 0.250359   LR 0.000503   
2022-11-26 06:22:14,691 - INFO  - Training [52][  120/  196]   Loss 2.302631   Top1 10.211589   Top5 49.830729   BatchTime 0.247590   LR 0.000498   
2022-11-26 06:22:19,146 - INFO  - Training [52][  140/  196]   Loss 2.302657   Top1 10.111607   Top5 49.687500   BatchTime 0.244043   LR 0.000493   
2022-11-26 06:22:23,624 - INFO  - Training [52][  160/  196]   Loss 2.302656   Top1 10.095215   Top5 49.636230   BatchTime 0.241520   LR 0.000488   
2022-11-26 06:22:27,847 - INFO  - Training [52][  180/  196]   Loss 2.302669   Top1 10.034722   Top5 49.672309   BatchTime 0.238148   LR 0.000483   
2022-11-26 06:22:31,401 - INFO  - ==> Top1: 9.974    Top5: 49.640    Loss: 2.303

2022-11-26 06:22:31,742 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:22:33,117 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:22:36,144 - INFO  - Validation [52][   20/   40]   Loss 2.433830   Top1 10.078125   Top5 50.058594   BatchTime 0.151267   
2022-11-26 06:22:37,211 - INFO  - Validation [52][   40/   40]   Loss 2.436405   Top1 10.000000   Top5 50.000000   BatchTime 0.102301   
2022-11-26 06:22:37,466 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.436

2022-11-26 06:22:37,466 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:22:37,466 - INFO  - Scoreboard best 1 ==> Epoch [52][Top1: 10.000   Top5: 50.000]
2022-11-26 06:22:37,467 - INFO  - Scoreboard best 2 ==> Epoch [51][Top1: 10.000   Top5: 50.000]
2022-11-26 06:22:37,467 - INFO  - Scoreboard best 3 ==> Epoch [50][Top1: 10.000   Top5: 50.000]
2022-11-26 06:22:42,241 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:22:42,245 - INFO  - >>>>>> Epoch  53
2022-11-26 06:22:42,247 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:22:48,955 - INFO  - Training [53][   20/  196]   Loss 2.302659   Top1 9.804688   Top5 50.058594   BatchTime 0.335264   LR 0.000474   
2022-11-26 06:22:53,471 - INFO  - Training [53][   40/  196]   Loss 2.302622   Top1 9.843750   Top5 49.726562   BatchTime 0.280540   LR 0.000470   
2022-11-26 06:22:58,215 - INFO  - Training [53][   60/  196]   Loss 2.302599   Top1 9.804688   Top5 50.000000   BatchTime 0.266096   LR 0.000465   
2022-11-26 06:23:02,833 - INFO  - Training [53][   80/  196]   Loss 2.302649   Top1 9.702148   Top5 49.926758   BatchTime 0.257287   LR 0.000460   
2022-11-26 06:23:07,248 - INFO  - Training [53][  100/  196]   Loss 2.302654   Top1 9.710938   Top5 49.824219   BatchTime 0.249983   LR 0.000455   
2022-11-26 06:23:11,631 - INFO  - Training [53][  120/  196]   Loss 2.302679   Top1 9.710286   Top5 49.759115   BatchTime 0.244840   LR 0.000450   
2022-11-26 06:23:16,347 - INFO  - Training [53][  140/  196]   Loss 2.302701   Top1 9.712612   Top5 49.642857   BatchTime 0.243552   LR 0.000445   
2022-11-26 06:23:20,734 - INFO  - Training [53][  160/  196]   Loss 2.302709   Top1 9.687500   Top5 49.584961   BatchTime 0.240528   LR 0.000441   
2022-11-26 06:23:25,038 - INFO  - Training [53][  180/  196]   Loss 2.302720   Top1 9.615885   Top5 49.483507   BatchTime 0.237708   LR 0.000436   
2022-11-26 06:23:28,605 - INFO  - ==> Top1: 9.624    Top5: 49.438    Loss: 2.303

2022-11-26 06:23:28,845 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:23:29,982 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:23:33,038 - INFO  - Validation [53][   20/   40]   Loss 2.430407   Top1 10.078125   Top5 50.058594   BatchTime 0.152737   
2022-11-26 06:23:34,114 - INFO  - Validation [53][   40/   40]   Loss 2.432766   Top1 10.000000   Top5 50.000000   BatchTime 0.103274   
2022-11-26 06:23:34,431 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.433

2022-11-26 06:23:34,432 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:23:34,432 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 10.000   Top5: 50.000]
2022-11-26 06:23:34,432 - INFO  - Scoreboard best 2 ==> Epoch [52][Top1: 10.000   Top5: 50.000]
2022-11-26 06:23:34,432 - INFO  - Scoreboard best 3 ==> Epoch [51][Top1: 10.000   Top5: 50.000]
2022-11-26 06:23:39,794 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:23:39,797 - INFO  - >>>>>> Epoch  54
2022-11-26 06:23:39,800 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:23:46,393 - INFO  - Training [54][   20/  196]   Loss 2.302429   Top1 10.292969   Top5 50.722656   BatchTime 0.329575   LR 0.000427   
2022-11-26 06:23:50,546 - INFO  - Training [54][   40/  196]   Loss 2.302551   Top1 9.853516   Top5 50.478516   BatchTime 0.268598   LR 0.000423   
2022-11-26 06:23:54,698 - INFO  - Training [54][   60/  196]   Loss 2.302525   Top1 9.954427   Top5 50.625000   BatchTime 0.248268   LR 0.000418   
2022-11-26 06:23:59,100 - INFO  - Training [54][   80/  196]   Loss 2.302560   Top1 9.799805   Top5 50.292969   BatchTime 0.241226   LR 0.000413   
2022-11-26 06:24:03,380 - INFO  - Training [54][  100/  196]   Loss 2.302593   Top1 9.703125   Top5 50.078125   BatchTime 0.235781   LR 0.000408   
2022-11-26 06:24:07,555 - INFO  - Training [54][  120/  196]   Loss 2.302608   Top1 9.713542   Top5 49.879557   BatchTime 0.231277   LR 0.000404   
2022-11-26 06:24:11,630 - INFO  - Training [54][  140/  196]   Loss 2.302634   Top1 9.690290   Top5 49.715402   BatchTime 0.227341   LR 0.000399   
2022-11-26 06:24:15,744 - INFO  - Training [54][  160/  196]   Loss 2.302645   Top1 9.626465   Top5 49.550781   BatchTime 0.224638   LR 0.000394   
2022-11-26 06:24:19,944 - INFO  - Training [54][  180/  196]   Loss 2.302633   Top1 9.659288   Top5 49.672309   BatchTime 0.223010   LR 0.000390   
2022-11-26 06:24:23,518 - INFO  - ==> Top1: 9.662    Top5: 49.594    Loss: 2.303

2022-11-26 06:24:23,742 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:24:24,658 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:24:27,569 - INFO  - Validation [54][   20/   40]   Loss 2.422874   Top1 10.078125   Top5 50.058594   BatchTime 0.145456   
2022-11-26 06:24:28,628 - INFO  - Validation [54][   40/   40]   Loss 2.425112   Top1 10.000000   Top5 50.000000   BatchTime 0.099231   
2022-11-26 06:24:28,940 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.425

2022-11-26 06:24:28,941 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:24:28,941 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 10.000   Top5: 50.000]
2022-11-26 06:24:28,941 - INFO  - Scoreboard best 2 ==> Epoch [53][Top1: 10.000   Top5: 50.000]
2022-11-26 06:24:28,941 - INFO  - Scoreboard best 3 ==> Epoch [52][Top1: 10.000   Top5: 50.000]
2022-11-26 06:24:34,479 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:24:34,482 - INFO  - >>>>>> Epoch  55
2022-11-26 06:24:34,484 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:24:41,180 - INFO  - Training [55][   20/  196]   Loss 2.302531   Top1 10.039062   Top5 49.804688   BatchTime 0.334686   LR 0.000381   
2022-11-26 06:24:45,852 - INFO  - Training [55][   40/  196]   Loss 2.302616   Top1 9.511719   Top5 49.384766   BatchTime 0.284134   LR 0.000377   
2022-11-26 06:24:50,870 - INFO  - Training [55][   60/  196]   Loss 2.302591   Top1 9.869792   Top5 49.654948   BatchTime 0.273061   LR 0.000372   
2022-11-26 06:24:55,185 - INFO  - Training [55][   80/  196]   Loss 2.302567   Top1 9.946289   Top5 49.990234   BatchTime 0.258737   LR 0.000368   
2022-11-26 06:24:59,484 - INFO  - Training [55][  100/  196]   Loss 2.302555   Top1 10.089844   Top5 49.863281   BatchTime 0.249980   LR 0.000363   
2022-11-26 06:25:03,821 - INFO  - Training [55][  120/  196]   Loss 2.302597   Top1 9.980469   Top5 49.680990   BatchTime 0.244457   LR 0.000358   
2022-11-26 06:25:08,300 - INFO  - Training [55][  140/  196]   Loss 2.302621   Top1 10.002790   Top5 49.656808   BatchTime 0.241523   LR 0.000354   
2022-11-26 06:25:12,897 - INFO  - Training [55][  160/  196]   Loss 2.302627   Top1 10.002441   Top5 49.599609   BatchTime 0.240063   LR 0.000349   
2022-11-26 06:25:17,420 - INFO  - Training [55][  180/  196]   Loss 2.302646   Top1 9.956597   Top5 49.498698   BatchTime 0.238520   LR 0.000345   
2022-11-26 06:25:21,021 - INFO  - ==> Top1: 9.932    Top5: 49.392    Loss: 2.303

2022-11-26 06:25:21,214 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:25:22,160 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:25:25,342 - INFO  - Validation [55][   20/   40]   Loss 2.422560   Top1 10.078125   Top5 50.058594   BatchTime 0.158980   
2022-11-26 06:25:26,421 - INFO  - Validation [55][   40/   40]   Loss 2.424949   Top1 10.000000   Top5 50.000000   BatchTime 0.106491   
2022-11-26 06:25:26,724 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.425

2022-11-26 06:25:26,725 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:25:26,725 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 10.000   Top5: 50.000]
2022-11-26 06:25:26,725 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 10.000   Top5: 50.000]
2022-11-26 06:25:26,725 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 10.000   Top5: 50.000]
2022-11-26 06:25:31,854 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:25:31,859 - INFO  - >>>>>> Epoch  56
2022-11-26 06:25:31,861 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:25:38,616 - INFO  - Training [56][   20/  196]   Loss 2.302654   Top1 10.175781   Top5 48.808594   BatchTime 0.337620   LR 0.000337   
2022-11-26 06:25:43,034 - INFO  - Training [56][   40/  196]   Loss 2.302647   Top1 10.107422   Top5 49.707031   BatchTime 0.279256   LR 0.000333   
2022-11-26 06:25:47,358 - INFO  - Training [56][   60/  196]   Loss 2.302663   Top1 9.856771   Top5 49.778646   BatchTime 0.258241   LR 0.000328   
2022-11-26 06:25:51,996 - INFO  - Training [56][   80/  196]   Loss 2.302655   Top1 9.916992   Top5 49.619141   BatchTime 0.251648   LR 0.000324   
2022-11-26 06:25:56,585 - INFO  - Training [56][  100/  196]   Loss 2.302673   Top1 9.726562   Top5 49.554688   BatchTime 0.247214   LR 0.000319   
2022-11-26 06:26:01,215 - INFO  - Training [56][  120/  196]   Loss 2.302679   Top1 9.674479   Top5 49.625651   BatchTime 0.244595   LR 0.000315   
2022-11-26 06:26:05,744 - INFO  - Training [56][  140/  196]   Loss 2.302669   Top1 9.776786   Top5 49.740513   BatchTime 0.241999   LR 0.000311   
2022-11-26 06:26:10,047 - INFO  - Training [56][  160/  196]   Loss 2.302668   Top1 9.919434   Top5 49.675293   BatchTime 0.238647   LR 0.000306   
2022-11-26 06:26:14,418 - INFO  - Training [56][  180/  196]   Loss 2.302668   Top1 9.884983   Top5 49.609375   BatchTime 0.236410   LR 0.000302   
2022-11-26 06:26:18,112 - INFO  - ==> Top1: 9.886    Top5: 49.558    Loss: 2.303

2022-11-26 06:26:18,335 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:26:19,407 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:26:22,481 - INFO  - Validation [56][   20/   40]   Loss 2.424283   Top1 10.078125   Top5 50.058594   BatchTime 0.153651   
2022-11-26 06:26:23,579 - INFO  - Validation [56][   40/   40]   Loss 2.426409   Top1 10.000000   Top5 50.000000   BatchTime 0.104283   
2022-11-26 06:26:23,853 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.426

2022-11-26 06:26:23,853 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:26:23,854 - INFO  - Scoreboard best 1 ==> Epoch [56][Top1: 10.000   Top5: 50.000]
2022-11-26 06:26:23,854 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 10.000   Top5: 50.000]
2022-11-26 06:26:23,854 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 10.000   Top5: 50.000]
2022-11-26 06:26:28,932 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:26:28,934 - INFO  - >>>>>> Epoch  57
2022-11-26 06:26:28,936 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:26:35,497 - INFO  - Training [57][   20/  196]   Loss 2.302694   Top1 9.394531   Top5 49.335938   BatchTime 0.327923   LR 0.000294   
2022-11-26 06:26:40,049 - INFO  - Training [57][   40/  196]   Loss 2.302667   Top1 9.765625   Top5 49.511719   BatchTime 0.277760   LR 0.000290   
2022-11-26 06:26:44,487 - INFO  - Training [57][   60/  196]   Loss 2.302678   Top1 9.843750   Top5 49.270833   BatchTime 0.259148   LR 0.000286   
2022-11-26 06:26:49,121 - INFO  - Training [57][   80/  196]   Loss 2.302630   Top1 9.838867   Top5 49.614258   BatchTime 0.252273   LR 0.000282   
2022-11-26 06:26:53,861 - INFO  - Training [57][  100/  196]   Loss 2.302602   Top1 9.859375   Top5 49.691406   BatchTime 0.249219   LR 0.000277   
2022-11-26 06:26:58,391 - INFO  - Training [57][  120/  196]   Loss 2.302621   Top1 9.869792   Top5 49.557292   BatchTime 0.245434   LR 0.000273   
2022-11-26 06:27:02,978 - INFO  - Training [57][  140/  196]   Loss 2.302649   Top1 9.790737   Top5 49.324777   BatchTime 0.243139   LR 0.000269   
2022-11-26 06:27:07,630 - INFO  - Training [57][  160/  196]   Loss 2.302646   Top1 9.868164   Top5 49.333496   BatchTime 0.241816   LR 0.000265   
2022-11-26 06:27:12,129 - INFO  - Training [57][  180/  196]   Loss 2.302632   Top1 9.906684   Top5 49.470486   BatchTime 0.239946   LR 0.000261   
2022-11-26 06:27:15,822 - INFO  - ==> Top1: 9.846    Top5: 49.374    Loss: 2.303

2022-11-26 06:27:16,029 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:27:17,138 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:27:20,191 - INFO  - Validation [57][   20/   40]   Loss 2.431699   Top1 10.078125   Top5 50.058594   BatchTime 0.152569   
2022-11-26 06:27:21,240 - INFO  - Validation [57][   40/   40]   Loss 2.433909   Top1 10.000000   Top5 50.000000   BatchTime 0.102502   
2022-11-26 06:27:21,576 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.434

2022-11-26 06:27:21,576 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:27:21,576 - INFO  - Scoreboard best 1 ==> Epoch [57][Top1: 10.000   Top5: 50.000]
2022-11-26 06:27:21,576 - INFO  - Scoreboard best 2 ==> Epoch [56][Top1: 10.000   Top5: 50.000]
2022-11-26 06:27:21,576 - INFO  - Scoreboard best 3 ==> Epoch [55][Top1: 10.000   Top5: 50.000]
2022-11-26 06:27:26,157 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:27:26,159 - INFO  - >>>>>> Epoch  58
2022-11-26 06:27:26,161 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:27:33,123 - INFO  - Training [58][   20/  196]   Loss 2.302572   Top1 9.726562   Top5 49.707031   BatchTime 0.347967   LR 0.000254   
2022-11-26 06:27:37,852 - INFO  - Training [58][   40/  196]   Loss 2.302548   Top1 10.312500   Top5 49.960938   BatchTime 0.292223   LR 0.000250   
2022-11-26 06:27:42,597 - INFO  - Training [58][   60/  196]   Loss 2.302596   Top1 10.065104   Top5 49.680990   BatchTime 0.273893   LR 0.000246   
2022-11-26 06:27:47,166 - INFO  - Training [58][   80/  196]   Loss 2.302639   Top1 9.882812   Top5 49.682617   BatchTime 0.262530   LR 0.000242   
2022-11-26 06:27:51,669 - INFO  - Training [58][  100/  196]   Loss 2.302634   Top1 9.867188   Top5 49.703125   BatchTime 0.255057   LR 0.000238   
2022-11-26 06:27:56,163 - INFO  - Training [58][  120/  196]   Loss 2.302650   Top1 9.772135   Top5 49.381510   BatchTime 0.249994   LR 0.000234   
2022-11-26 06:28:00,685 - INFO  - Training [58][  140/  196]   Loss 2.302638   Top1 9.804688   Top5 49.525670   BatchTime 0.246581   LR 0.000230   
2022-11-26 06:28:05,044 - INFO  - Training [58][  160/  196]   Loss 2.302633   Top1 9.736328   Top5 49.572754   BatchTime 0.243000   LR 0.000226   
2022-11-26 06:28:09,616 - INFO  - Training [58][  180/  196]   Loss 2.302640   Top1 9.774306   Top5 49.520399   BatchTime 0.241403   LR 0.000222   
2022-11-26 06:28:13,283 - INFO  - ==> Top1: 9.794    Top5: 49.604    Loss: 2.303

2022-11-26 06:28:13,514 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:28:15,105 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:28:18,265 - INFO  - Validation [58][   20/   40]   Loss 2.432679   Top1 10.078125   Top5 50.058594   BatchTime 0.157901   
2022-11-26 06:28:19,406 - INFO  - Validation [58][   40/   40]   Loss 2.435056   Top1 10.000000   Top5 50.000000   BatchTime 0.107496   
2022-11-26 06:28:19,744 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.435

2022-11-26 06:28:19,744 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:28:19,744 - INFO  - Scoreboard best 1 ==> Epoch [58][Top1: 10.000   Top5: 50.000]
2022-11-26 06:28:19,745 - INFO  - Scoreboard best 2 ==> Epoch [57][Top1: 10.000   Top5: 50.000]
2022-11-26 06:28:19,745 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 10.000   Top5: 50.000]
2022-11-26 06:28:24,658 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:28:24,664 - INFO  - >>>>>> Epoch  59
2022-11-26 06:28:24,666 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:28:31,427 - INFO  - Training [59][   20/  196]   Loss 2.302585   Top1 10.644531   Top5 50.000000   BatchTime 0.337892   LR 0.000215   
2022-11-26 06:28:35,883 - INFO  - Training [59][   40/  196]   Loss 2.302565   Top1 10.244141   Top5 50.625000   BatchTime 0.280357   LR 0.000212   
2022-11-26 06:28:40,488 - INFO  - Training [59][   60/  196]   Loss 2.302597   Top1 10.136719   Top5 50.520833   BatchTime 0.263652   LR 0.000208   
2022-11-26 06:28:44,897 - INFO  - Training [59][   80/  196]   Loss 2.302652   Top1 9.877930   Top5 50.053711   BatchTime 0.252856   LR 0.000204   
2022-11-26 06:28:49,436 - INFO  - Training [59][  100/  196]   Loss 2.302647   Top1 9.828125   Top5 49.996094   BatchTime 0.247670   LR 0.000201   
2022-11-26 06:28:53,818 - INFO  - Training [59][  120/  196]   Loss 2.302653   Top1 9.847005   Top5 49.775391   BatchTime 0.242911   LR 0.000197   
2022-11-26 06:28:58,200 - INFO  - Training [59][  140/  196]   Loss 2.302640   Top1 9.888393   Top5 49.829799   BatchTime 0.239507   LR 0.000193   
2022-11-26 06:29:02,848 - INFO  - Training [59][  160/  196]   Loss 2.302631   Top1 9.946289   Top5 49.792480   BatchTime 0.238617   LR 0.000190   
2022-11-26 06:29:07,485 - INFO  - Training [59][  180/  196]   Loss 2.302654   Top1 9.900174   Top5 49.650608   BatchTime 0.237868   LR 0.000186   
2022-11-26 06:29:11,392 - INFO  - ==> Top1: 9.854    Top5: 49.624    Loss: 2.303

2022-11-26 06:29:11,626 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:29:12,805 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:29:15,900 - INFO  - Validation [59][   20/   40]   Loss 2.435388   Top1 10.078125   Top5 50.058594   BatchTime 0.154631   
2022-11-26 06:29:16,969 - INFO  - Validation [59][   40/   40]   Loss 2.437797   Top1 10.000000   Top5 50.000000   BatchTime 0.104063   
2022-11-26 06:29:17,319 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.438

2022-11-26 06:29:17,319 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:29:17,319 - INFO  - Scoreboard best 1 ==> Epoch [59][Top1: 10.000   Top5: 50.000]
2022-11-26 06:29:17,319 - INFO  - Scoreboard best 2 ==> Epoch [58][Top1: 10.000   Top5: 50.000]
2022-11-26 06:29:17,319 - INFO  - Scoreboard best 3 ==> Epoch [57][Top1: 10.000   Top5: 50.000]
2022-11-26 06:29:22,014 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:29:22,017 - INFO  - >>>>>> Epoch  60
2022-11-26 06:29:22,019 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:29:28,745 - INFO  - Training [60][   20/  196]   Loss 2.302694   Top1 9.980469   Top5 49.062500   BatchTime 0.336181   LR 0.000180   
2022-11-26 06:29:33,294 - INFO  - Training [60][   40/  196]   Loss 2.302664   Top1 10.068359   Top5 49.794922   BatchTime 0.281814   LR 0.000176   
2022-11-26 06:29:37,933 - INFO  - Training [60][   60/  196]   Loss 2.302673   Top1 10.091146   Top5 49.798177   BatchTime 0.265195   LR 0.000173   
2022-11-26 06:29:42,219 - INFO  - Training [60][   80/  196]   Loss 2.302661   Top1 10.092773   Top5 49.975586   BatchTime 0.252469   LR 0.000169   
2022-11-26 06:29:46,742 - INFO  - Training [60][  100/  196]   Loss 2.302641   Top1 10.144531   Top5 50.074219   BatchTime 0.247209   LR 0.000166   
2022-11-26 06:29:51,033 - INFO  - Training [60][  120/  196]   Loss 2.302641   Top1 10.074870   Top5 49.915365   BatchTime 0.241763   LR 0.000162   
2022-11-26 06:29:55,330 - INFO  - Training [60][  140/  196]   Loss 2.302640   Top1 10.022321   Top5 49.796317   BatchTime 0.237919   LR 0.000159   
2022-11-26 06:29:59,623 - INFO  - Training [60][  160/  196]   Loss 2.302651   Top1 9.987793   Top5 49.648438   BatchTime 0.235008   LR 0.000156   
2022-11-26 06:30:04,058 - INFO  - Training [60][  180/  196]   Loss 2.302649   Top1 9.997830   Top5 49.602865   BatchTime 0.233535   LR 0.000152   
2022-11-26 06:30:07,798 - INFO  - ==> Top1: 9.958    Top5: 49.546    Loss: 2.303

2022-11-26 06:30:07,980 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:30:09,501 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:30:12,730 - INFO  - Validation [60][   20/   40]   Loss 2.425404   Top1 10.078125   Top5 50.058594   BatchTime 0.161412   
2022-11-26 06:30:13,814 - INFO  - Validation [60][   40/   40]   Loss 2.427941   Top1 10.000000   Top5 50.000000   BatchTime 0.107794   
2022-11-26 06:30:14,166 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.428

2022-11-26 06:30:14,166 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:30:14,166 - INFO  - Scoreboard best 1 ==> Epoch [60][Top1: 10.000   Top5: 50.000]
2022-11-26 06:30:14,166 - INFO  - Scoreboard best 2 ==> Epoch [59][Top1: 10.000   Top5: 50.000]
2022-11-26 06:30:14,167 - INFO  - Scoreboard best 3 ==> Epoch [58][Top1: 10.000   Top5: 50.000]
2022-11-26 06:30:18,910 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:30:18,913 - INFO  - >>>>>> Epoch  61
2022-11-26 06:30:18,916 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:30:25,840 - INFO  - Training [61][   20/  196]   Loss 2.302581   Top1 10.468750   Top5 49.453125   BatchTime 0.346115   LR 0.000147   
2022-11-26 06:30:30,437 - INFO  - Training [61][   40/  196]   Loss 2.302602   Top1 10.058594   Top5 49.619141   BatchTime 0.287975   LR 0.000143   
2022-11-26 06:30:34,789 - INFO  - Training [61][   60/  196]   Loss 2.302619   Top1 9.902344   Top5 49.589844   BatchTime 0.264512   LR 0.000140   
2022-11-26 06:30:39,415 - INFO  - Training [61][   80/  196]   Loss 2.302614   Top1 9.931641   Top5 49.956055   BatchTime 0.256213   LR 0.000137   
2022-11-26 06:30:44,133 - INFO  - Training [61][  100/  196]   Loss 2.302618   Top1 9.937500   Top5 49.871094   BatchTime 0.252146   LR 0.000134   
2022-11-26 06:30:48,495 - INFO  - Training [61][  120/  196]   Loss 2.302619   Top1 9.951172   Top5 49.882812   BatchTime 0.246475   LR 0.000131   
2022-11-26 06:30:53,033 - INFO  - Training [61][  140/  196]   Loss 2.302621   Top1 10.061384   Top5 50.000000   BatchTime 0.243672   LR 0.000128   
2022-11-26 06:30:57,465 - INFO  - Training [61][  160/  196]   Loss 2.302611   Top1 10.136719   Top5 49.995117   BatchTime 0.240916   LR 0.000125   
2022-11-26 06:31:02,111 - INFO  - Training [61][  180/  196]   Loss 2.302623   Top1 10.043403   Top5 49.986979   BatchTime 0.239961   LR 0.000122   
2022-11-26 06:31:05,854 - INFO  - ==> Top1: 10.080    Top5: 50.028    Loss: 2.303

2022-11-26 06:31:06,049 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:31:07,308 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:31:10,484 - INFO  - Validation [61][   20/   40]   Loss 2.433283   Top1 10.078125   Top5 50.058594   BatchTime 0.158736   
2022-11-26 06:31:11,539 - INFO  - Validation [61][   40/   40]   Loss 2.435719   Top1 10.000000   Top5 50.000000   BatchTime 0.105735   
2022-11-26 06:31:11,881 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.436

2022-11-26 06:31:11,881 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:31:11,882 - INFO  - Scoreboard best 1 ==> Epoch [61][Top1: 10.000   Top5: 50.000]
2022-11-26 06:31:11,882 - INFO  - Scoreboard best 2 ==> Epoch [60][Top1: 10.000   Top5: 50.000]
2022-11-26 06:31:11,882 - INFO  - Scoreboard best 3 ==> Epoch [59][Top1: 10.000   Top5: 50.000]
2022-11-26 06:31:16,865 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:31:16,869 - INFO  - >>>>>> Epoch  62
2022-11-26 06:31:16,871 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:31:23,486 - INFO  - Training [62][   20/  196]   Loss 2.302508   Top1 9.707031   Top5 49.863281   BatchTime 0.330650   LR 0.000117   
2022-11-26 06:31:28,308 - INFO  - Training [62][   40/  196]   Loss 2.302595   Top1 9.658203   Top5 49.599609   BatchTime 0.285872   LR 0.000114   
2022-11-26 06:31:32,937 - INFO  - Training [62][   60/  196]   Loss 2.302646   Top1 9.648438   Top5 49.251302   BatchTime 0.267725   LR 0.000111   
2022-11-26 06:31:37,338 - INFO  - Training [62][   80/  196]   Loss 2.302612   Top1 9.868164   Top5 49.311523   BatchTime 0.255802   LR 0.000108   
2022-11-26 06:31:42,448 - INFO  - Training [62][  100/  196]   Loss 2.302625   Top1 9.808594   Top5 49.281250   BatchTime 0.255741   LR 0.000105   
2022-11-26 06:31:46,888 - INFO  - Training [62][  120/  196]   Loss 2.302618   Top1 9.873047   Top5 49.401042   BatchTime 0.250115   LR 0.000102   
2022-11-26 06:31:51,335 - INFO  - Training [62][  140/  196]   Loss 2.302631   Top1 9.835379   Top5 49.363839   BatchTime 0.246154   LR 0.000100   
2022-11-26 06:31:55,720 - INFO  - Training [62][  160/  196]   Loss 2.302638   Top1 9.846191   Top5 49.355469   BatchTime 0.242787   LR 0.000097   
2022-11-26 06:32:00,144 - INFO  - Training [62][  180/  196]   Loss 2.302644   Top1 9.858941   Top5 49.303385   BatchTime 0.240387   LR 0.000094   
2022-11-26 06:32:03,748 - INFO  - ==> Top1: 9.850    Top5: 49.438    Loss: 2.303

2022-11-26 06:32:03,944 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:32:05,038 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:32:08,178 - INFO  - Validation [62][   20/   40]   Loss 2.427857   Top1 10.078125   Top5 50.058594   BatchTime 0.156937   
2022-11-26 06:32:09,227 - INFO  - Validation [62][   40/   40]   Loss 2.430283   Top1 10.000000   Top5 50.000000   BatchTime 0.104708   
2022-11-26 06:32:09,553 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.430

2022-11-26 06:32:09,554 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:32:09,554 - INFO  - Scoreboard best 1 ==> Epoch [62][Top1: 10.000   Top5: 50.000]
2022-11-26 06:32:09,554 - INFO  - Scoreboard best 2 ==> Epoch [61][Top1: 10.000   Top5: 50.000]
2022-11-26 06:32:09,554 - INFO  - Scoreboard best 3 ==> Epoch [60][Top1: 10.000   Top5: 50.000]
2022-11-26 06:32:14,397 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:32:14,400 - INFO  - >>>>>> Epoch  63
2022-11-26 06:32:14,403 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:32:21,251 - INFO  - Training [63][   20/  196]   Loss 2.302781   Top1 9.628906   Top5 48.847656   BatchTime 0.342264   LR 0.000090   
2022-11-26 06:32:26,150 - INFO  - Training [63][   40/  196]   Loss 2.302660   Top1 10.136719   Top5 49.951172   BatchTime 0.293615   LR 0.000087   
2022-11-26 06:32:30,673 - INFO  - Training [63][   60/  196]   Loss 2.302637   Top1 10.039062   Top5 49.960938   BatchTime 0.271130   LR 0.000085   
2022-11-26 06:32:35,219 - INFO  - Training [63][   80/  196]   Loss 2.302647   Top1 9.926758   Top5 49.780273   BatchTime 0.260168   LR 0.000082   
2022-11-26 06:32:39,870 - INFO  - Training [63][  100/  196]   Loss 2.302622   Top1 10.031250   Top5 49.914062   BatchTime 0.254647   LR 0.000080   
2022-11-26 06:32:44,307 - INFO  - Training [63][  120/  196]   Loss 2.302619   Top1 9.980469   Top5 49.925130   BatchTime 0.249180   LR 0.000077   
2022-11-26 06:32:48,994 - INFO  - Training [63][  140/  196]   Loss 2.302609   Top1 10.033482   Top5 50.139509   BatchTime 0.247060   LR 0.000075   
2022-11-26 06:32:53,665 - INFO  - Training [63][  160/  196]   Loss 2.302606   Top1 10.080566   Top5 50.090332   BatchTime 0.245373   LR 0.000072   
2022-11-26 06:32:57,958 - INFO  - Training [63][  180/  196]   Loss 2.302604   Top1 10.101997   Top5 50.088976   BatchTime 0.241955   LR 0.000070   
2022-11-26 06:33:01,771 - INFO  - ==> Top1: 10.112    Top5: 50.174    Loss: 2.303

2022-11-26 06:33:01,964 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:33:03,116 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:33:06,295 - INFO  - Validation [63][   20/   40]   Loss 2.450969   Top1 10.078125   Top5 50.058594   BatchTime 0.158850   
2022-11-26 06:33:07,380 - INFO  - Validation [63][   40/   40]   Loss 2.453337   Top1 10.000000   Top5 50.000000   BatchTime 0.106542   
2022-11-26 06:33:07,651 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.453

2022-11-26 06:33:07,652 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:33:07,652 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 10.000   Top5: 50.000]
2022-11-26 06:33:07,652 - INFO  - Scoreboard best 2 ==> Epoch [62][Top1: 10.000   Top5: 50.000]
2022-11-26 06:33:07,652 - INFO  - Scoreboard best 3 ==> Epoch [61][Top1: 10.000   Top5: 50.000]
2022-11-26 06:33:12,673 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:33:12,676 - INFO  - >>>>>> Epoch  64
2022-11-26 06:33:12,678 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:33:19,590 - INFO  - Training [64][   20/  196]   Loss 2.302625   Top1 9.726562   Top5 51.230469   BatchTime 0.345497   LR 0.000066   
2022-11-26 06:33:24,094 - INFO  - Training [64][   40/  196]   Loss 2.302618   Top1 9.736328   Top5 50.888672   BatchTime 0.285360   LR 0.000064   
2022-11-26 06:33:28,523 - INFO  - Training [64][   60/  196]   Loss 2.302623   Top1 9.837240   Top5 50.416667   BatchTime 0.264059   LR 0.000062   
2022-11-26 06:33:32,906 - INFO  - Training [64][   80/  196]   Loss 2.302635   Top1 10.019531   Top5 50.190430   BatchTime 0.252829   LR 0.000059   
2022-11-26 06:33:37,093 - INFO  - Training [64][  100/  196]   Loss 2.302678   Top1 9.949219   Top5 49.941406   BatchTime 0.244132   LR 0.000057   
2022-11-26 06:33:41,427 - INFO  - Training [64][  120/  196]   Loss 2.302674   Top1 9.824219   Top5 49.899089   BatchTime 0.239561   LR 0.000055   
2022-11-26 06:33:45,738 - INFO  - Training [64][  140/  196]   Loss 2.302673   Top1 9.843750   Top5 49.773996   BatchTime 0.236125   LR 0.000053   
2022-11-26 06:33:50,154 - INFO  - Training [64][  160/  196]   Loss 2.302669   Top1 9.924316   Top5 49.768066   BatchTime 0.234209   LR 0.000051   
2022-11-26 06:33:54,488 - INFO  - Training [64][  180/  196]   Loss 2.302679   Top1 9.858941   Top5 49.754774   BatchTime 0.232266   LR 0.000049   
2022-11-26 06:33:58,072 - INFO  - ==> Top1: 9.926    Top5: 49.746    Loss: 2.303

2022-11-26 06:33:58,254 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:33:59,193 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:34:02,396 - INFO  - Validation [64][   20/   40]   Loss 2.443854   Top1 10.078125   Top5 50.058594   BatchTime 0.160085   
2022-11-26 06:34:03,391 - INFO  - Validation [64][   40/   40]   Loss 2.446359   Top1 10.000000   Top5 50.000000   BatchTime 0.104909   
2022-11-26 06:34:03,742 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.446

2022-11-26 06:34:03,742 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:34:03,743 - INFO  - Scoreboard best 1 ==> Epoch [64][Top1: 10.000   Top5: 50.000]
2022-11-26 06:34:03,743 - INFO  - Scoreboard best 2 ==> Epoch [63][Top1: 10.000   Top5: 50.000]
2022-11-26 06:34:03,743 - INFO  - Scoreboard best 3 ==> Epoch [62][Top1: 10.000   Top5: 50.000]
2022-11-26 06:34:08,735 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:34:08,738 - INFO  - >>>>>> Epoch  65
2022-11-26 06:34:08,740 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:34:15,268 - INFO  - Training [65][   20/  196]   Loss 2.302605   Top1 9.648438   Top5 48.906250   BatchTime 0.326307   LR 0.000046   
2022-11-26 06:34:19,850 - INFO  - Training [65][   40/  196]   Loss 2.302634   Top1 9.960938   Top5 49.355469   BatchTime 0.277695   LR 0.000044   
2022-11-26 06:34:24,655 - INFO  - Training [65][   60/  196]   Loss 2.302557   Top1 10.253906   Top5 49.947917   BatchTime 0.265222   LR 0.000042   
2022-11-26 06:34:29,259 - INFO  - Training [65][   80/  196]   Loss 2.302531   Top1 10.322266   Top5 50.063477   BatchTime 0.256456   LR 0.000040   
2022-11-26 06:34:33,750 - INFO  - Training [65][  100/  196]   Loss 2.302562   Top1 10.257812   Top5 50.023438   BatchTime 0.250075   LR 0.000039   
2022-11-26 06:34:38,120 - INFO  - Training [65][  120/  196]   Loss 2.302569   Top1 10.081380   Top5 49.957682   BatchTime 0.244812   LR 0.000037   
2022-11-26 06:34:42,500 - INFO  - Training [65][  140/  196]   Loss 2.302552   Top1 10.044643   Top5 50.117188   BatchTime 0.241125   LR 0.000035   
2022-11-26 06:34:46,927 - INFO  - Training [65][  160/  196]   Loss 2.302567   Top1 9.990234   Top5 50.117188   BatchTime 0.238655   LR 0.000033   
2022-11-26 06:34:51,233 - INFO  - Training [65][  180/  196]   Loss 2.302567   Top1 10.075955   Top5 50.056424   BatchTime 0.236057   LR 0.000032   
2022-11-26 06:34:55,038 - INFO  - ==> Top1: 10.130    Top5: 49.964    Loss: 2.303

2022-11-26 06:34:55,219 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:34:56,122 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:34:59,461 - INFO  - Validation [65][   20/   40]   Loss 2.437347   Top1 10.078125   Top5 50.058594   BatchTime 0.166864   
2022-11-26 06:35:00,552 - INFO  - Validation [65][   40/   40]   Loss 2.439583   Top1 10.000000   Top5 50.000000   BatchTime 0.110706   
2022-11-26 06:35:00,824 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.440

2022-11-26 06:35:00,824 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:35:00,825 - INFO  - Scoreboard best 1 ==> Epoch [65][Top1: 10.000   Top5: 50.000]
2022-11-26 06:35:00,825 - INFO  - Scoreboard best 2 ==> Epoch [64][Top1: 10.000   Top5: 50.000]
2022-11-26 06:35:00,825 - INFO  - Scoreboard best 3 ==> Epoch [63][Top1: 10.000   Top5: 50.000]
2022-11-26 06:35:06,331 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:35:06,335 - INFO  - >>>>>> Epoch  66
2022-11-26 06:35:06,337 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:35:12,952 - INFO  - Training [66][   20/  196]   Loss 2.302664   Top1 10.175781   Top5 50.156250   BatchTime 0.330629   LR 0.000029   
2022-11-26 06:35:17,590 - INFO  - Training [66][   40/  196]   Loss 2.302676   Top1 10.000000   Top5 49.853516   BatchTime 0.281273   LR 0.000028   
2022-11-26 06:35:22,450 - INFO  - Training [66][   60/  196]   Loss 2.302687   Top1 9.863281   Top5 49.498698   BatchTime 0.268505   LR 0.000026   
2022-11-26 06:35:27,535 - INFO  - Training [66][   80/  196]   Loss 2.302666   Top1 9.956055   Top5 49.667969   BatchTime 0.264951   LR 0.000025   
2022-11-26 06:35:32,214 - INFO  - Training [66][  100/  196]   Loss 2.302651   Top1 9.898438   Top5 49.875000   BatchTime 0.258747   LR 0.000023   
2022-11-26 06:35:36,827 - INFO  - Training [66][  120/  196]   Loss 2.302646   Top1 9.843750   Top5 49.752604   BatchTime 0.254063   LR 0.000022   
2022-11-26 06:35:41,416 - INFO  - Training [66][  140/  196]   Loss 2.302629   Top1 9.891183   Top5 49.899554   BatchTime 0.250546   LR 0.000021   
2022-11-26 06:35:46,320 - INFO  - Training [66][  160/  196]   Loss 2.302631   Top1 9.916992   Top5 49.782715   BatchTime 0.249879   LR 0.000019   
2022-11-26 06:35:50,608 - INFO  - Training [66][  180/  196]   Loss 2.302626   Top1 9.937066   Top5 49.871962   BatchTime 0.245933   LR 0.000018   
2022-11-26 06:35:54,214 - INFO  - ==> Top1: 9.922    Top5: 49.824    Loss: 2.303

2022-11-26 06:35:54,431 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:35:55,602 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:35:58,824 - INFO  - Validation [66][   20/   40]   Loss 2.428817   Top1 10.078125   Top5 50.058594   BatchTime 0.160987   
2022-11-26 06:35:59,913 - INFO  - Validation [66][   40/   40]   Loss 2.431189   Top1 10.000000   Top5 50.000000   BatchTime 0.107730   
2022-11-26 06:36:00,248 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.431

2022-11-26 06:36:00,248 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:36:00,249 - INFO  - Scoreboard best 1 ==> Epoch [66][Top1: 10.000   Top5: 50.000]
2022-11-26 06:36:00,249 - INFO  - Scoreboard best 2 ==> Epoch [65][Top1: 10.000   Top5: 50.000]
2022-11-26 06:36:00,249 - INFO  - Scoreboard best 3 ==> Epoch [64][Top1: 10.000   Top5: 50.000]
2022-11-26 06:36:05,059 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:36:05,063 - INFO  - >>>>>> Epoch  67
2022-11-26 06:36:05,065 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:36:11,960 - INFO  - Training [67][   20/  196]   Loss 2.302787   Top1 9.531250   Top5 48.398438   BatchTime 0.344657   LR 0.000016   
2022-11-26 06:36:16,244 - INFO  - Training [67][   40/  196]   Loss 2.302700   Top1 9.892578   Top5 48.886719   BatchTime 0.279416   LR 0.000015   
2022-11-26 06:36:20,347 - INFO  - Training [67][   60/  196]   Loss 2.302668   Top1 10.026042   Top5 49.335938   BatchTime 0.254660   LR 0.000014   
2022-11-26 06:36:24,416 - INFO  - Training [67][   80/  196]   Loss 2.302659   Top1 10.112305   Top5 49.643555   BatchTime 0.241856   LR 0.000013   
2022-11-26 06:36:28,742 - INFO  - Training [67][  100/  196]   Loss 2.302642   Top1 10.085938   Top5 49.835938   BatchTime 0.236748   LR 0.000012   
2022-11-26 06:36:32,813 - INFO  - Training [67][  120/  196]   Loss 2.302640   Top1 10.003255   Top5 49.729818   BatchTime 0.231216   LR 0.000011   
2022-11-26 06:36:37,097 - INFO  - Training [67][  140/  196]   Loss 2.302647   Top1 9.949777   Top5 49.827009   BatchTime 0.228781   LR 0.000010   
2022-11-26 06:36:41,376 - INFO  - Training [67][  160/  196]   Loss 2.302632   Top1 10.004883   Top5 49.772949   BatchTime 0.226927   LR 0.000009   
2022-11-26 06:36:45,417 - INFO  - Training [67][  180/  196]   Loss 2.302625   Top1 9.982639   Top5 49.876302   BatchTime 0.224164   LR 0.000008   
2022-11-26 06:36:49,074 - INFO  - ==> Top1: 9.982    Top5: 49.906    Loss: 2.303

2022-11-26 06:36:49,295 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:36:50,347 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:36:53,670 - INFO  - Validation [67][   20/   40]   Loss 2.428981   Top1 10.078125   Top5 50.058594   BatchTime 0.166073   
2022-11-26 06:36:54,814 - INFO  - Validation [67][   40/   40]   Loss 2.431364   Top1 10.000000   Top5 50.000000   BatchTime 0.111655   
2022-11-26 06:36:55,174 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.431

2022-11-26 06:36:55,175 - INFO  - ==> Sparsity : 0.522

2022-11-26 06:36:55,175 - INFO  - Scoreboard best 1 ==> Epoch [67][Top1: 10.000   Top5: 50.000]
2022-11-26 06:36:55,175 - INFO  - Scoreboard best 2 ==> Epoch [66][Top1: 10.000   Top5: 50.000]
2022-11-26 06:36:55,175 - INFO  - Scoreboard best 3 ==> Epoch [65][Top1: 10.000   Top5: 50.000]
2022-11-26 06:37:00,649 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:37:00,651 - INFO  - >>>>>> Epoch  68
2022-11-26 06:37:00,653 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:37:07,683 - INFO  - Training [68][   20/  196]   Loss 2.302630   Top1 10.136719   Top5 49.726562   BatchTime 0.351390   LR 0.000007   
2022-11-26 06:37:12,394 - INFO  - Training [68][   40/  196]   Loss 2.302659   Top1 10.058594   Top5 49.804688   BatchTime 0.293456   LR 0.000006   
2022-11-26 06:37:17,029 - INFO  - Training [68][   60/  196]   Loss 2.302675   Top1 10.123698   Top5 49.804688   BatchTime 0.272885   LR 0.000006   
2022-11-26 06:37:21,608 - INFO  - Training [68][   80/  196]   Loss 2.302660   Top1 9.941406   Top5 49.863281   BatchTime 0.261912   LR 0.000005   
2022-11-26 06:37:26,011 - INFO  - Training [68][  100/  196]   Loss 2.302649   Top1 9.949219   Top5 49.664062   BatchTime 0.253557   LR 0.000004   
2022-11-26 06:37:30,433 - INFO  - Training [68][  120/  196]   Loss 2.302640   Top1 10.035807   Top5 49.619141   BatchTime 0.248147   LR 0.000004   
2022-11-26 06:37:34,827 - INFO  - Training [68][  140/  196]   Loss 2.302631   Top1 10.002790   Top5 49.762835   BatchTime 0.244078   LR 0.000003   
2022-11-26 06:37:39,193 - INFO  - Training [68][  160/  196]   Loss 2.302635   Top1 10.017090   Top5 49.809570   BatchTime 0.240860   LR 0.000003   
2022-11-26 06:37:43,423 - INFO  - Training [68][  180/  196]   Loss 2.302627   Top1 10.004340   Top5 49.748264   BatchTime 0.237593   LR 0.000002   
2022-11-26 06:37:47,046 - INFO  - ==> Top1: 9.978    Top5: 49.672    Loss: 2.303

2022-11-26 06:37:47,252 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:37:48,209 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:37:51,488 - INFO  - Validation [68][   20/   40]   Loss 2.428835   Top1 10.078125   Top5 50.058594   BatchTime 0.163882   
2022-11-26 06:37:52,585 - INFO  - Validation [68][   40/   40]   Loss 2.431027   Top1 10.000000   Top5 50.000000   BatchTime 0.109347   
2022-11-26 06:37:52,949 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.431

2022-11-26 06:37:52,949 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:37:52,950 - INFO  - Scoreboard best 1 ==> Epoch [68][Top1: 10.000   Top5: 50.000]
2022-11-26 06:37:52,950 - INFO  - Scoreboard best 2 ==> Epoch [67][Top1: 10.000   Top5: 50.000]
2022-11-26 06:37:52,950 - INFO  - Scoreboard best 3 ==> Epoch [66][Top1: 10.000   Top5: 50.000]
2022-11-26 06:37:57,845 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:37:57,849 - INFO  - >>>>>> Epoch  69
2022-11-26 06:37:57,850 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-26 06:38:04,316 - INFO  - Training [69][   20/  196]   Loss 2.302630   Top1 9.882812   Top5 49.785156   BatchTime 0.323169   LR 0.000002   
2022-11-26 06:38:08,617 - INFO  - Training [69][   40/  196]   Loss 2.302623   Top1 9.882812   Top5 49.912109   BatchTime 0.269122   LR 0.000001   
2022-11-26 06:38:12,929 - INFO  - Training [69][   60/  196]   Loss 2.302616   Top1 10.000000   Top5 49.986979   BatchTime 0.251271   LR 0.000001   
2022-11-26 06:38:17,011 - INFO  - Training [69][   80/  196]   Loss 2.302596   Top1 10.078125   Top5 50.244141   BatchTime 0.239479   LR 0.000001   
2022-11-26 06:38:21,076 - INFO  - Training [69][  100/  196]   Loss 2.302597   Top1 10.023438   Top5 50.042969   BatchTime 0.232231   LR 0.000000   
2022-11-26 06:38:25,381 - INFO  - Training [69][  120/  196]   Loss 2.302599   Top1 10.019531   Top5 49.889323   BatchTime 0.229401   LR 0.000000   
2022-11-26 06:38:29,670 - INFO  - Training [69][  140/  196]   Loss 2.302586   Top1 10.016741   Top5 50.058594   BatchTime 0.227264   LR 0.000000   
2022-11-26 06:38:33,881 - INFO  - Training [69][  160/  196]   Loss 2.302588   Top1 10.102539   Top5 50.053711   BatchTime 0.225178   LR 0.000000   
2022-11-26 06:38:37,966 - INFO  - Training [69][  180/  196]   Loss 2.302579   Top1 10.052083   Top5 50.097656   BatchTime 0.222853   LR 0.000000   
2022-11-26 06:38:41,698 - INFO  - ==> Top1: 10.006    Top5: 50.034    Loss: 2.303

2022-11-26 06:38:41,916 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-26 06:38:43,007 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:38:46,935 - INFO  - Validation [69][   20/   40]   Loss 2.414381   Top1 10.078125   Top5 50.058594   BatchTime 0.196298   
2022-11-26 06:38:48,047 - INFO  - Validation [69][   40/   40]   Loss 2.416656   Top1 10.000000   Top5 50.000000   BatchTime 0.125959   
2022-11-26 06:38:48,524 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.417

2022-11-26 06:38:48,525 - INFO  - ==> Sparsity : 0.523

2022-11-26 06:38:48,525 - INFO  - Scoreboard best 1 ==> Epoch [69][Top1: 10.000   Top5: 50.000]
2022-11-26 06:38:48,525 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 10.000   Top5: 50.000]
2022-11-26 06:38:48,525 - INFO  - Scoreboard best 3 ==> Epoch [67][Top1: 10.000   Top5: 50.000]
2022-11-26 06:38:53,944 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221126-042522/88hard_pruning_best.pth.tar
save quantized models...
2022-11-26 06:38:53,946 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-26 06:38:53,947 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-26 06:38:57,173 - INFO  - Validation [   20/   40]   Loss 2.414381   Top1 10.078125   Top5 50.058594   BatchTime 0.161236   
2022-11-26 06:38:58,224 - INFO  - Validation [   40/   40]   Loss 2.416656   Top1 10.000000   Top5 50.000000   BatchTime 0.106907   
2022-11-26 06:38:58,438 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.417

2022-11-26 06:38:58,439 - INFO  - ==> Sparsity : 0.000

2022-11-26 06:38:58,439 - INFO  - Program completed sucessfully ... exiting ...
