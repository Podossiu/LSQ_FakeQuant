2022-11-25 10:12:58,429 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88_20221125-101258.log
2022-11-25 10:13:02,462 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-25 10:13:04,256 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-25 10:13:04,928 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
2022-11-25 10:13:04,928 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005

2022-11-25 10:13:05,220 - INFO  - >>>>>> Epoch   0
2022-11-25 10:13:05,221 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:13:14,470 - INFO  - Training [0][   20/  196]   Loss 1.579268   Top1 53.320312   Top5 89.101562   BatchTime 0.462311   LR 0.004999   
2022-11-25 10:13:22,617 - INFO  - Training [0][   40/  196]   Loss 1.494304   Top1 52.597656   Top5 89.667969   BatchTime 0.434832   LR 0.004995   
2022-11-25 10:13:29,753 - INFO  - Training [0][   60/  196]   Loss 1.388046   Top1 55.169271   Top5 90.748698   BatchTime 0.408817   LR 0.004989   
2022-11-25 10:13:36,851 - INFO  - Training [0][   80/  196]   Loss 1.322441   Top1 56.772461   Top5 91.625977   BatchTime 0.395343   LR 0.004980   
2022-11-25 10:13:45,312 - INFO  - Training [0][  100/  196]   Loss 1.262185   Top1 58.429688   Top5 92.265625   BatchTime 0.400880   LR 0.004968   
2022-11-25 10:13:53,568 - INFO  - Training [0][  120/  196]   Loss 1.212714   Top1 59.918620   Top5 92.815755   BatchTime 0.402868   LR 0.004954   
2022-11-25 10:14:01,805 - INFO  - Training [0][  140/  196]   Loss 1.181057   Top1 60.929129   Top5 93.200335   BatchTime 0.404147   LR 0.004938   
2022-11-25 10:14:10,954 - INFO  - Training [0][  160/  196]   Loss 1.159270   Top1 61.601562   Top5 93.386230   BatchTime 0.410809   LR 0.004919   
2022-11-25 10:14:19,641 - INFO  - Training [0][  180/  196]   Loss 1.136386   Top1 62.272135   Top5 93.561198   BatchTime 0.413428   LR 0.004897   
2022-11-25 10:14:26,856 - INFO  - ==> Top1: 62.836    Top5: 93.720    Loss: 1.118

2022-11-25 10:14:27,150 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:14:28,876 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:14:31,000 - INFO  - Validation [0][   20/   40]   Loss 0.892575   Top1 71.582031   Top5 97.343750   BatchTime 0.106148   
2022-11-25 10:14:32,081 - INFO  - Validation [0][   40/   40]   Loss 0.878241   Top1 71.870000   Top5 97.430000   BatchTime 0.080092   
2022-11-25 10:14:32,256 - INFO  - ==> Top1: 71.870    Top5: 97.430    Loss: 0.878

2022-11-25 10:14:32,256 - INFO  - ==> Sparsity : 0.118

2022-11-25 10:14:32,257 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 71.870   Top5: 97.430]
2022-11-25 10:14:37,348 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:14:37,350 - INFO  - >>>>>> Epoch   1
2022-11-25 10:14:37,353 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:14:45,492 - INFO  - Training [1][   20/  196]   Loss 0.937208   Top1 68.652344   Top5 95.468750   BatchTime 0.406841   LR 0.004853   
2022-11-25 10:14:51,698 - INFO  - Training [1][   40/  196]   Loss 0.919020   Top1 69.150391   Top5 95.761719   BatchTime 0.358569   LR 0.004825   
2022-11-25 10:14:59,214 - INFO  - Training [1][   60/  196]   Loss 0.907187   Top1 69.225260   Top5 95.781250   BatchTime 0.364320   LR 0.004794   
2022-11-25 10:15:06,955 - INFO  - Training [1][   80/  196]   Loss 0.898102   Top1 69.677734   Top5 95.917969   BatchTime 0.369999   LR 0.004761   
2022-11-25 10:15:14,155 - INFO  - Training [1][  100/  196]   Loss 0.880755   Top1 70.195312   Top5 96.050781   BatchTime 0.367995   LR 0.004725   
2022-11-25 10:15:21,478 - INFO  - Training [1][  120/  196]   Loss 0.875264   Top1 70.358073   Top5 96.155599   BatchTime 0.367689   LR 0.004687   
2022-11-25 10:15:28,787 - INFO  - Training [1][  140/  196]   Loss 0.866921   Top1 70.597098   Top5 96.255580   BatchTime 0.367371   LR 0.004647   
2022-11-25 10:15:36,481 - INFO  - Training [1][  160/  196]   Loss 0.861160   Top1 70.771484   Top5 96.274414   BatchTime 0.369538   LR 0.004605   
2022-11-25 10:15:43,821 - INFO  - Training [1][  180/  196]   Loss 0.850831   Top1 71.117622   Top5 96.341146   BatchTime 0.369255   LR 0.004560   
2022-11-25 10:15:50,314 - INFO  - ==> Top1: 71.256    Top5: 96.362    Loss: 0.847

2022-11-25 10:15:50,574 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:15:52,111 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:15:54,386 - INFO  - Validation [1][   20/   40]   Loss 0.636989   Top1 79.238281   Top5 97.949219   BatchTime 0.113604   
2022-11-25 10:15:55,507 - INFO  - Validation [1][   40/   40]   Loss 0.624728   Top1 79.540000   Top5 98.200000   BatchTime 0.084830   
2022-11-25 10:15:55,733 - INFO  - ==> Top1: 79.540    Top5: 98.200    Loss: 0.625

2022-11-25 10:15:55,733 - INFO  - ==> Sparsity : 0.141

2022-11-25 10:15:55,733 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 79.540   Top5: 98.200]
2022-11-25 10:15:55,733 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 71.870   Top5: 97.430]
2022-11-25 10:16:01,148 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:16:01,151 - INFO  - >>>>>> Epoch   2
2022-11-25 10:16:01,153 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:16:08,868 - INFO  - Training [2][   20/  196]   Loss 0.823446   Top1 71.660156   Top5 95.937500   BatchTime 0.385613   LR 0.004477   
2022-11-25 10:16:16,476 - INFO  - Training [2][   40/  196]   Loss 0.807194   Top1 72.578125   Top5 96.162109   BatchTime 0.383011   LR 0.004426   
2022-11-25 10:16:23,730 - INFO  - Training [2][   60/  196]   Loss 0.796474   Top1 72.845052   Top5 96.315104   BatchTime 0.376248   LR 0.004374   
2022-11-25 10:16:31,293 - INFO  - Training [2][   80/  196]   Loss 0.781955   Top1 73.305664   Top5 96.513672   BatchTime 0.376713   LR 0.004320   
2022-11-25 10:16:38,345 - INFO  - Training [2][  100/  196]   Loss 0.772080   Top1 73.718750   Top5 96.585938   BatchTime 0.371894   LR 0.004264   
2022-11-25 10:16:45,938 - INFO  - Training [2][  120/  196]   Loss 0.763170   Top1 74.075521   Top5 96.722005   BatchTime 0.373186   LR 0.004206   
2022-11-25 10:16:53,879 - INFO  - Training [2][  140/  196]   Loss 0.761162   Top1 74.171317   Top5 96.799665   BatchTime 0.376594   LR 0.004146   
2022-11-25 10:17:01,030 - INFO  - Training [2][  160/  196]   Loss 0.763969   Top1 74.050293   Top5 96.760254   BatchTime 0.374210   LR 0.004085   
2022-11-25 10:17:08,114 - INFO  - Training [2][  180/  196]   Loss 0.762042   Top1 74.082031   Top5 96.742622   BatchTime 0.371986   LR 0.004022   
2022-11-25 10:17:14,162 - INFO  - ==> Top1: 74.282    Top5: 96.776    Loss: 0.758

2022-11-25 10:17:14,432 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:17:15,820 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:17:18,036 - INFO  - Validation [2][   20/   40]   Loss 0.554052   Top1 81.640625   Top5 99.042969   BatchTime 0.110671   
2022-11-25 10:17:19,107 - INFO  - Validation [2][   40/   40]   Loss 0.542837   Top1 81.820000   Top5 99.150000   BatchTime 0.082136   
2022-11-25 10:17:19,326 - INFO  - ==> Top1: 81.820    Top5: 99.150    Loss: 0.543

2022-11-25 10:17:19,327 - INFO  - ==> Sparsity : 0.211

2022-11-25 10:17:19,327 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 81.820   Top5: 99.150]
2022-11-25 10:17:19,327 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 79.540   Top5: 98.200]
2022-11-25 10:17:19,328 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 71.870   Top5: 97.430]
2022-11-25 10:17:26,191 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:17:26,194 - INFO  - >>>>>> Epoch   3
2022-11-25 10:17:26,196 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:17:35,279 - INFO  - Training [3][   20/  196]   Loss 0.714229   Top1 75.839844   Top5 96.640625   BatchTime 0.454007   LR 0.003907   
2022-11-25 10:17:43,025 - INFO  - Training [3][   40/  196]   Loss 0.717261   Top1 75.458984   Top5 96.777344   BatchTime 0.420672   LR 0.003840   
2022-11-25 10:17:50,188 - INFO  - Training [3][   60/  196]   Loss 0.715055   Top1 75.579427   Top5 97.050781   BatchTime 0.399826   LR 0.003771   
2022-11-25 10:17:57,937 - INFO  - Training [3][   80/  196]   Loss 0.704145   Top1 75.908203   Top5 97.138672   BatchTime 0.396730   LR 0.003701   
2022-11-25 10:18:05,240 - INFO  - Training [3][  100/  196]   Loss 0.695994   Top1 76.316406   Top5 97.191406   BatchTime 0.390413   LR 0.003630   
2022-11-25 10:18:12,830 - INFO  - Training [3][  120/  196]   Loss 0.691094   Top1 76.669922   Top5 97.265625   BatchTime 0.388590   LR 0.003558   
2022-11-25 10:18:20,102 - INFO  - Training [3][  140/  196]   Loss 0.688122   Top1 76.746652   Top5 97.321429   BatchTime 0.385023   LR 0.003484   
2022-11-25 10:18:27,429 - INFO  - Training [3][  160/  196]   Loss 0.689697   Top1 76.667480   Top5 97.329102   BatchTime 0.382686   LR 0.003410   
2022-11-25 10:18:34,634 - INFO  - Training [3][  180/  196]   Loss 0.687954   Top1 76.660156   Top5 97.300347   BatchTime 0.380191   LR 0.003335   
2022-11-25 10:18:40,551 - INFO  - ==> Top1: 76.694    Top5: 97.302    Loss: 0.686

2022-11-25 10:18:40,731 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:18:41,741 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:18:44,613 - INFO  - Validation [3][   20/   40]   Loss 0.609571   Top1 80.234375   Top5 98.398438   BatchTime 0.143490   
2022-11-25 10:18:45,865 - INFO  - Validation [3][   40/   40]   Loss 0.615419   Top1 79.570000   Top5 98.520000   BatchTime 0.103047   
2022-11-25 10:18:46,405 - INFO  - ==> Top1: 79.570    Top5: 98.520    Loss: 0.615

2022-11-25 10:18:46,405 - INFO  - ==> Sparsity : 0.283

2022-11-25 10:18:46,405 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 81.820   Top5: 99.150]
2022-11-25 10:18:46,406 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 79.570   Top5: 98.520]
2022-11-25 10:18:46,406 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 79.540   Top5: 98.200]
2022-11-25 10:18:46,556 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:18:46,558 - INFO  - >>>>>> Epoch   4
2022-11-25 10:18:46,560 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:18:55,661 - INFO  - Training [4][   20/  196]   Loss 0.647899   Top1 77.832031   Top5 97.109375   BatchTime 0.454951   LR 0.003200   
2022-11-25 10:19:03,702 - INFO  - Training [4][   40/  196]   Loss 0.672451   Top1 76.923828   Top5 97.128906   BatchTime 0.428481   LR 0.003122   
2022-11-25 10:19:11,926 - INFO  - Training [4][   60/  196]   Loss 0.677710   Top1 76.894531   Top5 97.161458   BatchTime 0.422732   LR 0.003044   
2022-11-25 10:19:19,937 - INFO  - Training [4][   80/  196]   Loss 0.671365   Top1 77.163086   Top5 97.285156   BatchTime 0.417182   LR 0.002965   
2022-11-25 10:19:27,274 - INFO  - Training [4][  100/  196]   Loss 0.667589   Top1 77.257812   Top5 97.335938   BatchTime 0.407112   LR 0.002886   
2022-11-25 10:19:34,517 - INFO  - Training [4][  120/  196]   Loss 0.664694   Top1 77.425130   Top5 97.434896   BatchTime 0.399618   LR 0.002806   
2022-11-25 10:19:41,663 - INFO  - Training [4][  140/  196]   Loss 0.660377   Top1 77.606027   Top5 97.488839   BatchTime 0.393571   LR 0.002726   
2022-11-25 10:19:48,880 - INFO  - Training [4][  160/  196]   Loss 0.659640   Top1 77.658691   Top5 97.475586   BatchTime 0.389482   LR 0.002646   
2022-11-25 10:19:56,746 - INFO  - Training [4][  180/  196]   Loss 0.653332   Top1 77.853733   Top5 97.471788   BatchTime 0.389904   LR 0.002566   
2022-11-25 10:20:02,070 - INFO  - ==> Top1: 78.010    Top5: 97.458    Loss: 0.648

2022-11-25 10:20:02,314 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:20:04,307 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:20:07,229 - INFO  - Validation [4][   20/   40]   Loss 0.466498   Top1 84.414062   Top5 99.160156   BatchTime 0.146012   
2022-11-25 10:20:08,691 - INFO  - Validation [4][   40/   40]   Loss 0.451677   Top1 84.620000   Top5 99.300000   BatchTime 0.109558   
2022-11-25 10:20:08,899 - INFO  - ==> Top1: 84.620    Top5: 99.300    Loss: 0.452

2022-11-25 10:20:08,899 - INFO  - ==> Sparsity : 0.314

2022-11-25 10:20:08,899 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 84.620   Top5: 99.300]
2022-11-25 10:20:08,900 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 81.820   Top5: 99.150]
2022-11-25 10:20:08,900 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 79.570   Top5: 98.520]
2022-11-25 10:20:14,659 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:20:14,661 - INFO  - >>>>>> Epoch   5
2022-11-25 10:20:14,663 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:20:23,063 - INFO  - Training [5][   20/  196]   Loss 0.639509   Top1 77.890625   Top5 97.148438   BatchTime 0.419903   LR 0.002424   
2022-11-25 10:20:30,474 - INFO  - Training [5][   40/  196]   Loss 0.642313   Top1 77.968750   Top5 97.304688   BatchTime 0.395221   LR 0.002343   
2022-11-25 10:20:38,110 - INFO  - Training [5][   60/  196]   Loss 0.628315   Top1 78.404948   Top5 97.428385   BatchTime 0.390744   LR 0.002263   
2022-11-25 10:20:45,323 - INFO  - Training [5][   80/  196]   Loss 0.625769   Top1 78.437500   Top5 97.539062   BatchTime 0.383218   LR 0.002183   
2022-11-25 10:20:52,409 - INFO  - Training [5][  100/  196]   Loss 0.615493   Top1 78.843750   Top5 97.628906   BatchTime 0.377436   LR 0.002104   
2022-11-25 10:21:00,188 - INFO  - Training [5][  120/  196]   Loss 0.603161   Top1 79.277344   Top5 97.692057   BatchTime 0.379357   LR 0.002024   
2022-11-25 10:21:08,381 - INFO  - Training [5][  140/  196]   Loss 0.594750   Top1 79.531250   Top5 97.770647   BatchTime 0.383681   LR 0.001946   
2022-11-25 10:21:15,266 - INFO  - Training [5][  160/  196]   Loss 0.595384   Top1 79.509277   Top5 97.778320   BatchTime 0.378753   LR 0.001868   
2022-11-25 10:21:21,374 - INFO  - Training [5][  180/  196]   Loss 0.594966   Top1 79.513889   Top5 97.717014   BatchTime 0.370600   LR 0.001790   
2022-11-25 10:21:26,553 - INFO  - ==> Top1: 79.764    Top5: 97.726    Loss: 0.590

2022-11-25 10:21:26,784 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:21:28,054 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:21:30,256 - INFO  - Validation [5][   20/   40]   Loss 0.461544   Top1 84.511719   Top5 99.257812   BatchTime 0.110047   
2022-11-25 10:21:31,306 - INFO  - Validation [5][   40/   40]   Loss 0.451852   Top1 84.640000   Top5 99.350000   BatchTime 0.081279   
2022-11-25 10:21:31,532 - INFO  - ==> Top1: 84.640    Top5: 99.350    Loss: 0.452

2022-11-25 10:21:31,532 - INFO  - ==> Sparsity : 0.352

2022-11-25 10:21:31,532 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 84.640   Top5: 99.350]
2022-11-25 10:21:31,532 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 84.620   Top5: 99.300]
2022-11-25 10:21:31,533 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 81.820   Top5: 99.150]
2022-11-25 10:21:37,017 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:21:37,021 - INFO  - >>>>>> Epoch   6
2022-11-25 10:21:37,024 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:21:45,363 - INFO  - Training [6][   20/  196]   Loss 0.570005   Top1 80.429688   Top5 97.304688   BatchTime 0.416858   LR 0.001655   
2022-11-25 10:21:52,899 - INFO  - Training [6][   40/  196]   Loss 0.567880   Top1 80.585938   Top5 97.509766   BatchTime 0.396832   LR 0.001580   
2022-11-25 10:22:00,548 - INFO  - Training [6][   60/  196]   Loss 0.565973   Top1 80.651042   Top5 97.675781   BatchTime 0.392039   LR 0.001506   
2022-11-25 10:22:08,516 - INFO  - Training [6][   80/  196]   Loss 0.558496   Top1 80.859375   Top5 97.827148   BatchTime 0.393628   LR 0.001432   
2022-11-25 10:22:16,070 - INFO  - Training [6][  100/  196]   Loss 0.551012   Top1 81.085938   Top5 97.894531   BatchTime 0.390432   LR 0.001360   
2022-11-25 10:22:23,560 - INFO  - Training [6][  120/  196]   Loss 0.542059   Top1 81.461589   Top5 98.001302   BatchTime 0.387784   LR 0.001289   
2022-11-25 10:22:30,982 - INFO  - Training [6][  140/  196]   Loss 0.539656   Top1 81.548549   Top5 98.044085   BatchTime 0.385397   LR 0.001220   
2022-11-25 10:22:37,961 - INFO  - Training [6][  160/  196]   Loss 0.543576   Top1 81.462402   Top5 98.041992   BatchTime 0.380842   LR 0.001151   
2022-11-25 10:22:44,432 - INFO  - Training [6][  180/  196]   Loss 0.542873   Top1 81.456163   Top5 98.001302   BatchTime 0.374474   LR 0.001084   
2022-11-25 10:22:50,342 - INFO  - ==> Top1: 81.552    Top5: 98.018    Loss: 0.541

2022-11-25 10:22:50,585 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:22:51,986 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:22:54,150 - INFO  - Validation [6][   20/   40]   Loss 0.417515   Top1 86.484375   Top5 99.375000   BatchTime 0.108118   
2022-11-25 10:22:55,224 - INFO  - Validation [6][   40/   40]   Loss 0.414269   Top1 86.380000   Top5 99.500000   BatchTime 0.080910   
2022-11-25 10:22:55,419 - INFO  - ==> Top1: 86.380    Top5: 99.500    Loss: 0.414

2022-11-25 10:22:55,419 - INFO  - ==> Sparsity : 0.353

2022-11-25 10:22:55,419 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 86.380   Top5: 99.500]
2022-11-25 10:22:55,419 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 84.640   Top5: 99.350]
2022-11-25 10:22:55,419 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 84.620   Top5: 99.300]
2022-11-25 10:23:01,742 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:23:01,743 - INFO  - >>>>>> Epoch   7
2022-11-25 10:23:01,745 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:23:10,482 - INFO  - Training [7][   20/  196]   Loss 0.546695   Top1 80.957031   Top5 97.480469   BatchTime 0.436747   LR 0.000969   
2022-11-25 10:23:17,564 - INFO  - Training [7][   40/  196]   Loss 0.531691   Top1 81.582031   Top5 97.705078   BatchTime 0.395409   LR 0.000907   
2022-11-25 10:23:24,847 - INFO  - Training [7][   60/  196]   Loss 0.526382   Top1 81.796875   Top5 97.832031   BatchTime 0.384992   LR 0.000845   
2022-11-25 10:23:32,684 - INFO  - Training [7][   80/  196]   Loss 0.524256   Top1 81.879883   Top5 97.944336   BatchTime 0.386705   LR 0.000786   
2022-11-25 10:23:40,477 - INFO  - Training [7][  100/  196]   Loss 0.519292   Top1 82.054688   Top5 98.007812   BatchTime 0.387294   LR 0.000728   
2022-11-25 10:23:47,432 - INFO  - Training [7][  120/  196]   Loss 0.514903   Top1 82.268880   Top5 98.102214   BatchTime 0.380703   LR 0.000673   
2022-11-25 10:23:54,419 - INFO  - Training [7][  140/  196]   Loss 0.511229   Top1 82.396763   Top5 98.191964   BatchTime 0.376221   LR 0.000619   
2022-11-25 10:24:00,493 - INFO  - Training [7][  160/  196]   Loss 0.513242   Top1 82.365723   Top5 98.178711   BatchTime 0.367160   LR 0.000567   
2022-11-25 10:24:07,260 - INFO  - Training [7][  180/  196]   Loss 0.512749   Top1 82.348090   Top5 98.118490   BatchTime 0.363953   LR 0.000517   
2022-11-25 10:24:13,176 - INFO  - ==> Top1: 82.442    Top5: 98.148    Loss: 0.509

2022-11-25 10:24:13,423 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:24:14,835 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:24:17,083 - INFO  - Validation [7][   20/   40]   Loss 0.371097   Top1 87.480469   Top5 99.453125   BatchTime 0.112314   
2022-11-25 10:24:18,158 - INFO  - Validation [7][   40/   40]   Loss 0.353159   Top1 88.000000   Top5 99.590000   BatchTime 0.083060   
2022-11-25 10:24:18,350 - INFO  - ==> Top1: 88.000    Top5: 99.590    Loss: 0.353

2022-11-25 10:24:18,350 - INFO  - ==> Sparsity : 0.352

2022-11-25 10:24:18,351 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:24:18,351 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 86.380   Top5: 99.500]
2022-11-25 10:24:18,351 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 84.640   Top5: 99.350]
2022-11-25 10:24:23,538 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:24:23,541 - INFO  - >>>>>> Epoch   8
2022-11-25 10:24:23,543 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:24:31,943 - INFO  - Training [8][   20/  196]   Loss 0.504450   Top1 82.421875   Top5 97.851562   BatchTime 0.419875   LR 0.000434   
2022-11-25 10:24:39,181 - INFO  - Training [8][   40/  196]   Loss 0.497376   Top1 82.763672   Top5 98.066406   BatchTime 0.390914   LR 0.000389   
2022-11-25 10:24:46,304 - INFO  - Training [8][   60/  196]   Loss 0.498193   Top1 82.897135   Top5 98.059896   BatchTime 0.379313   LR 0.000347   
2022-11-25 10:24:54,451 - INFO  - Training [8][   80/  196]   Loss 0.494772   Top1 83.149414   Top5 98.198242   BatchTime 0.386326   LR 0.000308   
2022-11-25 10:25:02,618 - INFO  - Training [8][  100/  196]   Loss 0.488887   Top1 83.421875   Top5 98.250000   BatchTime 0.390722   LR 0.000270   
2022-11-25 10:25:10,523 - INFO  - Training [8][  120/  196]   Loss 0.482046   Top1 83.541667   Top5 98.362630   BatchTime 0.391484   LR 0.000235   
2022-11-25 10:25:16,918 - INFO  - Training [8][  140/  196]   Loss 0.475368   Top1 83.808594   Top5 98.429129   BatchTime 0.381233   LR 0.000202   
2022-11-25 10:25:23,383 - INFO  - Training [8][  160/  196]   Loss 0.479642   Top1 83.645020   Top5 98.403320   BatchTime 0.373985   LR 0.000172   
2022-11-25 10:25:30,559 - INFO  - Training [8][  180/  196]   Loss 0.477268   Top1 83.687066   Top5 98.305122   BatchTime 0.372298   LR 0.000143   
2022-11-25 10:25:36,139 - INFO  - ==> Top1: 83.784    Top5: 98.304    Loss: 0.476

2022-11-25 10:25:36,417 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:25:37,900 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:25:40,155 - INFO  - Validation [8][   20/   40]   Loss 0.564727   Top1 81.308594   Top5 98.710938   BatchTime 0.112655   
2022-11-25 10:25:41,122 - INFO  - Validation [8][   40/   40]   Loss 0.553518   Top1 81.240000   Top5 98.940000   BatchTime 0.080497   
2022-11-25 10:25:41,382 - INFO  - ==> Top1: 81.240    Top5: 98.940    Loss: 0.554

2022-11-25 10:25:41,382 - INFO  - ==> Sparsity : 0.356

2022-11-25 10:25:41,383 - INFO  - Scoreboard best 1 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:25:41,383 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 86.380   Top5: 99.500]
2022-11-25 10:25:41,383 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 84.640   Top5: 99.350]
2022-11-25 10:25:41,521 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:25:41,523 - INFO  - >>>>>> Epoch   9
2022-11-25 10:25:41,524 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:25:50,441 - INFO  - Training [9][   20/  196]   Loss 0.498787   Top1 82.988281   Top5 97.597656   BatchTime 0.445685   LR 0.000100   
2022-11-25 10:25:57,575 - INFO  - Training [9][   40/  196]   Loss 0.493173   Top1 82.978516   Top5 97.910156   BatchTime 0.401200   LR 0.000079   
2022-11-25 10:26:05,135 - INFO  - Training [9][   60/  196]   Loss 0.483271   Top1 83.424479   Top5 98.085938   BatchTime 0.393457   LR 0.000060   
2022-11-25 10:26:12,238 - INFO  - Training [9][   80/  196]   Loss 0.481871   Top1 83.466797   Top5 98.242188   BatchTime 0.383876   LR 0.000044   
2022-11-25 10:26:19,245 - INFO  - Training [9][  100/  196]   Loss 0.469819   Top1 83.917969   Top5 98.289062   BatchTime 0.377176   LR 0.000030   
2022-11-25 10:26:26,554 - INFO  - Training [9][  120/  196]   Loss 0.463522   Top1 84.156901   Top5 98.385417   BatchTime 0.375219   LR 0.000019   
2022-11-25 10:26:33,737 - INFO  - Training [9][  140/  196]   Loss 0.463309   Top1 84.070871   Top5 98.423549   BatchTime 0.372922   LR 0.000010   
2022-11-25 10:26:40,150 - INFO  - Training [9][  160/  196]   Loss 0.465311   Top1 83.974609   Top5 98.437500   BatchTime 0.366387   LR 0.000004   
2022-11-25 10:26:47,094 - INFO  - Training [9][  180/  196]   Loss 0.465727   Top1 83.973524   Top5 98.378906   BatchTime 0.364254   LR 0.000001   
2022-11-25 10:26:53,132 - INFO  - ==> Top1: 83.958    Top5: 98.364    Loss: 0.467

2022-11-25 10:26:53,395 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:26:54,886 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:26:57,190 - INFO  - Validation [9][   20/   40]   Loss 0.362255   Top1 88.203125   Top5 99.570312   BatchTime 0.115150   
2022-11-25 10:26:58,287 - INFO  - Validation [9][   40/   40]   Loss 0.349438   Top1 88.270000   Top5 99.610000   BatchTime 0.084989   
2022-11-25 10:26:58,549 - INFO  - ==> Top1: 88.270    Top5: 99.610    Loss: 0.349

2022-11-25 10:26:58,550 - INFO  - ==> Sparsity : 0.357

2022-11-25 10:26:58,550 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:26:58,550 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:26:58,550 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 86.380   Top5: 99.500]
2022-11-25 10:27:04,743 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:27:04,744 - INFO  - >>>>>> Epoch  10
2022-11-25 10:27:04,746 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:27:13,511 - INFO  - Training [10][   20/  196]   Loss 0.539394   Top1 81.621094   Top5 97.695312   BatchTime 0.438103   LR 0.002500   
2022-11-25 10:27:20,875 - INFO  - Training [10][   40/  196]   Loss 0.545847   Top1 81.464844   Top5 97.861328   BatchTime 0.403160   LR 0.002499   
2022-11-25 10:27:28,040 - INFO  - Training [10][   60/  196]   Loss 0.553761   Top1 81.243490   Top5 97.923177   BatchTime 0.388189   LR 0.002499   
2022-11-25 10:27:35,133 - INFO  - Training [10][   80/  196]   Loss 0.554602   Top1 81.225586   Top5 97.993164   BatchTime 0.379804   LR 0.002497   
2022-11-25 10:27:42,387 - INFO  - Training [10][  100/  196]   Loss 0.550202   Top1 81.410156   Top5 98.046875   BatchTime 0.376379   LR 0.002496   
2022-11-25 10:27:49,684 - INFO  - Training [10][  120/  196]   Loss 0.550717   Top1 81.442057   Top5 98.037109   BatchTime 0.374462   LR 0.002494   
2022-11-25 10:27:55,856 - INFO  - Training [10][  140/  196]   Loss 0.550214   Top1 81.462054   Top5 98.077567   BatchTime 0.365052   LR 0.002492   
2022-11-25 10:28:02,616 - INFO  - Training [10][  160/  196]   Loss 0.596299   Top1 80.385742   Top5 97.770996   BatchTime 0.361669   LR 0.002490   
2022-11-25 10:28:10,368 - INFO  - Training [10][  180/  196]   Loss 0.606742   Top1 80.017361   Top5 97.632378   BatchTime 0.364548   LR 0.002487   
2022-11-25 10:28:16,928 - INFO  - ==> Top1: 79.752    Top5: 97.562    Loss: 0.612

2022-11-25 10:28:17,203 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:28:18,877 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:28:21,282 - INFO  - Validation [10][   20/   40]   Loss 0.575634   Top1 81.855469   Top5 98.847656   BatchTime 0.120158   
2022-11-25 10:28:22,442 - INFO  - Validation [10][   40/   40]   Loss 0.566897   Top1 82.130000   Top5 99.010000   BatchTime 0.089081   
2022-11-25 10:28:22,729 - INFO  - ==> Top1: 82.130    Top5: 99.010    Loss: 0.567

2022-11-25 10:28:22,729 - INFO  - ==> Sparsity : 0.446

2022-11-25 10:28:22,729 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:28:22,730 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:28:22,730 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 86.380   Top5: 99.500]
2022-11-25 10:28:22,880 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:28:22,884 - INFO  - >>>>>> Epoch  11
2022-11-25 10:28:22,888 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:28:31,663 - INFO  - Training [11][   20/  196]   Loss 0.657036   Top1 77.832031   Top5 96.640625   BatchTime 0.438466   LR 0.002481   
2022-11-25 10:28:39,043 - INFO  - Training [11][   40/  196]   Loss 0.637489   Top1 78.222656   Top5 97.060547   BatchTime 0.403734   LR 0.002478   
2022-11-25 10:28:46,216 - INFO  - Training [11][   60/  196]   Loss 0.630961   Top1 78.554688   Top5 97.272135   BatchTime 0.388691   LR 0.002474   
2022-11-25 10:28:53,694 - INFO  - Training [11][   80/  196]   Loss 0.628542   Top1 78.618164   Top5 97.470703   BatchTime 0.384997   LR 0.002470   
2022-11-25 10:29:01,003 - INFO  - Training [11][  100/  196]   Loss 0.618390   Top1 78.867188   Top5 97.566406   BatchTime 0.381084   LR 0.002465   
2022-11-25 10:29:08,680 - INFO  - Training [11][  120/  196]   Loss 0.610255   Top1 79.153646   Top5 97.692057   BatchTime 0.381544   LR 0.002460   
2022-11-25 10:29:15,362 - INFO  - Training [11][  140/  196]   Loss 0.607745   Top1 79.238281   Top5 97.745536   BatchTime 0.374766   LR 0.002455   
2022-11-25 10:29:22,248 - INFO  - Training [11][  160/  196]   Loss 0.609638   Top1 79.177246   Top5 97.783203   BatchTime 0.370958   LR 0.002450   
2022-11-25 10:29:27,804 - INFO  - Training [11][  180/  196]   Loss 0.604610   Top1 79.281684   Top5 97.749566   BatchTime 0.360610   LR 0.002444   
2022-11-25 10:29:34,018 - INFO  - ==> Top1: 79.356    Top5: 97.766    Loss: 0.604

2022-11-25 10:29:34,272 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:29:35,571 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:29:37,962 - INFO  - Validation [11][   20/   40]   Loss 0.458464   Top1 84.941406   Top5 99.355469   BatchTime 0.119416   
2022-11-25 10:29:39,001 - INFO  - Validation [11][   40/   40]   Loss 0.442060   Top1 85.350000   Top5 99.440000   BatchTime 0.085697   
2022-11-25 10:29:39,248 - INFO  - ==> Top1: 85.350    Top5: 99.440    Loss: 0.442

2022-11-25 10:29:39,248 - INFO  - ==> Sparsity : 0.319

2022-11-25 10:29:39,248 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:29:39,249 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:29:39,249 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 86.380   Top5: 99.500]
2022-11-25 10:29:39,389 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:29:39,391 - INFO  - >>>>>> Epoch  12
2022-11-25 10:29:39,393 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:29:48,006 - INFO  - Training [12][   20/  196]   Loss 0.568999   Top1 80.546875   Top5 97.226562   BatchTime 0.430530   LR 0.002433   
2022-11-25 10:29:55,876 - INFO  - Training [12][   40/  196]   Loss 0.574690   Top1 80.390625   Top5 97.626953   BatchTime 0.412007   LR 0.002426   
2022-11-25 10:30:03,281 - INFO  - Training [12][   60/  196]   Loss 0.574969   Top1 80.240885   Top5 97.682292   BatchTime 0.398099   LR 0.002419   
2022-11-25 10:30:10,467 - INFO  - Training [12][   80/  196]   Loss 0.569177   Top1 80.541992   Top5 97.763672   BatchTime 0.388392   LR 0.002412   
2022-11-25 10:30:17,853 - INFO  - Training [12][  100/  196]   Loss 0.560287   Top1 80.828125   Top5 97.867188   BatchTime 0.384578   LR 0.002404   
2022-11-25 10:30:25,064 - INFO  - Training [12][  120/  196]   Loss 0.556474   Top1 80.983073   Top5 97.975260   BatchTime 0.380573   LR 0.002396   
2022-11-25 10:30:32,123 - INFO  - Training [12][  140/  196]   Loss 0.555945   Top1 81.010045   Top5 97.996652   BatchTime 0.376625   LR 0.002388   
2022-11-25 10:30:39,659 - INFO  - Training [12][  160/  196]   Loss 0.557578   Top1 80.981445   Top5 98.005371   BatchTime 0.376645   LR 0.002380   
2022-11-25 10:30:46,264 - INFO  - Training [12][  180/  196]   Loss 0.559054   Top1 80.872396   Top5 97.942708   BatchTime 0.371489   LR 0.002371   
2022-11-25 10:30:51,547 - INFO  - ==> Top1: 80.962    Top5: 97.970    Loss: 0.557

2022-11-25 10:30:51,789 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:30:53,250 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:30:55,671 - INFO  - Validation [12][   20/   40]   Loss 0.419991   Top1 86.113281   Top5 99.394531   BatchTime 0.120925   
2022-11-25 10:30:56,676 - INFO  - Validation [12][   40/   40]   Loss 0.409304   Top1 86.390000   Top5 99.470000   BatchTime 0.085606   
2022-11-25 10:30:56,915 - INFO  - ==> Top1: 86.390    Top5: 99.470    Loss: 0.409

2022-11-25 10:30:56,915 - INFO  - ==> Sparsity : 0.362

2022-11-25 10:30:56,916 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:30:56,916 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:30:56,916 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 86.390   Top5: 99.470]
2022-11-25 10:30:57,039 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:30:57,041 - INFO  - >>>>>> Epoch  13
2022-11-25 10:30:57,042 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:31:05,545 - INFO  - Training [13][   20/  196]   Loss 0.548364   Top1 81.367188   Top5 97.363281   BatchTime 0.424990   LR 0.002355   
2022-11-25 10:31:13,450 - INFO  - Training [13][   40/  196]   Loss 0.553069   Top1 81.171875   Top5 97.666016   BatchTime 0.410133   LR 0.002345   
2022-11-25 10:31:21,192 - INFO  - Training [13][   60/  196]   Loss 0.548566   Top1 81.399740   Top5 97.845052   BatchTime 0.402455   LR 0.002336   
2022-11-25 10:31:28,928 - INFO  - Training [13][   80/  196]   Loss 0.554791   Top1 81.064453   Top5 97.871094   BatchTime 0.398537   LR 0.002325   
2022-11-25 10:31:36,025 - INFO  - Training [13][  100/  196]   Loss 0.550429   Top1 81.222656   Top5 97.902344   BatchTime 0.389792   LR 0.002315   
2022-11-25 10:31:43,425 - INFO  - Training [13][  120/  196]   Loss 0.546026   Top1 81.370443   Top5 97.945964   BatchTime 0.386494   LR 0.002304   
2022-11-25 10:31:50,460 - INFO  - Training [13][  140/  196]   Loss 0.545649   Top1 81.431362   Top5 98.049665   BatchTime 0.381535   LR 0.002293   
2022-11-25 10:31:57,633 - INFO  - Training [13][  160/  196]   Loss 0.545332   Top1 81.445312   Top5 98.051758   BatchTime 0.378669   LR 0.002282   
2022-11-25 10:32:04,285 - INFO  - Training [13][  180/  196]   Loss 0.545774   Top1 81.399740   Top5 98.009983   BatchTime 0.373552   LR 0.002271   
2022-11-25 10:32:09,357 - INFO  - ==> Top1: 81.452    Top5: 98.020    Loss: 0.544

2022-11-25 10:32:09,546 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:32:11,191 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:32:13,561 - INFO  - Validation [13][   20/   40]   Loss 0.430571   Top1 85.488281   Top5 99.433594   BatchTime 0.118422   
2022-11-25 10:32:14,581 - INFO  - Validation [13][   40/   40]   Loss 0.420024   Top1 85.830000   Top5 99.510000   BatchTime 0.084724   
2022-11-25 10:32:14,787 - INFO  - ==> Top1: 85.830    Top5: 99.510    Loss: 0.420

2022-11-25 10:32:14,787 - INFO  - ==> Sparsity : 0.380

2022-11-25 10:32:14,788 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:32:14,788 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:32:14,788 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 86.390   Top5: 99.470]
2022-11-25 10:32:14,905 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:32:14,907 - INFO  - >>>>>> Epoch  14
2022-11-25 10:32:14,908 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:32:23,674 - INFO  - Training [14][   20/  196]   Loss 0.522823   Top1 81.816406   Top5 97.363281   BatchTime 0.438169   LR 0.002250   
2022-11-25 10:32:30,983 - INFO  - Training [14][   40/  196]   Loss 0.544802   Top1 81.162109   Top5 97.626953   BatchTime 0.401795   LR 0.002238   
2022-11-25 10:32:39,059 - INFO  - Training [14][   60/  196]   Loss 0.539670   Top1 81.458333   Top5 97.832031   BatchTime 0.402475   LR 0.002225   
2022-11-25 10:32:46,951 - INFO  - Training [14][   80/  196]   Loss 0.536652   Top1 81.591797   Top5 97.924805   BatchTime 0.400502   LR 0.002213   
2022-11-25 10:32:54,582 - INFO  - Training [14][  100/  196]   Loss 0.530201   Top1 81.769531   Top5 98.000000   BatchTime 0.396707   LR 0.002200   
2022-11-25 10:33:02,263 - INFO  - Training [14][  120/  196]   Loss 0.525814   Top1 81.949870   Top5 98.095703   BatchTime 0.394596   LR 0.002186   
2022-11-25 10:33:09,862 - INFO  - Training [14][  140/  196]   Loss 0.526938   Top1 81.961496   Top5 98.119420   BatchTime 0.392507   LR 0.002173   
2022-11-25 10:33:17,711 - INFO  - Training [14][  160/  196]   Loss 0.528180   Top1 81.962891   Top5 98.085938   BatchTime 0.392498   LR 0.002159   
2022-11-25 10:33:24,495 - INFO  - Training [14][  180/  196]   Loss 0.528071   Top1 81.987847   Top5 98.031684   BatchTime 0.386573   LR 0.002145   
2022-11-25 10:33:30,156 - INFO  - ==> Top1: 82.086    Top5: 98.034    Loss: 0.525

2022-11-25 10:33:30,439 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:33:31,902 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:33:34,242 - INFO  - Validation [14][   20/   40]   Loss 0.398386   Top1 86.601562   Top5 99.511719   BatchTime 0.116915   
2022-11-25 10:33:35,296 - INFO  - Validation [14][   40/   40]   Loss 0.393351   Top1 86.600000   Top5 99.540000   BatchTime 0.084816   
2022-11-25 10:33:35,513 - INFO  - ==> Top1: 86.600    Top5: 99.540    Loss: 0.393

2022-11-25 10:33:35,514 - INFO  - ==> Sparsity : 0.346

2022-11-25 10:33:35,514 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:33:35,514 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:33:35,514 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 86.600   Top5: 99.540]
2022-11-25 10:33:35,649 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:33:35,650 - INFO  - >>>>>> Epoch  15
2022-11-25 10:33:35,652 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:33:44,414 - INFO  - Training [15][   20/  196]   Loss 0.532092   Top1 81.914062   Top5 97.539062   BatchTime 0.437945   LR 0.002120   
2022-11-25 10:33:51,737 - INFO  - Training [15][   40/  196]   Loss 0.526541   Top1 81.875000   Top5 97.802734   BatchTime 0.402067   LR 0.002106   
2022-11-25 10:33:59,388 - INFO  - Training [15][   60/  196]   Loss 0.529649   Top1 81.940104   Top5 97.942708   BatchTime 0.395551   LR 0.002091   
2022-11-25 10:34:06,691 - INFO  - Training [15][   80/  196]   Loss 0.527176   Top1 82.104492   Top5 98.046875   BatchTime 0.387943   LR 0.002076   
2022-11-25 10:34:14,587 - INFO  - Training [15][  100/  196]   Loss 0.517524   Top1 82.378906   Top5 98.082031   BatchTime 0.389324   LR 0.002061   
2022-11-25 10:34:22,518 - INFO  - Training [15][  120/  196]   Loss 0.514315   Top1 82.454427   Top5 98.196615   BatchTime 0.390528   LR 0.002045   
2022-11-25 10:34:30,475 - INFO  - Training [15][  140/  196]   Loss 0.513964   Top1 82.536272   Top5 98.233817   BatchTime 0.391567   LR 0.002030   
2022-11-25 10:34:37,835 - INFO  - Training [15][  160/  196]   Loss 0.516706   Top1 82.470703   Top5 98.212891   BatchTime 0.388625   LR 0.002014   
2022-11-25 10:34:44,676 - INFO  - Training [15][  180/  196]   Loss 0.515532   Top1 82.497830   Top5 98.138021   BatchTime 0.383445   LR 0.001998   
2022-11-25 10:34:50,350 - INFO  - ==> Top1: 82.542    Top5: 98.146    Loss: 0.514

2022-11-25 10:34:50,562 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:34:51,844 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:34:54,655 - INFO  - Validation [15][   20/   40]   Loss 0.415889   Top1 86.230469   Top5 99.296875   BatchTime 0.140492   
2022-11-25 10:34:55,877 - INFO  - Validation [15][   40/   40]   Loss 0.401737   Top1 86.500000   Top5 99.450000   BatchTime 0.100801   
2022-11-25 10:34:56,101 - INFO  - ==> Top1: 86.500    Top5: 99.450    Loss: 0.402

2022-11-25 10:34:56,101 - INFO  - ==> Sparsity : 0.369

2022-11-25 10:34:56,101 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:34:56,101 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:34:56,102 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 86.600   Top5: 99.540]
2022-11-25 10:34:56,237 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:34:56,239 - INFO  - >>>>>> Epoch  16
2022-11-25 10:34:56,241 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:35:05,410 - INFO  - Training [16][   20/  196]   Loss 0.524995   Top1 81.777344   Top5 97.968750   BatchTime 0.458273   LR 0.001969   
2022-11-25 10:35:12,962 - INFO  - Training [16][   40/  196]   Loss 0.519332   Top1 82.060547   Top5 97.968750   BatchTime 0.417950   LR 0.001953   
2022-11-25 10:35:20,290 - INFO  - Training [16][   60/  196]   Loss 0.511255   Top1 82.382812   Top5 98.098958   BatchTime 0.400757   LR 0.001936   
2022-11-25 10:35:27,855 - INFO  - Training [16][   80/  196]   Loss 0.514366   Top1 82.392578   Top5 98.144531   BatchTime 0.395133   LR 0.001919   
2022-11-25 10:35:35,378 - INFO  - Training [16][  100/  196]   Loss 0.505307   Top1 82.632812   Top5 98.171875   BatchTime 0.391333   LR 0.001902   
2022-11-25 10:35:42,415 - INFO  - Training [16][  120/  196]   Loss 0.499652   Top1 82.835286   Top5 98.232422   BatchTime 0.384751   LR 0.001885   
2022-11-25 10:35:49,348 - INFO  - Training [16][  140/  196]   Loss 0.497265   Top1 83.005022   Top5 98.281250   BatchTime 0.379314   LR 0.001867   
2022-11-25 10:35:56,054 - INFO  - Training [16][  160/  196]   Loss 0.498374   Top1 83.051758   Top5 98.283691   BatchTime 0.373811   LR 0.001850   
2022-11-25 10:36:03,269 - INFO  - Training [16][  180/  196]   Loss 0.497797   Top1 83.040365   Top5 98.216146   BatchTime 0.372357   LR 0.001832   
2022-11-25 10:36:09,363 - INFO  - ==> Top1: 83.036    Top5: 98.208    Loss: 0.498

2022-11-25 10:36:09,666 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:36:11,441 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:36:13,985 - INFO  - Validation [16][   20/   40]   Loss 0.380699   Top1 86.679688   Top5 99.531250   BatchTime 0.127138   
2022-11-25 10:36:15,308 - INFO  - Validation [16][   40/   40]   Loss 0.373687   Top1 87.060000   Top5 99.610000   BatchTime 0.096634   
2022-11-25 10:36:15,553 - INFO  - ==> Top1: 87.060    Top5: 99.610    Loss: 0.374

2022-11-25 10:36:15,553 - INFO  - ==> Sparsity : 0.382

2022-11-25 10:36:15,554 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:36:15,554 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:36:15,555 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 87.060   Top5: 99.610]
2022-11-25 10:36:15,736 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:36:15,738 - INFO  - >>>>>> Epoch  17
2022-11-25 10:36:15,740 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:36:24,407 - INFO  - Training [17][   20/  196]   Loss 0.516236   Top1 81.367188   Top5 97.949219   BatchTime 0.433249   LR 0.001800   
2022-11-25 10:36:32,433 - INFO  - Training [17][   40/  196]   Loss 0.503590   Top1 82.353516   Top5 97.929688   BatchTime 0.417270   LR 0.001782   
2022-11-25 10:36:40,550 - INFO  - Training [17][   60/  196]   Loss 0.494300   Top1 82.851562   Top5 98.072917   BatchTime 0.413454   LR 0.001764   
2022-11-25 10:36:48,069 - INFO  - Training [17][   80/  196]   Loss 0.494634   Top1 82.949219   Top5 98.144531   BatchTime 0.404085   LR 0.001746   
2022-11-25 10:36:55,398 - INFO  - Training [17][  100/  196]   Loss 0.489416   Top1 83.113281   Top5 98.160156   BatchTime 0.396549   LR 0.001727   
2022-11-25 10:37:03,053 - INFO  - Training [17][  120/  196]   Loss 0.486597   Top1 83.251953   Top5 98.255208   BatchTime 0.394254   LR 0.001708   
2022-11-25 10:37:10,386 - INFO  - Training [17][  140/  196]   Loss 0.484255   Top1 83.395647   Top5 98.317522   BatchTime 0.390311   LR 0.001690   
2022-11-25 10:37:18,013 - INFO  - Training [17][  160/  196]   Loss 0.486402   Top1 83.405762   Top5 98.291016   BatchTime 0.389170   LR 0.001671   
2022-11-25 10:37:25,487 - INFO  - Training [17][  180/  196]   Loss 0.485110   Top1 83.413628   Top5 98.248698   BatchTime 0.387467   LR 0.001652   
2022-11-25 10:37:32,163 - INFO  - ==> Top1: 83.456    Top5: 98.254    Loss: 0.484

2022-11-25 10:37:32,435 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:37:33,747 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:37:36,363 - INFO  - Validation [17][   20/   40]   Loss 0.367132   Top1 87.890625   Top5 99.453125   BatchTime 0.130715   
2022-11-25 10:37:37,538 - INFO  - Validation [17][   40/   40]   Loss 0.361847   Top1 87.870000   Top5 99.590000   BatchTime 0.094727   
2022-11-25 10:37:37,994 - INFO  - ==> Top1: 87.870    Top5: 99.590    Loss: 0.362

2022-11-25 10:37:37,994 - INFO  - ==> Sparsity : 0.381

2022-11-25 10:37:37,995 - INFO  - Scoreboard best 1 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:37:37,995 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:37:37,995 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 87.870   Top5: 99.590]
2022-11-25 10:37:38,173 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:37:38,176 - INFO  - >>>>>> Epoch  18
2022-11-25 10:37:38,179 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:37:47,166 - INFO  - Training [18][   20/  196]   Loss 0.486026   Top1 83.125000   Top5 97.734375   BatchTime 0.449157   LR 0.001618   
2022-11-25 10:37:55,125 - INFO  - Training [18][   40/  196]   Loss 0.489438   Top1 83.271484   Top5 97.851562   BatchTime 0.423546   LR 0.001599   
2022-11-25 10:38:03,216 - INFO  - Training [18][   60/  196]   Loss 0.484721   Top1 83.509115   Top5 98.001302   BatchTime 0.417202   LR 0.001579   
2022-11-25 10:38:11,102 - INFO  - Training [18][   80/  196]   Loss 0.482393   Top1 83.623047   Top5 98.139648   BatchTime 0.411483   LR 0.001560   
2022-11-25 10:38:18,365 - INFO  - Training [18][  100/  196]   Loss 0.474193   Top1 83.847656   Top5 98.222656   BatchTime 0.401815   LR 0.001540   
2022-11-25 10:38:25,374 - INFO  - Training [18][  120/  196]   Loss 0.464019   Top1 84.166667   Top5 98.313802   BatchTime 0.393252   LR 0.001521   
2022-11-25 10:38:32,708 - INFO  - Training [18][  140/  196]   Loss 0.463726   Top1 84.196429   Top5 98.353795   BatchTime 0.389457   LR 0.001501   
2022-11-25 10:38:40,113 - INFO  - Training [18][  160/  196]   Loss 0.465925   Top1 84.140625   Top5 98.364258   BatchTime 0.387057   LR 0.001482   
2022-11-25 10:38:47,509 - INFO  - Training [18][  180/  196]   Loss 0.466332   Top1 84.127604   Top5 98.311632   BatchTime 0.385137   LR 0.001462   
2022-11-25 10:38:53,408 - INFO  - ==> Top1: 84.228    Top5: 98.322    Loss: 0.464

2022-11-25 10:38:53,645 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:38:54,789 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:38:57,150 - INFO  - Validation [18][   20/   40]   Loss 0.359240   Top1 88.300781   Top5 99.609375   BatchTime 0.117937   
2022-11-25 10:38:58,694 - INFO  - Validation [18][   40/   40]   Loss 0.346826   Top1 88.510000   Top5 99.630000   BatchTime 0.097585   
2022-11-25 10:38:59,197 - INFO  - ==> Top1: 88.510    Top5: 99.630    Loss: 0.347

2022-11-25 10:38:59,197 - INFO  - ==> Sparsity : 0.378

2022-11-25 10:38:59,197 - INFO  - Scoreboard best 1 ==> Epoch [18][Top1: 88.510   Top5: 99.630]
2022-11-25 10:38:59,198 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:38:59,198 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 88.000   Top5: 99.590]
2022-11-25 10:39:06,254 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:39:06,257 - INFO  - >>>>>> Epoch  19
2022-11-25 10:39:06,259 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:39:14,985 - INFO  - Training [19][   20/  196]   Loss 0.473064   Top1 83.281250   Top5 97.832031   BatchTime 0.436194   LR 0.001427   
2022-11-25 10:39:22,174 - INFO  - Training [19][   40/  196]   Loss 0.464147   Top1 83.505859   Top5 98.056641   BatchTime 0.397825   LR 0.001407   
2022-11-25 10:39:29,423 - INFO  - Training [19][   60/  196]   Loss 0.463007   Top1 83.691406   Top5 98.131510   BatchTime 0.386029   LR 0.001387   
2022-11-25 10:39:36,716 - INFO  - Training [19][   80/  196]   Loss 0.461476   Top1 83.916016   Top5 98.193359   BatchTime 0.380679   LR 0.001367   
2022-11-25 10:39:44,185 - INFO  - Training [19][  100/  196]   Loss 0.457170   Top1 84.042969   Top5 98.214844   BatchTime 0.379234   LR 0.001347   
2022-11-25 10:39:51,587 - INFO  - Training [19][  120/  196]   Loss 0.449768   Top1 84.329427   Top5 98.277995   BatchTime 0.377714   LR 0.001327   
2022-11-25 10:39:59,754 - INFO  - Training [19][  140/  196]   Loss 0.448656   Top1 84.408482   Top5 98.342634   BatchTime 0.382091   LR 0.001307   
2022-11-25 10:40:07,511 - INFO  - Training [19][  160/  196]   Loss 0.452708   Top1 84.318848   Top5 98.322754   BatchTime 0.382805   LR 0.001287   
2022-11-25 10:40:14,787 - INFO  - Training [19][  180/  196]   Loss 0.453015   Top1 84.316406   Top5 98.279080   BatchTime 0.380697   LR 0.001266   
2022-11-25 10:40:20,542 - INFO  - ==> Top1: 84.408    Top5: 98.294    Loss: 0.451

2022-11-25 10:40:20,819 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:40:22,099 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:40:27,081 - INFO  - Validation [19][   20/   40]   Loss 0.357969   Top1 88.359375   Top5 99.492188   BatchTime 0.248993   
2022-11-25 10:40:28,467 - INFO  - Validation [19][   40/   40]   Loss 0.343824   Top1 88.670000   Top5 99.640000   BatchTime 0.159153   
2022-11-25 10:40:28,701 - INFO  - ==> Top1: 88.670    Top5: 99.640    Loss: 0.344

2022-11-25 10:40:28,702 - INFO  - ==> Sparsity : 0.392

2022-11-25 10:40:28,702 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 88.670   Top5: 99.640]
2022-11-25 10:40:28,702 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 88.510   Top5: 99.630]
2022-11-25 10:40:28,702 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 88.270   Top5: 99.610]
2022-11-25 10:40:33,952 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:40:33,957 - INFO  - >>>>>> Epoch  20
2022-11-25 10:40:33,960 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:40:43,621 - INFO  - Training [20][   20/  196]   Loss 0.469215   Top1 83.398438   Top5 97.851562   BatchTime 0.482916   LR 0.001231   
2022-11-25 10:40:51,218 - INFO  - Training [20][   40/  196]   Loss 0.457996   Top1 84.003906   Top5 98.183594   BatchTime 0.431387   LR 0.001211   
2022-11-25 10:40:58,306 - INFO  - Training [20][   60/  196]   Loss 0.459241   Top1 83.984375   Top5 98.183594   BatchTime 0.405720   LR 0.001191   
2022-11-25 10:41:05,823 - INFO  - Training [20][   80/  196]   Loss 0.451535   Top1 84.282227   Top5 98.305664   BatchTime 0.398251   LR 0.001171   
2022-11-25 10:41:13,355 - INFO  - Training [20][  100/  196]   Loss 0.445706   Top1 84.496094   Top5 98.371094   BatchTime 0.393923   LR 0.001151   
2022-11-25 10:41:21,516 - INFO  - Training [20][  120/  196]   Loss 0.440909   Top1 84.720052   Top5 98.427734   BatchTime 0.396275   LR 0.001131   
2022-11-25 10:41:29,592 - INFO  - Training [20][  140/  196]   Loss 0.439724   Top1 84.824219   Top5 98.493304   BatchTime 0.397353   LR 0.001111   
2022-11-25 10:41:35,718 - INFO  - Training [20][  160/  196]   Loss 0.439338   Top1 84.858398   Top5 98.496094   BatchTime 0.385968   LR 0.001091   
2022-11-25 10:41:43,218 - INFO  - Training [20][  180/  196]   Loss 0.440308   Top1 84.806858   Top5 98.450521   BatchTime 0.384751   LR 0.001071   
2022-11-25 10:41:49,619 - INFO  - ==> Top1: 84.880    Top5: 98.462    Loss: 0.438

2022-11-25 10:41:49,887 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:41:51,949 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:41:54,282 - INFO  - Validation [20][   20/   40]   Loss 0.367513   Top1 87.851562   Top5 99.492188   BatchTime 0.116547   
2022-11-25 10:41:55,247 - INFO  - Validation [20][   40/   40]   Loss 0.351042   Top1 88.330000   Top5 99.590000   BatchTime 0.082398   
2022-11-25 10:41:55,494 - INFO  - ==> Top1: 88.330    Top5: 99.590    Loss: 0.351

2022-11-25 10:41:55,494 - INFO  - ==> Sparsity : 0.392

2022-11-25 10:41:55,495 - INFO  - Scoreboard best 1 ==> Epoch [19][Top1: 88.670   Top5: 99.640]
2022-11-25 10:41:55,495 - INFO  - Scoreboard best 2 ==> Epoch [18][Top1: 88.510   Top5: 99.630]
2022-11-25 10:41:55,495 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 88.330   Top5: 99.590]
2022-11-25 10:41:55,635 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:41:55,637 - INFO  - >>>>>> Epoch  21
2022-11-25 10:41:55,639 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:42:04,096 - INFO  - Training [21][   20/  196]   Loss 0.445382   Top1 84.589844   Top5 97.929688   BatchTime 0.422705   LR 0.001036   
2022-11-25 10:42:11,416 - INFO  - Training [21][   40/  196]   Loss 0.447071   Top1 84.335938   Top5 98.251953   BatchTime 0.394349   LR 0.001016   
2022-11-25 10:42:18,923 - INFO  - Training [21][   60/  196]   Loss 0.433985   Top1 84.986979   Top5 98.320312   BatchTime 0.388022   LR 0.000996   
2022-11-25 10:42:27,283 - INFO  - Training [21][   80/  196]   Loss 0.435243   Top1 85.053711   Top5 98.403320   BatchTime 0.395509   LR 0.000976   
2022-11-25 10:42:34,839 - INFO  - Training [21][  100/  196]   Loss 0.428257   Top1 85.316406   Top5 98.449219   BatchTime 0.391977   LR 0.000957   
2022-11-25 10:42:42,193 - INFO  - Training [21][  120/  196]   Loss 0.422254   Top1 85.530599   Top5 98.551432   BatchTime 0.387923   LR 0.000937   
2022-11-25 10:42:49,415 - INFO  - Training [21][  140/  196]   Loss 0.420220   Top1 85.577567   Top5 98.593750   BatchTime 0.384094   LR 0.000918   
2022-11-25 10:42:55,976 - INFO  - Training [21][  160/  196]   Loss 0.425690   Top1 85.339355   Top5 98.554688   BatchTime 0.377089   LR 0.000899   
2022-11-25 10:43:02,589 - INFO  - Training [21][  180/  196]   Loss 0.423650   Top1 85.397135   Top5 98.489583   BatchTime 0.371927   LR 0.000879   
2022-11-25 10:43:09,511 - INFO  - ==> Top1: 85.432    Top5: 98.478    Loss: 0.423

2022-11-25 10:43:09,771 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:43:11,251 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:43:13,694 - INFO  - Validation [21][   20/   40]   Loss 0.325849   Top1 89.296875   Top5 99.667969   BatchTime 0.122077   
2022-11-25 10:43:14,816 - INFO  - Validation [21][   40/   40]   Loss 0.319558   Top1 89.200000   Top5 99.690000   BatchTime 0.089085   
2022-11-25 10:43:15,050 - INFO  - ==> Top1: 89.200    Top5: 99.690    Loss: 0.320

2022-11-25 10:43:15,050 - INFO  - ==> Sparsity : 0.397

2022-11-25 10:43:15,050 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 89.200   Top5: 99.690]
2022-11-25 10:43:15,050 - INFO  - Scoreboard best 2 ==> Epoch [19][Top1: 88.670   Top5: 99.640]
2022-11-25 10:43:15,051 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 88.510   Top5: 99.630]
2022-11-25 10:43:20,429 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:43:20,431 - INFO  - >>>>>> Epoch  22
2022-11-25 10:43:20,433 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:43:29,175 - INFO  - Training [22][   20/  196]   Loss 0.420040   Top1 85.507812   Top5 97.910156   BatchTime 0.436945   LR 0.000846   
2022-11-25 10:43:36,524 - INFO  - Training [22][   40/  196]   Loss 0.423975   Top1 85.224609   Top5 98.173828   BatchTime 0.402220   LR 0.000827   
2022-11-25 10:43:43,859 - INFO  - Training [22][   60/  196]   Loss 0.423357   Top1 85.221354   Top5 98.313802   BatchTime 0.390390   LR 0.000808   
2022-11-25 10:43:51,215 - INFO  - Training [22][   80/  196]   Loss 0.422206   Top1 85.322266   Top5 98.354492   BatchTime 0.384737   LR 0.000789   
2022-11-25 10:43:58,931 - INFO  - Training [22][  100/  196]   Loss 0.418612   Top1 85.449219   Top5 98.410156   BatchTime 0.384953   LR 0.000770   
2022-11-25 10:44:06,355 - INFO  - Training [22][  120/  196]   Loss 0.411987   Top1 85.755208   Top5 98.535156   BatchTime 0.382660   LR 0.000752   
2022-11-25 10:44:12,874 - INFO  - Training [22][  140/  196]   Loss 0.406062   Top1 85.917969   Top5 98.607701   BatchTime 0.374553   LR 0.000734   
2022-11-25 10:44:19,576 - INFO  - Training [22][  160/  196]   Loss 0.410509   Top1 85.834961   Top5 98.571777   BatchTime 0.369623   LR 0.000715   
2022-11-25 10:44:27,763 - INFO  - Training [22][  180/  196]   Loss 0.410319   Top1 85.863715   Top5 98.513455   BatchTime 0.374035   LR 0.000697   
2022-11-25 10:44:34,632 - INFO  - ==> Top1: 85.892    Top5: 98.512    Loss: 0.409

2022-11-25 10:44:34,895 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:44:36,609 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:44:38,993 - INFO  - Validation [22][   20/   40]   Loss 0.357326   Top1 88.183594   Top5 99.472656   BatchTime 0.119099   
2022-11-25 10:44:40,008 - INFO  - Validation [22][   40/   40]   Loss 0.343381   Top1 88.720000   Top5 99.580000   BatchTime 0.084924   
2022-11-25 10:44:40,256 - INFO  - ==> Top1: 88.720    Top5: 99.580    Loss: 0.343

2022-11-25 10:44:40,256 - INFO  - ==> Sparsity : 0.396

2022-11-25 10:44:40,256 - INFO  - Scoreboard best 1 ==> Epoch [21][Top1: 89.200   Top5: 99.690]
2022-11-25 10:44:40,256 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 88.720   Top5: 99.580]
2022-11-25 10:44:40,257 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 88.670   Top5: 99.640]
2022-11-25 10:44:40,404 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:44:40,406 - INFO  - >>>>>> Epoch  23
2022-11-25 10:44:40,408 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:44:49,662 - INFO  - Training [23][   20/  196]   Loss 0.411218   Top1 85.585938   Top5 97.929688   BatchTime 0.462555   LR 0.000666   
2022-11-25 10:44:57,561 - INFO  - Training [23][   40/  196]   Loss 0.425322   Top1 85.146484   Top5 98.154297   BatchTime 0.428770   LR 0.000648   
2022-11-25 10:45:05,003 - INFO  - Training [23][   60/  196]   Loss 0.413648   Top1 85.605469   Top5 98.307292   BatchTime 0.409868   LR 0.000630   
2022-11-25 10:45:12,519 - INFO  - Training [23][   80/  196]   Loss 0.411300   Top1 85.732422   Top5 98.432617   BatchTime 0.401347   LR 0.000613   
2022-11-25 10:45:19,820 - INFO  - Training [23][  100/  196]   Loss 0.406310   Top1 85.976562   Top5 98.523438   BatchTime 0.394088   LR 0.000596   
2022-11-25 10:45:27,295 - INFO  - Training [23][  120/  196]   Loss 0.397564   Top1 86.253255   Top5 98.629557   BatchTime 0.390699   LR 0.000579   
2022-11-25 10:45:33,774 - INFO  - Training [23][  140/  196]   Loss 0.397335   Top1 86.367188   Top5 98.660714   BatchTime 0.381160   LR 0.000562   
2022-11-25 10:45:40,966 - INFO  - Training [23][  160/  196]   Loss 0.398754   Top1 86.315918   Top5 98.630371   BatchTime 0.378466   LR 0.000545   
2022-11-25 10:45:48,131 - INFO  - Training [23][  180/  196]   Loss 0.398482   Top1 86.336806   Top5 98.563368   BatchTime 0.376218   LR 0.000529   
2022-11-25 10:45:54,288 - INFO  - ==> Top1: 86.386    Top5: 98.576    Loss: 0.397

2022-11-25 10:45:54,595 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:45:56,676 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:45:59,207 - INFO  - Validation [23][   20/   40]   Loss 0.338124   Top1 88.828125   Top5 99.648438   BatchTime 0.126439   
2022-11-25 10:46:00,340 - INFO  - Validation [23][   40/   40]   Loss 0.325468   Top1 89.320000   Top5 99.720000   BatchTime 0.091562   
2022-11-25 10:46:00,591 - INFO  - ==> Top1: 89.320    Top5: 99.720    Loss: 0.325

2022-11-25 10:46:00,591 - INFO  - ==> Sparsity : 0.401

2022-11-25 10:46:00,592 - INFO  - Scoreboard best 1 ==> Epoch [23][Top1: 89.320   Top5: 99.720]
2022-11-25 10:46:00,592 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 89.200   Top5: 99.690]
2022-11-25 10:46:00,592 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 88.720   Top5: 99.580]
2022-11-25 10:46:06,344 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:46:06,348 - INFO  - >>>>>> Epoch  24
2022-11-25 10:46:06,351 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:46:15,812 - INFO  - Training [24][   20/  196]   Loss 0.401203   Top1 86.093750   Top5 98.203125   BatchTime 0.472949   LR 0.000500   
2022-11-25 10:46:23,475 - INFO  - Training [24][   40/  196]   Loss 0.410441   Top1 85.810547   Top5 98.251953   BatchTime 0.428037   LR 0.000484   
2022-11-25 10:46:30,747 - INFO  - Training [24][   60/  196]   Loss 0.402985   Top1 86.113281   Top5 98.391927   BatchTime 0.406560   LR 0.000468   
2022-11-25 10:46:37,934 - INFO  - Training [24][   80/  196]   Loss 0.398649   Top1 86.406250   Top5 98.500977   BatchTime 0.394756   LR 0.000453   
2022-11-25 10:46:45,072 - INFO  - Training [24][  100/  196]   Loss 0.390720   Top1 86.671875   Top5 98.593750   BatchTime 0.387186   LR 0.000437   
2022-11-25 10:46:51,497 - INFO  - Training [24][  120/  196]   Loss 0.382020   Top1 86.894531   Top5 98.694661   BatchTime 0.376198   LR 0.000422   
2022-11-25 10:46:58,157 - INFO  - Training [24][  140/  196]   Loss 0.380605   Top1 86.983817   Top5 98.722098   BatchTime 0.370024   LR 0.000407   
2022-11-25 10:47:04,879 - INFO  - Training [24][  160/  196]   Loss 0.382767   Top1 86.904297   Top5 98.696289   BatchTime 0.365785   LR 0.000392   
2022-11-25 10:47:12,762 - INFO  - Training [24][  180/  196]   Loss 0.384076   Top1 86.870660   Top5 98.611111   BatchTime 0.368933   LR 0.000378   
2022-11-25 10:47:19,391 - INFO  - ==> Top1: 86.878    Top5: 98.618    Loss: 0.385

2022-11-25 10:47:19,644 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:47:21,255 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:47:23,850 - INFO  - Validation [24][   20/   40]   Loss 0.313710   Top1 89.667969   Top5 99.648438   BatchTime 0.129665   
2022-11-25 10:47:24,896 - INFO  - Validation [24][   40/   40]   Loss 0.302890   Top1 90.050000   Top5 99.690000   BatchTime 0.090979   
2022-11-25 10:47:25,152 - INFO  - ==> Top1: 90.050    Top5: 99.690    Loss: 0.303

2022-11-25 10:47:25,152 - INFO  - ==> Sparsity : 0.400

2022-11-25 10:47:25,152 - INFO  - Scoreboard best 1 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 10:47:25,152 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 89.320   Top5: 99.720]
2022-11-25 10:47:25,153 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 89.200   Top5: 99.690]
2022-11-25 10:47:31,111 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:47:31,115 - INFO  - >>>>>> Epoch  25
2022-11-25 10:47:31,117 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:47:39,583 - INFO  - Training [25][   20/  196]   Loss 0.408135   Top1 85.781250   Top5 98.144531   BatchTime 0.423155   LR 0.000353   
2022-11-25 10:47:47,012 - INFO  - Training [25][   40/  196]   Loss 0.402913   Top1 86.250000   Top5 98.222656   BatchTime 0.397294   LR 0.000339   
2022-11-25 10:47:54,287 - INFO  - Training [25][   60/  196]   Loss 0.394685   Top1 86.490885   Top5 98.365885   BatchTime 0.386115   LR 0.000325   
2022-11-25 10:48:01,569 - INFO  - Training [25][   80/  196]   Loss 0.392868   Top1 86.459961   Top5 98.413086   BatchTime 0.380617   LR 0.000312   
2022-11-25 10:48:08,827 - INFO  - Training [25][  100/  196]   Loss 0.389861   Top1 86.503906   Top5 98.460938   BatchTime 0.377071   LR 0.000299   
2022-11-25 10:48:15,807 - INFO  - Training [25][  120/  196]   Loss 0.382625   Top1 86.813151   Top5 98.531901   BatchTime 0.372387   LR 0.000286   
2022-11-25 10:48:22,372 - INFO  - Training [25][  140/  196]   Loss 0.380297   Top1 86.958705   Top5 98.643973   BatchTime 0.366085   LR 0.000273   
2022-11-25 10:48:29,821 - INFO  - Training [25][  160/  196]   Loss 0.382739   Top1 86.850586   Top5 98.620605   BatchTime 0.366878   LR 0.000261   
2022-11-25 10:48:37,451 - INFO  - Training [25][  180/  196]   Loss 0.381504   Top1 86.896701   Top5 98.565538   BatchTime 0.368503   LR 0.000248   
2022-11-25 10:48:43,789 - INFO  - ==> Top1: 86.968    Top5: 98.594    Loss: 0.379

2022-11-25 10:48:44,107 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:48:46,239 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:48:48,677 - INFO  - Validation [25][   20/   40]   Loss 0.304888   Top1 89.824219   Top5 99.707031   BatchTime 0.121792   
2022-11-25 10:48:49,696 - INFO  - Validation [25][   40/   40]   Loss 0.289028   Top1 90.260000   Top5 99.770000   BatchTime 0.086382   
2022-11-25 10:48:49,931 - INFO  - ==> Top1: 90.260    Top5: 99.770    Loss: 0.289

2022-11-25 10:48:49,931 - INFO  - ==> Sparsity : 0.406

2022-11-25 10:48:49,932 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 10:48:49,932 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 10:48:49,932 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 89.320   Top5: 99.720]
2022-11-25 10:48:56,376 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 10:48:56,379 - INFO  - >>>>>> Epoch  26
2022-11-25 10:48:56,380 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:49:05,738 - INFO  - Training [26][   20/  196]   Loss 0.421328   Top1 85.175781   Top5 97.968750   BatchTime 0.467757   LR 0.000228   
2022-11-25 10:49:13,207 - INFO  - Training [26][   40/  196]   Loss 0.406565   Top1 85.664062   Top5 98.144531   BatchTime 0.420587   LR 0.000216   
2022-11-25 10:49:20,598 - INFO  - Training [26][   60/  196]   Loss 0.399281   Top1 86.087240   Top5 98.229167   BatchTime 0.403587   LR 0.000205   
2022-11-25 10:49:27,955 - INFO  - Training [26][   80/  196]   Loss 0.396187   Top1 86.191406   Top5 98.393555   BatchTime 0.394645   LR 0.000194   
2022-11-25 10:49:34,571 - INFO  - Training [26][  100/  196]   Loss 0.388397   Top1 86.433594   Top5 98.480469   BatchTime 0.381880   LR 0.000183   
2022-11-25 10:49:41,298 - INFO  - Training [26][  120/  196]   Loss 0.379053   Top1 86.835938   Top5 98.593750   BatchTime 0.374292   LR 0.000173   
2022-11-25 10:49:48,751 - INFO  - Training [26][  140/  196]   Loss 0.377647   Top1 86.905692   Top5 98.674665   BatchTime 0.374052   LR 0.000163   
2022-11-25 10:49:56,164 - INFO  - Training [26][  160/  196]   Loss 0.377500   Top1 86.857910   Top5 98.684082   BatchTime 0.373628   LR 0.000153   
2022-11-25 10:50:03,467 - INFO  - Training [26][  180/  196]   Loss 0.378077   Top1 86.879340   Top5 98.634983   BatchTime 0.372683   LR 0.000144   
2022-11-25 10:50:10,062 - INFO  - ==> Top1: 86.992    Top5: 98.646    Loss: 0.374

2022-11-25 10:50:10,332 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:50:11,881 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:50:14,280 - INFO  - Validation [26][   20/   40]   Loss 0.311913   Top1 89.882812   Top5 99.667969   BatchTime 0.119835   
2022-11-25 10:50:15,311 - INFO  - Validation [26][   40/   40]   Loss 0.300653   Top1 90.010000   Top5 99.700000   BatchTime 0.085701   
2022-11-25 10:50:15,542 - INFO  - ==> Top1: 90.010    Top5: 99.700    Loss: 0.301

2022-11-25 10:50:15,542 - INFO  - ==> Sparsity : 0.414

2022-11-25 10:50:15,542 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 10:50:15,542 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 10:50:15,543 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 90.010   Top5: 99.700]
2022-11-25 10:50:15,676 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:50:15,678 - INFO  - >>>>>> Epoch  27
2022-11-25 10:50:15,680 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:50:25,493 - INFO  - Training [27][   20/  196]   Loss 0.385675   Top1 86.132812   Top5 98.007812   BatchTime 0.490513   LR 0.000128   
2022-11-25 10:50:33,407 - INFO  - Training [27][   40/  196]   Loss 0.394264   Top1 86.132812   Top5 98.232422   BatchTime 0.443121   LR 0.000119   
2022-11-25 10:50:41,586 - INFO  - Training [27][   60/  196]   Loss 0.386860   Top1 86.627604   Top5 98.294271   BatchTime 0.431733   LR 0.000111   
2022-11-25 10:50:49,284 - INFO  - Training [27][   80/  196]   Loss 0.381161   Top1 86.811523   Top5 98.457031   BatchTime 0.420024   LR 0.000102   
2022-11-25 10:50:56,014 - INFO  - Training [27][  100/  196]   Loss 0.378157   Top1 86.933594   Top5 98.515625   BatchTime 0.403314   LR 0.000095   
2022-11-25 10:51:03,257 - INFO  - Training [27][  120/  196]   Loss 0.370409   Top1 87.164714   Top5 98.606771   BatchTime 0.396454   LR 0.000087   
2022-11-25 10:51:10,534 - INFO  - Training [27][  140/  196]   Loss 0.367715   Top1 87.148438   Top5 98.691406   BatchTime 0.391793   LR 0.000080   
2022-11-25 10:51:17,776 - INFO  - Training [27][  160/  196]   Loss 0.371430   Top1 87.075195   Top5 98.664551   BatchTime 0.388080   LR 0.000073   
2022-11-25 10:51:25,474 - INFO  - Training [27][  180/  196]   Loss 0.371349   Top1 87.109375   Top5 98.613281   BatchTime 0.387723   LR 0.000066   
2022-11-25 10:51:31,598 - INFO  - ==> Top1: 87.256    Top5: 98.616    Loss: 0.368

2022-11-25 10:51:31,863 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:51:34,810 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:51:37,345 - INFO  - Validation [27][   20/   40]   Loss 0.309267   Top1 89.804688   Top5 99.687500   BatchTime 0.126644   
2022-11-25 10:51:38,354 - INFO  - Validation [27][   40/   40]   Loss 0.297128   Top1 90.020000   Top5 99.770000   BatchTime 0.088564   
2022-11-25 10:51:38,620 - INFO  - ==> Top1: 90.020    Top5: 99.770    Loss: 0.297

2022-11-25 10:51:38,620 - INFO  - ==> Sparsity : 0.437

2022-11-25 10:51:38,620 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 10:51:38,621 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 10:51:38,621 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 10:51:38,765 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:51:38,767 - INFO  - >>>>>> Epoch  28
2022-11-25 10:51:38,769 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:51:47,635 - INFO  - Training [28][   20/  196]   Loss 0.384133   Top1 86.093750   Top5 98.066406   BatchTime 0.443196   LR 0.000055   
2022-11-25 10:51:54,785 - INFO  - Training [28][   40/  196]   Loss 0.384726   Top1 86.123047   Top5 98.349609   BatchTime 0.400341   LR 0.000050   
2022-11-25 10:52:02,160 - INFO  - Training [28][   60/  196]   Loss 0.373034   Top1 86.946615   Top5 98.463542   BatchTime 0.389802   LR 0.000044   
2022-11-25 10:52:08,942 - INFO  - Training [28][   80/  196]   Loss 0.369822   Top1 87.099609   Top5 98.535156   BatchTime 0.377129   LR 0.000039   
2022-11-25 10:52:15,437 - INFO  - Training [28][  100/  196]   Loss 0.364378   Top1 87.246094   Top5 98.585938   BatchTime 0.366653   LR 0.000034   
2022-11-25 10:52:22,572 - INFO  - Training [28][  120/  196]   Loss 0.359158   Top1 87.389323   Top5 98.649089   BatchTime 0.365003   LR 0.000030   
2022-11-25 10:52:29,781 - INFO  - Training [28][  140/  196]   Loss 0.358665   Top1 87.477679   Top5 98.705357   BatchTime 0.364351   LR 0.000026   
2022-11-25 10:52:37,574 - INFO  - Training [28][  160/  196]   Loss 0.364284   Top1 87.290039   Top5 98.723145   BatchTime 0.367510   LR 0.000022   
2022-11-25 10:52:44,806 - INFO  - Training [28][  180/  196]   Loss 0.363907   Top1 87.341580   Top5 98.674045   BatchTime 0.366853   LR 0.000018   
2022-11-25 10:52:50,882 - INFO  - ==> Top1: 87.388    Top5: 98.676    Loss: 0.363

2022-11-25 10:52:51,216 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:52:53,434 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:52:56,097 - INFO  - Validation [28][   20/   40]   Loss 0.307897   Top1 89.746094   Top5 99.726562   BatchTime 0.133073   
2022-11-25 10:52:57,367 - INFO  - Validation [28][   40/   40]   Loss 0.306066   Top1 89.660000   Top5 99.760000   BatchTime 0.098287   
2022-11-25 10:52:57,961 - INFO  - ==> Top1: 89.660    Top5: 99.760    Loss: 0.306

2022-11-25 10:52:57,961 - INFO  - ==> Sparsity : 0.433

2022-11-25 10:52:57,962 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 10:52:57,962 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 10:52:57,962 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 10:52:58,107 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:52:58,109 - INFO  - >>>>>> Epoch  29
2022-11-25 10:52:58,111 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:53:07,235 - INFO  - Training [29][   20/  196]   Loss 0.373492   Top1 86.718750   Top5 98.222656   BatchTime 0.456080   LR 0.000013   
2022-11-25 10:53:14,493 - INFO  - Training [29][   40/  196]   Loss 0.381787   Top1 86.699219   Top5 98.457031   BatchTime 0.409493   LR 0.000010   
2022-11-25 10:53:22,346 - INFO  - Training [29][   60/  196]   Loss 0.372230   Top1 87.005208   Top5 98.567708   BatchTime 0.403873   LR 0.000008   
2022-11-25 10:53:28,940 - INFO  - Training [29][   80/  196]   Loss 0.364924   Top1 87.275391   Top5 98.662109   BatchTime 0.385330   LR 0.000005   
2022-11-25 10:53:35,446 - INFO  - Training [29][  100/  196]   Loss 0.359243   Top1 87.460938   Top5 98.707031   BatchTime 0.373320   LR 0.000004   
2022-11-25 10:53:42,448 - INFO  - Training [29][  120/  196]   Loss 0.355658   Top1 87.620443   Top5 98.772786   BatchTime 0.369447   LR 0.000002   
2022-11-25 10:53:49,752 - INFO  - Training [29][  140/  196]   Loss 0.355127   Top1 87.589286   Top5 98.811384   BatchTime 0.368840   LR 0.000001   
2022-11-25 10:53:56,500 - INFO  - Training [29][  160/  196]   Loss 0.359397   Top1 87.456055   Top5 98.798828   BatchTime 0.364909   LR 0.000001   
2022-11-25 10:54:03,354 - INFO  - Training [29][  180/  196]   Loss 0.359717   Top1 87.508681   Top5 98.743490   BatchTime 0.362445   LR 0.000000   
2022-11-25 10:54:09,321 - INFO  - ==> Top1: 87.540    Top5: 98.758    Loss: 0.358

2022-11-25 10:54:09,583 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:54:11,077 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:54:13,447 - INFO  - Validation [29][   20/   40]   Loss 0.314034   Top1 89.707031   Top5 99.648438   BatchTime 0.118387   
2022-11-25 10:54:14,433 - INFO  - Validation [29][   40/   40]   Loss 0.303550   Top1 89.890000   Top5 99.730000   BatchTime 0.083859   
2022-11-25 10:54:14,705 - INFO  - ==> Top1: 89.890    Top5: 99.730    Loss: 0.304

2022-11-25 10:54:14,705 - INFO  - ==> Sparsity : 0.433

2022-11-25 10:54:14,705 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 10:54:14,705 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 10:54:14,706 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 10:54:14,823 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:54:14,825 - INFO  - >>>>>> Epoch  30
2022-11-25 10:54:14,826 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:54:23,567 - INFO  - Training [30][   20/  196]   Loss 0.420817   Top1 85.605469   Top5 98.281250   BatchTime 0.436908   LR 0.001250   
2022-11-25 10:54:31,551 - INFO  - Training [30][   40/  196]   Loss 0.420412   Top1 85.478516   Top5 98.310547   BatchTime 0.418046   LR 0.001250   
2022-11-25 10:54:38,728 - INFO  - Training [30][   60/  196]   Loss 0.419787   Top1 85.677083   Top5 98.372396   BatchTime 0.398321   LR 0.001250   
2022-11-25 10:54:46,108 - INFO  - Training [30][   80/  196]   Loss 0.419258   Top1 85.625000   Top5 98.476562   BatchTime 0.390986   LR 0.001250   
2022-11-25 10:54:52,701 - INFO  - Training [30][  100/  196]   Loss 0.415226   Top1 85.777344   Top5 98.476562   BatchTime 0.378717   LR 0.001250   
2022-11-25 10:54:59,294 - INFO  - Training [30][  120/  196]   Loss 0.410471   Top1 85.914714   Top5 98.554688   BatchTime 0.370538   LR 0.001249   
2022-11-25 10:55:06,726 - INFO  - Training [30][  140/  196]   Loss 0.410056   Top1 85.943080   Top5 98.607701   BatchTime 0.370693   LR 0.001249   
2022-11-25 10:55:13,839 - INFO  - Training [30][  160/  196]   Loss 0.414223   Top1 85.769043   Top5 98.623047   BatchTime 0.368811   LR 0.001249   
2022-11-25 10:55:21,233 - INFO  - Training [30][  180/  196]   Loss 0.416908   Top1 85.705295   Top5 98.608941   BatchTime 0.368907   LR 0.001248   
2022-11-25 10:55:27,487 - INFO  - ==> Top1: 85.758    Top5: 98.596    Loss: 0.416

2022-11-25 10:55:27,882 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:55:29,757 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:55:32,247 - INFO  - Validation [30][   20/   40]   Loss 0.345083   Top1 88.261719   Top5 99.648438   BatchTime 0.124398   
2022-11-25 10:55:33,232 - INFO  - Validation [30][   40/   40]   Loss 0.330353   Top1 88.630000   Top5 99.750000   BatchTime 0.086824   
2022-11-25 10:55:33,483 - INFO  - ==> Top1: 88.630    Top5: 99.750    Loss: 0.330

2022-11-25 10:55:33,484 - INFO  - ==> Sparsity : 0.393

2022-11-25 10:55:33,484 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 10:55:33,484 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 10:55:33,484 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 10:55:33,640 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:55:33,641 - INFO  - >>>>>> Epoch  31
2022-11-25 10:55:33,643 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:55:42,965 - INFO  - Training [31][   20/  196]   Loss 0.426160   Top1 85.234375   Top5 98.085938   BatchTime 0.465926   LR 0.001248   
2022-11-25 10:55:50,291 - INFO  - Training [31][   40/  196]   Loss 0.430597   Top1 85.273438   Top5 98.222656   BatchTime 0.416118   LR 0.001247   
2022-11-25 10:55:57,790 - INFO  - Training [31][   60/  196]   Loss 0.427908   Top1 85.449219   Top5 98.326823   BatchTime 0.402394   LR 0.001247   
2022-11-25 10:56:05,806 - INFO  - Training [31][   80/  196]   Loss 0.424464   Top1 85.522461   Top5 98.496094   BatchTime 0.401995   LR 0.001246   
2022-11-25 10:56:13,042 - INFO  - Training [31][  100/  196]   Loss 0.418345   Top1 85.644531   Top5 98.535156   BatchTime 0.393955   LR 0.001246   
2022-11-25 10:56:19,874 - INFO  - Training [31][  120/  196]   Loss 0.413312   Top1 85.807292   Top5 98.597005   BatchTime 0.385232   LR 0.001245   
2022-11-25 10:56:27,326 - INFO  - Training [31][  140/  196]   Loss 0.411020   Top1 85.851004   Top5 98.657924   BatchTime 0.383423   LR 0.001244   
2022-11-25 10:56:34,375 - INFO  - Training [31][  160/  196]   Loss 0.414513   Top1 85.764160   Top5 98.645020   BatchTime 0.379550   LR 0.001244   
2022-11-25 10:56:41,598 - INFO  - Training [31][  180/  196]   Loss 0.417128   Top1 85.674913   Top5 98.585069   BatchTime 0.377507   LR 0.001243   
2022-11-25 10:56:47,799 - INFO  - ==> Top1: 85.606    Top5: 98.570    Loss: 0.418

2022-11-25 10:56:48,076 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:56:49,745 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:56:52,081 - INFO  - Validation [31][   20/   40]   Loss 0.359478   Top1 88.339844   Top5 99.433594   BatchTime 0.116669   
2022-11-25 10:56:53,006 - INFO  - Validation [31][   40/   40]   Loss 0.353686   Top1 87.960000   Top5 99.570000   BatchTime 0.081468   
2022-11-25 10:56:53,500 - INFO  - ==> Top1: 87.960    Top5: 99.570    Loss: 0.354

2022-11-25 10:56:53,500 - INFO  - ==> Sparsity : 0.372

2022-11-25 10:56:53,501 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 10:56:53,501 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 10:56:53,501 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 10:56:53,848 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:56:53,850 - INFO  - >>>>>> Epoch  32
2022-11-25 10:56:53,851 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:57:03,203 - INFO  - Training [32][   20/  196]   Loss 0.422652   Top1 85.175781   Top5 97.968750   BatchTime 0.467415   LR 0.001242   
2022-11-25 10:57:11,045 - INFO  - Training [32][   40/  196]   Loss 0.421598   Top1 85.380859   Top5 98.125000   BatchTime 0.429793   LR 0.001241   
2022-11-25 10:57:18,570 - INFO  - Training [32][   60/  196]   Loss 0.422120   Top1 85.397135   Top5 98.242188   BatchTime 0.411934   LR 0.001240   
2022-11-25 10:57:25,846 - INFO  - Training [32][   80/  196]   Loss 0.421528   Top1 85.463867   Top5 98.383789   BatchTime 0.399899   LR 0.001239   
2022-11-25 10:57:31,982 - INFO  - Training [32][  100/  196]   Loss 0.414576   Top1 85.687500   Top5 98.437500   BatchTime 0.381275   LR 0.001238   
2022-11-25 10:57:37,997 - INFO  - Training [32][  120/  196]   Loss 0.408157   Top1 85.901693   Top5 98.525391   BatchTime 0.367856   LR 0.001237   
2022-11-25 10:57:45,290 - INFO  - Training [32][  140/  196]   Loss 0.408563   Top1 85.917969   Top5 98.630022   BatchTime 0.367398   LR 0.001236   
2022-11-25 10:57:52,532 - INFO  - Training [32][  160/  196]   Loss 0.413989   Top1 85.727539   Top5 98.593750   BatchTime 0.366733   LR 0.001235   
2022-11-25 10:57:59,885 - INFO  - Training [32][  180/  196]   Loss 0.414668   Top1 85.733507   Top5 98.537326   BatchTime 0.366837   LR 0.001234   
2022-11-25 10:58:05,808 - INFO  - ==> Top1: 85.744    Top5: 98.542    Loss: 0.414

2022-11-25 10:58:06,044 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:58:07,473 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:58:09,889 - INFO  - Validation [32][   20/   40]   Loss 0.332951   Top1 89.492188   Top5 99.648438   BatchTime 0.120714   
2022-11-25 10:58:10,924 - INFO  - Validation [32][   40/   40]   Loss 0.315379   Top1 89.540000   Top5 99.720000   BatchTime 0.086245   
2022-11-25 10:58:11,139 - INFO  - ==> Top1: 89.540    Top5: 99.720    Loss: 0.315

2022-11-25 10:58:11,139 - INFO  - ==> Sparsity : 0.377

2022-11-25 10:58:11,139 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 10:58:11,139 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 10:58:11,140 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 10:58:11,292 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:58:11,294 - INFO  - >>>>>> Epoch  33
2022-11-25 10:58:11,297 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:58:20,202 - INFO  - Training [33][   20/  196]   Loss 0.428061   Top1 85.839844   Top5 98.164062   BatchTime 0.445030   LR 0.001232   
2022-11-25 10:58:27,615 - INFO  - Training [33][   40/  196]   Loss 0.418307   Top1 85.830078   Top5 98.330078   BatchTime 0.407841   LR 0.001230   
2022-11-25 10:58:35,842 - INFO  - Training [33][   60/  196]   Loss 0.417574   Top1 85.690104   Top5 98.404948   BatchTime 0.409005   LR 0.001229   
2022-11-25 10:58:43,275 - INFO  - Training [33][   80/  196]   Loss 0.417663   Top1 85.673828   Top5 98.520508   BatchTime 0.399667   LR 0.001228   
2022-11-25 10:58:50,220 - INFO  - Training [33][  100/  196]   Loss 0.415690   Top1 85.703125   Top5 98.578125   BatchTime 0.389190   LR 0.001226   
2022-11-25 10:58:56,747 - INFO  - Training [33][  120/  196]   Loss 0.406649   Top1 86.025391   Top5 98.649089   BatchTime 0.378716   LR 0.001225   
2022-11-25 10:59:04,341 - INFO  - Training [33][  140/  196]   Loss 0.405535   Top1 86.079799   Top5 98.705357   BatchTime 0.378851   LR 0.001224   
2022-11-25 10:59:11,564 - INFO  - Training [33][  160/  196]   Loss 0.409083   Top1 85.939941   Top5 98.684082   BatchTime 0.376638   LR 0.001222   
2022-11-25 10:59:18,854 - INFO  - Training [33][  180/  196]   Loss 0.409883   Top1 85.935330   Top5 98.598090   BatchTime 0.375292   LR 0.001221   
2022-11-25 10:59:24,921 - INFO  - ==> Top1: 85.932    Top5: 98.592    Loss: 0.410

2022-11-25 10:59:25,291 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:59:27,189 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:59:30,333 - INFO  - Validation [33][   20/   40]   Loss 0.352649   Top1 88.300781   Top5 99.589844   BatchTime 0.157136   
2022-11-25 10:59:31,501 - INFO  - Validation [33][   40/   40]   Loss 0.348396   Top1 88.220000   Top5 99.650000   BatchTime 0.107755   
2022-11-25 10:59:31,742 - INFO  - ==> Top1: 88.220    Top5: 99.650    Loss: 0.348

2022-11-25 10:59:31,742 - INFO  - ==> Sparsity : 0.382

2022-11-25 10:59:31,743 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 10:59:31,743 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 10:59:31,743 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 10:59:31,878 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 10:59:31,879 - INFO  - >>>>>> Epoch  34
2022-11-25 10:59:31,881 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:59:41,053 - INFO  - Training [34][   20/  196]   Loss 0.429380   Top1 85.410156   Top5 98.222656   BatchTime 0.458470   LR 0.001218   
2022-11-25 10:59:49,018 - INFO  - Training [34][   40/  196]   Loss 0.420962   Top1 85.761719   Top5 98.281250   BatchTime 0.428351   LR 0.001216   
2022-11-25 10:59:56,596 - INFO  - Training [34][   60/  196]   Loss 0.415825   Top1 86.002604   Top5 98.411458   BatchTime 0.411866   LR 0.001215   
2022-11-25 11:00:03,749 - INFO  - Training [34][   80/  196]   Loss 0.411614   Top1 86.083984   Top5 98.569336   BatchTime 0.398314   LR 0.001213   
2022-11-25 11:00:10,721 - INFO  - Training [34][  100/  196]   Loss 0.402466   Top1 86.207031   Top5 98.613281   BatchTime 0.388364   LR 0.001211   
2022-11-25 11:00:16,413 - INFO  - Training [34][  120/  196]   Loss 0.396428   Top1 86.402995   Top5 98.675130   BatchTime 0.371069   LR 0.001209   
2022-11-25 11:00:23,234 - INFO  - Training [34][  140/  196]   Loss 0.396271   Top1 86.386719   Top5 98.730469   BatchTime 0.366782   LR 0.001208   
2022-11-25 11:00:31,466 - INFO  - Training [34][  160/  196]   Loss 0.403360   Top1 86.191406   Top5 98.703613   BatchTime 0.372384   LR 0.001206   
2022-11-25 11:00:38,989 - INFO  - Training [34][  180/  196]   Loss 0.404504   Top1 86.180556   Top5 98.630642   BatchTime 0.372800   LR 0.001204   
2022-11-25 11:00:44,945 - INFO  - ==> Top1: 86.182    Top5: 98.624    Loss: 0.405

2022-11-25 11:00:45,268 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:00:46,952 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:00:49,610 - INFO  - Validation [34][   20/   40]   Loss 0.343786   Top1 88.945312   Top5 99.589844   BatchTime 0.132761   
2022-11-25 11:00:50,850 - INFO  - Validation [34][   40/   40]   Loss 0.333341   Top1 88.990000   Top5 99.620000   BatchTime 0.097390   
2022-11-25 11:00:51,450 - INFO  - ==> Top1: 88.990    Top5: 99.620    Loss: 0.333

2022-11-25 11:00:51,450 - INFO  - ==> Sparsity : 0.372

2022-11-25 11:00:51,450 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:00:51,451 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:00:51,451 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 11:00:51,595 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:00:51,597 - INFO  - >>>>>> Epoch  35
2022-11-25 11:00:51,599 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:01:00,554 - INFO  - Training [35][   20/  196]   Loss 0.403765   Top1 85.820312   Top5 98.164062   BatchTime 0.447602   LR 0.001201   
2022-11-25 11:01:08,788 - INFO  - Training [35][   40/  196]   Loss 0.413949   Top1 85.693359   Top5 98.330078   BatchTime 0.429662   LR 0.001199   
2022-11-25 11:01:16,380 - INFO  - Training [35][   60/  196]   Loss 0.406640   Top1 85.800781   Top5 98.365885   BatchTime 0.412961   LR 0.001197   
2022-11-25 11:01:24,011 - INFO  - Training [35][   80/  196]   Loss 0.407169   Top1 85.883789   Top5 98.535156   BatchTime 0.405117   LR 0.001195   
2022-11-25 11:01:31,324 - INFO  - Training [35][  100/  196]   Loss 0.397872   Top1 86.218750   Top5 98.613281   BatchTime 0.397217   LR 0.001192   
2022-11-25 11:01:37,907 - INFO  - Training [35][  120/  196]   Loss 0.391729   Top1 86.422526   Top5 98.668620   BatchTime 0.385869   LR 0.001190   
2022-11-25 11:01:44,962 - INFO  - Training [35][  140/  196]   Loss 0.392976   Top1 86.411830   Top5 98.691406   BatchTime 0.381142   LR 0.001188   
2022-11-25 11:01:52,335 - INFO  - Training [35][  160/  196]   Loss 0.398960   Top1 86.230469   Top5 98.681641   BatchTime 0.379580   LR 0.001186   
2022-11-25 11:01:59,736 - INFO  - Training [35][  180/  196]   Loss 0.398416   Top1 86.158854   Top5 98.630642   BatchTime 0.378519   LR 0.001184   
2022-11-25 11:02:06,052 - INFO  - ==> Top1: 86.184    Top5: 98.658    Loss: 0.398

2022-11-25 11:02:06,310 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:02:07,814 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:02:11,145 - INFO  - Validation [35][   20/   40]   Loss 0.326096   Top1 89.257812   Top5 99.648438   BatchTime 0.166403   
2022-11-25 11:02:12,421 - INFO  - Validation [35][   40/   40]   Loss 0.310085   Top1 89.580000   Top5 99.740000   BatchTime 0.115119   
2022-11-25 11:02:12,667 - INFO  - ==> Top1: 89.580    Top5: 99.740    Loss: 0.310

2022-11-25 11:02:12,667 - INFO  - ==> Sparsity : 0.375

2022-11-25 11:02:12,668 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:02:12,668 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:02:12,668 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 11:02:12,802 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:02:12,804 - INFO  - >>>>>> Epoch  36
2022-11-25 11:02:12,806 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:02:21,707 - INFO  - Training [36][   20/  196]   Loss 0.408726   Top1 85.703125   Top5 98.085938   BatchTime 0.444928   LR 0.001180   
2022-11-25 11:02:29,342 - INFO  - Training [36][   40/  196]   Loss 0.402633   Top1 85.849609   Top5 98.281250   BatchTime 0.413327   LR 0.001177   
2022-11-25 11:02:37,238 - INFO  - Training [36][   60/  196]   Loss 0.403472   Top1 85.865885   Top5 98.457031   BatchTime 0.407153   LR 0.001175   
2022-11-25 11:02:44,436 - INFO  - Training [36][   80/  196]   Loss 0.404418   Top1 86.030273   Top5 98.554688   BatchTime 0.395339   LR 0.001173   
2022-11-25 11:02:50,807 - INFO  - Training [36][  100/  196]   Loss 0.401529   Top1 86.238281   Top5 98.562500   BatchTime 0.379978   LR 0.001170   
2022-11-25 11:02:56,871 - INFO  - Training [36][  120/  196]   Loss 0.396080   Top1 86.422526   Top5 98.619792   BatchTime 0.367184   LR 0.001168   
2022-11-25 11:03:02,580 - INFO  - Training [36][  140/  196]   Loss 0.396526   Top1 86.492746   Top5 98.671875   BatchTime 0.355508   LR 0.001165   
2022-11-25 11:03:09,802 - INFO  - Training [36][  160/  196]   Loss 0.399942   Top1 86.384277   Top5 98.610840   BatchTime 0.356204   LR 0.001163   
2022-11-25 11:03:17,198 - INFO  - Training [36][  180/  196]   Loss 0.399625   Top1 86.443142   Top5 98.572049   BatchTime 0.357718   LR 0.001160   
2022-11-25 11:03:23,148 - INFO  - ==> Top1: 86.458    Top5: 98.552    Loss: 0.399

2022-11-25 11:03:23,399 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:03:24,887 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:03:27,642 - INFO  - Validation [36][   20/   40]   Loss 0.326512   Top1 89.453125   Top5 99.531250   BatchTime 0.137643   
2022-11-25 11:03:29,667 - INFO  - Validation [36][   40/   40]   Loss 0.323294   Top1 89.150000   Top5 99.650000   BatchTime 0.119465   
2022-11-25 11:03:30,295 - INFO  - ==> Top1: 89.150    Top5: 99.650    Loss: 0.323

2022-11-25 11:03:30,295 - INFO  - ==> Sparsity : 0.369

2022-11-25 11:03:30,296 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:03:30,296 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:03:30,296 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 11:03:30,680 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:03:30,682 - INFO  - >>>>>> Epoch  37
2022-11-25 11:03:30,685 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:03:40,039 - INFO  - Training [37][   20/  196]   Loss 0.417512   Top1 85.683594   Top5 98.046875   BatchTime 0.467521   LR 0.001155   
2022-11-25 11:03:47,694 - INFO  - Training [37][   40/  196]   Loss 0.407779   Top1 85.888672   Top5 98.310547   BatchTime 0.425129   LR 0.001153   
2022-11-25 11:03:55,019 - INFO  - Training [37][   60/  196]   Loss 0.405812   Top1 86.048177   Top5 98.372396   BatchTime 0.405501   LR 0.001150   
2022-11-25 11:04:02,657 - INFO  - Training [37][   80/  196]   Loss 0.402807   Top1 86.176758   Top5 98.491211   BatchTime 0.399599   LR 0.001147   
2022-11-25 11:04:10,851 - INFO  - Training [37][  100/  196]   Loss 0.394106   Top1 86.511719   Top5 98.546875   BatchTime 0.401614   LR 0.001144   
2022-11-25 11:04:17,880 - INFO  - Training [37][  120/  196]   Loss 0.392443   Top1 86.471354   Top5 98.629557   BatchTime 0.393253   LR 0.001142   
2022-11-25 11:04:24,194 - INFO  - Training [37][  140/  196]   Loss 0.392109   Top1 86.462054   Top5 98.657924   BatchTime 0.382176   LR 0.001139   
2022-11-25 11:04:30,914 - INFO  - Training [37][  160/  196]   Loss 0.391872   Top1 86.489258   Top5 98.645020   BatchTime 0.376405   LR 0.001136   
2022-11-25 11:04:38,385 - INFO  - Training [37][  180/  196]   Loss 0.392280   Top1 86.475694   Top5 98.582899   BatchTime 0.376086   LR 0.001133   
2022-11-25 11:04:44,897 - INFO  - ==> Top1: 86.488    Top5: 98.606    Loss: 0.392

2022-11-25 11:04:45,133 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:04:46,636 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:04:49,138 - INFO  - Validation [37][   20/   40]   Loss 0.349943   Top1 88.847656   Top5 99.707031   BatchTime 0.124955   
2022-11-25 11:04:50,267 - INFO  - Validation [37][   40/   40]   Loss 0.333781   Top1 89.230000   Top5 99.730000   BatchTime 0.090732   
2022-11-25 11:04:50,489 - INFO  - ==> Top1: 89.230    Top5: 99.730    Loss: 0.334

2022-11-25 11:04:50,489 - INFO  - ==> Sparsity : 0.368

2022-11-25 11:04:50,490 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:04:50,490 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:04:50,490 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 11:04:50,637 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:04:50,638 - INFO  - >>>>>> Epoch  38
2022-11-25 11:04:50,640 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:05:00,483 - INFO  - Training [38][   20/  196]   Loss 0.410103   Top1 85.468750   Top5 98.437500   BatchTime 0.492012   LR 0.001128   
2022-11-25 11:05:07,880 - INFO  - Training [38][   40/  196]   Loss 0.404611   Top1 85.986328   Top5 98.476562   BatchTime 0.430941   LR 0.001125   
2022-11-25 11:05:15,002 - INFO  - Training [38][   60/  196]   Loss 0.401906   Top1 85.904948   Top5 98.593750   BatchTime 0.405986   LR 0.001122   
2022-11-25 11:05:22,723 - INFO  - Training [38][   80/  196]   Loss 0.405009   Top1 85.913086   Top5 98.686523   BatchTime 0.401005   LR 0.001119   
2022-11-25 11:05:30,070 - INFO  - Training [38][  100/  196]   Loss 0.394872   Top1 86.234375   Top5 98.765625   BatchTime 0.394267   LR 0.001116   
2022-11-25 11:05:36,604 - INFO  - Training [38][  120/  196]   Loss 0.388716   Top1 86.448568   Top5 98.789062   BatchTime 0.383007   LR 0.001112   
2022-11-25 11:05:42,422 - INFO  - Training [38][  140/  196]   Loss 0.386557   Top1 86.587612   Top5 98.819754   BatchTime 0.369847   LR 0.001109   
2022-11-25 11:05:48,830 - INFO  - Training [38][  160/  196]   Loss 0.389831   Top1 86.494141   Top5 98.803711   BatchTime 0.363667   LR 0.001106   
2022-11-25 11:05:56,099 - INFO  - Training [38][  180/  196]   Loss 0.391420   Top1 86.449653   Top5 98.743490   BatchTime 0.363643   LR 0.001103   
2022-11-25 11:06:01,994 - INFO  - ==> Top1: 86.554    Top5: 98.728    Loss: 0.389

2022-11-25 11:06:02,250 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:06:03,926 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:06:06,413 - INFO  - Validation [38][   20/   40]   Loss 0.365499   Top1 87.812500   Top5 99.589844   BatchTime 0.124252   
2022-11-25 11:06:07,581 - INFO  - Validation [38][   40/   40]   Loss 0.353403   Top1 88.170000   Top5 99.650000   BatchTime 0.091340   
2022-11-25 11:06:07,866 - INFO  - ==> Top1: 88.170    Top5: 99.650    Loss: 0.353

2022-11-25 11:06:07,866 - INFO  - ==> Sparsity : 0.376

2022-11-25 11:06:07,867 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:06:07,867 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:06:07,867 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 11:06:07,999 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:06:08,000 - INFO  - >>>>>> Epoch  39
2022-11-25 11:06:08,002 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:06:17,319 - INFO  - Training [39][   20/  196]   Loss 0.398739   Top1 85.781250   Top5 98.125000   BatchTime 0.465713   LR 0.001097   
2022-11-25 11:06:25,267 - INFO  - Training [39][   40/  196]   Loss 0.401025   Top1 86.181641   Top5 98.320312   BatchTime 0.431574   LR 0.001094   
2022-11-25 11:06:32,631 - INFO  - Training [39][   60/  196]   Loss 0.399612   Top1 86.230469   Top5 98.430990   BatchTime 0.410440   LR 0.001090   
2022-11-25 11:06:40,015 - INFO  - Training [39][   80/  196]   Loss 0.399709   Top1 86.337891   Top5 98.486328   BatchTime 0.400130   LR 0.001087   
2022-11-25 11:06:47,343 - INFO  - Training [39][  100/  196]   Loss 0.391445   Top1 86.492188   Top5 98.585938   BatchTime 0.393385   LR 0.001084   
2022-11-25 11:06:54,410 - INFO  - Training [39][  120/  196]   Loss 0.384663   Top1 86.722005   Top5 98.681641   BatchTime 0.386712   LR 0.001080   
2022-11-25 11:07:00,820 - INFO  - Training [39][  140/  196]   Loss 0.381251   Top1 86.827567   Top5 98.744420   BatchTime 0.377248   LR 0.001077   
2022-11-25 11:07:07,964 - INFO  - Training [39][  160/  196]   Loss 0.384174   Top1 86.718750   Top5 98.725586   BatchTime 0.374747   LR 0.001073   
2022-11-25 11:07:14,999 - INFO  - Training [39][  180/  196]   Loss 0.384359   Top1 86.681858   Top5 98.637153   BatchTime 0.372190   LR 0.001070   
2022-11-25 11:07:20,773 - INFO  - ==> Top1: 86.688    Top5: 98.640    Loss: 0.384

2022-11-25 11:07:21,073 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:07:22,670 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:07:25,245 - INFO  - Validation [39][   20/   40]   Loss 0.340920   Top1 88.652344   Top5 99.531250   BatchTime 0.128614   
2022-11-25 11:07:26,387 - INFO  - Validation [39][   40/   40]   Loss 0.330011   Top1 89.020000   Top5 99.620000   BatchTime 0.092877   
2022-11-25 11:07:26,650 - INFO  - ==> Top1: 89.020    Top5: 99.620    Loss: 0.330

2022-11-25 11:07:26,650 - INFO  - ==> Sparsity : 0.414

2022-11-25 11:07:26,650 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:07:26,651 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:07:26,651 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 11:07:26,772 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:07:26,773 - INFO  - >>>>>> Epoch  40
2022-11-25 11:07:26,775 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:07:36,444 - INFO  - Training [40][   20/  196]   Loss 0.398540   Top1 85.996094   Top5 98.046875   BatchTime 0.483313   LR 0.001064   
2022-11-25 11:07:44,296 - INFO  - Training [40][   40/  196]   Loss 0.406255   Top1 85.966797   Top5 98.105469   BatchTime 0.437967   LR 0.001060   
2022-11-25 11:07:51,794 - INFO  - Training [40][   60/  196]   Loss 0.398185   Top1 86.341146   Top5 98.294271   BatchTime 0.416949   LR 0.001056   
2022-11-25 11:07:59,251 - INFO  - Training [40][   80/  196]   Loss 0.396350   Top1 86.474609   Top5 98.437500   BatchTime 0.405917   LR 0.001053   
2022-11-25 11:08:06,460 - INFO  - Training [40][  100/  196]   Loss 0.388104   Top1 86.757812   Top5 98.527344   BatchTime 0.396825   LR 0.001049   
2022-11-25 11:08:13,260 - INFO  - Training [40][  120/  196]   Loss 0.384176   Top1 86.923828   Top5 98.623047   BatchTime 0.387350   LR 0.001045   
2022-11-25 11:08:20,219 - INFO  - Training [40][  140/  196]   Loss 0.381167   Top1 87.031250   Top5 98.691406   BatchTime 0.381724   LR 0.001042   
2022-11-25 11:08:27,458 - INFO  - Training [40][  160/  196]   Loss 0.381552   Top1 86.945801   Top5 98.669434   BatchTime 0.379247   LR 0.001038   
2022-11-25 11:08:34,935 - INFO  - Training [40][  180/  196]   Loss 0.380929   Top1 86.944444   Top5 98.632812   BatchTime 0.378648   LR 0.001034   
2022-11-25 11:08:41,266 - INFO  - ==> Top1: 86.940    Top5: 98.668    Loss: 0.380

2022-11-25 11:08:41,563 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:08:43,195 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:08:45,609 - INFO  - Validation [40][   20/   40]   Loss 0.354855   Top1 88.632812   Top5 99.511719   BatchTime 0.120609   
2022-11-25 11:08:46,666 - INFO  - Validation [40][   40/   40]   Loss 0.349518   Top1 88.730000   Top5 99.590000   BatchTime 0.086738   
2022-11-25 11:08:46,886 - INFO  - ==> Top1: 88.730    Top5: 99.590    Loss: 0.350

2022-11-25 11:08:46,886 - INFO  - ==> Sparsity : 0.370

2022-11-25 11:08:46,886 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:08:46,886 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:08:46,887 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 11:08:47,006 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:08:47,007 - INFO  - >>>>>> Epoch  41
2022-11-25 11:08:47,009 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:08:56,377 - INFO  - Training [41][   20/  196]   Loss 0.405993   Top1 85.859375   Top5 97.890625   BatchTime 0.468267   LR 0.001027   
2022-11-25 11:09:03,816 - INFO  - Training [41][   40/  196]   Loss 0.408250   Top1 85.537109   Top5 98.076172   BatchTime 0.420106   LR 0.001023   
2022-11-25 11:09:11,074 - INFO  - Training [41][   60/  196]   Loss 0.392633   Top1 86.315104   Top5 98.320312   BatchTime 0.401051   LR 0.001020   
2022-11-25 11:09:18,372 - INFO  - Training [41][   80/  196]   Loss 0.387412   Top1 86.655273   Top5 98.452148   BatchTime 0.392002   LR 0.001016   
2022-11-25 11:09:25,501 - INFO  - Training [41][  100/  196]   Loss 0.380273   Top1 86.890625   Top5 98.535156   BatchTime 0.384895   LR 0.001012   
2022-11-25 11:09:31,596 - INFO  - Training [41][  120/  196]   Loss 0.376263   Top1 87.167969   Top5 98.616536   BatchTime 0.371537   LR 0.001008   
2022-11-25 11:09:38,319 - INFO  - Training [41][  140/  196]   Loss 0.375991   Top1 87.117746   Top5 98.646763   BatchTime 0.366479   LR 0.001004   
2022-11-25 11:09:45,577 - INFO  - Training [41][  160/  196]   Loss 0.381072   Top1 86.882324   Top5 98.640137   BatchTime 0.366034   LR 0.001000   
2022-11-25 11:09:52,803 - INFO  - Training [41][  180/  196]   Loss 0.380896   Top1 86.840278   Top5 98.589410   BatchTime 0.365505   LR 0.000996   
2022-11-25 11:09:58,730 - INFO  - ==> Top1: 86.874    Top5: 98.604    Loss: 0.379

2022-11-25 11:09:58,970 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:10:00,418 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:10:02,900 - INFO  - Validation [41][   20/   40]   Loss 0.324865   Top1 89.140625   Top5 99.687500   BatchTime 0.124015   
2022-11-25 11:10:03,914 - INFO  - Validation [41][   40/   40]   Loss 0.304587   Top1 89.800000   Top5 99.700000   BatchTime 0.087347   
2022-11-25 11:10:04,161 - INFO  - ==> Top1: 89.800    Top5: 99.700    Loss: 0.305

2022-11-25 11:10:04,162 - INFO  - ==> Sparsity : 0.375

2022-11-25 11:10:04,162 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:10:04,162 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:10:04,162 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 11:10:04,473 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:10:04,475 - INFO  - >>>>>> Epoch  42
2022-11-25 11:10:04,477 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:10:13,444 - INFO  - Training [42][   20/  196]   Loss 0.379504   Top1 87.031250   Top5 98.105469   BatchTime 0.448243   LR 0.000988   
2022-11-25 11:10:21,362 - INFO  - Training [42][   40/  196]   Loss 0.385215   Top1 86.933594   Top5 98.349609   BatchTime 0.422068   LR 0.000984   
2022-11-25 11:10:28,976 - INFO  - Training [42][   60/  196]   Loss 0.379163   Top1 86.979167   Top5 98.528646   BatchTime 0.408277   LR 0.000980   
2022-11-25 11:10:36,482 - INFO  - Training [42][   80/  196]   Loss 0.377265   Top1 87.060547   Top5 98.637695   BatchTime 0.400027   LR 0.000976   
2022-11-25 11:10:42,911 - INFO  - Training [42][  100/  196]   Loss 0.367009   Top1 87.468750   Top5 98.667969   BatchTime 0.384316   LR 0.000972   
2022-11-25 11:10:49,796 - INFO  - Training [42][  120/  196]   Loss 0.364041   Top1 87.483724   Top5 98.753255   BatchTime 0.377632   LR 0.000968   
2022-11-25 11:10:57,012 - INFO  - Training [42][  140/  196]   Loss 0.362263   Top1 87.586496   Top5 98.800223   BatchTime 0.375230   LR 0.000964   
2022-11-25 11:11:04,258 - INFO  - Training [42][  160/  196]   Loss 0.367529   Top1 87.463379   Top5 98.737793   BatchTime 0.373611   LR 0.000959   
2022-11-25 11:11:11,532 - INFO  - Training [42][  180/  196]   Loss 0.366827   Top1 87.456597   Top5 98.704427   BatchTime 0.372513   LR 0.000955   
2022-11-25 11:11:17,342 - INFO  - ==> Top1: 87.448    Top5: 98.726    Loss: 0.366

2022-11-25 11:11:17,594 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:11:19,086 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:11:21,565 - INFO  - Validation [42][   20/   40]   Loss 0.330424   Top1 89.375000   Top5 99.609375   BatchTime 0.123860   
2022-11-25 11:11:22,624 - INFO  - Validation [42][   40/   40]   Loss 0.314757   Top1 89.500000   Top5 99.710000   BatchTime 0.088425   
2022-11-25 11:11:22,860 - INFO  - ==> Top1: 89.500    Top5: 99.710    Loss: 0.315

2022-11-25 11:11:22,860 - INFO  - ==> Sparsity : 0.364

2022-11-25 11:11:22,860 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:11:22,860 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:11:22,860 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 11:11:22,979 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:11:22,981 - INFO  - >>>>>> Epoch  43
2022-11-25 11:11:22,982 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:11:31,819 - INFO  - Training [43][   20/  196]   Loss 0.390308   Top1 86.679688   Top5 98.027344   BatchTime 0.441701   LR 0.000947   
2022-11-25 11:11:39,435 - INFO  - Training [43][   40/  196]   Loss 0.390212   Top1 86.757812   Top5 98.349609   BatchTime 0.411255   LR 0.000943   
2022-11-25 11:11:47,080 - INFO  - Training [43][   60/  196]   Loss 0.384725   Top1 86.842448   Top5 98.457031   BatchTime 0.401576   LR 0.000939   
2022-11-25 11:11:54,358 - INFO  - Training [43][   80/  196]   Loss 0.380114   Top1 87.006836   Top5 98.569336   BatchTime 0.392166   LR 0.000934   
2022-11-25 11:12:01,041 - INFO  - Training [43][  100/  196]   Loss 0.374641   Top1 87.253906   Top5 98.570312   BatchTime 0.380555   LR 0.000930   
2022-11-25 11:12:08,063 - INFO  - Training [43][  120/  196]   Loss 0.366296   Top1 87.513021   Top5 98.701172   BatchTime 0.375652   LR 0.000926   
2022-11-25 11:12:15,785 - INFO  - Training [43][  140/  196]   Loss 0.367241   Top1 87.500000   Top5 98.741629   BatchTime 0.377144   LR 0.000921   
2022-11-25 11:12:23,342 - INFO  - Training [43][  160/  196]   Loss 0.370059   Top1 87.321777   Top5 98.737793   BatchTime 0.377229   LR 0.000917   
2022-11-25 11:12:30,670 - INFO  - Training [43][  180/  196]   Loss 0.370130   Top1 87.341580   Top5 98.665365   BatchTime 0.376027   LR 0.000912   
2022-11-25 11:12:36,512 - INFO  - ==> Top1: 87.400    Top5: 98.676    Loss: 0.370

2022-11-25 11:12:36,997 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:12:39,049 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:12:41,395 - INFO  - Validation [43][   20/   40]   Loss 0.351703   Top1 88.632812   Top5 99.511719   BatchTime 0.117220   
2022-11-25 11:12:42,510 - INFO  - Validation [43][   40/   40]   Loss 0.348670   Top1 88.540000   Top5 99.560000   BatchTime 0.086485   
2022-11-25 11:12:42,782 - INFO  - ==> Top1: 88.540    Top5: 99.560    Loss: 0.349

2022-11-25 11:12:42,782 - INFO  - ==> Sparsity : 0.371

2022-11-25 11:12:42,783 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:12:42,783 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:12:42,783 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 90.020   Top5: 99.770]
2022-11-25 11:12:42,900 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:12:42,902 - INFO  - >>>>>> Epoch  44
2022-11-25 11:12:42,904 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:12:52,214 - INFO  - Training [44][   20/  196]   Loss 0.376552   Top1 86.679688   Top5 98.222656   BatchTime 0.465382   LR 0.000904   
2022-11-25 11:12:59,934 - INFO  - Training [44][   40/  196]   Loss 0.370755   Top1 87.041016   Top5 98.300781   BatchTime 0.425694   LR 0.000900   
2022-11-25 11:13:06,674 - INFO  - Training [44][   60/  196]   Loss 0.367773   Top1 87.096354   Top5 98.430990   BatchTime 0.396130   LR 0.000895   
2022-11-25 11:13:12,838 - INFO  - Training [44][   80/  196]   Loss 0.365590   Top1 87.236328   Top5 98.598633   BatchTime 0.374146   LR 0.000891   
2022-11-25 11:13:18,979 - INFO  - Training [44][  100/  196]   Loss 0.359324   Top1 87.453125   Top5 98.621094   BatchTime 0.360723   LR 0.000886   
2022-11-25 11:13:24,521 - INFO  - Training [44][  120/  196]   Loss 0.353189   Top1 87.711589   Top5 98.701172   BatchTime 0.346783   LR 0.000882   
2022-11-25 11:13:30,908 - INFO  - Training [44][  140/  196]   Loss 0.352747   Top1 87.700893   Top5 98.761161   BatchTime 0.342865   LR 0.000877   
2022-11-25 11:13:37,350 - INFO  - Training [44][  160/  196]   Loss 0.354686   Top1 87.680664   Top5 98.757324   BatchTime 0.340272   LR 0.000873   
2022-11-25 11:13:42,936 - INFO  - Training [44][  180/  196]   Loss 0.357343   Top1 87.580295   Top5 98.715278   BatchTime 0.333496   LR 0.000868   
2022-11-25 11:13:47,736 - INFO  - ==> Top1: 87.610    Top5: 98.716    Loss: 0.357

2022-11-25 11:13:47,948 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:13:49,325 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:13:51,755 - INFO  - Validation [44][   20/   40]   Loss 0.305038   Top1 90.332031   Top5 99.550781   BatchTime 0.121394   
2022-11-25 11:13:52,720 - INFO  - Validation [44][   40/   40]   Loss 0.296886   Top1 90.100000   Top5 99.670000   BatchTime 0.084823   
2022-11-25 11:13:53,166 - INFO  - ==> Top1: 90.100    Top5: 99.670    Loss: 0.297

2022-11-25 11:13:53,166 - INFO  - ==> Sparsity : 0.376

2022-11-25 11:13:53,167 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:13:53,167 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.100   Top5: 99.670]
2022-11-25 11:13:53,167 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:13:53,292 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:13:53,294 - INFO  - >>>>>> Epoch  45
2022-11-25 11:13:53,295 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:14:00,268 - INFO  - Training [45][   20/  196]   Loss 0.365878   Top1 86.660156   Top5 98.437500   BatchTime 0.348494   LR 0.000860   
2022-11-25 11:14:05,551 - INFO  - Training [45][   40/  196]   Loss 0.371869   Top1 87.089844   Top5 98.369141   BatchTime 0.306311   LR 0.000855   
2022-11-25 11:14:11,928 - INFO  - Training [45][   60/  196]   Loss 0.367639   Top1 87.246094   Top5 98.593750   BatchTime 0.310501   LR 0.000850   
2022-11-25 11:14:17,066 - INFO  - Training [45][   80/  196]   Loss 0.366578   Top1 87.553711   Top5 98.691406   BatchTime 0.297098   LR 0.000846   
2022-11-25 11:14:22,725 - INFO  - Training [45][  100/  196]   Loss 0.359707   Top1 87.792969   Top5 98.730469   BatchTime 0.294268   LR 0.000841   
2022-11-25 11:14:28,394 - INFO  - Training [45][  120/  196]   Loss 0.354679   Top1 87.942708   Top5 98.795573   BatchTime 0.292465   LR 0.000836   
2022-11-25 11:14:34,042 - INFO  - Training [45][  140/  196]   Loss 0.353499   Top1 87.949219   Top5 98.822545   BatchTime 0.291021   LR 0.000832   
2022-11-25 11:14:39,984 - INFO  - Training [45][  160/  196]   Loss 0.356260   Top1 87.890625   Top5 98.798828   BatchTime 0.291781   LR 0.000827   
2022-11-25 11:14:45,547 - INFO  - Training [45][  180/  196]   Loss 0.357948   Top1 87.799479   Top5 98.741319   BatchTime 0.290268   LR 0.000822   
2022-11-25 11:14:50,260 - INFO  - ==> Top1: 87.892    Top5: 98.752    Loss: 0.356

2022-11-25 11:14:50,495 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:14:51,779 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:14:54,497 - INFO  - Validation [45][   20/   40]   Loss 0.347077   Top1 88.750000   Top5 99.609375   BatchTime 0.135807   
2022-11-25 11:14:55,644 - INFO  - Validation [45][   40/   40]   Loss 0.338282   Top1 88.920000   Top5 99.690000   BatchTime 0.096573   
2022-11-25 11:14:55,871 - INFO  - ==> Top1: 88.920    Top5: 99.690    Loss: 0.338

2022-11-25 11:14:55,871 - INFO  - ==> Sparsity : 0.378

2022-11-25 11:14:55,871 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:14:55,872 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.100   Top5: 99.670]
2022-11-25 11:14:55,872 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:14:55,989 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:14:55,991 - INFO  - >>>>>> Epoch  46
2022-11-25 11:14:55,992 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:15:03,454 - INFO  - Training [46][   20/  196]   Loss 0.359151   Top1 87.851562   Top5 98.183594   BatchTime 0.372983   LR 0.000814   
2022-11-25 11:15:08,469 - INFO  - Training [46][   40/  196]   Loss 0.358650   Top1 87.929688   Top5 98.378906   BatchTime 0.311857   LR 0.000809   
2022-11-25 11:15:14,419 - INFO  - Training [46][   60/  196]   Loss 0.355912   Top1 87.942708   Top5 98.483073   BatchTime 0.307064   LR 0.000804   
2022-11-25 11:15:19,943 - INFO  - Training [46][   80/  196]   Loss 0.353100   Top1 88.041992   Top5 98.618164   BatchTime 0.299352   LR 0.000799   
2022-11-25 11:15:25,425 - INFO  - Training [46][  100/  196]   Loss 0.349228   Top1 88.136719   Top5 98.726562   BatchTime 0.294304   LR 0.000794   
2022-11-25 11:15:30,453 - INFO  - Training [46][  120/  196]   Loss 0.341667   Top1 88.486328   Top5 98.776042   BatchTime 0.287146   LR 0.000789   
2022-11-25 11:15:35,785 - INFO  - Training [46][  140/  196]   Loss 0.343188   Top1 88.468192   Top5 98.803013   BatchTime 0.284209   LR 0.000785   
2022-11-25 11:15:41,519 - INFO  - Training [46][  160/  196]   Loss 0.349028   Top1 88.244629   Top5 98.789062   BatchTime 0.284524   LR 0.000780   
2022-11-25 11:15:47,328 - INFO  - Training [46][  180/  196]   Loss 0.349213   Top1 88.203125   Top5 98.715278   BatchTime 0.285183   LR 0.000775   
2022-11-25 11:15:52,021 - INFO  - ==> Top1: 88.192    Top5: 98.718    Loss: 0.349

2022-11-25 11:15:52,292 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:15:53,669 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:15:56,071 - INFO  - Validation [46][   20/   40]   Loss 0.449373   Top1 85.917969   Top5 99.218750   BatchTime 0.120005   
2022-11-25 11:15:57,135 - INFO  - Validation [46][   40/   40]   Loss 0.435945   Top1 85.990000   Top5 99.370000   BatchTime 0.086611   
2022-11-25 11:15:57,347 - INFO  - ==> Top1: 85.990    Top5: 99.370    Loss: 0.436

2022-11-25 11:15:57,347 - INFO  - ==> Sparsity : 0.381

2022-11-25 11:15:57,348 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:15:57,348 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.100   Top5: 99.670]
2022-11-25 11:15:57,348 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:15:57,691 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:15:57,692 - INFO  - >>>>>> Epoch  47
2022-11-25 11:15:57,694 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:16:04,256 - INFO  - Training [47][   20/  196]   Loss 0.372879   Top1 86.933594   Top5 98.359375   BatchTime 0.327971   LR 0.000766   
2022-11-25 11:16:09,812 - INFO  - Training [47][   40/  196]   Loss 0.365471   Top1 87.314453   Top5 98.476562   BatchTime 0.302876   LR 0.000761   
2022-11-25 11:16:15,217 - INFO  - Training [47][   60/  196]   Loss 0.354485   Top1 87.766927   Top5 98.593750   BatchTime 0.292011   LR 0.000756   
2022-11-25 11:16:20,455 - INFO  - Training [47][   80/  196]   Loss 0.356915   Top1 87.768555   Top5 98.710938   BatchTime 0.284479   LR 0.000752   
2022-11-25 11:16:26,137 - INFO  - Training [47][  100/  196]   Loss 0.350759   Top1 88.000000   Top5 98.769531   BatchTime 0.284398   LR 0.000747   
2022-11-25 11:16:31,687 - INFO  - Training [47][  120/  196]   Loss 0.345798   Top1 88.157552   Top5 98.850911   BatchTime 0.283252   LR 0.000742   
2022-11-25 11:16:37,878 - INFO  - Training [47][  140/  196]   Loss 0.342379   Top1 88.320312   Top5 98.903460   BatchTime 0.287007   LR 0.000737   
2022-11-25 11:16:44,238 - INFO  - Training [47][  160/  196]   Loss 0.346009   Top1 88.198242   Top5 98.884277   BatchTime 0.290879   LR 0.000732   
2022-11-25 11:16:49,473 - INFO  - Training [47][  180/  196]   Loss 0.346937   Top1 88.155382   Top5 98.819444   BatchTime 0.287646   LR 0.000727   
2022-11-25 11:16:54,193 - INFO  - ==> Top1: 88.308    Top5: 98.844    Loss: 0.343

2022-11-25 11:16:54,425 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:16:55,733 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:16:58,143 - INFO  - Validation [47][   20/   40]   Loss 0.359230   Top1 88.417969   Top5 99.414062   BatchTime 0.120416   
2022-11-25 11:16:59,250 - INFO  - Validation [47][   40/   40]   Loss 0.349484   Top1 88.390000   Top5 99.570000   BatchTime 0.087894   
2022-11-25 11:16:59,445 - INFO  - ==> Top1: 88.390    Top5: 99.570    Loss: 0.349

2022-11-25 11:16:59,446 - INFO  - ==> Sparsity : 0.388

2022-11-25 11:16:59,446 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:16:59,446 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.100   Top5: 99.670]
2022-11-25 11:16:59,446 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:16:59,581 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:16:59,583 - INFO  - >>>>>> Epoch  48
2022-11-25 11:16:59,584 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:17:05,852 - INFO  - Training [48][   20/  196]   Loss 0.353933   Top1 87.988281   Top5 98.164062   BatchTime 0.313240   LR 0.000718   
2022-11-25 11:17:10,820 - INFO  - Training [48][   40/  196]   Loss 0.356126   Top1 88.017578   Top5 98.388672   BatchTime 0.280833   LR 0.000713   
2022-11-25 11:17:15,893 - INFO  - Training [48][   60/  196]   Loss 0.350534   Top1 88.085938   Top5 98.522135   BatchTime 0.271766   LR 0.000708   
2022-11-25 11:17:20,964 - INFO  - Training [48][   80/  196]   Loss 0.351202   Top1 88.100586   Top5 98.662109   BatchTime 0.267208   LR 0.000703   
2022-11-25 11:17:26,753 - INFO  - Training [48][  100/  196]   Loss 0.343675   Top1 88.300781   Top5 98.734375   BatchTime 0.271661   LR 0.000698   
2022-11-25 11:17:33,041 - INFO  - Training [48][  120/  196]   Loss 0.340724   Top1 88.382161   Top5 98.782552   BatchTime 0.278780   LR 0.000693   
2022-11-25 11:17:39,579 - INFO  - Training [48][  140/  196]   Loss 0.335564   Top1 88.551897   Top5 98.836496   BatchTime 0.285656   LR 0.000688   
2022-11-25 11:17:45,778 - INFO  - Training [48][  160/  196]   Loss 0.338835   Top1 88.491211   Top5 98.813477   BatchTime 0.288694   LR 0.000683   
2022-11-25 11:17:52,035 - INFO  - Training [48][  180/  196]   Loss 0.338833   Top1 88.478733   Top5 98.739149   BatchTime 0.291372   LR 0.000678   
2022-11-25 11:17:57,487 - INFO  - ==> Top1: 88.512    Top5: 98.740    Loss: 0.339

2022-11-25 11:17:57,794 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:17:59,467 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:18:02,084 - INFO  - Validation [48][   20/   40]   Loss 0.359975   Top1 89.277344   Top5 99.609375   BatchTime 0.130752   
2022-11-25 11:18:03,215 - INFO  - Validation [48][   40/   40]   Loss 0.343832   Top1 89.550000   Top5 99.690000   BatchTime 0.093671   
2022-11-25 11:18:03,433 - INFO  - ==> Top1: 89.550    Top5: 99.690    Loss: 0.344

2022-11-25 11:18:03,433 - INFO  - ==> Sparsity : 0.387

2022-11-25 11:18:03,434 - INFO  - Scoreboard best 1 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:18:03,434 - INFO  - Scoreboard best 2 ==> Epoch [44][Top1: 90.100   Top5: 99.670]
2022-11-25 11:18:03,434 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 90.050   Top5: 99.690]
2022-11-25 11:18:03,574 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:18:03,575 - INFO  - >>>>>> Epoch  49
2022-11-25 11:18:03,577 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:18:10,764 - INFO  - Training [49][   20/  196]   Loss 0.354441   Top1 87.988281   Top5 98.320312   BatchTime 0.359186   LR 0.000669   
2022-11-25 11:18:17,791 - INFO  - Training [49][   40/  196]   Loss 0.348656   Top1 88.017578   Top5 98.564453   BatchTime 0.355268   LR 0.000664   
2022-11-25 11:18:25,000 - INFO  - Training [49][   60/  196]   Loss 0.345331   Top1 88.125000   Top5 98.587240   BatchTime 0.356999   LR 0.000659   
2022-11-25 11:18:32,102 - INFO  - Training [49][   80/  196]   Loss 0.346049   Top1 88.100586   Top5 98.715820   BatchTime 0.356526   LR 0.000654   
2022-11-25 11:18:39,816 - INFO  - Training [49][  100/  196]   Loss 0.341866   Top1 88.222656   Top5 98.765625   BatchTime 0.362359   LR 0.000649   
2022-11-25 11:18:47,453 - INFO  - Training [49][  120/  196]   Loss 0.333172   Top1 88.531901   Top5 98.857422   BatchTime 0.365606   LR 0.000644   
2022-11-25 11:18:54,582 - INFO  - Training [49][  140/  196]   Loss 0.332196   Top1 88.526786   Top5 98.909040   BatchTime 0.364295   LR 0.000639   
2022-11-25 11:19:01,850 - INFO  - Training [49][  160/  196]   Loss 0.334640   Top1 88.483887   Top5 98.894043   BatchTime 0.364184   LR 0.000634   
2022-11-25 11:19:09,234 - INFO  - Training [49][  180/  196]   Loss 0.335529   Top1 88.454861   Top5 98.845486   BatchTime 0.364743   LR 0.000629   
2022-11-25 11:19:15,258 - INFO  - ==> Top1: 88.436    Top5: 98.852    Loss: 0.335

2022-11-25 11:19:15,520 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:19:17,156 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:19:19,669 - INFO  - Validation [49][   20/   40]   Loss 0.320796   Top1 90.312500   Top5 99.687500   BatchTime 0.125542   
2022-11-25 11:19:20,735 - INFO  - Validation [49][   40/   40]   Loss 0.301251   Top1 90.470000   Top5 99.760000   BatchTime 0.089427   
2022-11-25 11:19:20,960 - INFO  - ==> Top1: 90.470    Top5: 99.760    Loss: 0.301

2022-11-25 11:19:20,961 - INFO  - ==> Sparsity : 0.387

2022-11-25 11:19:20,961 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:19:20,961 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:19:20,962 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.100   Top5: 99.670]
2022-11-25 11:19:25,872 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 11:19:25,874 - INFO  - >>>>>> Epoch  50
2022-11-25 11:19:25,876 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:19:33,876 - INFO  - Training [50][   20/  196]   Loss 0.345144   Top1 88.398438   Top5 98.535156   BatchTime 0.399863   LR 0.000620   
2022-11-25 11:19:39,508 - INFO  - Training [50][   40/  196]   Loss 0.359863   Top1 87.763672   Top5 98.505859   BatchTime 0.340747   LR 0.000615   
2022-11-25 11:19:46,862 - INFO  - Training [50][   60/  196]   Loss 0.343513   Top1 88.229167   Top5 98.717448   BatchTime 0.349724   LR 0.000610   
2022-11-25 11:19:54,353 - INFO  - Training [50][   80/  196]   Loss 0.340622   Top1 88.305664   Top5 98.872070   BatchTime 0.355930   LR 0.000605   
2022-11-25 11:20:01,802 - INFO  - Training [50][  100/  196]   Loss 0.336426   Top1 88.589844   Top5 98.878906   BatchTime 0.359230   LR 0.000600   
2022-11-25 11:20:09,309 - INFO  - Training [50][  120/  196]   Loss 0.329508   Top1 88.779297   Top5 98.958333   BatchTime 0.361922   LR 0.000595   
2022-11-25 11:20:16,437 - INFO  - Training [50][  140/  196]   Loss 0.328583   Top1 88.755580   Top5 98.978795   BatchTime 0.361127   LR 0.000590   
2022-11-25 11:20:23,448 - INFO  - Training [50][  160/  196]   Loss 0.331421   Top1 88.696289   Top5 98.955078   BatchTime 0.359807   LR 0.000585   
2022-11-25 11:20:30,763 - INFO  - Training [50][  180/  196]   Loss 0.332994   Top1 88.619792   Top5 98.912760   BatchTime 0.360466   LR 0.000580   
2022-11-25 11:20:37,380 - INFO  - ==> Top1: 88.728    Top5: 98.916    Loss: 0.331

2022-11-25 11:20:37,639 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:20:39,116 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:20:41,593 - INFO  - Validation [50][   20/   40]   Loss 0.310283   Top1 89.902344   Top5 99.570312   BatchTime 0.123791   
2022-11-25 11:20:42,700 - INFO  - Validation [50][   40/   40]   Loss 0.300859   Top1 89.920000   Top5 99.690000   BatchTime 0.089582   
2022-11-25 11:20:42,967 - INFO  - ==> Top1: 89.920    Top5: 99.690    Loss: 0.301

2022-11-25 11:20:42,967 - INFO  - ==> Sparsity : 0.418

2022-11-25 11:20:42,967 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:20:42,967 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:20:42,968 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.100   Top5: 99.670]
2022-11-25 11:20:43,116 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:20:43,118 - INFO  - >>>>>> Epoch  51
2022-11-25 11:20:43,120 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:20:51,611 - INFO  - Training [51][   20/  196]   Loss 0.322913   Top1 88.828125   Top5 98.613281   BatchTime 0.424427   LR 0.000571   
2022-11-25 11:20:58,328 - INFO  - Training [51][   40/  196]   Loss 0.337557   Top1 88.398438   Top5 98.681641   BatchTime 0.380140   LR 0.000566   
2022-11-25 11:21:05,257 - INFO  - Training [51][   60/  196]   Loss 0.333427   Top1 88.580729   Top5 98.723958   BatchTime 0.368910   LR 0.000561   
2022-11-25 11:21:12,326 - INFO  - Training [51][   80/  196]   Loss 0.329352   Top1 88.715820   Top5 98.852539   BatchTime 0.365047   LR 0.000556   
2022-11-25 11:21:19,785 - INFO  - Training [51][  100/  196]   Loss 0.323669   Top1 88.949219   Top5 98.867188   BatchTime 0.366626   LR 0.000551   
2022-11-25 11:21:27,298 - INFO  - Training [51][  120/  196]   Loss 0.319025   Top1 89.072266   Top5 98.948568   BatchTime 0.368129   LR 0.000546   
2022-11-25 11:21:34,495 - INFO  - Training [51][  140/  196]   Loss 0.319122   Top1 89.042969   Top5 99.012277   BatchTime 0.366946   LR 0.000541   
2022-11-25 11:21:42,331 - INFO  - Training [51][  160/  196]   Loss 0.323023   Top1 88.906250   Top5 98.996582   BatchTime 0.370050   LR 0.000536   
2022-11-25 11:21:50,580 - INFO  - Training [51][  180/  196]   Loss 0.323742   Top1 88.847656   Top5 98.951823   BatchTime 0.374761   LR 0.000531   
2022-11-25 11:21:56,639 - INFO  - ==> Top1: 88.804    Top5: 98.930    Loss: 0.324

2022-11-25 11:21:56,890 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:21:58,546 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:22:00,980 - INFO  - Validation [51][   20/   40]   Loss 0.333392   Top1 89.667969   Top5 99.511719   BatchTime 0.121562   
2022-11-25 11:22:02,092 - INFO  - Validation [51][   40/   40]   Loss 0.317426   Top1 89.860000   Top5 99.670000   BatchTime 0.088574   
2022-11-25 11:22:02,306 - INFO  - ==> Top1: 89.860    Top5: 99.670    Loss: 0.317

2022-11-25 11:22:02,307 - INFO  - ==> Sparsity : 0.399

2022-11-25 11:22:02,307 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:22:02,307 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:22:02,307 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.100   Top5: 99.670]
2022-11-25 11:22:02,429 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:22:02,430 - INFO  - >>>>>> Epoch  52
2022-11-25 11:22:02,432 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:22:11,160 - INFO  - Training [52][   20/  196]   Loss 0.349121   Top1 87.851562   Top5 98.359375   BatchTime 0.436261   LR 0.000523   
2022-11-25 11:22:18,443 - INFO  - Training [52][   40/  196]   Loss 0.346595   Top1 87.773438   Top5 98.613281   BatchTime 0.400210   LR 0.000518   
2022-11-25 11:22:25,662 - INFO  - Training [52][   60/  196]   Loss 0.344967   Top1 88.059896   Top5 98.691406   BatchTime 0.387116   LR 0.000513   
2022-11-25 11:22:31,569 - INFO  - Training [52][   80/  196]   Loss 0.341309   Top1 88.208008   Top5 98.813477   BatchTime 0.364174   LR 0.000508   
2022-11-25 11:22:38,506 - INFO  - Training [52][  100/  196]   Loss 0.333420   Top1 88.531250   Top5 98.800781   BatchTime 0.360712   LR 0.000503   
2022-11-25 11:22:45,797 - INFO  - Training [52][  120/  196]   Loss 0.326113   Top1 88.873698   Top5 98.893229   BatchTime 0.361349   LR 0.000498   
2022-11-25 11:22:52,976 - INFO  - Training [52][  140/  196]   Loss 0.326892   Top1 88.783482   Top5 98.920201   BatchTime 0.361004   LR 0.000493   
2022-11-25 11:23:00,127 - INFO  - Training [52][  160/  196]   Loss 0.326400   Top1 88.845215   Top5 98.913574   BatchTime 0.360571   LR 0.000488   
2022-11-25 11:23:07,594 - INFO  - Training [52][  180/  196]   Loss 0.326315   Top1 88.836806   Top5 98.891059   BatchTime 0.361994   LR 0.000483   
2022-11-25 11:23:13,738 - INFO  - ==> Top1: 88.826    Top5: 98.904    Loss: 0.326

2022-11-25 11:23:14,004 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:23:15,478 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:23:17,956 - INFO  - Validation [52][   20/   40]   Loss 0.333418   Top1 89.082031   Top5 99.531250   BatchTime 0.123796   
2022-11-25 11:23:18,956 - INFO  - Validation [52][   40/   40]   Loss 0.325737   Top1 89.430000   Top5 99.590000   BatchTime 0.086893   
2022-11-25 11:23:19,224 - INFO  - ==> Top1: 89.430    Top5: 99.590    Loss: 0.326

2022-11-25 11:23:19,224 - INFO  - ==> Sparsity : 0.411

2022-11-25 11:23:19,224 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:23:19,225 - INFO  - Scoreboard best 2 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:23:19,225 - INFO  - Scoreboard best 3 ==> Epoch [44][Top1: 90.100   Top5: 99.670]
2022-11-25 11:23:19,376 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:23:19,378 - INFO  - >>>>>> Epoch  53
2022-11-25 11:23:19,380 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:23:28,621 - INFO  - Training [53][   20/  196]   Loss 0.331182   Top1 88.828125   Top5 98.535156   BatchTime 0.461955   LR 0.000474   
2022-11-25 11:23:36,224 - INFO  - Training [53][   40/  196]   Loss 0.328379   Top1 88.964844   Top5 98.652344   BatchTime 0.421044   LR 0.000470   
2022-11-25 11:23:44,098 - INFO  - Training [53][   60/  196]   Loss 0.327903   Top1 88.906250   Top5 98.697917   BatchTime 0.411936   LR 0.000465   
2022-11-25 11:23:50,630 - INFO  - Training [53][   80/  196]   Loss 0.327369   Top1 88.930664   Top5 98.837891   BatchTime 0.390595   LR 0.000460   
2022-11-25 11:23:56,369 - INFO  - Training [53][  100/  196]   Loss 0.318912   Top1 89.152344   Top5 98.863281   BatchTime 0.369863   LR 0.000455   
2022-11-25 11:24:03,921 - INFO  - Training [53][  120/  196]   Loss 0.314892   Top1 89.270833   Top5 98.942057   BatchTime 0.371158   LR 0.000450   
2022-11-25 11:24:10,979 - INFO  - Training [53][  140/  196]   Loss 0.313495   Top1 89.347098   Top5 99.009487   BatchTime 0.368545   LR 0.000445   
2022-11-25 11:24:18,116 - INFO  - Training [53][  160/  196]   Loss 0.313109   Top1 89.301758   Top5 99.013672   BatchTime 0.367083   LR 0.000441   
2022-11-25 11:24:25,452 - INFO  - Training [53][  180/  196]   Loss 0.316862   Top1 89.205729   Top5 98.960503   BatchTime 0.367051   LR 0.000436   
2022-11-25 11:24:31,435 - INFO  - ==> Top1: 89.196    Top5: 98.964    Loss: 0.317

2022-11-25 11:24:31,669 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:24:33,139 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:24:35,580 - INFO  - Validation [53][   20/   40]   Loss 0.307161   Top1 90.585938   Top5 99.628906   BatchTime 0.121969   
2022-11-25 11:24:36,671 - INFO  - Validation [53][   40/   40]   Loss 0.290741   Top1 90.400000   Top5 99.730000   BatchTime 0.088274   
2022-11-25 11:24:36,906 - INFO  - ==> Top1: 90.400    Top5: 99.730    Loss: 0.291

2022-11-25 11:24:36,906 - INFO  - ==> Sparsity : 0.402

2022-11-25 11:24:36,906 - INFO  - Scoreboard best 1 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:24:36,906 - INFO  - Scoreboard best 2 ==> Epoch [53][Top1: 90.400   Top5: 99.730]
2022-11-25 11:24:36,907 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 90.260   Top5: 99.770]
2022-11-25 11:24:37,048 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:24:37,050 - INFO  - >>>>>> Epoch  54
2022-11-25 11:24:37,052 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:24:45,667 - INFO  - Training [54][   20/  196]   Loss 0.317820   Top1 88.808594   Top5 98.554688   BatchTime 0.430618   LR 0.000427   
2022-11-25 11:24:53,576 - INFO  - Training [54][   40/  196]   Loss 0.335416   Top1 88.330078   Top5 98.808594   BatchTime 0.413049   LR 0.000423   
2022-11-25 11:25:00,764 - INFO  - Training [54][   60/  196]   Loss 0.331709   Top1 88.463542   Top5 98.867188   BatchTime 0.395164   LR 0.000418   
2022-11-25 11:25:08,229 - INFO  - Training [54][   80/  196]   Loss 0.327031   Top1 88.696289   Top5 98.984375   BatchTime 0.389684   LR 0.000413   
2022-11-25 11:25:14,600 - INFO  - Training [54][  100/  196]   Loss 0.320969   Top1 88.929688   Top5 99.027344   BatchTime 0.375450   LR 0.000408   
2022-11-25 11:25:20,465 - INFO  - Training [54][  120/  196]   Loss 0.315820   Top1 89.153646   Top5 99.062500   BatchTime 0.361751   LR 0.000404   
2022-11-25 11:25:28,477 - INFO  - Training [54][  140/  196]   Loss 0.313428   Top1 89.229911   Top5 99.098772   BatchTime 0.367297   LR 0.000399   
2022-11-25 11:25:36,511 - INFO  - Training [54][  160/  196]   Loss 0.314668   Top1 89.204102   Top5 99.072266   BatchTime 0.371602   LR 0.000394   
2022-11-25 11:25:44,658 - INFO  - Training [54][  180/  196]   Loss 0.313611   Top1 89.251302   Top5 99.042969   BatchTime 0.375572   LR 0.000390   
2022-11-25 11:25:50,819 - INFO  - ==> Top1: 89.256    Top5: 99.036    Loss: 0.313

2022-11-25 11:25:51,113 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:25:52,759 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:25:55,765 - INFO  - Validation [54][   20/   40]   Loss 0.302886   Top1 90.234375   Top5 99.726562   BatchTime 0.150175   
2022-11-25 11:25:56,798 - INFO  - Validation [54][   40/   40]   Loss 0.296609   Top1 90.510000   Top5 99.700000   BatchTime 0.100924   
2022-11-25 11:25:57,053 - INFO  - ==> Top1: 90.510    Top5: 99.700    Loss: 0.297

2022-11-25 11:25:57,053 - INFO  - ==> Sparsity : 0.428

2022-11-25 11:25:57,054 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:25:57,054 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:25:57,054 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 90.400   Top5: 99.730]
2022-11-25 11:26:02,484 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 11:26:02,486 - INFO  - >>>>>> Epoch  55
2022-11-25 11:26:02,488 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:26:11,696 - INFO  - Training [55][   20/  196]   Loss 0.330738   Top1 88.535156   Top5 98.593750   BatchTime 0.460254   LR 0.000381   
2022-11-25 11:26:19,202 - INFO  - Training [55][   40/  196]   Loss 0.331516   Top1 88.613281   Top5 98.710938   BatchTime 0.417793   LR 0.000377   
2022-11-25 11:26:26,872 - INFO  - Training [55][   60/  196]   Loss 0.321068   Top1 88.873698   Top5 98.828125   BatchTime 0.406351   LR 0.000372   
2022-11-25 11:26:33,679 - INFO  - Training [55][   80/  196]   Loss 0.317343   Top1 88.979492   Top5 98.911133   BatchTime 0.389859   LR 0.000368   
2022-11-25 11:26:40,226 - INFO  - Training [55][  100/  196]   Loss 0.309941   Top1 89.285156   Top5 98.949219   BatchTime 0.377354   LR 0.000363   
2022-11-25 11:26:46,728 - INFO  - Training [55][  120/  196]   Loss 0.306163   Top1 89.404297   Top5 99.036458   BatchTime 0.368642   LR 0.000358   
2022-11-25 11:26:53,394 - INFO  - Training [55][  140/  196]   Loss 0.305780   Top1 89.453125   Top5 99.087612   BatchTime 0.363591   LR 0.000354   
2022-11-25 11:27:00,114 - INFO  - Training [55][  160/  196]   Loss 0.306250   Top1 89.440918   Top5 99.079590   BatchTime 0.360145   LR 0.000349   
2022-11-25 11:27:06,744 - INFO  - Training [55][  180/  196]   Loss 0.307148   Top1 89.398872   Top5 99.040799   BatchTime 0.356959   LR 0.000345   
2022-11-25 11:27:13,367 - INFO  - ==> Top1: 89.430    Top5: 99.040    Loss: 0.306

2022-11-25 11:27:13,659 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:27:15,196 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:27:17,701 - INFO  - Validation [55][   20/   40]   Loss 0.459396   Top1 86.132812   Top5 99.414062   BatchTime 0.125037   
2022-11-25 11:27:18,744 - INFO  - Validation [55][   40/   40]   Loss 0.446707   Top1 86.070000   Top5 99.460000   BatchTime 0.088611   
2022-11-25 11:27:18,989 - INFO  - ==> Top1: 86.070    Top5: 99.460    Loss: 0.447

2022-11-25 11:27:18,989 - INFO  - ==> Sparsity : 0.504

2022-11-25 11:27:18,989 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:27:18,990 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:27:18,990 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 90.400   Top5: 99.730]
2022-11-25 11:27:19,121 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:27:19,122 - INFO  - >>>>>> Epoch  56
2022-11-25 11:27:19,124 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:27:28,080 - INFO  - Training [56][   20/  196]   Loss 0.307057   Top1 89.433594   Top5 98.554688   BatchTime 0.447665   LR 0.000337   
2022-11-25 11:27:35,827 - INFO  - Training [56][   40/  196]   Loss 0.311219   Top1 89.384766   Top5 98.671875   BatchTime 0.417505   LR 0.000333   
2022-11-25 11:27:43,196 - INFO  - Training [56][   60/  196]   Loss 0.316325   Top1 89.218750   Top5 98.678385   BatchTime 0.401147   LR 0.000328   
2022-11-25 11:27:50,361 - INFO  - Training [56][   80/  196]   Loss 0.317903   Top1 89.218750   Top5 98.798828   BatchTime 0.390430   LR 0.000324   
2022-11-25 11:27:56,619 - INFO  - Training [56][  100/  196]   Loss 0.308521   Top1 89.531250   Top5 98.855469   BatchTime 0.374922   LR 0.000319   
2022-11-25 11:28:02,917 - INFO  - Training [56][  120/  196]   Loss 0.304408   Top1 89.641927   Top5 98.909505   BatchTime 0.364913   LR 0.000315   
2022-11-25 11:28:08,221 - INFO  - Training [56][  140/  196]   Loss 0.304996   Top1 89.612165   Top5 98.967634   BatchTime 0.350671   LR 0.000311   
2022-11-25 11:28:15,618 - INFO  - Training [56][  160/  196]   Loss 0.306837   Top1 89.575195   Top5 98.967285   BatchTime 0.353067   LR 0.000306   
2022-11-25 11:28:23,417 - INFO  - Training [56][  180/  196]   Loss 0.310346   Top1 89.466146   Top5 98.945312   BatchTime 0.357165   LR 0.000302   
2022-11-25 11:28:29,540 - INFO  - ==> Top1: 89.452    Top5: 98.954    Loss: 0.310

2022-11-25 11:28:29,766 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:28:31,052 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:28:33,558 - INFO  - Validation [56][   20/   40]   Loss 0.430017   Top1 86.269531   Top5 99.316406   BatchTime 0.125161   
2022-11-25 11:28:34,611 - INFO  - Validation [56][   40/   40]   Loss 0.414828   Top1 86.530000   Top5 99.420000   BatchTime 0.088916   
2022-11-25 11:28:34,865 - INFO  - ==> Top1: 86.530    Top5: 99.420    Loss: 0.415

2022-11-25 11:28:34,865 - INFO  - ==> Sparsity : 0.489

2022-11-25 11:28:34,865 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:28:34,866 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:28:34,866 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 90.400   Top5: 99.730]
2022-11-25 11:28:34,985 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:28:34,986 - INFO  - >>>>>> Epoch  57
2022-11-25 11:28:34,988 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:28:43,947 - INFO  - Training [57][   20/  196]   Loss 0.314172   Top1 89.335938   Top5 98.574219   BatchTime 0.447802   LR 0.000294   
2022-11-25 11:28:51,002 - INFO  - Training [57][   40/  196]   Loss 0.316492   Top1 89.228516   Top5 98.662109   BatchTime 0.400290   LR 0.000290   
2022-11-25 11:28:58,384 - INFO  - Training [57][   60/  196]   Loss 0.319114   Top1 89.153646   Top5 98.769531   BatchTime 0.389895   LR 0.000286   
2022-11-25 11:29:05,557 - INFO  - Training [57][   80/  196]   Loss 0.315055   Top1 89.252930   Top5 98.896484   BatchTime 0.382077   LR 0.000282   
2022-11-25 11:29:12,954 - INFO  - Training [57][  100/  196]   Loss 0.309086   Top1 89.394531   Top5 98.964844   BatchTime 0.379626   LR 0.000277   
2022-11-25 11:29:20,198 - INFO  - Training [57][  120/  196]   Loss 0.305077   Top1 89.505208   Top5 99.036458   BatchTime 0.376723   LR 0.000273   
2022-11-25 11:29:27,658 - INFO  - Training [57][  140/  196]   Loss 0.306180   Top1 89.559152   Top5 99.070871   BatchTime 0.376191   LR 0.000269   
2022-11-25 11:29:35,581 - INFO  - Training [57][  160/  196]   Loss 0.308764   Top1 89.414062   Top5 99.033203   BatchTime 0.378683   LR 0.000265   
2022-11-25 11:29:42,971 - INFO  - Training [57][  180/  196]   Loss 0.308863   Top1 89.414062   Top5 99.006076   BatchTime 0.377665   LR 0.000261   
2022-11-25 11:29:48,978 - INFO  - ==> Top1: 89.462    Top5: 98.996    Loss: 0.308

2022-11-25 11:29:49,313 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:29:51,302 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:29:53,679 - INFO  - Validation [57][   20/   40]   Loss 0.312732   Top1 90.253906   Top5 99.648438   BatchTime 0.118768   
2022-11-25 11:29:54,682 - INFO  - Validation [57][   40/   40]   Loss 0.303739   Top1 90.190000   Top5 99.720000   BatchTime 0.084471   
2022-11-25 11:29:54,942 - INFO  - ==> Top1: 90.190    Top5: 99.720    Loss: 0.304

2022-11-25 11:29:54,942 - INFO  - ==> Sparsity : 0.480

2022-11-25 11:29:54,942 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:29:54,942 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:29:54,942 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 90.400   Top5: 99.730]
2022-11-25 11:29:55,064 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:29:55,066 - INFO  - >>>>>> Epoch  58
2022-11-25 11:29:55,067 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:30:04,217 - INFO  - Training [58][   20/  196]   Loss 0.314113   Top1 89.296875   Top5 98.554688   BatchTime 0.457349   LR 0.000254   
2022-11-25 11:30:11,657 - INFO  - Training [58][   40/  196]   Loss 0.320593   Top1 88.916016   Top5 98.769531   BatchTime 0.414663   LR 0.000250   
2022-11-25 11:30:18,968 - INFO  - Training [58][   60/  196]   Loss 0.315345   Top1 89.108073   Top5 98.860677   BatchTime 0.398291   LR 0.000246   
2022-11-25 11:30:26,456 - INFO  - Training [58][   80/  196]   Loss 0.316779   Top1 89.013672   Top5 98.950195   BatchTime 0.392316   LR 0.000242   
2022-11-25 11:30:33,763 - INFO  - Training [58][  100/  196]   Loss 0.308426   Top1 89.332031   Top5 98.980469   BatchTime 0.386930   LR 0.000238   
2022-11-25 11:30:40,385 - INFO  - Training [58][  120/  196]   Loss 0.304027   Top1 89.527995   Top5 99.023438   BatchTime 0.377618   LR 0.000234   
2022-11-25 11:30:46,840 - INFO  - Training [58][  140/  196]   Loss 0.302346   Top1 89.648438   Top5 99.068080   BatchTime 0.369780   LR 0.000230   
2022-11-25 11:30:54,868 - INFO  - Training [58][  160/  196]   Loss 0.306637   Top1 89.526367   Top5 99.069824   BatchTime 0.373732   LR 0.000226   
2022-11-25 11:31:02,151 - INFO  - Training [58][  180/  196]   Loss 0.305311   Top1 89.563802   Top5 99.010417   BatchTime 0.372667   LR 0.000222   
2022-11-25 11:31:07,897 - INFO  - ==> Top1: 89.696    Top5: 99.024    Loss: 0.302

2022-11-25 11:31:08,119 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:31:09,568 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:31:12,029 - INFO  - Validation [58][   20/   40]   Loss 0.333139   Top1 90.058594   Top5 99.531250   BatchTime 0.122963   
2022-11-25 11:31:13,103 - INFO  - Validation [58][   40/   40]   Loss 0.323112   Top1 89.960000   Top5 99.610000   BatchTime 0.088347   
2022-11-25 11:31:13,351 - INFO  - ==> Top1: 89.960    Top5: 99.610    Loss: 0.323

2022-11-25 11:31:13,352 - INFO  - ==> Sparsity : 0.488

2022-11-25 11:31:13,352 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:31:13,352 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:31:13,352 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 90.400   Top5: 99.730]
2022-11-25 11:31:13,471 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:31:13,472 - INFO  - >>>>>> Epoch  59
2022-11-25 11:31:13,474 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:31:22,639 - INFO  - Training [59][   20/  196]   Loss 0.302353   Top1 89.687500   Top5 98.417969   BatchTime 0.458141   LR 0.000215   
2022-11-25 11:31:29,892 - INFO  - Training [59][   40/  196]   Loss 0.310342   Top1 89.619141   Top5 98.583984   BatchTime 0.410387   LR 0.000212   
2022-11-25 11:31:37,194 - INFO  - Training [59][   60/  196]   Loss 0.303998   Top1 89.778646   Top5 98.750000   BatchTime 0.395286   LR 0.000208   
2022-11-25 11:31:44,433 - INFO  - Training [59][   80/  196]   Loss 0.305592   Top1 89.667969   Top5 98.876953   BatchTime 0.386950   LR 0.000204   
2022-11-25 11:31:51,588 - INFO  - Training [59][  100/  196]   Loss 0.298588   Top1 89.898438   Top5 98.968750   BatchTime 0.381111   LR 0.000201   
2022-11-25 11:31:58,570 - INFO  - Training [59][  120/  196]   Loss 0.292609   Top1 90.087891   Top5 99.010417   BatchTime 0.375776   LR 0.000197   
2022-11-25 11:32:04,406 - INFO  - Training [59][  140/  196]   Loss 0.293200   Top1 90.094866   Top5 99.051339   BatchTime 0.363781   LR 0.000193   
2022-11-25 11:32:10,805 - INFO  - Training [59][  160/  196]   Loss 0.296292   Top1 89.960938   Top5 99.064941   BatchTime 0.358300   LR 0.000190   
2022-11-25 11:32:18,377 - INFO  - Training [59][  180/  196]   Loss 0.297911   Top1 89.858941   Top5 99.014757   BatchTime 0.360553   LR 0.000186   
2022-11-25 11:32:24,110 - INFO  - ==> Top1: 89.908    Top5: 99.018    Loss: 0.297

2022-11-25 11:32:24,392 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:32:26,012 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:32:28,349 - INFO  - Validation [59][   20/   40]   Loss 0.325186   Top1 90.097656   Top5 99.628906   BatchTime 0.116803   
2022-11-25 11:32:29,420 - INFO  - Validation [59][   40/   40]   Loss 0.310260   Top1 90.340000   Top5 99.710000   BatchTime 0.085184   
2022-11-25 11:32:29,663 - INFO  - ==> Top1: 90.340    Top5: 99.710    Loss: 0.310

2022-11-25 11:32:29,664 - INFO  - ==> Sparsity : 0.503

2022-11-25 11:32:29,664 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:32:29,664 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:32:29,664 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 90.400   Top5: 99.730]
2022-11-25 11:32:29,808 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:32:29,809 - INFO  - >>>>>> Epoch  60
2022-11-25 11:32:29,811 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:32:38,889 - INFO  - Training [60][   20/  196]   Loss 0.320206   Top1 89.277344   Top5 98.613281   BatchTime 0.453775   LR 0.000180   
2022-11-25 11:32:46,436 - INFO  - Training [60][   40/  196]   Loss 0.312999   Top1 89.433594   Top5 98.818359   BatchTime 0.415548   LR 0.000176   
2022-11-25 11:32:54,362 - INFO  - Training [60][   60/  196]   Loss 0.308008   Top1 89.635417   Top5 98.893229   BatchTime 0.409128   LR 0.000173   
2022-11-25 11:33:01,611 - INFO  - Training [60][   80/  196]   Loss 0.301097   Top1 89.819336   Top5 98.974609   BatchTime 0.397466   LR 0.000169   
2022-11-25 11:33:08,838 - INFO  - Training [60][  100/  196]   Loss 0.297649   Top1 89.886719   Top5 98.984375   BatchTime 0.390242   LR 0.000166   
2022-11-25 11:33:16,301 - INFO  - Training [60][  120/  196]   Loss 0.291182   Top1 90.104167   Top5 99.059245   BatchTime 0.387393   LR 0.000162   
2022-11-25 11:33:23,214 - INFO  - Training [60][  140/  196]   Loss 0.290458   Top1 90.108817   Top5 99.104353   BatchTime 0.381425   LR 0.000159   
2022-11-25 11:33:29,379 - INFO  - Training [60][  160/  196]   Loss 0.296635   Top1 89.865723   Top5 99.072266   BatchTime 0.372277   LR 0.000156   
2022-11-25 11:33:37,183 - INFO  - Training [60][  180/  196]   Loss 0.296651   Top1 89.826389   Top5 99.051649   BatchTime 0.374266   LR 0.000152   
2022-11-25 11:33:43,359 - INFO  - ==> Top1: 89.814    Top5: 99.044    Loss: 0.297

2022-11-25 11:33:43,632 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:33:45,277 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:33:47,670 - INFO  - Validation [60][   20/   40]   Loss 0.342023   Top1 89.785156   Top5 99.628906   BatchTime 0.119572   
2022-11-25 11:33:48,705 - INFO  - Validation [60][   40/   40]   Loss 0.329906   Top1 89.760000   Top5 99.730000   BatchTime 0.085657   
2022-11-25 11:33:48,954 - INFO  - ==> Top1: 89.760    Top5: 99.730    Loss: 0.330

2022-11-25 11:33:48,955 - INFO  - ==> Sparsity : 0.505

2022-11-25 11:33:48,955 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:33:48,955 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:33:48,955 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 90.400   Top5: 99.730]
2022-11-25 11:33:49,116 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:33:49,118 - INFO  - >>>>>> Epoch  61
2022-11-25 11:33:49,119 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:33:58,094 - INFO  - Training [61][   20/  196]   Loss 0.291196   Top1 89.707031   Top5 98.613281   BatchTime 0.448581   LR 0.000147   
2022-11-25 11:34:05,843 - INFO  - Training [61][   40/  196]   Loss 0.293401   Top1 89.716797   Top5 98.759766   BatchTime 0.418011   LR 0.000143   
2022-11-25 11:34:13,078 - INFO  - Training [61][   60/  196]   Loss 0.293388   Top1 89.661458   Top5 98.854167   BatchTime 0.399261   LR 0.000140   
2022-11-25 11:34:20,383 - INFO  - Training [61][   80/  196]   Loss 0.297998   Top1 89.555664   Top5 98.984375   BatchTime 0.390755   LR 0.000137   
2022-11-25 11:34:27,682 - INFO  - Training [61][  100/  196]   Loss 0.297483   Top1 89.578125   Top5 99.011719   BatchTime 0.385594   LR 0.000134   
2022-11-25 11:34:35,060 - INFO  - Training [61][  120/  196]   Loss 0.292035   Top1 89.840495   Top5 99.069010   BatchTime 0.382811   LR 0.000131   
2022-11-25 11:34:42,616 - INFO  - Training [61][  140/  196]   Loss 0.290055   Top1 89.933036   Top5 99.107143   BatchTime 0.382099   LR 0.000128   
2022-11-25 11:34:49,589 - INFO  - Training [61][  160/  196]   Loss 0.295217   Top1 89.753418   Top5 99.089355   BatchTime 0.377914   LR 0.000125   
2022-11-25 11:34:57,948 - INFO  - Training [61][  180/  196]   Loss 0.296209   Top1 89.670139   Top5 99.062500   BatchTime 0.382363   LR 0.000122   
2022-11-25 11:35:04,521 - INFO  - ==> Top1: 89.752    Top5: 99.086    Loss: 0.295

2022-11-25 11:35:04,932 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:35:06,591 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:35:09,048 - INFO  - Validation [61][   20/   40]   Loss 0.324584   Top1 90.097656   Top5 99.511719   BatchTime 0.122784   
2022-11-25 11:35:10,040 - INFO  - Validation [61][   40/   40]   Loss 0.311641   Top1 90.060000   Top5 99.630000   BatchTime 0.086186   
2022-11-25 11:35:10,323 - INFO  - ==> Top1: 90.060    Top5: 99.630    Loss: 0.312

2022-11-25 11:35:10,324 - INFO  - ==> Sparsity : 0.516

2022-11-25 11:35:10,324 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:35:10,324 - INFO  - Scoreboard best 2 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:35:10,324 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 90.400   Top5: 99.730]
2022-11-25 11:35:10,472 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:35:10,474 - INFO  - >>>>>> Epoch  62
2022-11-25 11:35:10,476 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:35:19,694 - INFO  - Training [62][   20/  196]   Loss 0.317384   Top1 88.945312   Top5 98.535156   BatchTime 0.460772   LR 0.000117   
2022-11-25 11:35:27,424 - INFO  - Training [62][   40/  196]   Loss 0.309848   Top1 89.150391   Top5 98.750000   BatchTime 0.423648   LR 0.000114   
2022-11-25 11:35:34,745 - INFO  - Training [62][   60/  196]   Loss 0.302451   Top1 89.505208   Top5 98.815104   BatchTime 0.404438   LR 0.000111   
2022-11-25 11:35:42,133 - INFO  - Training [62][   80/  196]   Loss 0.297739   Top1 89.589844   Top5 98.994141   BatchTime 0.395684   LR 0.000108   
2022-11-25 11:35:49,565 - INFO  - Training [62][  100/  196]   Loss 0.292055   Top1 89.792969   Top5 99.019531   BatchTime 0.390864   LR 0.000105   
2022-11-25 11:35:57,037 - INFO  - Training [62][  120/  196]   Loss 0.286149   Top1 90.048828   Top5 99.111328   BatchTime 0.387984   LR 0.000102   
2022-11-25 11:36:03,867 - INFO  - Training [62][  140/  196]   Loss 0.286650   Top1 90.064174   Top5 99.151786   BatchTime 0.381347   LR 0.000100   
2022-11-25 11:36:11,325 - INFO  - Training [62][  160/  196]   Loss 0.291516   Top1 89.907227   Top5 99.167480   BatchTime 0.380292   LR 0.000097   
2022-11-25 11:36:18,852 - INFO  - Training [62][  180/  196]   Loss 0.290730   Top1 89.913194   Top5 99.127604   BatchTime 0.379849   LR 0.000094   
2022-11-25 11:36:24,851 - INFO  - ==> Top1: 89.928    Top5: 99.108    Loss: 0.291

2022-11-25 11:36:25,078 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:36:26,499 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:36:28,972 - INFO  - Validation [62][   20/   40]   Loss 0.309234   Top1 90.722656   Top5 99.648438   BatchTime 0.123538   
2022-11-25 11:36:29,998 - INFO  - Validation [62][   40/   40]   Loss 0.296243   Top1 90.890000   Top5 99.720000   BatchTime 0.087430   
2022-11-25 11:36:30,242 - INFO  - ==> Top1: 90.890    Top5: 99.720    Loss: 0.296

2022-11-25 11:36:30,242 - INFO  - ==> Sparsity : 0.512

2022-11-25 11:36:30,242 - INFO  - Scoreboard best 1 ==> Epoch [62][Top1: 90.890   Top5: 99.720]
2022-11-25 11:36:30,242 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:36:30,243 - INFO  - Scoreboard best 3 ==> Epoch [49][Top1: 90.470   Top5: 99.760]
2022-11-25 11:36:37,279 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 11:36:37,282 - INFO  - >>>>>> Epoch  63
2022-11-25 11:36:37,284 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:36:46,108 - INFO  - Training [63][   20/  196]   Loss 0.321935   Top1 89.082031   Top5 98.515625   BatchTime 0.441032   LR 0.000090   
2022-11-25 11:36:53,607 - INFO  - Training [63][   40/  196]   Loss 0.313486   Top1 89.238281   Top5 98.662109   BatchTime 0.408000   LR 0.000087   
2022-11-25 11:37:01,051 - INFO  - Training [63][   60/  196]   Loss 0.304476   Top1 89.628906   Top5 98.723958   BatchTime 0.396063   LR 0.000085   
2022-11-25 11:37:08,518 - INFO  - Training [63][   80/  196]   Loss 0.299936   Top1 89.775391   Top5 98.862305   BatchTime 0.390378   LR 0.000082   
2022-11-25 11:37:15,649 - INFO  - Training [63][  100/  196]   Loss 0.293587   Top1 90.089844   Top5 98.910156   BatchTime 0.383619   LR 0.000080   
2022-11-25 11:37:21,764 - INFO  - Training [63][  120/  196]   Loss 0.289002   Top1 90.224609   Top5 98.981120   BatchTime 0.370641   LR 0.000077   
2022-11-25 11:37:29,409 - INFO  - Training [63][  140/  196]   Loss 0.285442   Top1 90.401786   Top5 99.031808   BatchTime 0.372292   LR 0.000075   
2022-11-25 11:37:37,603 - INFO  - Training [63][  160/  196]   Loss 0.287709   Top1 90.283203   Top5 99.057617   BatchTime 0.376972   LR 0.000072   
2022-11-25 11:37:45,784 - INFO  - Training [63][  180/  196]   Loss 0.288247   Top1 90.203993   Top5 99.040799   BatchTime 0.380536   LR 0.000070   
2022-11-25 11:37:52,558 - INFO  - ==> Top1: 90.224    Top5: 99.042    Loss: 0.287

2022-11-25 11:37:52,795 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:37:54,538 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:37:58,063 - INFO  - Validation [63][   20/   40]   Loss 0.303910   Top1 90.996094   Top5 99.667969   BatchTime 0.176145   
2022-11-25 11:37:59,593 - INFO  - Validation [63][   40/   40]   Loss 0.284531   Top1 91.060000   Top5 99.730000   BatchTime 0.126344   
2022-11-25 11:37:59,805 - INFO  - ==> Top1: 91.060    Top5: 99.730    Loss: 0.285

2022-11-25 11:37:59,805 - INFO  - ==> Sparsity : 0.516

2022-11-25 11:37:59,806 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 91.060   Top5: 99.730]
2022-11-25 11:37:59,806 - INFO  - Scoreboard best 2 ==> Epoch [62][Top1: 90.890   Top5: 99.720]
2022-11-25 11:37:59,806 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:38:05,048 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_best.pth.tar
save quantized models...
2022-11-25 11:38:05,049 - INFO  - >>>>>> Epoch  64
2022-11-25 11:38:05,051 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:38:13,980 - INFO  - Training [64][   20/  196]   Loss 0.301761   Top1 89.550781   Top5 98.554688   BatchTime 0.446339   LR 0.000066   
2022-11-25 11:38:21,259 - INFO  - Training [64][   40/  196]   Loss 0.307118   Top1 89.433594   Top5 98.681641   BatchTime 0.405133   LR 0.000064   
2022-11-25 11:38:28,527 - INFO  - Training [64][   60/  196]   Loss 0.303114   Top1 89.635417   Top5 98.763021   BatchTime 0.391221   LR 0.000062   
2022-11-25 11:38:35,555 - INFO  - Training [64][   80/  196]   Loss 0.296572   Top1 89.785156   Top5 98.920898   BatchTime 0.381270   LR 0.000059   
2022-11-25 11:38:42,027 - INFO  - Training [64][  100/  196]   Loss 0.294102   Top1 89.867188   Top5 98.949219   BatchTime 0.369739   LR 0.000057   
2022-11-25 11:38:49,858 - INFO  - Training [64][  120/  196]   Loss 0.287026   Top1 90.081380   Top5 99.033203   BatchTime 0.373368   LR 0.000055   
2022-11-25 11:38:57,770 - INFO  - Training [64][  140/  196]   Loss 0.285500   Top1 90.153460   Top5 99.076451   BatchTime 0.376545   LR 0.000053   
2022-11-25 11:39:05,462 - INFO  - Training [64][  160/  196]   Loss 0.287613   Top1 90.083008   Top5 99.074707   BatchTime 0.377550   LR 0.000051   
2022-11-25 11:39:13,518 - INFO  - Training [64][  180/  196]   Loss 0.290060   Top1 90.008681   Top5 99.029948   BatchTime 0.380356   LR 0.000049   
2022-11-25 11:39:19,398 - INFO  - ==> Top1: 90.074    Top5: 99.022    Loss: 0.289

2022-11-25 11:39:19,776 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:39:21,604 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:39:24,105 - INFO  - Validation [64][   20/   40]   Loss 0.344365   Top1 89.316406   Top5 99.492188   BatchTime 0.124945   
2022-11-25 11:39:25,068 - INFO  - Validation [64][   40/   40]   Loss 0.330003   Top1 89.510000   Top5 99.670000   BatchTime 0.086575   
2022-11-25 11:39:25,306 - INFO  - ==> Top1: 89.510    Top5: 99.670    Loss: 0.330

2022-11-25 11:39:25,307 - INFO  - ==> Sparsity : 0.533

2022-11-25 11:39:25,307 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 91.060   Top5: 99.730]
2022-11-25 11:39:25,307 - INFO  - Scoreboard best 2 ==> Epoch [62][Top1: 90.890   Top5: 99.720]
2022-11-25 11:39:25,307 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:39:25,429 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:39:25,431 - INFO  - >>>>>> Epoch  65
2022-11-25 11:39:25,433 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:39:34,495 - INFO  - Training [65][   20/  196]   Loss 0.323953   Top1 88.320312   Top5 98.496094   BatchTime 0.453010   LR 0.000046   
2022-11-25 11:39:41,673 - INFO  - Training [65][   40/  196]   Loss 0.316872   Top1 88.730469   Top5 98.769531   BatchTime 0.405960   LR 0.000044   
2022-11-25 11:39:49,568 - INFO  - Training [65][   60/  196]   Loss 0.313599   Top1 89.082031   Top5 98.847656   BatchTime 0.402222   LR 0.000042   
2022-11-25 11:39:55,978 - INFO  - Training [65][   80/  196]   Loss 0.307213   Top1 89.287109   Top5 99.008789   BatchTime 0.381779   LR 0.000040   
2022-11-25 11:40:03,967 - INFO  - Training [65][  100/  196]   Loss 0.299401   Top1 89.546875   Top5 99.070312   BatchTime 0.385313   LR 0.000039   
2022-11-25 11:40:11,609 - INFO  - Training [65][  120/  196]   Loss 0.293367   Top1 89.830729   Top5 99.101562   BatchTime 0.384776   LR 0.000037   
2022-11-25 11:40:18,963 - INFO  - Training [65][  140/  196]   Loss 0.292897   Top1 89.902344   Top5 99.121094   BatchTime 0.382341   LR 0.000035   
2022-11-25 11:40:26,443 - INFO  - Training [65][  160/  196]   Loss 0.293149   Top1 89.934082   Top5 99.096680   BatchTime 0.381294   LR 0.000033   
2022-11-25 11:40:34,072 - INFO  - Training [65][  180/  196]   Loss 0.292363   Top1 89.991319   Top5 99.034288   BatchTime 0.381312   LR 0.000032   
2022-11-25 11:40:40,348 - INFO  - ==> Top1: 90.000    Top5: 99.032    Loss: 0.292

2022-11-25 11:40:40,634 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:40:42,229 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:40:44,645 - INFO  - Validation [65][   20/   40]   Loss 0.401857   Top1 87.714844   Top5 99.433594   BatchTime 0.120660   
2022-11-25 11:40:45,674 - INFO  - Validation [65][   40/   40]   Loss 0.384993   Top1 87.910000   Top5 99.540000   BatchTime 0.086072   
2022-11-25 11:40:45,913 - INFO  - ==> Top1: 87.910    Top5: 99.540    Loss: 0.385

2022-11-25 11:40:45,913 - INFO  - ==> Sparsity : 0.533

2022-11-25 11:40:45,913 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 91.060   Top5: 99.730]
2022-11-25 11:40:45,914 - INFO  - Scoreboard best 2 ==> Epoch [62][Top1: 90.890   Top5: 99.720]
2022-11-25 11:40:45,914 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:40:46,030 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:40:46,031 - INFO  - >>>>>> Epoch  66
2022-11-25 11:40:46,033 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:40:54,807 - INFO  - Training [66][   20/  196]   Loss 0.312144   Top1 89.101562   Top5 98.574219   BatchTime 0.438551   LR 0.000029   
2022-11-25 11:41:01,895 - INFO  - Training [66][   40/  196]   Loss 0.305017   Top1 89.638672   Top5 98.818359   BatchTime 0.396479   LR 0.000028   
2022-11-25 11:41:09,301 - INFO  - Training [66][   60/  196]   Loss 0.305576   Top1 89.687500   Top5 98.854167   BatchTime 0.387750   LR 0.000026   
2022-11-25 11:41:15,733 - INFO  - Training [66][   80/  196]   Loss 0.302526   Top1 89.707031   Top5 98.955078   BatchTime 0.371213   LR 0.000025   
2022-11-25 11:41:23,113 - INFO  - Training [66][  100/  196]   Loss 0.295286   Top1 89.894531   Top5 99.000000   BatchTime 0.370771   LR 0.000023   
2022-11-25 11:41:30,390 - INFO  - Training [66][  120/  196]   Loss 0.290912   Top1 90.081380   Top5 99.036458   BatchTime 0.369617   LR 0.000022   
2022-11-25 11:41:37,800 - INFO  - Training [66][  140/  196]   Loss 0.289814   Top1 90.114397   Top5 99.107143   BatchTime 0.369742   LR 0.000021   
2022-11-25 11:41:44,789 - INFO  - Training [66][  160/  196]   Loss 0.292073   Top1 89.987793   Top5 99.089355   BatchTime 0.367202   LR 0.000019   
2022-11-25 11:41:52,175 - INFO  - Training [66][  180/  196]   Loss 0.291248   Top1 90.008681   Top5 99.066840   BatchTime 0.367437   LR 0.000018   
2022-11-25 11:41:58,192 - INFO  - ==> Top1: 90.082    Top5: 99.058    Loss: 0.289

2022-11-25 11:41:58,442 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:41:59,831 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:42:02,232 - INFO  - Validation [66][   20/   40]   Loss 0.343060   Top1 89.375000   Top5 99.472656   BatchTime 0.119947   
2022-11-25 11:42:03,265 - INFO  - Validation [66][   40/   40]   Loss 0.326857   Top1 89.670000   Top5 99.590000   BatchTime 0.085796   
2022-11-25 11:42:03,527 - INFO  - ==> Top1: 89.670    Top5: 99.590    Loss: 0.327

2022-11-25 11:42:03,528 - INFO  - ==> Sparsity : 0.534

2022-11-25 11:42:03,528 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 91.060   Top5: 99.730]
2022-11-25 11:42:03,529 - INFO  - Scoreboard best 2 ==> Epoch [62][Top1: 90.890   Top5: 99.720]
2022-11-25 11:42:03,529 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:42:03,988 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:42:03,990 - INFO  - >>>>>> Epoch  67
2022-11-25 11:42:03,992 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:42:12,800 - INFO  - Training [67][   20/  196]   Loss 0.311924   Top1 89.218750   Top5 98.671875   BatchTime 0.440286   LR 0.000016   
2022-11-25 11:42:20,461 - INFO  - Training [67][   40/  196]   Loss 0.310370   Top1 89.257812   Top5 98.798828   BatchTime 0.411675   LR 0.000015   
2022-11-25 11:42:27,772 - INFO  - Training [67][   60/  196]   Loss 0.301491   Top1 89.700521   Top5 98.841146   BatchTime 0.396285   LR 0.000014   
2022-11-25 11:42:34,049 - INFO  - Training [67][   80/  196]   Loss 0.301345   Top1 89.721680   Top5 99.003906   BatchTime 0.375676   LR 0.000013   
2022-11-25 11:42:40,309 - INFO  - Training [67][  100/  196]   Loss 0.298692   Top1 89.851562   Top5 99.035156   BatchTime 0.363143   LR 0.000012   
2022-11-25 11:42:47,485 - INFO  - Training [67][  120/  196]   Loss 0.292524   Top1 90.042318   Top5 99.098307   BatchTime 0.362415   LR 0.000011   
2022-11-25 11:42:55,050 - INFO  - Training [67][  140/  196]   Loss 0.291534   Top1 90.103237   Top5 99.151786   BatchTime 0.364682   LR 0.000010   
2022-11-25 11:43:02,514 - INFO  - Training [67][  160/  196]   Loss 0.292822   Top1 90.014648   Top5 99.140625   BatchTime 0.365741   LR 0.000009   
2022-11-25 11:43:10,229 - INFO  - Training [67][  180/  196]   Loss 0.292294   Top1 90.032552   Top5 99.099392   BatchTime 0.367964   LR 0.000008   
2022-11-25 11:43:15,755 - INFO  - ==> Top1: 90.098    Top5: 99.088    Loss: 0.290

2022-11-25 11:43:15,990 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:43:17,425 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:43:19,935 - INFO  - Validation [67][   20/   40]   Loss 0.314443   Top1 90.253906   Top5 99.531250   BatchTime 0.125416   
2022-11-25 11:43:21,061 - INFO  - Validation [67][   40/   40]   Loss 0.299343   Top1 90.470000   Top5 99.710000   BatchTime 0.090849   
2022-11-25 11:43:21,271 - INFO  - ==> Top1: 90.470    Top5: 99.710    Loss: 0.299

2022-11-25 11:43:21,272 - INFO  - ==> Sparsity : 0.535

2022-11-25 11:43:21,272 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 91.060   Top5: 99.730]
2022-11-25 11:43:21,272 - INFO  - Scoreboard best 2 ==> Epoch [62][Top1: 90.890   Top5: 99.720]
2022-11-25 11:43:21,272 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 90.510   Top5: 99.700]
2022-11-25 11:43:21,399 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:43:21,402 - INFO  - >>>>>> Epoch  68
2022-11-25 11:43:21,403 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:43:30,222 - INFO  - Training [68][   20/  196]   Loss 0.301421   Top1 89.335938   Top5 98.613281   BatchTime 0.440813   LR 0.000007   
2022-11-25 11:43:37,520 - INFO  - Training [68][   40/  196]   Loss 0.306573   Top1 89.375000   Top5 98.740234   BatchTime 0.402851   LR 0.000006   
2022-11-25 11:43:44,995 - INFO  - Training [68][   60/  196]   Loss 0.299816   Top1 89.602865   Top5 98.776042   BatchTime 0.393145   LR 0.000006   
2022-11-25 11:43:52,408 - INFO  - Training [68][   80/  196]   Loss 0.296916   Top1 89.794922   Top5 98.867188   BatchTime 0.387532   LR 0.000005   
2022-11-25 11:43:59,625 - INFO  - Training [68][  100/  196]   Loss 0.288949   Top1 90.101562   Top5 98.906250   BatchTime 0.382192   LR 0.000004   
2022-11-25 11:44:06,830 - INFO  - Training [68][  120/  196]   Loss 0.284387   Top1 90.302734   Top5 98.987630   BatchTime 0.378529   LR 0.000004   
2022-11-25 11:44:14,253 - INFO  - Training [68][  140/  196]   Loss 0.283198   Top1 90.348772   Top5 99.048549   BatchTime 0.377480   LR 0.000003   
2022-11-25 11:44:21,638 - INFO  - Training [68][  160/  196]   Loss 0.286740   Top1 90.202637   Top5 99.035645   BatchTime 0.376449   LR 0.000003   
2022-11-25 11:44:28,982 - INFO  - Training [68][  180/  196]   Loss 0.285947   Top1 90.199653   Top5 99.016927   BatchTime 0.375421   LR 0.000002   
2022-11-25 11:44:34,705 - INFO  - ==> Top1: 90.206    Top5: 99.020    Loss: 0.286

2022-11-25 11:44:34,941 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:44:36,356 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:44:38,866 - INFO  - Validation [68][   20/   40]   Loss 0.312208   Top1 90.839844   Top5 99.707031   BatchTime 0.125407   
2022-11-25 11:44:39,986 - INFO  - Validation [68][   40/   40]   Loss 0.297833   Top1 90.930000   Top5 99.740000   BatchTime 0.090711   
2022-11-25 11:44:40,266 - INFO  - ==> Top1: 90.930    Top5: 99.740    Loss: 0.298

2022-11-25 11:44:40,266 - INFO  - ==> Sparsity : 0.537

2022-11-25 11:44:40,267 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 91.060   Top5: 99.730]
2022-11-25 11:44:40,267 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.930   Top5: 99.740]
2022-11-25 11:44:40,267 - INFO  - Scoreboard best 3 ==> Epoch [62][Top1: 90.890   Top5: 99.720]
2022-11-25 11:44:40,701 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:44:40,703 - INFO  - >>>>>> Epoch  69
2022-11-25 11:44:40,706 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:44:49,848 - INFO  - Training [69][   20/  196]   Loss 0.304932   Top1 89.570312   Top5 98.730469   BatchTime 0.456948   LR 0.000002   
2022-11-25 11:44:57,430 - INFO  - Training [69][   40/  196]   Loss 0.308232   Top1 89.375000   Top5 98.798828   BatchTime 0.418030   LR 0.000001   
2022-11-25 11:45:04,738 - INFO  - Training [69][   60/  196]   Loss 0.298780   Top1 89.589844   Top5 98.964844   BatchTime 0.400488   LR 0.000001   
2022-11-25 11:45:12,708 - INFO  - Training [69][   80/  196]   Loss 0.294701   Top1 89.750977   Top5 99.057617   BatchTime 0.399987   LR 0.000001   
2022-11-25 11:45:18,859 - INFO  - Training [69][  100/  196]   Loss 0.286733   Top1 90.101562   Top5 99.089844   BatchTime 0.381503   LR 0.000000   
2022-11-25 11:45:23,888 - INFO  - Training [69][  120/  196]   Loss 0.282372   Top1 90.227865   Top5 99.147135   BatchTime 0.359827   LR 0.000000   
2022-11-25 11:45:30,627 - INFO  - Training [69][  140/  196]   Loss 0.280882   Top1 90.292969   Top5 99.202009   BatchTime 0.356556   LR 0.000000   
2022-11-25 11:45:37,857 - INFO  - Training [69][  160/  196]   Loss 0.283572   Top1 90.170898   Top5 99.189453   BatchTime 0.357172   LR 0.000000   
2022-11-25 11:45:45,316 - INFO  - Training [69][  180/  196]   Loss 0.285020   Top1 90.141059   Top5 99.123264   BatchTime 0.358929   LR 0.000000   
2022-11-25 11:45:51,003 - INFO  - ==> Top1: 90.168    Top5: 99.108    Loss: 0.284

2022-11-25 11:45:51,439 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:45:53,253 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:45:55,766 - INFO  - Validation [69][   20/   40]   Loss 0.360704   Top1 89.414062   Top5 99.472656   BatchTime 0.125516   
2022-11-25 11:45:56,811 - INFO  - Validation [69][   40/   40]   Loss 0.352113   Top1 89.160000   Top5 99.640000   BatchTime 0.088896   
2022-11-25 11:45:57,041 - INFO  - ==> Top1: 89.160    Top5: 99.640    Loss: 0.352

2022-11-25 11:45:57,041 - INFO  - ==> Sparsity : 0.537

2022-11-25 11:45:57,042 - INFO  - Scoreboard best 1 ==> Epoch [63][Top1: 91.060   Top5: 99.730]
2022-11-25 11:45:57,042 - INFO  - Scoreboard best 2 ==> Epoch [68][Top1: 90.930   Top5: 99.740]
2022-11-25 11:45:57,042 - INFO  - Scoreboard best 3 ==> Epoch [62][Top1: 90.890   Top5: 99.720]
2022-11-25 11:45:57,227 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/_checkpoint.pth.tar

2022-11-25 11:45:57,229 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 11:45:57,229 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:45:59,733 - INFO  - Validation [   20/   40]   Loss 0.360704   Top1 89.414062   Top5 99.472656   BatchTime 0.125096   
2022-11-25 11:46:00,755 - INFO  - Validation [   40/   40]   Loss 0.352113   Top1 89.160000   Top5 99.640000   BatchTime 0.088098   
2022-11-25 11:46:00,891 - INFO  - ==> Top1: 89.160    Top5: 99.640    Loss: 0.352

2022-11-25 11:46:00,891 - INFO  - ==> Sparsity : 0.000

2022-11-25 11:46:00,892 - INFO  - Program completed sucessfully ... exiting ...
2022-11-25 11:46:00,913 - INFO  - >>>>>> Epoch   0
2022-11-25 11:46:00,914 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:46:09,092 - INFO  - Training [0][   20/  196]   Loss 0.522496   Top1 81.464844   Top5 97.832031   BatchTime 0.408779   LR 0.004999   
2022-11-25 11:46:15,875 - INFO  - Training [0][   40/  196]   Loss 0.534686   Top1 81.347656   Top5 97.763672   BatchTime 0.373963   LR 0.004995   
2022-11-25 11:46:22,666 - INFO  - Training [0][   60/  196]   Loss 0.534703   Top1 81.367188   Top5 97.858073   BatchTime 0.362494   LR 0.004989   
2022-11-25 11:46:29,894 - INFO  - Training [0][   80/  196]   Loss 0.598289   Top1 79.804688   Top5 97.377930   BatchTime 0.362217   LR 0.004980   
2022-11-25 11:46:36,858 - INFO  - Training [0][  100/  196]   Loss 0.602411   Top1 79.507812   Top5 97.449219   BatchTime 0.359413   LR 0.004968   
2022-11-25 11:46:42,441 - INFO  - Training [0][  120/  196]   Loss 0.595269   Top1 79.762370   Top5 97.555339   BatchTime 0.346032   LR 0.004954   
2022-11-25 11:46:49,659 - INFO  - Training [0][  140/  196]   Loss 0.585381   Top1 80.036272   Top5 97.664621   BatchTime 0.348157   LR 0.004938   
2022-11-25 11:46:57,009 - INFO  - Training [0][  160/  196]   Loss 0.580252   Top1 80.197754   Top5 97.717285   BatchTime 0.350574   LR 0.004919   
2022-11-25 11:47:03,862 - INFO  - Training [0][  180/  196]   Loss 0.573890   Top1 80.353733   Top5 97.708333   BatchTime 0.349694   LR 0.004897   
2022-11-25 11:47:09,459 - INFO  - ==> Top1: 80.452    Top5: 97.758    Loss: 0.570

2022-11-25 11:47:09,737 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:47:11,446 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:47:13,972 - INFO  - Validation [0][   20/   40]   Loss 0.416289   Top1 85.800781   Top5 99.414062   BatchTime 0.126241   
2022-11-25 11:47:15,059 - INFO  - Validation [0][   40/   40]   Loss 0.415516   Top1 85.350000   Top5 99.560000   BatchTime 0.090308   
2022-11-25 11:47:15,303 - INFO  - ==> Top1: 85.350    Top5: 99.560    Loss: 0.416

2022-11-25 11:47:15,303 - INFO  - ==> Sparsity : 0.605

2022-11-25 11:47:15,303 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 85.350   Top5: 99.560]
2022-11-25 11:47:20,248 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 11:47:20,252 - INFO  - >>>>>> Epoch   1
2022-11-25 11:47:20,255 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:47:28,451 - INFO  - Training [1][   20/  196]   Loss 0.536056   Top1 81.035156   Top5 98.144531   BatchTime 0.409701   LR 0.004853   
2022-11-25 11:47:35,285 - INFO  - Training [1][   40/  196]   Loss 0.531802   Top1 81.542969   Top5 98.017578   BatchTime 0.375688   LR 0.004825   
2022-11-25 11:47:42,591 - INFO  - Training [1][   60/  196]   Loss 0.525367   Top1 81.712240   Top5 98.138021   BatchTime 0.372223   LR 0.004794   
2022-11-25 11:47:49,687 - INFO  - Training [1][   80/  196]   Loss 0.519640   Top1 81.962891   Top5 98.251953   BatchTime 0.367870   LR 0.004761   
2022-11-25 11:47:56,187 - INFO  - Training [1][  100/  196]   Loss 0.509280   Top1 82.269531   Top5 98.273438   BatchTime 0.359293   LR 0.004725   
2022-11-25 11:48:01,940 - INFO  - Training [1][  120/  196]   Loss 0.503178   Top1 82.539062   Top5 98.333333   BatchTime 0.347358   LR 0.004687   
2022-11-25 11:48:09,113 - INFO  - Training [1][  140/  196]   Loss 0.499888   Top1 82.647879   Top5 98.390067   BatchTime 0.348964   LR 0.004647   
2022-11-25 11:48:16,682 - INFO  - Training [1][  160/  196]   Loss 0.512559   Top1 82.133789   Top5 98.088379   BatchTime 0.352653   LR 0.004605   
2022-11-25 11:48:23,439 - INFO  - Training [1][  180/  196]   Loss 0.511966   Top1 82.135417   Top5 98.070747   BatchTime 0.351004   LR 0.004560   
2022-11-25 11:48:29,008 - INFO  - ==> Top1: 82.206    Top5: 98.086    Loss: 0.510

2022-11-25 11:48:29,250 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:48:30,667 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:48:33,057 - INFO  - Validation [1][   20/   40]   Loss 0.397145   Top1 86.640625   Top5 99.453125   BatchTime 0.119432   
2022-11-25 11:48:34,097 - INFO  - Validation [1][   40/   40]   Loss 0.392260   Top1 86.670000   Top5 99.410000   BatchTime 0.085714   
2022-11-25 11:48:34,325 - INFO  - ==> Top1: 86.670    Top5: 99.410    Loss: 0.392

2022-11-25 11:48:34,325 - INFO  - ==> Sparsity : 0.618

2022-11-25 11:48:34,325 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 86.670   Top5: 99.410]
2022-11-25 11:48:34,326 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 85.350   Top5: 99.560]
2022-11-25 11:48:39,770 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 11:48:39,772 - INFO  - >>>>>> Epoch   2
2022-11-25 11:48:39,774 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:48:48,107 - INFO  - Training [2][   20/  196]   Loss 0.519744   Top1 82.421875   Top5 97.285156   BatchTime 0.416510   LR 0.004477   
2022-11-25 11:48:54,808 - INFO  - Training [2][   40/  196]   Loss 0.505375   Top1 82.578125   Top5 97.714844   BatchTime 0.375786   LR 0.004426   
2022-11-25 11:49:01,760 - INFO  - Training [2][   60/  196]   Loss 0.504509   Top1 82.486979   Top5 97.877604   BatchTime 0.366388   LR 0.004374   
2022-11-25 11:49:08,764 - INFO  - Training [2][   80/  196]   Loss 0.498037   Top1 82.827148   Top5 98.061523   BatchTime 0.362338   LR 0.004320   
2022-11-25 11:49:14,732 - INFO  - Training [2][  100/  196]   Loss 0.495019   Top1 82.894531   Top5 98.070312   BatchTime 0.349555   LR 0.004264   
2022-11-25 11:49:20,899 - INFO  - Training [2][  120/  196]   Loss 0.490476   Top1 82.994792   Top5 98.170573   BatchTime 0.342688   LR 0.004206   
2022-11-25 11:49:27,794 - INFO  - Training [2][  140/  196]   Loss 0.487125   Top1 83.155692   Top5 98.250558   BatchTime 0.342976   LR 0.004146   
2022-11-25 11:49:35,023 - INFO  - Training [2][  160/  196]   Loss 0.487945   Top1 83.105469   Top5 98.254395   BatchTime 0.345285   LR 0.004085   
2022-11-25 11:49:41,935 - INFO  - Training [2][  180/  196]   Loss 0.486131   Top1 83.111979   Top5 98.213976   BatchTime 0.345319   LR 0.004022   
2022-11-25 11:49:47,746 - INFO  - ==> Top1: 83.202    Top5: 98.230    Loss: 0.484

2022-11-25 11:49:47,973 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:49:49,421 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:49:51,947 - INFO  - Validation [2][   20/   40]   Loss 0.367656   Top1 87.382812   Top5 99.492188   BatchTime 0.126248   
2022-11-25 11:49:53,026 - INFO  - Validation [2][   40/   40]   Loss 0.363592   Top1 87.330000   Top5 99.570000   BatchTime 0.090092   
2022-11-25 11:49:53,260 - INFO  - ==> Top1: 87.330    Top5: 99.570    Loss: 0.364

2022-11-25 11:49:53,260 - INFO  - ==> Sparsity : 0.626

2022-11-25 11:49:53,260 - INFO  - Scoreboard best 1 ==> Epoch [2][Top1: 87.330   Top5: 99.570]
2022-11-25 11:49:53,260 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 86.670   Top5: 99.410]
2022-11-25 11:49:53,260 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 85.350   Top5: 99.560]
2022-11-25 11:49:58,732 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 11:49:58,736 - INFO  - >>>>>> Epoch   3
2022-11-25 11:49:58,737 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:50:06,859 - INFO  - Training [3][   20/  196]   Loss 0.511206   Top1 82.558594   Top5 97.832031   BatchTime 0.405954   LR 0.003907   
2022-11-25 11:50:13,807 - INFO  - Training [3][   40/  196]   Loss 0.500295   Top1 82.675781   Top5 97.939453   BatchTime 0.376673   LR 0.003840   
2022-11-25 11:50:20,597 - INFO  - Training [3][   60/  196]   Loss 0.484453   Top1 83.170573   Top5 98.111979   BatchTime 0.364285   LR 0.003771   
2022-11-25 11:50:27,535 - INFO  - Training [3][   80/  196]   Loss 0.479964   Top1 83.339844   Top5 98.203125   BatchTime 0.359936   LR 0.003701   
2022-11-25 11:50:33,435 - INFO  - Training [3][  100/  196]   Loss 0.471665   Top1 83.648438   Top5 98.261719   BatchTime 0.346950   LR 0.003630   
2022-11-25 11:50:40,221 - INFO  - Training [3][  120/  196]   Loss 0.462653   Top1 83.984375   Top5 98.375651   BatchTime 0.345670   LR 0.003558   
2022-11-25 11:50:47,581 - INFO  - Training [3][  140/  196]   Loss 0.456803   Top1 84.165737   Top5 98.440290   BatchTime 0.348862   LR 0.003484   
2022-11-25 11:50:54,749 - INFO  - Training [3][  160/  196]   Loss 0.456768   Top1 84.191895   Top5 98.444824   BatchTime 0.350054   LR 0.003410   
2022-11-25 11:51:01,535 - INFO  - Training [3][  180/  196]   Loss 0.456806   Top1 84.140625   Top5 98.374566   BatchTime 0.348857   LR 0.003335   
2022-11-25 11:51:07,036 - INFO  - ==> Top1: 84.238    Top5: 98.402    Loss: 0.454

2022-11-25 11:51:07,322 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:51:08,819 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:51:11,250 - INFO  - Validation [3][   20/   40]   Loss 0.386206   Top1 87.539062   Top5 99.375000   BatchTime 0.121462   
2022-11-25 11:51:12,247 - INFO  - Validation [3][   40/   40]   Loss 0.383602   Top1 87.530000   Top5 99.480000   BatchTime 0.085682   
2022-11-25 11:51:12,528 - INFO  - ==> Top1: 87.530    Top5: 99.480    Loss: 0.384

2022-11-25 11:51:12,528 - INFO  - ==> Sparsity : 0.632

2022-11-25 11:51:12,529 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 87.530   Top5: 99.480]
2022-11-25 11:51:12,529 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 87.330   Top5: 99.570]
2022-11-25 11:51:12,529 - INFO  - Scoreboard best 3 ==> Epoch [1][Top1: 86.670   Top5: 99.410]
2022-11-25 11:51:18,208 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 11:51:18,212 - INFO  - >>>>>> Epoch   4
2022-11-25 11:51:18,215 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:51:26,506 - INFO  - Training [4][   20/  196]   Loss 0.466152   Top1 84.003906   Top5 98.066406   BatchTime 0.414442   LR 0.003200   
2022-11-25 11:51:33,457 - INFO  - Training [4][   40/  196]   Loss 0.458221   Top1 84.306641   Top5 98.105469   BatchTime 0.381000   LR 0.003122   
2022-11-25 11:51:40,228 - INFO  - Training [4][   60/  196]   Loss 0.457330   Top1 84.055990   Top5 98.274740   BatchTime 0.366837   LR 0.003044   
2022-11-25 11:51:46,370 - INFO  - Training [4][   80/  196]   Loss 0.450956   Top1 84.272461   Top5 98.437500   BatchTime 0.351908   LR 0.002965   
2022-11-25 11:51:51,799 - INFO  - Training [4][  100/  196]   Loss 0.445843   Top1 84.476562   Top5 98.425781   BatchTime 0.335812   LR 0.002886   
2022-11-25 11:51:57,182 - INFO  - Training [4][  120/  196]   Loss 0.434515   Top1 84.801432   Top5 98.525391   BatchTime 0.324704   LR 0.002806   
2022-11-25 11:52:04,619 - INFO  - Training [4][  140/  196]   Loss 0.435114   Top1 84.863281   Top5 98.565848   BatchTime 0.331436   LR 0.002726   
2022-11-25 11:52:12,066 - INFO  - Training [4][  160/  196]   Loss 0.435729   Top1 84.853516   Top5 98.540039   BatchTime 0.336549   LR 0.002646   
2022-11-25 11:52:18,937 - INFO  - Training [4][  180/  196]   Loss 0.437003   Top1 84.774306   Top5 98.454861   BatchTime 0.337329   LR 0.002566   
2022-11-25 11:52:25,139 - INFO  - ==> Top1: 84.936    Top5: 98.466    Loss: 0.433

2022-11-25 11:52:25,414 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:52:27,053 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:52:29,515 - INFO  - Validation [4][   20/   40]   Loss 0.350066   Top1 88.632812   Top5 99.433594   BatchTime 0.122996   
2022-11-25 11:52:30,558 - INFO  - Validation [4][   40/   40]   Loss 0.343547   Top1 88.490000   Top5 99.660000   BatchTime 0.087603   
2022-11-25 11:52:30,772 - INFO  - ==> Top1: 88.490    Top5: 99.660    Loss: 0.344

2022-11-25 11:52:30,772 - INFO  - ==> Sparsity : 0.634

2022-11-25 11:52:30,772 - INFO  - Scoreboard best 1 ==> Epoch [4][Top1: 88.490   Top5: 99.660]
2022-11-25 11:52:30,772 - INFO  - Scoreboard best 2 ==> Epoch [3][Top1: 87.530   Top5: 99.480]
2022-11-25 11:52:30,773 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 87.330   Top5: 99.570]
2022-11-25 11:52:36,439 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 11:52:36,441 - INFO  - >>>>>> Epoch   5
2022-11-25 11:52:36,443 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:52:44,793 - INFO  - Training [5][   20/  196]   Loss 0.400913   Top1 85.449219   Top5 98.144531   BatchTime 0.417362   LR 0.002424   
2022-11-25 11:52:52,216 - INFO  - Training [5][   40/  196]   Loss 0.413873   Top1 85.419922   Top5 98.427734   BatchTime 0.394274   LR 0.002343   
2022-11-25 11:52:59,250 - INFO  - Training [5][   60/  196]   Loss 0.414226   Top1 85.462240   Top5 98.522135   BatchTime 0.380064   LR 0.002263   
2022-11-25 11:53:06,446 - INFO  - Training [5][   80/  196]   Loss 0.433507   Top1 84.619141   Top5 98.051758   BatchTime 0.375006   LR 0.002183   
2022-11-25 11:53:12,197 - INFO  - Training [5][  100/  196]   Loss 0.420575   Top1 85.003906   Top5 98.218750   BatchTime 0.357510   LR 0.002104   
2022-11-25 11:53:19,045 - INFO  - Training [5][  120/  196]   Loss 0.412052   Top1 85.374349   Top5 98.330078   BatchTime 0.354994   LR 0.002024   
2022-11-25 11:53:26,341 - INFO  - Training [5][  140/  196]   Loss 0.407137   Top1 85.530134   Top5 98.470982   BatchTime 0.356391   LR 0.001946   
2022-11-25 11:53:33,436 - INFO  - Training [5][  160/  196]   Loss 0.410133   Top1 85.415039   Top5 98.461914   BatchTime 0.356184   LR 0.001868   
2022-11-25 11:53:39,995 - INFO  - Training [5][  180/  196]   Loss 0.408673   Top1 85.392795   Top5 98.439670   BatchTime 0.353048   LR 0.001790   
2022-11-25 11:53:45,337 - INFO  - ==> Top1: 85.468    Top5: 98.452    Loss: 0.408

2022-11-25 11:53:45,594 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:53:47,027 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:53:49,531 - INFO  - Validation [5][   20/   40]   Loss 0.325917   Top1 88.574219   Top5 99.687500   BatchTime 0.125147   
2022-11-25 11:53:50,499 - INFO  - Validation [5][   40/   40]   Loss 0.319515   Top1 88.870000   Top5 99.690000   BatchTime 0.086774   
2022-11-25 11:53:50,738 - INFO  - ==> Top1: 88.870    Top5: 99.690    Loss: 0.320

2022-11-25 11:53:50,738 - INFO  - ==> Sparsity : 0.637

2022-11-25 11:53:50,738 - INFO  - Scoreboard best 1 ==> Epoch [5][Top1: 88.870   Top5: 99.690]
2022-11-25 11:53:50,738 - INFO  - Scoreboard best 2 ==> Epoch [4][Top1: 88.490   Top5: 99.660]
2022-11-25 11:53:50,738 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 87.530   Top5: 99.480]
2022-11-25 11:53:55,579 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 11:53:55,582 - INFO  - >>>>>> Epoch   6
2022-11-25 11:53:55,584 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:54:04,162 - INFO  - Training [6][   20/  196]   Loss 0.406124   Top1 85.683594   Top5 98.027344   BatchTime 0.428774   LR 0.001655   
2022-11-25 11:54:11,212 - INFO  - Training [6][   40/  196]   Loss 0.396876   Top1 85.791016   Top5 98.222656   BatchTime 0.390625   LR 0.001580   
2022-11-25 11:54:18,039 - INFO  - Training [6][   60/  196]   Loss 0.387346   Top1 86.256510   Top5 98.417969   BatchTime 0.374204   LR 0.001506   
2022-11-25 11:54:24,706 - INFO  - Training [6][   80/  196]   Loss 0.379821   Top1 86.630859   Top5 98.569336   BatchTime 0.363988   LR 0.001432   
2022-11-25 11:54:30,219 - INFO  - Training [6][  100/  196]   Loss 0.377222   Top1 86.695312   Top5 98.621094   BatchTime 0.346323   LR 0.001360   
2022-11-25 11:54:36,473 - INFO  - Training [6][  120/  196]   Loss 0.375337   Top1 86.832682   Top5 98.688151   BatchTime 0.340717   LR 0.001289   
2022-11-25 11:54:42,708 - INFO  - Training [6][  140/  196]   Loss 0.372952   Top1 86.930804   Top5 98.766741   BatchTime 0.336574   LR 0.001220   
2022-11-25 11:54:50,058 - INFO  - Training [6][  160/  196]   Loss 0.373943   Top1 86.889648   Top5 98.718262   BatchTime 0.340441   LR 0.001151   
2022-11-25 11:54:56,918 - INFO  - Training [6][  180/  196]   Loss 0.375683   Top1 86.827257   Top5 98.708767   BatchTime 0.340723   LR 0.001084   
2022-11-25 11:55:02,414 - INFO  - ==> Top1: 86.850    Top5: 98.714    Loss: 0.374

2022-11-25 11:55:02,646 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:55:04,175 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:55:06,675 - INFO  - Validation [6][   20/   40]   Loss 0.296263   Top1 89.824219   Top5 99.609375   BatchTime 0.124907   
2022-11-25 11:55:07,693 - INFO  - Validation [6][   40/   40]   Loss 0.283257   Top1 90.060000   Top5 99.700000   BatchTime 0.087924   
2022-11-25 11:55:07,961 - INFO  - ==> Top1: 90.060    Top5: 99.700    Loss: 0.283

2022-11-25 11:55:07,961 - INFO  - ==> Sparsity : 0.639

2022-11-25 11:55:07,961 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 11:55:07,961 - INFO  - Scoreboard best 2 ==> Epoch [5][Top1: 88.870   Top5: 99.690]
2022-11-25 11:55:07,961 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 88.490   Top5: 99.660]
2022-11-25 11:55:13,247 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 11:55:13,249 - INFO  - >>>>>> Epoch   7
2022-11-25 11:55:13,251 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:55:21,668 - INFO  - Training [7][   20/  196]   Loss 0.380780   Top1 86.425781   Top5 98.281250   BatchTime 0.420734   LR 0.000969   
2022-11-25 11:55:28,506 - INFO  - Training [7][   40/  196]   Loss 0.373204   Top1 86.757812   Top5 98.496094   BatchTime 0.381301   LR 0.000907   
2022-11-25 11:55:35,452 - INFO  - Training [7][   60/  196]   Loss 0.370274   Top1 86.816406   Top5 98.502604   BatchTime 0.369975   LR 0.000845   
2022-11-25 11:55:42,144 - INFO  - Training [7][   80/  196]   Loss 0.370550   Top1 87.016602   Top5 98.652344   BatchTime 0.361125   LR 0.000786   
2022-11-25 11:55:49,105 - INFO  - Training [7][  100/  196]   Loss 0.362526   Top1 87.332031   Top5 98.699219   BatchTime 0.358511   LR 0.000728   
2022-11-25 11:55:54,871 - INFO  - Training [7][  120/  196]   Loss 0.356959   Top1 87.587891   Top5 98.776042   BatchTime 0.346810   LR 0.000673   
2022-11-25 11:56:01,758 - INFO  - Training [7][  140/  196]   Loss 0.352791   Top1 87.787388   Top5 98.808594   BatchTime 0.346456   LR 0.000619   
2022-11-25 11:56:08,878 - INFO  - Training [7][  160/  196]   Loss 0.353047   Top1 87.763672   Top5 98.793945   BatchTime 0.347646   LR 0.000567   
2022-11-25 11:56:15,785 - INFO  - Training [7][  180/  196]   Loss 0.353952   Top1 87.736545   Top5 98.756510   BatchTime 0.347394   LR 0.000517   
2022-11-25 11:56:21,608 - INFO  - ==> Top1: 87.768    Top5: 98.750    Loss: 0.352

2022-11-25 11:56:21,863 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:56:23,290 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:56:25,821 - INFO  - Validation [7][   20/   40]   Loss 0.330204   Top1 89.140625   Top5 99.531250   BatchTime 0.126471   
2022-11-25 11:56:26,845 - INFO  - Validation [7][   40/   40]   Loss 0.318779   Top1 89.330000   Top5 99.640000   BatchTime 0.088841   
2022-11-25 11:56:27,134 - INFO  - ==> Top1: 89.330    Top5: 99.640    Loss: 0.319

2022-11-25 11:56:27,135 - INFO  - ==> Sparsity : 0.639

2022-11-25 11:56:27,135 - INFO  - Scoreboard best 1 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 11:56:27,135 - INFO  - Scoreboard best 2 ==> Epoch [7][Top1: 89.330   Top5: 99.640]
2022-11-25 11:56:27,135 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 88.870   Top5: 99.690]
2022-11-25 11:56:27,306 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 11:56:27,308 - INFO  - >>>>>> Epoch   8
2022-11-25 11:56:27,310 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:56:35,743 - INFO  - Training [8][   20/  196]   Loss 0.362890   Top1 87.480469   Top5 98.378906   BatchTime 0.421509   LR 0.000434   
2022-11-25 11:56:43,096 - INFO  - Training [8][   40/  196]   Loss 0.359743   Top1 87.314453   Top5 98.496094   BatchTime 0.394575   LR 0.000389   
2022-11-25 11:56:50,294 - INFO  - Training [8][   60/  196]   Loss 0.353190   Top1 87.552083   Top5 98.593750   BatchTime 0.383023   LR 0.000347   
2022-11-25 11:56:57,094 - INFO  - Training [8][   80/  196]   Loss 0.344926   Top1 87.929688   Top5 98.750000   BatchTime 0.372258   LR 0.000308   
2022-11-25 11:57:04,249 - INFO  - Training [8][  100/  196]   Loss 0.339844   Top1 88.132812   Top5 98.792969   BatchTime 0.369361   LR 0.000270   
2022-11-25 11:57:10,632 - INFO  - Training [8][  120/  196]   Loss 0.333596   Top1 88.375651   Top5 98.857422   BatchTime 0.360991   LR 0.000235   
2022-11-25 11:57:15,919 - INFO  - Training [8][  140/  196]   Loss 0.332051   Top1 88.415179   Top5 98.925781   BatchTime 0.347183   LR 0.000202   
2022-11-25 11:57:20,875 - INFO  - Training [8][  160/  196]   Loss 0.335169   Top1 88.269043   Top5 98.940430   BatchTime 0.334762   LR 0.000172   
2022-11-25 11:57:27,920 - INFO  - Training [8][  180/  196]   Loss 0.333332   Top1 88.300781   Top5 98.912760   BatchTime 0.336704   LR 0.000143   
2022-11-25 11:57:33,335 - INFO  - ==> Top1: 88.320    Top5: 98.906    Loss: 0.332

2022-11-25 11:57:33,608 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:57:35,113 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:57:37,999 - INFO  - Validation [8][   20/   40]   Loss 0.282665   Top1 90.722656   Top5 99.687500   BatchTime 0.144198   
2022-11-25 11:57:39,070 - INFO  - Validation [8][   40/   40]   Loss 0.266247   Top1 91.050000   Top5 99.760000   BatchTime 0.098876   
2022-11-25 11:57:39,302 - INFO  - ==> Top1: 91.050    Top5: 99.760    Loss: 0.266

2022-11-25 11:57:39,303 - INFO  - ==> Sparsity : 0.638

2022-11-25 11:57:39,303 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 11:57:39,303 - INFO  - Scoreboard best 2 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 11:57:39,303 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 89.330   Top5: 99.640]
2022-11-25 11:57:44,369 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 11:57:44,371 - INFO  - >>>>>> Epoch   9
2022-11-25 11:57:44,373 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:57:52,585 - INFO  - Training [9][   20/  196]   Loss 0.343568   Top1 87.597656   Top5 98.378906   BatchTime 0.410466   LR 0.000100   
2022-11-25 11:57:59,410 - INFO  - Training [9][   40/  196]   Loss 0.339858   Top1 87.714844   Top5 98.613281   BatchTime 0.375869   LR 0.000079   
2022-11-25 11:58:06,100 - INFO  - Training [9][   60/  196]   Loss 0.338066   Top1 87.662760   Top5 98.717448   BatchTime 0.362081   LR 0.000060   
2022-11-25 11:58:13,110 - INFO  - Training [9][   80/  196]   Loss 0.334331   Top1 87.944336   Top5 98.837891   BatchTime 0.359182   LR 0.000044   
2022-11-25 11:58:19,939 - INFO  - Training [9][  100/  196]   Loss 0.328031   Top1 88.187500   Top5 98.878906   BatchTime 0.355627   LR 0.000030   
2022-11-25 11:58:26,938 - INFO  - Training [9][  120/  196]   Loss 0.319939   Top1 88.574219   Top5 98.958333   BatchTime 0.354688   LR 0.000019   
2022-11-25 11:58:34,119 - INFO  - Training [9][  140/  196]   Loss 0.316968   Top1 88.669085   Top5 99.029018   BatchTime 0.355307   LR 0.000010   
2022-11-25 11:58:39,557 - INFO  - Training [9][  160/  196]   Loss 0.318124   Top1 88.713379   Top5 99.030762   BatchTime 0.344879   LR 0.000004   
2022-11-25 11:58:46,603 - INFO  - Training [9][  180/  196]   Loss 0.319212   Top1 88.658854   Top5 98.960503   BatchTime 0.345704   LR 0.000001   
2022-11-25 11:58:53,015 - INFO  - ==> Top1: 88.712    Top5: 98.968    Loss: 0.319

2022-11-25 11:58:53,269 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:58:54,707 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:58:57,327 - INFO  - Validation [9][   20/   40]   Loss 0.291151   Top1 90.468750   Top5 99.707031   BatchTime 0.130884   
2022-11-25 11:58:58,398 - INFO  - Validation [9][   40/   40]   Loss 0.276423   Top1 90.770000   Top5 99.730000   BatchTime 0.092222   
2022-11-25 11:58:58,626 - INFO  - ==> Top1: 90.770    Top5: 99.730    Loss: 0.276

2022-11-25 11:58:58,626 - INFO  - ==> Sparsity : 0.638

2022-11-25 11:58:58,627 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 11:58:58,627 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 11:58:58,627 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 11:58:58,754 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 11:58:58,756 - INFO  - >>>>>> Epoch  10
2022-11-25 11:58:58,757 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:59:07,069 - INFO  - Training [10][   20/  196]   Loss 0.364713   Top1 87.031250   Top5 98.378906   BatchTime 0.415435   LR 0.002500   
2022-11-25 11:59:13,874 - INFO  - Training [10][   40/  196]   Loss 0.377668   Top1 86.757812   Top5 98.564453   BatchTime 0.377840   LR 0.002499   
2022-11-25 11:59:20,763 - INFO  - Training [10][   60/  196]   Loss 0.377670   Top1 86.803385   Top5 98.639323   BatchTime 0.366713   LR 0.002499   
2022-11-25 11:59:27,828 - INFO  - Training [10][   80/  196]   Loss 0.380628   Top1 86.855469   Top5 98.715820   BatchTime 0.363349   LR 0.002497   
2022-11-25 11:59:35,162 - INFO  - Training [10][  100/  196]   Loss 0.377947   Top1 86.957031   Top5 98.714844   BatchTime 0.364017   LR 0.002496   
2022-11-25 11:59:41,942 - INFO  - Training [10][  120/  196]   Loss 0.373340   Top1 87.024740   Top5 98.795573   BatchTime 0.359846   LR 0.002494   
2022-11-25 11:59:48,735 - INFO  - Training [10][  140/  196]   Loss 0.374591   Top1 87.047991   Top5 98.828125   BatchTime 0.356964   LR 0.002492   
2022-11-25 11:59:54,172 - INFO  - Training [10][  160/  196]   Loss 0.381969   Top1 86.728516   Top5 98.774414   BatchTime 0.346323   LR 0.002490   
2022-11-25 11:59:59,170 - INFO  - Training [10][  180/  196]   Loss 0.386177   Top1 86.621094   Top5 98.730469   BatchTime 0.335605   LR 0.002487   
2022-11-25 12:00:05,108 - INFO  - ==> Top1: 86.648    Top5: 98.720    Loss: 0.386

2022-11-25 12:00:05,403 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:00:07,212 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:00:10,158 - INFO  - Validation [10][   20/   40]   Loss 0.307214   Top1 89.648438   Top5 99.531250   BatchTime 0.147205   
2022-11-25 12:00:11,995 - INFO  - Validation [10][   40/   40]   Loss 0.306522   Top1 89.800000   Top5 99.540000   BatchTime 0.119535   
2022-11-25 12:00:12,661 - INFO  - ==> Top1: 89.800    Top5: 99.540    Loss: 0.307

2022-11-25 12:00:12,661 - INFO  - ==> Sparsity : 0.642

2022-11-25 12:00:12,662 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:00:12,662 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:00:12,662 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 12:00:12,852 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:00:12,854 - INFO  - >>>>>> Epoch  11
2022-11-25 12:00:12,856 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:00:22,293 - INFO  - Training [11][   20/  196]   Loss 0.402264   Top1 86.093750   Top5 97.929688   BatchTime 0.471724   LR 0.002481   
2022-11-25 12:00:29,107 - INFO  - Training [11][   40/  196]   Loss 0.411638   Top1 85.878906   Top5 98.212891   BatchTime 0.406203   LR 0.002478   
2022-11-25 12:00:36,046 - INFO  - Training [11][   60/  196]   Loss 0.407965   Top1 86.015625   Top5 98.391927   BatchTime 0.386448   LR 0.002474   
2022-11-25 12:00:42,992 - INFO  - Training [11][   80/  196]   Loss 0.403191   Top1 86.054688   Top5 98.535156   BatchTime 0.376670   LR 0.002470   
2022-11-25 12:00:49,824 - INFO  - Training [11][  100/  196]   Loss 0.397670   Top1 86.160156   Top5 98.582031   BatchTime 0.369655   LR 0.002465   
2022-11-25 12:00:56,767 - INFO  - Training [11][  120/  196]   Loss 0.391371   Top1 86.344401   Top5 98.688151   BatchTime 0.365903   LR 0.002460   
2022-11-25 12:01:03,535 - INFO  - Training [11][  140/  196]   Loss 0.391976   Top1 86.325335   Top5 98.722098   BatchTime 0.361973   LR 0.002455   
2022-11-25 12:01:10,303 - INFO  - Training [11][  160/  196]   Loss 0.394709   Top1 86.230469   Top5 98.715820   BatchTime 0.359021   LR 0.002450   
2022-11-25 12:01:16,002 - INFO  - Training [11][  180/  196]   Loss 0.393697   Top1 86.254340   Top5 98.667535   BatchTime 0.350792   LR 0.002444   
2022-11-25 12:01:21,947 - INFO  - ==> Top1: 86.322    Top5: 98.660    Loss: 0.393

2022-11-25 12:01:22,195 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:01:23,598 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:01:26,215 - INFO  - Validation [11][   20/   40]   Loss 0.372839   Top1 87.402344   Top5 99.472656   BatchTime 0.130762   
2022-11-25 12:01:27,302 - INFO  - Validation [11][   40/   40]   Loss 0.372324   Top1 87.380000   Top5 99.550000   BatchTime 0.092559   
2022-11-25 12:01:27,545 - INFO  - ==> Top1: 87.380    Top5: 99.550    Loss: 0.372

2022-11-25 12:01:27,546 - INFO  - ==> Sparsity : 0.644

2022-11-25 12:01:27,546 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:01:27,546 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:01:27,547 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 12:01:27,715 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:01:27,717 - INFO  - >>>>>> Epoch  12
2022-11-25 12:01:27,719 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:01:36,955 - INFO  - Training [12][   20/  196]   Loss 0.419289   Top1 85.351562   Top5 98.164062   BatchTime 0.461662   LR 0.002433   
2022-11-25 12:01:44,015 - INFO  - Training [12][   40/  196]   Loss 0.421337   Top1 85.634766   Top5 98.271484   BatchTime 0.407332   LR 0.002426   
2022-11-25 12:01:50,842 - INFO  - Training [12][   60/  196]   Loss 0.411711   Top1 85.898438   Top5 98.385417   BatchTime 0.385337   LR 0.002419   
2022-11-25 12:01:57,558 - INFO  - Training [12][   80/  196]   Loss 0.412001   Top1 85.957031   Top5 98.500977   BatchTime 0.372951   LR 0.002412   
2022-11-25 12:02:04,177 - INFO  - Training [12][  100/  196]   Loss 0.399796   Top1 86.308594   Top5 98.601562   BatchTime 0.364550   LR 0.002404   
2022-11-25 12:02:11,137 - INFO  - Training [12][  120/  196]   Loss 0.394069   Top1 86.546224   Top5 98.658854   BatchTime 0.361794   LR 0.002396   
2022-11-25 12:02:18,879 - INFO  - Training [12][  140/  196]   Loss 0.393706   Top1 86.531808   Top5 98.713728   BatchTime 0.365408   LR 0.002388   
2022-11-25 12:02:26,110 - INFO  - Training [12][  160/  196]   Loss 0.398989   Top1 86.376953   Top5 98.681641   BatchTime 0.364927   LR 0.002380   
2022-11-25 12:02:32,462 - INFO  - Training [12][  180/  196]   Loss 0.396263   Top1 86.464844   Top5 98.650174   BatchTime 0.359668   LR 0.002371   
2022-11-25 12:02:36,735 - INFO  - ==> Top1: 86.454    Top5: 98.656    Loss: 0.396

2022-11-25 12:02:36,930 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:02:38,578 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:02:41,182 - INFO  - Validation [12][   20/   40]   Loss 0.378449   Top1 87.617188   Top5 99.394531   BatchTime 0.130073   
2022-11-25 12:02:42,193 - INFO  - Validation [12][   40/   40]   Loss 0.367136   Top1 87.630000   Top5 99.520000   BatchTime 0.090340   
2022-11-25 12:02:42,459 - INFO  - ==> Top1: 87.630    Top5: 99.520    Loss: 0.367

2022-11-25 12:02:42,460 - INFO  - ==> Sparsity : 0.646

2022-11-25 12:02:42,460 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:02:42,460 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:02:42,460 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 12:02:42,587 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:02:42,589 - INFO  - >>>>>> Epoch  13
2022-11-25 12:02:42,590 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:02:51,108 - INFO  - Training [13][   20/  196]   Loss 0.382678   Top1 86.328125   Top5 98.183594   BatchTime 0.425733   LR 0.002355   
2022-11-25 12:02:58,802 - INFO  - Training [13][   40/  196]   Loss 0.383393   Top1 86.542969   Top5 98.437500   BatchTime 0.405234   LR 0.002345   
2022-11-25 12:03:06,140 - INFO  - Training [13][   60/  196]   Loss 0.383142   Top1 86.582031   Top5 98.554688   BatchTime 0.392445   LR 0.002336   
2022-11-25 12:03:12,918 - INFO  - Training [13][   80/  196]   Loss 0.386508   Top1 86.376953   Top5 98.681641   BatchTime 0.379055   LR 0.002325   
2022-11-25 12:03:19,738 - INFO  - Training [13][  100/  196]   Loss 0.385744   Top1 86.347656   Top5 98.730469   BatchTime 0.371449   LR 0.002315   
2022-11-25 12:03:26,558 - INFO  - Training [13][  120/  196]   Loss 0.381988   Top1 86.608073   Top5 98.763021   BatchTime 0.366372   LR 0.002304   
2022-11-25 12:03:33,281 - INFO  - Training [13][  140/  196]   Loss 0.385621   Top1 86.476004   Top5 98.758371   BatchTime 0.362052   LR 0.002293   
2022-11-25 12:03:40,082 - INFO  - Training [13][  160/  196]   Loss 0.387784   Top1 86.418457   Top5 98.740234   BatchTime 0.359300   LR 0.002282   
2022-11-25 12:03:47,073 - INFO  - Training [13][  180/  196]   Loss 0.386518   Top1 86.434462   Top5 98.687066   BatchTime 0.358214   LR 0.002271   
2022-11-25 12:03:51,997 - INFO  - ==> Top1: 86.352    Top5: 98.670    Loss: 0.389

2022-11-25 12:03:52,306 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:03:54,424 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:03:57,628 - INFO  - Validation [13][   20/   40]   Loss 0.447074   Top1 84.824219   Top5 99.160156   BatchTime 0.160112   
2022-11-25 12:03:58,770 - INFO  - Validation [13][   40/   40]   Loss 0.444537   Top1 85.080000   Top5 99.260000   BatchTime 0.108622   
2022-11-25 12:03:59,020 - INFO  - ==> Top1: 85.080    Top5: 99.260    Loss: 0.445

2022-11-25 12:03:59,020 - INFO  - ==> Sparsity : 0.650

2022-11-25 12:03:59,020 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:03:59,021 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:03:59,021 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 12:03:59,162 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:03:59,164 - INFO  - >>>>>> Epoch  14
2022-11-25 12:03:59,165 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:04:07,594 - INFO  - Training [14][   20/  196]   Loss 0.476452   Top1 83.164062   Top5 97.792969   BatchTime 0.421325   LR 0.002250   
2022-11-25 12:04:14,750 - INFO  - Training [14][   40/  196]   Loss 0.455690   Top1 84.052734   Top5 97.968750   BatchTime 0.389563   LR 0.002238   
2022-11-25 12:04:21,731 - INFO  - Training [14][   60/  196]   Loss 0.443040   Top1 84.557292   Top5 98.203125   BatchTime 0.376056   LR 0.002225   
2022-11-25 12:04:28,292 - INFO  - Training [14][   80/  196]   Loss 0.431862   Top1 84.946289   Top5 98.364258   BatchTime 0.364044   LR 0.002213   
2022-11-25 12:04:35,112 - INFO  - Training [14][  100/  196]   Loss 0.421401   Top1 85.289062   Top5 98.449219   BatchTime 0.359433   LR 0.002200   
2022-11-25 12:04:41,949 - INFO  - Training [14][  120/  196]   Loss 0.411674   Top1 85.615234   Top5 98.583984   BatchTime 0.356509   LR 0.002186   
2022-11-25 12:04:49,106 - INFO  - Training [14][  140/  196]   Loss 0.411066   Top1 85.630580   Top5 98.663504   BatchTime 0.356696   LR 0.002173   
2022-11-25 12:04:56,278 - INFO  - Training [14][  160/  196]   Loss 0.413895   Top1 85.561523   Top5 98.640137   BatchTime 0.356935   LR 0.002159   
2022-11-25 12:05:03,249 - INFO  - Training [14][  180/  196]   Loss 0.411625   Top1 85.635851   Top5 98.621962   BatchTime 0.356004   LR 0.002145   
2022-11-25 12:05:08,807 - INFO  - ==> Top1: 85.698    Top5: 98.630    Loss: 0.411

2022-11-25 12:05:09,052 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:05:10,190 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:05:13,088 - INFO  - Validation [14][   20/   40]   Loss 0.343484   Top1 88.593750   Top5 99.472656   BatchTime 0.144813   
2022-11-25 12:05:15,109 - INFO  - Validation [14][   40/   40]   Loss 0.334738   Top1 88.850000   Top5 99.590000   BatchTime 0.122945   
2022-11-25 12:05:15,640 - INFO  - ==> Top1: 88.850    Top5: 99.590    Loss: 0.335

2022-11-25 12:05:15,640 - INFO  - ==> Sparsity : 0.648

2022-11-25 12:05:15,641 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:05:15,641 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:05:15,641 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 12:05:15,783 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:05:15,785 - INFO  - >>>>>> Epoch  15
2022-11-25 12:05:15,787 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:05:24,662 - INFO  - Training [15][   20/  196]   Loss 0.401477   Top1 85.449219   Top5 98.359375   BatchTime 0.443638   LR 0.002120   
2022-11-25 12:05:31,376 - INFO  - Training [15][   40/  196]   Loss 0.396778   Top1 85.869141   Top5 98.544922   BatchTime 0.389657   LR 0.002106   
2022-11-25 12:05:39,108 - INFO  - Training [15][   60/  196]   Loss 0.393996   Top1 86.132812   Top5 98.580729   BatchTime 0.388638   LR 0.002091   
2022-11-25 12:05:46,334 - INFO  - Training [15][   80/  196]   Loss 0.389100   Top1 86.337891   Top5 98.701172   BatchTime 0.381808   LR 0.002076   
2022-11-25 12:05:53,072 - INFO  - Training [15][  100/  196]   Loss 0.381770   Top1 86.640625   Top5 98.726562   BatchTime 0.372826   LR 0.002061   
2022-11-25 12:05:59,907 - INFO  - Training [15][  120/  196]   Loss 0.374793   Top1 86.881510   Top5 98.792318   BatchTime 0.367640   LR 0.002045   
2022-11-25 12:06:06,866 - INFO  - Training [15][  140/  196]   Loss 0.373897   Top1 86.936384   Top5 98.794643   BatchTime 0.364829   LR 0.002030   
2022-11-25 12:06:13,679 - INFO  - Training [15][  160/  196]   Loss 0.377346   Top1 86.799316   Top5 98.750000   BatchTime 0.361805   LR 0.002014   
2022-11-25 12:06:20,465 - INFO  - Training [15][  180/  196]   Loss 0.377223   Top1 86.846788   Top5 98.693576   BatchTime 0.359305   LR 0.001998   
2022-11-25 12:06:26,007 - INFO  - ==> Top1: 86.822    Top5: 98.678    Loss: 0.377

2022-11-25 12:06:26,236 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:06:27,611 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:06:30,258 - INFO  - Validation [15][   20/   40]   Loss 0.349159   Top1 88.417969   Top5 99.550781   BatchTime 0.132297   
2022-11-25 12:06:31,401 - INFO  - Validation [15][   40/   40]   Loss 0.336871   Top1 88.610000   Top5 99.680000   BatchTime 0.094719   
2022-11-25 12:06:31,766 - INFO  - ==> Top1: 88.610    Top5: 99.680    Loss: 0.337

2022-11-25 12:06:31,766 - INFO  - ==> Sparsity : 0.654

2022-11-25 12:06:31,766 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:06:31,766 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:06:31,767 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 12:06:31,907 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:06:31,908 - INFO  - >>>>>> Epoch  16
2022-11-25 12:06:31,910 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:06:39,285 - INFO  - Training [16][   20/  196]   Loss 0.387689   Top1 86.367188   Top5 98.359375   BatchTime 0.368603   LR 0.001969   
2022-11-25 12:06:46,204 - INFO  - Training [16][   40/  196]   Loss 0.385601   Top1 86.318359   Top5 98.388672   BatchTime 0.357290   LR 0.001953   
2022-11-25 12:06:53,512 - INFO  - Training [16][   60/  196]   Loss 0.378753   Top1 86.582031   Top5 98.541667   BatchTime 0.359992   LR 0.001936   
2022-11-25 12:07:00,848 - INFO  - Training [16][   80/  196]   Loss 0.373597   Top1 86.723633   Top5 98.706055   BatchTime 0.361688   LR 0.001919   
2022-11-25 12:07:07,570 - INFO  - Training [16][  100/  196]   Loss 0.367207   Top1 87.015625   Top5 98.742188   BatchTime 0.356569   LR 0.001902   
2022-11-25 12:07:14,262 - INFO  - Training [16][  120/  196]   Loss 0.359968   Top1 87.272135   Top5 98.837891   BatchTime 0.352908   LR 0.001885   
2022-11-25 12:07:20,919 - INFO  - Training [16][  140/  196]   Loss 0.358239   Top1 87.340960   Top5 98.911830   BatchTime 0.350037   LR 0.001867   
2022-11-25 12:07:27,613 - INFO  - Training [16][  160/  196]   Loss 0.363735   Top1 87.136230   Top5 98.901367   BatchTime 0.348122   LR 0.001850   
2022-11-25 12:07:34,232 - INFO  - Training [16][  180/  196]   Loss 0.364224   Top1 87.096354   Top5 98.880208   BatchTime 0.346216   LR 0.001832   
2022-11-25 12:07:39,835 - INFO  - ==> Top1: 87.110    Top5: 98.876    Loss: 0.364

2022-11-25 12:07:40,064 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:07:41,466 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:07:44,042 - INFO  - Validation [16][   20/   40]   Loss 0.367488   Top1 88.027344   Top5 99.472656   BatchTime 0.128684   
2022-11-25 12:07:45,080 - INFO  - Validation [16][   40/   40]   Loss 0.366004   Top1 87.840000   Top5 99.520000   BatchTime 0.090302   
2022-11-25 12:07:45,357 - INFO  - ==> Top1: 87.840    Top5: 99.520    Loss: 0.366

2022-11-25 12:07:45,357 - INFO  - ==> Sparsity : 0.656

2022-11-25 12:07:45,357 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:07:45,358 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:07:45,358 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 90.060   Top5: 99.700]
2022-11-25 12:07:45,751 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:07:45,753 - INFO  - >>>>>> Epoch  17
2022-11-25 12:07:45,756 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:07:53,499 - INFO  - Training [17][   20/  196]   Loss 0.375141   Top1 86.601562   Top5 98.164062   BatchTime 0.387023   LR 0.001800   
2022-11-25 12:08:00,108 - INFO  - Training [17][   40/  196]   Loss 0.365117   Top1 87.041016   Top5 98.544922   BatchTime 0.358719   LR 0.001782   
2022-11-25 12:08:06,919 - INFO  - Training [17][   60/  196]   Loss 0.364086   Top1 87.135417   Top5 98.619792   BatchTime 0.352666   LR 0.001764   
2022-11-25 12:08:13,864 - INFO  - Training [17][   80/  196]   Loss 0.364396   Top1 87.182617   Top5 98.720703   BatchTime 0.351311   LR 0.001746   
2022-11-25 12:08:21,194 - INFO  - Training [17][  100/  196]   Loss 0.360992   Top1 87.265625   Top5 98.792969   BatchTime 0.354347   LR 0.001727   
2022-11-25 12:08:28,104 - INFO  - Training [17][  120/  196]   Loss 0.358739   Top1 87.434896   Top5 98.841146   BatchTime 0.352873   LR 0.001708   
2022-11-25 12:08:35,236 - INFO  - Training [17][  140/  196]   Loss 0.359859   Top1 87.477679   Top5 98.864397   BatchTime 0.353408   LR 0.001690   
2022-11-25 12:08:42,312 - INFO  - Training [17][  160/  196]   Loss 0.358860   Top1 87.492676   Top5 98.850098   BatchTime 0.353454   LR 0.001671   
2022-11-25 12:08:49,060 - INFO  - Training [17][  180/  196]   Loss 0.355598   Top1 87.595486   Top5 98.834635   BatchTime 0.351671   LR 0.001652   
2022-11-25 12:08:54,474 - INFO  - ==> Top1: 87.594    Top5: 98.834    Loss: 0.355

2022-11-25 12:08:54,793 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:08:56,421 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:08:59,084 - INFO  - Validation [17][   20/   40]   Loss 0.304963   Top1 90.136719   Top5 99.648438   BatchTime 0.133029   
2022-11-25 12:09:00,084 - INFO  - Validation [17][   40/   40]   Loss 0.295041   Top1 90.260000   Top5 99.710000   BatchTime 0.091523   
2022-11-25 12:09:00,327 - INFO  - ==> Top1: 90.260    Top5: 99.710    Loss: 0.295

2022-11-25 12:09:00,327 - INFO  - ==> Sparsity : 0.658

2022-11-25 12:09:00,327 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:09:00,328 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:09:00,328 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 90.260   Top5: 99.710]
2022-11-25 12:09:00,479 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:09:00,481 - INFO  - >>>>>> Epoch  18
2022-11-25 12:09:00,483 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:09:08,482 - INFO  - Training [18][   20/  196]   Loss 0.355992   Top1 87.324219   Top5 98.125000   BatchTime 0.399786   LR 0.001618   
2022-11-25 12:09:14,407 - INFO  - Training [18][   40/  196]   Loss 0.358722   Top1 87.412109   Top5 98.300781   BatchTime 0.348022   LR 0.001599   
2022-11-25 12:09:21,288 - INFO  - Training [18][   60/  196]   Loss 0.359249   Top1 87.500000   Top5 98.411458   BatchTime 0.346698   LR 0.001579   
2022-11-25 12:09:28,342 - INFO  - Training [18][   80/  196]   Loss 0.355790   Top1 87.666016   Top5 98.598633   BatchTime 0.348204   LR 0.001560   
2022-11-25 12:09:35,279 - INFO  - Training [18][  100/  196]   Loss 0.348151   Top1 88.039062   Top5 98.667969   BatchTime 0.347932   LR 0.001540   
2022-11-25 12:09:42,781 - INFO  - Training [18][  120/  196]   Loss 0.343380   Top1 88.196615   Top5 98.753255   BatchTime 0.352456   LR 0.001521   
2022-11-25 12:09:49,643 - INFO  - Training [18][  140/  196]   Loss 0.344469   Top1 88.147321   Top5 98.816964   BatchTime 0.351124   LR 0.001501   
2022-11-25 12:09:56,954 - INFO  - Training [18][  160/  196]   Loss 0.350423   Top1 87.873535   Top5 98.791504   BatchTime 0.352923   LR 0.001482   
2022-11-25 12:10:04,537 - INFO  - Training [18][  180/  196]   Loss 0.347608   Top1 87.912326   Top5 98.760851   BatchTime 0.355837   LR 0.001462   
2022-11-25 12:10:10,709 - INFO  - ==> Top1: 87.924    Top5: 98.786    Loss: 0.347

2022-11-25 12:10:10,968 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:10:12,668 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:10:15,318 - INFO  - Validation [18][   20/   40]   Loss 0.305396   Top1 90.332031   Top5 99.531250   BatchTime 0.132417   
2022-11-25 12:10:16,391 - INFO  - Validation [18][   40/   40]   Loss 0.293203   Top1 90.530000   Top5 99.650000   BatchTime 0.093038   
2022-11-25 12:10:16,657 - INFO  - ==> Top1: 90.530    Top5: 99.650    Loss: 0.293

2022-11-25 12:10:16,657 - INFO  - ==> Sparsity : 0.658

2022-11-25 12:10:16,658 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:10:16,658 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:10:16,658 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 90.530   Top5: 99.650]
2022-11-25 12:10:17,037 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:10:17,039 - INFO  - >>>>>> Epoch  19
2022-11-25 12:10:17,040 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:10:25,491 - INFO  - Training [19][   20/  196]   Loss 0.378918   Top1 86.386719   Top5 98.281250   BatchTime 0.422410   LR 0.001427   
2022-11-25 12:10:31,157 - INFO  - Training [19][   40/  196]   Loss 0.376711   Top1 86.679688   Top5 98.496094   BatchTime 0.352867   LR 0.001407   
2022-11-25 12:10:37,526 - INFO  - Training [19][   60/  196]   Loss 0.369540   Top1 86.972656   Top5 98.639323   BatchTime 0.341383   LR 0.001387   
2022-11-25 12:10:44,380 - INFO  - Training [19][   80/  196]   Loss 0.363398   Top1 87.192383   Top5 98.759766   BatchTime 0.341712   LR 0.001367   
2022-11-25 12:10:51,324 - INFO  - Training [19][  100/  196]   Loss 0.355471   Top1 87.570312   Top5 98.742188   BatchTime 0.342809   LR 0.001347   
2022-11-25 12:10:58,795 - INFO  - Training [19][  120/  196]   Loss 0.348751   Top1 87.698568   Top5 98.792318   BatchTime 0.347933   LR 0.001327   
2022-11-25 12:11:05,658 - INFO  - Training [19][  140/  196]   Loss 0.343591   Top1 87.887835   Top5 98.861607   BatchTime 0.347245   LR 0.001307   
2022-11-25 12:11:12,590 - INFO  - Training [19][  160/  196]   Loss 0.345664   Top1 87.841797   Top5 98.857422   BatchTime 0.347166   LR 0.001287   
2022-11-25 12:11:19,264 - INFO  - Training [19][  180/  196]   Loss 0.344178   Top1 87.936198   Top5 98.817274   BatchTime 0.345671   LR 0.001266   
2022-11-25 12:11:25,041 - INFO  - ==> Top1: 88.000    Top5: 98.820    Loss: 0.342

2022-11-25 12:11:25,321 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:11:26,893 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:11:29,592 - INFO  - Validation [19][   20/   40]   Loss 0.303796   Top1 90.332031   Top5 99.570312   BatchTime 0.134866   
2022-11-25 12:11:30,718 - INFO  - Validation [19][   40/   40]   Loss 0.285417   Top1 90.530000   Top5 99.680000   BatchTime 0.095588   
2022-11-25 12:11:30,976 - INFO  - ==> Top1: 90.530    Top5: 99.680    Loss: 0.285

2022-11-25 12:11:30,976 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:11:30,977 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:11:30,977 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:11:30,977 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 90.530   Top5: 99.680]
2022-11-25 12:11:31,123 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:11:31,124 - INFO  - >>>>>> Epoch  20
2022-11-25 12:11:31,126 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:11:39,428 - INFO  - Training [20][   20/  196]   Loss 0.345458   Top1 87.968750   Top5 98.261719   BatchTime 0.414925   LR 0.001231   
2022-11-25 12:11:45,960 - INFO  - Training [20][   40/  196]   Loss 0.347455   Top1 87.724609   Top5 98.398438   BatchTime 0.370764   LR 0.001211   
2022-11-25 12:11:51,415 - INFO  - Training [20][   60/  196]   Loss 0.345802   Top1 87.805990   Top5 98.522135   BatchTime 0.338106   LR 0.001191   
2022-11-25 12:11:58,106 - INFO  - Training [20][   80/  196]   Loss 0.344527   Top1 87.978516   Top5 98.642578   BatchTime 0.337212   LR 0.001171   
2022-11-25 12:12:05,145 - INFO  - Training [20][  100/  196]   Loss 0.335396   Top1 88.242188   Top5 98.742188   BatchTime 0.340154   LR 0.001151   
2022-11-25 12:12:12,620 - INFO  - Training [20][  120/  196]   Loss 0.329730   Top1 88.395182   Top5 98.808594   BatchTime 0.345758   LR 0.001131   
2022-11-25 12:12:20,046 - INFO  - Training [20][  140/  196]   Loss 0.327399   Top1 88.459821   Top5 98.883929   BatchTime 0.349402   LR 0.001111   
2022-11-25 12:12:27,466 - INFO  - Training [20][  160/  196]   Loss 0.331073   Top1 88.361816   Top5 98.869629   BatchTime 0.352100   LR 0.001091   
2022-11-25 12:12:34,123 - INFO  - Training [20][  180/  196]   Loss 0.329425   Top1 88.450521   Top5 98.845486   BatchTime 0.349965   LR 0.001071   
2022-11-25 12:12:39,845 - INFO  - ==> Top1: 88.498    Top5: 98.872    Loss: 0.328

2022-11-25 12:12:40,074 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:12:41,498 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:12:44,024 - INFO  - Validation [20][   20/   40]   Loss 0.346008   Top1 89.882812   Top5 99.433594   BatchTime 0.126234   
2022-11-25 12:12:45,055 - INFO  - Validation [20][   40/   40]   Loss 0.325823   Top1 90.010000   Top5 99.610000   BatchTime 0.088891   
2022-11-25 12:12:45,347 - INFO  - ==> Top1: 90.010    Top5: 99.610    Loss: 0.326

2022-11-25 12:12:45,347 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:12:45,347 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:12:45,347 - INFO  - Scoreboard best 2 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:12:45,347 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 90.530   Top5: 99.680]
2022-11-25 12:12:45,482 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:12:45,484 - INFO  - >>>>>> Epoch  21
2022-11-25 12:12:45,486 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:12:55,221 - INFO  - Training [21][   20/  196]   Loss 0.334729   Top1 88.300781   Top5 98.652344   BatchTime 0.486646   LR 0.001036   
2022-11-25 12:13:01,926 - INFO  - Training [21][   40/  196]   Loss 0.332076   Top1 88.369141   Top5 98.740234   BatchTime 0.410947   LR 0.001016   
2022-11-25 12:13:07,877 - INFO  - Training [21][   60/  196]   Loss 0.329674   Top1 88.535156   Top5 98.808594   BatchTime 0.373150   LR 0.000996   
2022-11-25 12:13:13,537 - INFO  - Training [21][   80/  196]   Loss 0.325812   Top1 88.657227   Top5 98.925781   BatchTime 0.350602   LR 0.000976   
2022-11-25 12:13:20,529 - INFO  - Training [21][  100/  196]   Loss 0.317133   Top1 88.851562   Top5 98.964844   BatchTime 0.350410   LR 0.000957   
2022-11-25 12:13:27,601 - INFO  - Training [21][  120/  196]   Loss 0.312560   Top1 89.049479   Top5 99.052734   BatchTime 0.350938   LR 0.000937   
2022-11-25 12:13:35,527 - INFO  - Training [21][  140/  196]   Loss 0.312722   Top1 89.082031   Top5 99.101562   BatchTime 0.357414   LR 0.000918   
2022-11-25 12:13:42,611 - INFO  - Training [21][  160/  196]   Loss 0.315140   Top1 88.962402   Top5 99.074707   BatchTime 0.357013   LR 0.000899   
2022-11-25 12:13:49,529 - INFO  - Training [21][  180/  196]   Loss 0.316773   Top1 88.860677   Top5 99.027778   BatchTime 0.355779   LR 0.000879   
2022-11-25 12:13:54,924 - INFO  - ==> Top1: 88.912    Top5: 99.012    Loss: 0.316

2022-11-25 12:13:55,159 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:13:56,562 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:13:59,058 - INFO  - Validation [21][   20/   40]   Loss 0.299658   Top1 90.546875   Top5 99.511719   BatchTime 0.124696   
2022-11-25 12:14:00,007 - INFO  - Validation [21][   40/   40]   Loss 0.282895   Top1 90.820000   Top5 99.630000   BatchTime 0.086080   
2022-11-25 12:14:00,289 - INFO  - ==> Top1: 90.820    Top5: 99.630    Loss: 0.283

2022-11-25 12:14:00,289 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:14:00,289 - INFO  - Scoreboard best 1 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:14:00,290 - INFO  - Scoreboard best 2 ==> Epoch [21][Top1: 90.820   Top5: 99.630]
2022-11-25 12:14:00,290 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 90.770   Top5: 99.730]
2022-11-25 12:14:00,414 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:14:00,416 - INFO  - >>>>>> Epoch  22
2022-11-25 12:14:00,418 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:14:08,604 - INFO  - Training [22][   20/  196]   Loss 0.311997   Top1 89.179688   Top5 98.632812   BatchTime 0.409162   LR 0.000846   
2022-11-25 12:14:15,704 - INFO  - Training [22][   40/  196]   Loss 0.323633   Top1 88.652344   Top5 98.886719   BatchTime 0.382088   LR 0.000827   
2022-11-25 12:14:22,527 - INFO  - Training [22][   60/  196]   Loss 0.313272   Top1 88.893229   Top5 98.958333   BatchTime 0.368434   LR 0.000808   
2022-11-25 12:14:28,625 - INFO  - Training [22][   80/  196]   Loss 0.316364   Top1 88.754883   Top5 99.003906   BatchTime 0.352557   LR 0.000789   
2022-11-25 12:14:35,491 - INFO  - Training [22][  100/  196]   Loss 0.310096   Top1 88.960938   Top5 99.019531   BatchTime 0.350704   LR 0.000770   
2022-11-25 12:14:42,420 - INFO  - Training [22][  120/  196]   Loss 0.304592   Top1 89.163411   Top5 99.072266   BatchTime 0.349996   LR 0.000752   
2022-11-25 12:14:49,976 - INFO  - Training [22][  140/  196]   Loss 0.302205   Top1 89.246652   Top5 99.118304   BatchTime 0.353963   LR 0.000734   
2022-11-25 12:14:57,210 - INFO  - Training [22][  160/  196]   Loss 0.304923   Top1 89.096680   Top5 99.079590   BatchTime 0.354929   LR 0.000715   
2022-11-25 12:15:04,083 - INFO  - Training [22][  180/  196]   Loss 0.307253   Top1 88.990885   Top5 99.036458   BatchTime 0.353676   LR 0.000697   
2022-11-25 12:15:09,705 - INFO  - ==> Top1: 89.074    Top5: 99.046    Loss: 0.305

2022-11-25 12:15:09,938 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:15:11,286 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:15:13,849 - INFO  - Validation [22][   20/   40]   Loss 0.285229   Top1 91.152344   Top5 99.609375   BatchTime 0.128010   
2022-11-25 12:15:14,843 - INFO  - Validation [22][   40/   40]   Loss 0.270419   Top1 91.470000   Top5 99.700000   BatchTime 0.088865   
2022-11-25 12:15:15,126 - INFO  - ==> Top1: 91.470    Top5: 99.700    Loss: 0.270

2022-11-25 12:15:15,126 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:15:15,126 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 91.470   Top5: 99.700]
2022-11-25 12:15:15,127 - INFO  - Scoreboard best 2 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:15:15,127 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 90.820   Top5: 99.630]
2022-11-25 12:15:20,439 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:15:20,440 - INFO  - >>>>>> Epoch  23
2022-11-25 12:15:20,442 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:15:28,712 - INFO  - Training [23][   20/  196]   Loss 0.315351   Top1 89.394531   Top5 98.476562   BatchTime 0.413375   LR 0.000666   
2022-11-25 12:15:35,446 - INFO  - Training [23][   40/  196]   Loss 0.319492   Top1 89.023438   Top5 98.740234   BatchTime 0.375029   LR 0.000648   
2022-11-25 12:15:42,038 - INFO  - Training [23][   60/  196]   Loss 0.318360   Top1 88.906250   Top5 98.821615   BatchTime 0.359885   LR 0.000630   
2022-11-25 12:15:48,497 - INFO  - Training [23][   80/  196]   Loss 0.313277   Top1 89.101562   Top5 98.945312   BatchTime 0.350661   LR 0.000613   
2022-11-25 12:15:55,161 - INFO  - Training [23][  100/  196]   Loss 0.305720   Top1 89.414062   Top5 98.957031   BatchTime 0.347165   LR 0.000596   
2022-11-25 12:16:01,954 - INFO  - Training [23][  120/  196]   Loss 0.300197   Top1 89.622396   Top5 99.010417   BatchTime 0.345911   LR 0.000579   
2022-11-25 12:16:09,338 - INFO  - Training [23][  140/  196]   Loss 0.299367   Top1 89.659598   Top5 99.073661   BatchTime 0.349233   LR 0.000562   
2022-11-25 12:16:16,471 - INFO  - Training [23][  160/  196]   Loss 0.302522   Top1 89.511719   Top5 99.052734   BatchTime 0.350161   LR 0.000545   
2022-11-25 12:16:23,655 - INFO  - Training [23][  180/  196]   Loss 0.301762   Top1 89.496528   Top5 99.025608   BatchTime 0.351165   LR 0.000529   
2022-11-25 12:16:29,847 - INFO  - ==> Top1: 89.472    Top5: 99.008    Loss: 0.302

2022-11-25 12:16:30,116 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:16:31,827 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:16:34,551 - INFO  - Validation [23][   20/   40]   Loss 0.305807   Top1 90.976562   Top5 99.589844   BatchTime 0.136088   
2022-11-25 12:16:35,641 - INFO  - Validation [23][   40/   40]   Loss 0.291634   Top1 91.130000   Top5 99.740000   BatchTime 0.095305   
2022-11-25 12:16:35,945 - INFO  - ==> Top1: 91.130    Top5: 99.740    Loss: 0.292

2022-11-25 12:16:35,945 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:16:35,946 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 91.470   Top5: 99.700]
2022-11-25 12:16:35,946 - INFO  - Scoreboard best 2 ==> Epoch [23][Top1: 91.130   Top5: 99.740]
2022-11-25 12:16:35,946 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 91.050   Top5: 99.760]
2022-11-25 12:16:36,072 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:16:36,073 - INFO  - >>>>>> Epoch  24
2022-11-25 12:16:36,075 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:16:44,685 - INFO  - Training [24][   20/  196]   Loss 0.324502   Top1 88.554688   Top5 98.554688   BatchTime 0.430381   LR 0.000500   
2022-11-25 12:16:51,311 - INFO  - Training [24][   40/  196]   Loss 0.315297   Top1 88.720703   Top5 98.837891   BatchTime 0.380829   LR 0.000484   
2022-11-25 12:16:58,095 - INFO  - Training [24][   60/  196]   Loss 0.305730   Top1 89.173177   Top5 98.847656   BatchTime 0.366946   LR 0.000468   
2022-11-25 12:17:03,673 - INFO  - Training [24][   80/  196]   Loss 0.300622   Top1 89.443359   Top5 98.964844   BatchTime 0.344938   LR 0.000453   
2022-11-25 12:17:09,927 - INFO  - Training [24][  100/  196]   Loss 0.293726   Top1 89.578125   Top5 99.039062   BatchTime 0.338487   LR 0.000437   
2022-11-25 12:17:16,595 - INFO  - Training [24][  120/  196]   Loss 0.289618   Top1 89.710286   Top5 99.085286   BatchTime 0.337642   LR 0.000422   
2022-11-25 12:17:23,789 - INFO  - Training [24][  140/  196]   Loss 0.288390   Top1 89.843750   Top5 99.093192   BatchTime 0.340788   LR 0.000407   
2022-11-25 12:17:30,599 - INFO  - Training [24][  160/  196]   Loss 0.289940   Top1 89.807129   Top5 99.089355   BatchTime 0.340753   LR 0.000392   
2022-11-25 12:17:37,604 - INFO  - Training [24][  180/  196]   Loss 0.291308   Top1 89.713542   Top5 99.058160   BatchTime 0.341810   LR 0.000378   
2022-11-25 12:17:43,061 - INFO  - ==> Top1: 89.790    Top5: 99.056    Loss: 0.291

2022-11-25 12:17:43,291 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:17:44,560 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:17:47,164 - INFO  - Validation [24][   20/   40]   Loss 0.302188   Top1 91.015625   Top5 99.589844   BatchTime 0.130134   
2022-11-25 12:17:48,177 - INFO  - Validation [24][   40/   40]   Loss 0.284655   Top1 91.320000   Top5 99.710000   BatchTime 0.090387   
2022-11-25 12:17:48,452 - INFO  - ==> Top1: 91.320    Top5: 99.710    Loss: 0.285

2022-11-25 12:17:48,453 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:17:48,453 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 91.470   Top5: 99.700]
2022-11-25 12:17:48,453 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 91.320   Top5: 99.710]
2022-11-25 12:17:48,453 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 91.130   Top5: 99.740]
2022-11-25 12:17:48,575 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:17:48,576 - INFO  - >>>>>> Epoch  25
2022-11-25 12:17:48,578 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:17:56,831 - INFO  - Training [25][   20/  196]   Loss 0.302497   Top1 89.160156   Top5 98.632812   BatchTime 0.412540   LR 0.000353   
2022-11-25 12:18:03,624 - INFO  - Training [25][   40/  196]   Loss 0.305608   Top1 89.130859   Top5 98.603516   BatchTime 0.376088   LR 0.000339   
2022-11-25 12:18:10,313 - INFO  - Training [25][   60/  196]   Loss 0.300237   Top1 89.290365   Top5 98.776042   BatchTime 0.362207   LR 0.000325   
2022-11-25 12:18:17,118 - INFO  - Training [25][   80/  196]   Loss 0.296145   Top1 89.418945   Top5 98.916016   BatchTime 0.356717   LR 0.000312   
2022-11-25 12:18:22,834 - INFO  - Training [25][  100/  196]   Loss 0.288666   Top1 89.761719   Top5 98.968750   BatchTime 0.342527   LR 0.000299   
2022-11-25 12:18:29,407 - INFO  - Training [25][  120/  196]   Loss 0.286853   Top1 89.856771   Top5 99.036458   BatchTime 0.340215   LR 0.000286   
2022-11-25 12:18:36,355 - INFO  - Training [25][  140/  196]   Loss 0.286185   Top1 89.910714   Top5 99.076451   BatchTime 0.341240   LR 0.000273   
2022-11-25 12:18:43,983 - INFO  - Training [25][  160/  196]   Loss 0.288370   Top1 89.797363   Top5 99.094238   BatchTime 0.346263   LR 0.000261   
2022-11-25 12:18:51,336 - INFO  - Training [25][  180/  196]   Loss 0.288009   Top1 89.791667   Top5 99.045139   BatchTime 0.348638   LR 0.000248   
2022-11-25 12:18:56,923 - INFO  - ==> Top1: 89.780    Top5: 99.008    Loss: 0.287

2022-11-25 12:18:57,154 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:18:58,558 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:19:01,052 - INFO  - Validation [25][   20/   40]   Loss 0.527850   Top1 84.414062   Top5 99.101562   BatchTime 0.124611   
2022-11-25 12:19:01,997 - INFO  - Validation [25][   40/   40]   Loss 0.518948   Top1 84.440000   Top5 99.210000   BatchTime 0.085947   
2022-11-25 12:19:02,304 - INFO  - ==> Top1: 84.440    Top5: 99.210    Loss: 0.519

2022-11-25 12:19:02,305 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:19:02,305 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 91.470   Top5: 99.700]
2022-11-25 12:19:02,305 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 91.320   Top5: 99.710]
2022-11-25 12:19:02,305 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 91.130   Top5: 99.740]
2022-11-25 12:19:02,447 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:19:02,448 - INFO  - >>>>>> Epoch  26
2022-11-25 12:19:02,450 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:19:10,699 - INFO  - Training [26][   20/  196]   Loss 0.298260   Top1 89.726562   Top5 98.593750   BatchTime 0.412345   LR 0.000228   
2022-11-25 12:19:17,408 - INFO  - Training [26][   40/  196]   Loss 0.288645   Top1 89.746094   Top5 98.720703   BatchTime 0.373893   LR 0.000216   
2022-11-25 12:19:24,029 - INFO  - Training [26][   60/  196]   Loss 0.287639   Top1 89.967448   Top5 98.789062   BatchTime 0.359606   LR 0.000205   
2022-11-25 12:19:30,803 - INFO  - Training [26][   80/  196]   Loss 0.285845   Top1 89.951172   Top5 98.935547   BatchTime 0.354377   LR 0.000194   
2022-11-25 12:19:37,179 - INFO  - Training [26][  100/  196]   Loss 0.281445   Top1 90.074219   Top5 98.996094   BatchTime 0.347262   LR 0.000183   
2022-11-25 12:19:42,679 - INFO  - Training [26][  120/  196]   Loss 0.276444   Top1 90.244141   Top5 99.082031   BatchTime 0.335215   LR 0.000173   
2022-11-25 12:19:49,804 - INFO  - Training [26][  140/  196]   Loss 0.276143   Top1 90.220424   Top5 99.132254   BatchTime 0.338221   LR 0.000163   
2022-11-25 12:19:57,065 - INFO  - Training [26][  160/  196]   Loss 0.280918   Top1 90.109863   Top5 99.106445   BatchTime 0.341322   LR 0.000153   
2022-11-25 12:20:04,616 - INFO  - Training [26][  180/  196]   Loss 0.280211   Top1 90.097656   Top5 99.095052   BatchTime 0.345349   LR 0.000144   
2022-11-25 12:20:10,252 - INFO  - ==> Top1: 90.128    Top5: 99.094    Loss: 0.280

2022-11-25 12:20:10,536 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:20:11,906 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:20:14,558 - INFO  - Validation [26][   20/   40]   Loss 0.439732   Top1 86.835938   Top5 99.277344   BatchTime 0.132505   
2022-11-25 12:20:15,641 - INFO  - Validation [26][   40/   40]   Loss 0.431312   Top1 86.800000   Top5 99.360000   BatchTime 0.093341   
2022-11-25 12:20:15,878 - INFO  - ==> Top1: 86.800    Top5: 99.360    Loss: 0.431

2022-11-25 12:20:15,878 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:20:15,879 - INFO  - Scoreboard best 1 ==> Epoch [22][Top1: 91.470   Top5: 99.700]
2022-11-25 12:20:15,879 - INFO  - Scoreboard best 2 ==> Epoch [24][Top1: 91.320   Top5: 99.710]
2022-11-25 12:20:15,879 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 91.130   Top5: 99.740]
2022-11-25 12:20:16,045 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:20:16,047 - INFO  - >>>>>> Epoch  27
2022-11-25 12:20:16,049 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:20:24,451 - INFO  - Training [27][   20/  196]   Loss 0.306716   Top1 89.257812   Top5 98.593750   BatchTime 0.419964   LR 0.000128   
2022-11-25 12:20:31,139 - INFO  - Training [27][   40/  196]   Loss 0.291933   Top1 89.746094   Top5 98.847656   BatchTime 0.377203   LR 0.000119   
2022-11-25 12:20:37,947 - INFO  - Training [27][   60/  196]   Loss 0.286083   Top1 89.902344   Top5 98.945312   BatchTime 0.364920   LR 0.000111   
2022-11-25 12:20:44,615 - INFO  - Training [27][   80/  196]   Loss 0.288001   Top1 89.843750   Top5 98.999023   BatchTime 0.357044   LR 0.000102   
2022-11-25 12:20:51,373 - INFO  - Training [27][  100/  196]   Loss 0.283549   Top1 90.054688   Top5 99.023438   BatchTime 0.353210   LR 0.000095   
2022-11-25 12:20:57,519 - INFO  - Training [27][  120/  196]   Loss 0.280104   Top1 90.221354   Top5 99.065755   BatchTime 0.345565   LR 0.000087   
2022-11-25 12:21:03,491 - INFO  - Training [27][  140/  196]   Loss 0.277659   Top1 90.318080   Top5 99.070871   BatchTime 0.338851   LR 0.000080   
2022-11-25 12:21:10,394 - INFO  - Training [27][  160/  196]   Loss 0.277165   Top1 90.319824   Top5 99.050293   BatchTime 0.339639   LR 0.000073   
2022-11-25 12:21:18,049 - INFO  - Training [27][  180/  196]   Loss 0.277199   Top1 90.323351   Top5 99.045139   BatchTime 0.344427   LR 0.000066   
2022-11-25 12:21:23,749 - INFO  - ==> Top1: 90.392    Top5: 99.060    Loss: 0.276

2022-11-25 12:21:23,998 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:21:25,423 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:21:28,022 - INFO  - Validation [27][   20/   40]   Loss 0.286411   Top1 91.347656   Top5 99.667969   BatchTime 0.129870   
2022-11-25 12:21:29,066 - INFO  - Validation [27][   40/   40]   Loss 0.270951   Top1 91.630000   Top5 99.790000   BatchTime 0.091029   
2022-11-25 12:21:29,344 - INFO  - ==> Top1: 91.630    Top5: 99.790    Loss: 0.271

2022-11-25 12:21:29,344 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:21:29,344 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:21:29,345 - INFO  - Scoreboard best 2 ==> Epoch [22][Top1: 91.470   Top5: 99.700]
2022-11-25 12:21:29,345 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 91.320   Top5: 99.710]
2022-11-25 12:21:35,157 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:21:35,163 - INFO  - >>>>>> Epoch  28
2022-11-25 12:21:35,166 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:21:43,626 - INFO  - Training [28][   20/  196]   Loss 0.294121   Top1 89.316406   Top5 98.613281   BatchTime 0.422854   LR 0.000055   
2022-11-25 12:21:50,715 - INFO  - Training [28][   40/  196]   Loss 0.288202   Top1 89.687500   Top5 98.779297   BatchTime 0.388660   LR 0.000050   
2022-11-25 12:21:57,626 - INFO  - Training [28][   60/  196]   Loss 0.285761   Top1 89.843750   Top5 98.880208   BatchTime 0.374288   LR 0.000044   
2022-11-25 12:22:04,583 - INFO  - Training [28][   80/  196]   Loss 0.282507   Top1 90.014648   Top5 98.989258   BatchTime 0.367679   LR 0.000039   
2022-11-25 12:22:11,437 - INFO  - Training [28][  100/  196]   Loss 0.279888   Top1 90.125000   Top5 99.031250   BatchTime 0.362682   LR 0.000034   
2022-11-25 12:22:17,868 - INFO  - Training [28][  120/  196]   Loss 0.275035   Top1 90.338542   Top5 99.127604   BatchTime 0.355826   LR 0.000030   
2022-11-25 12:22:24,505 - INFO  - Training [28][  140/  196]   Loss 0.274199   Top1 90.421317   Top5 99.162946   BatchTime 0.352397   LR 0.000026   
2022-11-25 12:22:31,063 - INFO  - Training [28][  160/  196]   Loss 0.275215   Top1 90.371094   Top5 99.145508   BatchTime 0.349337   LR 0.000022   
2022-11-25 12:22:38,238 - INFO  - Training [28][  180/  196]   Loss 0.276028   Top1 90.366753   Top5 99.075521   BatchTime 0.350383   LR 0.000018   
2022-11-25 12:22:43,746 - INFO  - ==> Top1: 90.380    Top5: 99.076    Loss: 0.276

2022-11-25 12:22:43,989 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:22:45,441 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:22:48,037 - INFO  - Validation [28][   20/   40]   Loss 0.280046   Top1 91.484375   Top5 99.667969   BatchTime 0.129712   
2022-11-25 12:22:49,194 - INFO  - Validation [28][   40/   40]   Loss 0.265471   Top1 91.610000   Top5 99.740000   BatchTime 0.093781   
2022-11-25 12:22:49,445 - INFO  - ==> Top1: 91.610    Top5: 99.740    Loss: 0.265

2022-11-25 12:22:49,445 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:22:49,445 - INFO  - Scoreboard best 1 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:22:49,446 - INFO  - Scoreboard best 2 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:22:49,446 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 91.470   Top5: 99.700]
2022-11-25 12:22:49,573 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:22:49,574 - INFO  - >>>>>> Epoch  29
2022-11-25 12:22:49,576 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:22:58,131 - INFO  - Training [29][   20/  196]   Loss 0.279947   Top1 90.000000   Top5 98.535156   BatchTime 0.427609   LR 0.000013   
2022-11-25 12:23:05,109 - INFO  - Training [29][   40/  196]   Loss 0.286155   Top1 89.824219   Top5 98.701172   BatchTime 0.388264   LR 0.000010   
2022-11-25 12:23:12,004 - INFO  - Training [29][   60/  196]   Loss 0.281487   Top1 89.993490   Top5 98.795573   BatchTime 0.373750   LR 0.000008   
2022-11-25 12:23:18,944 - INFO  - Training [29][   80/  196]   Loss 0.277965   Top1 90.268555   Top5 98.935547   BatchTime 0.367059   LR 0.000005   
2022-11-25 12:23:26,128 - INFO  - Training [29][  100/  196]   Loss 0.271932   Top1 90.500000   Top5 98.976562   BatchTime 0.365495   LR 0.000004   
2022-11-25 12:23:32,642 - INFO  - Training [29][  120/  196]   Loss 0.267949   Top1 90.654297   Top5 99.055990   BatchTime 0.358856   LR 0.000002   
2022-11-25 12:23:38,420 - INFO  - Training [29][  140/  196]   Loss 0.270652   Top1 90.552455   Top5 99.090402   BatchTime 0.348865   LR 0.000001   
2022-11-25 12:23:44,753 - INFO  - Training [29][  160/  196]   Loss 0.271844   Top1 90.488281   Top5 99.052734   BatchTime 0.344835   LR 0.000001   
2022-11-25 12:23:52,028 - INFO  - Training [29][  180/  196]   Loss 0.273539   Top1 90.375434   Top5 99.036458   BatchTime 0.346938   LR 0.000000   
2022-11-25 12:23:57,609 - INFO  - ==> Top1: 90.416    Top5: 99.040    Loss: 0.272

2022-11-25 12:23:58,135 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:23:59,597 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:24:02,157 - INFO  - Validation [29][   20/   40]   Loss 0.273592   Top1 91.621094   Top5 99.667969   BatchTime 0.127900   
2022-11-25 12:24:03,111 - INFO  - Validation [29][   40/   40]   Loss 0.260588   Top1 91.730000   Top5 99.740000   BatchTime 0.087818   
2022-11-25 12:24:03,394 - INFO  - ==> Top1: 91.730    Top5: 99.740    Loss: 0.261

2022-11-25 12:24:03,394 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:24:03,394 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:24:03,395 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:24:03,395 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:24:08,668 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:24:08,674 - INFO  - >>>>>> Epoch  30
2022-11-25 12:24:08,676 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:24:17,133 - INFO  - Training [30][   20/  196]   Loss 0.300925   Top1 89.394531   Top5 98.457031   BatchTime 0.422725   LR 0.001250   
2022-11-25 12:24:23,876 - INFO  - Training [30][   40/  196]   Loss 0.305592   Top1 89.287109   Top5 98.632812   BatchTime 0.379929   LR 0.001250   
2022-11-25 12:24:30,741 - INFO  - Training [30][   60/  196]   Loss 0.305767   Top1 89.322917   Top5 98.782552   BatchTime 0.367706   LR 0.001250   
2022-11-25 12:24:37,613 - INFO  - Training [30][   80/  196]   Loss 0.303725   Top1 89.243164   Top5 98.935547   BatchTime 0.361679   LR 0.001250   
2022-11-25 12:24:44,759 - INFO  - Training [30][  100/  196]   Loss 0.302750   Top1 89.296875   Top5 98.941406   BatchTime 0.360803   LR 0.001250   
2022-11-25 12:24:51,336 - INFO  - Training [30][  120/  196]   Loss 0.300448   Top1 89.361979   Top5 99.000651   BatchTime 0.355470   LR 0.001249   
2022-11-25 12:24:57,215 - INFO  - Training [30][  140/  196]   Loss 0.298999   Top1 89.402902   Top5 99.073661   BatchTime 0.346684   LR 0.001249   
2022-11-25 12:25:04,237 - INFO  - Training [30][  160/  196]   Loss 0.303658   Top1 89.211426   Top5 99.062500   BatchTime 0.347238   LR 0.001249   
2022-11-25 12:25:11,495 - INFO  - Training [30][  180/  196]   Loss 0.304685   Top1 89.188368   Top5 99.027778   BatchTime 0.348977   LR 0.001248   
2022-11-25 12:25:17,383 - INFO  - ==> Top1: 89.148    Top5: 99.022    Loss: 0.306

2022-11-25 12:25:17,646 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:25:19,276 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:25:21,891 - INFO  - Validation [30][   20/   40]   Loss 0.304764   Top1 90.859375   Top5 99.570312   BatchTime 0.130620   
2022-11-25 12:25:22,886 - INFO  - Validation [30][   40/   40]   Loss 0.288132   Top1 91.130000   Top5 99.690000   BatchTime 0.090205   
2022-11-25 12:25:23,132 - INFO  - ==> Top1: 91.130    Top5: 99.690    Loss: 0.288

2022-11-25 12:25:23,133 - INFO  - ==> Sparsity : 0.659

2022-11-25 12:25:23,133 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:25:23,133 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:25:23,133 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:25:23,261 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:25:23,262 - INFO  - >>>>>> Epoch  31
2022-11-25 12:25:23,264 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:25:31,838 - INFO  - Training [31][   20/  196]   Loss 0.318085   Top1 88.632812   Top5 98.671875   BatchTime 0.428580   LR 0.001248   
2022-11-25 12:25:39,081 - INFO  - Training [31][   40/  196]   Loss 0.327416   Top1 88.271484   Top5 98.701172   BatchTime 0.395355   LR 0.001247   
2022-11-25 12:25:46,362 - INFO  - Training [31][   60/  196]   Loss 0.323157   Top1 88.639323   Top5 98.782552   BatchTime 0.384920   LR 0.001247   
2022-11-25 12:25:53,523 - INFO  - Training [31][   80/  196]   Loss 0.317064   Top1 88.813477   Top5 98.945312   BatchTime 0.378207   LR 0.001246   
2022-11-25 12:26:00,556 - INFO  - Training [31][  100/  196]   Loss 0.313346   Top1 88.890625   Top5 98.972656   BatchTime 0.372891   LR 0.001246   
2022-11-25 12:26:07,550 - INFO  - Training [31][  120/  196]   Loss 0.308886   Top1 89.065755   Top5 99.042969   BatchTime 0.369024   LR 0.001245   
2022-11-25 12:26:13,760 - INFO  - Training [31][  140/  196]   Loss 0.305843   Top1 89.160156   Top5 99.079241   BatchTime 0.360666   LR 0.001244   
2022-11-25 12:26:19,534 - INFO  - Training [31][  160/  196]   Loss 0.310534   Top1 88.986816   Top5 99.069824   BatchTime 0.351665   LR 0.001244   
2022-11-25 12:26:26,411 - INFO  - Training [31][  180/  196]   Loss 0.311146   Top1 88.962674   Top5 99.025608   BatchTime 0.350798   LR 0.001243   
2022-11-25 12:26:32,604 - INFO  - ==> Top1: 89.068    Top5: 99.000    Loss: 0.309

2022-11-25 12:26:32,964 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:26:34,595 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:26:37,365 - INFO  - Validation [31][   20/   40]   Loss 0.330051   Top1 90.332031   Top5 99.492188   BatchTime 0.138383   
2022-11-25 12:26:38,408 - INFO  - Validation [31][   40/   40]   Loss 0.310552   Top1 90.540000   Top5 99.620000   BatchTime 0.095280   
2022-11-25 12:26:38,672 - INFO  - ==> Top1: 90.540    Top5: 99.620    Loss: 0.311

2022-11-25 12:26:38,672 - INFO  - ==> Sparsity : 0.660

2022-11-25 12:26:38,672 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:26:38,672 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:26:38,672 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:26:38,794 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:26:38,796 - INFO  - >>>>>> Epoch  32
2022-11-25 12:26:38,797 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:26:47,287 - INFO  - Training [32][   20/  196]   Loss 0.325141   Top1 88.593750   Top5 98.496094   BatchTime 0.424299   LR 0.001242   
2022-11-25 12:26:54,260 - INFO  - Training [32][   40/  196]   Loss 0.327434   Top1 88.642578   Top5 98.642578   BatchTime 0.386468   LR 0.001241   
2022-11-25 12:27:01,041 - INFO  - Training [32][   60/  196]   Loss 0.327444   Top1 88.665365   Top5 98.730469   BatchTime 0.370665   LR 0.001240   
2022-11-25 12:27:07,963 - INFO  - Training [32][   80/  196]   Loss 0.320401   Top1 88.906250   Top5 98.862305   BatchTime 0.364527   LR 0.001239   
2022-11-25 12:27:14,674 - INFO  - Training [32][  100/  196]   Loss 0.313682   Top1 89.148438   Top5 98.937500   BatchTime 0.358726   LR 0.001238   
2022-11-25 12:27:21,453 - INFO  - Training [32][  120/  196]   Loss 0.311497   Top1 89.173177   Top5 99.000651   BatchTime 0.355430   LR 0.001237   
2022-11-25 12:27:28,163 - INFO  - Training [32][  140/  196]   Loss 0.310211   Top1 89.185268   Top5 99.026228   BatchTime 0.352585   LR 0.001236   
2022-11-25 12:27:34,890 - INFO  - Training [32][  160/  196]   Loss 0.313391   Top1 89.079590   Top5 99.035645   BatchTime 0.350555   LR 0.001235   
2022-11-25 12:27:40,719 - INFO  - Training [32][  180/  196]   Loss 0.312650   Top1 89.118924   Top5 99.012587   BatchTime 0.343987   LR 0.001234   
2022-11-25 12:27:46,538 - INFO  - ==> Top1: 89.128    Top5: 98.996    Loss: 0.313

2022-11-25 12:27:46,859 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:27:48,346 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:27:52,393 - INFO  - Validation [32][   20/   40]   Loss 0.579225   Top1 82.304688   Top5 98.925781   BatchTime 0.202232   
2022-11-25 12:27:53,748 - INFO  - Validation [32][   40/   40]   Loss 0.570408   Top1 82.440000   Top5 99.070000   BatchTime 0.135001   
2022-11-25 12:27:54,100 - INFO  - ==> Top1: 82.440    Top5: 99.070    Loss: 0.570

2022-11-25 12:27:54,100 - INFO  - ==> Sparsity : 0.661

2022-11-25 12:27:54,100 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:27:54,100 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:27:54,101 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:27:54,246 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:27:54,247 - INFO  - >>>>>> Epoch  33
2022-11-25 12:27:54,249 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:28:02,827 - INFO  - Training [33][   20/  196]   Loss 0.322185   Top1 88.437500   Top5 98.750000   BatchTime 0.428725   LR 0.001232   
2022-11-25 12:28:09,683 - INFO  - Training [33][   40/  196]   Loss 0.327048   Top1 88.642578   Top5 98.681641   BatchTime 0.385776   LR 0.001230   
2022-11-25 12:28:16,848 - INFO  - Training [33][   60/  196]   Loss 0.318034   Top1 88.841146   Top5 98.750000   BatchTime 0.376594   LR 0.001229   
2022-11-25 12:28:24,014 - INFO  - Training [33][   80/  196]   Loss 0.315021   Top1 88.984375   Top5 98.862305   BatchTime 0.372017   LR 0.001228   
2022-11-25 12:28:30,862 - INFO  - Training [33][  100/  196]   Loss 0.308484   Top1 89.191406   Top5 98.902344   BatchTime 0.366093   LR 0.001226   
2022-11-25 12:28:37,774 - INFO  - Training [33][  120/  196]   Loss 0.305882   Top1 89.342448   Top5 98.977865   BatchTime 0.362681   LR 0.001225   
2022-11-25 12:28:44,727 - INFO  - Training [33][  140/  196]   Loss 0.305510   Top1 89.363839   Top5 99.056920   BatchTime 0.360532   LR 0.001224   
2022-11-25 12:28:51,105 - INFO  - Training [33][  160/  196]   Loss 0.307197   Top1 89.299316   Top5 98.984375   BatchTime 0.355330   LR 0.001222   
2022-11-25 12:28:56,583 - INFO  - Training [33][  180/  196]   Loss 0.308016   Top1 89.264323   Top5 98.953993   BatchTime 0.346279   LR 0.001221   
2022-11-25 12:29:00,503 - INFO  - ==> Top1: 89.274    Top5: 98.938    Loss: 0.307

2022-11-25 12:29:00,701 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:29:01,895 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:29:04,573 - INFO  - Validation [33][   20/   40]   Loss 0.503425   Top1 85.292969   Top5 99.335938   BatchTime 0.133754   
2022-11-25 12:29:05,680 - INFO  - Validation [33][   40/   40]   Loss 0.496700   Top1 85.260000   Top5 99.360000   BatchTime 0.094557   
2022-11-25 12:29:05,925 - INFO  - ==> Top1: 85.260    Top5: 99.360    Loss: 0.497

2022-11-25 12:29:05,925 - INFO  - ==> Sparsity : 0.662

2022-11-25 12:29:05,926 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:29:05,926 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:29:05,926 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:29:06,050 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:29:06,052 - INFO  - >>>>>> Epoch  34
2022-11-25 12:29:06,054 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:29:15,021 - INFO  - Training [34][   20/  196]   Loss 0.300681   Top1 88.945312   Top5 98.652344   BatchTime 0.448231   LR 0.001218   
2022-11-25 12:29:22,567 - INFO  - Training [34][   40/  196]   Loss 0.307529   Top1 89.130859   Top5 98.681641   BatchTime 0.412767   LR 0.001216   
2022-11-25 12:29:29,776 - INFO  - Training [34][   60/  196]   Loss 0.306170   Top1 89.147135   Top5 98.743490   BatchTime 0.395331   LR 0.001215   
2022-11-25 12:29:36,951 - INFO  - Training [34][   80/  196]   Loss 0.310211   Top1 88.964844   Top5 98.881836   BatchTime 0.386178   LR 0.001213   
2022-11-25 12:29:43,680 - INFO  - Training [34][  100/  196]   Loss 0.304676   Top1 89.179688   Top5 98.941406   BatchTime 0.376239   LR 0.001211   
2022-11-25 12:29:50,348 - INFO  - Training [34][  120/  196]   Loss 0.298880   Top1 89.410807   Top5 98.994141   BatchTime 0.369095   LR 0.001209   
2022-11-25 12:29:57,023 - INFO  - Training [34][  140/  196]   Loss 0.300043   Top1 89.425223   Top5 99.012277   BatchTime 0.364048   LR 0.001208   
2022-11-25 12:30:03,694 - INFO  - Training [34][  160/  196]   Loss 0.303339   Top1 89.313965   Top5 99.008789   BatchTime 0.360233   LR 0.001206   
2022-11-25 12:30:10,377 - INFO  - Training [34][  180/  196]   Loss 0.307006   Top1 89.220920   Top5 98.951823   BatchTime 0.357336   LR 0.001204   
2022-11-25 12:30:15,873 - INFO  - ==> Top1: 89.212    Top5: 98.966    Loss: 0.307

2022-11-25 12:30:16,082 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:30:17,216 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:30:21,444 - INFO  - Validation [34][   20/   40]   Loss 0.299665   Top1 90.527344   Top5 99.589844   BatchTime 0.211318   
2022-11-25 12:30:22,479 - INFO  - Validation [34][   40/   40]   Loss 0.284517   Top1 90.860000   Top5 99.680000   BatchTime 0.131529   
2022-11-25 12:30:22,774 - INFO  - ==> Top1: 90.860    Top5: 99.680    Loss: 0.285

2022-11-25 12:30:22,775 - INFO  - ==> Sparsity : 0.663

2022-11-25 12:30:22,775 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:30:22,775 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:30:22,775 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:30:22,967 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:30:22,969 - INFO  - >>>>>> Epoch  35
2022-11-25 12:30:22,971 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:30:32,079 - INFO  - Training [35][   20/  196]   Loss 0.295920   Top1 89.414062   Top5 98.671875   BatchTime 0.455203   LR 0.001201   
2022-11-25 12:30:39,619 - INFO  - Training [35][   40/  196]   Loss 0.305382   Top1 88.974609   Top5 98.740234   BatchTime 0.416101   LR 0.001199   
2022-11-25 12:30:46,656 - INFO  - Training [35][   60/  196]   Loss 0.302717   Top1 89.153646   Top5 98.763021   BatchTime 0.394695   LR 0.001197   
2022-11-25 12:30:53,411 - INFO  - Training [35][   80/  196]   Loss 0.307189   Top1 88.974609   Top5 98.901367   BatchTime 0.380457   LR 0.001195   
2022-11-25 12:30:59,959 - INFO  - Training [35][  100/  196]   Loss 0.306203   Top1 89.011719   Top5 98.890625   BatchTime 0.369841   LR 0.001192   
2022-11-25 12:31:06,268 - INFO  - Training [35][  120/  196]   Loss 0.301435   Top1 89.267578   Top5 98.987630   BatchTime 0.360773   LR 0.001190   
2022-11-25 12:31:13,054 - INFO  - Training [35][  140/  196]   Loss 0.301338   Top1 89.347098   Top5 99.048549   BatchTime 0.357706   LR 0.001188   
2022-11-25 12:31:19,920 - INFO  - Training [35][  160/  196]   Loss 0.302823   Top1 89.296875   Top5 99.040527   BatchTime 0.355903   LR 0.001186   
2022-11-25 12:31:26,772 - INFO  - Training [35][  180/  196]   Loss 0.304306   Top1 89.194878   Top5 99.027778   BatchTime 0.354426   LR 0.001184   
2022-11-25 12:31:32,352 - INFO  - ==> Top1: 89.178    Top5: 99.024    Loss: 0.304

2022-11-25 12:31:32,598 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:31:34,127 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:31:36,915 - INFO  - Validation [35][   20/   40]   Loss 0.292917   Top1 91.035156   Top5 99.609375   BatchTime 0.139325   
2022-11-25 12:31:38,173 - INFO  - Validation [35][   40/   40]   Loss 0.277170   Top1 91.350000   Top5 99.700000   BatchTime 0.101112   
2022-11-25 12:31:38,436 - INFO  - ==> Top1: 91.350    Top5: 99.700    Loss: 0.277

2022-11-25 12:31:38,436 - INFO  - ==> Sparsity : 0.663

2022-11-25 12:31:38,436 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:31:38,437 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:31:38,437 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:31:38,565 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:31:38,566 - INFO  - >>>>>> Epoch  36
2022-11-25 12:31:38,568 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:31:46,093 - INFO  - Training [36][   20/  196]   Loss 0.320594   Top1 88.378906   Top5 98.613281   BatchTime 0.376112   LR 0.001180   
2022-11-25 12:31:52,446 - INFO  - Training [36][   40/  196]   Loss 0.329823   Top1 88.037109   Top5 98.652344   BatchTime 0.346870   LR 0.001177   
2022-11-25 12:31:59,992 - INFO  - Training [36][   60/  196]   Loss 0.320413   Top1 88.424479   Top5 98.750000   BatchTime 0.357023   LR 0.001175   
2022-11-25 12:32:07,563 - INFO  - Training [36][   80/  196]   Loss 0.315390   Top1 88.579102   Top5 98.867188   BatchTime 0.362395   LR 0.001173   
2022-11-25 12:32:14,960 - INFO  - Training [36][  100/  196]   Loss 0.306486   Top1 88.906250   Top5 98.937500   BatchTime 0.363892   LR 0.001170   
2022-11-25 12:32:21,836 - INFO  - Training [36][  120/  196]   Loss 0.305012   Top1 89.039714   Top5 98.990885   BatchTime 0.360537   LR 0.001168   
2022-11-25 12:32:28,642 - INFO  - Training [36][  140/  196]   Loss 0.301827   Top1 89.171317   Top5 99.042969   BatchTime 0.357651   LR 0.001165   
2022-11-25 12:32:35,420 - INFO  - Training [36][  160/  196]   Loss 0.304217   Top1 89.147949   Top5 99.040527   BatchTime 0.355301   LR 0.001163   
2022-11-25 12:32:42,053 - INFO  - Training [36][  180/  196]   Loss 0.305336   Top1 89.105903   Top5 98.971354   BatchTime 0.352677   LR 0.001160   
2022-11-25 12:32:47,460 - INFO  - ==> Top1: 89.084    Top5: 98.962    Loss: 0.306

2022-11-25 12:32:47,801 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:32:49,507 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:32:52,088 - INFO  - Validation [36][   20/   40]   Loss 0.335306   Top1 90.351562   Top5 99.492188   BatchTime 0.128924   
2022-11-25 12:32:53,122 - INFO  - Validation [36][   40/   40]   Loss 0.323674   Top1 90.200000   Top5 99.650000   BatchTime 0.090322   
2022-11-25 12:32:53,340 - INFO  - ==> Top1: 90.200    Top5: 99.650    Loss: 0.324

2022-11-25 12:32:53,340 - INFO  - ==> Sparsity : 0.664

2022-11-25 12:32:53,341 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:32:53,341 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:32:53,341 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:32:53,459 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:32:53,461 - INFO  - >>>>>> Epoch  37
2022-11-25 12:32:53,462 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:33:01,474 - INFO  - Training [37][   20/  196]   Loss 0.312549   Top1 89.140625   Top5 98.496094   BatchTime 0.400449   LR 0.001155   
2022-11-25 12:33:06,919 - INFO  - Training [37][   40/  196]   Loss 0.310921   Top1 89.082031   Top5 98.681641   BatchTime 0.336349   LR 0.001153   
2022-11-25 12:33:14,248 - INFO  - Training [37][   60/  196]   Loss 0.311987   Top1 89.029948   Top5 98.736979   BatchTime 0.346384   LR 0.001150   
2022-11-25 12:33:21,912 - INFO  - Training [37][   80/  196]   Loss 0.306632   Top1 89.101562   Top5 98.857422   BatchTime 0.355588   LR 0.001147   
2022-11-25 12:33:28,879 - INFO  - Training [37][  100/  196]   Loss 0.301109   Top1 89.273438   Top5 98.949219   BatchTime 0.354142   LR 0.001144   
2022-11-25 12:33:35,556 - INFO  - Training [37][  120/  196]   Loss 0.296431   Top1 89.417318   Top5 99.039714   BatchTime 0.350760   LR 0.001142   
2022-11-25 12:33:42,326 - INFO  - Training [37][  140/  196]   Loss 0.294333   Top1 89.464286   Top5 99.065290   BatchTime 0.349008   LR 0.001139   
2022-11-25 12:33:49,045 - INFO  - Training [37][  160/  196]   Loss 0.296581   Top1 89.499512   Top5 99.025879   BatchTime 0.347369   LR 0.001136   
2022-11-25 12:33:55,659 - INFO  - Training [37][  180/  196]   Loss 0.297707   Top1 89.463976   Top5 99.010417   BatchTime 0.345518   LR 0.001133   
2022-11-25 12:34:01,301 - INFO  - ==> Top1: 89.538    Top5: 99.018    Loss: 0.296

2022-11-25 12:34:01,532 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:34:02,832 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:34:05,490 - INFO  - Validation [37][   20/   40]   Loss 0.394469   Top1 88.125000   Top5 99.316406   BatchTime 0.132794   
2022-11-25 12:34:06,581 - INFO  - Validation [37][   40/   40]   Loss 0.377349   Top1 88.290000   Top5 99.490000   BatchTime 0.093674   
2022-11-25 12:34:06,851 - INFO  - ==> Top1: 88.290    Top5: 99.490    Loss: 0.377

2022-11-25 12:34:06,851 - INFO  - ==> Sparsity : 0.664

2022-11-25 12:34:06,851 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:34:06,852 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:34:06,852 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:34:06,974 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:34:06,976 - INFO  - >>>>>> Epoch  38
2022-11-25 12:34:06,977 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:34:15,078 - INFO  - Training [38][   20/  196]   Loss 0.319344   Top1 88.886719   Top5 98.417969   BatchTime 0.404927   LR 0.001128   
2022-11-25 12:34:21,214 - INFO  - Training [38][   40/  196]   Loss 0.321090   Top1 88.798828   Top5 98.496094   BatchTime 0.355847   LR 0.001125   
2022-11-25 12:34:27,032 - INFO  - Training [38][   60/  196]   Loss 0.315409   Top1 88.932292   Top5 98.684896   BatchTime 0.334205   LR 0.001122   
2022-11-25 12:34:34,584 - INFO  - Training [38][   80/  196]   Loss 0.312021   Top1 88.935547   Top5 98.862305   BatchTime 0.345053   LR 0.001119   
2022-11-25 12:34:41,942 - INFO  - Training [38][  100/  196]   Loss 0.306683   Top1 89.128906   Top5 98.941406   BatchTime 0.349617   LR 0.001116   
2022-11-25 12:34:48,926 - INFO  - Training [38][  120/  196]   Loss 0.300225   Top1 89.404297   Top5 99.020182   BatchTime 0.349545   LR 0.001112   
2022-11-25 12:34:55,585 - INFO  - Training [38][  140/  196]   Loss 0.296726   Top1 89.547991   Top5 99.068080   BatchTime 0.347175   LR 0.001109   
2022-11-25 12:35:02,287 - INFO  - Training [38][  160/  196]   Loss 0.300500   Top1 89.494629   Top5 99.052734   BatchTime 0.345665   LR 0.001106   
2022-11-25 12:35:09,014 - INFO  - Training [38][  180/  196]   Loss 0.299508   Top1 89.507378   Top5 99.038628   BatchTime 0.344630   LR 0.001103   
2022-11-25 12:35:14,699 - INFO  - ==> Top1: 89.558    Top5: 99.040    Loss: 0.299

2022-11-25 12:35:14,950 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:35:16,434 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:35:19,179 - INFO  - Validation [38][   20/   40]   Loss 0.301646   Top1 90.859375   Top5 99.726562   BatchTime 0.137137   
2022-11-25 12:35:20,324 - INFO  - Validation [38][   40/   40]   Loss 0.288634   Top1 90.860000   Top5 99.780000   BatchTime 0.097215   
2022-11-25 12:35:20,644 - INFO  - ==> Top1: 90.860    Top5: 99.780    Loss: 0.289

2022-11-25 12:35:20,644 - INFO  - ==> Sparsity : 0.665

2022-11-25 12:35:20,644 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:35:20,644 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:35:20,645 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:35:21,045 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:35:21,046 - INFO  - >>>>>> Epoch  39
2022-11-25 12:35:21,048 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:35:29,813 - INFO  - Training [39][   20/  196]   Loss 0.320427   Top1 88.320312   Top5 98.632812   BatchTime 0.438129   LR 0.001097   
2022-11-25 12:35:36,776 - INFO  - Training [39][   40/  196]   Loss 0.318301   Top1 88.447266   Top5 98.828125   BatchTime 0.393132   LR 0.001094   
2022-11-25 12:35:42,468 - INFO  - Training [39][   60/  196]   Loss 0.313722   Top1 88.678385   Top5 98.893229   BatchTime 0.356952   LR 0.001090   
2022-11-25 12:35:49,292 - INFO  - Training [39][   80/  196]   Loss 0.311865   Top1 88.999023   Top5 98.979492   BatchTime 0.353013   LR 0.001087   
2022-11-25 12:35:56,262 - INFO  - Training [39][  100/  196]   Loss 0.302185   Top1 89.289062   Top5 99.000000   BatchTime 0.352108   LR 0.001084   
2022-11-25 12:36:03,084 - INFO  - Training [39][  120/  196]   Loss 0.294274   Top1 89.514974   Top5 99.069010   BatchTime 0.350272   LR 0.001080   
2022-11-25 12:36:10,423 - INFO  - Training [39][  140/  196]   Loss 0.293843   Top1 89.547991   Top5 99.104353   BatchTime 0.352654   LR 0.001077   
2022-11-25 12:36:18,108 - INFO  - Training [39][  160/  196]   Loss 0.294431   Top1 89.541016   Top5 99.084473   BatchTime 0.356607   LR 0.001073   
2022-11-25 12:36:25,108 - INFO  - Training [39][  180/  196]   Loss 0.296234   Top1 89.479167   Top5 99.049479   BatchTime 0.355870   LR 0.001070   
2022-11-25 12:36:30,666 - INFO  - ==> Top1: 89.534    Top5: 99.052    Loss: 0.295

2022-11-25 12:36:30,904 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:36:32,383 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:36:35,047 - INFO  - Validation [39][   20/   40]   Loss 0.297567   Top1 91.171875   Top5 99.628906   BatchTime 0.133133   
2022-11-25 12:36:36,074 - INFO  - Validation [39][   40/   40]   Loss 0.281534   Top1 91.370000   Top5 99.690000   BatchTime 0.092228   
2022-11-25 12:36:36,335 - INFO  - ==> Top1: 91.370    Top5: 99.690    Loss: 0.282

2022-11-25 12:36:36,335 - INFO  - ==> Sparsity : 0.666

2022-11-25 12:36:36,335 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:36:36,336 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:36:36,336 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:36:36,481 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:36:36,483 - INFO  - >>>>>> Epoch  40
2022-11-25 12:36:36,485 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:36:44,629 - INFO  - Training [40][   20/  196]   Loss 0.305302   Top1 89.101562   Top5 98.945312   BatchTime 0.407063   LR 0.001064   
2022-11-25 12:36:51,488 - INFO  - Training [40][   40/  196]   Loss 0.305828   Top1 89.150391   Top5 98.867188   BatchTime 0.375018   LR 0.001060   
2022-11-25 12:36:58,194 - INFO  - Training [40][   60/  196]   Loss 0.298688   Top1 89.518229   Top5 98.880208   BatchTime 0.361767   LR 0.001056   
2022-11-25 12:37:04,227 - INFO  - Training [40][   80/  196]   Loss 0.299792   Top1 89.536133   Top5 98.974609   BatchTime 0.346747   LR 0.001053   
2022-11-25 12:37:10,991 - INFO  - Training [40][  100/  196]   Loss 0.293056   Top1 89.777344   Top5 99.042969   BatchTime 0.345034   LR 0.001049   
2022-11-25 12:37:18,427 - INFO  - Training [40][  120/  196]   Loss 0.288140   Top1 89.977214   Top5 99.091797   BatchTime 0.349496   LR 0.001045   
2022-11-25 12:37:25,555 - INFO  - Training [40][  140/  196]   Loss 0.287690   Top1 90.008371   Top5 99.135045   BatchTime 0.350477   LR 0.001042   
2022-11-25 12:37:32,562 - INFO  - Training [40][  160/  196]   Loss 0.288367   Top1 89.931641   Top5 99.113770   BatchTime 0.350462   LR 0.001038   
2022-11-25 12:37:39,219 - INFO  - Training [40][  180/  196]   Loss 0.289822   Top1 89.913194   Top5 99.071181   BatchTime 0.348504   LR 0.001034   
2022-11-25 12:37:45,059 - INFO  - ==> Top1: 89.896    Top5: 99.076    Loss: 0.289

2022-11-25 12:37:45,304 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:37:46,637 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:37:49,352 - INFO  - Validation [40][   20/   40]   Loss 0.301564   Top1 90.761719   Top5 99.648438   BatchTime 0.135625   
2022-11-25 12:37:50,430 - INFO  - Validation [40][   40/   40]   Loss 0.289826   Top1 90.840000   Top5 99.740000   BatchTime 0.094777   
2022-11-25 12:37:50,746 - INFO  - ==> Top1: 90.840    Top5: 99.740    Loss: 0.290

2022-11-25 12:37:50,747 - INFO  - ==> Sparsity : 0.666

2022-11-25 12:37:50,747 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:37:50,747 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:37:50,747 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:37:51,141 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:37:51,143 - INFO  - >>>>>> Epoch  41
2022-11-25 12:37:51,144 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:37:59,945 - INFO  - Training [41][   20/  196]   Loss 0.302416   Top1 89.179688   Top5 98.417969   BatchTime 0.439911   LR 0.001027   
2022-11-25 12:38:06,893 - INFO  - Training [41][   40/  196]   Loss 0.296397   Top1 89.521484   Top5 98.632812   BatchTime 0.393657   LR 0.001023   
2022-11-25 12:38:13,783 - INFO  - Training [41][   60/  196]   Loss 0.294616   Top1 89.544271   Top5 98.730469   BatchTime 0.377263   LR 0.001020   
2022-11-25 12:38:20,346 - INFO  - Training [41][   80/  196]   Loss 0.294249   Top1 89.545898   Top5 98.842773   BatchTime 0.364986   LR 0.001016   
2022-11-25 12:38:26,555 - INFO  - Training [41][  100/  196]   Loss 0.289126   Top1 89.757812   Top5 98.882812   BatchTime 0.354071   LR 0.001012   
2022-11-25 12:38:33,466 - INFO  - Training [41][  120/  196]   Loss 0.283760   Top1 89.921875   Top5 98.964844   BatchTime 0.352658   LR 0.001008   
2022-11-25 12:38:40,949 - INFO  - Training [41][  140/  196]   Loss 0.280316   Top1 90.103237   Top5 99.037388   BatchTime 0.355725   LR 0.001004   
2022-11-25 12:38:47,699 - INFO  - Training [41][  160/  196]   Loss 0.283556   Top1 89.992676   Top5 99.033203   BatchTime 0.353444   LR 0.001000   
2022-11-25 12:38:54,553 - INFO  - Training [41][  180/  196]   Loss 0.285448   Top1 89.928385   Top5 99.023438   BatchTime 0.352252   LR 0.000996   
2022-11-25 12:39:00,172 - INFO  - ==> Top1: 89.920    Top5: 99.010    Loss: 0.286

2022-11-25 12:39:00,433 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:39:01,826 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:39:04,521 - INFO  - Validation [41][   20/   40]   Loss 0.301799   Top1 91.113281   Top5 99.667969   BatchTime 0.134665   
2022-11-25 12:39:05,594 - INFO  - Validation [41][   40/   40]   Loss 0.284946   Top1 91.040000   Top5 99.740000   BatchTime 0.094174   
2022-11-25 12:39:05,827 - INFO  - ==> Top1: 91.040    Top5: 99.740    Loss: 0.285

2022-11-25 12:39:05,827 - INFO  - ==> Sparsity : 0.666

2022-11-25 12:39:05,828 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:39:05,828 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:39:05,829 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:39:05,993 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:39:05,994 - INFO  - >>>>>> Epoch  42
2022-11-25 12:39:05,996 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:39:14,252 - INFO  - Training [42][   20/  196]   Loss 0.293079   Top1 89.492188   Top5 98.593750   BatchTime 0.412652   LR 0.000988   
2022-11-25 12:39:21,478 - INFO  - Training [42][   40/  196]   Loss 0.304360   Top1 89.296875   Top5 98.710938   BatchTime 0.386983   LR 0.000984   
2022-11-25 12:39:28,531 - INFO  - Training [42][   60/  196]   Loss 0.301895   Top1 89.368490   Top5 98.808594   BatchTime 0.375545   LR 0.000980   
2022-11-25 12:39:35,951 - INFO  - Training [42][   80/  196]   Loss 0.298596   Top1 89.477539   Top5 98.945312   BatchTime 0.374403   LR 0.000976   
2022-11-25 12:39:42,539 - INFO  - Training [42][  100/  196]   Loss 0.293714   Top1 89.628906   Top5 98.988281   BatchTime 0.365399   LR 0.000972   
2022-11-25 12:39:47,464 - INFO  - Training [42][  120/  196]   Loss 0.288998   Top1 89.817708   Top5 99.036458   BatchTime 0.345544   LR 0.000968   
2022-11-25 12:39:54,331 - INFO  - Training [42][  140/  196]   Loss 0.285431   Top1 89.907924   Top5 99.090402   BatchTime 0.345230   LR 0.000964   
2022-11-25 12:40:01,211 - INFO  - Training [42][  160/  196]   Loss 0.289803   Top1 89.716797   Top5 99.069824   BatchTime 0.345076   LR 0.000959   
2022-11-25 12:40:07,955 - INFO  - Training [42][  180/  196]   Loss 0.289211   Top1 89.806858   Top5 99.027778   BatchTime 0.344196   LR 0.000955   
2022-11-25 12:40:13,595 - INFO  - ==> Top1: 89.820    Top5: 99.028    Loss: 0.288

2022-11-25 12:40:13,894 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:40:15,560 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:40:18,266 - INFO  - Validation [42][   20/   40]   Loss 0.303657   Top1 90.507812   Top5 99.628906   BatchTime 0.135178   
2022-11-25 12:40:19,359 - INFO  - Validation [42][   40/   40]   Loss 0.284760   Top1 91.030000   Top5 99.710000   BatchTime 0.094927   
2022-11-25 12:40:19,580 - INFO  - ==> Top1: 91.030    Top5: 99.710    Loss: 0.285

2022-11-25 12:40:19,580 - INFO  - ==> Sparsity : 0.667

2022-11-25 12:40:19,580 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:40:19,581 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:40:19,581 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:40:19,719 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:40:19,721 - INFO  - >>>>>> Epoch  43
2022-11-25 12:40:19,725 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:40:28,075 - INFO  - Training [43][   20/  196]   Loss 0.283272   Top1 90.585938   Top5 98.652344   BatchTime 0.417271   LR 0.000947   
2022-11-25 12:40:35,471 - INFO  - Training [43][   40/  196]   Loss 0.294750   Top1 89.931641   Top5 98.632812   BatchTime 0.393525   LR 0.000943   
2022-11-25 12:40:42,547 - INFO  - Training [43][   60/  196]   Loss 0.286061   Top1 90.058594   Top5 98.795573   BatchTime 0.380281   LR 0.000939   
2022-11-25 12:40:49,491 - INFO  - Training [43][   80/  196]   Loss 0.287739   Top1 89.985352   Top5 98.911133   BatchTime 0.372007   LR 0.000934   
2022-11-25 12:40:56,346 - INFO  - Training [43][  100/  196]   Loss 0.282594   Top1 90.078125   Top5 98.984375   BatchTime 0.366160   LR 0.000930   
2022-11-25 12:41:02,704 - INFO  - Training [43][  120/  196]   Loss 0.276621   Top1 90.315755   Top5 99.078776   BatchTime 0.358118   LR 0.000926   
2022-11-25 12:41:08,663 - INFO  - Training [43][  140/  196]   Loss 0.276451   Top1 90.348772   Top5 99.140625   BatchTime 0.349518   LR 0.000921   
2022-11-25 12:41:14,331 - INFO  - Training [43][  160/  196]   Loss 0.281090   Top1 90.175781   Top5 99.123535   BatchTime 0.341253   LR 0.000917   
2022-11-25 12:41:20,527 - INFO  - Training [43][  180/  196]   Loss 0.282725   Top1 90.095486   Top5 99.097222   BatchTime 0.337760   LR 0.000912   
2022-11-25 12:41:25,994 - INFO  - ==> Top1: 90.084    Top5: 99.090    Loss: 0.282

2022-11-25 12:41:26,261 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:41:27,736 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:41:30,286 - INFO  - Validation [43][   20/   40]   Loss 0.372582   Top1 88.984375   Top5 99.511719   BatchTime 0.127376   
2022-11-25 12:41:31,291 - INFO  - Validation [43][   40/   40]   Loss 0.362731   Top1 89.120000   Top5 99.600000   BatchTime 0.088826   
2022-11-25 12:41:31,597 - INFO  - ==> Top1: 89.120    Top5: 99.600    Loss: 0.363

2022-11-25 12:41:31,597 - INFO  - ==> Sparsity : 0.667

2022-11-25 12:41:31,597 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:41:31,597 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:41:31,598 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:41:31,732 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:41:31,734 - INFO  - >>>>>> Epoch  44
2022-11-25 12:41:31,736 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:41:39,957 - INFO  - Training [44][   20/  196]   Loss 0.294789   Top1 89.277344   Top5 98.906250   BatchTime 0.410886   LR 0.000904   
2022-11-25 12:41:46,719 - INFO  - Training [44][   40/  196]   Loss 0.287927   Top1 89.873047   Top5 98.886719   BatchTime 0.374513   LR 0.000900   
2022-11-25 12:41:53,757 - INFO  - Training [44][   60/  196]   Loss 0.287475   Top1 89.934896   Top5 98.899740   BatchTime 0.366964   LR 0.000895   
2022-11-25 12:42:00,751 - INFO  - Training [44][   80/  196]   Loss 0.287357   Top1 89.853516   Top5 98.955078   BatchTime 0.362649   LR 0.000891   
2022-11-25 12:42:07,883 - INFO  - Training [44][  100/  196]   Loss 0.282479   Top1 89.992188   Top5 98.988281   BatchTime 0.361435   LR 0.000886   
2022-11-25 12:42:14,582 - INFO  - Training [44][  120/  196]   Loss 0.275649   Top1 90.322266   Top5 99.052734   BatchTime 0.357026   LR 0.000882   
2022-11-25 12:42:20,937 - INFO  - Training [44][  140/  196]   Loss 0.276216   Top1 90.306920   Top5 99.082031   BatchTime 0.351414   LR 0.000877   
2022-11-25 12:42:27,911 - INFO  - Training [44][  160/  196]   Loss 0.279507   Top1 90.214844   Top5 99.086914   BatchTime 0.351073   LR 0.000873   
2022-11-25 12:42:33,924 - INFO  - Training [44][  180/  196]   Loss 0.280267   Top1 90.162760   Top5 99.053819   BatchTime 0.345470   LR 0.000868   
2022-11-25 12:42:39,075 - INFO  - ==> Top1: 90.194    Top5: 99.062    Loss: 0.280

2022-11-25 12:42:39,324 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:42:40,598 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:42:43,177 - INFO  - Validation [44][   20/   40]   Loss 0.468831   Top1 86.210938   Top5 99.257812   BatchTime 0.128814   
2022-11-25 12:42:44,244 - INFO  - Validation [44][   40/   40]   Loss 0.458564   Top1 86.470000   Top5 99.370000   BatchTime 0.091100   
2022-11-25 12:42:44,536 - INFO  - ==> Top1: 86.470    Top5: 99.370    Loss: 0.459

2022-11-25 12:42:44,537 - INFO  - ==> Sparsity : 0.667

2022-11-25 12:42:44,537 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:42:44,537 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:42:44,537 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:42:44,721 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:42:44,723 - INFO  - >>>>>> Epoch  45
2022-11-25 12:42:44,727 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:42:53,646 - INFO  - Training [45][   20/  196]   Loss 0.291842   Top1 89.628906   Top5 98.671875   BatchTime 0.445779   LR 0.000860   
2022-11-25 12:43:01,266 - INFO  - Training [45][   40/  196]   Loss 0.282425   Top1 89.873047   Top5 98.837891   BatchTime 0.413381   LR 0.000855   
2022-11-25 12:43:09,072 - INFO  - Training [45][   60/  196]   Loss 0.274958   Top1 90.260417   Top5 98.938802   BatchTime 0.405684   LR 0.000850   
2022-11-25 12:43:16,164 - INFO  - Training [45][   80/  196]   Loss 0.277062   Top1 90.107422   Top5 99.038086   BatchTime 0.392922   LR 0.000846   
2022-11-25 12:43:23,623 - INFO  - Training [45][  100/  196]   Loss 0.274664   Top1 90.179688   Top5 99.050781   BatchTime 0.388922   LR 0.000841   
2022-11-25 12:43:30,339 - INFO  - Training [45][  120/  196]   Loss 0.273334   Top1 90.328776   Top5 99.098307   BatchTime 0.380067   LR 0.000836   
2022-11-25 12:43:37,064 - INFO  - Training [45][  140/  196]   Loss 0.272560   Top1 90.368304   Top5 99.140625   BatchTime 0.373809   LR 0.000832   
2022-11-25 12:43:43,824 - INFO  - Training [45][  160/  196]   Loss 0.275929   Top1 90.270996   Top5 99.130859   BatchTime 0.369333   LR 0.000827   
2022-11-25 12:43:50,196 - INFO  - Training [45][  180/  196]   Loss 0.277509   Top1 90.221354   Top5 99.095052   BatchTime 0.363692   LR 0.000822   
2022-11-25 12:43:54,903 - INFO  - ==> Top1: 90.272    Top5: 99.092    Loss: 0.277

2022-11-25 12:43:55,223 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:43:56,859 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:43:59,457 - INFO  - Validation [45][   20/   40]   Loss 0.316139   Top1 90.214844   Top5 99.550781   BatchTime 0.129831   
2022-11-25 12:44:00,475 - INFO  - Validation [45][   40/   40]   Loss 0.300781   Top1 90.780000   Top5 99.670000   BatchTime 0.090374   
2022-11-25 12:44:00,764 - INFO  - ==> Top1: 90.780    Top5: 99.670    Loss: 0.301

2022-11-25 12:44:00,764 - INFO  - ==> Sparsity : 0.668

2022-11-25 12:44:00,765 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:44:00,765 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:44:00,765 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:44:00,909 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:44:00,911 - INFO  - >>>>>> Epoch  46
2022-11-25 12:44:00,913 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:44:10,010 - INFO  - Training [46][   20/  196]   Loss 0.313324   Top1 89.082031   Top5 98.320312   BatchTime 0.454743   LR 0.000814   
2022-11-25 12:44:17,408 - INFO  - Training [46][   40/  196]   Loss 0.296285   Top1 89.472656   Top5 98.671875   BatchTime 0.412305   LR 0.000809   
2022-11-25 12:44:24,327 - INFO  - Training [46][   60/  196]   Loss 0.291817   Top1 89.687500   Top5 98.795573   BatchTime 0.390180   LR 0.000804   
2022-11-25 12:44:31,234 - INFO  - Training [46][   80/  196]   Loss 0.287401   Top1 89.873047   Top5 98.896484   BatchTime 0.378981   LR 0.000799   
2022-11-25 12:44:38,359 - INFO  - Training [46][  100/  196]   Loss 0.284007   Top1 89.953125   Top5 98.953125   BatchTime 0.374425   LR 0.000794   
2022-11-25 12:44:45,899 - INFO  - Training [46][  120/  196]   Loss 0.276908   Top1 90.234375   Top5 99.046224   BatchTime 0.374855   LR 0.000789   
2022-11-25 12:44:52,633 - INFO  - Training [46][  140/  196]   Loss 0.274305   Top1 90.365513   Top5 99.121094   BatchTime 0.369404   LR 0.000785   
2022-11-25 12:44:59,611 - INFO  - Training [46][  160/  196]   Loss 0.276241   Top1 90.288086   Top5 99.140625   BatchTime 0.366842   LR 0.000780   
2022-11-25 12:45:07,019 - INFO  - Training [46][  180/  196]   Loss 0.278320   Top1 90.203993   Top5 99.116753   BatchTime 0.367234   LR 0.000775   
2022-11-25 12:45:11,820 - INFO  - ==> Top1: 90.278    Top5: 99.108    Loss: 0.276

2022-11-25 12:45:12,023 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:45:13,040 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:45:15,757 - INFO  - Validation [46][   20/   40]   Loss 0.312770   Top1 90.507812   Top5 99.589844   BatchTime 0.135762   
2022-11-25 12:45:16,823 - INFO  - Validation [46][   40/   40]   Loss 0.290271   Top1 90.970000   Top5 99.690000   BatchTime 0.094533   
2022-11-25 12:45:17,077 - INFO  - ==> Top1: 90.970    Top5: 99.690    Loss: 0.290

2022-11-25 12:45:17,078 - INFO  - ==> Sparsity : 0.668

2022-11-25 12:45:17,078 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:45:17,078 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:45:17,078 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:45:17,223 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:45:17,225 - INFO  - >>>>>> Epoch  47
2022-11-25 12:45:17,227 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:45:25,883 - INFO  - Training [47][   20/  196]   Loss 0.298732   Top1 89.667969   Top5 98.808594   BatchTime 0.432688   LR 0.000766   
2022-11-25 12:45:33,366 - INFO  - Training [47][   40/  196]   Loss 0.291246   Top1 89.794922   Top5 98.906250   BatchTime 0.403406   LR 0.000761   
2022-11-25 12:45:40,439 - INFO  - Training [47][   60/  196]   Loss 0.288607   Top1 89.850260   Top5 98.938802   BatchTime 0.386811   LR 0.000756   
2022-11-25 12:45:48,155 - INFO  - Training [47][   80/  196]   Loss 0.284072   Top1 90.014648   Top5 99.086914   BatchTime 0.386562   LR 0.000752   
2022-11-25 12:45:55,781 - INFO  - Training [47][  100/  196]   Loss 0.276168   Top1 90.324219   Top5 99.132812   BatchTime 0.385515   LR 0.000747   
2022-11-25 12:46:03,118 - INFO  - Training [47][  120/  196]   Loss 0.267244   Top1 90.634766   Top5 99.182943   BatchTime 0.382400   LR 0.000742   
2022-11-25 12:46:09,976 - INFO  - Training [47][  140/  196]   Loss 0.267409   Top1 90.594308   Top5 99.238281   BatchTime 0.376756   LR 0.000737   
2022-11-25 12:46:16,616 - INFO  - Training [47][  160/  196]   Loss 0.268441   Top1 90.568848   Top5 99.204102   BatchTime 0.371159   LR 0.000732   
2022-11-25 12:46:23,753 - INFO  - Training [47][  180/  196]   Loss 0.269081   Top1 90.538194   Top5 99.166667   BatchTime 0.369568   LR 0.000727   
2022-11-25 12:46:29,163 - INFO  - ==> Top1: 90.538    Top5: 99.170    Loss: 0.268

2022-11-25 12:46:29,408 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:46:31,228 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:46:34,642 - INFO  - Validation [47][   20/   40]   Loss 0.308024   Top1 90.917969   Top5 99.667969   BatchTime 0.170647   
2022-11-25 12:46:35,654 - INFO  - Validation [47][   40/   40]   Loss 0.291090   Top1 91.350000   Top5 99.720000   BatchTime 0.110618   
2022-11-25 12:46:35,910 - INFO  - ==> Top1: 91.350    Top5: 99.720    Loss: 0.291

2022-11-25 12:46:35,910 - INFO  - ==> Sparsity : 0.668

2022-11-25 12:46:35,910 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:46:35,910 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:46:35,910 - INFO  - Scoreboard best 3 ==> Epoch [28][Top1: 91.610   Top5: 99.740]
2022-11-25 12:46:36,032 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:46:36,034 - INFO  - >>>>>> Epoch  48
2022-11-25 12:46:36,036 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:46:44,299 - INFO  - Training [48][   20/  196]   Loss 0.280988   Top1 89.785156   Top5 98.496094   BatchTime 0.413006   LR 0.000718   
2022-11-25 12:46:51,169 - INFO  - Training [48][   40/  196]   Loss 0.288498   Top1 89.707031   Top5 98.652344   BatchTime 0.378264   LR 0.000713   
2022-11-25 12:46:57,968 - INFO  - Training [48][   60/  196]   Loss 0.290780   Top1 89.537760   Top5 98.802083   BatchTime 0.365486   LR 0.000708   
2022-11-25 12:47:05,095 - INFO  - Training [48][   80/  196]   Loss 0.289134   Top1 89.526367   Top5 98.994141   BatchTime 0.363204   LR 0.000703   
2022-11-25 12:47:11,959 - INFO  - Training [48][  100/  196]   Loss 0.285105   Top1 89.621094   Top5 99.027344   BatchTime 0.359205   LR 0.000698   
2022-11-25 12:47:18,606 - INFO  - Training [48][  120/  196]   Loss 0.277614   Top1 90.006510   Top5 99.078776   BatchTime 0.354730   LR 0.000693   
2022-11-25 12:47:25,457 - INFO  - Training [48][  140/  196]   Loss 0.276956   Top1 90.066964   Top5 99.123884   BatchTime 0.352983   LR 0.000688   
2022-11-25 12:47:32,118 - INFO  - Training [48][  160/  196]   Loss 0.277745   Top1 90.087891   Top5 99.123535   BatchTime 0.350496   LR 0.000683   
2022-11-25 12:47:38,790 - INFO  - Training [48][  180/  196]   Loss 0.275575   Top1 90.182292   Top5 99.101562   BatchTime 0.348616   LR 0.000678   
2022-11-25 12:47:44,898 - INFO  - ==> Top1: 90.272    Top5: 99.100    Loss: 0.274

2022-11-25 12:47:45,192 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:47:46,409 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:47:49,408 - INFO  - Validation [48][   20/   40]   Loss 0.295197   Top1 91.523438   Top5 99.667969   BatchTime 0.149829   
2022-11-25 12:47:52,005 - INFO  - Validation [48][   40/   40]   Loss 0.277255   Top1 91.620000   Top5 99.720000   BatchTime 0.139850   
2022-11-25 12:47:52,539 - INFO  - ==> Top1: 91.620    Top5: 99.720    Loss: 0.277

2022-11-25 12:47:52,539 - INFO  - ==> Sparsity : 0.668

2022-11-25 12:47:52,540 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:47:52,540 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:47:52,540 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 91.620   Top5: 99.720]
2022-11-25 12:47:52,675 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:47:52,676 - INFO  - >>>>>> Epoch  49
2022-11-25 12:47:52,678 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:48:01,531 - INFO  - Training [49][   20/  196]   Loss 0.283134   Top1 90.039062   Top5 98.691406   BatchTime 0.442500   LR 0.000669   
2022-11-25 12:48:08,092 - INFO  - Training [49][   40/  196]   Loss 0.284586   Top1 90.009766   Top5 98.964844   BatchTime 0.385271   LR 0.000664   
2022-11-25 12:48:15,059 - INFO  - Training [49][   60/  196]   Loss 0.275245   Top1 90.292969   Top5 99.029948   BatchTime 0.372969   LR 0.000659   
2022-11-25 12:48:22,135 - INFO  - Training [49][   80/  196]   Loss 0.274395   Top1 90.239258   Top5 99.116211   BatchTime 0.368171   LR 0.000654   
2022-11-25 12:48:28,790 - INFO  - Training [49][  100/  196]   Loss 0.268331   Top1 90.464844   Top5 99.148438   BatchTime 0.361096   LR 0.000649   
2022-11-25 12:48:35,634 - INFO  - Training [49][  120/  196]   Loss 0.263562   Top1 90.696615   Top5 99.199219   BatchTime 0.357939   LR 0.000644   
2022-11-25 12:48:42,297 - INFO  - Training [49][  140/  196]   Loss 0.260407   Top1 90.778460   Top5 99.243862   BatchTime 0.354396   LR 0.000639   
2022-11-25 12:48:49,307 - INFO  - Training [49][  160/  196]   Loss 0.263973   Top1 90.646973   Top5 99.206543   BatchTime 0.353910   LR 0.000634   
2022-11-25 12:48:56,143 - INFO  - Training [49][  180/  196]   Loss 0.264901   Top1 90.625000   Top5 99.179688   BatchTime 0.352563   LR 0.000629   
2022-11-25 12:49:02,230 - INFO  - ==> Top1: 90.642    Top5: 99.192    Loss: 0.265

2022-11-25 12:49:02,487 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:49:03,989 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:49:06,718 - INFO  - Validation [49][   20/   40]   Loss 0.299158   Top1 90.800781   Top5 99.648438   BatchTime 0.136333   
2022-11-25 12:49:08,055 - INFO  - Validation [49][   40/   40]   Loss 0.290657   Top1 90.980000   Top5 99.750000   BatchTime 0.101593   
2022-11-25 12:49:08,343 - INFO  - ==> Top1: 90.980    Top5: 99.750    Loss: 0.291

2022-11-25 12:49:08,344 - INFO  - ==> Sparsity : 0.669

2022-11-25 12:49:08,344 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:49:08,344 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:49:08,344 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 91.620   Top5: 99.720]
2022-11-25 12:49:08,493 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:49:08,495 - INFO  - >>>>>> Epoch  50
2022-11-25 12:49:08,496 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:49:16,938 - INFO  - Training [50][   20/  196]   Loss 0.288788   Top1 89.570312   Top5 98.769531   BatchTime 0.421924   LR 0.000620   
2022-11-25 12:49:23,945 - INFO  - Training [50][   40/  196]   Loss 0.281977   Top1 89.941406   Top5 98.916016   BatchTime 0.386156   LR 0.000615   
2022-11-25 12:49:31,210 - INFO  - Training [50][   60/  196]   Loss 0.276210   Top1 90.162760   Top5 98.977865   BatchTime 0.378507   LR 0.000610   
2022-11-25 12:49:38,083 - INFO  - Training [50][   80/  196]   Loss 0.272236   Top1 90.263672   Top5 99.082031   BatchTime 0.369794   LR 0.000605   
2022-11-25 12:49:44,873 - INFO  - Training [50][  100/  196]   Loss 0.265194   Top1 90.542969   Top5 99.164062   BatchTime 0.363740   LR 0.000600   
2022-11-25 12:49:52,124 - INFO  - Training [50][  120/  196]   Loss 0.258228   Top1 90.843099   Top5 99.208984   BatchTime 0.363534   LR 0.000595   
2022-11-25 12:49:58,924 - INFO  - Training [50][  140/  196]   Loss 0.253634   Top1 91.071429   Top5 99.271763   BatchTime 0.360175   LR 0.000590   
2022-11-25 12:50:05,604 - INFO  - Training [50][  160/  196]   Loss 0.256338   Top1 90.957031   Top5 99.257812   BatchTime 0.356903   LR 0.000585   
2022-11-25 12:50:12,329 - INFO  - Training [50][  180/  196]   Loss 0.259069   Top1 90.950521   Top5 99.194878   BatchTime 0.354607   LR 0.000580   
2022-11-25 12:50:17,887 - INFO  - ==> Top1: 90.978    Top5: 99.168    Loss: 0.258

2022-11-25 12:50:18,186 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:50:19,779 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:50:22,445 - INFO  - Validation [50][   20/   40]   Loss 0.299255   Top1 90.937500   Top5 99.648438   BatchTime 0.133169   
2022-11-25 12:50:23,740 - INFO  - Validation [50][   40/   40]   Loss 0.279621   Top1 91.380000   Top5 99.720000   BatchTime 0.098982   
2022-11-25 12:50:24,253 - INFO  - ==> Top1: 91.380    Top5: 99.720    Loss: 0.280

2022-11-25 12:50:24,254 - INFO  - ==> Sparsity : 0.669

2022-11-25 12:50:24,254 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:50:24,254 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:50:24,254 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 91.620   Top5: 99.720]
2022-11-25 12:50:24,476 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:50:24,479 - INFO  - >>>>>> Epoch  51
2022-11-25 12:50:24,482 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:50:31,926 - INFO  - Training [51][   20/  196]   Loss 0.271247   Top1 90.019531   Top5 98.847656   BatchTime 0.371925   LR 0.000571   
2022-11-25 12:50:38,833 - INFO  - Training [51][   40/  196]   Loss 0.268008   Top1 90.341797   Top5 98.886719   BatchTime 0.358646   LR 0.000566   
2022-11-25 12:50:45,794 - INFO  - Training [51][   60/  196]   Loss 0.265841   Top1 90.475260   Top5 99.010417   BatchTime 0.355118   LR 0.000561   
2022-11-25 12:50:52,760 - INFO  - Training [51][   80/  196]   Loss 0.263089   Top1 90.629883   Top5 99.067383   BatchTime 0.353408   LR 0.000556   
2022-11-25 12:51:00,240 - INFO  - Training [51][  100/  196]   Loss 0.258391   Top1 90.789062   Top5 99.070312   BatchTime 0.357521   LR 0.000551   
2022-11-25 12:51:07,001 - INFO  - Training [51][  120/  196]   Loss 0.251851   Top1 90.989583   Top5 99.140625   BatchTime 0.354278   LR 0.000546   
2022-11-25 12:51:13,783 - INFO  - Training [51][  140/  196]   Loss 0.250384   Top1 91.102121   Top5 99.171317   BatchTime 0.352110   LR 0.000541   
2022-11-25 12:51:20,613 - INFO  - Training [51][  160/  196]   Loss 0.255457   Top1 90.917969   Top5 99.172363   BatchTime 0.350786   LR 0.000536   
2022-11-25 12:51:27,986 - INFO  - Training [51][  180/  196]   Loss 0.256981   Top1 90.811632   Top5 99.142795   BatchTime 0.352771   LR 0.000531   
2022-11-25 12:51:33,548 - INFO  - ==> Top1: 90.866    Top5: 99.158    Loss: 0.256

2022-11-25 12:51:33,817 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:51:35,101 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:51:37,792 - INFO  - Validation [51][   20/   40]   Loss 0.297916   Top1 91.308594   Top5 99.707031   BatchTime 0.134458   
2022-11-25 12:51:38,918 - INFO  - Validation [51][   40/   40]   Loss 0.286027   Top1 91.450000   Top5 99.740000   BatchTime 0.095385   
2022-11-25 12:51:39,171 - INFO  - ==> Top1: 91.450    Top5: 99.740    Loss: 0.286

2022-11-25 12:51:39,171 - INFO  - ==> Sparsity : 0.668

2022-11-25 12:51:39,172 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:51:39,172 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:51:39,172 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 91.620   Top5: 99.720]
2022-11-25 12:51:39,341 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:51:39,343 - INFO  - >>>>>> Epoch  52
2022-11-25 12:51:39,344 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:51:47,604 - INFO  - Training [52][   20/  196]   Loss 0.278738   Top1 90.468750   Top5 98.554688   BatchTime 0.412828   LR 0.000523   
2022-11-25 12:51:54,234 - INFO  - Training [52][   40/  196]   Loss 0.272983   Top1 90.546875   Top5 98.720703   BatchTime 0.372162   LR 0.000518   
2022-11-25 12:51:59,470 - INFO  - Training [52][   60/  196]   Loss 0.267187   Top1 90.787760   Top5 98.795573   BatchTime 0.335384   LR 0.000513   
2022-11-25 12:52:05,302 - INFO  - Training [52][   80/  196]   Loss 0.271457   Top1 90.566406   Top5 98.940430   BatchTime 0.324434   LR 0.000508   
2022-11-25 12:52:12,021 - INFO  - Training [52][  100/  196]   Loss 0.264920   Top1 90.804688   Top5 99.019531   BatchTime 0.326734   LR 0.000503   
2022-11-25 12:52:18,984 - INFO  - Training [52][  120/  196]   Loss 0.260126   Top1 90.950521   Top5 99.091797   BatchTime 0.330303   LR 0.000498   
2022-11-25 12:52:25,869 - INFO  - Training [52][  140/  196]   Loss 0.257722   Top1 91.074219   Top5 99.148996   BatchTime 0.332296   LR 0.000493   
2022-11-25 12:52:32,735 - INFO  - Training [52][  160/  196]   Loss 0.258528   Top1 91.047363   Top5 99.128418   BatchTime 0.333670   LR 0.000488   
2022-11-25 12:52:39,648 - INFO  - Training [52][  180/  196]   Loss 0.257980   Top1 91.063368   Top5 99.108073   BatchTime 0.335000   LR 0.000483   
2022-11-25 12:52:45,068 - INFO  - ==> Top1: 91.108    Top5: 99.094    Loss: 0.258

2022-11-25 12:52:45,305 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:52:46,591 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:52:49,176 - INFO  - Validation [52][   20/   40]   Loss 0.297878   Top1 91.250000   Top5 99.648438   BatchTime 0.129185   
2022-11-25 12:52:50,194 - INFO  - Validation [52][   40/   40]   Loss 0.282687   Top1 91.510000   Top5 99.730000   BatchTime 0.090036   
2022-11-25 12:52:50,463 - INFO  - ==> Top1: 91.510    Top5: 99.730    Loss: 0.283

2022-11-25 12:52:50,464 - INFO  - ==> Sparsity : 0.669

2022-11-25 12:52:50,464 - INFO  - Scoreboard best 1 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:52:50,464 - INFO  - Scoreboard best 2 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:52:50,464 - INFO  - Scoreboard best 3 ==> Epoch [48][Top1: 91.620   Top5: 99.720]
2022-11-25 12:52:50,652 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:52:50,654 - INFO  - >>>>>> Epoch  53
2022-11-25 12:52:50,656 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:52:59,885 - INFO  - Training [53][   20/  196]   Loss 0.274171   Top1 90.292969   Top5 98.847656   BatchTime 0.461325   LR 0.000474   
2022-11-25 12:53:07,068 - INFO  - Training [53][   40/  196]   Loss 0.269652   Top1 90.615234   Top5 98.876953   BatchTime 0.410246   LR 0.000470   
2022-11-25 12:53:14,195 - INFO  - Training [53][   60/  196]   Loss 0.266282   Top1 90.768229   Top5 98.958333   BatchTime 0.392282   LR 0.000465   
2022-11-25 12:53:20,485 - INFO  - Training [53][   80/  196]   Loss 0.263917   Top1 90.844727   Top5 99.096680   BatchTime 0.372826   LR 0.000460   
2022-11-25 12:53:25,547 - INFO  - Training [53][  100/  196]   Loss 0.258966   Top1 91.031250   Top5 99.089844   BatchTime 0.348887   LR 0.000455   
2022-11-25 12:53:32,544 - INFO  - Training [53][  120/  196]   Loss 0.252846   Top1 91.171875   Top5 99.163411   BatchTime 0.349043   LR 0.000450   
2022-11-25 12:53:39,292 - INFO  - Training [53][  140/  196]   Loss 0.251010   Top1 91.210938   Top5 99.196429   BatchTime 0.347380   LR 0.000445   
2022-11-25 12:53:46,357 - INFO  - Training [53][  160/  196]   Loss 0.252545   Top1 91.118164   Top5 99.182129   BatchTime 0.348111   LR 0.000441   
2022-11-25 12:53:53,353 - INFO  - Training [53][  180/  196]   Loss 0.253350   Top1 91.078559   Top5 99.151476   BatchTime 0.348302   LR 0.000436   
2022-11-25 12:53:59,133 - INFO  - ==> Top1: 91.092    Top5: 99.170    Loss: 0.253

2022-11-25 12:53:59,376 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:54:00,687 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:54:03,370 - INFO  - Validation [53][   20/   40]   Loss 0.293508   Top1 91.406250   Top5 99.589844   BatchTime 0.134086   
2022-11-25 12:54:04,428 - INFO  - Validation [53][   40/   40]   Loss 0.274254   Top1 91.780000   Top5 99.700000   BatchTime 0.093477   
2022-11-25 12:54:04,678 - INFO  - ==> Top1: 91.780    Top5: 99.700    Loss: 0.274

2022-11-25 12:54:04,679 - INFO  - ==> Sparsity : 0.669

2022-11-25 12:54:04,679 - INFO  - Scoreboard best 1 ==> Epoch [53][Top1: 91.780   Top5: 99.700]
2022-11-25 12:54:04,679 - INFO  - Scoreboard best 2 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:54:04,679 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 91.630   Top5: 99.790]
2022-11-25 12:54:10,451 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:54:10,456 - INFO  - >>>>>> Epoch  54
2022-11-25 12:54:10,459 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:54:19,243 - INFO  - Training [54][   20/  196]   Loss 0.261052   Top1 90.781250   Top5 98.632812   BatchTime 0.439104   LR 0.000427   
2022-11-25 12:54:26,719 - INFO  - Training [54][   40/  196]   Loss 0.261844   Top1 90.664062   Top5 98.837891   BatchTime 0.406439   LR 0.000423   
2022-11-25 12:54:33,415 - INFO  - Training [54][   60/  196]   Loss 0.265555   Top1 90.462240   Top5 98.880208   BatchTime 0.382554   LR 0.000418   
2022-11-25 12:54:38,705 - INFO  - Training [54][   80/  196]   Loss 0.264135   Top1 90.546875   Top5 99.023438   BatchTime 0.353046   LR 0.000413   
2022-11-25 12:54:44,905 - INFO  - Training [54][  100/  196]   Loss 0.253329   Top1 90.972656   Top5 99.085938   BatchTime 0.344427   LR 0.000408   
2022-11-25 12:54:51,870 - INFO  - Training [54][  120/  196]   Loss 0.247514   Top1 91.155599   Top5 99.169922   BatchTime 0.345068   LR 0.000404   
2022-11-25 12:54:58,864 - INFO  - Training [54][  140/  196]   Loss 0.247033   Top1 91.185826   Top5 99.215960   BatchTime 0.345730   LR 0.000399   
2022-11-25 12:55:05,838 - INFO  - Training [54][  160/  196]   Loss 0.250462   Top1 91.027832   Top5 99.208984   BatchTime 0.346099   LR 0.000394   
2022-11-25 12:55:12,774 - INFO  - Training [54][  180/  196]   Loss 0.250047   Top1 91.056858   Top5 99.175347   BatchTime 0.346175   LR 0.000390   
2022-11-25 12:55:18,230 - INFO  - ==> Top1: 91.106    Top5: 99.166    Loss: 0.249

2022-11-25 12:55:18,478 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:55:20,294 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:55:22,945 - INFO  - Validation [54][   20/   40]   Loss 0.285382   Top1 91.738281   Top5 99.628906   BatchTime 0.132450   
2022-11-25 12:55:23,938 - INFO  - Validation [54][   40/   40]   Loss 0.270251   Top1 91.960000   Top5 99.740000   BatchTime 0.091059   
2022-11-25 12:55:24,246 - INFO  - ==> Top1: 91.960    Top5: 99.740    Loss: 0.270

2022-11-25 12:55:24,246 - INFO  - ==> Sparsity : 0.669

2022-11-25 12:55:24,247 - INFO  - Scoreboard best 1 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 12:55:24,247 - INFO  - Scoreboard best 2 ==> Epoch [53][Top1: 91.780   Top5: 99.700]
2022-11-25 12:55:24,247 - INFO  - Scoreboard best 3 ==> Epoch [29][Top1: 91.730   Top5: 99.740]
2022-11-25 12:55:29,762 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:55:29,768 - INFO  - >>>>>> Epoch  55
2022-11-25 12:55:29,771 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:55:38,819 - INFO  - Training [55][   20/  196]   Loss 0.263783   Top1 90.683594   Top5 98.750000   BatchTime 0.452263   LR 0.000381   
2022-11-25 12:55:45,743 - INFO  - Training [55][   40/  196]   Loss 0.262124   Top1 90.742188   Top5 98.896484   BatchTime 0.399233   LR 0.000377   
2022-11-25 12:55:52,163 - INFO  - Training [55][   60/  196]   Loss 0.266582   Top1 90.618490   Top5 99.016927   BatchTime 0.373153   LR 0.000372   
2022-11-25 12:55:57,532 - INFO  - Training [55][   80/  196]   Loss 0.260734   Top1 90.878906   Top5 99.101562   BatchTime 0.346977   LR 0.000368   
2022-11-25 12:56:03,280 - INFO  - Training [55][  100/  196]   Loss 0.256080   Top1 90.988281   Top5 99.132812   BatchTime 0.335055   LR 0.000363   
2022-11-25 12:56:10,229 - INFO  - Training [55][  120/  196]   Loss 0.252837   Top1 91.106771   Top5 99.199219   BatchTime 0.337118   LR 0.000358   
2022-11-25 12:56:17,213 - INFO  - Training [55][  140/  196]   Loss 0.249626   Top1 91.222098   Top5 99.266183   BatchTime 0.338845   LR 0.000354   
2022-11-25 12:56:24,447 - INFO  - Training [55][  160/  196]   Loss 0.251141   Top1 91.152344   Top5 99.228516   BatchTime 0.341703   LR 0.000349   
2022-11-25 12:56:32,223 - INFO  - Training [55][  180/  196]   Loss 0.251261   Top1 91.115451   Top5 99.227431   BatchTime 0.346934   LR 0.000345   
2022-11-25 12:56:38,558 - INFO  - ==> Top1: 91.118    Top5: 99.214    Loss: 0.251

2022-11-25 12:56:38,869 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:56:40,328 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:56:43,353 - INFO  - Validation [55][   20/   40]   Loss 0.284162   Top1 91.914062   Top5 99.707031   BatchTime 0.151155   
2022-11-25 12:56:44,784 - INFO  - Validation [55][   40/   40]   Loss 0.270740   Top1 92.030000   Top5 99.780000   BatchTime 0.111342   
2022-11-25 12:56:45,332 - INFO  - ==> Top1: 92.030    Top5: 99.780    Loss: 0.271

2022-11-25 12:56:45,332 - INFO  - ==> Sparsity : 0.669

2022-11-25 12:56:45,333 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 12:56:45,333 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 12:56:45,333 - INFO  - Scoreboard best 3 ==> Epoch [53][Top1: 91.780   Top5: 99.700]
2022-11-25 12:56:51,383 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 12:56:51,385 - INFO  - >>>>>> Epoch  56
2022-11-25 12:56:51,387 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:57:00,154 - INFO  - Training [56][   20/  196]   Loss 0.268668   Top1 90.527344   Top5 98.632812   BatchTime 0.438234   LR 0.000337   
2022-11-25 12:57:07,376 - INFO  - Training [56][   40/  196]   Loss 0.268271   Top1 90.751953   Top5 98.759766   BatchTime 0.399676   LR 0.000333   
2022-11-25 12:57:13,776 - INFO  - Training [56][   60/  196]   Loss 0.262625   Top1 90.781250   Top5 98.906250   BatchTime 0.373119   LR 0.000328   
2022-11-25 12:57:19,948 - INFO  - Training [56][   80/  196]   Loss 0.261958   Top1 90.830078   Top5 99.018555   BatchTime 0.356988   LR 0.000324   
2022-11-25 12:57:26,611 - INFO  - Training [56][  100/  196]   Loss 0.254564   Top1 91.140625   Top5 99.105469   BatchTime 0.352216   LR 0.000319   
2022-11-25 12:57:33,445 - INFO  - Training [56][  120/  196]   Loss 0.250356   Top1 91.302083   Top5 99.127604   BatchTime 0.350462   LR 0.000315   
2022-11-25 12:57:40,272 - INFO  - Training [56][  140/  196]   Loss 0.248039   Top1 91.383929   Top5 99.182478   BatchTime 0.349162   LR 0.000311   
2022-11-25 12:57:47,137 - INFO  - Training [56][  160/  196]   Loss 0.250186   Top1 91.323242   Top5 99.172363   BatchTime 0.348418   LR 0.000306   
2022-11-25 12:57:54,052 - INFO  - Training [56][  180/  196]   Loss 0.249289   Top1 91.328125   Top5 99.162326   BatchTime 0.348123   LR 0.000302   
2022-11-25 12:57:59,771 - INFO  - ==> Top1: 91.362    Top5: 99.156    Loss: 0.249

2022-11-25 12:58:00,089 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:58:01,780 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:58:04,420 - INFO  - Validation [56][   20/   40]   Loss 0.285325   Top1 91.875000   Top5 99.707031   BatchTime 0.131867   
2022-11-25 12:58:05,367 - INFO  - Validation [56][   40/   40]   Loss 0.272514   Top1 91.940000   Top5 99.740000   BatchTime 0.089606   
2022-11-25 12:58:05,676 - INFO  - ==> Top1: 91.940    Top5: 99.740    Loss: 0.273

2022-11-25 12:58:05,676 - INFO  - ==> Sparsity : 0.669

2022-11-25 12:58:05,677 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 12:58:05,677 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 12:58:05,677 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 12:58:05,817 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:58:05,819 - INFO  - >>>>>> Epoch  57
2022-11-25 12:58:05,821 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:58:14,217 - INFO  - Training [57][   20/  196]   Loss 0.269200   Top1 90.820312   Top5 98.613281   BatchTime 0.419658   LR 0.000294   
2022-11-25 12:58:21,070 - INFO  - Training [57][   40/  196]   Loss 0.261955   Top1 90.849609   Top5 98.779297   BatchTime 0.381159   LR 0.000290   
2022-11-25 12:58:28,031 - INFO  - Training [57][   60/  196]   Loss 0.252845   Top1 91.204427   Top5 98.893229   BatchTime 0.370129   LR 0.000286   
2022-11-25 12:58:33,356 - INFO  - Training [57][   80/  196]   Loss 0.250684   Top1 91.303711   Top5 99.033203   BatchTime 0.344153   LR 0.000282   
2022-11-25 12:58:38,332 - INFO  - Training [57][  100/  196]   Loss 0.245013   Top1 91.484375   Top5 99.105469   BatchTime 0.325079   LR 0.000277   
2022-11-25 12:58:44,569 - INFO  - Training [57][  120/  196]   Loss 0.240914   Top1 91.630859   Top5 99.160156   BatchTime 0.322875   LR 0.000273   
2022-11-25 12:58:51,471 - INFO  - Training [57][  140/  196]   Loss 0.239502   Top1 91.651786   Top5 99.207589   BatchTime 0.326055   LR 0.000269   
2022-11-25 12:58:58,462 - INFO  - Training [57][  160/  196]   Loss 0.242382   Top1 91.533203   Top5 99.194336   BatchTime 0.328987   LR 0.000265   
2022-11-25 12:59:05,277 - INFO  - Training [57][  180/  196]   Loss 0.244478   Top1 91.482205   Top5 99.155816   BatchTime 0.330293   LR 0.000261   
2022-11-25 12:59:11,184 - INFO  - ==> Top1: 91.532    Top5: 99.174    Loss: 0.243

2022-11-25 12:59:11,454 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 12:59:12,923 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 12:59:15,649 - INFO  - Validation [57][   20/   40]   Loss 0.318540   Top1 90.859375   Top5 99.648438   BatchTime 0.136183   
2022-11-25 12:59:16,610 - INFO  - Validation [57][   40/   40]   Loss 0.304279   Top1 91.020000   Top5 99.720000   BatchTime 0.092137   
2022-11-25 12:59:16,944 - INFO  - ==> Top1: 91.020    Top5: 99.720    Loss: 0.304

2022-11-25 12:59:16,944 - INFO  - ==> Sparsity : 0.669

2022-11-25 12:59:16,944 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 12:59:16,944 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 12:59:16,945 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 12:59:17,331 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 12:59:17,333 - INFO  - >>>>>> Epoch  58
2022-11-25 12:59:17,334 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 12:59:26,126 - INFO  - Training [58][   20/  196]   Loss 0.260357   Top1 90.488281   Top5 98.554688   BatchTime 0.439457   LR 0.000254   
2022-11-25 12:59:32,760 - INFO  - Training [58][   40/  196]   Loss 0.271129   Top1 90.341797   Top5 98.779297   BatchTime 0.385586   LR 0.000250   
2022-11-25 12:59:39,706 - INFO  - Training [58][   60/  196]   Loss 0.263319   Top1 90.722656   Top5 98.880208   BatchTime 0.372821   LR 0.000246   
2022-11-25 12:59:46,817 - INFO  - Training [58][   80/  196]   Loss 0.259467   Top1 90.800781   Top5 99.072266   BatchTime 0.368492   LR 0.000242   
2022-11-25 12:59:52,621 - INFO  - Training [58][  100/  196]   Loss 0.250127   Top1 91.164062   Top5 99.140625   BatchTime 0.352839   LR 0.000238   
2022-11-25 12:59:57,614 - INFO  - Training [58][  120/  196]   Loss 0.244571   Top1 91.435547   Top5 99.192708   BatchTime 0.335638   LR 0.000234   
2022-11-25 13:00:03,805 - INFO  - Training [58][  140/  196]   Loss 0.243580   Top1 91.506696   Top5 99.243862   BatchTime 0.331910   LR 0.000230   
2022-11-25 13:00:10,538 - INFO  - Training [58][  160/  196]   Loss 0.243789   Top1 91.567383   Top5 99.216309   BatchTime 0.332505   LR 0.000226   
2022-11-25 13:00:16,898 - INFO  - Training [58][  180/  196]   Loss 0.245184   Top1 91.508247   Top5 99.190538   BatchTime 0.330891   LR 0.000222   
2022-11-25 13:00:22,214 - INFO  - ==> Top1: 91.526    Top5: 99.178    Loss: 0.245

2022-11-25 13:00:22,587 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:00:25,477 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:00:28,357 - INFO  - Validation [58][   20/   40]   Loss 0.285968   Top1 91.699219   Top5 99.687500   BatchTime 0.143928   
2022-11-25 13:00:29,339 - INFO  - Validation [58][   40/   40]   Loss 0.270913   Top1 91.940000   Top5 99.720000   BatchTime 0.096523   
2022-11-25 13:00:29,608 - INFO  - ==> Top1: 91.940    Top5: 99.720    Loss: 0.271

2022-11-25 13:00:29,608 - INFO  - ==> Sparsity : 0.669

2022-11-25 13:00:29,608 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:00:29,608 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:00:29,609 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 13:00:29,781 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:00:29,782 - INFO  - >>>>>> Epoch  59
2022-11-25 13:00:29,784 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:00:37,980 - INFO  - Training [59][   20/  196]   Loss 0.269887   Top1 90.273438   Top5 98.593750   BatchTime 0.409641   LR 0.000215   
2022-11-25 13:00:44,737 - INFO  - Training [59][   40/  196]   Loss 0.266981   Top1 90.468750   Top5 98.691406   BatchTime 0.373746   LR 0.000212   
2022-11-25 13:00:51,646 - INFO  - Training [59][   60/  196]   Loss 0.256431   Top1 90.787760   Top5 98.932292   BatchTime 0.364316   LR 0.000208   
2022-11-25 13:00:59,253 - INFO  - Training [59][   80/  196]   Loss 0.253159   Top1 91.000977   Top5 99.086914   BatchTime 0.368325   LR 0.000204   
2022-11-25 13:01:06,356 - INFO  - Training [59][  100/  196]   Loss 0.250368   Top1 91.164062   Top5 99.097656   BatchTime 0.365683   LR 0.000201   
2022-11-25 13:01:12,127 - INFO  - Training [59][  120/  196]   Loss 0.245063   Top1 91.321615   Top5 99.134115   BatchTime 0.352829   LR 0.000197   
2022-11-25 13:01:17,320 - INFO  - Training [59][  140/  196]   Loss 0.244290   Top1 91.372768   Top5 99.168527   BatchTime 0.339520   LR 0.000193   
2022-11-25 13:01:24,645 - INFO  - Training [59][  160/  196]   Loss 0.243649   Top1 91.379395   Top5 99.189453   BatchTime 0.342855   LR 0.000190   
2022-11-25 13:01:31,622 - INFO  - Training [59][  180/  196]   Loss 0.242619   Top1 91.397569   Top5 99.155816   BatchTime 0.343522   LR 0.000186   
2022-11-25 13:01:37,916 - INFO  - ==> Top1: 91.424    Top5: 99.144    Loss: 0.242

2022-11-25 13:01:38,144 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:01:39,536 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:01:42,230 - INFO  - Validation [59][   20/   40]   Loss 0.289602   Top1 91.757812   Top5 99.687500   BatchTime 0.134579   
2022-11-25 13:01:43,222 - INFO  - Validation [59][   40/   40]   Loss 0.273526   Top1 91.900000   Top5 99.760000   BatchTime 0.092102   
2022-11-25 13:01:43,495 - INFO  - ==> Top1: 91.900    Top5: 99.760    Loss: 0.274

2022-11-25 13:01:43,495 - INFO  - ==> Sparsity : 0.669

2022-11-25 13:01:43,495 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:01:43,496 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:01:43,496 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 13:01:43,943 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:01:43,945 - INFO  - >>>>>> Epoch  60
2022-11-25 13:01:43,947 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:01:53,243 - INFO  - Training [60][   20/  196]   Loss 0.271978   Top1 90.664062   Top5 98.671875   BatchTime 0.464662   LR 0.000180   
2022-11-25 13:02:00,267 - INFO  - Training [60][   40/  196]   Loss 0.268120   Top1 90.839844   Top5 98.808594   BatchTime 0.407945   LR 0.000176   
2022-11-25 13:02:07,570 - INFO  - Training [60][   60/  196]   Loss 0.252223   Top1 91.367188   Top5 98.977865   BatchTime 0.393670   LR 0.000173   
2022-11-25 13:02:14,125 - INFO  - Training [60][   80/  196]   Loss 0.249515   Top1 91.445312   Top5 99.077148   BatchTime 0.377197   LR 0.000169   
2022-11-25 13:02:21,128 - INFO  - Training [60][  100/  196]   Loss 0.243349   Top1 91.636719   Top5 99.121094   BatchTime 0.371785   LR 0.000166   
2022-11-25 13:02:27,535 - INFO  - Training [60][  120/  196]   Loss 0.239263   Top1 91.806641   Top5 99.208984   BatchTime 0.363209   LR 0.000162   
2022-11-25 13:02:33,092 - INFO  - Training [60][  140/  196]   Loss 0.237738   Top1 91.827567   Top5 99.257812   BatchTime 0.351017   LR 0.000159   
2022-11-25 13:02:38,478 - INFO  - Training [60][  160/  196]   Loss 0.240774   Top1 91.716309   Top5 99.240723   BatchTime 0.340798   LR 0.000156   
2022-11-25 13:02:45,337 - INFO  - Training [60][  180/  196]   Loss 0.239947   Top1 91.705729   Top5 99.227431   BatchTime 0.341038   LR 0.000152   
2022-11-25 13:02:50,923 - INFO  - ==> Top1: 91.772    Top5: 99.222    Loss: 0.237

2022-11-25 13:02:51,184 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:02:52,738 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:02:55,406 - INFO  - Validation [60][   20/   40]   Loss 0.300589   Top1 91.406250   Top5 99.707031   BatchTime 0.133315   
2022-11-25 13:02:56,565 - INFO  - Validation [60][   40/   40]   Loss 0.288655   Top1 91.590000   Top5 99.750000   BatchTime 0.095637   
2022-11-25 13:02:56,869 - INFO  - ==> Top1: 91.590    Top5: 99.750    Loss: 0.289

2022-11-25 13:02:56,869 - INFO  - ==> Sparsity : 0.668

2022-11-25 13:02:56,869 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:02:56,870 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:02:56,870 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 13:02:56,993 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:02:56,995 - INFO  - >>>>>> Epoch  61
2022-11-25 13:02:56,996 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:03:05,982 - INFO  - Training [61][   20/  196]   Loss 0.258800   Top1 90.839844   Top5 98.769531   BatchTime 0.449155   LR 0.000147   
2022-11-25 13:03:13,624 - INFO  - Training [61][   40/  196]   Loss 0.249488   Top1 91.015625   Top5 98.925781   BatchTime 0.415623   LR 0.000143   
2022-11-25 13:03:20,822 - INFO  - Training [61][   60/  196]   Loss 0.246559   Top1 91.282552   Top5 99.003906   BatchTime 0.397058   LR 0.000140   
2022-11-25 13:03:27,640 - INFO  - Training [61][   80/  196]   Loss 0.247811   Top1 91.293945   Top5 99.082031   BatchTime 0.383015   LR 0.000137   
2022-11-25 13:03:34,284 - INFO  - Training [61][  100/  196]   Loss 0.242573   Top1 91.558594   Top5 99.085938   BatchTime 0.372853   LR 0.000134   
2022-11-25 13:03:41,781 - INFO  - Training [61][  120/  196]   Loss 0.237701   Top1 91.725260   Top5 99.147135   BatchTime 0.373184   LR 0.000131   
2022-11-25 13:03:47,684 - INFO  - Training [61][  140/  196]   Loss 0.235177   Top1 91.788504   Top5 99.199219   BatchTime 0.362035   LR 0.000128   
2022-11-25 13:03:53,858 - INFO  - Training [61][  160/  196]   Loss 0.239403   Top1 91.630859   Top5 99.182129   BatchTime 0.355367   LR 0.000125   
2022-11-25 13:04:00,696 - INFO  - Training [61][  180/  196]   Loss 0.239621   Top1 91.657986   Top5 99.147135   BatchTime 0.353871   LR 0.000122   
2022-11-25 13:04:06,488 - INFO  - ==> Top1: 91.638    Top5: 99.148    Loss: 0.239

2022-11-25 13:04:06,729 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:04:08,213 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:04:10,867 - INFO  - Validation [61][   20/   40]   Loss 0.303480   Top1 91.523438   Top5 99.667969   BatchTime 0.132623   
2022-11-25 13:04:11,949 - INFO  - Validation [61][   40/   40]   Loss 0.287205   Top1 91.830000   Top5 99.750000   BatchTime 0.093352   
2022-11-25 13:04:12,191 - INFO  - ==> Top1: 91.830    Top5: 99.750    Loss: 0.287

2022-11-25 13:04:12,191 - INFO  - ==> Sparsity : 0.669

2022-11-25 13:04:12,192 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:04:12,192 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:04:12,192 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 13:04:12,318 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:04:12,320 - INFO  - >>>>>> Epoch  62
2022-11-25 13:04:12,322 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:04:20,941 - INFO  - Training [62][   20/  196]   Loss 0.260496   Top1 91.113281   Top5 98.730469   BatchTime 0.430856   LR 0.000117   
2022-11-25 13:04:28,038 - INFO  - Training [62][   40/  196]   Loss 0.260874   Top1 91.015625   Top5 98.857422   BatchTime 0.392844   LR 0.000114   
2022-11-25 13:04:35,439 - INFO  - Training [62][   60/  196]   Loss 0.252986   Top1 91.236979   Top5 98.977865   BatchTime 0.385246   LR 0.000111   
2022-11-25 13:04:42,278 - INFO  - Training [62][   80/  196]   Loss 0.250301   Top1 91.298828   Top5 99.077148   BatchTime 0.374424   LR 0.000108   
2022-11-25 13:04:49,159 - INFO  - Training [62][  100/  196]   Loss 0.237443   Top1 91.703125   Top5 99.183594   BatchTime 0.368343   LR 0.000105   
2022-11-25 13:04:56,102 - INFO  - Training [62][  120/  196]   Loss 0.233810   Top1 91.845703   Top5 99.225260   BatchTime 0.364815   LR 0.000102   
2022-11-25 13:05:02,974 - INFO  - Training [62][  140/  196]   Loss 0.231036   Top1 91.925223   Top5 99.274554   BatchTime 0.361778   LR 0.000100   
2022-11-25 13:05:08,432 - INFO  - Training [62][  160/  196]   Loss 0.236072   Top1 91.796875   Top5 99.226074   BatchTime 0.350667   LR 0.000097   
2022-11-25 13:05:14,762 - INFO  - Training [62][  180/  196]   Loss 0.235027   Top1 91.809896   Top5 99.229601   BatchTime 0.346874   LR 0.000094   
2022-11-25 13:05:20,928 - INFO  - ==> Top1: 91.834    Top5: 99.226    Loss: 0.234

2022-11-25 13:05:21,174 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:05:22,770 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:05:25,494 - INFO  - Validation [62][   20/   40]   Loss 0.339931   Top1 90.429688   Top5 99.609375   BatchTime 0.136106   
2022-11-25 13:05:26,539 - INFO  - Validation [62][   40/   40]   Loss 0.323783   Top1 90.670000   Top5 99.690000   BatchTime 0.094181   
2022-11-25 13:05:26,818 - INFO  - ==> Top1: 90.670    Top5: 99.690    Loss: 0.324

2022-11-25 13:05:26,818 - INFO  - ==> Sparsity : 0.669

2022-11-25 13:05:26,818 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:05:26,818 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:05:26,819 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 13:05:26,962 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:05:26,964 - INFO  - >>>>>> Epoch  63
2022-11-25 13:05:26,965 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:05:35,459 - INFO  - Training [63][   20/  196]   Loss 0.247931   Top1 91.289062   Top5 98.457031   BatchTime 0.424539   LR 0.000090   
2022-11-25 13:05:42,307 - INFO  - Training [63][   40/  196]   Loss 0.255770   Top1 90.927734   Top5 98.750000   BatchTime 0.383474   LR 0.000087   
2022-11-25 13:05:49,673 - INFO  - Training [63][   60/  196]   Loss 0.249715   Top1 91.236979   Top5 98.860677   BatchTime 0.378421   LR 0.000085   
2022-11-25 13:05:57,240 - INFO  - Training [63][   80/  196]   Loss 0.249378   Top1 91.235352   Top5 99.018555   BatchTime 0.378400   LR 0.000082   
2022-11-25 13:06:04,760 - INFO  - Training [63][  100/  196]   Loss 0.240889   Top1 91.542969   Top5 99.121094   BatchTime 0.377923   LR 0.000080   
2022-11-25 13:06:12,285 - INFO  - Training [63][  120/  196]   Loss 0.233979   Top1 91.845703   Top5 99.205729   BatchTime 0.377638   LR 0.000077   
2022-11-25 13:06:19,407 - INFO  - Training [63][  140/  196]   Loss 0.233070   Top1 91.883371   Top5 99.260603   BatchTime 0.374561   LR 0.000075   
2022-11-25 13:06:25,538 - INFO  - Training [63][  160/  196]   Loss 0.236651   Top1 91.784668   Top5 99.235840   BatchTime 0.366063   LR 0.000072   
2022-11-25 13:06:32,849 - INFO  - Training [63][  180/  196]   Loss 0.236347   Top1 91.759983   Top5 99.194878   BatchTime 0.366002   LR 0.000070   
2022-11-25 13:06:38,475 - INFO  - ==> Top1: 91.820    Top5: 99.204    Loss: 0.235

2022-11-25 13:06:38,757 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:06:40,219 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:06:42,823 - INFO  - Validation [63][   20/   40]   Loss 0.513863   Top1 85.957031   Top5 99.218750   BatchTime 0.130131   
2022-11-25 13:06:43,841 - INFO  - Validation [63][   40/   40]   Loss 0.499413   Top1 86.060000   Top5 99.400000   BatchTime 0.090515   
2022-11-25 13:06:44,120 - INFO  - ==> Top1: 86.060    Top5: 99.400    Loss: 0.499

2022-11-25 13:06:44,120 - INFO  - ==> Sparsity : 0.669

2022-11-25 13:06:44,120 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:06:44,121 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:06:44,121 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 13:06:44,257 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:06:44,258 - INFO  - >>>>>> Epoch  64
2022-11-25 13:06:44,260 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:06:53,018 - INFO  - Training [64][   20/  196]   Loss 0.252483   Top1 91.230469   Top5 98.750000   BatchTime 0.437787   LR 0.000066   
2022-11-25 13:07:00,084 - INFO  - Training [64][   40/  196]   Loss 0.245547   Top1 91.250000   Top5 98.857422   BatchTime 0.395535   LR 0.000064   
2022-11-25 13:07:07,587 - INFO  - Training [64][   60/  196]   Loss 0.240662   Top1 91.477865   Top5 98.997396   BatchTime 0.388732   LR 0.000062   
2022-11-25 13:07:14,917 - INFO  - Training [64][   80/  196]   Loss 0.238690   Top1 91.601562   Top5 99.125977   BatchTime 0.383180   LR 0.000059   
2022-11-25 13:07:21,814 - INFO  - Training [64][  100/  196]   Loss 0.233474   Top1 91.796875   Top5 99.195312   BatchTime 0.375513   LR 0.000057   
2022-11-25 13:07:28,791 - INFO  - Training [64][  120/  196]   Loss 0.229625   Top1 91.995443   Top5 99.228516   BatchTime 0.371063   LR 0.000055   
2022-11-25 13:07:34,437 - INFO  - Training [64][  140/  196]   Loss 0.228225   Top1 92.061942   Top5 99.282924   BatchTime 0.358384   LR 0.000053   
2022-11-25 13:07:40,322 - INFO  - Training [64][  160/  196]   Loss 0.231135   Top1 91.953125   Top5 99.262695   BatchTime 0.350367   LR 0.000051   
2022-11-25 13:07:47,894 - INFO  - Training [64][  180/  196]   Loss 0.231454   Top1 91.888021   Top5 99.270833   BatchTime 0.353501   LR 0.000049   
2022-11-25 13:07:53,892 - INFO  - ==> Top1: 91.904    Top5: 99.260    Loss: 0.231

2022-11-25 13:07:54,178 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:07:55,851 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:07:58,452 - INFO  - Validation [64][   20/   40]   Loss 0.501992   Top1 85.742188   Top5 99.218750   BatchTime 0.129964   
2022-11-25 13:07:59,510 - INFO  - Validation [64][   40/   40]   Loss 0.488853   Top1 86.070000   Top5 99.320000   BatchTime 0.091434   
2022-11-25 13:07:59,807 - INFO  - ==> Top1: 86.070    Top5: 99.320    Loss: 0.489

2022-11-25 13:07:59,807 - INFO  - ==> Sparsity : 0.669

2022-11-25 13:07:59,807 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:07:59,807 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:07:59,808 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 13:07:59,927 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:07:59,928 - INFO  - >>>>>> Epoch  65
2022-11-25 13:07:59,930 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:08:09,004 - INFO  - Training [65][   20/  196]   Loss 0.258006   Top1 90.781250   Top5 98.652344   BatchTime 0.453549   LR 0.000046   
2022-11-25 13:08:16,500 - INFO  - Training [65][   40/  196]   Loss 0.250997   Top1 91.289062   Top5 98.769531   BatchTime 0.414196   LR 0.000044   
2022-11-25 13:08:23,645 - INFO  - Training [65][   60/  196]   Loss 0.244624   Top1 91.510417   Top5 98.821615   BatchTime 0.395213   LR 0.000042   
2022-11-25 13:08:31,233 - INFO  - Training [65][   80/  196]   Loss 0.243367   Top1 91.523438   Top5 98.979492   BatchTime 0.391253   LR 0.000040   
2022-11-25 13:08:38,722 - INFO  - Training [65][  100/  196]   Loss 0.237108   Top1 91.738281   Top5 99.089844   BatchTime 0.387891   LR 0.000039   
2022-11-25 13:08:45,251 - INFO  - Training [65][  120/  196]   Loss 0.231742   Top1 91.940104   Top5 99.124349   BatchTime 0.377651   LR 0.000037   
2022-11-25 13:08:51,028 - INFO  - Training [65][  140/  196]   Loss 0.231728   Top1 91.981027   Top5 99.171317   BatchTime 0.364962   LR 0.000035   
2022-11-25 13:08:57,240 - INFO  - Training [65][  160/  196]   Loss 0.233100   Top1 91.887207   Top5 99.177246   BatchTime 0.358168   LR 0.000033   
2022-11-25 13:09:04,590 - INFO  - Training [65][  180/  196]   Loss 0.232377   Top1 91.888021   Top5 99.153646   BatchTime 0.359207   LR 0.000032   
2022-11-25 13:09:10,307 - INFO  - ==> Top1: 91.904    Top5: 99.142    Loss: 0.232

2022-11-25 13:09:10,521 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:09:11,804 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:09:14,514 - INFO  - Validation [65][   20/   40]   Loss 0.295948   Top1 91.347656   Top5 99.687500   BatchTime 0.135462   
2022-11-25 13:09:15,640 - INFO  - Validation [65][   40/   40]   Loss 0.278338   Top1 91.700000   Top5 99.730000   BatchTime 0.095866   
2022-11-25 13:09:15,938 - INFO  - ==> Top1: 91.700    Top5: 99.730    Loss: 0.278

2022-11-25 13:09:15,938 - INFO  - ==> Sparsity : 0.669

2022-11-25 13:09:15,939 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:09:15,939 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:09:15,939 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 13:09:16,104 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:09:16,106 - INFO  - >>>>>> Epoch  66
2022-11-25 13:09:16,108 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:09:24,755 - INFO  - Training [66][   20/  196]   Loss 0.250944   Top1 91.289062   Top5 98.574219   BatchTime 0.432207   LR 0.000029   
2022-11-25 13:09:32,085 - INFO  - Training [66][   40/  196]   Loss 0.247593   Top1 91.445312   Top5 98.720703   BatchTime 0.399353   LR 0.000028   
2022-11-25 13:09:39,140 - INFO  - Training [66][   60/  196]   Loss 0.244078   Top1 91.497396   Top5 98.899740   BatchTime 0.383832   LR 0.000026   
2022-11-25 13:09:46,030 - INFO  - Training [66][   80/  196]   Loss 0.239468   Top1 91.591797   Top5 99.067383   BatchTime 0.373993   LR 0.000025   
2022-11-25 13:09:52,870 - INFO  - Training [66][  100/  196]   Loss 0.234511   Top1 91.761719   Top5 99.128906   BatchTime 0.367595   LR 0.000023   
2022-11-25 13:09:59,918 - INFO  - Training [66][  120/  196]   Loss 0.229632   Top1 91.962891   Top5 99.192708   BatchTime 0.365063   LR 0.000022   
2022-11-25 13:10:05,731 - INFO  - Training [66][  140/  196]   Loss 0.229123   Top1 92.022879   Top5 99.227121   BatchTime 0.354430   LR 0.000021   
2022-11-25 13:10:12,411 - INFO  - Training [66][  160/  196]   Loss 0.231767   Top1 91.940918   Top5 99.216309   BatchTime 0.351872   LR 0.000019   
2022-11-25 13:10:19,653 - INFO  - Training [66][  180/  196]   Loss 0.233092   Top1 91.866319   Top5 99.190538   BatchTime 0.353011   LR 0.000018   
2022-11-25 13:10:25,057 - INFO  - ==> Top1: 91.882    Top5: 99.200    Loss: 0.232

2022-11-25 13:10:25,324 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:10:26,779 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:10:29,449 - INFO  - Validation [66][   20/   40]   Loss 0.312266   Top1 91.171875   Top5 99.609375   BatchTime 0.133435   
2022-11-25 13:10:30,532 - INFO  - Validation [66][   40/   40]   Loss 0.290786   Top1 91.500000   Top5 99.700000   BatchTime 0.093792   
2022-11-25 13:10:30,860 - INFO  - ==> Top1: 91.500    Top5: 99.700    Loss: 0.291

2022-11-25 13:10:30,860 - INFO  - ==> Sparsity : 0.668

2022-11-25 13:10:30,860 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:10:30,861 - INFO  - Scoreboard best 2 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:10:30,861 - INFO  - Scoreboard best 3 ==> Epoch [56][Top1: 91.940   Top5: 99.740]
2022-11-25 13:10:31,019 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:10:31,021 - INFO  - >>>>>> Epoch  67
2022-11-25 13:10:31,023 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:10:39,580 - INFO  - Training [67][   20/  196]   Loss 0.259147   Top1 90.605469   Top5 98.808594   BatchTime 0.427677   LR 0.000016   
2022-11-25 13:10:46,856 - INFO  - Training [67][   40/  196]   Loss 0.257780   Top1 90.615234   Top5 98.916016   BatchTime 0.395746   LR 0.000015   
2022-11-25 13:10:54,186 - INFO  - Training [67][   60/  196]   Loss 0.246431   Top1 91.171875   Top5 99.036458   BatchTime 0.386007   LR 0.000014   
2022-11-25 13:11:00,985 - INFO  - Training [67][   80/  196]   Loss 0.244631   Top1 91.274414   Top5 99.140625   BatchTime 0.374486   LR 0.000013   
2022-11-25 13:11:07,808 - INFO  - Training [67][  100/  196]   Loss 0.237598   Top1 91.546875   Top5 99.179688   BatchTime 0.367821   LR 0.000012   
2022-11-25 13:11:13,734 - INFO  - Training [67][  120/  196]   Loss 0.231324   Top1 91.839193   Top5 99.225260   BatchTime 0.355898   LR 0.000011   
2022-11-25 13:11:19,104 - INFO  - Training [67][  140/  196]   Loss 0.229003   Top1 91.955915   Top5 99.241071   BatchTime 0.343409   LR 0.000010   
2022-11-25 13:11:26,232 - INFO  - Training [67][  160/  196]   Loss 0.230521   Top1 91.877441   Top5 99.221191   BatchTime 0.345035   LR 0.000009   
2022-11-25 13:11:33,502 - INFO  - Training [67][  180/  196]   Loss 0.231217   Top1 91.853299   Top5 99.166667   BatchTime 0.347087   LR 0.000008   
2022-11-25 13:11:39,296 - INFO  - ==> Top1: 91.868    Top5: 99.166    Loss: 0.231

2022-11-25 13:11:39,579 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:11:41,118 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:11:43,888 - INFO  - Validation [67][   20/   40]   Loss 0.289139   Top1 91.757812   Top5 99.667969   BatchTime 0.138410   
2022-11-25 13:11:44,986 - INFO  - Validation [67][   40/   40]   Loss 0.271291   Top1 92.000000   Top5 99.710000   BatchTime 0.096646   
2022-11-25 13:11:45,224 - INFO  - ==> Top1: 92.000    Top5: 99.710    Loss: 0.271

2022-11-25 13:11:45,225 - INFO  - ==> Sparsity : 0.669

2022-11-25 13:11:45,225 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:11:45,225 - INFO  - Scoreboard best 2 ==> Epoch [67][Top1: 92.000   Top5: 99.710]
2022-11-25 13:11:45,225 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:11:45,347 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:11:45,349 - INFO  - >>>>>> Epoch  68
2022-11-25 13:11:45,351 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:11:54,165 - INFO  - Training [68][   20/  196]   Loss 0.238842   Top1 91.132812   Top5 98.867188   BatchTime 0.440554   LR 0.000007   
2022-11-25 13:12:01,008 - INFO  - Training [68][   40/  196]   Loss 0.245905   Top1 91.230469   Top5 99.003906   BatchTime 0.391364   LR 0.000006   
2022-11-25 13:12:07,657 - INFO  - Training [68][   60/  196]   Loss 0.237922   Top1 91.542969   Top5 99.055990   BatchTime 0.371724   LR 0.000006   
2022-11-25 13:12:14,445 - INFO  - Training [68][   80/  196]   Loss 0.237989   Top1 91.547852   Top5 99.150391   BatchTime 0.363647   LR 0.000005   
2022-11-25 13:12:21,111 - INFO  - Training [68][  100/  196]   Loss 0.232560   Top1 91.757812   Top5 99.167969   BatchTime 0.357577   LR 0.000004   
2022-11-25 13:12:27,383 - INFO  - Training [68][  120/  196]   Loss 0.229232   Top1 91.897786   Top5 99.208984   BatchTime 0.350246   LR 0.000004   
2022-11-25 13:12:33,508 - INFO  - Training [68][  140/  196]   Loss 0.227792   Top1 92.003348   Top5 99.263393   BatchTime 0.343960   LR 0.000003   
2022-11-25 13:12:40,537 - INFO  - Training [68][  160/  196]   Loss 0.229230   Top1 91.914062   Top5 99.250488   BatchTime 0.344894   LR 0.000003   
2022-11-25 13:12:48,680 - INFO  - Training [68][  180/  196]   Loss 0.229727   Top1 91.946615   Top5 99.203559   BatchTime 0.351814   LR 0.000002   
2022-11-25 13:12:54,396 - INFO  - ==> Top1: 91.972    Top5: 99.202    Loss: 0.229

2022-11-25 13:12:54,657 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:12:56,229 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:12:59,057 - INFO  - Validation [68][   20/   40]   Loss 0.382885   Top1 88.808594   Top5 99.550781   BatchTime 0.141328   
2022-11-25 13:13:00,202 - INFO  - Validation [68][   40/   40]   Loss 0.368296   Top1 89.200000   Top5 99.590000   BatchTime 0.099274   
2022-11-25 13:13:00,538 - INFO  - ==> Top1: 89.200    Top5: 99.590    Loss: 0.368

2022-11-25 13:13:00,538 - INFO  - ==> Sparsity : 0.668

2022-11-25 13:13:00,538 - INFO  - Scoreboard best 1 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:13:00,539 - INFO  - Scoreboard best 2 ==> Epoch [67][Top1: 92.000   Top5: 99.710]
2022-11-25 13:13:00,539 - INFO  - Scoreboard best 3 ==> Epoch [54][Top1: 91.960   Top5: 99.740]
2022-11-25 13:13:00,677 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar

2022-11-25 13:13:00,679 - INFO  - >>>>>> Epoch  69
2022-11-25 13:13:00,681 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 13:13:09,997 - INFO  - Training [69][   20/  196]   Loss 0.248196   Top1 91.035156   Top5 98.417969   BatchTime 0.465655   LR 0.000002   
2022-11-25 13:13:17,032 - INFO  - Training [69][   40/  196]   Loss 0.255638   Top1 91.035156   Top5 98.662109   BatchTime 0.408695   LR 0.000001   
2022-11-25 13:13:23,941 - INFO  - Training [69][   60/  196]   Loss 0.245286   Top1 91.354167   Top5 98.795573   BatchTime 0.387616   LR 0.000001   
2022-11-25 13:13:30,772 - INFO  - Training [69][   80/  196]   Loss 0.242016   Top1 91.435547   Top5 98.979492   BatchTime 0.376102   LR 0.000001   
2022-11-25 13:13:37,828 - INFO  - Training [69][  100/  196]   Loss 0.235829   Top1 91.695312   Top5 99.039062   BatchTime 0.371436   LR 0.000000   
2022-11-25 13:13:44,084 - INFO  - Training [69][  120/  196]   Loss 0.228398   Top1 92.018229   Top5 99.104818   BatchTime 0.361661   LR 0.000000   
2022-11-25 13:13:50,144 - INFO  - Training [69][  140/  196]   Loss 0.226587   Top1 92.109375   Top5 99.162946   BatchTime 0.353286   LR 0.000000   
2022-11-25 13:13:57,574 - INFO  - Training [69][  160/  196]   Loss 0.227910   Top1 92.026367   Top5 99.174805   BatchTime 0.355562   LR 0.000000   
2022-11-25 13:14:04,476 - INFO  - Training [69][  180/  196]   Loss 0.228493   Top1 92.007378   Top5 99.164497   BatchTime 0.354400   LR 0.000000   
2022-11-25 13:14:10,214 - INFO  - ==> Top1: 92.048    Top5: 99.176    Loss: 0.227

2022-11-25 13:14:10,505 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 13:14:12,043 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:14:14,870 - INFO  - Validation [69][   20/   40]   Loss 0.292446   Top1 91.855469   Top5 99.609375   BatchTime 0.141142   
2022-11-25 13:14:15,962 - INFO  - Validation [69][   40/   40]   Loss 0.274526   Top1 92.070000   Top5 99.690000   BatchTime 0.097908   
2022-11-25 13:14:16,307 - INFO  - ==> Top1: 92.070    Top5: 99.690    Loss: 0.275

2022-11-25 13:14:16,307 - INFO  - ==> Sparsity : 0.669

2022-11-25 13:14:16,308 - INFO  - Scoreboard best 1 ==> Epoch [69][Top1: 92.070   Top5: 99.690]
2022-11-25 13:14:16,308 - INFO  - Scoreboard best 2 ==> Epoch [55][Top1: 92.030   Top5: 99.780]
2022-11-25 13:14:16,308 - INFO  - Scoreboard best 3 ==> Epoch [67][Top1: 92.000   Top5: 99.710]
2022-11-25 13:14:23,095 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-101258/88hard_pruning_best.pth.tar
save quantized models...
2022-11-25 13:14:23,102 - INFO  - >>>>>> Epoch -1 (final model evaluation)
2022-11-25 13:14:23,102 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 13:14:25,829 - INFO  - Validation [   20/   40]   Loss 0.292446   Top1 91.855469   Top5 99.609375   BatchTime 0.136250   
2022-11-25 13:14:26,902 - INFO  - Validation [   40/   40]   Loss 0.274526   Top1 92.070000   Top5 99.690000   BatchTime 0.094945   
2022-11-25 13:14:27,109 - INFO  - ==> Top1: 92.070    Top5: 99.690    Loss: 0.275

2022-11-25 13:14:27,110 - INFO  - ==> Sparsity : 0.000

2022-11-25 13:14:27,110 - INFO  - Program completed sucessfully ... exiting ...
