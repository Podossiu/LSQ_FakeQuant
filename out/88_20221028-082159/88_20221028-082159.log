2022-10-28 08:21:59,697 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-082159/88_20221028-082159.log
2022-10-28 08:22:01,435 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 08:22:01,470 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-28 08:22:01,635 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 08:22:01,635 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 08:22:02,903 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 08:22:02,903 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:22:05,960 - INFO  - Validation [   20/   40]   Loss 3047.717822   Top1 12.753906   Top5 57.070312   BatchTime 0.152859   
2022-10-28 08:22:07,461 - INFO  - Validation [   40/   40]   Loss 3031.409704   Top1 12.670000   Top5 56.460000   BatchTime 0.113946   
2022-10-28 08:22:07,531 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-28 08:22:07,531 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 08:22:07,531 - INFO  - >>>>>> Epoch   0
2022-10-28 08:22:07,531 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 08:22:09,824 - INFO  - Training [0][   20/  196]   Loss 1.084329   Top1 70.351562   Top5 97.578125   BatchTime 0.114608   LR 0.001000   
2022-10-28 08:22:11,524 - INFO  - Training [0][   40/  196]   Loss 0.871283   Top1 75.390625   Top5 98.056641   BatchTime 0.099806   LR 0.001000   
2022-10-28 08:22:13,226 - INFO  - Training [0][   60/  196]   Loss 0.741334   Top1 78.430990   Top5 98.541667   BatchTime 0.094901   LR 0.001000   
2022-10-28 08:22:14,929 - INFO  - Training [0][   80/  196]   Loss 0.660291   Top1 80.341797   Top5 98.818359   BatchTime 0.092463   LR 0.001000   
2022-10-28 08:22:16,633 - INFO  - Training [0][  100/  196]   Loss 0.606852   Top1 81.675781   Top5 98.910156   BatchTime 0.091008   LR 0.001000   
2022-10-28 08:22:18,343 - INFO  - Training [0][  120/  196]   Loss 0.569159   Top1 82.721354   Top5 98.971354   BatchTime 0.090088   LR 0.001000   
2022-10-28 08:22:20,046 - INFO  - Training [0][  140/  196]   Loss 0.538686   Top1 83.412388   Top5 99.065290   BatchTime 0.089386   LR 0.001000   
2022-10-28 08:22:21,749 - INFO  - Training [0][  160/  196]   Loss 0.515199   Top1 83.950195   Top5 99.140625   BatchTime 0.088855   LR 0.001000   
2022-10-28 08:22:23,435 - INFO  - Training [0][  180/  196]   Loss 0.493393   Top1 84.513889   Top5 99.186198   BatchTime 0.088349   LR 0.001000   
2022-10-28 08:22:24,835 - INFO  - ==> Top1: 84.918    Top5: 99.220    Loss: 0.479

2022-10-28 08:22:24,950 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:22:26,592 - INFO  - Validation [0][   20/   40]   Loss 0.423712   Top1 86.894531   Top5 99.355469   BatchTime 0.082062   
2022-10-28 08:22:27,674 - INFO  - Validation [0][   40/   40]   Loss 0.414504   Top1 86.940000   Top5 99.430000   BatchTime 0.068097   
2022-10-28 08:22:27,754 - INFO  - ==> Top1: 86.940    Top5: 99.430    Loss: 0.415

2022-10-28 08:22:27,755 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:22:29,455 - INFO  - Validation [0][   20/   40]   Loss 2.466454   Top1 12.695312   Top5 49.628906   BatchTime 0.085020   
2022-10-28 08:22:30,401 - INFO  - Validation [0][   40/   40]   Loss 2.464620   Top1 12.610000   Top5 50.000000   BatchTime 0.066146   
2022-10-28 08:22:30,486 - INFO  - ==> Top1: 12.610    Top5: 50.000    Loss: 2.465

2022-10-28 08:22:30,486 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 08:22:30,486 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 12.610   Top5: 50.000]
2022-10-28 08:22:30,521 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221028-082159/88_checkpoint.pth.tar

2022-10-28 08:22:30,521 - INFO  - >>>>>> Epoch   1
2022-10-28 08:22:30,521 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 08:22:32,836 - INFO  - Training [1][   20/  196]   Loss 0.302312   Top1 89.648438   Top5 99.667969   BatchTime 0.115691   LR 0.001000   
2022-10-28 08:22:34,530 - INFO  - Training [1][   40/  196]   Loss 0.299872   Top1 89.521484   Top5 99.677734   BatchTime 0.100205   LR 0.001000   
2022-10-28 08:22:36,224 - INFO  - Training [1][   60/  196]   Loss 0.295551   Top1 89.628906   Top5 99.713542   BatchTime 0.095025   LR 0.001000   
2022-10-28 08:22:37,918 - INFO  - Training [1][   80/  196]   Loss 0.284762   Top1 90.039062   Top5 99.716797   BatchTime 0.092454   LR 0.001000   
