2022-10-28 08:38:42,445 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-083842/88_20221028-083842.log
2022-10-28 08:38:44,172 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 08:38:44,206 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-28 08:38:44,370 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 08:38:44,370 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 08:38:45,629 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 08:38:45,629 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:38:48,640 - INFO  - Validation [   20/   40]   Loss 3047.717822   Top1 12.753906   Top5 57.070312   BatchTime 0.150557   
2022-10-28 08:38:50,123 - INFO  - Validation [   40/   40]   Loss 3031.409704   Top1 12.670000   Top5 56.460000   BatchTime 0.112348   
2022-10-28 08:38:50,203 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-28 08:38:50,203 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 08:38:50,203 - INFO  - >>>>>> Epoch   0
2022-10-28 08:38:50,203 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 08:38:52,480 - INFO  - Training [0][   20/  196]   Loss 1.114732   Top1 70.800781   Top5 97.460938   BatchTime 0.113772   LR 0.001000   
2022-10-28 08:38:54,188 - INFO  - Training [0][   40/  196]   Loss 0.838338   Top1 76.445312   Top5 98.291016   BatchTime 0.099608   LR 0.001000   
2022-10-28 08:38:55,890 - INFO  - Training [0][   60/  196]   Loss 0.723671   Top1 79.010417   Top5 98.574219   BatchTime 0.094768   LR 0.001000   
2022-10-28 08:38:57,592 - INFO  - Training [0][   80/  196]   Loss 0.654608   Top1 80.610352   Top5 98.774414   BatchTime 0.092353   LR 0.001000   
2022-10-28 08:38:59,295 - INFO  - Training [0][  100/  196]   Loss 0.600565   Top1 81.960938   Top5 98.914062   BatchTime 0.090909   LR 0.001000   
2022-10-28 08:39:00,998 - INFO  - Training [0][  120/  196]   Loss 0.563210   Top1 82.926432   Top5 99.033203   BatchTime 0.089944   LR 0.001000   
2022-10-28 08:39:02,701 - INFO  - Training [0][  140/  196]   Loss 0.532963   Top1 83.646763   Top5 99.115513   BatchTime 0.089262   LR 0.001000   
2022-10-28 08:39:04,403 - INFO  - Training [0][  160/  196]   Loss 0.511604   Top1 84.196777   Top5 99.182129   BatchTime 0.088739   LR 0.001000   
2022-10-28 08:39:06,087 - INFO  - Training [0][  180/  196]   Loss 0.492672   Top1 84.683160   Top5 99.236111   BatchTime 0.088239   LR 0.001000   
2022-10-28 08:39:07,478 - INFO  - ==> Top1: 85.014    Top5: 99.266    Loss: 0.479

