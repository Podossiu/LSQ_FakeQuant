2022-11-25 10:35:00,383 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/88_20221125-103500.log
2022-11-25 10:35:04,731 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-25 10:35:06,878 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-25 10:35:07,724 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.005
               maximize: False
               weight_decay: 4e-05
           )
2022-11-25 10:35:07,725 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.005

2022-11-25 10:35:08,017 - INFO  - >>>>>> Epoch   0
2022-11-25 10:35:08,019 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:35:17,247 - INFO  - Training [0][   20/  196]   Loss 1.580746   Top1 53.750000   Top5 88.906250   BatchTime 0.461280   LR 0.004999   
2022-11-25 10:35:25,450 - INFO  - Training [0][   40/  196]   Loss 1.496292   Top1 52.783203   Top5 89.541016   BatchTime 0.435704   LR 0.004995   
2022-11-25 10:35:33,746 - INFO  - Training [0][   60/  196]   Loss 1.397735   Top1 55.123698   Top5 90.703125   BatchTime 0.428738   LR 0.004989   
2022-11-25 10:35:42,234 - INFO  - Training [0][   80/  196]   Loss 1.336352   Top1 56.752930   Top5 91.464844   BatchTime 0.427656   LR 0.004980   
2022-11-25 10:35:50,680 - INFO  - Training [0][  100/  196]   Loss 1.275738   Top1 58.519531   Top5 92.171875   BatchTime 0.426583   LR 0.004968   
2022-11-25 10:35:58,958 - INFO  - Training [0][  120/  196]   Loss 1.222449   Top1 60.185547   Top5 92.783203   BatchTime 0.424466   LR 0.004954   
2022-11-25 10:36:06,661 - INFO  - Training [0][  140/  196]   Loss 1.190312   Top1 61.163504   Top5 93.164062   BatchTime 0.418846   LR 0.004938   
2022-11-25 10:36:12,499 - INFO  - Training [0][  160/  196]   Loss 1.166264   Top1 61.916504   Top5 93.393555   BatchTime 0.402983   LR 0.004919   
2022-11-25 10:36:21,136 - INFO  - Training [0][  180/  196]   Loss 1.144198   Top1 62.465278   Top5 93.576389   BatchTime 0.406184   LR 0.004897   
2022-11-25 10:36:27,709 - INFO  - ==> Top1: 62.964    Top5: 93.760    Loss: 1.126

2022-11-25 10:36:27,977 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:36:29,379 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:36:31,555 - INFO  - Validation [0][   20/   40]   Loss 0.895440   Top1 70.957031   Top5 97.363281   BatchTime 0.108738   
2022-11-25 10:36:32,650 - INFO  - Validation [0][   40/   40]   Loss 0.906538   Top1 70.790000   Top5 97.130000   BatchTime 0.081746   
2022-11-25 10:36:32,859 - INFO  - ==> Top1: 70.790    Top5: 97.130    Loss: 0.907

2022-11-25 10:36:32,860 - INFO  - ==> Sparsity : 0.225

2022-11-25 10:36:32,860 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:36:37,806 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_best.pth.tar
save quantized models...
2022-11-25 10:36:37,809 - INFO  - >>>>>> Epoch   1
2022-11-25 10:36:37,811 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:36:46,220 - INFO  - Training [1][   20/  196]   Loss 0.946618   Top1 68.535156   Top5 95.253906   BatchTime 0.420315   LR 0.004853   
2022-11-25 10:36:53,492 - INFO  - Training [1][   40/  196]   Loss 0.953847   Top1 68.359375   Top5 95.478516   BatchTime 0.391935   LR 0.004825   
2022-11-25 10:37:00,779 - INFO  - Training [1][   60/  196]   Loss 0.943377   Top1 68.483073   Top5 95.598958   BatchTime 0.382746   LR 0.004794   
2022-11-25 10:37:08,198 - INFO  - Training [1][   80/  196]   Loss 0.927948   Top1 69.140625   Top5 95.732422   BatchTime 0.379801   LR 0.004761   
2022-11-25 10:37:15,307 - INFO  - Training [1][  100/  196]   Loss 0.908337   Top1 69.964844   Top5 95.863281   BatchTime 0.374928   LR 0.004725   
2022-11-25 10:37:22,327 - INFO  - Training [1][  120/  196]   Loss 0.899003   Top1 70.335286   Top5 96.083984   BatchTime 0.370942   LR 0.004687   
2022-11-25 10:37:28,316 - INFO  - Training [1][  140/  196]   Loss 0.890353   Top1 70.638951   Top5 96.202567   BatchTime 0.360727   LR 0.004647   
2022-11-25 10:37:35,534 - INFO  - Training [1][  160/  196]   Loss 0.884566   Top1 70.859375   Top5 96.230469   BatchTime 0.360747   LR 0.004605   
2022-11-25 10:37:43,179 - INFO  - Training [1][  180/  196]   Loss 0.872594   Top1 71.276042   Top5 96.250000   BatchTime 0.363136   LR 0.004560   
2022-11-25 10:37:49,166 - INFO  - ==> Top1: 71.470    Top5: 96.278    Loss: 0.867

2022-11-25 10:37:49,432 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:37:50,905 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:37:53,290 - INFO  - Validation [1][   20/   40]   Loss 0.754639   Top1 75.839844   Top5 97.753906   BatchTime 0.119162   
2022-11-25 10:37:54,386 - INFO  - Validation [1][   40/   40]   Loss 0.738611   Top1 76.020000   Top5 97.780000   BatchTime 0.086981   
2022-11-25 10:37:54,576 - INFO  - ==> Top1: 76.020    Top5: 97.780    Loss: 0.739

2022-11-25 10:37:54,576 - INFO  - ==> Sparsity : 0.286

2022-11-25 10:37:54,576 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:37:54,577 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:37:59,703 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_best.pth.tar
save quantized models...
2022-11-25 10:37:59,706 - INFO  - >>>>>> Epoch   2
2022-11-25 10:37:59,708 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:38:08,244 - INFO  - Training [2][   20/  196]   Loss 0.832800   Top1 72.089844   Top5 95.664062   BatchTime 0.426646   LR 0.004477   
2022-11-25 10:38:15,658 - INFO  - Training [2][   40/  196]   Loss 1.570073   Top1 45.703125   Top5 78.193359   BatchTime 0.398688   LR 0.004426   
2022-11-25 10:38:22,275 - INFO  - Training [2][   60/  196]   Loss 1.832511   Top1 33.645833   Top5 68.906250   BatchTime 0.376073   LR 0.004374   
2022-11-25 10:38:27,966 - INFO  - Training [2][   80/  196]   Loss 1.960379   Top1 27.607422   Top5 64.360352   BatchTime 0.353196   LR 0.004320   
2022-11-25 10:38:33,342 - INFO  - Training [2][  100/  196]   Loss 2.036684   Top1 24.125000   Top5 61.625000   BatchTime 0.336310   LR 0.004264   
2022-11-25 10:38:38,756 - INFO  - Training [2][  120/  196]   Loss 2.087516   Top1 21.725260   Top5 59.667969   BatchTime 0.325371   LR 0.004206   
2022-11-25 10:38:44,355 - INFO  - Training [2][  140/  196]   Loss 2.123092   Top1 20.011161   Top5 58.317522   BatchTime 0.318882   LR 0.004146   
2022-11-25 10:38:49,748 - INFO  - Training [2][  160/  196]   Loss 2.149865   Top1 18.747559   Top5 57.438965   BatchTime 0.312727   LR 0.004085   
2022-11-25 10:38:55,753 - INFO  - Training [2][  180/  196]   Loss 2.170433   Top1 17.849392   Top5 56.733941   BatchTime 0.311342   LR 0.004022   
2022-11-25 10:39:02,024 - INFO  - ==> Top1: 17.166    Top5: 56.140    Loss: 2.184

2022-11-25 10:39:02,257 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:39:03,969 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:39:06,197 - INFO  - Validation [2][   20/   40]   Loss 2.389739   Top1 10.253906   Top5 50.078125   BatchTime 0.111322   
2022-11-25 10:39:07,153 - INFO  - Validation [2][   40/   40]   Loss 2.390388   Top1 10.000000   Top5 50.000000   BatchTime 0.079578   
2022-11-25 10:39:07,767 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.390

2022-11-25 10:39:07,768 - INFO  - ==> Sparsity : 0.315

2022-11-25 10:39:07,768 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:39:07,768 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:39:07,768 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 10.000   Top5: 50.000]
2022-11-25 10:39:07,904 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:39:07,906 - INFO  - >>>>>> Epoch   3
2022-11-25 10:39:07,908 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:39:16,203 - INFO  - Training [3][   20/  196]   Loss 2.336336   Top1 10.195312   Top5 51.250000   BatchTime 0.414635   LR 0.003907   
2022-11-25 10:39:23,648 - INFO  - Training [3][   40/  196]   Loss 2.334600   Top1 10.195312   Top5 50.830078   BatchTime 0.393432   LR 0.003840   
2022-11-25 10:39:31,004 - INFO  - Training [3][   60/  196]   Loss 2.335026   Top1 10.221354   Top5 50.631510   BatchTime 0.384885   LR 0.003771   
2022-11-25 10:39:38,287 - INFO  - Training [3][   80/  196]   Loss 2.334255   Top1 10.288086   Top5 50.751953   BatchTime 0.379699   LR 0.003701   
2022-11-25 10:39:45,555 - INFO  - Training [3][  100/  196]   Loss 2.333834   Top1 10.238281   Top5 50.617188   BatchTime 0.376444   LR 0.003630   
2022-11-25 10:39:52,930 - INFO  - Training [3][  120/  196]   Loss 2.334353   Top1 10.006510   Top5 50.442708   BatchTime 0.375161   LR 0.003558   
2022-11-25 10:40:00,244 - INFO  - Training [3][  140/  196]   Loss 2.333774   Top1 9.991629   Top5 50.432478   BatchTime 0.373805   LR 0.003484   
2022-11-25 10:40:07,429 - INFO  - Training [3][  160/  196]   Loss 2.333644   Top1 10.100098   Top5 50.397949   BatchTime 0.371988   LR 0.003410   
2022-11-25 10:40:14,070 - INFO  - Training [3][  180/  196]   Loss 2.333907   Top1 10.023872   Top5 50.221354   BatchTime 0.367547   LR 0.003335   
2022-11-25 10:40:19,263 - INFO  - ==> Top1: 10.074    Top5: 50.112    Loss: 2.334

2022-11-25 10:40:19,458 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:40:21,279 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:40:24,503 - INFO  - Validation [3][   20/   40]   Loss 2.335316   Top1 9.863281   Top5 50.078125   BatchTime 0.161088   
2022-11-25 10:40:25,577 - INFO  - Validation [3][   40/   40]   Loss 2.335024   Top1 10.000000   Top5 50.000000   BatchTime 0.107395   
2022-11-25 10:40:25,974 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.335

2022-11-25 10:40:25,975 - INFO  - ==> Sparsity : 0.260

2022-11-25 10:40:25,975 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:40:25,975 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:40:25,976 - INFO  - Scoreboard best 3 ==> Epoch [3][Top1: 10.000   Top5: 50.000]
2022-11-25 10:40:26,216 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:40:26,218 - INFO  - >>>>>> Epoch   4
2022-11-25 10:40:26,221 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:40:35,274 - INFO  - Training [4][   20/  196]   Loss 2.331820   Top1 10.039062   Top5 50.429688   BatchTime 0.452433   LR 0.003200   
2022-11-25 10:40:42,599 - INFO  - Training [4][   40/  196]   Loss 2.330997   Top1 10.078125   Top5 50.126953   BatchTime 0.409360   LR 0.003122   
2022-11-25 10:40:50,006 - INFO  - Training [4][   60/  196]   Loss 2.330936   Top1 10.026042   Top5 50.104167   BatchTime 0.396354   LR 0.003044   
2022-11-25 10:40:57,151 - INFO  - Training [4][   80/  196]   Loss 2.330542   Top1 10.078125   Top5 50.146484   BatchTime 0.386575   LR 0.002965   
2022-11-25 10:41:04,672 - INFO  - Training [4][  100/  196]   Loss 2.330757   Top1 9.992188   Top5 50.046875   BatchTime 0.384462   LR 0.002886   
2022-11-25 10:41:11,937 - INFO  - Training [4][  120/  196]   Loss 2.330412   Top1 10.065104   Top5 50.166016   BatchTime 0.380929   LR 0.002806   
2022-11-25 10:41:19,528 - INFO  - Training [4][  140/  196]   Loss 2.330398   Top1 9.997210   Top5 50.206473   BatchTime 0.380730   LR 0.002726   
2022-11-25 10:41:26,834 - INFO  - Training [4][  160/  196]   Loss 2.330355   Top1 10.053711   Top5 50.014648   BatchTime 0.378804   LR 0.002646   
2022-11-25 10:41:34,118 - INFO  - Training [4][  180/  196]   Loss 2.330298   Top1 10.054253   Top5 50.015191   BatchTime 0.377179   LR 0.002566   
2022-11-25 10:41:39,551 - INFO  - ==> Top1: 10.146    Top5: 49.976    Loss: 2.330

2022-11-25 10:41:39,743 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:41:41,958 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:41:44,699 - INFO  - Validation [4][   20/   40]   Loss 2.450002   Top1 10.078125   Top5 49.960938   BatchTime 0.136913   
2022-11-25 10:41:45,893 - INFO  - Validation [4][   40/   40]   Loss 2.451310   Top1 10.000000   Top5 50.000000   BatchTime 0.098309   
2022-11-25 10:41:46,105 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.451

2022-11-25 10:41:46,105 - INFO  - ==> Sparsity : 0.291

2022-11-25 10:41:46,105 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:41:46,106 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:41:46,106 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 10.000   Top5: 50.000]
2022-11-25 10:41:46,220 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:41:46,222 - INFO  - >>>>>> Epoch   5
2022-11-25 10:41:46,223 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:41:53,834 - INFO  - Training [5][   20/  196]   Loss 2.329710   Top1 9.414062   Top5 50.527344   BatchTime 0.380414   LR 0.002424   
2022-11-25 10:42:01,198 - INFO  - Training [5][   40/  196]   Loss 2.329541   Top1 9.453125   Top5 49.648438   BatchTime 0.374293   LR 0.002343   
2022-11-25 10:42:08,629 - INFO  - Training [5][   60/  196]   Loss 2.329656   Top1 9.583333   Top5 49.674479   BatchTime 0.373385   LR 0.002263   
2022-11-25 10:42:16,066 - INFO  - Training [5][   80/  196]   Loss 2.329465   Top1 9.643555   Top5 49.487305   BatchTime 0.372998   LR 0.002183   
2022-11-25 10:42:23,550 - INFO  - Training [5][  100/  196]   Loss 2.329218   Top1 9.675781   Top5 49.519531   BatchTime 0.373237   LR 0.002104   
2022-11-25 10:42:31,070 - INFO  - Training [5][  120/  196]   Loss 2.328998   Top1 9.847005   Top5 49.615885   BatchTime 0.373694   LR 0.002024   
2022-11-25 10:42:38,258 - INFO  - Training [5][  140/  196]   Loss 2.328809   Top1 9.729353   Top5 49.631696   BatchTime 0.371655   LR 0.001946   
2022-11-25 10:42:45,654 - INFO  - Training [5][  160/  196]   Loss 2.328715   Top1 9.770508   Top5 49.665527   BatchTime 0.371423   LR 0.001868   
2022-11-25 10:42:52,907 - INFO  - Training [5][  180/  196]   Loss 2.328701   Top1 9.817708   Top5 49.659288   BatchTime 0.370448   LR 0.001790   
2022-11-25 10:42:59,388 - INFO  - ==> Top1: 9.842    Top5: 49.576    Loss: 2.329

2022-11-25 10:42:59,629 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:43:01,639 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:43:03,980 - INFO  - Validation [5][   20/   40]   Loss 2.772228   Top1 10.078125   Top5 49.980469   BatchTime 0.116979   
2022-11-25 10:43:05,258 - INFO  - Validation [5][   40/   40]   Loss 2.775725   Top1 10.000000   Top5 50.000000   BatchTime 0.090433   
2022-11-25 10:43:05,488 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.776

2022-11-25 10:43:05,489 - INFO  - ==> Sparsity : 0.339

2022-11-25 10:43:05,489 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:43:05,489 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:43:05,489 - INFO  - Scoreboard best 3 ==> Epoch [5][Top1: 10.000   Top5: 50.000]
2022-11-25 10:43:05,640 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:43:05,642 - INFO  - >>>>>> Epoch   6
2022-11-25 10:43:05,644 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:43:13,960 - INFO  - Training [6][   20/  196]   Loss 2.327092   Top1 10.058594   Top5 50.742188   BatchTime 0.415639   LR 0.001655   
2022-11-25 10:43:20,583 - INFO  - Training [6][   40/  196]   Loss 2.327177   Top1 9.912109   Top5 50.341797   BatchTime 0.373394   LR 0.001580   
2022-11-25 10:43:28,244 - INFO  - Training [6][   60/  196]   Loss 2.327333   Top1 10.058594   Top5 49.921875   BatchTime 0.376625   LR 0.001506   
2022-11-25 10:43:35,432 - INFO  - Training [6][   80/  196]   Loss 2.327353   Top1 9.985352   Top5 50.053711   BatchTime 0.372314   LR 0.001432   
2022-11-25 10:43:42,801 - INFO  - Training [6][  100/  196]   Loss 2.327241   Top1 9.968750   Top5 50.031250   BatchTime 0.371537   LR 0.001360   
2022-11-25 10:43:50,217 - INFO  - Training [6][  120/  196]   Loss 2.327253   Top1 9.951172   Top5 49.918620   BatchTime 0.371417   LR 0.001289   
2022-11-25 10:43:57,565 - INFO  - Training [6][  140/  196]   Loss 2.327224   Top1 9.958147   Top5 49.963728   BatchTime 0.370838   LR 0.001220   
2022-11-25 10:44:04,879 - INFO  - Training [6][  160/  196]   Loss 2.327277   Top1 9.926758   Top5 49.904785   BatchTime 0.370199   LR 0.001151   
2022-11-25 10:44:12,224 - INFO  - Training [6][  180/  196]   Loss 2.327204   Top1 9.976128   Top5 49.989149   BatchTime 0.369868   LR 0.001084   
2022-11-25 10:44:18,165 - INFO  - ==> Top1: 9.964    Top5: 49.906    Loss: 2.327

2022-11-25 10:44:18,403 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:44:19,812 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:44:22,071 - INFO  - Validation [6][   20/   40]   Loss 2.457179   Top1 10.078125   Top5 49.960938   BatchTime 0.112824   
2022-11-25 10:44:23,153 - INFO  - Validation [6][   40/   40]   Loss 2.458518   Top1 10.000000   Top5 50.000000   BatchTime 0.083485   
2022-11-25 10:44:23,404 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.459

2022-11-25 10:44:23,405 - INFO  - ==> Sparsity : 0.419

2022-11-25 10:44:23,405 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:44:23,406 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:44:23,406 - INFO  - Scoreboard best 3 ==> Epoch [6][Top1: 10.000   Top5: 50.000]
2022-11-25 10:44:23,552 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:44:23,554 - INFO  - >>>>>> Epoch   7
2022-11-25 10:44:23,556 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:44:31,481 - INFO  - Training [7][   20/  196]   Loss 2.325562   Top1 10.136719   Top5 51.171875   BatchTime 0.396117   LR 0.000969   
2022-11-25 10:44:37,416 - INFO  - Training [7][   40/  196]   Loss 2.326406   Top1 9.638672   Top5 50.078125   BatchTime 0.346433   LR 0.000907   
2022-11-25 10:44:44,044 - INFO  - Training [7][   60/  196]   Loss 2.326418   Top1 9.687500   Top5 50.136719   BatchTime 0.341416   LR 0.000845   
2022-11-25 10:44:51,248 - INFO  - Training [7][   80/  196]   Loss 2.326537   Top1 9.638672   Top5 49.907227   BatchTime 0.346111   LR 0.000786   
2022-11-25 10:44:58,706 - INFO  - Training [7][  100/  196]   Loss 2.326726   Top1 9.570312   Top5 49.628906   BatchTime 0.351465   LR 0.000728   
2022-11-25 10:45:06,211 - INFO  - Training [7][  120/  196]   Loss 2.326489   Top1 9.739583   Top5 49.609375   BatchTime 0.355432   LR 0.000673   
2022-11-25 10:45:13,568 - INFO  - Training [7][  140/  196]   Loss 2.326233   Top1 9.726562   Top5 49.966518   BatchTime 0.357201   LR 0.000619   
2022-11-25 10:45:20,778 - INFO  - Training [7][  160/  196]   Loss 2.326057   Top1 9.758301   Top5 50.146484   BatchTime 0.357614   LR 0.000567   
2022-11-25 10:45:27,739 - INFO  - Training [7][  180/  196]   Loss 2.325981   Top1 9.780816   Top5 50.026042   BatchTime 0.356553   LR 0.000517   
2022-11-25 10:45:33,765 - INFO  - ==> Top1: 9.824    Top5: 50.064    Loss: 2.326

2022-11-25 10:45:34,066 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:45:35,785 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:45:38,394 - INFO  - Validation [7][   20/   40]   Loss 2.393330   Top1 10.078125   Top5 49.804688   BatchTime 0.130345   
2022-11-25 10:45:39,375 - INFO  - Validation [7][   40/   40]   Loss 2.394332   Top1 10.000000   Top5 50.000000   BatchTime 0.089715   
2022-11-25 10:45:39,572 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.394

2022-11-25 10:45:39,572 - INFO  - ==> Sparsity : 0.494

2022-11-25 10:45:39,573 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:45:39,573 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:45:39,573 - INFO  - Scoreboard best 3 ==> Epoch [7][Top1: 10.000   Top5: 50.000]
2022-11-25 10:45:39,693 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:45:39,694 - INFO  - >>>>>> Epoch   8
2022-11-25 10:45:39,696 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:45:47,918 - INFO  - Training [8][   20/  196]   Loss 2.324335   Top1 9.882812   Top5 50.156250   BatchTime 0.410975   LR 0.000434   
2022-11-25 10:45:54,508 - INFO  - Training [8][   40/  196]   Loss 2.323811   Top1 10.029297   Top5 50.058594   BatchTime 0.370244   LR 0.000389   
2022-11-25 10:46:01,116 - INFO  - Training [8][   60/  196]   Loss 2.323574   Top1 9.980469   Top5 50.312500   BatchTime 0.356956   LR 0.000347   
2022-11-25 10:46:07,569 - INFO  - Training [8][   80/  196]   Loss 2.323600   Top1 9.858398   Top5 50.185547   BatchTime 0.348381   LR 0.000308   
2022-11-25 10:46:14,923 - INFO  - Training [8][  100/  196]   Loss 2.323787   Top1 9.773438   Top5 49.914062   BatchTime 0.352245   LR 0.000270   
2022-11-25 10:46:22,478 - INFO  - Training [8][  120/  196]   Loss 2.323505   Top1 9.915365   Top5 50.074870   BatchTime 0.356493   LR 0.000235   
2022-11-25 10:46:29,860 - INFO  - Training [8][  140/  196]   Loss 2.323463   Top1 9.888393   Top5 50.011161   BatchTime 0.358294   LR 0.000202   
2022-11-25 10:46:37,232 - INFO  - Training [8][  160/  196]   Loss 2.323501   Top1 9.853516   Top5 49.882812   BatchTime 0.359581   LR 0.000172   
2022-11-25 10:46:44,442 - INFO  - Training [8][  180/  196]   Loss 2.323520   Top1 9.863281   Top5 49.811198   BatchTime 0.359684   LR 0.000143   
2022-11-25 10:46:50,355 - INFO  - ==> Top1: 9.914    Top5: 49.818    Loss: 2.323

2022-11-25 10:46:50,616 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:46:52,689 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:46:55,331 - INFO  - Validation [8][   20/   40]   Loss 2.410998   Top1 10.078125   Top5 49.804688   BatchTime 0.132018   
2022-11-25 10:46:56,408 - INFO  - Validation [8][   40/   40]   Loss 2.412194   Top1 10.000000   Top5 50.000000   BatchTime 0.092939   
2022-11-25 10:46:56,608 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.412

2022-11-25 10:46:56,608 - INFO  - ==> Sparsity : 0.536

2022-11-25 10:46:56,608 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:46:56,608 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:46:56,609 - INFO  - Scoreboard best 3 ==> Epoch [8][Top1: 10.000   Top5: 50.000]
2022-11-25 10:46:56,924 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:46:56,926 - INFO  - >>>>>> Epoch   9
2022-11-25 10:46:56,928 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:47:05,438 - INFO  - Training [9][   20/  196]   Loss 2.322635   Top1 10.195312   Top5 49.882812   BatchTime 0.425375   LR 0.000100   
2022-11-25 10:47:12,610 - INFO  - Training [9][   40/  196]   Loss 2.322728   Top1 9.785156   Top5 50.253906   BatchTime 0.391992   LR 0.000079   
2022-11-25 10:47:19,183 - INFO  - Training [9][   60/  196]   Loss 2.322871   Top1 9.765625   Top5 50.162760   BatchTime 0.370879   LR 0.000060   
2022-11-25 10:47:25,183 - INFO  - Training [9][   80/  196]   Loss 2.322592   Top1 9.951172   Top5 50.434570   BatchTime 0.353155   LR 0.000044   
2022-11-25 10:47:32,066 - INFO  - Training [9][  100/  196]   Loss 2.322683   Top1 9.917969   Top5 50.363281   BatchTime 0.351356   LR 0.000030   
2022-11-25 10:47:39,669 - INFO  - Training [9][  120/  196]   Loss 2.322750   Top1 10.009766   Top5 50.224609   BatchTime 0.356150   LR 0.000019   
2022-11-25 10:47:47,023 - INFO  - Training [9][  140/  196]   Loss 2.322739   Top1 9.969308   Top5 50.186942   BatchTime 0.357804   LR 0.000010   
2022-11-25 10:47:54,328 - INFO  - Training [9][  160/  196]   Loss 2.322728   Top1 9.987793   Top5 50.046387   BatchTime 0.358730   LR 0.000004   
2022-11-25 10:48:01,632 - INFO  - Training [9][  180/  196]   Loss 2.322721   Top1 9.954427   Top5 50.080295   BatchTime 0.359451   LR 0.000001   
2022-11-25 10:48:07,602 - INFO  - ==> Top1: 9.958    Top5: 50.108    Loss: 2.323

2022-11-25 10:48:07,895 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:48:09,415 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:48:11,816 - INFO  - Validation [9][   20/   40]   Loss 2.347614   Top1 10.078125   Top5 49.804688   BatchTime 0.119958   
2022-11-25 10:48:12,938 - INFO  - Validation [9][   40/   40]   Loss 2.347898   Top1 10.000000   Top5 50.000000   BatchTime 0.088035   
2022-11-25 10:48:13,137 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.348

2022-11-25 10:48:13,137 - INFO  - ==> Sparsity : 0.540

2022-11-25 10:48:13,137 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:48:13,138 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:48:13,138 - INFO  - Scoreboard best 3 ==> Epoch [9][Top1: 10.000   Top5: 50.000]
2022-11-25 10:48:13,269 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:48:13,271 - INFO  - >>>>>> Epoch  10
2022-11-25 10:48:13,273 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:48:22,216 - INFO  - Training [10][   20/  196]   Loss 2.324797   Top1 10.253906   Top5 50.136719   BatchTime 0.447051   LR 0.002500   
2022-11-25 10:48:29,644 - INFO  - Training [10][   40/  196]   Loss 2.324550   Top1 10.244141   Top5 49.521484   BatchTime 0.409225   LR 0.002499   
2022-11-25 10:48:36,858 - INFO  - Training [10][   60/  196]   Loss 2.323934   Top1 10.247396   Top5 49.563802   BatchTime 0.393042   LR 0.002499   
2022-11-25 10:48:43,555 - INFO  - Training [10][   80/  196]   Loss 2.323447   Top1 10.117188   Top5 49.448242   BatchTime 0.378490   LR 0.002497   
2022-11-25 10:48:50,052 - INFO  - Training [10][  100/  196]   Loss 2.323314   Top1 10.117188   Top5 49.546875   BatchTime 0.367767   LR 0.002496   
2022-11-25 10:48:56,315 - INFO  - Training [10][  120/  196]   Loss 2.323090   Top1 10.078125   Top5 49.707031   BatchTime 0.358658   LR 0.002494   
2022-11-25 10:49:03,673 - INFO  - Training [10][  140/  196]   Loss 2.323033   Top1 10.094866   Top5 49.732143   BatchTime 0.359984   LR 0.002492   
2022-11-25 10:49:10,916 - INFO  - Training [10][  160/  196]   Loss 2.322860   Top1 10.085449   Top5 49.812012   BatchTime 0.360249   LR 0.002490   
2022-11-25 10:49:18,279 - INFO  - Training [10][  180/  196]   Loss 2.322767   Top1 10.010851   Top5 49.789497   BatchTime 0.361130   LR 0.002487   
2022-11-25 10:49:24,394 - INFO  - ==> Top1: 9.974    Top5: 49.876    Loss: 2.323

2022-11-25 10:49:24,687 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:49:26,350 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:49:28,926 - INFO  - Validation [10][   20/   40]   Loss 2.309767   Top1 10.253906   Top5 49.960938   BatchTime 0.128707   
2022-11-25 10:49:30,038 - INFO  - Validation [10][   40/   40]   Loss 2.310188   Top1 10.000000   Top5 50.000000   BatchTime 0.092162   
2022-11-25 10:49:30,245 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.310

2022-11-25 10:49:30,246 - INFO  - ==> Sparsity : 0.592

2022-11-25 10:49:30,246 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:49:30,246 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:49:30,246 - INFO  - Scoreboard best 3 ==> Epoch [10][Top1: 10.000   Top5: 50.000]
2022-11-25 10:49:30,369 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:49:30,371 - INFO  - >>>>>> Epoch  11
2022-11-25 10:49:30,373 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:49:39,357 - INFO  - Training [11][   20/  196]   Loss 2.320538   Top1 9.687500   Top5 50.976562   BatchTime 0.449061   LR 0.002481   
2022-11-25 10:49:46,649 - INFO  - Training [11][   40/  196]   Loss 2.321561   Top1 9.453125   Top5 50.136719   BatchTime 0.406834   LR 0.002478   
2022-11-25 10:49:53,911 - INFO  - Training [11][   60/  196]   Loss 2.321331   Top1 9.856771   Top5 50.247396   BatchTime 0.392256   LR 0.002474   
2022-11-25 10:50:01,203 - INFO  - Training [11][   80/  196]   Loss 2.321360   Top1 9.863281   Top5 50.092773   BatchTime 0.385348   LR 0.002470   
2022-11-25 10:50:07,858 - INFO  - Training [11][  100/  196]   Loss 2.321396   Top1 9.839844   Top5 49.957031   BatchTime 0.374821   LR 0.002465   
2022-11-25 10:50:14,034 - INFO  - Training [11][  120/  196]   Loss 2.321296   Top1 9.820964   Top5 49.873047   BatchTime 0.363820   LR 0.002460   
2022-11-25 10:50:20,439 - INFO  - Training [11][  140/  196]   Loss 2.321158   Top1 9.885603   Top5 49.840960   BatchTime 0.357592   LR 0.002455   
2022-11-25 10:50:27,844 - INFO  - Training [11][  160/  196]   Loss 2.321138   Top1 9.848633   Top5 49.770508   BatchTime 0.359178   LR 0.002450   
2022-11-25 10:50:35,057 - INFO  - Training [11][  180/  196]   Loss 2.321145   Top1 9.878472   Top5 49.717882   BatchTime 0.359340   LR 0.002444   
2022-11-25 10:50:40,793 - INFO  - ==> Top1: 9.846    Top5: 49.698    Loss: 2.321

2022-11-25 10:50:41,025 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:50:42,423 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:50:44,785 - INFO  - Validation [11][   20/   40]   Loss 2.340532   Top1 9.882812   Top5 49.785156   BatchTime 0.118033   
2022-11-25 10:50:45,838 - INFO  - Validation [11][   40/   40]   Loss 2.339230   Top1 10.000000   Top5 50.000000   BatchTime 0.085346   
2022-11-25 10:50:46,049 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.339

2022-11-25 10:50:46,049 - INFO  - ==> Sparsity : 0.602

2022-11-25 10:50:46,049 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:50:46,049 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:50:46,049 - INFO  - Scoreboard best 3 ==> Epoch [11][Top1: 10.000   Top5: 50.000]
2022-11-25 10:50:46,344 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:50:46,346 - INFO  - >>>>>> Epoch  12
2022-11-25 10:50:46,347 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:50:54,912 - INFO  - Training [12][   20/  196]   Loss 2.320659   Top1 9.804688   Top5 49.785156   BatchTime 0.428104   LR 0.002433   
2022-11-25 10:51:02,045 - INFO  - Training [12][   40/  196]   Loss 2.321080   Top1 9.882812   Top5 49.873047   BatchTime 0.392380   LR 0.002426   
2022-11-25 10:51:09,215 - INFO  - Training [12][   60/  196]   Loss 2.320868   Top1 9.928385   Top5 50.286458   BatchTime 0.381088   LR 0.002419   
2022-11-25 10:51:16,552 - INFO  - Training [12][   80/  196]   Loss 2.321086   Top1 9.814453   Top5 50.000000   BatchTime 0.377525   LR 0.002412   
2022-11-25 10:51:23,804 - INFO  - Training [12][  100/  196]   Loss 2.321078   Top1 9.968750   Top5 50.179688   BatchTime 0.374536   LR 0.002404   
2022-11-25 10:51:30,812 - INFO  - Training [12][  120/  196]   Loss 2.321136   Top1 10.058594   Top5 50.042318   BatchTime 0.370513   LR 0.002396   
2022-11-25 10:51:37,061 - INFO  - Training [12][  140/  196]   Loss nan   Top1 10.041853   Top5 49.944196   BatchTime 0.362221   LR 0.002388   
2022-11-25 10:51:43,119 - INFO  - Training [12][  160/  196]   Loss nan   Top1 10.085449   Top5 49.975586   BatchTime 0.354801   LR 0.002380   
2022-11-25 10:51:50,482 - INFO  - Training [12][  180/  196]   Loss nan   Top1 10.071615   Top5 49.852431   BatchTime 0.356284   LR 0.002371   
2022-11-25 10:51:56,461 - INFO  - ==> Top1: 10.038    Top5: 49.842    Loss: nan

2022-11-25 10:51:56,782 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:51:58,350 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:52:00,670 - INFO  - Validation [12][   20/   40]   Loss 2.350814   Top1 9.882812   Top5 49.785156   BatchTime 0.115955   
2022-11-25 10:52:01,722 - INFO  - Validation [12][   40/   40]   Loss 2.349360   Top1 10.000000   Top5 50.000000   BatchTime 0.084275   
2022-11-25 10:52:01,937 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.349

2022-11-25 10:52:01,937 - INFO  - ==> Sparsity : 0.609

2022-11-25 10:52:01,937 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:52:01,938 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:52:01,938 - INFO  - Scoreboard best 3 ==> Epoch [12][Top1: 10.000   Top5: 50.000]
2022-11-25 10:52:02,059 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:52:02,060 - INFO  - >>>>>> Epoch  13
2022-11-25 10:52:02,062 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:52:10,614 - INFO  - Training [13][   20/  196]   Loss nan   Top1 9.960938   Top5 50.390625   BatchTime 0.427450   LR 0.002355   
2022-11-25 10:52:18,111 - INFO  - Training [13][   40/  196]   Loss nan   Top1 9.941406   Top5 49.570312   BatchTime 0.401149   LR 0.002345   
2022-11-25 10:52:25,573 - INFO  - Training [13][   60/  196]   Loss nan   Top1 10.130208   Top5 49.524740   BatchTime 0.391794   LR 0.002336   
2022-11-25 10:52:32,946 - INFO  - Training [13][   80/  196]   Loss nan   Top1 9.990234   Top5 49.570312   BatchTime 0.386013   LR 0.002325   
2022-11-25 10:52:40,376 - INFO  - Training [13][  100/  196]   Loss nan   Top1 9.988281   Top5 49.535156   BatchTime 0.383111   LR 0.002315   
2022-11-25 10:52:47,802 - INFO  - Training [13][  120/  196]   Loss nan   Top1 9.921875   Top5 49.567057   BatchTime 0.381139   LR 0.002304   
2022-11-25 10:52:54,562 - INFO  - Training [13][  140/  196]   Loss nan   Top1 9.952567   Top5 49.536830   BatchTime 0.374977   LR 0.002293   
2022-11-25 10:53:01,388 - INFO  - Training [13][  160/  196]   Loss nan   Top1 9.938965   Top5 49.599609   BatchTime 0.370768   LR 0.002282   
2022-11-25 10:53:07,024 - INFO  - Training [13][  180/  196]   Loss nan   Top1 9.954427   Top5 49.594184   BatchTime 0.360877   LR 0.002271   
2022-11-25 10:53:12,906 - INFO  - ==> Top1: 9.998    Top5: 49.784    Loss: nan

2022-11-25 10:53:13,177 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:53:14,570 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:53:16,963 - INFO  - Validation [13][   20/   40]   Loss 2.347446   Top1 9.882812   Top5 49.785156   BatchTime 0.119565   
2022-11-25 10:53:18,105 - INFO  - Validation [13][   40/   40]   Loss 2.346011   Top1 10.000000   Top5 50.000000   BatchTime 0.088337   
2022-11-25 10:53:18,285 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.346

2022-11-25 10:53:18,286 - INFO  - ==> Sparsity : 0.634

2022-11-25 10:53:18,286 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:53:18,286 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:53:18,286 - INFO  - Scoreboard best 3 ==> Epoch [13][Top1: 10.000   Top5: 50.000]
2022-11-25 10:53:18,411 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:53:18,413 - INFO  - >>>>>> Epoch  14
2022-11-25 10:53:18,415 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:53:26,845 - INFO  - Training [14][   20/  196]   Loss nan   Top1 9.531250   Top5 50.429688   BatchTime 0.421412   LR 0.002250   
2022-11-25 10:53:34,288 - INFO  - Training [14][   40/  196]   Loss nan   Top1 9.804688   Top5 50.341797   BatchTime 0.396770   LR 0.002238   
2022-11-25 10:53:41,804 - INFO  - Training [14][   60/  196]   Loss nan   Top1 9.791667   Top5 50.045573   BatchTime 0.389775   LR 0.002225   
2022-11-25 10:53:49,219 - INFO  - Training [14][   80/  196]   Loss nan   Top1 9.858398   Top5 50.048828   BatchTime 0.385016   LR 0.002213   
2022-11-25 10:53:56,433 - INFO  - Training [14][  100/  196]   Loss nan   Top1 9.843750   Top5 50.101562   BatchTime 0.380152   LR 0.002200   
2022-11-25 10:54:04,096 - INFO  - Training [14][  120/  196]   Loss nan   Top1 9.967448   Top5 50.263672   BatchTime 0.380654   LR 0.002186   
2022-11-25 10:54:11,236 - INFO  - Training [14][  140/  196]   Loss nan   Top1 9.972098   Top5 50.245536   BatchTime 0.377273   LR 0.002173   
2022-11-25 10:54:18,550 - INFO  - Training [14][  160/  196]   Loss nan   Top1 9.992676   Top5 50.090332   BatchTime 0.375824   LR 0.002159   
2022-11-25 10:54:24,756 - INFO  - Training [14][  180/  196]   Loss nan   Top1 9.939236   Top5 50.082465   BatchTime 0.368547   LR 0.002145   
2022-11-25 10:54:30,860 - INFO  - ==> Top1: 9.972    Top5: 50.078    Loss: nan

2022-11-25 10:54:31,132 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:54:32,595 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:54:34,858 - INFO  - Validation [14][   20/   40]   Loss 2.346487   Top1 9.882812   Top5 49.785156   BatchTime 0.113062   
2022-11-25 10:54:35,941 - INFO  - Validation [14][   40/   40]   Loss 2.345050   Top1 10.000000   Top5 50.000000   BatchTime 0.083590   
2022-11-25 10:54:36,132 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.345

2022-11-25 10:54:36,132 - INFO  - ==> Sparsity : 0.619

2022-11-25 10:54:36,133 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:54:36,133 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:54:36,133 - INFO  - Scoreboard best 3 ==> Epoch [14][Top1: 10.000   Top5: 50.000]
2022-11-25 10:54:36,250 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:54:36,252 - INFO  - >>>>>> Epoch  15
2022-11-25 10:54:36,254 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:54:44,536 - INFO  - Training [15][   20/  196]   Loss nan   Top1 9.726562   Top5 50.449219   BatchTime 0.413994   LR 0.002120   
2022-11-25 10:54:51,914 - INFO  - Training [15][   40/  196]   Loss nan   Top1 9.423828   Top5 50.224609   BatchTime 0.391453   LR 0.002106   
2022-11-25 10:54:59,636 - INFO  - Training [15][   60/  196]   Loss nan   Top1 9.791667   Top5 49.980469   BatchTime 0.389660   LR 0.002091   
2022-11-25 10:55:06,852 - INFO  - Training [15][   80/  196]   Loss nan   Top1 9.682617   Top5 49.907227   BatchTime 0.382446   LR 0.002076   
2022-11-25 10:55:14,076 - INFO  - Training [15][  100/  196]   Loss nan   Top1 9.769531   Top5 49.722656   BatchTime 0.378199   LR 0.002061   
2022-11-25 10:55:21,340 - INFO  - Training [15][  120/  196]   Loss nan   Top1 9.882812   Top5 49.694010   BatchTime 0.375698   LR 0.002045   
2022-11-25 10:55:28,611 - INFO  - Training [15][  140/  196]   Loss nan   Top1 9.891183   Top5 49.589844   BatchTime 0.373964   LR 0.002030   
2022-11-25 10:55:35,832 - INFO  - Training [15][  160/  196]   Loss nan   Top1 9.892578   Top5 49.536133   BatchTime 0.372344   LR 0.002014   
2022-11-25 10:55:42,286 - INFO  - Training [15][  180/  196]   Loss nan   Top1 9.861111   Top5 49.602865   BatchTime 0.366832   LR 0.001998   
2022-11-25 10:55:48,089 - INFO  - ==> Top1: 9.886    Top5: 49.558    Loss: nan

2022-11-25 10:55:48,370 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:55:49,877 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:55:52,254 - INFO  - Validation [15][   20/   40]   Loss 2.343832   Top1 9.882812   Top5 49.785156   BatchTime 0.118760   
2022-11-25 10:55:53,281 - INFO  - Validation [15][   40/   40]   Loss 2.342511   Top1 10.000000   Top5 50.000000   BatchTime 0.085080   
2022-11-25 10:55:53,478 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.343

2022-11-25 10:55:53,478 - INFO  - ==> Sparsity : 0.622

2022-11-25 10:55:53,478 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:55:53,479 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:55:53,479 - INFO  - Scoreboard best 3 ==> Epoch [15][Top1: 10.000   Top5: 50.000]
2022-11-25 10:55:53,615 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:55:53,617 - INFO  - >>>>>> Epoch  16
2022-11-25 10:55:53,618 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:56:02,445 - INFO  - Training [16][   20/  196]   Loss nan   Top1 9.765625   Top5 49.960938   BatchTime 0.441207   LR 0.001969   
2022-11-25 10:56:09,681 - INFO  - Training [16][   40/  196]   Loss nan   Top1 9.921875   Top5 49.580078   BatchTime 0.401508   LR 0.001953   
2022-11-25 10:56:17,231 - INFO  - Training [16][   60/  196]   Loss nan   Top1 9.882812   Top5 49.615885   BatchTime 0.393503   LR 0.001936   
2022-11-25 10:56:24,866 - INFO  - Training [16][   80/  196]   Loss nan   Top1 9.794922   Top5 49.589844   BatchTime 0.390562   LR 0.001919   
2022-11-25 10:56:32,191 - INFO  - Training [16][  100/  196]   Loss nan   Top1 9.925781   Top5 49.546875   BatchTime 0.385693   LR 0.001902   
2022-11-25 10:56:39,624 - INFO  - Training [16][  120/  196]   Loss nan   Top1 9.856771   Top5 49.583333   BatchTime 0.383351   LR 0.001885   
2022-11-25 10:56:46,974 - INFO  - Training [16][  140/  196]   Loss nan   Top1 9.840960   Top5 49.430804   BatchTime 0.381086   LR 0.001867   
2022-11-25 10:56:53,888 - INFO  - Training [16][  160/  196]   Loss nan   Top1 9.777832   Top5 49.270020   BatchTime 0.376660   LR 0.001850   
2022-11-25 10:57:00,558 - INFO  - Training [16][  180/  196]   Loss nan   Top1 9.815538   Top5 49.296875   BatchTime 0.371870   LR 0.001832   
2022-11-25 10:57:06,540 - INFO  - ==> Top1: 9.814    Top5: 49.244    Loss: nan

2022-11-25 10:57:06,753 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:57:08,105 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:57:10,552 - INFO  - Validation [16][   20/   40]   Loss 2.332541   Top1 9.882812   Top5 49.785156   BatchTime 0.122268   
2022-11-25 10:57:11,627 - INFO  - Validation [16][   40/   40]   Loss 2.331517   Top1 10.000000   Top5 50.000000   BatchTime 0.088004   
2022-11-25 10:57:11,812 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.332

2022-11-25 10:57:11,812 - INFO  - ==> Sparsity : 0.625

2022-11-25 10:57:11,812 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:57:11,813 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:57:11,813 - INFO  - Scoreboard best 3 ==> Epoch [16][Top1: 10.000   Top5: 50.000]
2022-11-25 10:57:11,930 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:57:11,932 - INFO  - >>>>>> Epoch  17
2022-11-25 10:57:11,934 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:57:20,667 - INFO  - Training [17][   20/  196]   Loss nan   Top1 10.683594   Top5 50.039062   BatchTime 0.436569   LR 0.001800   
2022-11-25 10:57:27,817 - INFO  - Training [17][   40/  196]   Loss nan   Top1 10.341797   Top5 49.785156   BatchTime 0.397022   LR 0.001782   
2022-11-25 10:57:35,435 - INFO  - Training [17][   60/  196]   Loss nan   Top1 10.208333   Top5 49.596354   BatchTime 0.391649   LR 0.001764   
2022-11-25 10:57:42,852 - INFO  - Training [17][   80/  196]   Loss nan   Top1 10.205078   Top5 49.658203   BatchTime 0.386442   LR 0.001746   
2022-11-25 10:57:50,156 - INFO  - Training [17][  100/  196]   Loss nan   Top1 10.199219   Top5 49.398438   BatchTime 0.382202   LR 0.001727   
2022-11-25 10:57:57,391 - INFO  - Training [17][  120/  196]   Loss nan   Top1 10.081380   Top5 49.492188   BatchTime 0.378792   LR 0.001708   
2022-11-25 10:58:04,622 - INFO  - Training [17][  140/  196]   Loss nan   Top1 10.097656   Top5 49.575893   BatchTime 0.376329   LR 0.001690   
2022-11-25 10:58:11,845 - INFO  - Training [17][  160/  196]   Loss nan   Top1 10.153809   Top5 49.519043   BatchTime 0.374425   LR 0.001671   
2022-11-25 10:58:18,620 - INFO  - Training [17][  180/  196]   Loss nan   Top1 10.099826   Top5 49.635417   BatchTime 0.370465   LR 0.001652   
2022-11-25 10:58:24,739 - INFO  - ==> Top1: 10.164    Top5: 49.674    Loss: nan

2022-11-25 10:58:24,988 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:58:26,458 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:58:28,932 - INFO  - Validation [17][   20/   40]   Loss 2.306973   Top1 9.882812   Top5 49.804688   BatchTime 0.123567   
2022-11-25 10:58:30,039 - INFO  - Validation [17][   40/   40]   Loss 2.306331   Top1 10.000000   Top5 50.000000   BatchTime 0.089462   
2022-11-25 10:58:30,282 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.306

2022-11-25 10:58:30,283 - INFO  - ==> Sparsity : 0.623

2022-11-25 10:58:30,283 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:58:30,283 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:58:30,283 - INFO  - Scoreboard best 3 ==> Epoch [17][Top1: 10.000   Top5: 50.000]
2022-11-25 10:58:30,429 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:58:30,431 - INFO  - >>>>>> Epoch  18
2022-11-25 10:58:30,432 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:58:38,961 - INFO  - Training [18][   20/  196]   Loss nan   Top1 10.410156   Top5 50.332031   BatchTime 0.426295   LR 0.001618   
2022-11-25 10:58:46,115 - INFO  - Training [18][   40/  196]   Loss nan   Top1 10.175781   Top5 49.853516   BatchTime 0.391997   LR 0.001599   
2022-11-25 10:58:53,405 - INFO  - Training [18][   60/  196]   Loss nan   Top1 10.156250   Top5 50.156250   BatchTime 0.382834   LR 0.001579   
2022-11-25 10:59:00,995 - INFO  - Training [18][   80/  196]   Loss nan   Top1 10.092773   Top5 50.209961   BatchTime 0.381997   LR 0.001560   
2022-11-25 10:59:08,299 - INFO  - Training [18][  100/  196]   Loss nan   Top1 10.085938   Top5 50.300781   BatchTime 0.378636   LR 0.001540   
2022-11-25 10:59:15,671 - INFO  - Training [18][  120/  196]   Loss nan   Top1 9.977214   Top5 50.247396   BatchTime 0.376961   LR 0.001521   
2022-11-25 10:59:23,076 - INFO  - Training [18][  140/  196]   Loss nan   Top1 9.980469   Top5 50.217634   BatchTime 0.376008   LR 0.001501   
2022-11-25 10:59:30,042 - INFO  - Training [18][  160/  196]   Loss nan   Top1 9.931641   Top5 50.117188   BatchTime 0.372542   LR 0.001482   
2022-11-25 10:59:36,500 - INFO  - Training [18][  180/  196]   Loss nan   Top1 9.963108   Top5 50.028212   BatchTime 0.367024   LR 0.001462   
2022-11-25 10:59:42,507 - INFO  - ==> Top1: 9.962    Top5: 50.070    Loss: nan

2022-11-25 10:59:42,780 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 10:59:44,294 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 10:59:46,736 - INFO  - Validation [18][   20/   40]   Loss 2.311844   Top1 9.882812   Top5 49.882812   BatchTime 0.121999   
2022-11-25 10:59:47,900 - INFO  - Validation [18][   40/   40]   Loss 2.311126   Top1 10.000000   Top5 50.000000   BatchTime 0.090098   
2022-11-25 10:59:48,121 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.311

2022-11-25 10:59:48,121 - INFO  - ==> Sparsity : 0.626

2022-11-25 10:59:48,122 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 10:59:48,122 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 10:59:48,122 - INFO  - Scoreboard best 3 ==> Epoch [18][Top1: 10.000   Top5: 50.000]
2022-11-25 10:59:48,243 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 10:59:48,244 - INFO  - >>>>>> Epoch  19
2022-11-25 10:59:48,246 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 10:59:56,981 - INFO  - Training [19][   20/  196]   Loss nan   Top1 10.390625   Top5 50.488281   BatchTime 0.436643   LR 0.001427   
2022-11-25 11:00:04,278 - INFO  - Training [19][   40/  196]   Loss nan   Top1 10.107422   Top5 49.697266   BatchTime 0.400746   LR 0.001407   
2022-11-25 11:00:11,704 - INFO  - Training [19][   60/  196]   Loss nan   Top1 10.286458   Top5 49.791667   BatchTime 0.390925   LR 0.001387   
2022-11-25 11:00:19,622 - INFO  - Training [19][   80/  196]   Loss nan   Top1 10.151367   Top5 49.741211   BatchTime 0.392164   LR 0.001367   
2022-11-25 11:00:27,128 - INFO  - Training [19][  100/  196]   Loss nan   Top1 9.976562   Top5 49.273438   BatchTime 0.388791   LR 0.001347   
2022-11-25 11:00:34,257 - INFO  - Training [19][  120/  196]   Loss nan   Top1 10.019531   Top5 49.449870   BatchTime 0.383401   LR 0.001327   
2022-11-25 11:00:41,510 - INFO  - Training [19][  140/  196]   Loss nan   Top1 9.960938   Top5 49.511719   BatchTime 0.380434   LR 0.001307   
2022-11-25 11:00:48,461 - INFO  - Training [19][  160/  196]   Loss nan   Top1 9.936523   Top5 49.638672   BatchTime 0.376327   LR 0.001287   
2022-11-25 11:00:54,812 - INFO  - Training [19][  180/  196]   Loss nan   Top1 9.911024   Top5 49.633247   BatchTime 0.369795   LR 0.001266   
2022-11-25 11:01:00,522 - INFO  - ==> Top1: 9.868    Top5: 49.750    Loss: nan

2022-11-25 11:01:00,759 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:01:02,316 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:01:04,633 - INFO  - Validation [19][   20/   40]   Loss 2.320097   Top1 9.882812   Top5 49.785156   BatchTime 0.115721   
2022-11-25 11:01:05,760 - INFO  - Validation [19][   40/   40]   Loss 2.319094   Top1 10.000000   Top5 50.000000   BatchTime 0.086042   
2022-11-25 11:01:05,953 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.319

2022-11-25 11:01:05,953 - INFO  - ==> Sparsity : 0.630

2022-11-25 11:01:05,953 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 11:01:05,953 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 11:01:05,953 - INFO  - Scoreboard best 3 ==> Epoch [19][Top1: 10.000   Top5: 50.000]
2022-11-25 11:01:06,078 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 11:01:06,080 - INFO  - >>>>>> Epoch  20
2022-11-25 11:01:06,082 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:01:14,707 - INFO  - Training [20][   20/  196]   Loss nan   Top1 9.570312   Top5 50.097656   BatchTime 0.431095   LR 0.001231   
2022-11-25 11:01:22,003 - INFO  - Training [20][   40/  196]   Loss nan   Top1 10.048828   Top5 49.511719   BatchTime 0.397968   LR 0.001211   
2022-11-25 11:01:29,387 - INFO  - Training [20][   60/  196]   Loss nan   Top1 10.019531   Top5 49.433594   BatchTime 0.388371   LR 0.001191   
2022-11-25 11:01:36,978 - INFO  - Training [20][   80/  196]   Loss nan   Top1 10.068359   Top5 49.296875   BatchTime 0.386164   LR 0.001171   
2022-11-25 11:01:44,569 - INFO  - Training [20][  100/  196]   Loss nan   Top1 9.929688   Top5 49.398438   BatchTime 0.384841   LR 0.001151   
2022-11-25 11:01:51,808 - INFO  - Training [20][  120/  196]   Loss nan   Top1 9.882812   Top5 49.423828   BatchTime 0.381026   LR 0.001131   
2022-11-25 11:01:59,363 - INFO  - Training [20][  140/  196]   Loss nan   Top1 9.893973   Top5 49.447545   BatchTime 0.380554   LR 0.001111   
2022-11-25 11:02:06,529 - INFO  - Training [20][  160/  196]   Loss nan   Top1 9.841309   Top5 49.494629   BatchTime 0.377772   LR 0.001091   
2022-11-25 11:02:13,403 - INFO  - Training [20][  180/  196]   Loss nan   Top1 9.822049   Top5 49.578993   BatchTime 0.373988   LR 0.001071   
2022-11-25 11:02:19,693 - INFO  - ==> Top1: 9.836    Top5: 49.616    Loss: nan

2022-11-25 11:02:19,910 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:02:21,285 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:02:23,623 - INFO  - Validation [20][   20/   40]   Loss 2.303959   Top1 9.882812   Top5 50.019531   BatchTime 0.116833   
2022-11-25 11:02:24,714 - INFO  - Validation [20][   40/   40]   Loss 2.303690   Top1 10.000000   Top5 50.000000   BatchTime 0.085700   
2022-11-25 11:02:24,940 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.304

2022-11-25 11:02:24,940 - INFO  - ==> Sparsity : 0.627

2022-11-25 11:02:24,940 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 11:02:24,940 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 11:02:24,941 - INFO  - Scoreboard best 3 ==> Epoch [20][Top1: 10.000   Top5: 50.000]
2022-11-25 11:02:25,067 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 11:02:25,069 - INFO  - >>>>>> Epoch  21
2022-11-25 11:02:25,070 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:02:33,812 - INFO  - Training [21][   20/  196]   Loss nan   Top1 10.371094   Top5 50.605469   BatchTime 0.436963   LR 0.001036   
2022-11-25 11:02:41,262 - INFO  - Training [21][   40/  196]   Loss nan   Top1 10.166016   Top5 50.234375   BatchTime 0.404726   LR 0.001016   
2022-11-25 11:02:48,662 - INFO  - Training [21][   60/  196]   Loss nan   Top1 10.045573   Top5 50.136719   BatchTime 0.393143   LR 0.000996   
2022-11-25 11:02:56,374 - INFO  - Training [21][   80/  196]   Loss nan   Top1 10.092773   Top5 50.209961   BatchTime 0.391264   LR 0.000976   
2022-11-25 11:03:03,932 - INFO  - Training [21][  100/  196]   Loss nan   Top1 10.054688   Top5 50.261719   BatchTime 0.388585   LR 0.000957   
2022-11-25 11:03:11,186 - INFO  - Training [21][  120/  196]   Loss nan   Top1 10.058594   Top5 50.104167   BatchTime 0.384273   LR 0.000937   
2022-11-25 11:03:18,414 - INFO  - Training [21][  140/  196]   Loss nan   Top1 10.027902   Top5 49.983259   BatchTime 0.381005   LR 0.000918   
2022-11-25 11:03:25,338 - INFO  - Training [21][  160/  196]   Loss nan   Top1 10.061035   Top5 50.031738   BatchTime 0.376649   LR 0.000899   
2022-11-25 11:03:31,788 - INFO  - Training [21][  180/  196]   Loss nan   Top1 10.023872   Top5 49.947917   BatchTime 0.370633   LR 0.000879   
2022-11-25 11:03:35,926 - INFO  - ==> Top1: 10.088    Top5: 49.980    Loss: nan

2022-11-25 11:03:36,185 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:03:38,441 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:03:40,887 - INFO  - Validation [21][   20/   40]   Loss 2.307700   Top1 9.882812   Top5 49.882812   BatchTime 0.122228   
2022-11-25 11:03:41,991 - INFO  - Validation [21][   40/   40]   Loss 2.307280   Top1 10.000000   Top5 50.000000   BatchTime 0.088720   
2022-11-25 11:03:42,222 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.307

2022-11-25 11:03:42,223 - INFO  - ==> Sparsity : 0.629

2022-11-25 11:03:42,223 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 11:03:42,223 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 11:03:42,223 - INFO  - Scoreboard best 3 ==> Epoch [21][Top1: 10.000   Top5: 50.000]
2022-11-25 11:03:42,341 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 11:03:42,342 - INFO  - >>>>>> Epoch  22
2022-11-25 11:03:42,344 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:03:50,853 - INFO  - Training [22][   20/  196]   Loss nan   Top1 9.570312   Top5 50.371094   BatchTime 0.425324   LR 0.000846   
2022-11-25 11:03:58,247 - INFO  - Training [22][   40/  196]   Loss nan   Top1 9.628906   Top5 51.230469   BatchTime 0.397521   LR 0.000827   
2022-11-25 11:04:05,601 - INFO  - Training [22][   60/  196]   Loss nan   Top1 9.726562   Top5 50.755208   BatchTime 0.387574   LR 0.000808   
2022-11-25 11:04:12,931 - INFO  - Training [22][   80/  196]   Loss nan   Top1 9.804688   Top5 50.732422   BatchTime 0.382299   LR 0.000789   
2022-11-25 11:04:20,539 - INFO  - Training [22][  100/  196]   Loss nan   Top1 9.761719   Top5 50.640625   BatchTime 0.381919   LR 0.000770   
2022-11-25 11:04:28,545 - INFO  - Training [22][  120/  196]   Loss nan   Top1 9.716797   Top5 50.338542   BatchTime 0.384985   LR 0.000752   
2022-11-25 11:04:35,949 - INFO  - Training [22][  140/  196]   Loss nan   Top1 9.679129   Top5 50.276228   BatchTime 0.382869   LR 0.000734   
2022-11-25 11:04:43,415 - INFO  - Training [22][  160/  196]   Loss nan   Top1 9.702148   Top5 50.100098   BatchTime 0.381673   LR 0.000715   
2022-11-25 11:04:50,085 - INFO  - Training [22][  180/  196]   Loss nan   Top1 9.752604   Top5 49.980469   BatchTime 0.376319   LR 0.000697   
2022-11-25 11:04:55,315 - INFO  - ==> Top1: 9.750    Top5: 49.908    Loss: nan

2022-11-25 11:04:55,507 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:04:57,047 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:04:59,414 - INFO  - Validation [22][   20/   40]   Loss 2.306795   Top1 9.882812   Top5 49.765625   BatchTime 0.118264   
2022-11-25 11:05:00,545 - INFO  - Validation [22][   40/   40]   Loss 2.306219   Top1 10.000000   Top5 50.000000   BatchTime 0.087413   
2022-11-25 11:05:00,771 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.306

2022-11-25 11:05:00,771 - INFO  - ==> Sparsity : 0.631

2022-11-25 11:05:00,772 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 11:05:00,772 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 11:05:00,772 - INFO  - Scoreboard best 3 ==> Epoch [22][Top1: 10.000   Top5: 50.000]
2022-11-25 11:05:00,891 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 11:05:00,893 - INFO  - >>>>>> Epoch  23
2022-11-25 11:05:00,895 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:05:09,649 - INFO  - Training [23][   20/  196]   Loss nan   Top1 9.921875   Top5 49.609375   BatchTime 0.437585   LR 0.000666   
2022-11-25 11:05:17,412 - INFO  - Training [23][   40/  196]   Loss nan   Top1 9.912109   Top5 49.453125   BatchTime 0.412882   LR 0.000648   
2022-11-25 11:05:24,784 - INFO  - Training [23][   60/  196]   Loss nan   Top1 9.934896   Top5 49.127604   BatchTime 0.398106   LR 0.000630   
2022-11-25 11:05:32,112 - INFO  - Training [23][   80/  196]   Loss nan   Top1 9.965820   Top5 49.155273   BatchTime 0.390179   LR 0.000613   
2022-11-25 11:05:39,334 - INFO  - Training [23][  100/  196]   Loss nan   Top1 10.058594   Top5 49.355469   BatchTime 0.384362   LR 0.000596   
2022-11-25 11:05:46,746 - INFO  - Training [23][  120/  196]   Loss nan   Top1 9.954427   Top5 49.498698   BatchTime 0.382070   LR 0.000579   
2022-11-25 11:05:54,261 - INFO  - Training [23][  140/  196]   Loss nan   Top1 9.807478   Top5 49.469866   BatchTime 0.381168   LR 0.000562   
2022-11-25 11:06:01,439 - INFO  - Training [23][  160/  196]   Loss nan   Top1 9.877930   Top5 49.426270   BatchTime 0.378382   LR 0.000545   
2022-11-25 11:06:08,354 - INFO  - Training [23][  180/  196]   Loss nan   Top1 9.830729   Top5 49.526910   BatchTime 0.374759   LR 0.000529   
2022-11-25 11:06:13,596 - INFO  - ==> Top1: 9.810    Top5: 49.530    Loss: nan

2022-11-25 11:06:13,877 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:06:15,251 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:06:17,585 - INFO  - Validation [23][   20/   40]   Loss 2.306856   Top1 9.882812   Top5 50.039062   BatchTime 0.116623   
2022-11-25 11:06:18,707 - INFO  - Validation [23][   40/   40]   Loss 2.306343   Top1 10.000000   Top5 50.000000   BatchTime 0.086365   
2022-11-25 11:06:18,931 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.306

2022-11-25 11:06:18,931 - INFO  - ==> Sparsity : 0.631

2022-11-25 11:06:18,932 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 11:06:18,932 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 11:06:18,932 - INFO  - Scoreboard best 3 ==> Epoch [23][Top1: 10.000   Top5: 50.000]
2022-11-25 11:06:19,069 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 11:06:19,070 - INFO  - >>>>>> Epoch  24
2022-11-25 11:06:19,072 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:06:27,390 - INFO  - Training [24][   20/  196]   Loss nan   Top1 9.824219   Top5 50.234375   BatchTime 0.415779   LR 0.000500   
2022-11-25 11:06:34,777 - INFO  - Training [24][   40/  196]   Loss nan   Top1 10.087891   Top5 50.498047   BatchTime 0.392550   LR 0.000484   
2022-11-25 11:06:42,035 - INFO  - Training [24][   60/  196]   Loss nan   Top1 10.130208   Top5 50.774740   BatchTime 0.382666   LR 0.000468   
2022-11-25 11:06:49,361 - INFO  - Training [24][   80/  196]   Loss nan   Top1 10.126953   Top5 50.341797   BatchTime 0.378572   LR 0.000453   
2022-11-25 11:06:56,646 - INFO  - Training [24][  100/  196]   Loss nan   Top1 10.097656   Top5 50.265625   BatchTime 0.375708   LR 0.000437   
2022-11-25 11:07:04,353 - INFO  - Training [24][  120/  196]   Loss nan   Top1 9.964193   Top5 50.009766   BatchTime 0.377316   LR 0.000422   
2022-11-25 11:07:11,808 - INFO  - Training [24][  140/  196]   Loss nan   Top1 9.969308   Top5 49.938616   BatchTime 0.376661   LR 0.000407   
2022-11-25 11:07:19,196 - INFO  - Training [24][  160/  196]   Loss nan   Top1 9.958496   Top5 49.938965   BatchTime 0.375752   LR 0.000392   
2022-11-25 11:07:26,441 - INFO  - Training [24][  180/  196]   Loss nan   Top1 9.950087   Top5 49.950087   BatchTime 0.374252   LR 0.000378   
2022-11-25 11:07:31,804 - INFO  - ==> Top1: 10.012    Top5: 49.910    Loss: nan

2022-11-25 11:07:32,017 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:07:33,264 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:07:35,772 - INFO  - Validation [24][   20/   40]   Loss 2.313929   Top1 9.882812   Top5 50.039062   BatchTime 0.125317   
2022-11-25 11:07:36,961 - INFO  - Validation [24][   40/   40]   Loss 2.313251   Top1 10.000000   Top5 50.000000   BatchTime 0.092392   
2022-11-25 11:07:37,195 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.313

2022-11-25 11:07:37,195 - INFO  - ==> Sparsity : 0.632

2022-11-25 11:07:37,196 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 11:07:37,196 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 11:07:37,196 - INFO  - Scoreboard best 3 ==> Epoch [24][Top1: 10.000   Top5: 50.000]
2022-11-25 11:07:37,355 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 11:07:37,357 - INFO  - >>>>>> Epoch  25
2022-11-25 11:07:37,359 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:07:45,993 - INFO  - Training [25][   20/  196]   Loss nan   Top1 9.843750   Top5 50.000000   BatchTime 0.431593   LR 0.000353   
2022-11-25 11:07:53,469 - INFO  - Training [25][   40/  196]   Loss nan   Top1 9.960938   Top5 49.804688   BatchTime 0.402690   LR 0.000339   
2022-11-25 11:08:00,878 - INFO  - Training [25][   60/  196]   Loss nan   Top1 10.039062   Top5 49.889323   BatchTime 0.391939   LR 0.000325   
2022-11-25 11:08:08,216 - INFO  - Training [25][   80/  196]   Loss nan   Top1 9.980469   Top5 49.912109   BatchTime 0.385679   LR 0.000312   
2022-11-25 11:08:15,974 - INFO  - Training [25][  100/  196]   Loss nan   Top1 10.015625   Top5 49.933594   BatchTime 0.386118   LR 0.000299   
2022-11-25 11:08:23,366 - INFO  - Training [25][  120/  196]   Loss nan   Top1 10.058594   Top5 49.895833   BatchTime 0.383366   LR 0.000286   
2022-11-25 11:08:30,794 - INFO  - Training [25][  140/  196]   Loss nan   Top1 9.991629   Top5 49.743304   BatchTime 0.381661   LR 0.000273   
2022-11-25 11:08:38,125 - INFO  - Training [25][  160/  196]   Loss nan   Top1 9.946289   Top5 49.743652   BatchTime 0.379769   LR 0.000261   
2022-11-25 11:08:45,484 - INFO  - Training [25][  180/  196]   Loss nan   Top1 9.989149   Top5 49.743924   BatchTime 0.378457   LR 0.000248   
2022-11-25 11:08:51,462 - INFO  - ==> Top1: 9.988    Top5: 49.732    Loss: nan

2022-11-25 11:08:51,661 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:08:52,994 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:08:56,842 - INFO  - Validation [25][   20/   40]   Loss 2.304977   Top1 9.882812   Top5 50.039062   BatchTime 0.192283   
2022-11-25 11:08:58,649 - INFO  - Validation [25][   40/   40]   Loss 2.304803   Top1 10.000000   Top5 50.000000   BatchTime 0.141324   
2022-11-25 11:08:58,945 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305

2022-11-25 11:08:58,946 - INFO  - ==> Sparsity : 0.632

2022-11-25 11:08:58,946 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 11:08:58,946 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 11:08:58,946 - INFO  - Scoreboard best 3 ==> Epoch [25][Top1: 10.000   Top5: 50.000]
2022-11-25 11:08:59,241 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 11:08:59,242 - INFO  - >>>>>> Epoch  26
2022-11-25 11:08:59,244 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:09:06,418 - INFO  - Training [26][   20/  196]   Loss nan   Top1 9.492188   Top5 49.179688   BatchTime 0.358586   LR 0.000228   
2022-11-25 11:09:13,793 - INFO  - Training [26][   40/  196]   Loss nan   Top1 9.228516   Top5 48.847656   BatchTime 0.363664   LR 0.000216   
2022-11-25 11:09:21,213 - INFO  - Training [26][   60/  196]   Loss nan   Top1 9.472656   Top5 48.997396   BatchTime 0.366096   LR 0.000205   
2022-11-25 11:09:28,594 - INFO  - Training [26][   80/  196]   Loss nan   Top1 9.599609   Top5 49.267578   BatchTime 0.366843   LR 0.000194   
2022-11-25 11:09:36,097 - INFO  - Training [26][  100/  196]   Loss nan   Top1 9.636719   Top5 49.312500   BatchTime 0.368506   LR 0.000183   
2022-11-25 11:09:43,528 - INFO  - Training [26][  120/  196]   Loss nan   Top1 9.739583   Top5 49.335938   BatchTime 0.369006   LR 0.000173   
2022-11-25 11:09:50,798 - INFO  - Training [26][  140/  196]   Loss nan   Top1 9.796317   Top5 49.416853   BatchTime 0.368225   LR 0.000163   
2022-11-25 11:09:58,273 - INFO  - Training [26][  160/  196]   Loss nan   Top1 9.877930   Top5 49.729004   BatchTime 0.368914   LR 0.000153   
2022-11-25 11:10:05,790 - INFO  - Training [26][  180/  196]   Loss nan   Top1 9.832899   Top5 49.796007   BatchTime 0.369681   LR 0.000144   
2022-11-25 11:10:11,836 - INFO  - ==> Top1: 9.826    Top5: 49.792    Loss: nan

2022-11-25 11:10:12,131 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:10:13,700 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:10:15,929 - INFO  - Validation [26][   20/   40]   Loss 2.305283   Top1 9.882812   Top5 50.039062   BatchTime 0.111366   
2022-11-25 11:10:16,933 - INFO  - Validation [26][   40/   40]   Loss 2.305098   Top1 10.000000   Top5 50.000000   BatchTime 0.080792   
2022-11-25 11:10:17,163 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305

2022-11-25 11:10:17,164 - INFO  - ==> Sparsity : 0.632

2022-11-25 11:10:17,164 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 11:10:17,164 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 11:10:17,164 - INFO  - Scoreboard best 3 ==> Epoch [26][Top1: 10.000   Top5: 50.000]
2022-11-25 11:10:17,284 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 11:10:17,285 - INFO  - >>>>>> Epoch  27
2022-11-25 11:10:17,287 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:10:24,966 - INFO  - Training [27][   20/  196]   Loss nan   Top1 10.019531   Top5 50.585938   BatchTime 0.383832   LR 0.000128   
2022-11-25 11:10:31,204 - INFO  - Training [27][   40/  196]   Loss nan   Top1 10.283203   Top5 50.107422   BatchTime 0.347868   LR 0.000119   
2022-11-25 11:10:38,358 - INFO  - Training [27][   60/  196]   Loss nan   Top1 10.156250   Top5 50.084635   BatchTime 0.351130   LR 0.000111   
2022-11-25 11:10:45,915 - INFO  - Training [27][   80/  196]   Loss nan   Top1 10.058594   Top5 49.965820   BatchTime 0.357820   LR 0.000102   
2022-11-25 11:10:53,354 - INFO  - Training [27][  100/  196]   Loss nan   Top1 10.074219   Top5 50.031250   BatchTime 0.360637   LR 0.000095   
2022-11-25 11:11:00,772 - INFO  - Training [27][  120/  196]   Loss nan   Top1 10.139974   Top5 49.899089   BatchTime 0.362352   LR 0.000087   
2022-11-25 11:11:08,425 - INFO  - Training [27][  140/  196]   Loss nan   Top1 10.119978   Top5 49.751674   BatchTime 0.365245   LR 0.000080   
2022-11-25 11:11:15,894 - INFO  - Training [27][  160/  196]   Loss nan   Top1 10.085449   Top5 49.755859   BatchTime 0.366270   LR 0.000073   
2022-11-25 11:11:23,644 - INFO  - Training [27][  180/  196]   Loss nan   Top1 10.010851   Top5 49.720052   BatchTime 0.368630   LR 0.000066   
2022-11-25 11:11:29,742 - INFO  - ==> Top1: 9.978    Top5: 49.706    Loss: nan

2022-11-25 11:11:30,016 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 11:11:31,618 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 11:11:33,901 - INFO  - Validation [27][   20/   40]   Loss 2.305041   Top1 9.882812   Top5 50.039062   BatchTime 0.114040   
2022-11-25 11:11:34,932 - INFO  - Validation [27][   40/   40]   Loss 2.304821   Top1 10.000000   Top5 50.000000   BatchTime 0.082786   
2022-11-25 11:11:35,155 - INFO  - ==> Top1: 10.000    Top5: 50.000    Loss: 2.305

2022-11-25 11:11:35,155 - INFO  - ==> Sparsity : 0.633

2022-11-25 11:11:35,156 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.020   Top5: 97.780]
2022-11-25 11:11:35,156 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 70.790   Top5: 97.130]
2022-11-25 11:11:35,156 - INFO  - Scoreboard best 3 ==> Epoch [27][Top1: 10.000   Top5: 50.000]
2022-11-25 11:11:35,284 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-103500/_checkpoint.pth.tar

2022-11-25 11:11:35,286 - INFO  - >>>>>> Epoch  28
2022-11-25 11:11:35,287 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 11:11:43,047 - INFO  - Training [28][   20/  196]   Loss nan   Top1 9.609375   Top5 49.433594   BatchTime 0.387852   LR 0.000055   
2022-11-25 11:11:49,680 - INFO  - Training [28][   40/  196]   Loss nan   Top1 10.000000   Top5 50.263672   BatchTime 0.359754   LR 0.000050   
2022-11-25 11:11:57,509 - INFO  - Training [28][   60/  196]   Loss nan   Top1 9.928385   Top5 50.423177   BatchTime 0.370316   LR 0.000044   
2022-11-25 11:12:05,041 - INFO  - Training [28][   80/  196]   Loss nan   Top1 10.053711   Top5 50.322266   BatchTime 0.371890   LR 0.000039   
