2022-10-20 18:49:54,881 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221020-184954/88_20221020-184954.log
2022-10-20 18:49:56,089 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-20 18:49:56,122 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-20 18:49:56,253 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-20 18:49:56,253 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-20 18:49:57,396 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-20 18:49:57,396 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:49:58,753 - INFO  - Validation [   20/   40]   Loss 2.510285   Top1 39.062500   Top5 86.074219   BatchTime 0.067820   
2022-10-20 18:49:59,366 - INFO  - Validation [   40/   40]   Loss 2.556888   Top1 38.200000   Top5 86.180000   BatchTime 0.049246   
2022-10-20 18:49:59,428 - INFO  - ==> Top1: 38.200    Top5: 86.180    Loss: 2.557

2022-10-20 18:49:59,428 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 38.200   Top5: 86.180]
2022-10-20 18:49:59,429 - INFO  - >>>>>> Epoch   0
2022-10-20 18:49:59,429 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-20 18:50:01,455 - INFO  - Training [0][   20/  196]   Loss 0.253660   Top1 92.109375   Top5 99.707031   BatchTime 0.101269   LR 0.001000   
2022-10-20 18:50:02,923 - INFO  - Training [0][   40/  196]   Loss 0.188299   Top1 93.837891   Top5 99.853516   BatchTime 0.087335   LR 0.001000   
2022-10-20 18:50:04,391 - INFO  - Training [0][   60/  196]   Loss 0.159424   Top1 94.707031   Top5 99.902344   BatchTime 0.082693   LR 0.001000   
2022-10-20 18:50:05,859 - INFO  - Training [0][   80/  196]   Loss 0.141042   Top1 95.327148   Top5 99.926758   BatchTime 0.080375   LR 0.001000   
2022-10-20 18:50:07,327 - INFO  - Training [0][  100/  196]   Loss 0.130512   Top1 95.636719   Top5 99.937500   BatchTime 0.078977   LR 0.001000   
2022-10-20 18:50:08,795 - INFO  - Training [0][  120/  196]   Loss 0.122139   Top1 95.885417   Top5 99.944661   BatchTime 0.078048   LR 0.001000   
2022-10-20 18:50:10,265 - INFO  - Training [0][  140/  196]   Loss 0.115888   Top1 96.090960   Top5 99.952567   BatchTime 0.077399   LR 0.001000   
2022-10-20 18:50:11,734 - INFO  - Training [0][  160/  196]   Loss 0.110014   Top1 96.296387   Top5 99.958496   BatchTime 0.076902   LR 0.001000   
2022-10-20 18:50:13,197 - INFO  - Training [0][  180/  196]   Loss 0.104961   Top1 96.477865   Top5 99.963108   BatchTime 0.076482   LR 0.001000   
2022-10-20 18:50:14,416 - INFO  - ==> Top1: 96.552    Top5: 99.966    Loss: 0.102

2022-10-20 18:50:16,860 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-20 18:50:17,971 - INFO  - Validation [0][   20/   40]   Loss 0.333387   Top1 90.976562   Top5 99.589844   BatchTime 0.055486   
2022-10-20 18:50:18,477 - INFO  - Validation [0][   40/   40]   Loss 0.320306   Top1 91.020000   Top5 99.680000   BatchTime 0.040386   
2022-10-20 18:50:18,547 - INFO  - ==> Top1: 91.020    Top5: 99.680    Loss: 0.320

2022-10-20 18:50:18,547 - INFO  - Validation: 10000 samples (256 per mini-batch)
