2022-10-28 08:11:26,480 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-081126/88_20221028-081126.log
2022-10-28 08:11:28,209 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 08:11:28,241 - INFO  - Created `resnet20` model
          Use pre-trained model = True
2022-10-28 08:11:28,408 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 08:11:28,408 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 08:11:29,653 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 08:11:29,653 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:11:32,581 - INFO  - Validation [   20/   40]   Loss 3047.717822   Top1 12.753906   Top5 57.070312   BatchTime 0.146350   
2022-10-28 08:11:34,221 - INFO  - Validation [   40/   40]   Loss 3031.409704   Top1 12.670000   Top5 56.460000   BatchTime 0.114179   
2022-10-28 08:11:34,282 - INFO  - ==> Top1: 12.670    Top5: 56.460    Loss: 3031.410

2022-10-28 08:11:34,282 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 08:11:34,282 - INFO  - >>>>>> Epoch   0
2022-10-28 08:11:34,282 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 08:11:36,511 - INFO  - Training [0][   20/  196]   Loss 1.054907   Top1 71.015625   Top5 97.363281   BatchTime 0.111403   LR 0.001000   
2022-10-28 08:11:38,208 - INFO  - Training [0][   40/  196]   Loss 0.822479   Top1 76.699219   Top5 98.173828   BatchTime 0.098126   LR 0.001000   
2022-10-28 08:11:39,915 - INFO  - Training [0][   60/  196]   Loss 0.700200   Top1 79.342448   Top5 98.554688   BatchTime 0.093864   LR 0.001000   
2022-10-28 08:11:41,616 - INFO  - Training [0][   80/  196]   Loss 0.635726   Top1 80.810547   Top5 98.725586   BatchTime 0.091665   LR 0.001000   
2022-10-28 08:11:43,317 - INFO  - Training [0][  100/  196]   Loss 0.588298   Top1 81.960938   Top5 98.894531   BatchTime 0.090344   LR 0.001000   
2022-10-28 08:11:45,018 - INFO  - Training [0][  120/  196]   Loss 0.549966   Top1 83.007812   Top5 98.994141   BatchTime 0.089458   LR 0.001000   
2022-10-28 08:11:46,719 - INFO  - Training [0][  140/  196]   Loss 0.522564   Top1 83.671875   Top5 99.084821   BatchTime 0.088830   LR 0.001000   
2022-10-28 08:11:48,420 - INFO  - Training [0][  160/  196]   Loss 0.499948   Top1 84.218750   Top5 99.167480   BatchTime 0.088356   LR 0.001000   
2022-10-28 08:11:50,103 - INFO  - Training [0][  180/  196]   Loss 0.481085   Top1 84.739583   Top5 99.212240   BatchTime 0.087887   LR 0.001000   
2022-10-28 08:11:51,501 - INFO  - ==> Top1: 85.018    Top5: 99.250    Loss: 0.470

2022-10-28 08:11:51,613 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:11:53,219 - INFO  - Validation [0][   20/   40]   Loss 0.437068   Top1 86.718750   Top5 99.277344   BatchTime 0.080265   
2022-10-28 08:11:54,295 - INFO  - Validation [0][   40/   40]   Loss 0.432135   Top1 86.590000   Top5 99.370000   BatchTime 0.067048   
2022-10-28 08:11:54,364 - INFO  - ==> Top1: 86.590    Top5: 99.370    Loss: 0.432

2022-10-28 08:11:54,364 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 08:11:56,039 - INFO  - Validation [0][   20/   40]   Loss 2.520423   Top1 10.000000   Top5 50.097656   BatchTime 0.083700   
2022-10-28 08:11:56,984 - INFO  - Validation [0][   40/   40]   Loss 2.519933   Top1 10.000000   Top5 50.210000   BatchTime 0.065495   
2022-10-28 08:11:57,062 - INFO  - ==> Top1: 10.000    Top5: 50.210    Loss: 2.520

2022-10-28 08:11:57,062 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 12.670   Top5: 56.460]
2022-10-28 08:11:57,062 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 10.000   Top5: 50.210]
2022-10-28 08:11:57,097 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQFakeQuant/out/88_20221028-081126/88_checkpoint.pth.tar

2022-10-28 08:11:57,097 - INFO  - >>>>>> Epoch   1
2022-10-28 08:11:57,098 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 08:11:59,388 - INFO  - Training [1][   20/  196]   Loss 0.308631   Top1 89.316406   Top5 99.628906   BatchTime 0.114505   LR 0.001000   
