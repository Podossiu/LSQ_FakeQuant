2022-10-28 11:03:54,010 - INFO  - Log file for this run: /home/ilena7440/LSQFakeQuant/out/88_20221028-110354/88_20221028-110354.log
2022-10-28 11:03:55,745 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-10-28 11:03:55,852 - INFO  - Created `mobilenetv2` model
          Use pre-trained model = True
2022-10-28 11:03:55,869 - INFO  - Optimizer: SGD (
           Parameter Group 0
               dampening: 0
               foreach: None
               lr: 0.001
               maximize: False
               momentum: 0.9
               nesterov: False
               weight_decay: 0.0001
           )
2022-10-28 11:03:55,869 - INFO  - LR scheduler: `MultiStepLr`
    Update per batch: True
             Group 0: 0.001

2022-10-28 11:03:57,118 - INFO  - >>>>>> Epoch -1 (pre-trained model evaluation)
2022-10-28 11:03:57,118 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 11:03:59,072 - INFO  - Validation [   20/   40]   Loss 7.499609   Top1 0.000000   Top5 0.000000   BatchTime 0.095750   
2022-10-28 11:03:59,776 - INFO  - Validation [   40/   40]   Loss 7.499092   Top1 0.000000   Top5 0.000000   BatchTime 0.065472   
2022-10-28 11:03:59,842 - INFO  - ==> Top1: 0.000    Top5: 0.000    Loss: 7.499

2022-10-28 11:03:59,842 - INFO  - Scoreboard best 1 ==> Epoch [-1][Top1: 0.000   Top5: 0.000]
2022-10-28 11:03:59,842 - INFO  - >>>>>> Epoch   0
2022-10-28 11:03:59,842 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-10-28 11:04:01,341 - INFO  - Training [0][   20/  196]   Loss 10.489772   Top1 0.488281   Top5 1.757812   BatchTime 0.074909   LR 0.001000   
2022-10-28 11:04:02,145 - INFO  - Training [0][   40/  196]   Loss 8.292368   Top1 3.798828   Top5 9.365234   BatchTime 0.057537   LR 0.001000   
2022-10-28 11:04:02,917 - INFO  - Training [0][   60/  196]   Loss 7.054090   Top1 9.042969   Top5 20.976562   BatchTime 0.051234   LR 0.001000   
2022-10-28 11:04:03,687 - INFO  - Training [0][   80/  196]   Loss 6.200714   Top1 13.608398   Top5 31.308594   BatchTime 0.048049   LR 0.001000   
2022-10-28 11:04:04,449 - INFO  - Training [0][  100/  196]   Loss 5.569504   Top1 17.312500   Top5 39.812500   BatchTime 0.046051   LR 0.001000   
2022-10-28 11:04:05,211 - INFO  - Training [0][  120/  196]   Loss 5.079158   Top1 20.485026   Top5 46.650391   BatchTime 0.044726   LR 0.001000   
2022-10-28 11:04:05,974 - INFO  - Training [0][  140/  196]   Loss 4.686295   Top1 23.325893   Top5 52.201451   BatchTime 0.043791   LR 0.001000   
2022-10-28 11:04:06,740 - INFO  - Training [0][  160/  196]   Loss 4.361316   Top1 25.895996   Top5 56.733398   BatchTime 0.043105   LR 0.001000   
2022-10-28 11:04:07,496 - INFO  - Training [0][  180/  196]   Loss 4.095337   Top1 27.960069   Top5 60.329861   BatchTime 0.042516   LR 0.001000   
2022-10-28 11:04:08,154 - INFO  - ==> Top1: 29.232    Top5: 62.634    Loss: 3.923

2022-10-28 11:04:08,215 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 11:04:09,938 - INFO  - Validation [0][   20/   40]   Loss 1.819873   Top1 48.593750   Top5 91.054688   BatchTime 0.086123   
2022-10-28 11:04:10,979 - INFO  - Validation [0][   40/   40]   Loss 1.839198   Top1 47.910000   Top5 90.890000   BatchTime 0.069082   
2022-10-28 11:04:11,058 - INFO  - ==> Top1: 47.910    Top5: 90.890    Loss: 1.839

2022-10-28 11:04:11,074 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-10-28 11:04:12,829 - INFO  - Validation [0][   20/   40]   Loss 1.838358   Top1 48.671875   Top5 90.761719   BatchTime 0.087696   
2022-10-28 11:04:13,869 - INFO  - Validation [0][   40/   40]   Loss 1.854390   Top1 48.030000   Top5 90.700000   BatchTime 0.069827   
2022-10-28 11:04:13,951 - INFO  - ==> Top1: 48.030    Top5: 90.700    Loss: 1.854

2022-10-28 11:04:13,952 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 48.030   Top5: 90.700]
2022-10-28 11:04:13,952 - INFO  - Scoreboard best 2 ==> Epoch [-1][Top1: 0.000   Top5: 0.000]
