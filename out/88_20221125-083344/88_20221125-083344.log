2022-11-25 08:33:44,501 - INFO  - Log file for this run: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083344/88_20221125-083344.log
2022-11-25 08:33:48,770 - INFO  - Dataset `cifar10` size:
          Training Set = 50000 (196)
        Validation Set = 10000 (40)
              Test Set = 10000 (40)
2022-11-25 08:33:50,642 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = True
2022-11-25 08:33:51,356 - INFO  - Optimizer: AdamW (
           Parameter Group 0
               amsgrad: False
               betas: (0.9, 0.999)
               capturable: False
               eps: 1e-08
               foreach: None
               lr: 0.0005
               maximize: False
               weight_decay: 4e-05
           )
2022-11-25 08:33:51,356 - INFO  - LR scheduler: `CosineWarmRestartsLr`
    Update per batch: True
             Group 0: 0.0005

2022-11-25 08:33:51,608 - INFO  - >>>>>> Epoch   0
2022-11-25 08:33:51,609 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 08:34:00,670 - INFO  - Training [0][   20/  196]   Loss 1.891364   Top1 62.070312   Top5 90.117188   BatchTime 0.452916   LR 0.000500   
2022-11-25 08:34:08,931 - INFO  - Training [0][   40/  196]   Loss 1.801405   Top1 55.009766   Top5 88.847656   BatchTime 0.433003   LR 0.000500   
2022-11-25 08:34:17,098 - INFO  - Training [0][   60/  196]   Loss 1.662418   Top1 54.290365   Top5 89.179688   BatchTime 0.424780   LR 0.000499   
2022-11-25 08:34:25,259 - INFO  - Training [0][   80/  196]   Loss 1.571847   Top1 54.506836   Top5 89.897461   BatchTime 0.420595   LR 0.000498   
2022-11-25 08:34:33,978 - INFO  - Training [0][  100/  196]   Loss 1.501487   Top1 55.070312   Top5 90.445312   BatchTime 0.423661   LR 0.000497   
2022-11-25 08:34:41,896 - INFO  - Training [0][  120/  196]   Loss 1.444370   Top1 55.940755   Top5 90.856120   BatchTime 0.419039   LR 0.000495   
2022-11-25 08:34:49,550 - INFO  - Training [0][  140/  196]   Loss 1.404827   Top1 56.350446   Top5 91.194196   BatchTime 0.413841   LR 0.000494   
2022-11-25 08:34:58,031 - INFO  - Training [0][  160/  196]   Loss 1.375750   Top1 56.696777   Top5 91.401367   BatchTime 0.415120   LR 0.000492   
2022-11-25 08:35:04,999 - INFO  - Training [0][  180/  196]   Loss 1.345065   Top1 57.263455   Top5 91.616753   BatchTime 0.407706   LR 0.000490   
2022-11-25 08:35:09,986 - INFO  - ==> Top1: 57.806    Top5: 91.816    Loss: 1.321

2022-11-25 08:35:10,180 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 08:35:11,153 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 08:35:13,549 - INFO  - Validation [0][   20/   40]   Loss 0.975193   Top1 67.324219   Top5 96.835938   BatchTime 0.119752   
2022-11-25 08:35:14,711 - INFO  - Validation [0][   40/   40]   Loss 0.968877   Top1 67.500000   Top5 96.880000   BatchTime 0.088924   
2022-11-25 08:35:14,907 - INFO  - ==> Top1: 67.500    Top5: 96.880    Loss: 0.969

2022-11-25 08:35:14,908 - INFO  - ==> Sparsity : 0.102

2022-11-25 08:35:14,908 - INFO  - Scoreboard best 1 ==> Epoch [0][Top1: 67.500   Top5: 96.880]
2022-11-25 08:35:20,357 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083344/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083344/_best.pth.tar
save quantized models...
2022-11-25 08:35:20,360 - INFO  - >>>>>> Epoch   1
2022-11-25 08:35:20,362 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 08:35:29,011 - INFO  - Training [1][   20/  196]   Loss 1.058437   Top1 63.046875   Top5 92.910156   BatchTime 0.432335   LR 0.000485   
2022-11-25 08:35:36,513 - INFO  - Training [1][   40/  196]   Loss 1.050931   Top1 63.525391   Top5 93.398438   BatchTime 0.403722   LR 0.000482   
2022-11-25 08:35:43,900 - INFO  - Training [1][   60/  196]   Loss 1.047999   Top1 63.528646   Top5 93.613281   BatchTime 0.392258   LR 0.000479   
2022-11-25 08:35:51,689 - INFO  - Training [1][   80/  196]   Loss 1.037579   Top1 63.852539   Top5 94.003906   BatchTime 0.391548   LR 0.000476   
2022-11-25 08:35:59,369 - INFO  - Training [1][  100/  196]   Loss 1.021614   Top1 64.464844   Top5 94.222656   BatchTime 0.390043   LR 0.000473   
2022-11-25 08:36:06,622 - INFO  - Training [1][  120/  196]   Loss 1.009535   Top1 64.915365   Top5 94.462891   BatchTime 0.385477   LR 0.000469   
2022-11-25 08:36:14,704 - INFO  - Training [1][  140/  196]   Loss 1.001727   Top1 65.189732   Top5 94.631696   BatchTime 0.388134   LR 0.000465   
2022-11-25 08:36:21,929 - INFO  - Training [1][  160/  196]   Loss 0.995564   Top1 65.336914   Top5 94.682617   BatchTime 0.384772   LR 0.000460   
2022-11-25 08:36:29,576 - INFO  - Training [1][  180/  196]   Loss 0.984363   Top1 65.729167   Top5 94.787326   BatchTime 0.384503   LR 0.000456   
2022-11-25 08:36:34,748 - INFO  - ==> Top1: 65.954    Top5: 94.880    Loss: 0.979

2022-11-25 08:36:34,964 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 08:36:36,350 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 08:36:39,074 - INFO  - Validation [1][   20/   40]   Loss 0.666829   Top1 76.523438   Top5 98.457031   BatchTime 0.136128   
2022-11-25 08:36:40,183 - INFO  - Validation [1][   40/   40]   Loss 0.660221   Top1 76.970000   Top5 98.500000   BatchTime 0.095798   
2022-11-25 08:36:40,389 - INFO  - ==> Top1: 76.970    Top5: 98.500    Loss: 0.660

2022-11-25 08:36:40,389 - INFO  - ==> Sparsity : 0.101

2022-11-25 08:36:40,389 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.970   Top5: 98.500]
2022-11-25 08:36:40,389 - INFO  - Scoreboard best 2 ==> Epoch [0][Top1: 67.500   Top5: 96.880]
2022-11-25 08:36:46,253 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083344/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083344/_best.pth.tar
save quantized models...
2022-11-25 08:36:46,255 - INFO  - >>>>>> Epoch   2
2022-11-25 08:36:46,257 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 08:36:54,746 - INFO  - Training [2][   20/  196]   Loss 0.916694   Top1 68.125000   Top5 95.078125   BatchTime 0.424314   LR 0.000448   
2022-11-25 08:37:02,342 - INFO  - Training [2][   40/  196]   Loss 0.915296   Top1 68.300781   Top5 95.292969   BatchTime 0.402073   LR 0.000443   
2022-11-25 08:37:09,410 - INFO  - Training [2][   60/  196]   Loss 0.903967   Top1 68.710938   Top5 95.507812   BatchTime 0.385838   LR 0.000437   
2022-11-25 08:37:16,502 - INFO  - Training [2][   80/  196]   Loss 0.894689   Top1 68.969727   Top5 95.668945   BatchTime 0.378031   LR 0.000432   
2022-11-25 08:37:24,327 - INFO  - Training [2][  100/  196]   Loss 0.879164   Top1 69.464844   Top5 95.742188   BatchTime 0.380672   LR 0.000426   
2022-11-25 08:37:31,685 - INFO  - Training [2][  120/  196]   Loss 0.871408   Top1 69.628906   Top5 95.823568   BatchTime 0.378542   LR 0.000421   
2022-11-25 08:37:39,612 - INFO  - Training [2][  140/  196]   Loss 0.867396   Top1 69.829799   Top5 95.909598   BatchTime 0.381084   LR 0.000415   
2022-11-25 08:37:46,781 - INFO  - Training [2][  160/  196]   Loss 0.868602   Top1 69.809570   Top5 95.876465   BatchTime 0.378257   LR 0.000409   
2022-11-25 08:37:54,117 - INFO  - Training [2][  180/  196]   Loss 0.862963   Top1 69.958767   Top5 95.852865   BatchTime 0.376981   LR 0.000402   
2022-11-25 08:37:59,641 - INFO  - ==> Top1: 70.148    Top5: 95.868    Loss: 0.858

2022-11-25 08:37:59,845 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 08:38:00,888 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 08:38:03,408 - INFO  - Validation [2][   20/   40]   Loss 0.730417   Top1 76.386719   Top5 97.792969   BatchTime 0.125892   
2022-11-25 08:38:04,646 - INFO  - Validation [2][   40/   40]   Loss 0.738475   Top1 75.880000   Top5 98.020000   BatchTime 0.093911   
2022-11-25 08:38:05,013 - INFO  - ==> Top1: 75.880    Top5: 98.020    Loss: 0.738

2022-11-25 08:38:05,014 - INFO  - ==> Sparsity : 0.100

2022-11-25 08:38:05,014 - INFO  - Scoreboard best 1 ==> Epoch [1][Top1: 76.970   Top5: 98.500]
2022-11-25 08:38:05,014 - INFO  - Scoreboard best 2 ==> Epoch [2][Top1: 75.880   Top5: 98.020]
2022-11-25 08:38:05,014 - INFO  - Scoreboard best 3 ==> Epoch [0][Top1: 67.500   Top5: 96.880]
2022-11-25 08:38:05,166 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083344/_checkpoint.pth.tar

2022-11-25 08:38:05,168 - INFO  - >>>>>> Epoch   3
2022-11-25 08:38:05,170 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 08:38:14,535 - INFO  - Training [3][   20/  196]   Loss 0.854544   Top1 70.507812   Top5 95.468750   BatchTime 0.468107   LR 0.000391   
2022-11-25 08:38:22,090 - INFO  - Training [3][   40/  196]   Loss 0.840012   Top1 70.732422   Top5 95.664062   BatchTime 0.422930   LR 0.000384   
2022-11-25 08:38:29,631 - INFO  - Training [3][   60/  196]   Loss 0.830709   Top1 70.904948   Top5 95.859375   BatchTime 0.407625   LR 0.000377   
2022-11-25 08:38:36,918 - INFO  - Training [3][   80/  196]   Loss 0.821164   Top1 71.323242   Top5 96.201172   BatchTime 0.396806   LR 0.000370   
2022-11-25 08:38:43,908 - INFO  - Training [3][  100/  196]   Loss 0.810464   Top1 71.597656   Top5 96.214844   BatchTime 0.387349   LR 0.000363   
2022-11-25 08:38:50,864 - INFO  - Training [3][  120/  196]   Loss 0.801923   Top1 72.005208   Top5 96.357422   BatchTime 0.380753   LR 0.000356   
2022-11-25 08:38:58,542 - INFO  - Training [3][  140/  196]   Loss 0.797813   Top1 72.165179   Top5 96.411830   BatchTime 0.381202   LR 0.000348   
2022-11-25 08:39:06,510 - INFO  - Training [3][  160/  196]   Loss 0.798729   Top1 72.197266   Top5 96.391602   BatchTime 0.383350   LR 0.000341   
2022-11-25 08:39:13,754 - INFO  - Training [3][  180/  196]   Loss 0.795941   Top1 72.348090   Top5 96.365017   BatchTime 0.381000   LR 0.000333   
2022-11-25 08:39:19,513 - INFO  - ==> Top1: 72.516    Top5: 96.414    Loss: 0.790

2022-11-25 08:39:19,726 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 08:39:21,267 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 08:39:24,652 - INFO  - Validation [3][   20/   40]   Loss 0.621235   Top1 78.613281   Top5 98.593750   BatchTime 0.169117   
2022-11-25 08:39:26,147 - INFO  - Validation [3][   40/   40]   Loss 0.613731   Top1 78.880000   Top5 98.820000   BatchTime 0.121925   
2022-11-25 08:39:26,378 - INFO  - ==> Top1: 78.880    Top5: 98.820    Loss: 0.614

2022-11-25 08:39:26,378 - INFO  - ==> Sparsity : 0.098

2022-11-25 08:39:26,378 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 78.880   Top5: 98.820]
2022-11-25 08:39:26,378 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 76.970   Top5: 98.500]
2022-11-25 08:39:26,379 - INFO  - Scoreboard best 3 ==> Epoch [2][Top1: 75.880   Top5: 98.020]
2022-11-25 08:39:32,775 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083344/_checkpoint.pth.tar
                Best: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083344/_best.pth.tar
save quantized models...
2022-11-25 08:39:32,779 - INFO  - >>>>>> Epoch   4
2022-11-25 08:39:32,782 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 08:39:41,371 - INFO  - Training [4][   20/  196]   Loss 0.762496   Top1 72.792969   Top5 96.464844   BatchTime 0.429342   LR 0.000320   
2022-11-25 08:39:49,388 - INFO  - Training [4][   40/  196]   Loss 0.778303   Top1 72.568359   Top5 96.494141   BatchTime 0.415076   LR 0.000312   
2022-11-25 08:39:56,773 - INFO  - Training [4][   60/  196]   Loss 0.773665   Top1 72.890625   Top5 96.569010   BatchTime 0.399801   LR 0.000304   
2022-11-25 08:40:03,971 - INFO  - Training [4][   80/  196]   Loss 0.770096   Top1 73.120117   Top5 96.606445   BatchTime 0.389827   LR 0.000296   
2022-11-25 08:40:11,339 - INFO  - Training [4][  100/  196]   Loss 0.762761   Top1 73.277344   Top5 96.625000   BatchTime 0.385543   LR 0.000289   
2022-11-25 08:40:18,879 - INFO  - Training [4][  120/  196]   Loss 0.756990   Top1 73.496094   Top5 96.679688   BatchTime 0.384113   LR 0.000281   
2022-11-25 08:40:26,703 - INFO  - Training [4][  140/  196]   Loss 0.751630   Top1 73.677455   Top5 96.752232   BatchTime 0.385125   LR 0.000273   
2022-11-25 08:40:33,628 - INFO  - Training [4][  160/  196]   Loss 0.752680   Top1 73.730469   Top5 96.777344   BatchTime 0.380269   LR 0.000265   
2022-11-25 08:40:40,033 - INFO  - Training [4][  180/  196]   Loss 0.746157   Top1 73.969184   Top5 96.779514   BatchTime 0.373599   LR 0.000257   
2022-11-25 08:40:45,250 - INFO  - ==> Top1: 74.120    Top5: 96.784    Loss: 0.743

2022-11-25 08:40:45,582 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 08:40:47,374 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 08:40:49,694 - INFO  - Validation [4][   20/   40]   Loss 0.717586   Top1 76.562500   Top5 98.007812   BatchTime 0.115912   
2022-11-25 08:40:50,863 - INFO  - Validation [4][   40/   40]   Loss 0.720924   Top1 76.110000   Top5 97.990000   BatchTime 0.087191   
2022-11-25 08:40:51,082 - INFO  - ==> Top1: 76.110    Top5: 97.990    Loss: 0.721

2022-11-25 08:40:51,083 - INFO  - ==> Sparsity : 0.097

2022-11-25 08:40:51,083 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 78.880   Top5: 98.820]
2022-11-25 08:40:51,083 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 76.970   Top5: 98.500]
2022-11-25 08:40:51,083 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 76.110   Top5: 97.990]
2022-11-25 08:40:51,233 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083344/_checkpoint.pth.tar

2022-11-25 08:40:51,234 - INFO  - >>>>>> Epoch   5
2022-11-25 08:40:51,236 - INFO  - Training: 50000 samples (256 per mini-batch)
2022-11-25 08:40:59,544 - INFO  - Training [5][   20/  196]   Loss 0.721547   Top1 74.433594   Top5 96.796875   BatchTime 0.415246   LR 0.000242   
2022-11-25 08:41:06,893 - INFO  - Training [5][   40/  196]   Loss 0.731445   Top1 74.384766   Top5 96.718750   BatchTime 0.391365   LR 0.000234   
2022-11-25 08:41:14,180 - INFO  - Training [5][   60/  196]   Loss 0.721855   Top1 74.811198   Top5 96.861979   BatchTime 0.382349   LR 0.000226   
2022-11-25 08:41:21,335 - INFO  - Training [5][   80/  196]   Loss 0.720879   Top1 74.956055   Top5 96.972656   BatchTime 0.376204   LR 0.000218   
2022-11-25 08:41:29,631 - INFO  - Training [5][  100/  196]   Loss 0.712766   Top1 75.289062   Top5 97.113281   BatchTime 0.383924   LR 0.000210   
2022-11-25 08:41:37,255 - INFO  - Training [5][  120/  196]   Loss 0.706080   Top1 75.530599   Top5 97.216797   BatchTime 0.383466   LR 0.000202   
2022-11-25 08:41:44,693 - INFO  - Training [5][  140/  196]   Loss 0.705738   Top1 75.488281   Top5 97.276786   BatchTime 0.381812   LR 0.000195   
2022-11-25 08:41:51,865 - INFO  - Training [5][  160/  196]   Loss 0.711008   Top1 75.322266   Top5 97.229004   BatchTime 0.378908   LR 0.000187   
2022-11-25 08:41:59,088 - INFO  - Training [5][  180/  196]   Loss 0.707997   Top1 75.418837   Top5 97.187500   BatchTime 0.376937   LR 0.000179   
2022-11-25 08:42:04,474 - INFO  - ==> Top1: 75.482    Top5: 97.208    Loss: 0.705

2022-11-25 08:42:05,036 - INFO  - Created `MobileNetv2` model
          Use pre-trained model = False
2022-11-25 08:42:08,043 - INFO  - Validation: 10000 samples (256 per mini-batch)
2022-11-25 08:42:10,415 - INFO  - Validation [5][   20/   40]   Loss 0.842597   Top1 72.031250   Top5 96.660156   BatchTime 0.118527   
2022-11-25 08:42:11,602 - INFO  - Validation [5][   40/   40]   Loss 0.846620   Top1 71.900000   Top5 96.740000   BatchTime 0.088937   
2022-11-25 08:42:11,900 - INFO  - ==> Top1: 71.900    Top5: 96.740    Loss: 0.847

2022-11-25 08:42:11,900 - INFO  - ==> Sparsity : 0.097

2022-11-25 08:42:11,900 - INFO  - Scoreboard best 1 ==> Epoch [3][Top1: 78.880   Top5: 98.820]
2022-11-25 08:42:11,901 - INFO  - Scoreboard best 2 ==> Epoch [1][Top1: 76.970   Top5: 98.500]
2022-11-25 08:42:11,901 - INFO  - Scoreboard best 3 ==> Epoch [4][Top1: 76.110   Top5: 97.990]
2022-11-25 08:42:12,065 - INFO  - Saving checkpoint to:
            Current: /home/ilena7440/LSQ_FakeQuant/out/88_20221125-083344/_checkpoint.pth.tar

2022-11-25 08:42:12,067 - INFO  - >>>>>> Epoch   6
2022-11-25 08:42:12,069 - INFO  - Training: 50000 samples (256 per mini-batch)
